Input Function,Expected If,Predicted If,CodeBLEU Score,BLEU-4 Score,Exact Match?
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> if DEBUG_COMM : <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> if ignore_non_errors and is_noerr ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise ","if ignore_timeouts and is_timeout ( e ) : 
","if ignore_timeouts and is_noerr ( e ) :
",75.22,73.49,False
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> if reuse_len is not None and reuse_len > 0 : <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem ","if prev_mem is None : 
","if len ( curr_out ) > mem_len :
",27.37,4.79,False
def filtered ( gen ) : <TAB> for example in gen : <TAB> <TAB> example_len = length_fn ( example ) <TAB> <TAB> # Checking max length boundary. <TAB> <TAB> if max_length is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Checking min length boundary. <TAB> <TAB> if min_length is not None : <TAB> <TAB> <TAB> if example_len < min_length : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Within bounds. <TAB> <TAB> yield example ,"if example_len > max_length : 
","if example_len > max_length :
",100.0,100.0,True
"def search ( self , query ) : <TAB> # ""Search.ashx?query="" + query + filterVal <TAB> if not query : <TAB> <TAB> logger . debug ( "" Empty search query "" ) <TAB> <TAB> return [ ] <TAB> logger . debug ( ' Searching TuneIn for  "" %s "" ' % query ) <TAB> args = "" &query= "" + query <TAB> search_results = self . _tunein ( "" Search.ashx "" , args ) <TAB> results = [ ] <TAB> for item in self . _flatten ( search_results ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Only return stations <TAB> <TAB> <TAB> self . _stations [ item [ "" guide_id "" ] ] = item <TAB> <TAB> <TAB> results . append ( item ) <TAB> return results ","if item . get ( "" type "" , "" "" ) == "" audio "" : 
","if "" guide_id "" in item :
",34.08,2.62,False
"def _check_script ( self , script , directive ) : <TAB> for var in compile_script ( script ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Skip variable checks <TAB> <TAB> <TAB> return False <TAB> <TAB> if var . can_contain ( "" . "" ) : <TAB> <TAB> <TAB> # Yay! Our variable can contain any symbols! <TAB> <TAB> <TAB> reason = ( <TAB> <TAB> <TAB> <TAB> ' At least variable  "" $ {var} ""  can contain untrusted user input ' . format ( <TAB> <TAB> <TAB> <TAB> <TAB> var = var . name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . add_issue ( directive = [ directive ] + var . providers , reason = reason ) <TAB> <TAB> <TAB> return True <TAB> return False ","if var . must_contain ( "" / "" ) : 
","if not var . is_trusted :
",31.94,8.42,False
"def getAllDataLinkIDs ( ) : <TAB> linkDataIDs = set ( ) <TAB> dataType = _forestData . dataTypeBySocket <TAB> for socketID , linkedIDs in _forestData . linkedSockets . items ( ) : <TAB> <TAB> for linkedID in linkedIDs : <TAB> <TAB> <TAB> if socketID [ 1 ] :<TAB> # check which one is origin/target <TAB> <TAB> <TAB> <TAB> linkDataIDs . add ( <TAB> <TAB> <TAB> <TAB> <TAB> ( socketID , linkedID , dataType [ socketID ] , dataType [ linkedID ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> linkDataIDs . add ( <TAB> <TAB> <TAB> <TAB> <TAB> ( linkedID , socketID , dataType [ linkedID ] , dataType [ socketID ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return linkDataIDs ","if socketID [ 1 ] : 
","if socketID [ 1 ] :
",100.0,100.0,True
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> if curses : <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama : <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False ","if curses . tigetnum ( "" colors "" ) > 0 : 
","if curses . tigetnum ( "" colors "" ) > 0 :
",100.0,100.0,True
"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB> <TAB> if isinstance ( ty , SimTypeBottom ) : <TAB> <TAB> <TAB> l . warning ( <TAB> <TAB> <TAB> <TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB> <TAB> <TAB> <TAB> "" element size. "" , <TAB> <TAB> <TAB> <TAB> self . name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self . _pack : <TAB> <TAB> <TAB> align = ty . alignment <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> offset_so_far + = align - offset_so_far % align <TAB> <TAB> offsets [ name ] = offset_so_far <TAB> <TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets ","if offset_so_far % align != 0 : 
","if align > offset_so_far % align :
",40.7,55.49,False
"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB> <TAB> if issubclass ( picker . __class__ , wx . FileDialog ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value [ - 1 ] <TAB> <TAB> picker . SetPath ( value ) <TAB> <TAB> return True <TAB> return False ","if type ( value ) == list : 
","if value [ - 2 ] == "" / "" :
",26.65,8.52,False
"def dt_s_tup_to_string ( dt_s_tup ) : <TAB> dt_string = dt_s_tup [ 0 ]<TAB> # string for identifying the file to parse. <TAB> if dt_s_tup [ 1 ] > 0 :<TAB> # if there are seasons in the model <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dt_string = dt_string [ : 2 ] + "" s "" + dt_string [ 2 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> dt_string = "" s "" + dt_string <TAB> return dt_string ","if "" co "" in dt_string or "" ci "" in dt_string or "" nc "" in dt_string : 
","if dt_string [ : 2 ] == "" s "" :
",33.2,5.96,False
"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB> <TAB> stream . write ( sep ) <TAB> <TAB> sep = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> if not PY3K : <TAB> <TAB> <TAB> if not isinstance ( item , unicode ) : <TAB> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" ) ","if not isinstance ( item , str ) : 
","if not isinstance ( item , unicode ) :
",83.27,66.06,False
"def _get_result_keys ( self , config ) : <TAB> result_key = config . get ( "" result_key "" ) <TAB> if result_key is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result_key = [ result_key ] <TAB> <TAB> result_key = [ jmespath . compile ( rk ) for rk in result_key ] <TAB> <TAB> return result_key ","if not isinstance ( result_key , list ) : 
","if not isinstance ( result_key , list ) :
",100.0,100.0,True
"def _download_build_artifacts ( self , build : Dict [ str , Any ] ) - > None : <TAB> arch = build [ "" arch_tag "" ] <TAB> snap_build = self . _lp_load_url ( build [ "" self_link "" ] ) <TAB> urls = snap_build . getFileUrls ( ) <TAB> if not urls : <TAB> <TAB> logger . error ( f "" Snap file not available for arch  { arch !r} . "" ) <TAB> <TAB> return <TAB> for url in urls : <TAB> <TAB> file_name = _get_url_basename ( url ) <TAB> <TAB> self . _download_file ( url = url , dst = file_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . info ( f "" Snapped  { file_name } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" Fetched  { file_name } "" ) ","if file_name . endswith ( "" .snap "" ) : 
","if arch == "" snap "" :
",30.74,7.43,False
"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB> <TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB> <TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB> <TAB> if not isinstance ( custom_statements , list ) : <TAB> <TAB> <TAB> custom_statements = [ custom_statements ] <TAB> <TAB> statement = self . resource_policy [ "" Statement "" ] <TAB> <TAB> if not isinstance ( statement , list ) : <TAB> <TAB> <TAB> statement = [ statement ] <TAB> <TAB> for s in custom_statements : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> statement . append ( s ) <TAB> <TAB> self . resource_policy [ "" Statement "" ] = statement ","if s not in statement : 
","if s not in statement :
",100.0,100.0,True
"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB> <TAB> message : Optional [ str ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message = f "" { idx } .  { check . message } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast ( Case , check . example )<TAB> # filtered in `_get_unique_failures` <TAB> <TAB> display_example ( example , check . name , message , result . seed ) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> if idx != len ( checks ) : <TAB> <TAB> <TAB> click . echo ( "" \n "" ) ","if check . message : 
","if check . message :
",100.0,100.0,True
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" qangaroo "" ) <TAB> version = "" v1.1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data . remove_dir ( dpath ) <TAB> <TAB> build_data . make_dir ( dpath ) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES : <TAB> <TAB> <TAB> downloadable_file . download_file ( dpath ) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data . mark_done ( dpath , version_string = version ) ","if build_data . built ( dpath ) : 
","if build_data . built ( dpath ) :
",100.0,100.0,True
"def call ( self , step_input , states ) : <TAB> new_states = [ ] <TAB> for i in range ( self . num_layers ) : <TAB> <TAB> out , new_state = self . lstm_cells [ i ] ( step_input , states [ i ] ) <TAB> <TAB> step_input = ( <TAB> <TAB> <TAB> layers . dropout ( <TAB> <TAB> <TAB> <TAB> out , self . dropout_prob , dropout_implementation = "" upscale_in_train "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else out <TAB> <TAB> ) <TAB> <TAB> new_states . append ( new_state ) <TAB> return step_input , new_states ","if self . dropout_prob > 0.0 
","if self . dropout_prob
",59.71,71.65,False
"def jupyter_progress_bar ( min = 0 , max = 1.0 ) : <TAB> """"""Returns an ipywidget progress bar or None if we can't import it"""""" <TAB> widgets = wandb . util . get_module ( "" ipywidgets "" ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # TODO: this currently works in iPython but it's deprecated since 4.0 <TAB> <TAB> <TAB> from IPython . html import widgets<TAB> # type: ignore <TAB> <TAB> assert hasattr ( widgets , "" VBox "" ) <TAB> <TAB> assert hasattr ( widgets , "" Label "" ) <TAB> <TAB> assert hasattr ( widgets , "" FloatProgress "" ) <TAB> <TAB> return ProgressWidget ( widgets , min = min , max = max ) <TAB> except ( ImportError , AssertionError ) : <TAB> <TAB> return None ","if widgets is None : 
","if widgets is not None :
",64.71,37.99,False
"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB> <TAB> self . events [ path ] . append ( events ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not os . path . exists ( path ) : <TAB> <TAB> <TAB> <TAB> self . watches . pop ( path ) . close ( ) ","if events | pyuv . fs . UV_RENAME : 
","if error is None :
",26.57,3.83,False
"def _get_v1_id_from_tags ( self , tags_obj , tag ) : <TAB> """"""Get image id from array of tags"""""" <TAB> if isinstance ( tags_obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return tags_obj [ tag ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> elif isinstance ( tags_obj , [ ] ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> for tag_dict in tags_obj : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return tag_dict [ "" layer "" ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> return "" "" ","if tag_dict [ "" name "" ] == tag : 
","if tag_dict [ "" name "" ] == "" v1 "" :
",70.51,71.66,False
"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB> <TAB> rs = domain . connection . query_with_attributes ( <TAB> <TAB> <TAB> domain , query , attr_names , next_token = next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if num_results == max_items : <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results + = 1 <TAB> <TAB> next_token = rs . next_token <TAB> <TAB> more_results = next_token != None ","if max_items : 
","if max_items :
",78.12,100.0,True
"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB> <TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kValue = array . get ( unicode ( k ) ) <TAB> <TAB> <TAB> if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) : <TAB> <TAB> <TAB> <TAB> res . append ( kValue ) <TAB> <TAB> k + = 1 <TAB> return args . space . ConstructArray ( res ) ","if array . has_property ( unicode ( k ) ) : 
","if array . has_property ( unicode ( k ) ) :
",100.0,100.0,True
"def every_one_is ( self , dst ) : <TAB> msg = "" all members of  %r  should be  %r , but the  %d th is  %r "" <TAB> for index , item in enumerate ( self . _src ) : <TAB> <TAB> if self . _range : <TAB> <TAB> <TAB> if index < self . _range [ 0 ] or index > self . _range [ 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> error = msg % ( self . _src , dst , index , item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AssertionError ( error ) <TAB> return True ","if item != dst : 
","if isinstance ( error , int ) :
",27.64,6.57,False
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> if delete : <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> if key in LoggerFactory . schedule_logger_dict : <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id ) ","if job_id in key : 
","if key == job_id + "" delete "" :
",27.63,14.99,False
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast ( TupleStr4 , item ) <TAB> <TAB> if item [ 0 ] : <TAB> <TAB> <TAB> typ = "" number "" <TAB> <TAB> <TAB> val = item [ 0 ] <TAB> <TAB> elif item [ 1 ] : <TAB> <TAB> <TAB> typ = "" name "" <TAB> <TAB> <TAB> val = item [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> typ = item [ 2 ] <TAB> <TAB> <TAB> val = item [ 2 ] <TAB> <TAB> elif item [ 3 ] : <TAB> <TAB> <TAB> typ = item [ 3 ] <TAB> <TAB> <TAB> val = item [ 3 ] <TAB> <TAB> yield Token ( typ , val ) ","elif item [ 2 ] : 
","elif item [ 2 ] :
",100.0,100.0,True
"def _read_data_from_all_categories ( self , directory , config , categories ) : <TAB> lines = [ ] <TAB> for category in categories : <TAB> <TAB> data_file = os . path . join ( directory , _DATASET_VERSION , category , config ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with open ( data_file ) as f : <TAB> <TAB> <TAB> <TAB> ls = f . read ( ) . split ( "" \n "" ) <TAB> <TAB> <TAB> <TAB> for l in ls [ : : - 1 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if not l : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ls . remove ( l ) <TAB> <TAB> <TAB> <TAB> lines . extend ( ls ) <TAB> return lines ","if os . path . exists ( data_file ) : 
","if os . path . exists ( data_file ) :
",100.0,100.0,True
"def find_handlers ( self , forms ) : <TAB> handlers = { } <TAB> for form in forms . itervalues ( ) : <TAB> <TAB> for action_name , _action_label in form . actions : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> handlers [ action_name ] = form <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise HandlerError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" More than one form defines the handler  %s "" % action_name <TAB> <TAB> <TAB> <TAB> ) <TAB> return handlers ","if action_name not in handlers : 
","if action_name in self . handlers :
",30.73,36.89,False
"def get_story_task_completed_body ( payload : Dict [ str , Any ] ) - > Optional [ str ] : <TAB> action = get_action_with_primary_id ( payload ) <TAB> kwargs = { <TAB> <TAB> "" task_description "" : action [ "" description "" ] , <TAB> } <TAB> story_id = action [ "" story_id "" ] <TAB> for ref in payload [ "" references "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs [ "" name_template "" ] = STORY_NAME_TEMPLATE . format ( <TAB> <TAB> <TAB> <TAB> name = ref [ "" name "" ] , <TAB> <TAB> <TAB> <TAB> app_url = ref [ "" app_url "" ] , <TAB> <TAB> <TAB> ) <TAB> if action [ "" changes "" ] [ "" complete "" ] [ "" new "" ] : <TAB> <TAB> return STORY_TASK_COMPLETED_TEMPLATE . format ( * * kwargs ) <TAB> else : <TAB> <TAB> return None ","if ref [ "" id "" ] == story_id : 
","if story_id == ref [ "" story_id "" ] :
",42.64,25.41,False
"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB> <TAB> for j in range ( len ( nodes ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB> <TAB> <TAB> if graph . has_edge ( edge ) : <TAB> <TAB> <TAB> <TAB> graph . del_edge ( edge ) <TAB> <TAB> <TAB> graph . add_edge ( edge , 1 ) ","if i == j : 
","if i == j :
",100.0,100.0,True
"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> <TAB> return op . body <TAB> <TAB> if op . attr_key == "" virtual_thread "" : <TAB> <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> <TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" ) ","if op . attr_key == "" storage_scope "" : 
","if op . attr_key == "" virtual_thread "" :
",83.19,65.92,False
"def format_lazy_import ( names ) : <TAB> """"""Formats lazy import lines"""""" <TAB> lines = "" "" <TAB> for _ , name , asname in names : <TAB> <TAB> pkg , _ , _ = name . partition ( "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line = "" {pkg}  = _LazyModule.load( {pkg!r} ,  {mod!r} ) \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> line = "" {asname}  = _LazyModule.load( {pkg!r} ,  {mod!r} ,  {asname!r} ) \n "" <TAB> <TAB> lines + = line . format ( pkg = pkg , mod = name , asname = asname ) <TAB> return lines ","if asname is None : 
","if asname is None :
",100.0,100.0,True
"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . endswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self . words : <TAB> <TAB> <TAB> <TAB> matched = bool ( re . search ( _regex , w ) ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] ) ","if matched : 
","if matched :
",78.12,0.0,False
"def setup ( self , ir : "" IR "" , aconf : Config ) - > bool : <TAB> if self . kind == "" ConsulResolver "" : <TAB> <TAB> self . resolve_with = "" consul "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . post_error ( "" ConsulResolver is required to have a datacenter "" ) <TAB> <TAB> <TAB> return False <TAB> elif self . kind == "" KubernetesServiceResolver "" : <TAB> <TAB> self . resolve_with = "" k8s "" <TAB> elif self . kind == "" KubernetesEndpointResolver "" : <TAB> <TAB> self . resolve_with = "" k8s "" <TAB> else : <TAB> <TAB> self . post_error ( f "" Resolver kind  { self . kind }  unknown "" ) <TAB> <TAB> return False <TAB> return True ","if not self . get ( "" datacenter "" ) : 
","if not self . datacenter :
",41.68,24.44,False
"def get_success_url ( self ) : <TAB> """"""Continue to the flow index or redirect according `?back` parameter."""""" <TAB> if "" back "" in self . request . GET : <TAB> <TAB> back_url = self . request . GET [ "" back "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> back_url = "" / "" <TAB> <TAB> return back_url <TAB> return reverse ( self . success_url ) ","if not is_safe_url ( url = back_url , allowed_hosts = { self . request . get_host ( ) } ) : 
","if not back_url . endswith ( "" / "" ) :
",28.61,4.51,False
"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB> <TAB> if url . startswith ( "" https:// "" ) : <TAB> <TAB> <TAB> url = url [ 8 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url = "" http:// "" + url <TAB> <TAB> if playlist : <TAB> <TAB> <TAB> download_playlist ( <TAB> <TAB> <TAB> <TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ","if not url . startswith ( "" http:// "" ) : 
","if not url . startswith ( "" http "" ) :
",85.27,61.92,False
"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB> <TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> buf . append ( "" line  "" ) <TAB> <TAB> buf . append ( str ( self . line ) ) <TAB> <TAB> if self . column != - 1 : <TAB> <TAB> <TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB> <TAB> buf . append ( "" : "" ) <TAB> buf . append ( "" "" ) <TAB> return str ( "" "" ) . join ( buf ) ","if not self . fileName : 
","if self . column != - 1 :
",35.47,11.34,False
"def parse_bash_set_output ( output ) : <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output . replace ( "" \\ \n "" , "" "" ) <TAB> environ = { } <TAB> for line in output . splitlines ( 0 ) : <TAB> <TAB> line = line . rstrip ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue<TAB> # skip black lines <TAB> <TAB> item = _ParseBashEnvStr ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> environ [ item [ 0 ] ] = item [ 1 ] <TAB> return environ ","if item : 
","if item :
",78.12,0.0,False
"def remove_selected ( self ) : <TAB> """"""Removes selected items from list."""""" <TAB> to_delete = [ ] <TAB> for i in range ( len ( self ) ) : <TAB> <TAB> if self [ i ] . selected : <TAB> <TAB> <TAB> to_delete . append ( i ) <TAB> to_delete . reverse ( ) <TAB> for i in to_delete : <TAB> <TAB> self . pop ( i ) <TAB> if len ( to_delete ) > 0 : <TAB> <TAB> first_to_delete = to_delete [ - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self [ 0 ] . selected = True <TAB> <TAB> elif first_to_delete > 0 : <TAB> <TAB> <TAB> self [ first_to_delete - 1 ] . selected = True ","if first_to_delete == 0 and len ( self ) > 0 : 
","if first_to_delete == 0 :
",39.39,46.21,False
"def update ( self , update_tracks = True ) : <TAB> self . enable_update_metadata_images ( False ) <TAB> old_album_title = self . metadata [ "" album "" ] <TAB> self . metadata [ "" album "" ] = config . setting [ "" nat_name "" ] <TAB> for track in self . tracks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> track . metadata [ "" album "" ] = self . metadata [ "" album "" ] <TAB> <TAB> for file in track . linked_files : <TAB> <TAB> <TAB> track . update_file_metadata ( file ) <TAB> self . enable_update_metadata_images ( True ) <TAB> super ( ) . update ( update_tracks ) ","if old_album_title == track . metadata [ "" album "" ] : 
","if track . metadata [ "" album "" ] != old_album_title :
",70.8,66.38,False
"def on_input ( self , target , message ) : <TAB> if message . strip ( ) == "" "" : <TAB> <TAB> self . panel ( "" No commit message provided "" ) <TAB> <TAB> return <TAB> if target : <TAB> <TAB> command = [ "" git "" , "" add "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> command . append ( "" --all "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> command . extend ( ( "" -- "" , target ) ) <TAB> <TAB> self . run_command ( command , functools . partial ( self . add_done , message ) ) <TAB> else : <TAB> <TAB> self . add_done ( message , "" "" ) ","if target == "" * "" : 
","if target == "" all "" :
",74.63,59.46,False
"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB> <TAB> filename , position = self . last_edit_cursor_pos <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> self . load ( filename ) <TAB> <TAB> <TAB> editor = self . get_current_editor ( ) <TAB> <TAB> <TAB> if position < editor . document ( ) . characterCount ( ) : <TAB> <TAB> <TAB> <TAB> editor . set_cursor_position ( position ) ","if not osp . isfile ( filename ) : 
","if filename is None :
",26.63,6.32,False
"def returnByType ( self , results ) : <TAB> new_results = { } <TAB> for r in results : <TAB> <TAB> type_name = r . get ( "" type "" , "" movie "" ) + "" s "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_results [ type_name ] = [ ] <TAB> <TAB> new_results [ type_name ] . append ( r ) <TAB> # Combine movies, needs a cleaner way.. <TAB> if "" movies "" in new_results : <TAB> <TAB> new_results [ "" movies "" ] = self . combineOnIMDB ( new_results [ "" movies "" ] ) <TAB> return new_results ","if type_name not in new_results : 
","if type_name not in new_results :
",100.0,100.0,True
"def cache_sns_topics_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> for account_id in accounts_d . keys ( ) : <TAB> <TAB> if config . get ( "" environment "" ) == "" prod "" : <TAB> <TAB> <TAB> cache_sns_topics_for_account . delay ( account_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cache_sns_topics_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True ","if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) : 
","if config . get ( "" environment "" ) == "" prod "" :
",45.44,16.72,False
"def get ( self , subject , topic ) : <TAB> """"""Handles GET requests."""""" <TAB> if subject in feconf . AVAILABLE_LANDING_PAGES : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . render_template ( "" topic-landing-page.mainpage.html "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise self . PageNotFoundException <TAB> else : <TAB> <TAB> raise self . PageNotFoundException ","if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] : 
","if topic in feconf . AVAILABLE_LANDING_PAGES [ subject ] :
",100.0,100.0,True
"def callback ( compiled ) : <TAB> <MASK> <TAB> <TAB> logger . show_tabulated ( <TAB> <TAB> <TAB> "" Compiled "" , showpath ( codepath ) , "" without writing to file. "" <TAB> <TAB> ) <TAB> else : <TAB> <TAB> with univ_open ( destpath , "" w "" ) as opened : <TAB> <TAB> <TAB> writefile ( opened , compiled ) <TAB> <TAB> logger . show_tabulated ( "" Compiled to "" , showpath ( destpath ) , "" . "" ) <TAB> if self . show : <TAB> <TAB> print ( compiled ) <TAB> if run : <TAB> <TAB> if destpath is None : <TAB> <TAB> <TAB> self . execute ( compiled , path = codepath , allow_show = False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . execute_file ( destpath ) ","if destpath is None : 
","if destpath is None :
",100.0,100.0,True
"def _find_start_index ( self , string , start , end ) : <TAB> while True : <TAB> <TAB> index = string . find ( "" { "" , start , end ) - 1 <TAB> <TAB> if index < 0 : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return index <TAB> <TAB> start = index + 2 ","if self . _start_index_is_ok ( string , index ) : 
","if string [ index : index + 2 ] == "" } "" :
",26.32,3.44,False
"def _get_nlu_target_format ( export_path : Text ) - > Text : <TAB> guessed_format = loading . guess_format ( export_path ) <TAB> if guessed_format not in { MARKDOWN , RASA , RASA_YAML } : <TAB> <TAB> if rasa . shared . data . is_likely_json_file ( export_path ) : <TAB> <TAB> <TAB> guessed_format = RASA <TAB> <TAB> elif rasa . shared . data . is_likely_markdown_file ( export_path ) : <TAB> <TAB> <TAB> guessed_format = MARKDOWN <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> guessed_format = RASA_YAML <TAB> return guessed_format ","elif rasa . shared . data . is_likely_yaml_file ( export_path ) : 
","elif rasa . shared . data . is_likely_yaml_file ( export_path ) :
",100.0,100.0,True
"def moveToThreadNext ( self ) : <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p . v : <TAB> <TAB> if p . v . children : <TAB> <TAB> <TAB> p . moveToFirstChild ( ) <TAB> <TAB> el<MASK> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> while p : <TAB> <TAB> <TAB> <TAB> if p . hasNext ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> <TAB> <TAB> <TAB> break<TAB> # found <TAB> <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> # not found. <TAB> return p ","if p . hasNext ( ) : 
","elif p . hasNext ( ) :
",68.29,80.91,False
"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB> <TAB> value = getattr ( obj , attr , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB> if formatter is not None : <TAB> <TAB> <TAB> value = formatter ( attr , value ) <TAB> <TAB> info_add ( name , value ) ","if value is None : 
","if value is None :
",100.0,100.0,True
"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB> <TAB> <TAB> if attr != None : <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB> <TAB> <TAB> <TAB> yield element ","if desc . getAttributeNS ( RDF_NAMESPACE , "" about "" ) == aboutUri : 
","if desc . getAttributeNS ( RDF_NAMESPACE , name ) == aboutUri :
",59.76,70.04,False
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ) ,"if self . timeout is not None : 
","if self . counter < self . count :
",36.53,19.07,False
"def _parse_fixits ( message , titer , line ) : <TAB> """"""Parses fixit messages."""""" <TAB> while ( <TAB> <TAB> OutputParser . message_line_re . match ( line ) is None <TAB> <TAB> and OutputParser . note_line_re . match ( line ) is None <TAB> ) : <TAB> <TAB> message_text = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message . fixits . append ( <TAB> <TAB> <TAB> <TAB> Note ( <TAB> <TAB> <TAB> <TAB> <TAB> message . path , <TAB> <TAB> <TAB> <TAB> <TAB> message . line , <TAB> <TAB> <TAB> <TAB> <TAB> line . find ( message_text ) + 1 , <TAB> <TAB> <TAB> <TAB> <TAB> message_text , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> line = next ( titer ) <TAB> return line ","if message_text != "" "" : 
","if message_text :
",30.04,31.77,False
"def _connect_db ( self , force_reconnect = False ) : <TAB> thread_id = thread . get_ident ( ) <TAB> if force_reconnect and thread_id in ENGINES : <TAB> <TAB> del ENGINES [ thread_id ] <TAB> conn = None <TAB> try : <TAB> <TAB> engine = ENGINES [ thread_id ] <TAB> <TAB> conn = engine . connect ( ) <TAB> <TAB> _test = conn . execute ( "" SELECT 1 "" ) <TAB> <TAB> _test . fetchall ( ) <TAB> except ( KeyError , MySQLdb . OperationalError ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conn . close ( ) <TAB> <TAB> engine = sqla . create_engine ( self . db_url , pool_recycle = 3600 ) <TAB> <TAB> ENGINES [ thread_id ] = engine <TAB> <TAB> conn = engine . connect ( ) <TAB> return conn ","if conn : 
","if conn :
",78.12,0.0,False
"def read ( self , n ) : <TAB> if self . current_frame : <TAB> <TAB> data = self . current_frame . read ( n ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current_frame = None <TAB> <TAB> <TAB> return self . file_read ( n ) <TAB> <TAB> if len ( data ) < n : <TAB> <TAB> <TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return self . file_read ( n ) ","if not data and n != 0 : 
","if not data :
",37.8,18.31,False
"def __setLoadCmd ( self ) : <TAB> base = self . __rawLoadCmd <TAB> for _ in range ( self . __machHeader . ncmds ) : <TAB> <TAB> command = LOAD_COMMAND . from_buffer_copy ( base ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND . from_buffer_copy ( base ) <TAB> <TAB> <TAB> self . __setSections ( segment , base [ 56 : ] , 32 ) <TAB> <TAB> elif command . cmd == MACHOFlags . LC_SEGMENT_64 : <TAB> <TAB> <TAB> segment = SEGMENT_COMMAND64 . from_buffer_copy ( base ) <TAB> <TAB> <TAB> self . __setSections ( segment , base [ 72 : ] , 64 ) <TAB> <TAB> base = base [ command . cmdsize : ] ","if command . cmd == MACHOFlags . LC_SEGMENT : 
","if command . cmd == MACHOFlags . LC_SEGMENT_32 :
",87.71,77.44,False
"def emit_post_sync_signal ( created_models , verbosity , interactive , db ) : <TAB> # Emit the post_sync signal for every application. <TAB> for app in models . get_apps ( ) : <TAB> <TAB> app_name = app . __name__ . split ( "" . "" ) [ - 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Running post-sync handlers for application  %s "" % app_name ) <TAB> <TAB> models . signals . post_syncdb . send ( <TAB> <TAB> <TAB> sender = app , <TAB> <TAB> <TAB> app = app , <TAB> <TAB> <TAB> created_models = created_models , <TAB> <TAB> <TAB> verbosity = verbosity , <TAB> <TAB> <TAB> interactive = interactive , <TAB> <TAB> <TAB> db = db , <TAB> <TAB> ) ","if verbosity > = 2 : 
","if verbosity > = 2 :
",100.0,100.0,True
"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB> <TAB> repo = _get_repo ( ) <TAB> <TAB> _confirm_dangerous ( ) <TAB> <TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB> <TAB> if url in repo . remotes : <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo . remotes . get ( origin ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> repo . pull ( origin_uri = url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB> <TAB> print ( command_help [ "" git pull "" ] ) ","if url : 
","if url :
",78.12,0.0,False
"def version ( self ) : <TAB> try : <TAB> <TAB> return self . _version <TAB> except AttributeError : <TAB> <TAB> for line in self . _get_metadata ( self . PKG_INFO ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _version = safe_version ( line . split ( "" : "" , 1 ) [ 1 ] . strip ( ) ) <TAB> <TAB> <TAB> <TAB> return self . _version <TAB> <TAB> else : <TAB> <TAB> <TAB> tmpl = "" Missing  ' Version: '  header and/or  %s  file "" <TAB> <TAB> <TAB> raise ValueError ( tmpl % self . PKG_INFO , self ) ","if line . lower ( ) . startswith ( "" version: "" ) : 
","if line . startswith ( "" Version: "" ) :
",49.49,39.19,False
"def increment ( self , metric , labels , delta ) : <TAB> """"""Increment a value by |delta|."""""" <TAB> with self . _lock : <TAB> <TAB> key = self . _get_key ( metric . name , labels ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> start_time = self . _store [ key ] . start_time <TAB> <TAB> <TAB> value = self . _store [ key ] . value + delta <TAB> <TAB> else : <TAB> <TAB> <TAB> start_time = time . time ( ) <TAB> <TAB> <TAB> value = metric . default_value + delta <TAB> <TAB> self . _store [ key ] = _StoreValue ( metric , labels , start_time , value ) ","if key in self . _store : 
","if key in self . _store :
",100.0,100.0,True
"def get_current_connections ( session ) : <TAB> """"""Retrieves open connections using the the given session"""""" <TAB> # Use Show process list to count the open sesions. <TAB> res = session . sql ( "" SHOW PROCESSLIST "" ) . execute ( ) <TAB> rows = res . fetch_all ( ) <TAB> connections = { } <TAB> for row in rows : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> connections [ row . get_string ( "" User "" ) ] = [ row . get_string ( "" Host "" ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> connections [ row . get_string ( "" User "" ) ] . append ( row . get_string ( "" Host "" ) ) <TAB> return connections ","if row . get_string ( "" User "" ) not in connections : 
","if row . get_string ( "" User "" ) not in connections :
",100.0,100.0,True
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> if path == paths [ - 1 ] : <TAB> <TAB> <TAB> <TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag ) ","if env . cache_static : 
","if os . path . exists ( fspath + "" .spt "" ) :
",35.69,3.46,False
def thread_loop ( self ) - > None : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> new_trials = self . study . trials <TAB> <TAB> with self . lock : <TAB> <TAB> <TAB> need_to_add_callback = self . new_trials is None <TAB> <TAB> <TAB> self . new_trials = new_trials <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . doc . add_next_tick_callback ( self . update_callback ) ,"if need_to_add_callback : 
","if need_to_add_callback :
",78.12,100.0,True
"def _cache_db_tables_iterator ( tables , cache_alias , db_alias ) : <TAB> no_tables = not tables <TAB> cache_aliases = settings . CACHES if cache_alias is None else ( cache_alias , ) <TAB> db_aliases = settings . DATABASES if db_alias is None else ( db_alias , ) <TAB> for db_alias in db_aliases : <TAB> <TAB> if no_tables : <TAB> <TAB> <TAB> tables = connections [ db_alias ] . introspection . table_names ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for cache_alias in cache_aliases : <TAB> <TAB> <TAB> <TAB> yield cache_alias , db_alias , tables ","if tables : 
","if cache_aliases :
",56.98,12.7,False
"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB> <TAB> if hasattr ( subscriber , "" _pyroRelease "" ) : <TAB> <TAB> <TAB> subscriber . _pyroRelease ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> <TAB> proxy . _pyroRelease ( ) <TAB> <TAB> <TAB> <TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . subscribers [ topic ] . discard ( subscriber ) ","if hasattr ( subscriber , "" _pyroUri "" ) : 
","elif hasattr ( subscriber , "" _pyroUri "" ) :
",82.23,89.32,False
"def test_constructor ( job_id ) : <TAB> with patch ( "" apscheduler.job.Job._modify "" ) as _modify : <TAB> <TAB> scheduler_mock = MagicMock ( BaseScheduler ) <TAB> <TAB> job = Job ( scheduler_mock , id = job_id ) <TAB> <TAB> assert job . _scheduler is scheduler_mock <TAB> <TAB> assert job . _jobstore_alias is None <TAB> <TAB> modify_kwargs = _modify . call_args [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert len ( modify_kwargs [ "" id "" ] ) == 32 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert modify_kwargs [ "" id "" ] == job_id ","if job_id is None : 
","if modify_kwargs [ "" id "" ] . startswith ( "" apscheduler.job. "" ) :
",26.94,2.86,False
"def get_connection ( self ) : <TAB> if self . config . proxy_host != "" "" : <TAB> <TAB> return httplib . HTTPConnection ( self . config . proxy_host , self . config . proxy_port ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return httplib . HTTPSConnection ( self . config . simpledb_host ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return httplib . HTTPConnection ( self . config . simpledb_host ) ","if self . config . use_https : 
","if self . config . simpledb_port == "" 443 "" :
",63.0,28.92,False
"def notify_login ( self , ipaddress = "" "" ) : <TAB> if app . NOTIFY_ON_LOGIN : <TAB> <TAB> update_text = common . notifyStrings [ common . NOTIFY_LOGIN_TEXT ] <TAB> <TAB> title = common . notifyStrings [ common . NOTIFY_LOGIN ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _notify_pht ( title , update_text . format ( ipaddress ) ) ","if update_text and title and ipaddress : 
","if title :
",27.03,0.0,False
"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB> <TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB> <TAB> # Set radio button layout <TAB> <TAB> if item [ "" layout "" ] == "" horiz "" : <TAB> <TAB> <TAB> return 0.03 + ctrl . labelHeight * 3 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl . labelHeight * len ( item [ "" options "" ] ) ","elif item [ "" layout "" ] == "" vert "" : 
","elif item [ "" layout "" ] == "" horizontal "" :
",88.57,79.11,False
"def _get_errors_lines ( self ) : <TAB> """"""Return the number of lines that contains errors to highlight."""""" <TAB> errors_lines = [ ] <TAB> block = self . document ( ) . begin ( ) <TAB> while block . isValid ( ) : <TAB> <TAB> user_data = get_user_data ( block ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errors_lines . append ( block . blockNumber ( ) ) <TAB> <TAB> block = block . next ( ) <TAB> return errors_lines ","if user_data . error : 
","if user_data . errors :
",64.48,64.35,False
"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB> <TAB> self . is_pulsing = False <TAB> <TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB> <TAB> self . pbar . set_text ( progress ) <TAB> <TAB> if frac > 1 : <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB> <TAB> gtk . gdk . threads_leave ( ) ","if frac < 0 : 
","elif frac < 0 :
",64.49,66.87,False
"def list_files ( basedir ) : <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os . path . isdir ( basedir ) : <TAB> <TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB> <TAB> d = directories . pop ( ) <TAB> <TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB> <TAB> <TAB> filename = os . path . join ( d , basename ) <TAB> <TAB> <TAB> if os . path . isdir ( os . path . join ( basedir , filename ) ) : <TAB> <TAB> <TAB> <TAB> directories . append ( filename ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield filename ","elif os . path . exists ( os . path . join ( basedir , filename ) ) : 
","elif os . path . isfile ( filename ) :
",43.28,20.47,False
"def assistive ( self ) : <TAB> """"""Detects if item can be used as assistance"""""" <TAB> # Make sure we cache results <TAB> if self . __assistive is None : <TAB> <TAB> assistive = False <TAB> <TAB> # Go through all effects and find first assistive <TAB> <TAB> for effect in self . effects . values ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # If we find one, stop and mark item as assistive <TAB> <TAB> <TAB> <TAB> assistive = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> self . __assistive = assistive <TAB> return self . __assistive ","if effect . isAssistance is True : 
","if effect . item is not None :
",39.75,23.36,False
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB> <TAB> for col in range ( self . width ) : <TAB> <TAB> <TAB> if filter is None or ( row , col ) not in filter : <TAB> <TAB> <TAB> <TAB> if self . map [ row ] [ col ] == UNSEEN : <TAB> <TAB> <TAB> <TAB> <TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen ","if dist < min_dist : 
","if dist < min_dist :
",100.0,100.0,True
"def _maybe_has_default_route ( self ) : <TAB> for route in self . iter_routes ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> for iface in self . iter_interfaces ( ) : <TAB> <TAB> for subnet in iface . get ( "" subnets "" , [ ] ) : <TAB> <TAB> <TAB> for route in subnet . get ( "" routes "" , [ ] ) : <TAB> <TAB> <TAB> <TAB> if self . _is_default_route ( route ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if self . _is_default_route ( route ) : 
","if self . _is_default_route ( route ) :
",100.0,100.0,True
"def data ( self , data ) : <TAB> if data is None : <TAB> <TAB> raise Exception ( "" Data cannot be None "" ) <TAB> val = [ ] <TAB> for d in data : <TAB> <TAB> if isinstance ( d , str ) : <TAB> <TAB> <TAB> val . append ( bytes ( d , "" utf-8 "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val . append ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Invalid type, data can only be an str or a bytes not  {} :  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> type ( data ) , d <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> self . __data = val ","elif isinstance ( d , bytes ) : 
","elif isinstance ( d , bytes ) :
",100.0,100.0,True
"def get_one_segment_function ( data , context , echoerr ) : <TAB> ext = data [ "" ext "" ] <TAB> function_name = context [ - 2 ] [ 1 ] . get ( "" function "" ) <TAB> if function_name : <TAB> <TAB> module , function_name = get_function_strings ( function_name , context , ext ) <TAB> <TAB> func = import_segment ( function_name , data , context , echoerr , module = module ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield func ","if func : 
","if func :
",78.12,0.0,False
"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB> <TAB> if isinstance ( value , list ) : <TAB> <TAB> <TAB> for item in value : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . visit ( item , parents ) <TAB> <TAB> elif isinstance ( value , AST ) : <TAB> <TAB> <TAB> self . visit ( value , parents ) ","if isinstance ( item , AST ) : 
","if isinstance ( item , AST ) :
",100.0,100.0,True
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" SCE_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states ) ","if v [ "" Category "" ] != "" Deprecated "" : 
","if v [ "" FeatureType "" ] == "" int "" :
",64.9,28.92,False
"def things ( self , query ) : <TAB> limit = query . pop ( "" limit "" , 100 ) <TAB> offset = query . pop ( "" offset "" , 0 ) <TAB> keys = set ( self . docs ) <TAB> for k , v in query . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # query keys need to be flattened properly, <TAB> <TAB> <TAB> # this corrects any nested keys that have been included <TAB> <TAB> <TAB> # in values. <TAB> <TAB> <TAB> flat = common . flatten_dict ( v ) [ 0 ] <TAB> <TAB> <TAB> k + = "" . "" + web . rstrips ( flat [ 0 ] , "" .key "" ) <TAB> <TAB> <TAB> v = flat [ 1 ] <TAB> <TAB> keys = set ( k for k in self . filter_index ( self . index , k , v ) if k in keys ) <TAB> keys = sorted ( keys ) <TAB> return keys [ offset : offset + limit ] ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> if self . _keys [ hash_ ] is self . _empty : <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self . _keys [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _values [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _len - = 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self . _rehash ( hash_ ) <TAB> <TAB> if initial_hash == hash_ : <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None ","elif self . _keys [ hash_ ] == key : 
","if self . _keys [ hash_ ] == self . _deleted :
",63.51,59.69,False
"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB> <TAB> response = self . fetch ( "" /?error=1 "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" requires HTTP/1.x "" ) <TAB> <TAB> if self . http_client . configured_class != SimpleAsyncHTTPClient : <TAB> <TAB> <TAB> self . skipTest ( "" curl client accepts invalid headers "" ) <TAB> <TAB> self . assertEqual ( response . code , 599 ) ","if not self . http1 : 
","if response is None :
",27.6,10.4,False
"def __str__ ( self ) - > str : <TAB> text = "" \n "" <TAB> for k , r in self . result . items ( ) : <TAB> <TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text + = "" #  {}  (failed) \n "" . format ( k ) <TAB> <TAB> else : <TAB> <TAB> <TAB> text + = "" #  {}  (succeeded) \n "" . format ( k ) <TAB> <TAB> text + = "" {} \n "" . format ( "" # "" * 40 ) <TAB> <TAB> for sub_r in r : <TAB> <TAB> <TAB> text + = "" ****  {} \n "" . format ( sub_r . name ) <TAB> <TAB> <TAB> text + = "" {} \n "" . format ( sub_r ) <TAB> return text ","if r . failed : 
","if r is None :
",31.5,23.64,False
"def DeleteTask ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB> <TAB> result = Mongo . coll [ "" Task "" ] . delete_one ( { "" _id "" : ObjectId ( oid ) } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = Mongo . coll [ "" Result "" ] . delete_many ( { "" task_id "" : ObjectId ( oid ) } ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return "" success "" <TAB> return "" fail "" ","if result . deleted_count > 0 : 
","if result :
",28.89,0.0,False
"def _replace_vars ( self , line , extracted , env_variables ) : <TAB> for e in extracted : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = env_variables . get ( e ) <TAB> <TAB> <TAB> if isinstance ( value , dict ) or isinstance ( value , list ) : <TAB> <TAB> <TAB> <TAB> value = pprint . pformat ( value ) <TAB> <TAB> <TAB> decorated = self . _decorate_var ( e ) <TAB> <TAB> <TAB> line = line . replace ( decorated , str ( value ) ) <TAB> return line ","if e in env_variables : 
","if e in env_variables :
",100.0,100.0,True
"def should_include ( service ) : <TAB> for f in filt : <TAB> <TAB> if f == "" status "" : <TAB> <TAB> <TAB> state = filt [ f ] <TAB> <TAB> <TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB> <TAB> <TAB> if not has_container_with_state ( containers , state ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == "" source "" : <TAB> <TAB> <TAB> source = filt [ f ] <TAB> <TAB> <TAB> if source == "" image "" or source == "" build "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True ","if source not in service . options : 
","if not has_image_with_build ( containers , source ) :
",26.88,3.72,False
def state_callback_loop ( ) : <TAB> if usercallback : <TAB> <TAB> when = 1 <TAB> <TAB> while ( <TAB> <TAB> <TAB> when <TAB> <TAB> <TAB> and not self . future_removed . done ( ) <TAB> <TAB> <TAB> and not self . session . shutdownstarttime <TAB> <TAB> ) : <TAB> <TAB> <TAB> result = usercallback ( self . get_state ( ) ) <TAB> <TAB> <TAB> when = ( await result ) if iscoroutine ( result ) else result <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> await sleep ( when ) ,"if when > 0.0 and not self . session . shutdownstarttime : 
","if when :
",26.37,0.0,False
"def __get_new_timeout ( self , timeout ) : <TAB> """"""When using --timeout_multiplier=#.#"""""" <TAB> self . __check_scope ( ) <TAB> try : <TAB> <TAB> timeout_multiplier = float ( self . timeout_multiplier ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> timeout_multiplier = 0.5 <TAB> <TAB> timeout = int ( math . ceil ( timeout_multiplier * timeout ) ) <TAB> <TAB> return timeout <TAB> except Exception : <TAB> <TAB> # Wrong data type for timeout_multiplier (expecting int or float) <TAB> <TAB> return timeout ","if timeout_multiplier < = 0.5 : 
","if timeout_multiplier < 0 :
",36.53,55.78,False
"def readexactly ( self , n ) : <TAB> buf = b "" "" <TAB> while n : <TAB> <TAB> yield IORead ( self . s ) <TAB> <TAB> res = self . s . read ( n ) <TAB> <TAB> assert res is not None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield IOReadDone ( self . s ) <TAB> <TAB> <TAB> break <TAB> <TAB> buf + = res <TAB> <TAB> n - = len ( res ) <TAB> return buf ","if not res : 
","if len ( res ) == 0 :
",28.4,6.27,False
"def contract_rendering_pane ( event ) : <TAB> """"""Expand the rendering pane."""""" <TAB> c = event . get ( "" c "" ) <TAB> if c : <TAB> <TAB> vr = c . frame . top . findChild ( QtWidgets . QWidget , "" viewrendered_pane "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vr . contract ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Just open the pane. <TAB> <TAB> <TAB> viewrendered ( event ) ","if vr : 
","if vr :
",78.12,0.0,False
"def translate_headers ( self , environ ) : <TAB> """"""Translate CGI-environ header names to HTTP header names."""""" <TAB> for cgiName in environ : <TAB> <TAB> # We assume all incoming header keys are uppercase already. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield self . headerNames [ cgiName ] , environ [ cgiName ] <TAB> <TAB> elif cgiName [ : 5 ] == "" HTTP_ "" : <TAB> <TAB> <TAB> # Hackish attempt at recovering original header names. <TAB> <TAB> <TAB> translatedHeader = cgiName [ 5 : ] . replace ( "" _ "" , "" - "" ) <TAB> <TAB> <TAB> yield translatedHeader , environ [ cgiName ] ","if cgiName in self . headerNames : 
","if cgiName in self . headerNames :
",100.0,100.0,True
"def get_value_from_string ( self , string_value ) : <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> string_value = str ( string_value ) . strip ( ) <TAB> <TAB> <TAB> if string_value != "" NONE "" : <TAB> <TAB> <TAB> <TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB> <TAB> self . pcluster_config . warn ( <TAB> <TAB> <TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB> <TAB> <TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB> <TAB> ) <TAB> return param_value ","if string_value is not None : 
","if string_value :
",29.58,38.81,False
"def monitor_filter ( self ) : <TAB> """"""Return filtered service objects list"""""" <TAB> services = self . client . services . list ( filters = { "" label "" : "" com.ouroboros.enable "" } ) <TAB> monitored_services = [ ] <TAB> for service in services : <TAB> <TAB> ouro_label = service . attrs [ "" Spec "" ] [ "" Labels "" ] . get ( "" com.ouroboros.enable "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> monitored_services . append ( service ) <TAB> self . data_manager . monitored_containers [ self . socket ] = len ( monitored_services ) <TAB> self . data_manager . set ( self . socket ) <TAB> return monitored_services ","if not self . config . label_enable or ouro_label . lower ( ) in [ "" true "" , "" yes "" ] : 
","if ouro_label and ouro_label != self . socket :
",29.68,5.66,False
"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB> <TAB> if len ( self . _editableChildren ) : <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> if ref in self . _editableChildren : <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable ","if nei > = len ( self . _editableChildren ) : 
","if nei > = len ( self . _editableChildren ) :
",100.0,100.0,True
"def linkify_cm_by_tp ( self , timeperiods ) : <TAB> for rm in self : <TAB> <TAB> mtp_name = rm . modulation_period . strip ( ) <TAB> <TAB> # The new member list, in id <TAB> <TAB> mtp = timeperiods . find_by_name ( mtp_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> err = ( <TAB> <TAB> <TAB> <TAB> "" Error: the business impact modulation  ' %s '  got an unknown  "" <TAB> <TAB> <TAB> <TAB> "" modulation_period  ' %s ' "" % ( rm . get_name ( ) , mtp_name ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> rm . configuration_errors . append ( err ) <TAB> <TAB> rm . modulation_period = mtp ","if mtp_name != "" "" and mtp is None : 
","if mtp is None :
",43.1,15.34,False
def close_open_fds ( keep = None ) :<TAB> # noqa <TAB> keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB> for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . close ( fd ) <TAB> <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <TAB> if exc . errno != errno . EBADF : <TAB> <TAB> <TAB> <TAB> <TAB> raise ,"if fd not in keep : 
","if fd not in keep :
",100.0,100.0,True
"def _append_child_from_unparsed_xml ( father_node , unparsed_xml ) : <TAB> """"""Append child xml nodes to a node."""""" <TAB> dom_tree = parseString ( unparsed_xml ) <TAB> if dom_tree . hasChildNodes ( ) : <TAB> <TAB> first_child = dom_tree . childNodes [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> child_nodes = first_child . childNodes <TAB> <TAB> <TAB> for _ in range ( len ( child_nodes ) ) : <TAB> <TAB> <TAB> <TAB> childNode = child_nodes . item ( 0 ) <TAB> <TAB> <TAB> <TAB> father_node . appendChild ( childNode ) <TAB> <TAB> <TAB> return <TAB> raise DistutilsInternalError ( <TAB> <TAB> "" Could not Append append elements to  "" "" the Windows msi descriptor. "" <TAB> ) ","if first_child . hasChildNodes ( ) : 
","if first_child . nodeType == dom_tree . ELEMENT_NODE :
",37.85,23.96,False
"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB> <TAB> request . uri = request . uri . replace ( old , new ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> body = six . ensure_str ( request . body ) <TAB> <TAB> <TAB> if old in body : <TAB> <TAB> <TAB> <TAB> request . body = body . replace ( old , new ) <TAB> return request ","if is_text_payload ( request ) and request . body : 
","if request . body :
",42.61,11.69,False
"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB> <TAB> from pygments . lexers . _luabuiltins import MODULES <TAB> <TAB> for mod , func in MODULES . iteritems ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options ) ","if mod not in self . disabled_modules : 
","if not mod in self . disabled_modules :
",64.07,69.85,False
"def GetBestSizeForParentSize ( self , parentSize ) : <TAB> """"""Finds the best width and height given the parent's width and height."""""" <TAB> if len ( self . GetChildren ( ) ) == 1 : <TAB> <TAB> win = self . GetChildren ( ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> temp_dc = wx . ClientDC ( self ) <TAB> <TAB> <TAB> childSize = win . GetBestSizeForParentSize ( parentSize ) <TAB> <TAB> <TAB> clientParentSize = self . _art . GetPanelClientSize ( <TAB> <TAB> <TAB> <TAB> temp_dc , self , wx . Size ( * parentSize ) , None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> overallSize = self . _art . GetPanelSize ( <TAB> <TAB> <TAB> <TAB> temp_dc , self , wx . Size ( * clientParentSize ) , None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return overallSize <TAB> return self . GetSize ( ) ","if isinstance ( win , RibbonControl ) : 
","if win . GetActive ( ) == True :
",26.98,6.27,False
"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> pid = int ( pid ) <TAB> <TAB> <TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> if name in cmdline . split ( "" "" , 1 ) [ 0 ] : <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name ) ","if name in pname : 
","if pname == "" pid "" :
",27.81,7.27,False
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> if idx == num : <TAB> <TAB> <TAB> return element <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> if not isinstance ( i , int ) : <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx ","if element [ 3 ] and element [ 4 ] : 
","if element [ 3 ] :
",53.76,36.55,False
"def scan_block_scalar_indentation ( self ) : <TAB> # See the specification for details. <TAB> chunks = [ ] <TAB> max_indent = 0 <TAB> end_mark = self . get_mark ( ) <TAB> while self . peek ( ) in "" \r \n \x85 \u2028 \u2029 "" : <TAB> <TAB> if self . peek ( ) != "" "" : <TAB> <TAB> <TAB> chunks . append ( self . scan_line_break ( ) ) <TAB> <TAB> <TAB> end_mark = self . get_mark ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . forward ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> max_indent = self . column <TAB> return chunks , max_indent , end_mark ","if self . column > max_indent : 
","if self . column > max_indent :
",100.0,100.0,True
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp ","elif col == FOOD : 
","elif col == LEGAL :
",64.48,53.73,False
"def prepare_data ( entry ) : <TAB> branch_wise_entries = { } <TAB> gross_pay = 0 <TAB> for d in entry : <TAB> <TAB> gross_pay + = d . gross_pay <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> branch_wise_entries [ d . branch ] [ d . mode_of_payment ] = d . net_pay <TAB> <TAB> else : <TAB> <TAB> <TAB> branch_wise_entries . setdefault ( d . branch , { } ) . setdefault ( <TAB> <TAB> <TAB> <TAB> d . mode_of_payment , d . net_pay <TAB> <TAB> <TAB> ) <TAB> return branch_wise_entries , gross_pay ","if branch_wise_entries . get ( d . branch ) : 
","if d . branch in branch_wise_entries :
",39.74,37.77,False
"def __init__ ( self , uuid = None , cluster_state = None , children = None , * * kwargs ) : <TAB> self . uuid = uuid <TAB> self . cluster_state = cluster_state <TAB> if self . cluster_state is not None : <TAB> <TAB> self . children = WeakSet ( <TAB> <TAB> <TAB> self . cluster_state . tasks . get ( task_id ) <TAB> <TAB> <TAB> for task_id in children or ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> self . children = WeakSet ( ) <TAB> self . _serializer_handlers = { <TAB> <TAB> "" children "" : self . _serializable_children , <TAB> <TAB> "" root "" : self . _serializable_root , <TAB> <TAB> "" parent "" : self . _serializable_parent , <TAB> } <TAB> if kwargs : <TAB> <TAB> self . __dict__ . update ( kwargs ) ","if task_id in self . cluster_state . tasks 
","if task_id
",27.02,13.53,False
"def listdir ( self , d ) : <TAB> try : <TAB> <TAB> return [ <TAB> <TAB> <TAB> p <TAB> <TAB> <TAB> for p in os . listdir ( d ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> except OSError : <TAB> <TAB> return [ ] ","if os . path . basename ( p ) != "" CVS "" and os . path . isdir ( os . path . join ( d , p ) ) 
","if p . startswith ( "" . "" ) and p [ - 1 ] . lower ( ) . startswith ( "" . "" )
",19.01,2.33,False
"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB> <TAB> self . connect ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> command = [ command ] <TAB> <TAB> for item in command : <TAB> <TAB> <TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> if len ( e . args ) == 1 : <TAB> <TAB> <TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> _errno , errmsg = e . args <TAB> <TAB> raise ConnectionError ( <TAB> <TAB> <TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> raise ","if isinstance ( command , str ) : 
","if not isinstance ( command , list ) :
",57.53,36.89,False
"def run ( self ) : <TAB> """"""Start the scanner"""""" <TAB> logging . info ( "" Dirscanner starting up "" ) <TAB> self . shutdown = False <TAB> while not self . shutdown : <TAB> <TAB> # Wait to be woken up or triggered <TAB> <TAB> with self . loop_condition : <TAB> <TAB> <TAB> self . loop_condition . wait ( self . dirscan_speed ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . scan ( ) ","if self . dirscan_speed and not self . shutdown : 
","if self . shutdown :
",48.92,20.74,False
"def __aexit__ ( <TAB> self , exc_type : type , exc_value : BaseException , tb : TracebackType ) - > None : <TAB> if exc_type is not None : <TAB> <TAB> await self . close ( ) <TAB> await self . _task <TAB> while not self . _receive_queue . empty ( ) : <TAB> <TAB> data = await self . _receive_queue . get ( ) <TAB> <TAB> if isinstance ( data , bytes ) : <TAB> <TAB> <TAB> self . response_data . extend ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise data ","elif not isinstance ( data , HTTPDisconnect ) : 
","elif isinstance ( data , Exception ) :
",51.57,37.71,False
"def f ( msg ) : <TAB> text = extractor ( msg ) <TAB> for px in prefix : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> chunks = text [ len ( px ) : ] . split ( separator ) <TAB> <TAB> <TAB> return chunks [ 0 ] , ( chunks [ 1 : ] , ) if pass_args else ( ) <TAB> return ( ( None , ) , )<TAB> # to distinguish with `None` ","if text . startswith ( px ) : 
","if text . startswith ( px ) :
",100.0,100.0,True
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> if type ( item ) is ActionHandle : <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> if type ( ah ) is not ActionHandle :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB> <TAB> <TAB> <TAB> <TAB> ahs . add ( ah ) <TAB> <TAB> <TAB> else :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs ","elif type ( item ) in ( list , tuple , dict , set ) : 
","elif isinstance ( item , list ) :
",26.91,6.61,False
"def find_class ( self , module , name ) : <TAB> # Subclasses may override this. <TAB> sys . audit ( "" pickle.find_class "" , module , name ) <TAB> if self . proto < 3 and self . fix_imports : <TAB> <TAB> if ( module , name ) in _compat_pickle . NAME_MAPPING : <TAB> <TAB> <TAB> module , name = _compat_pickle . NAME_MAPPING [ ( module , name ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module = _compat_pickle . IMPORT_MAPPING [ module ] <TAB> __import__ ( module , level = 0 ) <TAB> if self . proto > = 4 : <TAB> <TAB> return _getattribute ( sys . modules [ module ] , name ) [ 0 ] <TAB> else : <TAB> <TAB> return getattr ( sys . modules [ module ] , name ) ","elif module in _compat_pickle . IMPORT_MAPPING : 
","elif module in _compat_pickle . IMPORT_MAPPING :
",100.0,100.0,True
"def _send_until_done ( self , data ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . connection . send ( data ) <TAB> <TAB> except OpenSSL . SSL . WantWriteError : <TAB> <TAB> <TAB> wr = util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise timeout ( ) <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL . SSL . SysCallError as e : <TAB> <TAB> <TAB> raise SocketError ( str ( e ) ) ","if not wr : 
","if not wr :
",100.0,100.0,True
"def __new__ ( cls , * args , * * kwargs ) : <TAB> """"""Hack to ensure method defined as async are implemented as such."""""" <TAB> coroutines = inspect . getmembers ( BaseManager , predicate = inspect . iscoroutinefunction ) <TAB> for coroutine in coroutines : <TAB> <TAB> implemented_method = getattr ( cls , coroutine [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" The method  %s  must be a coroutine "" % implemented_method ) <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs ) ","if not inspect . iscoroutinefunction ( implemented_method ) : 
","if not inspect . iscoroutinefunction ( implemented_method ) :
",100.0,100.0,True
"def add_directive ( self , name , obj , content = None , arguments = None , * * options ) : <TAB> if isinstance ( obj , clstypes ) and issubclass ( obj , Directive ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ExtensionError ( <TAB> <TAB> <TAB> <TAB> "" when adding directive classes, no  "" "" additional arguments may be given "" <TAB> <TAB> <TAB> ) <TAB> <TAB> directives . register_directive ( name , directive_dwim ( obj ) ) <TAB> else : <TAB> <TAB> obj . content = content <TAB> <TAB> obj . arguments = arguments <TAB> <TAB> obj . options = options <TAB> <TAB> directives . register_directive ( name , obj ) ","if content or arguments or options : 
","if arguments is not None :
",27.18,9.04,False
"def create ( self , w ) : <TAB> if w . use_eventloop : <TAB> <TAB> # does not use dedicated timer thread. <TAB> <TAB> w . timer = _Timer ( max_interval = 10.0 ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Default Timer is set by the pool, as for example, the <TAB> <TAB> <TAB> # eventlet pool needs a custom timer implementation. <TAB> <TAB> <TAB> w . timer_cls = w . pool_cls . Timer <TAB> <TAB> w . timer = self . instantiate ( <TAB> <TAB> <TAB> w . timer_cls , <TAB> <TAB> <TAB> max_interval = w . timer_precision , <TAB> <TAB> <TAB> on_error = self . on_timer_error , <TAB> <TAB> <TAB> on_tick = self . on_timer_tick , <TAB> <TAB> ) ","if not w . timer_cls : 
","if not hasattr ( w , "" timer_cls "" ) :
",29.04,15.73,False
"def _config ( _molecule_file , request ) : <TAB> with open ( _molecule_file ) as f : <TAB> <TAB> d = util . safe_load ( f ) <TAB> if hasattr ( request , "" param "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d2 = util . safe_load ( request . getfixturevalue ( request . param ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d2 = request . getfixturevalue ( request . param ) <TAB> <TAB> # print(100, d) <TAB> <TAB> # print(200, d2) <TAB> <TAB> d = util . merge_dicts ( d , d2 ) <TAB> <TAB> # print(300, d) <TAB> return d ","if isinstance ( request . getfixturevalue ( request . param ) , str ) : 
","if isinstance ( request . param , dict ) :
",50.02,36.32,False
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) :<TAB> # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_layer = self . _instrument ( value ) <TAB> <TAB> <TAB> if new_layer is not value : <TAB> <TAB> <TAB> <TAB> setattr ( model , key , new_layer ) <TAB> <TAB> elif isinstance ( value , list ) : <TAB> <TAB> <TAB> for i , item in enumerate ( value ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( item , tf . keras . layers . Layer ) : <TAB> <TAB> <TAB> <TAB> <TAB> value [ i ] = self . _instrument ( item ) <TAB> return model ","if isinstance ( value , tf . keras . layers . Layer ) : 
","if isinstance ( value , tf . keras . layers . Layer ) :
",100.0,100.0,True
"def is_accepted_drag_event ( self , event ) : <TAB> if event . source ( ) == self . table : <TAB> <TAB> return True <TAB> mime = event . mimeData ( ) <TAB> if mime . hasUrls ( ) : <TAB> <TAB> for url in mime . urls ( ) : <TAB> <TAB> <TAB> # Only support local files. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # And only allow supported extensions. <TAB> <TAB> <TAB> filename = url . toLocalFile ( ) <TAB> <TAB> <TAB> extension = os . path . splitext ( filename ) [ 1 ] . lower ( ) [ 1 : ] <TAB> <TAB> <TAB> if extension not in _dictionary_formats ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> return True <TAB> return False ","if not url . isLocalFile ( ) : 
","if url . isLocalFile ( ) :
",72.37,72.9,False
"def explain ( self , other , depth = 0 ) : <TAB> exp = super ( UnionType , self ) . explain ( other , depth ) <TAB> for ndx , subtype in enumerate ( self . params [ "" allowed_types "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exp + = "" \n {} and "" . format ( "" "" . join ( [ "" \t "" ] * depth ) ) <TAB> <TAB> exp + = "" \n "" + subtype . explain ( other , depth = depth + 1 ) <TAB> return exp ","if ndx > 0 : 
","if ndx > 0 :
",100.0,100.0,True
"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB> seen = [ False , False ] <TAB> for i in sm . xrange ( 100 ) : <TAB> <TAB> observed = aug . augment_image ( self . base_img ) <TAB> <TAB> if np . array_equal ( observed , self . blur3x3 ) : <TAB> <TAB> <TAB> seen [ 0 ] + = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seen [ 1 ] + = True <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB> <TAB> if all ( seen ) : <TAB> <TAB> <TAB> break <TAB> assert np . all ( seen ) ","elif np . array_equal ( observed , self . blur5x5 ) : 
","elif np . array_equal ( observed , self . blur5x5 ) :
",100.0,100.0,True
"def test_get_message ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> message_id = await self . _send_message ( ) <TAB> <TAB> <TAB> message = await self . chat_thread_client . get_message ( message_id ) <TAB> <TAB> <TAB> assert message . id == message_id <TAB> <TAB> <TAB> assert message . type == ChatMessageType . TEXT <TAB> <TAB> <TAB> assert message . content . message == "" hello world "" <TAB> <TAB> # delete chat threads <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . chat_client . delete_chat_thread ( self . thread_id ) ","if not self . is_playback ( ) : 
","if self . thread_id is not None :
",32.98,11.48,False
"def do_write_property ( self , device , callback = None ) : <TAB> try : <TAB> <TAB> iocb = ( <TAB> <TAB> <TAB> device <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else self . form_iocb ( device , request_type = "" writeProperty "" ) <TAB> <TAB> ) <TAB> <TAB> deferred ( self . request_io , iocb ) <TAB> <TAB> self . requests_in_progress . update ( { iocb : { "" callback "" : callback } } ) <TAB> <TAB> iocb . add_callback ( self . __general_cb ) <TAB> except Exception as error : <TAB> <TAB> log . exception ( "" exception:  %r "" , error ) ","if isinstance ( device , IOCB ) 
","if not device . startswith ( "" / "" )
",26.99,5.93,False
"def fit ( self , dataset , force_retrain ) : <TAB> if force_retrain : <TAB> <TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB> <TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB> <TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB> <TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> else : <TAB> <TAB> if not self . sub_unit_1 [ "" fitted "" ] : <TAB> <TAB> <TAB> self . sub_unit_1 [ "" fitted "" ] = True <TAB> <TAB> <TAB> self . sub_unit_1 [ "" calls "" ] + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . sub_unit_2 [ "" fitted "" ] = True <TAB> <TAB> <TAB> self . sub_unit_2 [ "" calls "" ] + = 1 <TAB> return self ","if not self . sub_unit_2 [ "" fitted "" ] : 
","if not self . sub_unit_2 [ "" fitted "" ] :
",100.0,100.0,True
"def _insert_with_loop ( self ) : <TAB> id_list = [ ] <TAB> last_id = None <TAB> return_id_list = self . _return_id_list <TAB> for row in self . _rows : <TAB> <TAB> last_id = InsertQuery ( self . model_class , row ) . upsert ( self . _upsert ) . execute ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> id_list . append ( last_id ) <TAB> if return_id_list : <TAB> <TAB> return id_list <TAB> else : <TAB> <TAB> return last_id ","if return_id_list : 
","if last_id :
",56.98,17.03,False
"def merge_block ( self ) : <TAB> """"""merges a block in the map"""""" <TAB> for i in range ( self . block . x ) : <TAB> <TAB> for j in range ( self . block . x ) : <TAB> <TAB> <TAB> c = self . block . get ( i , j ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . map [ ( i + self . block . pos . x , j + self . block . pos . y ) ] = c ","if c : 
","if c is not None :
",34.04,17.97,False
"def configure_plex ( config ) : <TAB> core . PLEX_SSL = int ( config [ "" Plex "" ] [ "" plex_ssl "" ] ) <TAB> core . PLEX_HOST = config [ "" Plex "" ] [ "" plex_host "" ] <TAB> core . PLEX_PORT = config [ "" Plex "" ] [ "" plex_port "" ] <TAB> core . PLEX_TOKEN = config [ "" Plex "" ] [ "" plex_token "" ] <TAB> plex_section = config [ "" Plex "" ] [ "" plex_sections "" ] or [ ] <TAB> if plex_section : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> plex_section = "" , "" . join ( plex_section )<TAB> # fix in case this imported as list. <TAB> <TAB> plex_section = [ tuple ( item . split ( "" , "" ) ) for item in plex_section . split ( "" | "" ) ] <TAB> core . PLEX_SECTION = plex_section ","if isinstance ( plex_section , list ) : 
","if isinstance ( plex_section , list ) :
",100.0,100.0,True
"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB> <TAB> xlib . XNextEvent ( self . _display , e ) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if xlib . XFilterEvent ( e , e . xany . window ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> dispatch = self . _window_map [ e . xany . window ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch ( e ) ","if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) : 
","if e . xany . window in self . _window_map :
",47.07,22.47,False
"def format_message ( self ) : <TAB> bits = [ self . message ] <TAB> if self . possibilities : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bits . append ( "" Did you mean  %s ? "" % self . possibilities [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> possibilities = sorted ( self . possibilities ) <TAB> <TAB> <TAB> bits . append ( "" (Possible options:  %s ) "" % "" ,  "" . join ( possibilities ) ) <TAB> return ""<TAB> "" . join ( bits ) ","if len ( self . possibilities ) == 1 : 
","if len ( self . possibilities ) == 1 :
",100.0,100.0,True
"def _collect_logs ( model ) : <TAB> page_token = None <TAB> all_logs = [ ] <TAB> while True : <TAB> <TAB> paginated_logs = model . lookup_logs ( now , later , page_token = page_token ) <TAB> <TAB> page_token = paginated_logs . next_page_token <TAB> <TAB> all_logs . extend ( paginated_logs . logs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return all_logs ","if page_token is None : 
","if page_token is None :
",100.0,100.0,True
"def run ( self ) : <TAB> while True : <TAB> <TAB> context_id_list_tuple = self . _inflated_addresses . get ( block = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> c_id , inflated_address_list = context_id_list_tuple <TAB> <TAB> inflated_value_map = dict ( inflated_address_list ) <TAB> <TAB> if c_id in self . _contexts : <TAB> <TAB> <TAB> self . _contexts [ c_id ] . set_from_tree ( inflated_value_map ) ","if context_id_list_tuple is _SHUTDOWN_SENTINEL : 
","if not context_id_list_tuple :
",28.78,45.61,False
"def _setup_prefix ( self ) : <TAB> # we assume here that our metadata may be nested inside a ""basket"" <TAB> # of multiple eggs; that's why we use module_path instead of .archive <TAB> path = self . module_path <TAB> old = None <TAB> while path != old : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . egg_name = os . path . basename ( path ) <TAB> <TAB> <TAB> self . egg_info = os . path . join ( path , "" EGG-INFO "" ) <TAB> <TAB> <TAB> self . egg_root = path <TAB> <TAB> <TAB> break <TAB> <TAB> old = path <TAB> <TAB> path , base = os . path . split ( path ) ","if path . lower ( ) . endswith ( "" .egg "" ) : 
","if os . path . isdir ( path ) :
",30.29,8.28,False
"def get_filename ( self , prompt ) : <TAB> okay = False <TAB> val = "" "" <TAB> while not okay : <TAB> <TAB> val = raw_input ( "" %s :  %s "" % ( prompt , val ) ) <TAB> <TAB> val = os . path . expanduser ( val ) <TAB> <TAB> if os . path . isfile ( val ) : <TAB> <TAB> <TAB> okay = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = val <TAB> <TAB> <TAB> val = self . choose_from_list ( os . listdir ( path ) ) <TAB> <TAB> <TAB> if val : <TAB> <TAB> <TAB> <TAB> val = os . path . join ( path , val ) <TAB> <TAB> <TAB> <TAB> okay = True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> val = "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Invalid value:  %s "" % val ) <TAB> <TAB> <TAB> val = "" "" <TAB> return val ","elif os . path . isdir ( val ) : 
","elif os . path . isdir ( val ) :
",100.0,100.0,True
"def versions ( self , sitename , data ) : <TAB> # handle the query of type {""query"": '{""key"": ""/books/ia:foo00bar"", ...}} <TAB> if "" query "" in data : <TAB> <TAB> q = json . loads ( data [ "" query "" ] ) <TAB> <TAB> itemid = self . _get_itemid ( q . get ( "" key "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = q [ "" key "" ] <TAB> <TAB> <TAB> return json . dumps ( [ self . dummy_edit ( key ) ] ) <TAB> # if not just go the default way <TAB> return ConnectionMiddleware . versions ( self , sitename , data ) ","if itemid : 
","if itemid :
",78.12,0.0,False
"def read_stanza ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> stanza_end = self . _buffer . index ( b "" \n "" ) <TAB> <TAB> <TAB> stanza = self . decoder . decode ( self . _buffer [ : stanza_end ] ) <TAB> <TAB> <TAB> self . _buffer = self . _buffer [ stanza_end + 1 : ] <TAB> <TAB> <TAB> colon = stanza . index ( "" : "" ) <TAB> <TAB> <TAB> return stanza [ : colon ] , stanza [ colon + 1 : ] <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> bytes = self . read_bytes ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _buffer + = bytes ","if not bytes : 
","if bytes == b "" "" :
",28.57,7.27,False
def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB> <TAB> mask = 1 << bit <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if attrnames . has_key ( mask ) : <TAB> <TAB> <TAB> <TAB> names . append ( attrnames [ mask ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> names . append ( hex ( mask ) ) <TAB> return names ,"if attrs & mask : 
","if attrs & mask :
",100.0,100.0,True
"def _set_http_cookie ( ) : <TAB> if conf . cookie : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = "" ;  "" . join ( <TAB> <TAB> <TAB> <TAB> map ( lambda x : "" = "" . join ( x ) , conf . cookie . items ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> conf . http_headers [ HTTP_HEADER . COOKIE ] = conf . cookie ","if isinstance ( conf . cookie , dict ) : 
","if isinstance ( conf . cookie , dict ) :
",100.0,100.0,True
"def __ne__ ( self , other ) : <TAB> if isinstance ( other , WeakMethod ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self is not other <TAB> <TAB> return weakref . ref . __ne__ ( self , other ) or self . _func_ref != other . _func_ref <TAB> return True ","if not self . _alive or not other . _alive : 
","if self . _refcount == 0 :
",34.44,12.93,False
"def update_unread ( self , order_id , reset = False ) : <TAB> conn = Database . connect_database ( self . PATH ) <TAB> with conn : <TAB> <TAB> cursor = conn . cursor ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cursor . execute ( <TAB> <TAB> <TAB> <TAB> """"""UPDATE sales SET unread = unread + 1 WHERE id=?;"""""" , ( order_id , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cursor . execute ( """""" UPDATE sales SET unread=0 WHERE id=?; """""" , ( order_id , ) ) <TAB> <TAB> conn . commit ( ) <TAB> conn . close ( ) ","if reset is False : 
","if reset :
",31.27,0.0,False
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value ","elif key == "" nw_dst "" : 
","elif key == "" nw_dst "" :
",100.0,100.0,True
"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB> <TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if keep_nested is not None : <TAB> <TAB> <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield k , v ","if k in keep_current : 
","if keep_current is not None and k in keep_current :
",57.96,36.36,False
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> elif p : <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> elif wrapped : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p )<TAB> # Sets focus. ","if p and p . isMarked ( ) : 
","if p and p . isMarked ( ) :
",100.0,100.0,True
"def sample ( self , * * config ) : <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( v , NestedSpace ) : <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB> <TAB> <TAB> <TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret [ k ] = v <TAB> return ret ","if k in striped_keys : 
","if k not in striped_keys :
",64.71,59.46,False
"def update_gradients_full ( self , dL_dK , X , X2 = None ) : <TAB> if self . ARD : <TAB> <TAB> phi1 = self . phi ( X ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> phi2 = self . phi ( X2 ) <TAB> <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,iq,jq->q "" , dL_dK , phi1 , phi2 ) <TAB> else : <TAB> <TAB> self . variance . gradient = np . einsum ( "" ij,ij "" , dL_dK , self . _K ( X , X2 ) ) * self . beta ","if X2 is None or X is X2 : 
","if self . variance . gradient is None :
",28.1,11.34,False
"def post ( self ) : <TAB> host_json = json . loads ( request . data ) <TAB> host_os = host_json . get ( "" os "" ) <TAB> if host_os : <TAB> <TAB> result = get_monkey_executable ( host_os . get ( "" type "" ) , host_os . get ( "" machine "" ) ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> # change resulting from new base path <TAB> <TAB> <TAB> executable_filename = result [ "" filename "" ] <TAB> <TAB> <TAB> real_path = MonkeyDownload . get_executable_full_path ( executable_filename ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ "" size "" ] = os . path . getsize ( real_path ) <TAB> <TAB> <TAB> <TAB> return result <TAB> return { } ","if os . path . isfile ( real_path ) : 
","if os . path . exists ( real_path ) :
",83.03,73.49,False
"def _encode_data ( <TAB> self , <TAB> data , <TAB> content_type , ) : <TAB> if content_type is MULTIPART_CONTENT : <TAB> <TAB> return encode_multipart ( BOUNDARY , data ) <TAB> else : <TAB> <TAB> # Encode the content so that the byte representation is correct. <TAB> <TAB> match = CONTENT_TYPE_RE . match ( content_type ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> charset = match . group ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> charset = settings . DEFAULT_CHARSET <TAB> <TAB> return force_bytes ( data , encoding = charset ) ","if match : 
","if match :
",78.12,0.0,False
"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB> <TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> if not re . match ( "" [0-9] "" , str ( tokens [ s ] ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB> <TAB> <TAB> i - = 1 <TAB> return tokens ","if re . match ( "" [0-9] "" , str ( tokens [ e ] ) ) : 
","elif re . match ( "" -[a-zA-Z] "" , str ( tokens [ e ] ) ) :
",77.09,69.59,False
"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self [ key ] = result <TAB> <TAB> if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) : <TAB> <TAB> <TAB> result . parent = self <TAB> <TAB> <TAB> result . key = key <TAB> return result ","if replace : 
","if replace :
",78.12,0.0,False
"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB> <TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB> <TAB> for bp in bplist : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if text . strip ( ) . lower ( ) == "" none "" : <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp . cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self . RespondDebuggerData ( ) ","if id ( bp ) == item_id : 
","if bp . item_id == item_id :
",33.11,46.17,False
"def add ( self , url : str , future_nzo : NzbObject , when : Optional [ int ] = None ) : <TAB> """"""Add an URL to the URLGrabber queue, 'when' is seconds from now"""""" <TAB> if future_nzo and when : <TAB> <TAB> # Always increase counter <TAB> <TAB> future_nzo . url_tries + = 1 <TAB> <TAB> # Too many tries? Cancel <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . fail_to_history ( future_nzo , url , T ( "" Maximum retries "" ) ) <TAB> <TAB> <TAB> return <TAB> <TAB> future_nzo . url_wait = time . time ( ) + when <TAB> self . queue . put ( ( url , future_nzo ) ) ","if future_nzo . url_tries > cfg . max_url_retries ( ) : 
","if future_nzo . url_tries > self . max_retries :
",51.75,52.79,False
def _is_datetime_string ( series ) : <TAB> if series . dtype == object : <TAB> <TAB> not_numeric = False <TAB> <TAB> try : <TAB> <TAB> <TAB> pd . to_numeric ( series ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> not_numeric = True <TAB> <TAB> datetime_col = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> datetime_col = pd . to_datetime ( series ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> if datetime_col is not None : <TAB> <TAB> <TAB> return True <TAB> return False ,"if not_numeric : 
","if not_numeric :
",78.12,100.0,True
"def _getEventAndObservers ( self , event ) : <TAB> if isinstance ( event , xpath . XPathQuery ) : <TAB> <TAB> # Treat as xpath <TAB> <TAB> observers = self . _xpathObservers <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Treat as event <TAB> <TAB> <TAB> observers = self . _eventObservers <TAB> <TAB> else : <TAB> <TAB> <TAB> # Treat as xpath <TAB> <TAB> <TAB> event = xpath . internQuery ( event ) <TAB> <TAB> <TAB> observers = self . _xpathObservers <TAB> return event , observers ","if self . prefix == event [ : len ( self . prefix ) ] : 
","if isinstance ( event , event . xpathQuery ) :
",19.03,3.26,False
"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> if name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr ( bonobo , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo . __all__ ","if inspect . ismodule ( attr ) : 
","if not hasattr ( attr , "" __all__ "" ) :
",28.79,7.86,False
"def relint_views ( wid = None ) : <TAB> windows = [ sublime . Window ( wid ) ] if wid else sublime . windows ( ) <TAB> for window in windows : <TAB> <TAB> for view in window . views ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> hit ( view , "" relint_views "" ) ","if view . buffer_id ( ) in persist . assigned_linters and view . is_primary ( ) : 
","if view . is_relint :
",34.06,5.5,False
def _check_for_unknown_gender ( self ) : <TAB> if self . obj . get_gender ( ) == Person . UNKNOWN : <TAB> <TAB> d = GenderDialog ( parent = self . window ) <TAB> <TAB> gender = d . run ( ) <TAB> <TAB> d . destroy ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . obj . set_gender ( gender ) ,"if gender > = 0 : 
","if gender != Person . UNKNOWN :
",29.53,13.13,False
"def add_to_path ( self , fnames ) : <TAB> """"""Add fnames to path"""""" <TAB> indexes = [ ] <TAB> for path in fnames : <TAB> <TAB> project = self . get_source_project ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . parent_widget . emit ( SIGNAL ( "" pythonpath_changed() "" ) ) <TAB> <TAB> <TAB> indexes . append ( self . get_index ( path ) ) <TAB> if indexes : <TAB> <TAB> self . reset_icon_provider ( ) <TAB> <TAB> for index in indexes : <TAB> <TAB> <TAB> self . update ( index ) ","if project . add_to_pythonpath ( path ) : 
","if project and project . is_valid ( ) :
",34.81,12.32,False
"def validate ( self , value ) : <TAB> if value . grid_id is not None : <TAB> <TAB> if not isinstance ( value , self . proxy_class ) : <TAB> <TAB> <TAB> self . error ( "" FileField only accepts GridFSProxy values "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . error ( "" Invalid GridFSProxy value "" ) ","if not isinstance ( value . grid_id , ObjectId ) : 
","elif value . grid_id not in self . proxy_class . _grid_ids :
",34.24,20.61,False
"def shortcut ( self , input , ch_out , stride , name , if_first = False ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB> <TAB> return input ","if if_first : 
","if if_first :
",78.12,100.0,True
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( ) ","elif code == Path . CURVE4 : 
","elif code == Path . CURVE4 :
",100.0,100.0,True
"def _get_build_status ( self , job_name , build_number ) : <TAB> try : <TAB> <TAB> build_info = self . server . get_build_info ( job_name , build_number ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" building "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" built "" <TAB> except jenkins . NotFoundException : <TAB> <TAB> return "" not found "" ","if build_info [ "" building "" ] : 
","if build_info [ "" build_status "" ] == "" built "" :
",54.86,32.64,False
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> if default . lower ( ) == "" true "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default . lower ( ) == "" false "" : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default ) ","if type ( default ) == float : 
","if type ( default ) == float :
",100.0,100.0,True
"def get_fills ( self , exchange_order_id ) : <TAB> async with aiohttp . ClientSession ( ) as client : <TAB> <TAB> response : aiohttp . ClientResponse = await client . get ( <TAB> <TAB> <TAB> f "" { BASE_URL } { FILLS_ROUTE } "" , <TAB> <TAB> <TAB> params = { "" orderId "" : exchange_order_id , "" limit "" : 100 } , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> msg = await response . json ( ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> msg = await response . text ( ) <TAB> <TAB> <TAB> raise DydxAsyncAPIError ( response . status , msg ) <TAB> <TAB> return await response . json ( ) ","if response . status > = 300 : 
","if response . status != 200 :
",48.99,38.26,False
"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB> <TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key , value in list ( semanticTags . items ( ) ) : <TAB> <TAB> if not isinstance ( key , int ) : <TAB> <TAB> <TAB> raise TypeError ( "" At least one key is not a valid int position "" ) <TAB> <TAB> if not isinstance ( value , list ) : <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" At least one value of the provided dict is not a list of string "" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" At least one value of the provided dict is not a list of string "" <TAB> <TAB> <TAB> <TAB> ) <TAB> self . __semanticTags = semanticTags ","if not isinstance ( x , str ) : 
","if not isinstance ( x , str ) :
",100.0,100.0,True
"def start_cutting_tool ( self , event , axis , direction ) : <TAB> toggle = event . EventObject <TAB> self . cutting = toggle . Value <TAB> if toggle . Value : <TAB> <TAB> # Disable the other toggles <TAB> <TAB> for child in self . cutsizer . Children : <TAB> <TAB> <TAB> child = child . Window <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> child . Value = False <TAB> <TAB> self . cutting_axis = axis <TAB> <TAB> self . cutting_direction = direction <TAB> else : <TAB> <TAB> self . cutting_axis = None <TAB> <TAB> self . cutting_direction = None <TAB> self . cutting_dist = None ","if child != toggle : 
","if child . Value == toggle . Value :
",29.98,12.55,False
"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB> <TAB> for patching in patched . patchings : <TAB> <TAB> <TAB> arg = exit_stack . enter_context ( patching ) <TAB> <TAB> <TAB> if patching . attribute_name is not None : <TAB> <TAB> <TAB> <TAB> keywargs . update ( arg ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> extra_args . append ( arg ) <TAB> <TAB> args + = tuple ( extra_args ) <TAB> <TAB> yield ( args , keywargs ) ","elif patching . new is DEFAULT : 
","if arg is not None :
",27.1,8.17,False
def decodeattrs ( attrs ) : <TAB> names = [ ] <TAB> for bit in range ( 16 ) : <TAB> <TAB> mask = 1 << bit <TAB> <TAB> if attrs & mask : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> names . append ( attrnames [ mask ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> names . append ( hex ( mask ) ) <TAB> return names ,"if attrnames . has_key ( mask ) : 
","if mask in attrnames :
",27.1,5.56,False
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if "" init "" not in item . keywords : 
","if "" init "" not in item . keywords :
",100.0,100.0,True
"def handle_socket ( self , request ) : <TAB> conn = request . connection <TAB> while True : <TAB> <TAB> chunk = conn . recv ( 4 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> slen = struct . unpack ( "" >L "" , chunk ) [ 0 ] <TAB> <TAB> chunk = conn . recv ( slen ) <TAB> <TAB> while len ( chunk ) < slen : <TAB> <TAB> <TAB> chunk = chunk + conn . recv ( slen - len ( chunk ) ) <TAB> <TAB> obj = pickle . loads ( chunk ) <TAB> <TAB> record = logging . makeLogRecord ( obj ) <TAB> <TAB> self . log_output + = record . msg + "" \n "" <TAB> <TAB> self . handled . release ( ) ","if len ( chunk ) < 4 : 
","if not chunk :
",26.99,7.73,False
"def on_source_foreach ( self , model , path , iter , id ) : <TAB> m_id = model . get_value ( iter , self . COLUMN_ID ) <TAB> if m_id == id : <TAB> <TAB> if self . _foreach_mode == "" get "" : <TAB> <TAB> <TAB> self . _foreach_take = model . get_value ( iter , self . COLUMN_ENABLED ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _foreach_take = iter ","elif self . _foreach_mode == "" set "" : 
","elif self . _foreach_mode == "" set "" :
",100.0,100.0,True
"def parts ( ) : <TAB> for l in lists . leaves : <TAB> <TAB> head_name = l . get_head_name ( ) <TAB> <TAB> if head_name == "" System`List "" : <TAB> <TAB> <TAB> yield l . leaves <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l ) ","elif head_name != "" System`Missing "" : 
","elif head_name == "" System`Error "" :
",55.31,46.6,False
"def __fill_counter_values ( self , command : str ) : <TAB> result = [ ] <TAB> regex = r "" (item[0-9]+ \ .counter_value) "" <TAB> for token in re . split ( regex , command ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> result . append ( str ( self . simulator_config . item_dict [ token ] . value ) ) <TAB> <TAB> <TAB> except ( KeyError , ValueError , AttributeError ) : <TAB> <TAB> <TAB> <TAB> logger . error ( "" Could not get counter value for  "" + token ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( token ) <TAB> return "" "" . join ( result ) ","if re . match ( regex , token ) is not None : 
","if token in self . simulator_config . item_dict :
",29.63,4.37,False
"def IMPORTFROM ( self , node ) : <TAB> <MASK> <TAB> <TAB> if not self . futuresAllowed : <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> if alias . name == "" * "" : <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation ) ","if node . module == "" __future__ "" : 
","if node . name :
",36.67,7.06,False
"def _split_batch_list ( args , batch_list ) : <TAB> new_list = [ ] <TAB> for batch in batch_list . batches : <TAB> <TAB> new_list . append ( batch ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield batch_pb2 . BatchList ( batches = new_list ) <TAB> <TAB> <TAB> new_list = [ ] <TAB> if new_list : <TAB> <TAB> yield batch_pb2 . BatchList ( batches = new_list ) ","if len ( new_list ) == args . batch_size_limit : 
","if len ( new_list ) == args . batch_size :
",89.28,82.4,False
"def get_branch_or_use_upstream ( branch_name , arg , repo ) : <TAB> if not branch_name :<TAB> # use upstream branch <TAB> <TAB> current_b = repo . current_branch <TAB> <TAB> upstream_b = current_b . upstream <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" No  {0}  branch specified and the current branch has no upstream  "" <TAB> <TAB> <TAB> <TAB> "" branch set "" . format ( arg ) <TAB> <TAB> <TAB> ) <TAB> <TAB> ret = current_b . upstream <TAB> else : <TAB> <TAB> ret = get_branch ( branch_name , repo ) <TAB> return ret ","if not upstream_b : 
","if not upstream_b :
",100.0,100.0,True
"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB> <TAB> if name not in default_settings : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> self . __class__ . __name__ , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr ( self , name , value ) ","if not hasattr ( self , name ) : 
","if name not in settings :
",26.83,6.96,False
"def _declare ( self , name , obj , included = False , quals = 0 ) : <TAB> if name in self . _declarations : <TAB> <TAB> prevobj , prevquals = self . _declarations [ name ] <TAB> <TAB> if prevobj is obj and prevquals == quals : <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise api . FFIError ( <TAB> <TAB> <TAB> <TAB> "" multiple declarations of  %s  (for interactive usage,  "" <TAB> <TAB> <TAB> <TAB> "" try cdef(xx, override=True)) "" % ( name , ) <TAB> <TAB> <TAB> ) <TAB> assert "" __dotdotdot__ "" not in name . split ( ) <TAB> self . _declarations [ name ] = ( obj , quals ) <TAB> if included : <TAB> <TAB> self . _included_declarations . add ( obj ) ","if not self . _override : 
","if len ( self . _declarations ) > 1 :
",35.05,15.85,False
"def include_file ( name , fdir = tmp_dir , b64 = False ) : <TAB> try : <TAB> <TAB> if fdir is None : <TAB> <TAB> <TAB> fdir = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with io . open ( os . path . join ( fdir , name ) , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> return base64 . b64encode ( f . read ( ) ) . decode ( "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with io . open ( os . path . join ( fdir , name ) , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> <TAB> return f . read ( ) <TAB> except ( OSError , IOError ) as e : <TAB> <TAB> logger . error ( "" Could not include file  ' {} ' :  {} "" . format ( name , e ) ) ","if b64 : 
","if b64 :
",78.12,0.0,False
"def to_raw_json ( self ) : <TAB> parts = { } <TAB> for p in self . parts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts [ p [ 0 ] ] = [ ] <TAB> <TAB> parts [ p [ 0 ] ] . append ( { "" value "" : p [ 2 ] , "" parameters "" : p [ 1 ] } ) <TAB> children = [ x . to_raw_json ( ) for x in self . children ] <TAB> return { <TAB> <TAB> "" type "" : self . __class__ . __name__ , <TAB> <TAB> "" children "" : children , <TAB> <TAB> "" parts "" : parts , <TAB> } ","if p [ 0 ] not in parts : 
","if not parts . get ( p [ 0 ] ) :
",44.84,25.21,False
"def process_output ( <TAB> output : str , filename : str , start_line : int ) - > Tuple [ Optional [ str ] , bool ] : <TAB> error_found = False <TAB> for line in output . splitlines ( ) : <TAB> <TAB> t = get_revealed_type ( line , filename , start_line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return t , error_found <TAB> <TAB> elif "" error: "" in line : <TAB> <TAB> <TAB> error_found = True <TAB> return None , True<TAB> # finding no reveal_type is an error ","if t : 
","if t is not None :
",34.04,17.97,False
"def __init__ ( <TAB> self , resize_keyboard = None , one_time_keyboard = None , selective = None , row_width = 3 ) : <TAB> if row_width > self . max_row_keys : <TAB> <TAB> # Todo: Will be replaced with Exception in future releases <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" Telegram does not support reply keyboard row width over  %d . "" <TAB> <TAB> <TAB> <TAB> % self . max_row_keys <TAB> <TAB> <TAB> ) <TAB> <TAB> row_width = self . max_row_keys <TAB> self . resize_keyboard = resize_keyboard <TAB> self . one_time_keyboard = one_time_keyboard <TAB> self . selective = selective <TAB> self . row_width = row_width <TAB> self . keyboard = [ ] ","if not DISABLE_KEYLEN_ERROR : 
","if self . max_row_keys > 1 :
",28.37,5.3,False
"def realizeElementExpressions ( innerElement ) : <TAB> elementHasBeenRealized = False <TAB> for exp in innerElement . expressions : <TAB> <TAB> if not hasattr ( exp , "" realize "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> # else: <TAB> <TAB> before , during , after = exp . realize ( innerElement ) <TAB> <TAB> elementHasBeenRealized = True <TAB> <TAB> for n in before : <TAB> <TAB> <TAB> newStream . append ( n ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newStream . append ( during ) <TAB> <TAB> for n in after : <TAB> <TAB> <TAB> newStream . append ( n ) <TAB> if elementHasBeenRealized is False : <TAB> <TAB> newStream . append ( innerElement ) ","if during is not None : 
","if during is not False :
",57.86,53.73,False
"def lex_number ( self , pos ) : <TAB> # numeric literal <TAB> start = pos <TAB> found_dot = False <TAB> while pos < len ( self . string ) and ( <TAB> <TAB> self . string [ pos ] . isdigit ( ) or self . string [ pos ] == "" . "" <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if found_dot is True : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Invalid number. Found multiple  ' . ' "" ) <TAB> <TAB> <TAB> found_dot = True <TAB> <TAB> # technically we allow more than one ""."" and let float()'s parsing <TAB> <TAB> # complain later <TAB> <TAB> pos + = 1 <TAB> val = self . string [ start : pos ] <TAB> return Token ( TokenType . LNUM , val , len ( val ) ) ","if self . string [ pos ] == "" . "" : 
","if self . string [ pos ] . isdot ( ) :
",61.07,50.52,False
"def rename ( src , dst ) : <TAB> # Try atomic or pseudo-atomic rename <TAB> if _rename ( src , dst ) : <TAB> <TAB> return <TAB> # Fall back to ""move away and replace"" <TAB> try : <TAB> <TAB> os . rename ( src , dst ) <TAB> except OSError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> old = "" %s - %08x "" % ( dst , random . randint ( 0 , sys . maxsize ) ) <TAB> <TAB> os . rename ( dst , old ) <TAB> <TAB> os . rename ( src , dst ) <TAB> <TAB> try : <TAB> <TAB> <TAB> os . unlink ( old ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass ","if e . errno != errno . EEXIST : 
","if e . errno != errno . EEXIST :
",100.0,100.0,True
"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB> <TAB> if num > 1 : <TAB> <TAB> <TAB> args = [ point , index ] <TAB> <TAB> else : <TAB> <TAB> <TAB> args = [ point ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . append ( widget ) <TAB> <TAB> try_callback ( callback , * args ) <TAB> return ","if pass_widget : 
","if widget . WIDGET_TYPE == "" WIDGET "" :
",29.31,4.79,False
"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB> <TAB> error = True <TAB> <TAB> try : <TAB> <TAB> <TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> if self . expect_exception : <TAB> <TAB> <TAB> assert error ","if not self . expect_exception : 
","if self . expect_exception :
",58.31,72.9,False
"def handle ( self , * args : Any , * * options : Any ) - > None : <TAB> realm = self . get_realm ( options ) <TAB> if options [ "" all "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> <TAB> "" You must specify a realm if you choose the --all option. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> self . fix_all_users ( realm ) <TAB> <TAB> return <TAB> self . fix_emails ( realm , options [ "" emails "" ] ) ","if realm is None : 
","if not realm :
",28.67,16.37,False
"def recv_tdi ( self , nbits , pos ) : <TAB> bits = 0 <TAB> for n in range ( nbits * 2 ) : <TAB> <TAB> yield from self . _wait_for_tck ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bits = ( bits << 1 ) | ( yield self . tdi . o ) <TAB> return bits ","if ( yield self . tck . o ) == pos : 
","if ( yield self . tck . o ) == pos :
",100.0,100.0,True
"def _split_head ( self ) : <TAB> if not hasattr ( self , "" _severed_head "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tree = self . _tree . copy ( ) <TAB> <TAB> <TAB> head = tree . get_heading_text ( ) <TAB> <TAB> <TAB> tree . remove_heading ( ) <TAB> <TAB> <TAB> self . _severed_head = ( head , tree ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _severed_head = ( None , None ) <TAB> return self . _severed_head ","if self . _tree : 
","if self . _tree :
",100.0,100.0,True
"def buildSearchTrie ( self , choices ) : <TAB> searchtrie = trie . Trie ( ) <TAB> for choice in choices : <TAB> <TAB> for token in self . tokenizeChoice ( choice ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> searchtrie [ token ] = [ ] <TAB> <TAB> <TAB> searchtrie [ token ] . append ( choice ) <TAB> return searchtrie ","if not searchtrie . has_key ( token ) : 
","if token not in searchtrie :
",26.9,5.27,False
"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter ( params ) <TAB> <TAB> if params : <TAB> <TAB> <TAB> sql = sql_to_string ( sql ) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv . params <TAB> <TAB> else : <TAB> <TAB> <TAB> params = ( ) <TAB> for param in params or ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rv . append ( "" NULL "" ) <TAB> <TAB> param = safe_repr ( param ) <TAB> <TAB> rv . append ( param ) <TAB> return sql , rv ","if param is None : 
","if param is None :
",100.0,100.0,True
def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB> <TAB> if len ( ql ) > 0 : <TAB> <TAB> <TAB> observer . on_next ( False ) <TAB> <TAB> <TAB> observer . on_completed ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> observer . on_next ( True ) <TAB> <TAB> <TAB> observer . on_completed ( ) ,"elif donel [ 0 ] : 
","elif len ( qr ) > 0 :
",27.37,7.27,False
"def notify_digest ( self , frequency , changes ) : <TAB> notifications = defaultdict ( list ) <TAB> users = { } <TAB> for change in changes : <TAB> <TAB> for user in self . get_users ( frequency , change ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> notifications [ user . pk ] . append ( change ) <TAB> <TAB> <TAB> <TAB> users [ user . pk ] = user <TAB> for user in users . values ( ) : <TAB> <TAB> self . send_digest ( <TAB> <TAB> <TAB> user . profile . language , <TAB> <TAB> <TAB> user . email , <TAB> <TAB> <TAB> notifications [ user . pk ] , <TAB> <TAB> <TAB> subscription = user . current_subscription , <TAB> <TAB> ) ","if change . project is None or user . can_access_project ( change . project ) : 
","if user . pk not in users :
",34.75,2.93,False
"def _any_listener_using ( self , target_group_arn ) : <TAB> for load_balancer in self . load_balancers . values ( ) : <TAB> <TAB> for listener in load_balancer . listeners . values ( ) : <TAB> <TAB> <TAB> for rule in listener . rules : <TAB> <TAB> <TAB> <TAB> for action in rule . actions : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if action . data . get ( "" target_group_arn "" ) == target_group_arn : 
","if action . target_group_arn == target_group_arn :
",34.0,49.06,False
"def train_dict ( self , triples ) : <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter ( ) <TAB> ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB> # find the most frequent mappings <TAB> for p , _ in ctr . most_common ( ) : <TAB> <TAB> w , pos , l = p <TAB> <TAB> if ( w , pos ) not in self . composite_dict : <TAB> <TAB> <TAB> self . composite_dict [ ( w , pos ) ] = l <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . word_dict [ w ] = l <TAB> return ","if w not in self . word_dict : 
","if ( w , pos ) not in self . word_dict :
",64.49,54.37,False
"def parse_git_config ( path ) : <TAB> """"""Parse git config file."""""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> config [ section ] = dict ( ) <TAB> <TAB> <TAB> elif section : <TAB> <TAB> <TAB> <TAB> key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB> <TAB> <TAB> <TAB> config [ section ] [ key ] = value <TAB> return config ","if line . startswith ( "" [ "" ) : 
","if line . startswith ( "" # "" ) :
",83.03,65.8,False
"def send_signal ( self , pid , signum ) : <TAB> if pid in self . processes : <TAB> <TAB> process = self . processes [ pid ] <TAB> <TAB> hook_result = self . call_hook ( "" before_signal "" , pid = pid , signum = signum ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> "" before_signal hook didn ' t return True  "" <TAB> <TAB> <TAB> <TAB> "" => signal  %i  is not sent to  %i "" % ( signum , pid ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> process . send_signal ( signum ) <TAB> <TAB> self . call_hook ( "" after_signal "" , pid = pid , signum = signum ) <TAB> else : <TAB> <TAB> logger . debug ( "" process  %s  does not exist "" % pid ) ","if signum != signal . SIGKILL and not hook_result : 
","if hook_result is False :
",26.36,11.79,False
"def validate_pos_return ( self ) : <TAB> if self . is_pos and self . is_return : <TAB> <TAB> total_amount_in_payments = 0 <TAB> <TAB> for payment in self . payments : <TAB> <TAB> <TAB> total_amount_in_payments + = payment . amount <TAB> <TAB> invoice_total = self . rounded_total or self . grand_total <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Total payments amount can ' t be greater than  {} "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> - invoice_total <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","if total_amount_in_payments < invoice_total : 
","if total_amount_in_payments > invoice_total :
",58.14,76.12,False
"def delete ( key , inner_key = None ) : <TAB> if inner_key is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> del cache [ key ] [ inner_key ] <TAB> <TAB> <TAB> del use_count [ key ] [ inner_key ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del cache [ key ] <TAB> <TAB> <TAB> <TAB> del use_count [ key ] <TAB> <TAB> <TAB> wrapper . cache_size - = 1 <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return True <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> wrapper . cache_size - = len ( cache [ key ] ) <TAB> <TAB> <TAB> del cache [ key ] <TAB> <TAB> <TAB> del use_count [ key ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return True ","if not cache [ key ] : 
","if not cache [ key ] :
",100.0,100.0,True
"def insertionsort ( array ) : <TAB> size = array . getsize ( ) <TAB> array . reset ( "" Insertion sort "" ) <TAB> for i in range ( 1 , size ) : <TAB> <TAB> j = i - 1 <TAB> <TAB> while j > = 0 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> array . swap ( j , j + 1 ) <TAB> <TAB> <TAB> j = j - 1 <TAB> array . message ( "" Sorted "" ) ","if array . compare ( j , j + 1 ) < = 0 : 
","if array . compare ( j , i ) < 0 :
",52.46,48.32,False
"def publish_state ( cls , payload , state ) : <TAB> try : <TAB> <TAB> if isinstance ( payload , LiveActionDB ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cls . process ( payload ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> print ( payload ) ","if state == action_constants . LIVEACTION_STATUS_REQUESTED : 
","if state == LiveActionDB . WAITING :
",59.45,18.07,False
"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB> <TAB> if type ( submob ) == AnnularSector : <TAB> <TAB> <TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self . opacity_function ( r ) <TAB> <TAB> submob . set_fill ( opacity = alpha ) ","if type ( submob ) != AnnularSector : 
","if submob . get_shape ( ) == [ ] :
",26.8,4.83,False
"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None : <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target , subtarget = warning_type , None <TAB> <TAB> if target == type : <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == "" * "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if "" . "" in warning_type : 
","if "" . "" in warning_type :
",100.0,100.0,True
"def set_many ( self , mapping , timeout = None ) : <TAB> timeout = self . _normalize_timeout ( timeout ) <TAB> # Use transaction=False to batch without calling redis MULTI <TAB> # which is not supported by twemproxy <TAB> pipe = self . _client . pipeline ( transaction = False ) <TAB> for key , value in _items ( mapping ) : <TAB> <TAB> dump = self . dump_object ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pipe . set ( name = self . key_prefix + key , value = dump ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pipe . setex ( name = self . key_prefix + key , value = dump , time = timeout ) <TAB> return pipe . execute ( ) ","if timeout == - 1 : 
","if timeout is None :
",30.17,15.85,False
"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB> <TAB> return path<TAB> # already relative <TAB> dir = path <TAB> names = [ ] <TAB> while True : <TAB> <TAB> prevdir = dir <TAB> <TAB> dir , name = os . path . split ( prevdir ) <TAB> <TAB> if dir == prevdir or not dir : <TAB> <TAB> <TAB> return path<TAB> # failed to make it relative <TAB> <TAB> names . append ( name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> names . reverse ( ) <TAB> <TAB> <TAB> <TAB> return os . path . join ( * names ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass ","if samefile ( dir , os . curdir ) : 
","if os . path . isdir ( name ) :
",33.57,13.13,False
"def word_range ( word ) : <TAB> for ind in range ( len ( word ) ) : <TAB> <TAB> temp = word [ ind ] <TAB> <TAB> for c in [ chr ( x ) for x in range ( ord ( "" a "" ) , ord ( "" z "" ) + 1 ) ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield word [ : ind ] + c + word [ ind + 1 : ] ","if c != temp : 
","if c in temp :
",58.14,24.74,False
"def validate ( self ) : <TAB> self . update_soil_edit ( "" sand_composition "" ) <TAB> for soil_type in self . soil_types : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" {0}  should be a value between 0 and 100 "" ) . format ( soil_type ) ) <TAB> if sum ( self . get ( soil_type ) for soil_type in self . soil_types ) != 100 : <TAB> <TAB> frappe . throw ( _ ( "" Soil compositions do not add up to 100 "" ) ) ","if self . get ( soil_type ) > 100 or self . get ( soil_type ) < 0 : 
","if not ( 0 < = soil_type < = 100 ) :
",25.83,7.51,False
"def on_click ( self , event ) : <TAB> run = self . _is_running ( ) <TAB> if event [ "" button "" ] == self . button_activate : <TAB> <TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -activate "" ] ) <TAB> if event [ "" button "" ] == self . button_toggle : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . py3 . command_run ( [ "" xscreensaver-command "" , "" -exit "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Because we want xscreensaver to continue running after <TAB> <TAB> <TAB> # exit, we instead use preexec_fn=setpgrp here. <TAB> <TAB> <TAB> Popen ( <TAB> <TAB> <TAB> <TAB> [ "" xscreensaver "" , "" -no-splash "" , "" -no-capture-stderr "" ] , <TAB> <TAB> <TAB> <TAB> stdout = PIPE , <TAB> <TAB> <TAB> <TAB> stderr = PIPE , <TAB> <TAB> <TAB> <TAB> preexec_fn = setpgrp , <TAB> <TAB> <TAB> ) ","if run : 
","if run :
",78.12,0.0,False
"def maybe_relative_path ( path ) : <TAB> if not os . path . isabs ( path ) : <TAB> <TAB> return path<TAB> # already relative <TAB> dir = path <TAB> names = [ ] <TAB> while True : <TAB> <TAB> prevdir = dir <TAB> <TAB> dir , name = os . path . split ( prevdir ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return path<TAB> # failed to make it relative <TAB> <TAB> names . append ( name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if samefile ( dir , os . curdir ) : <TAB> <TAB> <TAB> <TAB> names . reverse ( ) <TAB> <TAB> <TAB> <TAB> return os . path . join ( * names ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass ","if dir == prevdir or not dir : 
","if not os . path . isabs ( name ) :
",26.63,4.93,False
"def _format_micros ( self , datestring ) : <TAB> parts = datestring [ : - 1 ] . split ( "" . "" ) <TAB> if len ( parts ) == 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return datestring [ : - 1 ] + "" .000000Z "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return datestring + "" .000000Z "" <TAB> else : <TAB> <TAB> micros = parts [ - 1 ] [ : 6 ] if len ( parts [ - 1 ] ) > 6 else parts [ - 1 ] <TAB> <TAB> return "" . "" . join ( parts [ : - 1 ] + [ "" {:06d} "" . format ( int ( micros ) ) ] ) + "" Z "" ","if datestring . endswith ( "" Z "" ) : 
","if len ( datestring ) > 1 :
",26.65,6.43,False
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if line [ 0 ] == "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" ) ","if line != "" "" and line != "" "" : 
","if line :
",26.65,0.0,False
"def set ( self , item , data ) : <TAB> if not type ( item ) is slice : <TAB> <TAB> item = slice ( item , item + len ( data ) , None ) <TAB> virt_item = self . item2virtitem ( item ) <TAB> if not virt_item : <TAB> <TAB> return <TAB> off = 0 <TAB> for s , n_item in virt_item : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> i = slice ( off , n_item . stop + off - n_item . start , n_item . step ) <TAB> <TAB> <TAB> data_slice = data . __getitem__ ( i ) <TAB> <TAB> <TAB> s . content . __setitem__ ( n_item , data_slice ) <TAB> <TAB> <TAB> off = i . stop <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" TODO XXX "" ) <TAB> return ","if isinstance ( s , ProgBits ) : 
","if type ( n_item ) is slice :
",27.04,5.93,False
"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part . get_content_maintype ( ) == "" multipart "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part . get_content_type ( ) <TAB> <TAB> if ctype is None : <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part . get_filename ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = PART_FN_TPL % ( partnum ) <TAB> <TAB> headers = dict ( part ) <TAB> <TAB> LOG . debug ( headers ) <TAB> <TAB> headers [ "" Content-Type "" ] = ctype <TAB> <TAB> payload = util . fully_decoded_payload ( part ) <TAB> <TAB> callback ( data , filename , payload , headers ) <TAB> <TAB> partnum = partnum + 1 ","if not filename : 
","if filename is None :
",29.25,14.06,False
"def _run_wes ( args ) : <TAB> """"""Run CWL using a Workflow Execution Service (WES) endpoint"""""" <TAB> main_file , json_file , project_name = _get_main_and_json ( args . directory ) <TAB> main_file = _pack_cwl ( main_file ) <TAB> if args . host and "" stratus "" in args . host : <TAB> <TAB> _run_wes_stratus ( args , main_file , json_file ) <TAB> else : <TAB> <TAB> opts = [ "" --no-wait "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> opts + = [ "" --host "" , args . host ] <TAB> <TAB> if args . auth : <TAB> <TAB> <TAB> opts + = [ "" --auth "" , args . auth ] <TAB> <TAB> cmd = [ "" wes-client "" ] + opts + [ main_file , json_file ] <TAB> <TAB> _run_tool ( cmd ) ","if args . host : 
","if args . host :
",100.0,100.0,True
"def insertTestData ( self , rows ) : <TAB> for row in rows : <TAB> <TAB> if isinstance ( row , Worker ) : <TAB> <TAB> <TAB> self . workers [ row . id ] = dict ( <TAB> <TAB> <TAB> <TAB> id = row . id , name = row . name , paused = 0 , graceful = 0 , info = row . info <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> row . id = row . buildermasterid * 10000 + row . workerid <TAB> <TAB> <TAB> self . configured [ row . id ] = dict ( <TAB> <TAB> <TAB> <TAB> buildermasterid = row . buildermasterid , workerid = row . workerid <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance ( row , ConnectedWorker ) : <TAB> <TAB> <TAB> self . connected [ row . id ] = dict ( masterid = row . masterid , workerid = row . workerid ) ","elif isinstance ( row , ConfiguredWorker ) : 
","elif isinstance ( row , ConnectionConfiguredWorker ) :
",79.9,59.46,False
"def local_shape_to_shape_i ( node ) : <TAB> if node . op == T . shape : <TAB> <TAB> # This optimization needs ShapeOpt and fgraph.shape_feature <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> shape_feature = node . fgraph . shape_feature <TAB> <TAB> ret = shape_feature . make_vector_shape ( node . inputs [ 0 ] ) <TAB> <TAB> # We need to copy over stack trace from input to output <TAB> <TAB> copy_stack_trace ( node . outputs [ 0 ] , ret ) <TAB> <TAB> return [ ret ] ","if not hasattr ( node . fgraph , "" shape_feature "" ) : 
","if not hasattr ( node , "" fgraph "" ) or not hasattr ( node . fgraph , "" shape_feature "" ) :
",81.18,57.31,False
"def get_config ( ) : <TAB> """"""Get INI parser with version.ini data."""""" <TAB> # TODO(hanuszczak): See comment in `setup.py` for `grr-response-proto`. <TAB> ini_path = os . path . join ( THIS_DIRECTORY , "" version.ini "" ) <TAB> <MASK> <TAB> <TAB> ini_path = os . path . join ( THIS_DIRECTORY , "" ../../version.ini "" ) <TAB> <TAB> if not os . path . exists ( ini_path ) : <TAB> <TAB> <TAB> raise RuntimeError ( "" Couldn ' t find version.ini "" ) <TAB> config = configparser . ConfigParser ( ) <TAB> config . read ( ini_path ) <TAB> return config ","if not os . path . exists ( ini_path ) : 
","if not os . path . exists ( ini_path ) :
",100.0,100.0,True
"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB> <TAB> logger = logging . getLogger ( ) <TAB> <TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB> <TAB> for m in self . modules ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <TAB> elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) : <TAB> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> else : <TAB> <TAB> raise TypeError ( "" pretrained must be a str or None "" ) ","if isinstance ( m , nn . Conv2d ) : 
","if isinstance ( m , nn . Conv2d ) :
",100.0,100.0,True
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) ","if value == "" DD-MM-YYYY "" : 
","if not valid_value :
",27.28,7.65,False
"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB> <TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> box_keys = [ ] <TAB> <TAB> if hasattr ( py_obj , "" masks "" ) and py_obj . masks : <TAB> <TAB> <TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask_keys = [ ] <TAB> <TAB> return cls ( box_keys , mask_keys ) ","if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes : 
","if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes :
",100.0,100.0,True
"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB> <TAB> if stat . S_ISREG ( st . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" file "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts . append ( "" dir "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB> <TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" link "" ) <TAB> return "" "" . join ( parts ) ","elif stat . S_ISDIR ( st . st_mode ) : 
","elif stat . S_ISDIR ( st . st_mode ) :
",100.0,100.0,True
"def is_destructive ( queries ) : <TAB> """"""Returns if any of the queries in *queries* is destructive."""""" <TAB> keywords = ( "" drop "" , "" shutdown "" , "" delete "" , "" truncate "" , "" alter "" ) <TAB> for query in sqlparse . split ( queries ) : <TAB> <TAB> if query : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif query_starts_with ( <TAB> <TAB> <TAB> <TAB> query , [ "" update "" ] <TAB> <TAB> <TAB> ) is True and not query_has_where_clause ( query ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if query_starts_with ( query , keywords ) is True : 
","if query in keywords :
",26.43,4.2,False
"def _store_gsuite_membership_post ( self ) : <TAB> """"""Flush storing gsuite memberships."""""" <TAB> if not self . member_cache : <TAB> <TAB> return <TAB> self . session . flush ( ) <TAB> # session.execute automatically flushes <TAB> if self . membership_items : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # SQLite doesn't support bulk insert <TAB> <TAB> <TAB> for item in self . membership_items : <TAB> <TAB> <TAB> <TAB> stmt = self . dao . TBL_MEMBERSHIP . insert ( item ) <TAB> <TAB> <TAB> <TAB> self . session . execute ( stmt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stmt = self . dao . TBL_MEMBERSHIP . insert ( self . membership_items ) <TAB> <TAB> <TAB> self . session . execute ( stmt ) ","if get_sql_dialect ( self . session ) == "" sqlite "" : 
","if isinstance ( self . membership_items [ 0 ] , list ) :
",33.51,10.58,False
"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB> <TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB> <TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB> <TAB> outputs . append ( block_out ) <TAB> <TAB> if i < 2 : <TAB> <TAB> <TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB> <TAB> <TAB> route = self . upsample ( route ) <TAB> return outputs ","if i > 0 : 
","if i < 1 :
",56.5,23.64,False
"def deep_dict ( self , root = None ) : <TAB> if root is None : <TAB> <TAB> root = self <TAB> result = { } <TAB> for key , value in root . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ key ] = self . deep_dict ( root = self . __class__ . _get_next ( key , root ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = value <TAB> return result ","if isinstance ( value , dict ) : 
","if isinstance ( value , dict ) :
",100.0,100.0,True
"def _parse_param_list ( self , content ) : <TAB> r = Reader ( content ) <TAB> params = [ ] <TAB> while not r . eof ( ) : <TAB> <TAB> header = r . read ( ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arg_name , arg_type = header . split ( ""  :  "" ) [ : 2 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> arg_name , arg_type = header , "" "" <TAB> <TAB> desc = r . read_to_next_unindented_line ( ) <TAB> <TAB> desc = dedent_lines ( desc ) <TAB> <TAB> params . append ( ( arg_name , arg_type , desc ) ) <TAB> return params ","if ""  :  "" in header : 
","if ""  :  "" in header :
",100.0,100.0,True
"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if groups is not None : <TAB> <TAB> <TAB> <TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB> <TAB> <TAB> for v in _ungroup ( v , groups ) : <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else : <TAB> <TAB> <TAB> yield v ","if isinstance ( v , ( list , tuple ) ) : 
","if isinstance ( v , ( list , tuple ) ) :
",100.0,100.0,True
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB> <TAB> <TAB> <TAB> if obj [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] ) ","if item_key != "" sourceVault "" : 
","if item_key in obj :
",29.24,28.32,False
"def haslayer ( self , cls ) : <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB> <TAB> return 1 <TAB> for f in self . packetfields : <TAB> <TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB> <TAB> if fvalue_gen is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f . islist : <TAB> <TAB> <TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB> <TAB> for fvalue in fvalue_gen : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret = fvalue . haslayer ( cls ) <TAB> <TAB> <TAB> <TAB> if ret : <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self . payload . haslayer ( cls ) ","if isinstance ( fvalue , Packet ) : 
","if hasattr ( fvalue , "" haslayer "" ) :
",33.08,20.56,False
"def _post_attachment ( self , message , channel , color , sub_fields = None ) : <TAB> if channel is None : <TAB> <TAB> message_channels = self . channels <TAB> else : <TAB> <TAB> message_channels = [ channel ] <TAB> for message_channel in message_channels : <TAB> <TAB> attachment = { <TAB> <TAB> <TAB> "" fallback "" : message , <TAB> <TAB> <TAB> "" text "" : message , <TAB> <TAB> <TAB> "" color "" : color , <TAB> <TAB> } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attachment [ "" fields "" ] = sub_fields <TAB> <TAB> self . slack_client . api_call ( <TAB> <TAB> <TAB> "" chat.postMessage "" , <TAB> <TAB> <TAB> channel = message_channel , <TAB> <TAB> <TAB> attachments = [ attachment ] , <TAB> <TAB> <TAB> as_user = True , <TAB> <TAB> ) ","if sub_fields is not None : 
","if sub_fields :
",29.58,38.81,False
"def create ( cls , repository , args ) : <TAB> key = cls ( ) <TAB> passphrase = os . environ . get ( "" ATTIC_PASSPHRASE "" ) <TAB> if passphrase is not None : <TAB> <TAB> passphrase2 = passphrase <TAB> else : <TAB> <TAB> passphrase , passphrase2 = 1 , 2 <TAB> while passphrase != passphrase2 : <TAB> <TAB> passphrase = getpass ( "" Enter passphrase:  "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Passphrase must not be blank "" ) <TAB> <TAB> <TAB> continue <TAB> <TAB> passphrase2 = getpass ( "" Enter same passphrase again:  "" ) <TAB> <TAB> if passphrase != passphrase2 : <TAB> <TAB> <TAB> print ( "" Passphrases do not match "" ) <TAB> key . init ( repository , passphrase ) <TAB> if passphrase : <TAB> <TAB> print ( "" Remember your passphrase. Your data will be inaccessible without it. "" ) <TAB> return key ","if not passphrase : 
","if passphrase is None :
",29.25,14.06,False
"def _generate_create_date ( self ) : <TAB> if self . timezone is not None : <TAB> <TAB> # First, assume correct capitalization <TAB> <TAB> tzinfo = tz . gettz ( self . timezone ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Fall back to uppercase <TAB> <TAB> <TAB> tzinfo = tz . gettz ( self . timezone . upper ( ) ) <TAB> <TAB> if tzinfo is None : <TAB> <TAB> <TAB> raise util . CommandError ( "" Can ' t locate timezone:  %s "" % self . timezone ) <TAB> <TAB> create_date = ( <TAB> <TAB> <TAB> datetime . datetime . utcnow ( ) . replace ( tzinfo = tz . tzutc ( ) ) . astimezone ( tzinfo ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> create_date = datetime . datetime . now ( ) <TAB> return create_date ","if tzinfo is None : 
","if tzinfo is None :
",100.0,100.0,True
"def _read_header_lines ( fp ) : <TAB> """"""Read lines with headers until the start of body"""""" <TAB> lines = deque ( ) <TAB> for line in fp : <TAB> <TAB> if is_empty ( line ) : <TAB> <TAB> <TAB> break <TAB> <TAB> # tricky case if it's not a header and not an empty line <TAB> <TAB> # usually means that user forgot to separate the body and newlines <TAB> <TAB> # so ""unread"" this line here, what means to treat it like a body <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fp . seek ( fp . tell ( ) - len ( line ) ) <TAB> <TAB> <TAB> break <TAB> <TAB> lines . append ( line ) <TAB> return lines ","if not _RE_HEADER . match ( line ) : 
","if not line . startswith ( "" [ "" ) and len ( line ) > 0 :
",39.13,10.93,False
"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB> <TAB> try : <TAB> <TAB> <TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> uri , unused = uri_tuple <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if utils . is_media_file ( uri ) == True : <TAB> <TAB> <TAB> <TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB> <TAB> return <TAB> open_dropped_files ( files ) ","if os . path . exists ( uri ) == True : 
","if uri :
",25.8,0.0,False
"def remove_importlib ( frame , options ) : <TAB> if frame is None : <TAB> <TAB> return None <TAB> for child in frame . children : <TAB> <TAB> remove_importlib ( child , options = options ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # remove this node, moving the self_time and children up to the parent <TAB> <TAB> <TAB> frame . self_time + = child . self_time <TAB> <TAB> <TAB> frame . add_children ( child . children , after = child ) <TAB> <TAB> <TAB> child . remove_from_parent ( ) <TAB> return frame ","if "" <frozen importlib._bootstrap "" in child . file_path : 
","if child . is_leaf :
",32.61,4.57,False
"def __call__ ( self , graph ) : <TAB> for layer_name , data in self . params : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> node = graph . get_node ( layer_name ) <TAB> <TAB> <TAB> node . data = self . adjust_parameters ( node , data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print_stderr ( "" Ignoring parameters for non-existent layer:  %s "" % layer_name ) <TAB> return graph ","if layer_name in graph : 
","if self . check_parameters ( graph , layer_name ) :
",27.53,12.57,False
"def test_with_three_points ( self ) : <TAB> cba = ia . Polygon ( [ ( 1 , 2 ) , ( 3 , 4 ) , ( 5 , 5 ) ] ) <TAB> for i , xy in enumerate ( cba ) : <TAB> <TAB> assert i in [ 0 , 1 , 2 ] <TAB> <TAB> if i == 0 : <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 1 , 2 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 3 , 4 ) ) <TAB> <TAB> elif i == 2 : <TAB> <TAB> <TAB> assert np . allclose ( xy , ( 5 , 5 ) ) <TAB> assert i == 2 ","elif i == 1 : 
","elif i == 1 :
",100.0,100.0,True
"def _serve ( self ) : <TAB> self . _conn = self . manager . request ( REQUEST_DNS_LISTENER , self . domain ) <TAB> conn = MsgPackMessages ( self . _conn ) <TAB> while self . active : <TAB> <TAB> request = conn . recv ( ) <TAB> <TAB> if not request : <TAB> <TAB> <TAB> logger . warning ( "" DNS: Recieved empty request. Shutdown "" ) <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> now = time . time ( ) <TAB> <TAB> response = self . handler . process ( request ) <TAB> <TAB> if not response : <TAB> <TAB> <TAB> response = [ ] <TAB> <TAB> used = time . time ( ) - now <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( "" DNS: Slow processing speed ( %s )s "" , used ) <TAB> <TAB> conn . send ( response ) ","if used > 1 : 
","if used > self . _slow_processing_speed :
",36.73,13.55,False
"def read ( cls , fp , * * kwargs ) : <TAB> major_version , minor_version , count = read_fmt ( "" 2HI "" , fp ) <TAB> items = [ ] <TAB> for _ in range ( count ) : <TAB> <TAB> length = read_fmt ( "" I "" , fp ) [ 0 ] - 4 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with io . BytesIO ( fp . read ( length ) ) as f : <TAB> <TAB> <TAB> <TAB> items . append ( Annotation . read ( f ) ) <TAB> return cls ( major_version = major_version , minor_version = minor_version , items = items ) ","if length > 0 : 
","if length > 0 :
",100.0,100.0,True
"def save_uploaded_files ( ) : <TAB> files = [ ] <TAB> unzip = bool ( request . form . get ( "" unzip "" ) in [ "" true "" , "" on "" ] ) <TAB> for uploaded_file in request . files . getlist ( "" files "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with zipfile . ZipFile ( uploaded_file , "" r "" ) as zf : <TAB> <TAB> <TAB> <TAB> for info in zf . infolist ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> name = info . filename <TAB> <TAB> <TAB> <TAB> <TAB> size = info . file_size <TAB> <TAB> <TAB> <TAB> <TAB> data = zf . read ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> if size > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> files . append ( save_file ( data , filename = name . split ( "" / "" ) [ - 1 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> files . append ( save_file ( uploaded_file ) ) <TAB> return files ","if unzip and zipfile . is_zipfile ( uploaded_file ) : 
","if unzip :
",26.96,0.0,False
"def analyze_string_content ( self , string , line_num , filename ) : <TAB> output = { } <TAB> if self . keyword_exclude and self . keyword_exclude . search ( string ) : <TAB> <TAB> return output <TAB> for identifier in self . secret_generator ( <TAB> <TAB> string , <TAB> <TAB> filetype = determine_file_type ( filename ) , <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> secret = PotentialSecret ( <TAB> <TAB> <TAB> self . secret_type , <TAB> <TAB> <TAB> filename , <TAB> <TAB> <TAB> identifier , <TAB> <TAB> <TAB> line_num , <TAB> <TAB> ) <TAB> <TAB> output [ secret ] = secret <TAB> return output ","if self . is_secret_false_positive ( identifier ) : 
","if self . secret_type is None :
",37.78,13.93,False
"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name , definition in self . hyperparameter_definitions . items ( ) : <TAB> <TAB> if name not in self . hyperparam_dict : <TAB> <TAB> <TAB> spec = definition [ "" spec "" ] <TAB> <TAB> <TAB> if "" DefaultValue "" in spec : <TAB> <TAB> <TAB> <TAB> self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name ) ","elif "" IsRequired "" in spec and spec [ "" IsRequired "" ] : 
","elif self . hyperparam_dict [ name ] is None :
",26.01,4.05,False
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> if mod_type == imp . PY_SOURCE : <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> elif mod_type == imp . PY_COMPILED : <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code ","elif mod_type == imp . PKG_DIRECTORY : 
","if self . _get_delegate :
",33.2,4.74,False
"def eigh_abstract_eval ( operand , lower ) : <TAB> if isinstance ( operand , ShapedArray ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Argument to symmetric eigendecomposition must have shape [..., n, n], "" <TAB> <TAB> <TAB> <TAB> "" got shape  {} "" . format ( operand . shape ) <TAB> <TAB> <TAB> ) <TAB> <TAB> batch_dims = operand . shape [ : - 2 ] <TAB> <TAB> n = operand . shape [ - 1 ] <TAB> <TAB> v = ShapedArray ( batch_dims + ( n , n ) , operand . dtype ) <TAB> <TAB> w = ShapedArray ( batch_dims + ( n , ) , lax . lax . _complex_basetype ( operand . dtype ) ) <TAB> else : <TAB> <TAB> v , w = operand , operand <TAB> return v , w ","if operand . ndim < 2 or operand . shape [ - 2 ] != operand . shape [ - 1 ] : 
","if operand . shape [ - 2 ] != n :
",54.61,29.26,False
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> if dsn [ i ] . isspace ( ) : <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> if i > = length : <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret ","if not param_match : 
","if param_match is None :
",29.25,27.78,False
"def load_weights_from_unsupervised ( self , unsupervised_model ) : <TAB> update_state_dict = copy . deepcopy ( self . network . state_dict ( ) ) <TAB> for param , weights in unsupervised_model . network . state_dict ( ) . items ( ) : <TAB> <TAB> if param . startswith ( "" encoder "" ) : <TAB> <TAB> <TAB> # Convert encoder's layers name to match <TAB> <TAB> <TAB> new_param = "" tabnet. "" + param <TAB> <TAB> else : <TAB> <TAB> <TAB> new_param = param <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # update only common layers <TAB> <TAB> <TAB> update_state_dict [ new_param ] = weights <TAB> self . network . load_state_dict ( update_state_dict ) ","if self . network . state_dict ( ) . get ( new_param ) is not None : 
","if new_param in self . network . get_layers ( ) :
",42.94,20.25,False
"def viewer_setup ( self ) : <TAB> for key , value in DEFAULT_CAMERA_CONFIG . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> getattr ( self . viewer . cam , key ) [ : ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( self . viewer . cam , key , value ) ","if isinstance ( value , np . ndarray ) : 
","if isinstance ( value , list ) :
",48.2,46.31,False
"def colormap_changed ( change ) : <TAB> if change [ "" new "" ] : <TAB> <TAB> cmap_colors = [ <TAB> <TAB> <TAB> color [ 1 : ] for color in cmap . step . __dict__ [ "" _schemes "" ] [ colormap . value ] <TAB> <TAB> ] <TAB> <TAB> palette . value = "" ,  "" . join ( cmap_colors ) <TAB> <TAB> colorbar = getattr ( cmap . step , colormap . value ) <TAB> <TAB> colorbar_output = self . colorbar_widget <TAB> <TAB> with colorbar_output : <TAB> <TAB> <TAB> colorbar_output . clear_output ( ) <TAB> <TAB> <TAB> display ( colorbar ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> labels = [ f "" Class  { i + 1 } "" for i in range ( len ( palette . value . split ( "" , "" ) ) ) ] <TAB> <TAB> <TAB> legend_labels . value = "" ,  "" . join ( labels ) ","if len ( palette . value ) > 0 and "" , "" in palette . value : 
","if change [ "" new "" ] :
",28.18,2.24,False
"def invalidate ( self , layers = None ) : <TAB> if layers is None : <TAB> <TAB> layers = Layer . AllLayers <TAB> if layers : <TAB> <TAB> layers = set ( layers ) <TAB> <TAB> self . invalidLayers . update ( layers ) <TAB> <TAB> blockRenderers = [ <TAB> <TAB> <TAB> br <TAB> <TAB> <TAB> for br in self . blockRenderers <TAB> <TAB> <TAB> if br . layer is Layer . Blocks or br . layer not in layers <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . forgetDisplayLists ( ) <TAB> <TAB> self . blockRenderers = blockRenderers <TAB> <TAB> if self . renderer . showRedraw and Layer . Blocks in layers : <TAB> <TAB> <TAB> self . needsRedisplay = True ","if len ( blockRenderers ) < len ( self . blockRenderers ) : 
","if len ( blockRenderers ) > 0 :
",46.53,28.96,False
"def fromstring ( cls , input ) : <TAB> productions = [ ] <TAB> for linenum , line in enumerate ( input . split ( "" \n "" ) ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> productions + = _read_dependency_production ( line ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" Unable to parse line  %s :  %s "" % ( linenum , line ) ) <TAB> if len ( productions ) == 0 : <TAB> <TAB> raise ValueError ( "" No productions found! "" ) <TAB> return DependencyGrammar ( productions ) ","if line . startswith ( "" # "" ) or line == "" "" : 
","if not line :
",25.65,1.05,False
"def repl ( m , base_path , rel_path = None ) : <TAB> if m . group ( "" comments "" ) : <TAB> <TAB> tag = m . group ( "" comments "" ) <TAB> else : <TAB> <TAB> tag = m . group ( "" open "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB> <TAB> <TAB> <TAB> lambda m2 : repl_absolute ( m2 , base_path ) , m . group ( "" attr "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tag + = RE_TAG_LINK_ATTR . sub ( <TAB> <TAB> <TAB> <TAB> lambda m2 : repl_relative ( m2 , base_path , rel_path ) , m . group ( "" attr "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> tag + = m . group ( "" close "" ) <TAB> return tag ","if rel_path is None : 
","if rel_path is None :
",100.0,100.0,True
"def encode ( path ) : <TAB> if isinstance ( path , str_cls ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> path = path . encode ( fs_encoding , "" strict "" ) <TAB> <TAB> except UnicodeEncodeError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> path = path . encode ( fs_fallback_encoding , "" strict "" ) <TAB> return path ","if not platform . is_linux ( ) : 
","if not sys . version_info [ 0 ] < 3 :
",32.28,7.77,False
"def __iter__ ( self ) : <TAB> base_iterator = super ( ProcessIterable , self ) . __iter__ ( ) <TAB> if getattr ( self . queryset , "" _coerced "" , False ) : <TAB> <TAB> for process in base_iterator : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> process = coerce_to_related_instance ( <TAB> <TAB> <TAB> <TAB> <TAB> process , process . flow_class . process_class <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield process <TAB> else : <TAB> <TAB> for process in base_iterator : <TAB> <TAB> <TAB> yield process ","if isinstance ( process , self . queryset . model ) : 
","if not isinstance ( process , self . queryset . queryset ) :
",74.59,62.63,False
"def footnotes_under ( n : Element ) - > Iterator [ nodes . footnote ] : <TAB> if isinstance ( n , nodes . footnote ) : <TAB> <TAB> yield n <TAB> else : <TAB> <TAB> for c in n . children : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif isinstance ( c , nodes . Element ) : <TAB> <TAB> <TAB> <TAB> yield from footnotes_under ( c ) ","if isinstance ( c , addnodes . start_of_file ) : 
","if c is None :
",26.44,2.32,False
"def _process_submissions ( self ) - > None : <TAB> """"""Process all submissions which have not been processed yet."""""" <TAB> while self . _to_be_processed : <TAB> <TAB> job = self . _to_be_processed [ 0 ] <TAB> <TAB> job . process ( )<TAB> # trigger computation <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> heapq . heappush ( <TAB> <TAB> <TAB> <TAB> self . _steady_priority_queue , <TAB> <TAB> <TAB> <TAB> OrderedJobs ( job . release_time , self . _order , job ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _to_be_processed . popleft ( )<TAB> # remove right after it is added to the heap queue <TAB> <TAB> self . _order + = 1 ","if not self . batch_mode : 
","if job . release_time > self . _order :
",35.23,8.52,False
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if line == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT . match ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters : <TAB> <TAB> <TAB> if "" , "" in line or "" ; "" in line : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line ","if match : 
","if match is None :
",34.79,23.64,False
"def _get_payload_hash ( self , method , data = None ) : <TAB> if method in ( "" POST "" , "" PUT "" ) : <TAB> <TAB> if data : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # File upload; don't try to read the entire payload <TAB> <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> <TAB> <TAB> return _hash ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return UNSIGNED_PAYLOAD <TAB> else : <TAB> <TAB> return _hash ( "" "" ) ","if hasattr ( data , "" next "" ) or hasattr ( data , "" __next__ "" ) : 
","if not data . endswith ( "" .h "" ) :
",33.55,6.23,False
"def get_download_info ( self ) : <TAB> try : <TAB> <TAB> download_info = self . api . get_download_info ( self . game ) <TAB> <TAB> result = True <TAB> except NoDownloadLinkFound as e : <TAB> <TAB> print ( e ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> Config . unset ( "" current_download "" ) <TAB> <TAB> GLib . idle_add ( <TAB> <TAB> <TAB> self . parent . parent . show_error , <TAB> <TAB> <TAB> _ ( "" Download error "" ) , <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> "" There was an error when trying to fetch the download link! \n {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> e <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> download_info = False <TAB> <TAB> result = False <TAB> return result , download_info ","if Config . get ( "" current_download "" ) == self . game . id : 
","if not download_info :
",25.57,1.31,False
"def find_id ( self , doc_id ) : <TAB> self . _lock . acquire ( ) <TAB> try : <TAB> <TAB> doc = self . _docs . get ( doc_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> doc = copy . deepcopy ( doc ) <TAB> <TAB> <TAB> doc [ "" id "" ] = doc_id <TAB> <TAB> <TAB> return doc <TAB> finally : <TAB> <TAB> self . _lock . release ( ) ","if doc : 
","if doc :
",78.12,0.0,False
"def assign_art ( self , session , task ) : <TAB> """"""Place the discovered art in the filesystem."""""" <TAB> if task in self . art_candidates : <TAB> <TAB> candidate = self . art_candidates . pop ( task ) <TAB> <TAB> self . _set_art ( task . album , candidate , not self . src_removed ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> task . prune ( candidate . path ) ","if self . src_removed : 
","if candidate . path and candidate . path not in self . src_removed :
",55.71,31.31,False
"def _replace_named ( self , named , replace_scalar ) : <TAB> for item in named : <TAB> <TAB> for name , value in self . _get_replaced_named ( item , replace_scalar ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise DataError ( "" Argument names must be strings. "" ) <TAB> <TAB> <TAB> yield name , value ","if not is_string ( name ) : 
","if not isinstance ( name , str ) :
",30.29,16.52,False
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr ( val , "" __len__ "" ) : <TAB> <TAB> <TAB> val = str ( val ) <TAB> <TAB> if len ( val ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB> <TAB> <TAB> value = ' "" ' + value + ' "" ' <TAB> <TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res ","if Driver . needsQuoting ( val , True ) : 
","if value :
",26.04,0.0,False
"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled ( n ) <TAB> <TAB> if has_unknown_shape ( tiled_n ) : <TAB> <TAB> <TAB> if any ( c . key not in chunk_result for c in tiled_n . chunks ) : <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB> <TAB> <TAB> for node in ( n , tiled_n ) : <TAB> <TAB> <TAB> <TAB> node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB> <TAB> <TAB> tiled_n . _nsplits = new_nsplits ","if n . op in failed_ops : 
","if n in failed_ops :
",36.0,53.14,False
"def _read_filter ( self , data ) : <TAB> if data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . inner_sha . update ( data ) <TAB> <TAB> if self . expected_inner_md5sum : <TAB> <TAB> <TAB> self . inner_md5 . update ( data ) <TAB> return data ","if self . expected_inner_sha256 : 
","if self . expected_inner_sha :
",64.48,75.06,False
"def find_previous_editable ( self , * args ) : <TAB> if self . editw == 0 : <TAB> <TAB> if self . _active_page > 0 : <TAB> <TAB> <TAB> self . switch_page ( self . _active_page - 1 ) <TAB> if not self . editw == 0 : <TAB> <TAB> # remember that xrange does not return the 'last' value, <TAB> <TAB> # so go to -1, not 0! (fence post error in reverse) <TAB> <TAB> for n in range ( self . editw - 1 , - 1 , - 1 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . editw = n <TAB> <TAB> <TAB> <TAB> break ","if self . _widgets__ [ n ] . editable and not self . _widgets__ [ n ] . hidden : 
","if self . _data [ n ] . editable :
",50.99,15.43,False
"def _get_event_for_message ( self , message_id ) : <TAB> with self . event_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Event for message[ {} ] should have been created before accessing "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> message_id <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _events [ message_id ] ","if message_id not in self . _events : 
","if message_id not in self . _events :
",100.0,100.0,True
"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB> <TAB> if len ( t ) == 1 : <TAB> <TAB> <TAB> return t [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> for part in t : <TAB> <TAB> <TAB> <TAB> res = self . _get_deepest ( part ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None ","if res : 
","if res :
",78.12,0.0,False
"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> elif self . _chain_notify : <TAB> <TAB> <TAB> return self . _chain_notify <TAB> return None ","if action_node . notify : 
","if action_node . notify :
",100.0,100.0,True
"def __init__ ( self , centered = None , shape_params = ( ) ) : <TAB> assert centered is None or isinstance ( centered , ( float , torch . Tensor ) ) <TAB> assert isinstance ( shape_params , ( tuple , list ) ) <TAB> assert all ( isinstance ( name , str ) for name in shape_params ) <TAB> if is_validation_enabled ( ) : <TAB> <TAB> if isinstance ( centered , float ) : <TAB> <TAB> <TAB> assert 0 < = centered and centered < = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert ( 0 < = centered ) . all ( ) <TAB> <TAB> <TAB> assert ( centered < = 1 ) . all ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert centered is None <TAB> self . centered = centered <TAB> self . shape_params = shape_params ","elif isinstance ( centered , torch . Tensor ) : 
","elif isinstance ( centered , torch . Tensor ) :
",100.0,100.0,True
"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB> <TAB> squid_host = self . squid_hosts [ nickname ] <TAB> <TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB> <TAB> if fulldata is not None : <TAB> <TAB> <TAB> fulldata = fulldata . splitlines ( ) <TAB> <TAB> <TAB> for data in fulldata : <TAB> <TAB> <TAB> <TAB> matches = self . stat_pattern . match ( data ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . publish_counter ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> ) ","if matches : 
","if matches :
",78.12,0.0,False
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ","elif size < = 9 : 
","elif size < = 9 :
",100.0,100.0,True
"def wait_for_initial_conf ( self , timeout = 1.0 ) : <TAB> logger . info ( "" Waiting for initial configuration "" ) <TAB> cur_timeout = timeout <TAB> # Arbiter do not already set our have_conf param <TAB> while not self . new_conf and not self . interrupted : <TAB> <TAB> elapsed , _ , _ = self . handleRequests ( cur_timeout ) <TAB> <TAB> if elapsed : <TAB> <TAB> <TAB> cur_timeout - = elapsed <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> cur_timeout = timeout <TAB> <TAB> sys . stdout . write ( "" . "" ) <TAB> <TAB> sys . stdout . flush ( ) ","if cur_timeout > 0 : 
","if cur_timeout < = 0 :
",32.18,41.11,False
"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB> <TAB> self . querylist = [ ] <TAB> else : <TAB> <TAB> self . querylist = querylist <TAB> <TAB> for query in self . querylist : <TAB> <TAB> <TAB> if self . query_id == - 1 : <TAB> <TAB> <TAB> <TAB> self . query_id = query . query_id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" query in list must be same query_id "" ) ","if self . query_id != query . query_id : 
","if query . query_id != self . query_id :
",64.54,79.72,False
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> if matchSelf : <TAB> <TAB> <TAB> yield s <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> if s . siblingAbove is None : <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ","if recurseInAnon : 
","elif recurseAnon :
",30.14,0.0,False
"def get_default_params ( problem_type : str , penalty : str ) : <TAB> # TODO: get seed from seeds provider <TAB> if problem_type == REGRESSION : <TAB> <TAB> default_params = { "" C "" : None , "" random_state "" : 0 , "" fit_intercept "" : True } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> default_params [ "" solver "" ] = "" auto "" <TAB> else : <TAB> <TAB> default_params = { <TAB> <TAB> <TAB> "" C "" : None , <TAB> <TAB> <TAB> "" random_state "" : 0 , <TAB> <TAB> <TAB> "" solver "" : _get_solver ( problem_type ) , <TAB> <TAB> <TAB> "" n_jobs "" : - 1 , <TAB> <TAB> <TAB> "" fit_intercept "" : True , <TAB> <TAB> } <TAB> model_params = list ( default_params . keys ( ) ) <TAB> return model_params , default_params ","if penalty == L2 : 
","if penalty == "" auto "" :
",36.73,36.56,False
"def _UploadDirectory ( local_dir : str , gcs_bucket : storage . Bucket , gcs_dir : str ) : <TAB> """"""Upload the contents of a local directory to a GCS Bucket."""""" <TAB> for file_name in os . listdir ( local_dir ) : <TAB> <TAB> path = os . path . join ( local_dir , file_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . info ( "" Skipping  %s  as it ' s not a file. "" , path ) <TAB> <TAB> <TAB> continue <TAB> <TAB> logging . info ( "" Uploading:  %s "" , path ) <TAB> <TAB> gcs_blob = gcs_bucket . blob ( f "" { gcs_dir } / { file_name } "" ) <TAB> <TAB> gcs_blob . upload_from_filename ( path ) ","if not os . path . isfile ( path ) : 
","if not os . path . isfile ( path ) :
",100.0,100.0,True
"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB> <TAB> self . decode_query_ids ( trans , conditional . left ) <TAB> <TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB> <TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB> <TAB> if left_base in self . FIELDS : <TAB> <TAB> <TAB> field = self . FIELDS [ left_base ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> conditional . right = trans . security . decode_id ( conditional . right ) ","if field . id_decode : 
","if field . get ( "" primary_key "" ) == "" key "" :
",42.57,9.67,False
"def data_dir ( self ) - > Path : <TAB> try : <TAB> <TAB> from appdirs import user_data_dir <TAB> except ImportError : <TAB> <TAB> # linux <TAB> <TAB> path = Path . home ( ) / "" .local "" / "" share "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return path / "" dephell "" <TAB> <TAB> # mac os <TAB> <TAB> path = Path . home ( ) / "" Library "" / "" Application Support "" <TAB> <TAB> if path . exists ( ) : <TAB> <TAB> <TAB> return path / "" dephell "" <TAB> <TAB> self . pip_main ( [ "" install "" , "" appdirs "" ] ) <TAB> <TAB> from appdirs import user_data_dir <TAB> return Path ( user_data_dir ( "" dephell "" ) ) ","if path . exists ( ) : 
","if path . exists ( ) :
",100.0,100.0,True
"def setGameCard ( self , isGameCard = False ) : <TAB> if isGameCard : <TAB> <TAB> targetValue = 1 <TAB> else : <TAB> <TAB> targetValue = 0 <TAB> for nca in self : <TAB> <TAB> if isinstance ( nca , Nca ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> Print . info ( "" writing isGameCard for  %s ,  %d "" % ( str ( nca . _path ) , targetValue ) ) <TAB> <TAB> <TAB> nca . header . setIsGameCard ( targetValue ) ","if nca . header . getIsGameCard ( ) == targetValue : 
","if nca . header . IsGameCard ( targetValue ) :
",52.74,37.25,False
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","elif mode == "" key "" : 
","elif mode == "" end "" :
",74.63,59.46,False
"def register_aggregate_groups ( conn , * groups ) : <TAB> seen = set ( ) <TAB> for group in groups : <TAB> <TAB> klasses = AGGREGATE_COLLECTION [ group ] <TAB> <TAB> for klass in klasses : <TAB> <TAB> <TAB> name = getattr ( klass , "" name "" , klass . __name__ ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> seen . add ( name ) <TAB> <TAB> <TAB> <TAB> conn . create_aggregate ( name , - 1 , klass ) ","if name not in seen : 
","if name not in seen :
",100.0,100.0,True
"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 :<TAB> # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> if isinstance ( inputs [ 1 ] , int ) : <TAB> <TAB> <TAB> axis = int ( inputs [ 1 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> axis = inputs [ 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB> <TAB> keepdims = bool ( inputs [ 2 ] ) <TAB> return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims ) ","elif _is_int_seq ( inputs [ 1 ] ) : 
","elif isinstance ( inputs [ 1 ] , list ) :
",53.83,31.76,False
"def walks_generator ( ) : <TAB> if filelist is not None : <TAB> <TAB> bucket = [ ] <TAB> <TAB> for filename in filelist : <TAB> <TAB> <TAB> with io . open ( filename ) as inf : <TAB> <TAB> <TAB> <TAB> for line in inf : <TAB> <TAB> <TAB> <TAB> <TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB> <TAB> <TAB> <TAB> <TAB> bucket . append ( walk ) <TAB> <TAB> <TAB> <TAB> <TAB> if len ( bucket ) == batch_size : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield bucket <TAB> else : <TAB> <TAB> for _ in range ( epoch ) : <TAB> <TAB> <TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB> <TAB> <TAB> <TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB> <TAB> <TAB> <TAB> yield walks ","if len ( bucket ) : 
","if len ( bucket ) :
",100.0,100.0,True
"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> if resultset [ "" result "" ] : <TAB> <TAB> <TAB> <TAB> results [ "" num_passed_states "" ] + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results [ "" num_failed_states "" ] + = 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB> log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB> return results ","if isinstance ( resultset , dict ) and "" duration "" in resultset : 
","if state in ( "" pass "" , "" failed "" ) :
",29.79,4.81,False
"def _replicator_primary_device ( ) - > snt_replicator . Replicator : <TAB> # NOTE: The explicit device list is required since currently Replicator <TAB> # only considers CPU and GPU devices. This means on TPU by default we only <TAB> # mirror on the local CPU. <TAB> for device_type in ( "" TPU "" , "" GPU "" , "" CPU "" ) : <TAB> <TAB> devices = tf . config . experimental . list_logical_devices ( device_type = device_type ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> devices = [ d . name for d in devices ] <TAB> <TAB> <TAB> logging . info ( "" Replicating over  %s "" , devices ) <TAB> <TAB> <TAB> return snt_replicator . Replicator ( devices = devices ) <TAB> assert False , "" No TPU/GPU or CPU found "" ","if devices : 
","if len ( devices ) > 0 :
",29.65,7.27,False
"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB> <TAB> return [ ] <TAB> if not http . headers : <TAB> <TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance ( headers , dict ) : <TAB> <TAB> headers = headers . items ( ) <TAB> output = [ ] <TAB> for key , value in headers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse ( value ) <TAB> <TAB> if not ua : <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self . get_tag_from_ua ( ua ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> output . append ( result ) <TAB> return output ","if key != "" User-Agent "" : 
","if key . lower ( ) != "" content-type "" :
",36.05,18.53,False
"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB> <TAB> if not value : <TAB> <TAB> <TAB> return None <TAB> <TAB> elif not metadata . get ( "" nargs "" ) : <TAB> <TAB> <TAB> return quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value ","if not metadata . get ( "" nargs "" ) : 
","if metadata . get ( "" nargs "" ) :
",78.87,81.76,False
"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB> <TAB> # take action <TAB> <TAB> if self . action_input . selected_index == 0 :<TAB> # Cancel <TAB> <TAB> <TAB> self . back_to_parent ( ) <TAB> <TAB> elif self . action_input . selected_index == 1 :<TAB> # Apply <TAB> <TAB> <TAB> self . _apply_prefs ( ) <TAB> <TAB> <TAB> client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB> <TAB> elif self . action_input . selected_index == 2 :<TAB> # OK <TAB> <TAB> <TAB> self . _apply_prefs ( ) <TAB> <TAB> <TAB> self . back_to_parent ( ) ","elif self . action_input . selected_index == 2 : 
","elif self . action_input . selected_index == 1 :
",87.71,85.55,False
def logic ( ) : <TAB> if reset == 1 : <TAB> <TAB> lfsr . next = 1 <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # lfsr.next[24:1] = lfsr[23:0] <TAB> <TAB> <TAB> lfsr . next = lfsr << 1 <TAB> <TAB> <TAB> lfsr . next [ 0 ] = lfsr [ 23 ] ^ lfsr [ 22 ] ^ lfsr [ 21 ] ^ lfsr [ 16 ] ,"if enable : 
","if reset == 2 :
",30.19,9.65,False
"def action_delete ( self , request , attachments ) : <TAB> deleted_attachments = [ ] <TAB> desynced_posts = [ ] <TAB> for attachment in attachments : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> deleted_attachments . append ( attachment . pk ) <TAB> <TAB> <TAB> desynced_posts . append ( attachment . post_id ) <TAB> if desynced_posts : <TAB> <TAB> with transaction . atomic ( ) : <TAB> <TAB> <TAB> for post in Post . objects . filter ( id__in = desynced_posts ) : <TAB> <TAB> <TAB> <TAB> self . delete_from_cache ( post , deleted_attachments ) <TAB> for attachment in attachments : <TAB> <TAB> attachment . delete ( ) <TAB> message = _ ( "" Selected attachments have been deleted. "" ) <TAB> messages . success ( request , message ) ","if attachment . post : 
","if attachment . deleted :
",64.48,42.73,False
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> if index < 0 or index > = len ( self . features ) : <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> if feature : <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ","elif isinstance ( index , slice ) : 
","elif isinstance ( index , Index ) :
",79.9,59.46,False
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self . _pos == start : <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> if stop is not None and self . _pos > stop : <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( ) ","if self . _pos < start : 
","if self . _pos > = start :
",53.93,51.33,False
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f ","if "" meta-environment "" in root or "" cross-canadian "" in root : 
","if "" .py "" in root or "" .pyc "" in root :
",76.65,44.8,False
"def _load_windows_store_certs ( self , storename , purpose ) : <TAB> certs = bytearray ( ) <TAB> try : <TAB> <TAB> for cert , encoding , trust in enum_certificates ( storename ) : <TAB> <TAB> <TAB> # CA certs are never PKCS#7 encoded <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if trust is True or purpose . oid in trust : <TAB> <TAB> <TAB> <TAB> <TAB> certs . extend ( cert ) <TAB> except PermissionError : <TAB> <TAB> warnings . warn ( "" unable to enumerate Windows certificate store "" ) <TAB> if certs : <TAB> <TAB> self . load_verify_locations ( cadata = certs ) <TAB> return certs ","if encoding == "" x509_asn "" : 
","if encoding == "" PKCS#7 "" :
",74.63,45.18,False
"def test_tokenizer_identifier_with_correct_config ( self ) : <TAB> for tokenizer_class in [ BertTokenizer , BertTokenizerFast , AutoTokenizer ] : <TAB> <TAB> tokenizer = tokenizer_class . from_pretrained ( "" wietsedv/bert-base-dutch-cased "" ) <TAB> <TAB> self . assertIsInstance ( tokenizer , ( BertTokenizer , BertTokenizerFast ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( tokenizer . basic_tokenizer . do_lower_case , False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( tokenizer . do_lower_case , False ) <TAB> <TAB> self . assertEqual ( tokenizer . model_max_length , 512 ) ","if isinstance ( tokenizer , BertTokenizer ) : 
","if tokenizer_class is AutoTokenizer :
",26.86,7.49,False
"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB> <TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB> <TAB> if path_id is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> self . lock . acquire ( ) <TAB> <TAB> self . modules [ path_id ] = module <TAB> <TAB> self . lock . release ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB> <TAB> <TAB> self . _relations [ path_id ] = [ ] <TAB> <TAB> <TAB> for package in resolution : <TAB> <TAB> <TAB> <TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB> <TAB> <TAB> self . queue_send . put ( ( path_id , module , False , resolution ) ) ","if resolve : 
","if resolve :
",78.12,0.0,False
"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB> <TAB> for base in bases : <TAB> <TAB> <TAB> if hasattr ( base , "" trace "" ) : <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile : <TAB> <TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB> <TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB> <TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs ) ","if hasattr ( base , "" garbage "" ) : 
","if hasattr ( base , "" garbage "" ) :
",100.0,100.0,True
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_owner_ : <TAB> <TAB> res + = prefix + ( "" owner:  %s \n "" % self . DebugFormatString ( self . owner_ ) ) <TAB> cnt = 0 <TAB> for e in self . entries_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" entries %s  < \n "" % elm ) <TAB> <TAB> res + = e . __str__ ( prefix + ""<TAB> "" , printElemNumber ) <TAB> <TAB> res + = prefix + "" > \n "" <TAB> <TAB> cnt + = 1 <TAB> return res ","if printElemNumber : 
","if printElemNumber :
",78.12,0.0,False
"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB> <TAB> if escaped : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> <TAB> elif c == "" \\ "" : <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" "" . join ( buf ) <TAB> <TAB> else : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) ) ","elif c == "" > "" : 
","elif c == "" . "" :
",74.63,59.46,False
"def get_batches ( train_nodes , train_labels , batch_size = 64 , shuffle = True ) : <TAB> if shuffle : <TAB> <TAB> random . shuffle ( train_nodes ) <TAB> total = train_nodes . shape [ 0 ] <TAB> for i in range ( 0 , total , batch_size ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cur_nodes = train_nodes [ i : i + batch_size ] <TAB> <TAB> <TAB> cur_labels = train_labels [ cur_nodes ] <TAB> <TAB> <TAB> yield cur_nodes , cur_labels ","if i + batch_size < = total : 
","if i + batch_size < = total :
",100.0,100.0,True
"def _get_all_info_lines ( data ) : <TAB> infos = [ ] <TAB> for row in data : <TAB> <TAB> splitrow = row . split ( ) <TAB> <TAB> if len ( splitrow ) > 0 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> infos . append ( "" "" . join ( splitrow [ 1 : ] ) ) <TAB> return infos ","if splitrow [ 0 ] == "" INFO: "" : 
","if splitrow [ 0 ] == "" INFO "" :
",85.49,77.72,False
"def _validate_client_public_key ( self , username , key_data ) : <TAB> """"""Validate a client public key for the specified user"""""" <TAB> try : <TAB> <TAB> key = decode_ssh_public_key ( key_data ) <TAB> except KeyImportError : <TAB> <TAB> return None <TAB> options = None <TAB> if self . _client_keys : <TAB> <TAB> options = self . _client_keys . validate ( key , self . _peer_addr ) <TAB> if options is None : <TAB> <TAB> result = self . _owner . validate_public_key ( username , key ) <TAB> <TAB> if asyncio . iscoroutine ( result ) : <TAB> <TAB> <TAB> result = yield from result <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> options = { } <TAB> self . _key_options = options <TAB> return key ","if not result : 
","if result is None :
",29.25,14.06,False
"def attach_related_versions ( addons , addon_dict = None ) : <TAB> if addon_dict is None : <TAB> <TAB> addon_dict = { addon . id : addon for addon in addons } <TAB> all_ids = set ( filter ( None , ( addon . _current_version_id for addon in addons ) ) ) <TAB> versions = list ( Version . objects . filter ( id__in = all_ids ) . order_by ( ) ) <TAB> for version in versions : <TAB> <TAB> try : <TAB> <TAB> <TAB> addon = addon_dict [ version . addon_id ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> log . info ( "" Version  %s  has an invalid add-on id. "" % version . id ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> addon . _current_version = version <TAB> <TAB> version . addon = addon ","if addon . _current_version_id == version . id : 
","if not addon . _current_version :
",38.19,32.41,False
"def move_view ( obj , evt ) : <TAB> position = obj . GetCurrentCursorPosition ( ) <TAB> for other_axis , axis_number in self . _axis_names . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> ipw3d = getattr ( self , "" ipw_3d_ %s "" % other_axis ) <TAB> <TAB> ipw3d . ipw . slice_position = position [ axis_number ] ","if other_axis == axis_name : 
","if other_axis == "" forward "" :
",36.73,53.73,False
"def func_wrapper ( * args , * * kwargs ) : <TAB> warnings . simplefilter ( "" always "" , DeprecationWarning )<TAB> # turn off filter <TAB> for old , new in arg_mapping . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> f "" Keyword argument  ' { old } '  has been  "" <TAB> <TAB> <TAB> <TAB> f "" deprecated in favour of  ' { new } ' .  "" <TAB> <TAB> <TAB> <TAB> f "" ' { old } '  will be removed in a future version. "" , <TAB> <TAB> <TAB> <TAB> category = DeprecationWarning , <TAB> <TAB> <TAB> <TAB> stacklevel = 2 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> val = kwargs . pop ( old ) <TAB> <TAB> <TAB> kwargs [ new ] = val <TAB> # reset filter <TAB> warnings . simplefilter ( "" default "" , DeprecationWarning ) <TAB> return func ( * args , * * kwargs ) ","if old in kwargs : 
","if old in kwargs :
",100.0,100.0,True
"def inner_connection_checker ( self , * args , * * kwargs ) : <TAB> LOG . debug ( "" in _connection_checker "" ) <TAB> for attempts in range ( 5 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( self , * args , * * kwargs ) <TAB> <TAB> except exception . VolumeBackendAPIException as e : <TAB> <TAB> <TAB> pattern = re . compile ( r "" .*Session id expired$ "" ) <TAB> <TAB> <TAB> matches = pattern . match ( six . text_type ( e ) ) <TAB> <TAB> <TAB> if matches : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> LOG . debug ( "" Session might have expired. "" ""  Trying to relogin "" ) <TAB> <TAB> <TAB> <TAB> <TAB> self . _login ( ) <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> LOG . error ( "" Re-throwing Exception  %s "" , e ) <TAB> <TAB> <TAB> raise ","if attempts < 4 : 
","if matches [ 1 ] [ 0 ] . isdigit ( ) :
",27.28,3.67,False
"def set ( self , pcount ) : <TAB> """"""Set channel prefetch_count setting."""""" <TAB> if pcount != self . prev : <TAB> <TAB> new_value = pcount <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" QoS: Disabled: prefetch_count exceeds  %r "" , PREFETCH_COUNT_MAX <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> new_value = 0 <TAB> <TAB> logger . debug ( "" basic.qos: prefetch_count-> %s "" , new_value ) <TAB> <TAB> self . callback ( prefetch_count = new_value ) <TAB> <TAB> self . prev = pcount <TAB> return pcount ","if pcount > PREFETCH_COUNT_MAX : 
","if PREFETCH_COUNT_MAX > = new_value :
",28.39,35.66,False
"def _build_gcs_object_key ( self , key ) : <TAB> if self . platform_specific_separator : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gcs_object_key = os . path . join ( <TAB> <TAB> <TAB> <TAB> self . prefix , self . _convert_key_to_filepath ( key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> else : <TAB> <TAB> if self . prefix : <TAB> <TAB> <TAB> gcs_object_key = "" / "" . join ( ( self . prefix , self . _convert_key_to_filepath ( key ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gcs_object_key = self . _convert_key_to_filepath ( key ) <TAB> return gcs_object_key ","if self . prefix : 
","if self . prefix :
",100.0,100.0,True
"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> if hasattr ( a , name ) : <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB> <TAB> if name not in skip : <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> if hasattr ( a , name ) : <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . unop_test ( a , res , expr , name ) ","if name not in skip : 
","if name not in skip :
",100.0,100.0,True
def isCurveMonotonic ( set_ ) : <TAB> for i in range ( len ( set_ ) - 1 ) : <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> # if set_[i][1] > set_[i + 1][1]: <TAB> <TAB> if set_ [ i ] [ 1 ] > = set_ [ i + 1 ] [ 1 ] : <TAB> <TAB> <TAB> # ==== added by zli ======= <TAB> <TAB> <TAB> return False <TAB> return True ,"if set_ [ i ] [ 0 ] > = set_ [ i + 1 ] [ 0 ] : 
","if set_ [ i ] [ 0 ] > = set_ [ i + 1 ] [ 0 ] :
",100.0,100.0,True
"def show_topics ( ) : <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os . listdir ( pp ) <TAB> <TAB> for pn in content : <TAB> <TAB> <TAB> if "" . "" in pn : <TAB> <TAB> <TAB> <TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print ( name ) ","if not os . path . isdir ( pp ) : 
","if not os . path . isdir ( pp ) :
",100.0,100.0,True
"def test_send_error ( self ) : <TAB> allow_transfer_encoding_codes = ( 205 , 304 ) <TAB> for code in ( 101 , 102 , 204 , 205 , 304 ) : <TAB> <TAB> self . con . request ( "" SEND_ERROR "" , "" / {} "" . format ( code ) ) <TAB> <TAB> res = self . con . getresponse ( ) <TAB> <TAB> self . assertEqual ( code , res . status ) <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Content-Length "" ) ) <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Content-Type "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( None , res . getheader ( "" Transfer-Encoding "" ) ) <TAB> <TAB> data = res . read ( ) <TAB> <TAB> self . assertEqual ( b "" "" , data ) ","if code not in allow_transfer_encoding_codes : 
","if code in allow_transfer_encoding_codes :
",56.72,77.72,False
"def _length_hint ( obj ) : <TAB> """"""Returns the length hint of an object."""""" <TAB> try : <TAB> <TAB> return len ( obj ) <TAB> except ( AttributeError , TypeError ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> get_hint = type ( obj ) . __length_hint__ <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> return None <TAB> <TAB> try : <TAB> <TAB> <TAB> hint = get_hint ( obj ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> return None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> return hint ","if hint is NotImplemented or not isinstance ( hint , int_types ) or hint < 0 : 
","if not hint :
",25.55,0.53,False
"def _rmtree ( self , path ) : <TAB> # Essentially a stripped down version of shutil.rmtree.  We can't <TAB> # use globals because they may be None'ed out at shutdown. <TAB> for name in self . _listdir ( path ) : <TAB> <TAB> fullname = self . _path_join ( path , name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> isdir = self . _isdir ( fullname ) <TAB> <TAB> except self . _os_error : <TAB> <TAB> <TAB> isdir = False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _rmtree ( fullname ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . _remove ( fullname ) <TAB> <TAB> <TAB> except self . _os_error : <TAB> <TAB> <TAB> <TAB> pass <TAB> try : <TAB> <TAB> self . _rmdir ( path ) <TAB> except self . _os_error : <TAB> <TAB> pass ","if isdir : 
","if isdir :
",78.12,0.0,False
"def get_sources ( self , sources = None ) : <TAB> """"""Returns all sources from this provider."""""" <TAB> self . _load ( ) <TAB> if sources is None : <TAB> <TAB> sources = list ( self . data . keys ( ) ) <TAB> elif not isinstance ( sources , ( list , tuple ) ) : <TAB> <TAB> sources = [ sources ] <TAB> for source in sources : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Invalid data key:  {} . Valid keys are:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> source , "" ,  "" . join ( str ( k ) for k in self . data ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return { k : self . data [ k ] for k in sources } ","if source not in self . data : 
","if source not in self . data :
",100.0,100.0,True
"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB> <TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB> <TAB> if short_has_arg ( opt , shortopts ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not args : <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB> <TAB> <TAB> <TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB> <TAB> <TAB> optarg , optstring = optstring , "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> optarg = "" "" <TAB> <TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args ","if optstring == "" "" : 
","if optstring == "" "" :
",100.0,100.0,True
"def _sanitize_dict ( self , config_dict , allow_val_change = None , ignore_keys : set = None ) : <TAB> sanitized = { } <TAB> for k , v in six . iteritems ( config_dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> k , v = self . _sanitize ( k , v , allow_val_change ) <TAB> <TAB> sanitized [ k ] = v <TAB> return sanitized ","if ignore_keys and k in ignore_keys : 
","if ignore_keys and k in ignore_keys :
",100.0,100.0,True
def x ( data ) : <TAB> count = 0 <TAB> while count < 10 : <TAB> <TAB> data . start_example ( SOME_LABEL ) <TAB> <TAB> b = data . draw_bits ( 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> data . stop_example ( discard = not b ) <TAB> data . mark_interesting ( ) ,"if b : 
","if b :
",78.12,0.0,False
"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB> <TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB> <TAB> prompt = "" (R/F)>  "" <TAB> <TAB> answer = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> answer = raw_input ( prompt ) <TAB> <TAB> except NameError : <TAB> <TAB> <TAB> answer = input ( prompt ) <TAB> <TAB> if answer . upper ( ) == "" F "" : <TAB> <TAB> <TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( "" Resuming previous scan "" ) <TAB> <TAB> <TAB> config . resume = True <TAB> return config . resume ","elif answer . upper ( ) == "" R "" : 
","elif answer . upper ( ) == "" R "" :
",100.0,100.0,True
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> elif isinstance ( in_arrays , dict ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> if self . _progress_hook : <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results ","if isinstance ( in_arrays , tuple ) : 
","if isinstance ( in_arrays , list ) :
",79.9,70.71,False
"def _send_until_done ( self , data ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . connection . send ( data ) <TAB> <TAB> except OpenSSL . SSL . WantWriteError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise timeout ( ) <TAB> <TAB> <TAB> continue <TAB> <TAB> except OpenSSL . SSL . SysCallError as e : <TAB> <TAB> <TAB> raise SocketError ( str ( e ) ) ","if not util . wait_for_write ( self . socket , self . socket . gettimeout ( ) ) : 
","if self . timeout :
",32.72,0.69,False
"def _read_jtl_chunk ( self , jtl ) : <TAB> data = jtl . read ( 1024 * 1024 * 10 ) <TAB> if data : <TAB> <TAB> parts = data . rsplit ( "" \n "" , 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ready_chunk = self . buffer + parts [ 0 ] + "" \n "" <TAB> <TAB> <TAB> self . buffer = parts [ 1 ] <TAB> <TAB> <TAB> df = string_to_df ( ready_chunk ) <TAB> <TAB> <TAB> self . stat_queue . put ( df ) <TAB> <TAB> <TAB> return df <TAB> <TAB> else : <TAB> <TAB> <TAB> self . buffer + = parts [ 0 ] <TAB> else : <TAB> <TAB> if self . jmeter_finished : <TAB> <TAB> <TAB> self . agg_finished = True <TAB> <TAB> jtl . readline ( ) <TAB> return None ","if len ( parts ) > 1 : 
","if len ( parts ) > 1 :
",100.0,100.0,True
"def __new__ ( mcl , classname , bases , dictionary ) : <TAB> slots = list ( dictionary . get ( "" __slots__ "" , [ ] ) ) <TAB> for getter_name in [ key for key in dictionary if key . startswith ( "" get_ "" ) ] : <TAB> <TAB> name = getter_name <TAB> <TAB> slots . append ( "" __ "" + name ) <TAB> <TAB> getter = dictionary . pop ( getter_name ) <TAB> <TAB> setter = dictionary . get ( setter_name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del dictionary [ setter_name ] <TAB> <TAB> dictionary [ name ] = property ( getter . setter ) <TAB> <TAB> dictionary [ "" __slots__ "" ] = tuple ( slots ) <TAB> <TAB> return super ( ) . __new__ ( mcl , classname , bases , dictionary ) ","if setter is not None and isinstance ( setter , collections . Callable ) : 
","if getter is None or setter is None :
",29.91,6.16,False
"def tex_coords ( self ) : <TAB> """"""Array of texture coordinate data."""""" <TAB> if "" multi_tex_coords "" not in self . domain . attribute_names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> domain = self . domain <TAB> <TAB> <TAB> attribute = domain . attribute_names [ "" tex_coords "" ] <TAB> <TAB> <TAB> self . _tex_coords_cache = attribute . get_region ( <TAB> <TAB> <TAB> <TAB> attribute . buffer , self . start , self . count <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _tex_coords_cache_version = domain . _version <TAB> <TAB> region = self . _tex_coords_cache <TAB> <TAB> region . invalidate ( ) <TAB> <TAB> return region . array <TAB> else : <TAB> <TAB> return None ","if self . _tex_coords_cache_version != self . domain . _version : 
","if self . _tex_coords_cache is None :
",38.57,37.44,False
"def index ( self , sub , start = 0 ) : <TAB> """"""Returns the index of the closing bracket"""""" <TAB> br = "" ([ { < "" [ "" )]}> "" . index ( sub ) ] <TAB> count = 0 <TAB> for i in range ( start , len ( self . string ) ) : <TAB> <TAB> char = self . string [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> elif char == sub : <TAB> <TAB> <TAB> if count > 0 : <TAB> <TAB> <TAB> <TAB> count - = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return i <TAB> err = "" Closing bracket  {!r}  missing in string  {!r} "" . format ( <TAB> <TAB> sub , "" "" . join ( self . original ) <TAB> ) <TAB> raise ParseError ( err ) ","if char == br : 
","if char in br :
",58.14,24.74,False
"def test_createFile ( self ) : <TAB> text = "" This is a test! "" <TAB> path = tempfile . mktemp ( ) <TAB> try : <TAB> <TAB> koDoc = self . _koDocFromPath ( path , load = False ) <TAB> <TAB> koDoc . buffer = text <TAB> <TAB> koDoc . save ( 0 ) <TAB> <TAB> del koDoc <TAB> <TAB> koDoc2 = self . _koDocFromPath ( path ) <TAB> <TAB> assert koDoc2 . buffer == text <TAB> finally : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . unlink ( path )<TAB> # clean up ","if os . path . exists ( path ) : 
","if os . path . exists ( path ) :
",100.0,100.0,True
"def __editScopeHasEdit ( self , attributeHistory ) : <TAB> with attributeHistory . context : <TAB> <TAB> tweak = GafferScene . EditScopeAlgo . acquireParameterEdit ( <TAB> <TAB> <TAB> attributeHistory . scene . node ( ) , <TAB> <TAB> <TAB> attributeHistory . context [ "" scene:path "" ] , <TAB> <TAB> <TAB> attributeHistory . attributeName , <TAB> <TAB> <TAB> IECoreScene . ShaderNetwork . Parameter ( "" "" , self . __parameter ) , <TAB> <TAB> <TAB> createIfNecessary = False , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> return tweak [ "" enabled "" ] . getValue ( ) ","if tweak is None : 
","if tweak is None :
",100.0,100.0,True
"def mail_migrator ( app , schema_editor ) : <TAB> Event_SettingsStore = app . get_model ( "" pretixbase "" , "" Event_SettingsStore "" ) <TAB> for ss in Event_SettingsStore . objects . filter ( <TAB> <TAB> key__in = [ <TAB> <TAB> <TAB> "" mail_text_order_approved "" , <TAB> <TAB> <TAB> "" mail_text_order_placed "" , <TAB> <TAB> <TAB> "" mail_text_order_placed_require_approval "" , <TAB> <TAB> ] <TAB> ) : <TAB> <TAB> chgd = ss . value . replace ( "" {date} "" , "" {expire_date} "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ss . value = chgd <TAB> <TAB> <TAB> ss . save ( ) <TAB> <TAB> <TAB> cache . delete ( "" hierarkey_ {} _ {} "" . format ( "" event "" , ss . object_id ) ) ","if chgd != ss . value : 
","if chgd != ss . value :
",100.0,100.0,True
"def __get_limits ( self ) : <TAB> dimension = len ( self . __tree . get_root ( ) . data ) <TAB> nodes = self . __get_all_nodes ( ) <TAB> max , min = [ float ( "" -inf "" ) ] * dimension , [ float ( "" +inf "" ) ] * dimension <TAB> for node in nodes : <TAB> <TAB> for d in range ( dimension ) : <TAB> <TAB> <TAB> if max [ d ] < node . data [ d ] : <TAB> <TAB> <TAB> <TAB> max [ d ] = node . data [ d ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> min [ d ] = node . data [ d ] <TAB> return min , max ","if min [ d ] > node . data [ d ] : 
","if min [ d ] > node . data [ d ] :
",100.0,100.0,True
"def get_complete_position ( self , context : UserContext ) - > int : <TAB> # Check member prefix pattern. <TAB> for prefix_pattern in convert2list ( <TAB> <TAB> self . get_filetype_var ( context [ "" filetype "" ] , "" prefix_patterns "" ) <TAB> ) : <TAB> <TAB> m = re . search ( self . _object_pattern + prefix_pattern + r "" \ w*$ "" , context [ "" input "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . _prefix = re . sub ( r "" \ w*$ "" , "" "" , m . group ( 0 ) ) <TAB> <TAB> m = re . search ( r "" \ w*$ "" , context [ "" input "" ] ) <TAB> <TAB> if m : <TAB> <TAB> <TAB> return m . start ( ) <TAB> return - 1 ","if m is None or prefix_pattern == "" "" : 
","if not m :
",26.27,2.22,False
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> if curses : <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False ","elif colorama : 
","elif colorama :
",78.12,0.0,False
"def setLabelColumnWidth ( self , panel , width ) : <TAB> for child in panel . GetChildren ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size = child . GetSize ( ) <TAB> <TAB> <TAB> size [ 0 ] = width <TAB> <TAB> <TAB> child . SetBestSize ( size ) ","if isinstance ( child , wx . lib . stattext . GenStaticText ) : 
","if child . GetKind ( ) == "" label "" :
",29.73,4.49,False
"def update ( self , other ) : <TAB> if other . M is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . items . update ( other . items ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for i in other . items : <TAB> <TAB> <TAB> <TAB> self . add ( i ) <TAB> <TAB> return <TAB> if self . M is None : <TAB> <TAB> self . convert ( ) <TAB> self . M = array . array ( "" B "" , list ( map ( max , list ( zip ( self . M , other . M ) ) ) ) ) ","if self . M is None : 
","if len ( self . items ) != len ( other . items ) :
",34.01,5.82,False
"def on_end_epoch ( self , state ) : <TAB> if self . write_epoch_metrics : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . writer . add_text ( <TAB> <TAB> <TAB> <TAB> "" epoch "" , <TAB> <TAB> <TAB> <TAB> "" <h4>Epoch  {} </h4> "" . format ( state [ torchbearer . EPOCH ] ) <TAB> <TAB> <TAB> <TAB> + self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB> <TAB> <TAB> <TAB> 1 , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . writer . add_text ( <TAB> <TAB> <TAB> <TAB> "" epoch "" , <TAB> <TAB> <TAB> <TAB> self . table_formatter ( str ( state [ torchbearer . METRICS ] ) ) , <TAB> <TAB> <TAB> <TAB> state [ torchbearer . EPOCH ] , <TAB> <TAB> <TAB> ) ","if self . visdom : 
","if state [ torchbearer . EPOCH ] :
",36.13,7.27,False
"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif e . get ( "" event "" ) == ActionExecuted . type_name : <TAB> <TAB> <TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False ","if e . get ( "" event "" ) == UserUttered . type_name : 
","if e . get ( "" event "" ) == ActionExecuted . type_name :
",89.21,82.82,False
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret ","if port . port_no == in_port : 
","if in_port is not None and in_port != nw_id_ :
",26.89,10.22,False
"def next_month ( billing_cycle_anchor : datetime , dt : datetime ) - > datetime : <TAB> estimated_months = round ( ( dt - billing_cycle_anchor ) . days * 12.0 / 365 ) <TAB> for months in range ( max ( estimated_months - 1 , 0 ) , estimated_months + 2 ) : <TAB> <TAB> proposed_next_month = add_months ( billing_cycle_anchor , months ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return proposed_next_month <TAB> raise AssertionError ( <TAB> <TAB> "" Something wrong in next_month calculation with  "" <TAB> <TAB> f "" billing_cycle_anchor:  { billing_cycle_anchor } , dt:  { dt } "" <TAB> ) ","if 20 < ( proposed_next_month - dt ) . days < 40 : 
","if proposed_next_month :
",25.72,16.03,False
"def wait_complete ( self ) : <TAB> """"""Wait for futures complete done."""""" <TAB> for future in concurrent . futures . as_completed ( self . _futures . keys ( ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> error = future . exception ( ) <TAB> <TAB> except concurrent . futures . CancelledError : <TAB> <TAB> <TAB> break <TAB> <TAB> name = self . _futures [ future ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> err_msg = ' Extracting  "" {0} "" , got:  {1} ' . format ( name , error ) <TAB> <TAB> <TAB> logger . error ( err_msg ) ","if error is not None : 
","if name :
",27.4,0.0,False
"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB> <TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB> <TAB> if issubclass ( target , mapperlib . Mapper ) : <TAB> <TAB> <TAB> return target <TAB> <TAB> else : <TAB> <TAB> <TAB> mapper = _mapper_or_none ( target ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB> <TAB> return target ","if mapper is not None : 
","if mapper :
",29.58,0.0,False
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> elif isinstance ( arg , ( int , float ) ) : <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> elif isinstance ( arg , str ) : <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( ) ","if isinstance ( arg , bool ) : 
","if isinstance ( arg , ( int , float ) ) :
",49.15,36.46,False
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> if isinstance ( test , unittest . TestSuite ) : <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if support . match_test ( test ) : <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) ) ","elif isinstance ( test , unittest . TestCase ) : 
","elif isinstance ( test , unittest . TestCase ) :
",100.0,100.0,True
def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB> <TAB> if page . relations . disambiguation_links is not None : <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ) ,"if page . relations . disambiguation_links_norm is not None : 
","if page . relations . disambiguation_links_norm is not None :
",100.0,100.0,True
"def test_decode_invalid ( self ) : <TAB> testcases = [ <TAB> <TAB> ( b "" xn--w& "" , "" strict "" , UnicodeError ( ) ) , <TAB> <TAB> ( b "" xn--w& "" , "" ignore "" , "" xn- "" ) , <TAB> ] <TAB> for puny , errors , expected in testcases : <TAB> <TAB> with self . subTest ( puny = puny , errors = errors ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertRaises ( UnicodeError , puny . decode , "" punycode "" , errors ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( puny . decode ( "" punycode "" , errors ) , expected ) ","if isinstance ( expected , Exception ) : 
","if isinstance ( puny , UnicodeError ) :
",59.17,27.05,False
"def find_globs ( walker , patterns , matches ) : <TAB> for root , dirs , files in walker : <TAB> <TAB> for d in dirs : <TAB> <TAB> <TAB> d = join ( root , d ) <TAB> <TAB> <TAB> for pattern in patterns : <TAB> <TAB> <TAB> <TAB> for p in Path ( d ) . glob ( pattern ) : <TAB> <TAB> <TAB> <TAB> <TAB> matches . add ( str ( p ) ) <TAB> <TAB> sub_files = set ( ) <TAB> <TAB> for p in matches : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> <TAB> <TAB> sub_files . add ( join ( root , f ) ) <TAB> <TAB> matches . update ( sub_files ) ","if root . startswith ( p ) : 
","if p . is_file ( ) :
",33.98,12.55,False
"def parse_stack_trace ( self , it , line ) : <TAB> """"""Iterate over lines and parse stack traces."""""" <TAB> events = [ ] <TAB> stack_traces = [ ] <TAB> while self . stack_trace_re . match ( line ) : <TAB> <TAB> event = self . parse_stack_trace_line ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> events . append ( event ) <TAB> <TAB> stack_traces . append ( line ) <TAB> <TAB> line = get_next ( it ) <TAB> events . reverse ( ) <TAB> return stack_traces , events , line ","if event : 
","if event :
",78.12,0.0,False
"def process ( self ) : <TAB> """"""Do processing necessary, storing result in feature."""""" <TAB> summation = 0<TAB> # count of all <TAB> histo = self . data [ "" flat.notes.quarterLengthHistogram "" ] <TAB> if not histo : <TAB> <TAB> raise NativeFeatureException ( "" input lacks notes "" ) <TAB> maxKey = 0<TAB> # max found for any one key <TAB> for key in histo : <TAB> <TAB> # all defined keys should be greater than zero, but just in case <TAB> <TAB> if histo [ key ] > 0 : <TAB> <TAB> <TAB> summation + = histo [ key ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> maxKey = histo [ key ] <TAB> self . feature . vector [ 0 ] = maxKey / summation ","if histo [ key ] > = maxKey : 
","if histo [ key ] > maxKey :
",63.55,67.53,False
"def load_resource ( name ) : <TAB> """"""return file contents for files within the package root folder"""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return sublime . load_resource ( "" Packages/Markdown Preview/ {0} "" . format ( name ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = os . path . join ( <TAB> <TAB> <TAB> <TAB> sublime . packages_path ( ) , INSTALLED_DIRECTORY , os . path . normpath ( name ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return load_utf8 ( filename ) <TAB> except : <TAB> <TAB> print ( "" Error while load_resource( ' %s ' ) "" % name ) <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> return "" "" ","if is_ST3 ( ) : 
","if name . endswith ( "" .markdown "" ) :
",29.8,8.91,False
"def get_password ( self , service , repo_url ) : <TAB> if self . is_unlocked : <TAB> <TAB> asyncio . set_event_loop ( asyncio . new_event_loop ( ) ) <TAB> <TAB> collection = secretstorage . get_default_collection ( self . connection ) <TAB> <TAB> attributes = { "" application "" : "" Vorta "" , "" service "" : service , "" repo_url "" : repo_url } <TAB> <TAB> items = list ( collection . search_items ( attributes ) ) <TAB> <TAB> logger . debug ( "" Found  %i  passwords matching repo URL. "" , len ( items ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return items [ 0 ] . get_secret ( ) . decode ( "" utf-8 "" ) <TAB> return None ","if len ( items ) > 0 : 
","if len ( items ) == 1 :
",77.42,46.71,False
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> if fname == "" output "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" :<TAB> # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> get_dir ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res . append ( p ) <TAB> return res ","if os . path . isdir ( p ) : 
","if os . path . isdir ( p ) :
",100.0,100.0,True
"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB> <TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if nic not in out : <TAB> <TAB> <TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic ) ","if "" pseudo-interface "" in nic . replace ( "" "" , "" - "" ) . lower ( ) : 
","if nic == "" all "" :
",31.78,1.63,False
"def vexop_to_simop ( op , extended = True , fp = True ) : <TAB> res = operations . get ( op ) <TAB> if res is None and extended : <TAB> <TAB> attrs = op_attrs ( op ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB> <TAB> res = SimIROp ( op , * * attrs ) <TAB> if res is None : <TAB> <TAB> raise UnsupportedIROpError ( "" Operation not implemented "" ) <TAB> if res . _float and not fp : <TAB> <TAB> raise UnsupportedIROpError ( "" Floating point support disabled "" ) <TAB> return res ","if attrs is None : 
","if attrs is None :
",100.0,100.0,True
"def rule_builder_add_value ( self , value , screenshot_name = None ) : <TAB> rule_builder = self . components . rule_builder <TAB> rule_builder . menu_button_column . wait_for_and_click ( ) <TAB> with self . rule_builder_rule_editor ( "" add-column-value "" ) as editor_element : <TAB> <TAB> filter_input = editor_element . find_element_by_css_selector ( "" input[type= ' text ' ] "" ) <TAB> <TAB> filter_input . clear ( ) <TAB> <TAB> filter_input . send_keys ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . screenshot ( screenshot_name ) ","if screenshot_name : 
","if screenshot_name :
",78.12,100.0,True
"def make_open_socket ( self ) : <TAB> s = socket . socket ( ) <TAB> try : <TAB> <TAB> s . bind ( DEFAULT_BIND_ADDR_TUPLE ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Windows and linux (with psutil) doesn't show as open until <TAB> <TAB> <TAB> # we call listen (linux with lsof accepts either) <TAB> <TAB> <TAB> s . listen ( 1 ) <TAB> <TAB> self . assert_open ( s , s . fileno ( ) ) <TAB> except : <TAB> <TAB> s . close ( ) <TAB> <TAB> s = None <TAB> <TAB> raise <TAB> return s ","if WIN or greentest . LINUX : 
","if sys . platform == "" win32 "" :
",33.15,5.52,False
"def handle_ray_task_error ( e ) : <TAB> for s in e . traceback_str . split ( "" \n "" ) [ : : - 1 ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> raise getattr ( builtins , s . split ( "" : "" ) [ 0 ] ) ( "" "" . join ( s . split ( "" : "" ) [ 1 : ] ) ) <TAB> <TAB> <TAB> except AttributeError as att_err : <TAB> <TAB> <TAB> <TAB> if "" module "" in str ( att_err ) and builtins . __name__ in str ( att_err ) : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise att_err <TAB> raise e ","if "" Error "" in s or "" Exception "" in s : 
","if s . startswith ( "" ERROR: "" ) :
",33.28,4.67,False
"def compare_multiple_events ( i , expected_results , actual_results ) : <TAB> events_in_a_row = [ ] <TAB> j = i <TAB> while j < len ( expected_results ) and isinstance ( <TAB> <TAB> actual_results [ j ] , actual_results [ i ] . __class__ <TAB> ) : <TAB> <TAB> events_in_a_row . append ( actual_results [ j ] ) <TAB> <TAB> j + = 1 <TAB> message = "" "" <TAB> for event in events_in_a_row : <TAB> <TAB> for k in range ( i , j ) : <TAB> <TAB> <TAB> passed , message = compare_events ( expected_results [ k ] , event ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> expected_results [ k ] = None <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> return i , False , message <TAB> return j , True , "" "" ","if passed : 
","if not passed :
",36.35,35.36,False
"def ListSubscriptions ( self , params ) : <TAB> queryreturn = sqlQuery ( """""" SELECT label, address, enabled FROM subscriptions """""" ) <TAB> data = ' { "" subscriptions "" :[ ' <TAB> for row in queryreturn : <TAB> <TAB> label , address , enabled = row <TAB> <TAB> label = shared . fixPotentiallyInvalidUTF8Data ( label ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data + = "" , "" <TAB> <TAB> data + = json . dumps ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" label "" : label . encode ( "" base64 "" ) , <TAB> <TAB> <TAB> <TAB> "" address "" : address , <TAB> <TAB> <TAB> <TAB> "" enabled "" : enabled == 1 , <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> indent = 4 , <TAB> <TAB> <TAB> separators = ( "" , "" , "" :  "" ) , <TAB> <TAB> ) <TAB> data + = "" ]} "" <TAB> return data ","if len ( data ) > 20 : 
","if data :
",26.73,0.0,False
"def compile ( self , args ) : <TAB> compiled_args = { } <TAB> for key , value in six . iteritems ( args ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> compiled_args [ key ] = str ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> compiled_args [ key ] = sjson_dumps ( value ) <TAB> return self . _minified_code % compiled_args ","if key in self . clean_args : 
","if isinstance ( value , dict ) :
",26.89,5.8,False
"def insert ( self , pack_id , data ) : <TAB> if ( pack_id not in self . queue ) and pack_id > self . begin_id : <TAB> <TAB> self . queue [ pack_id ] = PacketInfo ( data ) <TAB> <TAB> if self . end_id == pack_id : <TAB> <TAB> <TAB> self . end_id = pack_id + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> eid = self . end_id <TAB> <TAB> <TAB> while eid < pack_id : <TAB> <TAB> <TAB> <TAB> self . miss_queue . add ( eid ) <TAB> <TAB> <TAB> <TAB> eid + = 1 <TAB> <TAB> <TAB> self . end_id = pack_id + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . miss_queue . remove ( pack_id ) ","elif self . end_id < pack_id : 
","elif self . end_id != pack_id :
",74.63,63.4,False
"def _target_generator ( self ) : <TAB> # since we do not have predictions yet, so we ignore sampling here <TAB> if self . _internal_target_generator is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> from . . . . model_zoo . ssd . target import SSDTargetGenerator <TAB> <TAB> self . _internal_target_generator = SSDTargetGenerator ( <TAB> <TAB> <TAB> iou_thresh = self . _iou_thresh , <TAB> <TAB> <TAB> stds = self . _box_norm , <TAB> <TAB> <TAB> negative_mining_ratio = - 1 , <TAB> <TAB> <TAB> * * self . _kwargs <TAB> <TAB> ) <TAB> <TAB> return self . _internal_target_generator <TAB> else : <TAB> <TAB> return self . _internal_target_generator ","if self . _anchors_none : 
","if self . _iou_thresh is None :
",45.06,29.07,False
"def test_heapsort ( self ) : <TAB> # Exercise everything with repeated heapsort checks <TAB> for trial in range ( 100 ) : <TAB> <TAB> size = random . randrange ( 50 ) <TAB> <TAB> data = [ random . randrange ( 25 ) for i in range ( size ) ] <TAB> <TAB> if trial & 1 :<TAB> # Half of the time, use heapify <TAB> <TAB> <TAB> heap = data [ : ] <TAB> <TAB> <TAB> self . module . heapify ( heap ) <TAB> <TAB> else :<TAB> # The rest of the time, use heappush <TAB> <TAB> <TAB> heap = [ ] <TAB> <TAB> <TAB> for item in data : <TAB> <TAB> <TAB> <TAB> self . module . heappush ( heap , item ) <TAB> <TAB> heap_sorted = [ self . module . heappop ( heap ) for i in range ( size ) ] <TAB> <TAB> self . assertEqual ( heap_sorted , sorted ( data ) ) ","if trial & 1 : 
","if trial & 1 :
",100.0,100.0,True
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> if timeout is None : <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> if code == TERMINATE : <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode ","if res == _subprocess . WAIT_OBJECT_0 : 
","if res == _subprocess . WAIT_OBJECT_0 :
",100.0,100.0,True
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed ","elif value is None : 
","elif value is None :
",100.0,100.0,True
"def isnotsurplus ( self , item : T ) - > bool : <TAB> if not self . matchers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . mismatch_description . append_text ( <TAB> <TAB> <TAB> <TAB> "" not matched:  "" <TAB> <TAB> <TAB> ) . append_description_of ( item ) <TAB> <TAB> return False <TAB> return True ","if self . mismatch_description : 
","if self . mismatch_description :
",100.0,100.0,True
"def resolve_env_secrets ( config , environ ) : <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance ( config , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB> <TAB> elif list ( config . keys ( ) ) == [ "" $file "" ] : <TAB> <TAB> <TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key : resolve_env_secrets ( value , environ ) <TAB> <TAB> <TAB> <TAB> for key , value in config . items ( ) <TAB> <TAB> <TAB> } <TAB> elif isinstance ( config , list ) : <TAB> <TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB> <TAB> return config ","if list ( config . keys ( ) ) == [ "" $env "" ] : 
","if list ( config . keys ( ) ) == [ "" $env "" ] :
",100.0,100.0,True
"def __open__ ( filename , * args , * * kwargs ) : <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> return __realopen__ ( filename , * args , * * kwargs ) <TAB> if not os . path . isabs ( filename ) : <TAB> <TAB> datafilename = __papplet__ . dataPath ( filename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return __realopen__ ( datafilename , * args , * * kwargs ) <TAB> <TAB> sketchfilename = __papplet__ . sketchPath ( filename ) <TAB> if os . path . isfile ( sketchfilename ) : <TAB> <TAB> return __realopen__ ( sketchfilename , * args , * * kwargs ) <TAB> # Fail naturally <TAB> return __realopen__ ( filename , * args , * * kwargs ) ","if os . path . isfile ( datafilename ) : 
","if os . path . isfile ( datafilename ) :
",100.0,100.0,True
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ) ,"if self . block : 
","if self . counter > = self . count :
",43.47,16.78,False
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> if config is None : <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> if defaults is None : <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass ","if error_on_path : 
","if error_on_path :
",78.12,100.0,True
"def structured_dot_grad ( sparse_A , dense_B , ga ) : <TAB> if sparse_A . type . format in ( "" csc "" , "" csr "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sdgcsx = sdg_csc <TAB> <TAB> <TAB> CSx = CSC <TAB> <TAB> else : <TAB> <TAB> <TAB> sdgcsx = sdg_csr <TAB> <TAB> <TAB> CSx = CSR <TAB> <TAB> g_A_data = sdgcsx ( csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , dense_B , ga ) <TAB> <TAB> return CSx ( <TAB> <TAB> <TAB> g_A_data , csm_indices ( sparse_A ) , csm_indptr ( sparse_A ) , csm_shape ( sparse_A ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise NotImplementedError ( ) ","if sparse_A . type . format == "" csc "" : 
","if sparse_B . type . format == "" csc "" :
",90.56,78.25,False
"def step_async ( self , actions ) : <TAB> listify = True <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> listify = False <TAB> except TypeError : <TAB> <TAB> pass <TAB> if not listify : <TAB> <TAB> self . actions = actions <TAB> else : <TAB> <TAB> assert ( <TAB> <TAB> <TAB> self . num_envs == 1 <TAB> <TAB> ) , f "" actions  { actions }  is either not a list or has a wrong size - cannot match to  { self . num_envs }  environments "" <TAB> <TAB> self . actions = [ actions ] ","if len ( actions ) == self . num_envs : 
","if not isinstance ( actions , list ) :
",27.92,7.69,False
"def tempFailureRetry ( func , * args , * * kwargs ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( * args , * * kwargs ) <TAB> <TAB> except ( os . error , IOError ) as ex : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ","if ex . errno == errno . EINTR : 
","if ex . errno == errno . EINTR :
",100.0,100.0,True
"def test_learning_always_changes_generation ( chars , order ) : <TAB> learner = LStar ( lambda s : len ( s ) == 1 and s [ 0 ] in chars ) <TAB> for c in order : <TAB> <TAB> prev = learner . generation <TAB> <TAB> s = bytes ( [ c ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> learner . learn ( s ) <TAB> <TAB> <TAB> assert learner . generation > prev ","if learner . dfa . matches ( s ) != learner . member ( s ) : 
","if s != chars [ c ] :
",25.78,4.41,False
"def test_costs_5D_noisy_names ( signal_bkps_5D_noisy , cost_name ) : <TAB> signal , bkps = signal_bkps_5D_noisy <TAB> cost = cost_factory ( cost_name ) <TAB> cost . fit ( signal ) <TAB> cost . error ( 0 , 100 ) <TAB> cost . error ( 100 , signal . shape [ 0 ] ) <TAB> cost . error ( 10 , 50 ) <TAB> cost . sum_of_costs ( bkps ) <TAB> with pytest . raises ( NotEnoughPoints ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cost . min_size = 4 <TAB> <TAB> <TAB> cost . error ( 1 , 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cost . error ( 1 , 2 ) ","if cost_name == "" cosine "" : 
","if cost_name == "" cosine "" :
",100.0,100.0,True
"def remove_empty_dirs ( dirname ) : <TAB> logger . debug ( "" remove_empty_dirs  ' %s ' "" % ( dirname ) ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dirname = dirname . encode ( "" utf-8 "" ) <TAB> <TAB> os . removedirs ( dirname ) <TAB> <TAB> logger . debug ( "" remove_empty_dirs  ' %s '  done "" % ( dirname ) ) <TAB> except OSError as exc :<TAB> # Python >2.5 <TAB> <TAB> if exc . errno == errno . ENOTEMPTY : <TAB> <TAB> <TAB> logger . debug ( "" remove_empty_dirs  ' %s '  not empty "" % ( dirname ) ) <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> raise <TAB> except Exception as e : <TAB> <TAB> logger . exception ( e ) <TAB> <TAB> logger . error ( "" remove_empty_dirs exception:  "" + dirname ) <TAB> <TAB> raise e ","if not isinstance ( dirname , str ) : 
","if isinstance ( dirname , str ) :
",71.9,76.73,False
"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if feat is not None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB> <TAB> <TAB> feat = f <TAB> if feat is None : <TAB> <TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name ) ","if self . _return_feature ( f ) and hasattr ( f , name ) : 
","if f . name == name :
",29.03,2.37,False
"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB> <TAB> occupied = False <TAB> <TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB> <TAB> <TAB> if strategy == self : <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot ( <TAB> <TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> ) ","if not occupied : 
","if occupied :
",34.18,0.0,False
"def __deepcopy__ ( self , memo ) : <TAB> cls = self . __class__ <TAB> result = cls . __new__ ( cls ) <TAB> memo [ id ( self ) ] = result <TAB> for key , value in self . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( result , key , copy . copy ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( result , key , copy . deepcopy ( value , memo ) ) <TAB> return result ","if key in cls . dynamic_methods : 
","if isinstance ( value , dict ) :
",26.89,5.8,False
def restore_forward ( model ) : <TAB> for child in model . children ( ) : <TAB> <TAB> # leaf node <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> child . forward = child . old_forward <TAB> <TAB> <TAB> child . old_forward = None <TAB> <TAB> else : <TAB> <TAB> <TAB> restore_forward ( child ) ,"if is_leaf ( child ) and hasattr ( child , "" old_forward "" ) : 
","if hasattr ( child , "" old_forward "" ) :
",61.91,51.53,False
"def add ( self , obj , allow_duplicates = False ) : <TAB> if allow_duplicates or obj not in self . _constants : <TAB> <TAB> self . _constant_pool . append ( obj ) <TAB> <TAB> self . _constants [ obj ] = len ( self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _constant_pool . append ( None ) ","if obj . __class__ in ( Double , Long ) : 
","if self . _constants [ obj ] == len ( self ) :
",32.38,8.55,False
"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] :<TAB> # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l . lower ( ) . find ( "" copyright "" ) <TAB> <TAB> if idx < 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l [ idx + 9 : ] . strip ( ) <TAB> <TAB> if not copyright : <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise ( copyright ) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> ret . add ( copyright ) <TAB> return ret ","if not copyright . find ( "" 200 "" ) > = 0 and not copyright . find ( "" 199 "" ) > = 0 : 
","if not copyright . startswith ( "" # "" ) :
",41.82,7.62,False
"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB> <TAB> context . next_indent = len ( text ) <TAB> <TAB> if context . next_indent < context . indent : <TAB> <TAB> <TAB> while context . next_indent < context . indent : <TAB> <TAB> <TAB> <TAB> context . indent = context . indent_stack . pop ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> extra = text [ context . indent : ] <TAB> <TAB> <TAB> <TAB> text = text [ : context . indent ] <TAB> else : <TAB> <TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB> <TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB> <TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( ) ","if context . next_indent > context . indent : 
","if text [ context . next_indent : ] == "" \n "" :
",40.75,24.62,False
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> if not cmd . stdout . strip ( ) : <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( ) ","if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : 
","if not log_cmd . run ( ) :
",29.92,10.11,False
"def nodes ( self ) : <TAB> if not self . _nodes : <TAB> <TAB> nodes = self . cluster_group . instances ( ) <TAB> <TAB> self . _nodes = [ ] <TAB> <TAB> master = self . master_node <TAB> <TAB> nodeid = 1 <TAB> <TAB> for node in nodes : <TAB> <TAB> <TAB> if node . state not in [ "" pending "" , "" running "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _nodes . insert ( 0 , master ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _nodes . append ( Node ( node , self . key_location , "" node %.3d "" % nodeid ) ) <TAB> <TAB> <TAB> nodeid + = 1 <TAB> else : <TAB> <TAB> for node in self . _nodes : <TAB> <TAB> <TAB> log . debug ( "" refreshing instance  %s "" % node . id ) <TAB> <TAB> <TAB> node . update ( ) <TAB> return self . _nodes ","if node . id == master . id : 
","if node . master != master :
",42.05,21.07,False
"def match ( cls , agent_name , guid , uri , media = None ) : <TAB> # Retrieve `Agent` for provided `guid` <TAB> agent = Agents . get ( agent_name ) <TAB> if agent is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # First occurrence of unsupported agent <TAB> <TAB> <TAB> log . warn ( "" Unsupported metadata agent:  %s "" % agent_name ) <TAB> <TAB> <TAB> # Mark unsupported agent as ""seen"" <TAB> <TAB> <TAB> unsupported_agents [ agent_name ] = True <TAB> <TAB> <TAB> return False <TAB> <TAB> # Duplicate occurrence of unsupported agent <TAB> <TAB> log . warn ( <TAB> <TAB> <TAB> "" Unsupported metadata agent:  %s "" % agent_name , extra = { "" duplicate "" : True } <TAB> <TAB> ) <TAB> <TAB> return False <TAB> # Fill `guid` with details from agent <TAB> return agent . fill ( guid , uri , media ) ","if agent_name not in unsupported_agents : 
","if agent_name not in unsupported_agents :
",100.0,100.0,True
"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB> <TAB> randomNode = Gaffer . Random ( ) <TAB> <TAB> parentNode . addChild ( randomNode ) <TAB> <TAB> if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) : <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode ) ","elif isinstance ( plug , Gaffer . Color3fPlug ) : 
","elif isinstance ( plug , Gaffer . ColorPlug ) :
",85.49,70.71,False
"def post_arrow ( self , arr : pa . Table , graph_type : str , opts : str = "" "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> sub_path = f "" api/v2/upload/datasets/ { dataset_id } / { graph_type } /arrow "" <TAB> try : <TAB> <TAB> resp = self . post_arrow_generic ( sub_path , tok , arr , opts ) <TAB> <TAB> out = resp . json ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" No success indicator in server response "" ) <TAB> <TAB> return out <TAB> except Exception as e : <TAB> <TAB> logger . error ( "" Failed to post arrow to  %s "" , sub_path , exc_info = True ) <TAB> <TAB> raise e ","if not ( "" success "" in out ) or not out [ "" success "" ] : 
","if "" success "" not in out :
",35.86,8.33,False
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> elif isinstance ( val , MutableMapping ) : <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if tag == "" config "" : <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem ","if tag == "" layers "" : 
","if isinstance ( val , MutableMapping ) :
",26.98,6.57,False
"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB> <TAB> node = self . path . find_dir ( dir ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not node in lst : <TAB> <TAB> <TAB> lst . append ( node ) <TAB> <TAB> self . bld_incpaths_lst . append ( node ) ","if not node : 
","if not node :
",100.0,100.0,True
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> if isinstance ( val , compat . string_types ) : <TAB> <TAB> <TAB> return ""<TAB> %s "" % val <TAB> <TAB> elif val < 1024 * * 2 : <TAB> <TAB> <TAB> return ""<TAB> %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ""<TAB> %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ""<TAB> %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return ""<TAB> %s "" % val ","elif val < 1024 * * 3 : 
","elif val < 1024 * * 3 :
",100.0,100.0,True
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> if prev_mem is None : <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> new_mem . stop_gradient = True <TAB> return new_mem ","if reuse_len is not None and reuse_len > 0 : 
","if reuse_len is not None :
",54.35,41.07,False
"def GROUP_CONCAT ( builder , distinct , expr , sep = None ) : <TAB> assert distinct in ( None , True , False ) <TAB> result = distinct and "" GROUP_CONCAT(DISTINCT  "" or "" GROUP_CONCAT( "" , builder ( expr ) <TAB> if sep is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = result , ""  SEPARATOR  "" , builder ( sep ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = result , "" ,  "" , builder ( sep ) <TAB> return result , "" ) "" ","if builder . provider . dialect == "" MySQL "" : 
","if sep == "" ) "" :
",32.24,16.41,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> self . custom_fields = [ ] <TAB> self . obj_type = ContentType . objects . get_for_model ( self . model ) <TAB> # Add all applicable CustomFields to the form <TAB> custom_fields = CustomField . objects . filter ( content_types = self . obj_type ) <TAB> for cf in custom_fields : <TAB> <TAB> # Annotate non-required custom fields as nullable <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . nullable_fields . append ( cf . name ) <TAB> <TAB> self . fields [ cf . name ] = cf . to_form_field ( <TAB> <TAB> <TAB> set_initial = False , enforce_required = False <TAB> <TAB> ) <TAB> <TAB> # Annotate this as a custom field <TAB> <TAB> self . custom_fields . append ( cf . name ) ","if not cf . required : 
","if not cf . required :
",100.0,100.0,True
"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> if possible_child_hash not in self . items : <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash ","if possible_child_hash == item_hash : 
","if self . get_last ( item_hash ) == self . get_last ( possible_child_hash ) :
",27.5,20.8,False
"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB> <TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB> <TAB> <TAB> <TAB> if not self . use_parallel_executor : <TAB> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) ) ","if self . use_parallel_executor and not self . use_double_buffer : 
","if self . use_unordered_batch :
",38.7,17.86,False
"def add_cells ( self , cells ) : <TAB> for cell in cells : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> id = len ( self . cell_id_map ) <TAB> <TAB> <TAB> self . cell_id_map [ cell ] = id <TAB> <TAB> <TAB> self . id_cell_map [ id ] = cell ","if cell not in self . cell_id_map : 
","if cell not in self . cell_id_map :
",100.0,100.0,True
"def _verify_out ( marker = "" >> "" ) : <TAB> if shared : <TAB> <TAB> self . assertIn ( "" libapp_lib.dylib "" , self . client . out ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIn ( "" libapp_lib.a "" , self . client . out ) <TAB> <TAB> else :<TAB> # Incremental build not the same msg <TAB> <TAB> <TAB> self . assertIn ( "" Built target app_lib "" , self . client . out ) <TAB> out = str ( self . client . out ) . splitlines ( ) <TAB> for k , v in vals . items ( ) : <TAB> <TAB> self . assertIn ( "" %s %s :  %s "" % ( marker , k , v ) , out ) ","if marker == "" >> "" : 
","if shared :
",27.04,0.0,False
"def Visit_expr ( self , node ) :<TAB> # pylint: disable=invalid-name <TAB> # expr ::= xor_expr ('|' xor_expr)* <TAB> for child in node . children : <TAB> <TAB> self . Visit ( child ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR ) ","if isinstance ( child , pytree . Leaf ) and child . value == "" | "" : 
","if isinstance ( child , pytree . Leaf ) and child . value == ""|' "" :
",90.1,87.39,False
"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB> <TAB> after = self . after . id if self . after else None <TAB> <TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB> <TAB> if not data : <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . limit = 0<TAB> # terminate loop <TAB> <TAB> self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB> <TAB> for element in reversed ( data ) : <TAB> <TAB> <TAB> await self . members . put ( self . create_member ( element ) ) ","if len ( data ) < 1000 : 
","if len ( data ) > 1 :
",77.42,54.11,False
"def assert_warns ( expected ) : <TAB> with warnings . catch_warnings ( record = True ) as w : <TAB> <TAB> warnings . simplefilter ( "" always "" ) <TAB> <TAB> yield <TAB> # Python 2 does not raise warnings multiple times from the same stack <TAB> # frame. <TAB> if sys . version_info > = ( 3 , 0 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> exc_name = expected . __name__ <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> exc_name = str ( expected ) <TAB> <TAB> <TAB> raise AssertionError ( "" %s  not triggerred "" % exc_name ) ","if not any ( isinstance ( m . message , expected ) for m in w ) : 
","if isinstance ( expected , type ) and expected . __name__ != "" AssertionError "" :
",12.69,5.14,False
"def __init__ ( self , measures ) : <TAB> """"""Constructs a ContingencyMeasures given a NgramAssocMeasures class"""""" <TAB> self . __class__ . __name__ = "" Contingency "" + measures . __class__ . __name__ <TAB> for k in dir ( measures ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> v = getattr ( measures , k ) <TAB> <TAB> if not k . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> v = self . _make_contingency_fn ( measures , v ) <TAB> <TAB> setattr ( self , k , v ) ","if k . startswith ( "" __ "" ) : 
","if k . startswith ( "" __ "" ) :
",100.0,100.0,True
"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB> <TAB> start = event == "" start "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> omitted_kws + = 1 <TAB> <TAB> if not omitted_kws : <TAB> <TAB> <TAB> yield event , elem <TAB> <TAB> elif not start : <TAB> <TAB> <TAB> elem . clear ( ) <TAB> <TAB> if omit and not start : <TAB> <TAB> <TAB> omitted_kws - = 1 ","if omit and start : 
","if omit and start :
",100.0,100.0,True
"def read_block ( buffer , i ) : <TAB> offset = i * BLOCK_LENGTH % config . CAPTURE_BUFFER <TAB> while True : <TAB> <TAB> if buffer [ offset ] == BLOCK_MARKER . END : <TAB> <TAB> <TAB> return None <TAB> <TAB> while buffer [ offset ] == BLOCK_MARKER . WRITE : <TAB> <TAB> <TAB> time . sleep ( SHORT_SENSOR_SLEEP_TIME ) <TAB> <TAB> buffer [ offset ] = BLOCK_MARKER . READ <TAB> <TAB> buffer . seek ( offset + 1 ) <TAB> <TAB> length = struct . unpack ( "" =H "" , buffer . read ( 2 ) ) [ 0 ] <TAB> <TAB> retval = buffer . read ( length ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> buffer [ offset ] = BLOCK_MARKER . NOP <TAB> return retval ","if buffer [ offset ] == BLOCK_MARKER . READ : 
","if not retval :
",26.29,2.0,False
def _start ( self ) : <TAB> try : <TAB> <TAB> instance_info = self . _get_instance_info ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _multipass_cmd . start ( instance_name = self . instance_name ) <TAB> except errors . ProviderInfoError as instance_error : <TAB> <TAB> # Until we have proper multipass error codes to know if this <TAB> <TAB> # was a communication error we should keep this error tracking <TAB> <TAB> # and generation here. <TAB> <TAB> raise errors . ProviderInstanceNotFoundError ( <TAB> <TAB> <TAB> instance_name = self . instance_name <TAB> <TAB> ) from instance_error ,"if not instance_info . is_running ( ) : 
","if instance_info . get ( "" multipass_cmd_instance "" , False ) :
",32.77,17.69,False
"def _river_driver ( self ) : <TAB> if self . _cached_river_driver : <TAB> <TAB> return self . _cached_river_driver <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _cached_river_driver = MsSqlDriver ( <TAB> <TAB> <TAB> <TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _cached_river_driver = OrmDriver ( <TAB> <TAB> <TAB> <TAB> self . workflow , self . wokflow_object_class , self . field_name <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _cached_river_driver ","if app_config . IS_MSSQL : 
","if self . is_sql :
",53.65,6.98,False
"def __LazyMap__ ( self , attr ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> debug_attr_print ( <TAB> <TAB> <TAB> <TAB> "" %s .__LazyMap__( %s ) added something "" % ( self . _username_ , attr ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return 1 <TAB> except AttributeError : <TAB> <TAB> return 0 ","if self . _LazyAddAttr_ ( attr ) : 
","if self . _debug_ :
",37.89,29.64,False
"def prepare ( self , data = None , user = None ) : <TAB> """"""Prepare activation for execution."""""" <TAB> super ( ManagedStartViewActivation , self ) . prepare . original ( ) <TAB> self . task . owner = user <TAB> management_form_class = self . get_management_form_class ( ) <TAB> self . management_form = management_form_class ( data = data , instance = self . task ) <TAB> if data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise FlowRuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Activation metadata is broken  {} "" . format ( self . management_form . errors ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . task = self . management_form . save ( commit = False ) ","if not self . management_form . is_valid ( ) : 
","if self . management_form . errors :
",46.68,36.22,False
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> if self . __Token : <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList : <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1 ","if not RegionSizeGuid : 
","elif self > = 3 :
",27.55,8.12,False
"def _get_completion ( self , document ) : <TAB> try : <TAB> <TAB> completion_header = document . xpath ( "" //div[@id= ' complete_day ' ] "" ) [ 0 ] <TAB> <TAB> completion_message = completion_header . getchildren ( ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif "" day_complete_message "" in completion_message . classes : <TAB> <TAB> <TAB> return True <TAB> except IndexError : <TAB> <TAB> return False<TAB> # Who knows, probably not my diary. ","if "" day_incomplete_message "" in completion_message . classes : 
","if completion_message . classes is None :
",36.82,24.93,False
"def run ( self ) : <TAB> DISPATCH_SYNC = components . interfaces . nsIEventTarget . DISPATCH_SYNC <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> for match in findlib2 . find_all_matches ( self . regex , self . text ) : <TAB> <TAB> <TAB> if self . _stopped : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> self . target . dispatch ( lambda : self . callback ( match ) , DISPATCH_SYNC ) <TAB> <TAB> <TAB> if self . _stopped : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self . target . dispatch ( lambda : self . callback ( None ) , DISPATCH_SYNC ) <TAB> finally : <TAB> <TAB> self . callback = None <TAB> <TAB> self . target = None ","if self . _stopped : 
","if self . _stopped :
",100.0,100.0,True
"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k ) ","elif "" regex "" in literal_or_identifier : 
","elif re . match ( r "" ^[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d+[a-zA-Z]: \ d
",26.28,0.68,False
"def process_image_pre_creation ( sender , instance : Image , * * kwargs ) : <TAB> # FIXME(winkidney): May have issue on determining if it <TAB> #  is created or not <TAB> if instance . pk is not None : <TAB> <TAB> return <TAB> for plugin in _plugin_instances : <TAB> <TAB> process_fn = getattr ( plugin , "" process_image_pre_creation "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> process_fn ( <TAB> <TAB> <TAB> <TAB> django_settings = settings , <TAB> <TAB> <TAB> <TAB> image_instance = instance , <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . exception ( <TAB> <TAB> <TAB> <TAB> "" Error occurs while trying to access plugin ' s pin_pre_save  "" <TAB> <TAB> <TAB> <TAB> "" for plugin  %s "" % plugin <TAB> <TAB> <TAB> ) ","if process_fn is None : 
","if process_fn is None :
",100.0,100.0,True
"def check_screenshots ( self ) : <TAB> # If we arrive here, there have not been any failures yet <TAB> if self . interactive : <TAB> <TAB> self . _commit_screenshots ( ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _validate_screenshots ( ) <TAB> <TAB> <TAB> # Always commit the screenshots here. They can be used for the next test run. <TAB> <TAB> <TAB> # If reference screenshots were already present and there was a mismatch, it should <TAB> <TAB> <TAB> # have failed above. <TAB> <TAB> <TAB> self . _commit_screenshots ( ) <TAB> <TAB> elif self . allow_missing_screenshots : <TAB> <TAB> <TAB> warnings . warn ( "" No committed reference screenshots available. Ignoring. "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( <TAB> <TAB> <TAB> <TAB> "" No committed reference screenshots available. Run interactive first. "" <TAB> <TAB> <TAB> ) ","if self . _has_reference_screenshots ( ) : 
","if self . screenshots :
",39.45,11.14,False
"def on_task_abort ( self , task , config ) : <TAB> if "" abort "" in config : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" sending abort notification "" ) <TAB> <TAB> self . send_notification ( <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" title "" ] , <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" message "" ] , <TAB> <TAB> <TAB> config [ "" abort "" ] [ "" via "" ] , <TAB> <TAB> <TAB> template_renderer = task . render , <TAB> <TAB> ) ","if task . silent_abort : 
","if "" message "" not in config [ "" abort "" ] :
",27.28,4.07,False
"def block_users ( self , user_ids ) : <TAB> broken_items = [ ] <TAB> self . logger . info ( "" Going to block  %d  users. "" % len ( user_ids ) ) <TAB> for user_id in tqdm ( user_ids ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . error_delay ( ) <TAB> <TAB> <TAB> broken_items = user_ids [ user_ids . index ( user_id ) : ] <TAB> <TAB> <TAB> break <TAB> self . logger . info ( "" DONE: Total blocked  %d  users. "" % self . total [ "" blocks "" ] ) <TAB> return broken_items ","if not self . block ( user_id ) : 
","if self . total [ "" blocks "" ] < = 0 :
",31.67,7.35,False
"def find_widget_by_id ( self , id , parent = None ) : <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None : <TAB> <TAB> if id in self : <TAB> <TAB> <TAB> return self [ id ]<TAB> # Do things fast if possible <TAB> <TAB> parent = self [ "" editor "" ] <TAB> for c in parent . get_children ( ) : <TAB> <TAB> if hasattr ( c , "" get_id "" ) : <TAB> <TAB> <TAB> if c . get_id ( ) == id : <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance ( c , Gtk . Container ) : <TAB> <TAB> <TAB> r = self . find_widget_by_id ( id , c ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None ","if not r is None : 
","if r :
",27.57,0.0,False
"def addClasses ( self , name ) : <TAB> # Result: void - None <TAB> # In: name: string <TAB> for n in name . split ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> k , method = n . split ( "" . "" ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> k = n <TAB> <TAB> <TAB> method = None <TAB> <TAB> self . classes [ k ] = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . methods . setdefault ( k , { } ) [ method ] = 1 ","if method is not None : 
","if method :
",29.58,0.0,False
"def Read ( self , lex_mode ) : <TAB> while True : <TAB> <TAB> t = self . _Read ( lex_mode ) <TAB> <TAB> self . was_line_cont = t . id == Id . Ignored_LineCont <TAB> <TAB> # TODO: Change to ALL IGNORED types, once you have SPACE_TOK.  This means <TAB> <TAB> # we don't have to handle them in the VS_1/VS_2/etc. states. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> # log('Read() Returning %s', t) <TAB> return t ","if t . id != Id . Ignored_LineCont : 
","if t . id in ( Id . SpaceTOK , Id . Gsi_LineCont ) :
",49.5,19.92,False
"def _dir_guildfile ( dir , ctx ) : <TAB> from guild import guildfile <TAB> try : <TAB> <TAB> return guildfile . for_dir ( dir ) <TAB> except guildfile . NoModels : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> help_suffix = ""  or  ' %s '  for help "" % click_util . cmd_help ( ctx ) <TAB> <TAB> else : <TAB> <TAB> <TAB> help_suffix = "" "" <TAB> <TAB> cli . error ( <TAB> <TAB> <TAB> "" %s  does not contain a Guild file (guild.yml) \n "" <TAB> <TAB> <TAB> "" Try specifying a project path or package name %s . "" <TAB> <TAB> <TAB> % ( cwd_desc ( dir ) , help_suffix ) <TAB> <TAB> ) <TAB> except guildfile . GuildfileError as e : <TAB> <TAB> cli . error ( str ( e ) ) ","if ctx : 
","if ctx :
",78.12,0.0,False
"def check_response ( self , response ) : <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response : <TAB> <TAB> # Skip blank lines: <TAB> <TAB> if not line . strip ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB> <TAB> <TAB> raise BadLogin ( line ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) ) ","if line . startswith ( b "" OK "" ) : 
","elif line . startswith ( b "" User "" ) :
",71.15,58.77,False
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> homedir = response . pathspec . path <TAB> <TAB> <TAB> username = os . path . basename ( homedir ) <TAB> <TAB> <TAB> if username not in self . _ignore_users : <TAB> <TAB> <TAB> <TAB> yield rdf_client . User ( username = username , homedir = homedir ) ","if stat . S_ISDIR ( int ( response . st_mode ) ) : 
","if response . st_mode == rdf_client . StatMode . ST_MODE :
",35.99,23.29,False
"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB> <TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB> <TAB> spk = uttid <TAB> if not self . reverse : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = np . add ( x , self . bias [ spk ] ) <TAB> <TAB> if self . norm_vars : <TAB> <TAB> <TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB> <TAB> if self . norm_vars : <TAB> <TAB> <TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB> <TAB> if self . norm_means : <TAB> <TAB> <TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x ","if self . norm_means : 
","if self . norm_means :
",100.0,100.0,True
"def hasFixtures ( self , ctx_callback = None ) : <TAB> context = self . context <TAB> if context is None : <TAB> <TAB> return False <TAB> if self . implementsAnyFixture ( context , ctx_callback = ctx_callback ) : <TAB> <TAB> return True <TAB> # My context doesn't have any, but its ancestors might <TAB> factory = self . factory <TAB> if factory : <TAB> <TAB> ancestors = factory . context . get ( self , [ ] ) <TAB> <TAB> for ancestor in ancestors : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) : 
","if self . implementsAnyFixture ( ancestor , ctx_callback = ctx_callback ) :
",100.0,100.0,True
def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self . radioButtons : <TAB> <TAB> btn = self . radioButtons [ moduleID ] <TAB> <TAB> if moduleID == active : <TAB> <TAB> <TAB> btn . SetValue ( True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> btn . SetValue ( False ) <TAB> <TAB> if self . demoModules . Exists ( moduleID ) : <TAB> <TAB> <TAB> btn . Enable ( True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . btnRestore . Enable ( True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> btn . Enable ( False ) <TAB> <TAB> <TAB> if moduleID == modModified : <TAB> <TAB> <TAB> <TAB> self . btnRestore . Enable ( False ) ,"if moduleID == modModified : 
","if moduleID == modModified :
",100.0,100.0,True
"def ignore_proxy_host ( self ) : <TAB> """"""Check if self.host is in the $no_proxy ignore list."""""" <TAB> if urllib . proxy_bypass ( self . host ) : <TAB> <TAB> return True <TAB> no_proxy = os . environ . get ( "" no_proxy "" ) <TAB> if no_proxy : <TAB> <TAB> entries = [ parse_host_port ( x ) for x in no_proxy . split ( "" , "" ) ] <TAB> <TAB> for host , port in entries : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if host . lower ( ) == self . host and port == self . port : 
","if self . host == host and port in self . ignore_hosts :
",32.66,16.7,False
"def run ( self , _ ) : <TAB> view = self . view <TAB> if not view . settings ( ) . get ( "" terminus_view "" ) : <TAB> <TAB> return <TAB> terminal = Terminal . from_id ( view . id ( ) ) <TAB> if terminal : <TAB> <TAB> terminal . close ( ) <TAB> <TAB> panel_name = terminal . panel_name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> window = panel_window ( view ) <TAB> <TAB> <TAB> if window : <TAB> <TAB> <TAB> <TAB> window . destroy_output_panel ( panel_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> view . close ( ) ","if panel_name : 
","if panel_name :
",78.12,100.0,True
"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB> <TAB> elif isinstance ( node , addnodes . start_of_file ) : <TAB> <TAB> <TAB> return node [ "" docname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> node = node . parent <TAB> return None<TAB> # never reached here. only for type hinting ","if isinstance ( node , nodes . document ) : 
","if isinstance ( node , addnodes . start_of_file ) :
",73.56,31.61,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB> <TAB> if self . has_gender_differences : <TAB> <TAB> <TAB> elements = path_elements + [ "" female "" ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> elif strict : <TAB> <TAB> <TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict ) ","if strict : 
","if not self . species_id in path_elements :
",29.42,4.03,False
"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB> <TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB> <TAB> <TAB> self . _cancel_editing ( ) <TAB> <TAB> elif event . GetKeyCode ( ) == wx . WXK_RETURN : <TAB> <TAB> <TAB> self . _update_value ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event . Skip ( ) ","elif event . GetKeyCode ( ) == wx . WXK_DELETE : 
","elif event . GetModifiers ( ) == wx . MOD_ALT :
",74.34,46.83,False
"def sync_up_to_new_location ( self , worker_ip ) : <TAB> if worker_ip != self . worker_ip : <TAB> <TAB> logger . debug ( "" Setting new worker IP to  %s "" , worker_ip ) <TAB> <TAB> self . set_worker_ip ( worker_ip ) <TAB> <TAB> self . reset ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( "" Sync up to new location skipped. This should not occur. "" ) <TAB> else : <TAB> <TAB> logger . warning ( "" Sync attempted to same IP  %s . "" , worker_ip ) ","if not self . sync_up ( ) : 
","if self . state == State . STARTING :
",32.42,9.98,False
"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB> <TAB> "" torrent "" : "" "" , <TAB> <TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB> <TAB> data = self . session . get ( url ) . text <TAB> <TAB> with bs4_parser ( data ) as html : <TAB> <TAB> <TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for download in downloads . findAll ( "" a "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> link = download [ "" href "" ] <TAB> <TAB> <TAB> <TAB> <TAB> if link . startswith ( "" magnet "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" magnet "" ] = link <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return links [ download_type ] ","if downloads : 
","if downloads :
",78.12,0.0,False
"def force_ipv4 ( self , * args ) : <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB> lines = [ ] <TAB> for line in open ( self . etc_hosts ( ) ) : <TAB> <TAB> if "" ::1 "" in line : <TAB> <TAB> <TAB> newline = re . sub ( "" \\ slocalhost \\ s "" , "" "" , line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB> <TAB> <TAB> <TAB> line = newline <TAB> <TAB> lines . append ( line ) <TAB> f = open ( self . etc_hosts ( ) , "" w "" ) <TAB> for line in lines : <TAB> <TAB> f . write ( line ) <TAB> f . close ( ) ","if line != newline : 
","if newline != "" :: "" :
",28.12,11.99,False
"def prepare ( self ) : <TAB> # Maybe the brok is a old daemon one or was already prepared <TAB> # if so, the data is already ok <TAB> if hasattr ( self , "" prepared "" ) and not self . prepared : <TAB> <TAB> self . data = SafeUnpickler . loads ( self . data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . data [ "" instance_id "" ] = self . instance_id <TAB> self . prepared = True ","if hasattr ( self , "" instance_id "" ) : 
","if self . instance_id :
",26.51,14.23,False
"def _test_compute_q0 ( self ) : <TAB> # Stub code to search a logq space and figure out logq0 by eyeballing <TAB> # results. This code does not run with the tests. Remove underscore to run. <TAB> sigma = 15 <TAB> order = 250 <TAB> logqs = np . arange ( - 290 , - 270 , 1 ) <TAB> count = 0 <TAB> for logq in logqs : <TAB> <TAB> count + = 1 <TAB> <TAB> sys . stdout . write ( <TAB> <TAB> <TAB> "" \t %0.5g :  %0.10g "" % ( logq , pate . rdp_gaussian ( logq , sigma , order ) ) <TAB> <TAB> ) <TAB> <TAB> sys . stdout . flush ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" "" ) ","if count % 5 == 0 : 
","if count % 100 == 0 :
",63.85,50.0,False
"def valid_fieldnames ( fieldnames ) : <TAB> """"""check if fieldnames are valid"""""" <TAB> for fieldname in fieldnames : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> elif fieldname in fieldname_map and fieldname_map [ fieldname ] == "" source "" : <TAB> <TAB> <TAB> return True <TAB> return False ","if fieldname in canonical_field_names and fieldname == "" source "" : 
","if fieldname == "" name "" and fieldname_map [ fieldname ] == "" target "" :
",39.15,17.92,False
"def ns_provide ( self , id_ ) : <TAB> global controllers , layouts <TAB> if id_ == "" _leo_viewrendered "" : <TAB> <TAB> c = self . c <TAB> <TAB> vr = controllers . get ( c . hash ( ) ) or ViewRenderedController ( c ) <TAB> <TAB> h = c . hash ( ) <TAB> <TAB> controllers [ h ] = vr <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> layouts [ h ] = c . db . get ( "" viewrendered_default_layouts "" , ( None , None ) ) <TAB> <TAB> # return ViewRenderedController(self.c) <TAB> <TAB> return vr ","if not layouts . get ( h ) : 
","if not layouts . get ( h ) :
",100.0,100.0,True
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> if config is None : <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass ","if defaults is None : 
","if defaults is None :
",100.0,100.0,True
"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB> <TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB> <TAB> for k , v in q . items ( ) : <TAB> <TAB> <TAB> if k not in query : <TAB> <TAB> <TAB> <TAB> query [ k ] = { } <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query [ k ] = v <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> query [ k ] . update ( v ) <TAB> return query ","if isinstance ( v , list ) : 
","if isinstance ( query [ k ] , dict ) :
",32.71,18.36,False
"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB> <TAB> self . data . append ( data ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> passon = b "" "" <TAB> <TAB> if data : <TAB> <TAB> <TAB> self . data . append ( data ) <TAB> return passon ","if self . size : 
","if len ( data ) > self . size :
",57.96,27.78,False
"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB> <TAB> if mode == "" append "" : <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . append ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB> <TAB> core . config . globalVariables [ name ] = data ","elif mode == "" add "" : 
","elif mode == "" add "" :
",100.0,100.0,True
"def vi_pos_back_short ( line , index = 0 , count = 1 ) : <TAB> line = vi_list ( line ) <TAB> try : <TAB> <TAB> for i in range ( count ) : <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> while vi_is_space ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> in_word = vi_is_word ( line [ index ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> while vi_is_word ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> while not vi_is_word_or_space ( line [ index ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> index - = 1 <TAB> <TAB> return index + 1 <TAB> except IndexError : <TAB> <TAB> return 0 ","if in_word : 
","if in_word :
",78.12,100.0,True
"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB> <TAB> example = list ( example ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for key , max_len in len_map . items ( ) : <TAB> <TAB> <TAB> <TAB> example_len = example [ key ] . shape <TAB> <TAB> <TAB> <TAB> if example_len > max_len : <TAB> <TAB> <TAB> <TAB> <TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB> <TAB> yield tuple ( example ) ","if len_map is not None : 
","if len_map :
",29.58,38.81,False
"def decorate ( f ) : <TAB> # call-signature of f is exposed via __wrapped__. <TAB> # we want it to mimic Obj.__init__ <TAB> f . __wrapped__ = Obj . __init__ <TAB> f . _uses_signature = Obj <TAB> # Supplement the docstring of f with information from Obj <TAB> if Obj . __doc__ : <TAB> <TAB> doclines = Obj . __doc__ . splitlines ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> doc = f . __doc__ + "" \n "" . join ( doclines [ 1 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> doc = "" \n "" . join ( doclines ) <TAB> <TAB> try : <TAB> <TAB> <TAB> f . __doc__ = doc <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> # __doc__ is not modifiable for classes in Python < 3.3 <TAB> <TAB> <TAB> pass <TAB> return f ","if f . __doc__ : 
","if doclines [ 0 ] == "" # "" :
",27.44,4.46,False
"def IncrementErrorCount ( self , category ) : <TAB> """"""Bumps the module's error statistic."""""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB> <TAB> if self . counting != "" detailed "" : <TAB> <TAB> <TAB> category = category . split ( "" / "" ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . errors_by_category [ category ] = 0 <TAB> <TAB> self . errors_by_category [ category ] + = 1 ","if category not in self . errors_by_category : 
","if category not in self . errors_by_category :
",100.0,100.0,True
"def _delete_fields ( self , data ) : <TAB> data = self . _del ( <TAB> <TAB> data , [ "" speaker_ids "" , "" track_id "" , "" microlocation_id "" , "" session_type_id "" ] <TAB> ) <TAB> # convert datetime fields <TAB> for _ in [ "" start_time_tz "" , "" end_time_tz "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data [ _ ] = SESSION_POST [ _ [ 0 : - 3 ] ] . from_str ( data [ _ ] ) <TAB> <TAB> <TAB> data [ _ [ 0 : - 3 ] ] = data . pop ( _ ) <TAB> return data ","if _ in data : 
","if _ in SESSION_POST :
",64.55,26.27,False
"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB> <TAB> if char in char_set : <TAB> <TAB> <TAB> letters + = char <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> strings . append ( letters ) <TAB> <TAB> <TAB> letters = "" "" <TAB> <TAB> <TAB> count = 0 <TAB> if count > threshold : <TAB> <TAB> strings . append ( letters ) <TAB> return strings ","if count > threshold : 
","if count > threshold :
",100.0,100.0,True
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> if token . value == "" { "" : <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token . OpensScope ( ) : <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False ","if token . ClosesScope ( ) : 
","elif token . value == "" } "" :
",33.13,9.29,False
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : 
","if mode == "" encrypted "" :
",30.65,2.67,False
"def main ( self ) : <TAB> self . model . clear ( ) <TAB> self . callman . unregister_all ( ) <TAB> active_handle = self . get_active ( "" Person "" ) <TAB> if active_handle : <TAB> <TAB> active = self . dbstate . db . get_person_from_handle ( active_handle ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . callman . register_obj ( active ) <TAB> <TAB> <TAB> self . display_citations ( active ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . set_has_data ( False ) <TAB> else : <TAB> <TAB> self . set_has_data ( False ) ","if active : 
","if active :
",78.12,0.0,False
"def _validate ( self ) - > None : <TAB> # Paren validation and such <TAB> super ( Tuple , self ) . _validate ( ) <TAB> if len ( self . elements ) == 0 : <TAB> <TAB> if len ( self . lpar ) == 0 :<TAB> # assumes len(lpar) == len(rpar), via superclass <TAB> <TAB> <TAB> raise CSTValidationError ( <TAB> <TAB> <TAB> <TAB> "" A zero-length tuple must be wrapped in parentheses. "" <TAB> <TAB> <TAB> ) ","if len ( self . lpar ) == 0 : 
","if len ( self . lpar ) == 0 :
",100.0,100.0,True
"def _session_from_arg ( self , session_obj , lock_type = None ) : <TAB> if not isinstance ( session_obj , self . ISession ) : <TAB> <TAB> vm = self . _machine_from_arg ( session_obj ) <TAB> <TAB> lock_type = lock_type or self . LockType . null <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return vm . create_session ( lock_type ) <TAB> <TAB> return None <TAB> return session_obj ","if vm : 
","if vm :
",78.12,0.0,False
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not private and name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot : <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls ","if name != "" __init__ "" : 
","if meth is None :
",27.23,3.13,False
"def pdb ( message = "" "" ) : <TAB> """"""Fall into pdb."""""" <TAB> import pdb<TAB> # Required: we have just defined pdb as a function! <TAB> if app and not app . useIpython : <TAB> <TAB> # from leo.core.leoQt import QtCore <TAB> <TAB> # This is more portable. <TAB> <TAB> try : <TAB> <TAB> <TAB> import PyQt5 . QtCore as QtCore <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> import PyQt4 . QtCore as QtCore <TAB> <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> <TAB> QtCore = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # pylint: disable=no-member <TAB> <TAB> <TAB> QtCore . pyqtRemoveInputHook ( ) <TAB> if message : <TAB> <TAB> print ( message ) <TAB> pdb . set_trace ( ) ","if QtCore : 
","if QtCore and hasattr ( QtCore , "" pyqtRemoveInputHook "" ) :
",32.64,7.5,False
"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets : <TAB> <TAB> if b . get ( "" Logging "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB> <TAB> if not self_log and b [ "" Name "" ] . startswith ( "" cf-templates- "" ) : <TAB> <TAB> <TAB> yield ( b [ "" Name "" ] , "" "" ) ","if self_log : 
","if "" TargetBucket "" in b [ "" Logging "" ] :
",29.1,4.03,False
"def prepare_fields ( self ) : <TAB> # See clean() <TAB> for k , v in self . fields . items ( ) : <TAB> <TAB> v . _required = v . required <TAB> <TAB> v . required = False <TAB> <TAB> v . widget . is_required = False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v . _required = v . one_required <TAB> <TAB> <TAB> v . one_required = False <TAB> <TAB> <TAB> v . widget . enabled_locales = self . locales ","if isinstance ( v , I18nFormField ) : 
","if k == "" locale "" :
",26.83,6.57,False
"def __pack__ ( self ) : <TAB> new_values = [ ] <TAB> for i in xrange ( len ( self . __unpacked_data_elms__ ) ) : <TAB> <TAB> for key in self . __keys__ [ i ] : <TAB> <TAB> <TAB> new_val = getattr ( self , key ) <TAB> <TAB> <TAB> old_val = self . __unpacked_data_elms__ [ i ] <TAB> <TAB> <TAB> # In the case of Unions, when the first changed value <TAB> <TAB> <TAB> # is picked the loop is exited <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_values . append ( new_val ) <TAB> return struct . pack ( self . __format__ , * new_values ) ","if new_val != old_val : 
","if new_val != old_val :
",100.0,100.0,True
"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB> <TAB> main_vault_directory = os . path . join ( <TAB> <TAB> <TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB> <TAB> <TAB> <TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB> <TAB> <TAB> <TAB> <TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if cred : <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found . append ( cred ) <TAB> return pwd_found ","if os . path . exists ( main_vault_directory ) : 
","if os . path . isdir ( main_vault_directory ) :
",83.03,78.25,False
"def on_revision_plugin_revision_pre_save ( * * kwargs ) : <TAB> instance = kwargs [ "" instance "" ] <TAB> if kwargs . get ( "" created "" , False ) : <TAB> <TAB> update_previous_revision = ( <TAB> <TAB> <TAB> not instance . previous_revision <TAB> <TAB> <TAB> and instance . plugin <TAB> <TAB> <TAB> and instance . plugin . current_revision <TAB> <TAB> <TAB> and instance . plugin . current_revision != instance <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> instance . previous_revision = instance . plugin . current_revision <TAB> if not instance . revision_number : <TAB> <TAB> try : <TAB> <TAB> <TAB> previous_revision = instance . plugin . revision_set . latest ( ) <TAB> <TAB> <TAB> instance . revision_number = previous_revision . revision_number + 1 <TAB> <TAB> except RevisionPluginRevision . DoesNotExist : <TAB> <TAB> <TAB> instance . revision_number = 1 ","if update_previous_revision : 
","if update_previous_revision :
",78.12,100.0,True
"def __setattr__ ( self , name , value ) : <TAB> super ( ) . __setattr__ ( name , value ) <TAB> field = self . _fields . get ( name ) <TAB> if field : <TAB> <TAB> self . check_field_type ( field , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( f "" cannot set immutable  { name }  on  { self !r} "" ) ","if name in self . __ast_frozen_fields__ : 
","if self . immutable :
",35.56,3.44,False
"def _check_for_req_data ( data ) : <TAB> required_args = [ "" columns "" ] <TAB> for arg in required_args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True , make_json_response ( <TAB> <TAB> <TAB> <TAB> status = 400 , <TAB> <TAB> <TAB> <TAB> success = 0 , <TAB> <TAB> <TAB> <TAB> errormsg = gettext ( "" Could not find required parameter ( {} ). "" ) . format ( arg ) , <TAB> <TAB> <TAB> ) <TAB> return False , "" "" ","if arg not in data or ( isinstance ( data [ arg ] , list ) and len ( data [ arg ] ) < 1 ) : 
","if data . get ( arg ) is None :
",25.4,1.09,False
"def train_dict ( self , triples ) : <TAB> """"""Train a dict lemmatizer given training (word, pos, lemma) triples."""""" <TAB> # accumulate counter <TAB> ctr = Counter ( ) <TAB> ctr . update ( [ ( p [ 0 ] , p [ 1 ] , p [ 2 ] ) for p in triples ] ) <TAB> # find the most frequent mappings <TAB> for p , _ in ctr . most_common ( ) : <TAB> <TAB> w , pos , l = p <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . composite_dict [ ( w , pos ) ] = l <TAB> <TAB> if w not in self . word_dict : <TAB> <TAB> <TAB> self . word_dict [ w ] = l <TAB> return ","if ( w , pos ) not in self . composite_dict : 
","if ( w , pos ) not in self . composite_dict :
",100.0,100.0,True
"def render ( type_ , obj , context ) : <TAB> if type_ == "" foreign_key "" : <TAB> <TAB> return None <TAB> if type_ == "" column "" : <TAB> <TAB> if obj . name == "" y "" : <TAB> <TAB> <TAB> return None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" col( %s ) "" % obj . name <TAB> if type_ == "" type "" and isinstance ( obj , MySpecialType ) : <TAB> <TAB> context . imports . add ( "" from mypackage import MySpecialType "" ) <TAB> <TAB> return "" MySpecialType() "" <TAB> return "" render: %s "" % type_ ","elif obj . name == "" q "" : 
","elif obj . name == "" x "" :
",83.19,70.71,False
"def test_knows_when_stepping_back_possible ( self ) : <TAB> iterator = bidirectional_iterator . BidirectionalIterator ( [ 0 , 1 , 2 , 3 ] ) <TAB> commands = [ 0 , 1 , 0 , 0 , 1 , 1 , 0 , 0 , 0 , 0 ] <TAB> command_count = 0 <TAB> results = [ ] <TAB> for _ in iterator : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> iterator . step_back_on_next_iteration ( ) <TAB> <TAB> results . append ( iterator . can_step_back ( ) ) <TAB> <TAB> command_count + = 1 <TAB> assert results == [ False , True , False , True , True , True , False , True , True , True ] ","if commands [ command_count ] : 
","if command_count == 1 :
",27.91,23.36,False
"def flask_debug_true ( context ) : <TAB> if context . is_module_imported_like ( "" flask "" ) : <TAB> <TAB> if context . call_function_name_qual . endswith ( "" .run "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return bandit . Issue ( <TAB> <TAB> <TAB> <TAB> <TAB> severity = bandit . HIGH , <TAB> <TAB> <TAB> <TAB> <TAB> confidence = bandit . MEDIUM , <TAB> <TAB> <TAB> <TAB> <TAB> text = "" A Flask app appears to be run with debug=True,  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" which exposes the Werkzeug debugger and allows  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" the execution of arbitrary code. "" , <TAB> <TAB> <TAB> <TAB> <TAB> lineno = context . get_lineno_for_call_arg ( "" debug "" ) , <TAB> <TAB> <TAB> <TAB> ) ","if context . check_call_arg_value ( "" debug "" , "" True "" ) : 
","if not context . call_function_name_qual . endswith ( "" .debug "" ) :
",41.07,13.53,False
"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . _should_meta_profile : <TAB> <TAB> end_time = timezone . now ( ) <TAB> <TAB> exception_raised = exc_type is not None <TAB> <TAB> if exception_raised : <TAB> <TAB> <TAB> Logger . error ( <TAB> <TAB> <TAB> <TAB> "" Exception when performing meta profiling, dumping trace below "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> traceback . print_exception ( exc_type , exc_val , exc_tb ) <TAB> <TAB> request = getattr ( DataCollector ( ) . local , "" request "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> curr = request . meta_time or 0 <TAB> <TAB> <TAB> request . meta_time = curr + _time_taken ( self . start_time , end_time ) ","if request : 
","if request :
",78.12,0.0,False
"def get_job_offer ( ja_list ) : <TAB> ja_joff_map = { } <TAB> offers = frappe . get_all ( <TAB> <TAB> "" Job Offer "" , <TAB> <TAB> filters = [ [ "" job_applicant "" , "" IN "" , ja_list ] ] , <TAB> <TAB> fields = [ "" name "" , "" job_applicant "" , "" status "" , "" offer_date "" , "" designation "" ] , <TAB> ) <TAB> for offer in offers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ja_joff_map [ offer . job_applicant ] = [ offer ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ja_joff_map [ offer . job_applicant ] . append ( offer ) <TAB> return ja_joff_map ","if offer . job_applicant not in ja_joff_map . keys ( ) : 
","if offer . job_applicant not in ja_joff_map :
",61.65,70.38,False
"def _get_deepest ( self , t ) : <TAB> if isinstance ( t , list ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return t [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> for part in t : <TAB> <TAB> <TAB> <TAB> res = self . _get_deepest ( part ) <TAB> <TAB> <TAB> <TAB> if res : <TAB> <TAB> <TAB> <TAB> <TAB> return res <TAB> <TAB> <TAB> return None <TAB> return None ","if len ( t ) == 1 : 
","if len ( t ) == 1 :
",100.0,100.0,True
"def test_main ( self ) : <TAB> root = os . path . dirname ( mutagen . __path__ [ 0 ] ) <TAB> skip = [ os . path . join ( root , "" docs "" ) , os . path . join ( root , "" venv "" ) ] <TAB> for dirpath , dirnames , filenames in os . walk ( root ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> if filename . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> <TAB> path = os . path . join ( dirpath , filename ) <TAB> <TAB> <TAB> <TAB> self . _check_encoding ( path ) ","if any ( ( dirpath . startswith ( s + os . sep ) or s == dirpath ) for s in skip ) : 
","if dirpath in skip :
",27.55,0.4,False
"def xview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB> <TAB> value = float ( value ) <TAB> if mode is None : <TAB> <TAB> return self . hsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB> <TAB> frameWidth = self . innerframe . winfo_reqwidth ( ) <TAB> <TAB> self . _startX = value * float ( frameWidth ) <TAB> else :<TAB> # mode == 'scroll' <TAB> <TAB> clipperWidth = self . _clipper . winfo_width ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> jump = int ( clipperWidth * self . _jfraction ) <TAB> <TAB> else : <TAB> <TAB> <TAB> jump = clipperWidth <TAB> <TAB> self . _startX = self . _startX + value * jump <TAB> self . reposition ( ) ","if units == "" units "" : 
","if self . _jfraction is not None :
",26.98,5.67,False
"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB> <TAB> DEFAULT_DOMAIN_PATH , <TAB> <TAB> DEFAULT_STORIES_FILE , <TAB> <TAB> tmpdir . strpath , <TAB> <TAB> interpreter = RegexInterpreter ( ) , <TAB> <TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB> <TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if type ( policy ) == FormPolicy : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 2 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 5 ","if hasattr ( policy . featurizer , "" max_history "" ) : 
","if policy . featurizer . max_history is not None :
",34.36,19.28,False
"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> compare_entry = compare_entry . lower ( ) <TAB> <TAB> <TAB> compare_base = compare_base . lower ( ) <TAB> <TAB> if self . compare_entries ( compare_entry , compare_base ) : <TAB> <TAB> <TAB> if entry not in sugg : <TAB> <TAB> <TAB> <TAB> sugg . append ( entry ) <TAB> return sugg ","if self . settings . get ( IGNORE_CASE_SETTING ) : 
","if self . is_lowercase :
",34.86,10.22,False
"def marker_expr ( remaining ) : <TAB> if remaining and remaining [ 0 ] == "" ( "" : <TAB> <TAB> result , remaining = marker ( remaining [ 1 : ] . lstrip ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise SyntaxError ( "" unterminated parenthesis:  %s "" % remaining ) <TAB> <TAB> remaining = remaining [ 1 : ] . lstrip ( ) <TAB> else : <TAB> <TAB> lhs , remaining = marker_var ( remaining ) <TAB> <TAB> while remaining : <TAB> <TAB> <TAB> m = MARKER_OP . match ( remaining ) <TAB> <TAB> <TAB> if not m : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> op = m . groups ( ) [ 0 ] <TAB> <TAB> <TAB> remaining = remaining [ m . end ( ) : ] <TAB> <TAB> <TAB> rhs , remaining = marker_var ( remaining ) <TAB> <TAB> <TAB> lhs = { "" op "" : op , "" lhs "" : lhs , "" rhs "" : rhs } <TAB> <TAB> result = lhs <TAB> return result , remaining ","if remaining [ 0 ] != "" ) "" : 
","if remaining [ 0 ] == "" ) "" :
",83.03,70.17,False
"def __repr__ ( self ) : <TAB> """"""Dump the class data in the format of a .netrc file."""""" <TAB> rep = "" "" <TAB> for host in self . hosts . keys ( ) : <TAB> <TAB> attrs = self . hosts [ host ] <TAB> <TAB> rep = rep + "" machine  "" + host + "" \n \t login  "" + repr ( attrs [ 0 ] ) + "" \n "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rep = rep + "" account  "" + repr ( attrs [ 1 ] ) <TAB> <TAB> rep = rep + "" \t password  "" + repr ( attrs [ 2 ] ) + "" \n "" <TAB> for macro in self . macros . keys ( ) : <TAB> <TAB> rep = rep + "" macdef  "" + macro + "" \n "" <TAB> <TAB> for line in self . macros [ macro ] : <TAB> <TAB> <TAB> rep = rep + line <TAB> <TAB> rep = rep + "" \n "" <TAB> return rep ","if attrs [ 1 ] : 
","if attrs [ 1 ] :
",100.0,100.0,True
"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB> <TAB> id_ = required_key ( item , "" id "" ) <TAB> <TAB> controls_ids = required_key ( item , "" controls "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if controls_ids != "" all "" : <TAB> <TAB> <TAB> <TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> id_ = id_ , controls = str ( controls_ids ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError ( msg ) <TAB> <TAB> self . policies [ id_ ] = controls_ids ","if not isinstance ( controls_ids , list ) : 
","if id_ :
",26.26,3.65,False
"def __set__ ( self , obj , value ) :<TAB> # noqa <TAB> if ( <TAB> <TAB> value is not None <TAB> <TAB> and self . field . _currency_field . null <TAB> <TAB> and not isinstance ( value , MONEY_CLASSES + ( Decimal , ) ) <TAB> ) : <TAB> <TAB> # For nullable fields we need either both NULL amount and currency or both NOT NULL <TAB> <TAB> raise ValueError ( "" Missing currency value "" ) <TAB> if isinstance ( value , BaseExpression ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = self . prepare_value ( obj , value . value ) <TAB> <TAB> elif not isinstance ( value , Func ) : <TAB> <TAB> <TAB> validate_money_expression ( obj , value ) <TAB> <TAB> <TAB> prepare_expression ( value ) <TAB> else : <TAB> <TAB> value = self . prepare_value ( obj , value ) <TAB> obj . __dict__ [ self . field . name ] = value ","if isinstance ( value , Value ) : 
","if value . is_constant :
",26.99,7.49,False
"def Children ( self ) : <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB> <TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not is_list : <TAB> <TAB> <TAB> <TAB> children . append ( self . _properties [ property ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> children . extend ( self . _properties [ property ] ) <TAB> return children ","if is_strong and property in self . _properties : 
","if is_strong and property_type == "" object "" :
",31.58,37.6,False
"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self . select ( start ) <TAB> <TAB> <TAB> break <TAB> <TAB> if i > = len ( self . items ) : <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0 : <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self . select ( i ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i + = direction <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> start = 0 ","if start < 0 : 
","if i == start :
",28.65,10.68,False
"def setup_displace ( self ) : <TAB> self . displace_mod = None <TAB> self . displace_strength = 0.020 <TAB> for mod in self . obj . modifiers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . displace_mod = mod <TAB> <TAB> <TAB> self . displace_strength = mod . strength <TAB> if not self . displace_mod : <TAB> <TAB> bpy . ops . object . modifier_add ( type = "" DISPLACE "" ) <TAB> <TAB> self . displace_mod = self . obj . modifiers [ - 1 ] <TAB> <TAB> self . displace_mod . show_expanded = False <TAB> <TAB> self . displace_mod . strength = self . displace_strength <TAB> <TAB> self . displace_mod . show_render = False <TAB> <TAB> self . displace_mod . show_viewport = False ","if mod . type == "" DISPLACE "" : 
","if isinstance ( mod , bpy . ops . object . modifier_type ) :
",31.37,3.66,False
"def set_json_body ( cls , request_builder ) : <TAB> old_body = request_builder . info . pop ( "" data "" , { } ) <TAB> if isinstance ( old_body , abc . Mapping ) : <TAB> <TAB> body = request_builder . info . setdefault ( "" json "" , { } ) <TAB> <TAB> for path in old_body : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cls . _sequence_path_resolver ( path , old_body [ path ] , body ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> body [ path ] = old_body [ path ] <TAB> else : <TAB> <TAB> request_builder . info . setdefault ( "" json "" , old_body ) ","if isinstance ( path , tuple ) : 
","if isinstance ( old_body [ path ] , abc . Mapping ) :
",32.39,13.38,False
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" DBLL "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data . remove_dir ( dpath ) <TAB> <TAB> build_data . make_dir ( dpath ) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES : <TAB> <TAB> <TAB> downloadable_file . download_file ( dpath ) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data . mark_done ( dpath , version_string = version ) ","if build_data . built ( dpath ) : 
","if build_data . built ( dpath ) :
",100.0,100.0,True
"def test_prefix_lm ( self ) : <TAB> num_tries = 100 <TAB> original = "" This is a long test with lots of words to see if it works ok. "" <TAB> dataset = tf . data . Dataset . from_tensor_slices ( { "" text "" : [ original ] * num_tries } ) <TAB> dataset = prep . prefix_lm ( dataset ) <TAB> for data in test_utils . dataset_as_text ( dataset ) : <TAB> <TAB> inputs = data [ "" inputs "" ] . replace ( "" prefix:  "" , "" "" ) <TAB> <TAB> targets = data [ "" targets "" ] <TAB> <TAB> reconstructed = "" "" . join ( inputs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> reconstructed + = "" "" <TAB> <TAB> reconstructed + = "" "" . join ( targets ) <TAB> <TAB> self . assertEqual ( reconstructed , original ) ","if inputs : 
","if len ( targets ) > 1 :
",29.42,6.57,False
"def leading_whitespace ( self , inputstring ) : <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB> <TAB> if c in legal_indent_chars : <TAB> <TAB> <TAB> leading_ws . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . indchar = c <TAB> <TAB> elif c != self . indchar : <TAB> <TAB> <TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws ) ","if self . indchar is None : 
","if i == 0 :
",27.08,8.17,False
"def __init__ ( self , text ) : <TAB> self . mappings = { } <TAB> self . attributes = collections . defaultdict ( set ) <TAB> for stanza in _ParseTextProperties ( text ) : <TAB> <TAB> processor_id , single_values , multiple_values = self . _ParseStanza ( stanza ) <TAB> <TAB> if processor_id is None :<TAB> # can be 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . warn ( "" Processor id  %s  seen twice in  %s "" , processor_id , text ) <TAB> <TAB> <TAB> continue <TAB> <TAB> self . mappings [ processor_id ] = single_values <TAB> <TAB> for key , value in multiple_values . items ( ) : <TAB> <TAB> <TAB> self . attributes [ key ] . add ( value ) ","if processor_id in self . mappings : 
","if processor_id in self . mappings :
",100.0,100.0,True
"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> elif self . wait_counter < self . wait_cntr_max : <TAB> <TAB> <TAB> self . wait_counter + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB> <TAB> <TAB> <TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( self . poll_period ) ","if chunk is not None : 
","if self . wait_counter == self . wait_cntr_max :
",26.87,2.91,False
"def download ( self , prefetch = False ) : <TAB> while self . running : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ( path , start , end ) = self . prefetch_queue . get ( <TAB> <TAB> <TAB> <TAB> <TAB> True , 1 <TAB> <TAB> <TAB> <TAB> )<TAB> # 1 second time-out <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ( path , start , end ) = self . download_queue . get ( <TAB> <TAB> <TAB> <TAB> <TAB> True , 1 <TAB> <TAB> <TAB> <TAB> )<TAB> # 1 second time-out <TAB> <TAB> <TAB> self . download_data ( path , start , end ) <TAB> <TAB> <TAB> if prefetch : <TAB> <TAB> <TAB> <TAB> self . prefetch_queue . task_done ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . download_queue . task_done ( ) <TAB> <TAB> except Queue . Empty : <TAB> <TAB> <TAB> pass ","if prefetch : 
","if prefetch :
",78.12,0.0,False
"def process_messages ( self , found_files , messages ) : <TAB> for message in messages : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message . to_absolute_path ( self . config . workdir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> message . to_relative_path ( self . config . workdir ) <TAB> if self . config . blending : <TAB> <TAB> messages = blender . blend ( messages ) <TAB> filepaths = found_files . iter_module_paths ( abspath = False ) <TAB> return postfilter . filter_messages ( filepaths , self . config . workdir , messages ) ","if self . config . absolute_paths : 
","if self . config . absolute :
",82.41,63.19,False
"def set_indentation_params ( self , ispythonsource , guess = 1 ) : <TAB> if guess and ispythonsource : <TAB> <TAB> i = self . guess_indent ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . indentwidth = i <TAB> <TAB> if self . indentwidth != self . tabwidth : <TAB> <TAB> <TAB> self . usetabs = 0 <TAB> self . editwin . set_tabwidth ( self . tabwidth ) ","if 2 < = i < = 8 : 
","if i > = 0 :
",36.8,6.96,False
"def to_tree ( self , tagname = None , value = None , namespace = None ) : <TAB> namespace = getattr ( self , "" namespace "" , namespace ) <TAB> if value is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tagname = "" { %s } %s "" % ( namespace , tagname ) <TAB> <TAB> el = Element ( tagname ) <TAB> <TAB> el . text = safe_string ( value ) <TAB> <TAB> return el ","if namespace is not None : 
","if namespace is not None :
",100.0,100.0,True
"def execute ( self , argv : List ) - > bool : <TAB> if not argv : <TAB> <TAB> print ( "" ERROR: You must give at least one module to download. "" ) <TAB> <TAB> return False <TAB> for _arg in argv : <TAB> <TAB> result = module_server . search_module ( _arg ) <TAB> <TAB> CacheUpdater ( "" hub_download "" , _arg ) . start ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url = result [ 0 ] [ "" url "" ] <TAB> <TAB> <TAB> with log . ProgressBar ( "" Download  {} "" . format ( url ) ) as bar : <TAB> <TAB> <TAB> <TAB> for file , ds , ts in utils . download_with_progress ( url ) : <TAB> <TAB> <TAB> <TAB> <TAB> bar . update ( float ( ds ) / ts ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" ERROR: Could not find a HubModule named  {} "" . format ( _arg ) ) <TAB> return True ","if result : 
","if result :
",78.12,0.0,False
"def visit_type_type ( self , t : TypeType ) - > ProperType : <TAB> if isinstance ( self . s , TypeType ) : <TAB> <TAB> typ = self . meet ( t . item , self . s . item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> typ = TypeType . make_normalized ( typ , line = t . line ) <TAB> <TAB> return typ <TAB> elif isinstance ( self . s , Instance ) and self . s . type . fullname == "" builtins.type "" : <TAB> <TAB> return t <TAB> elif isinstance ( self . s , CallableType ) : <TAB> <TAB> return self . meet ( t , self . s ) <TAB> else : <TAB> <TAB> return self . default ( self . s ) ","if not isinstance ( typ , NoneType ) : 
","if typ . is_normalized ( ) :
",28.23,11.99,False
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . name ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" ) ","if len ( items ) > 1 : 
","if len ( items ) > 1 :
",100.0,100.0,True
"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB> <TAB> <TAB> except GObject . GError as ge : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB> <TAB> theme = Gtk . IconTheme ( ) <TAB> <TAB> if theme . has_icon ( icon_name ) : <TAB> <TAB> <TAB> return theme . load_icon ( icon_name , 24 , 0 ) ","if os . path . exists ( self . icon ) : 
","if os . path . isabs ( self . icon ) :
",86.85,73.49,False
"def setup_logger ( ) : <TAB> """"""Set up logger and add stdout handler"""""" <TAB> logging . setLoggerClass ( IPDLogger ) <TAB> logger = logging . getLogger ( "" icloudpd "" ) <TAB> has_stdout_handler = False <TAB> for handler in logger . handlers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> has_stdout_handler = True <TAB> if not has_stdout_handler : <TAB> <TAB> formatter = logging . Formatter ( <TAB> <TAB> <TAB> fmt = "" %(asctime)s %(levelname)-8s %(message)s "" , datefmt = "" % Y- % m- %d % H: % M: % S "" <TAB> <TAB> ) <TAB> <TAB> stdout_handler = logging . StreamHandler ( stream = sys . stdout ) <TAB> <TAB> stdout_handler . setFormatter ( formatter ) <TAB> <TAB> stdout_handler . name = "" stdoutLogger "" <TAB> <TAB> logger . addHandler ( stdout_handler ) <TAB> return logger ","if handler . name == "" stdoutLogger "" : 
","if isinstance ( handler , IPDLogger ) :
",26.7,5.66,False
"def process_extra_fields ( self ) : <TAB> if self . instance . pk is not None : <TAB> <TAB> if self . cleaned_data . get ( "" initialize "" , None ) : <TAB> <TAB> <TAB> self . instance . initialize ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . instance . update_from_templates ( ) ","if self . cleaned_data . get ( "" update "" , None ) or not self . instance . stores . count ( ) : 
","elif self . cleaned_data . get ( "" update "" , None ) :
",58.42,44.88,False
"def testFunctions ( self ) : <TAB> from zim . formats . wiki import match_url , is_url <TAB> for input , input_is_url , tail in self . examples : <TAB> <TAB> if input_is_url : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , input [ : - len ( tail ) ] ) <TAB> <TAB> <TAB> <TAB> self . assertFalse ( is_url ( input ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , input ) <TAB> <TAB> <TAB> <TAB> self . assertTrue ( is_url ( input ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( match_url ( input ) , None ) <TAB> <TAB> <TAB> self . assertFalse ( is_url ( input ) ) ","if tail : 
","if tail :
",78.12,0.0,False
"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB> <TAB> username = user [ 0 ] <TAB> <TAB> settings = user [ 1 ] <TAB> <TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB> <TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" joined "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB> <TAB> <TAB> elif "" left "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . removeUser ( username ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _client . userlist . modUser ( username , room , file_ ) ","if "" event "" in settings : 
","if settings [ "" user_id "" ] :
",33.47,6.27,False
"def restoreTerminals ( self , state ) : <TAB> for name in list ( self . terminals . keys ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . removeTerminal ( name ) <TAB> for name , opts in state . items ( ) : <TAB> <TAB> if name in self . terminals : <TAB> <TAB> <TAB> term = self [ name ] <TAB> <TAB> <TAB> term . setOpts ( * * opts ) <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> opts = strDict ( opts ) <TAB> <TAB> <TAB> self . addTerminal ( name , * * opts ) <TAB> <TAB> except : <TAB> <TAB> <TAB> printExc ( "" Error restoring terminal  %s  ( %s ): "" % ( str ( name ) , str ( opts ) ) ) ","if name not in state : 
","if name in state :
",56.72,40.94,False
"def htmlify ( path , text ) : <TAB> fname = os . path . basename ( path ) <TAB> if any ( ( fnmatch . fnmatchcase ( fname , p ) for p in _patterns ) ) : <TAB> <TAB> # Get file_id, skip if not in database <TAB> <TAB> sql = "" SELECT files.id FROM files WHERE path = ? LIMIT 1 "" <TAB> <TAB> row = _conn . execute ( sql , ( path , ) ) . fetchone ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ClangHtmlifier ( _tree , _conn , path , text , row [ 0 ] ) <TAB> return None ","if row : 
","if row :
",78.12,0.0,False
"def autoformat_filter_conv2d ( fsize , in_depth , out_depth ) : <TAB> if isinstance ( fsize , int ) : <TAB> <TAB> return [ fsize , fsize , in_depth , out_depth ] <TAB> elif isinstance ( fsize , ( tuple , list , tf . TensorShape ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ fsize [ 0 ] , fsize [ 1 ] , in_depth , out_depth ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" filter length error:  "" <TAB> <TAB> <TAB> <TAB> + str ( len ( fsize ) ) <TAB> <TAB> <TAB> <TAB> + "" , only a length of 2 is supported. "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" filter format error:  "" + str ( type ( fsize ) ) ) ","if len ( fsize ) == 2 : 
","if len ( fsize ) == 2 :
",100.0,100.0,True
"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if count : <TAB> <TAB> <TAB> <TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new + = bytes ( [ cur ] ) <TAB> return new ","if not cur : 
","if cur == b "" \x00 "" :
",28.4,5.52,False
"def is_clean ( self ) : <TAB> acceptable_statuses = { "" external "" , "" unversioned "" } <TAB> root = self . _capture_output ( "" status "" , "" --quiet "" ) <TAB> for elem in root . findall ( "" ./target/entry "" ) : <TAB> <TAB> status = elem . find ( "" ./wc-status "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> log . debug ( "" Path  %s  is  %s "" , elem . get ( "" path "" ) , status . get ( "" item "" ) ) <TAB> <TAB> return False <TAB> return True ","if status . get ( "" item "" , None ) in acceptable_statuses : 
","if status . get ( "" item "" ) not in acceptable_statuses :
",63.33,69.01,False
"def process ( self , body , message ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> ' Received an unexpected type  "" %s ""  for payload. ' % type ( body ) <TAB> <TAB> <TAB> ) <TAB> <TAB> response = self . _handler . pre_ack_process ( body ) <TAB> <TAB> self . _dispatcher . dispatch ( self . _process_message , response ) <TAB> except : <TAB> <TAB> LOG . exception ( "" %s  failed to process message:  %s "" , self . __class__ . __name__ , body ) <TAB> finally : <TAB> <TAB> # At this point we will always ack a message. <TAB> <TAB> message . ack ( ) ","if not isinstance ( body , self . _handler . message_type ) : 
","if not isinstance ( body , self . _handler . post_ack_process_body ) :
",89.71,55.57,False
"def page_file ( self , page ) : <TAB> try : <TAB> <TAB> page = self . notebook . get_page ( page ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return page . source <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> except PageNotFoundError : <TAB> <TAB> return None ","if hasattr ( page , "" source "" ) and isinstance ( page . source , File ) : 
","if page . source :
",29.76,2.75,False
"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif silhouette < = best_silhouette : <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a , best_silhouette , best_k ","if best_silhouette is None : 
","if a > best_silhouette :
",28.38,27.78,False
"def _cancel_tasks_for_partitions ( self , to_cancel_partitions ) : <TAB> # type: (Iterable[str]) -> None <TAB> with self . _lock : <TAB> <TAB> _LOGGER . debug ( <TAB> <TAB> <TAB> "" EventProcessor  %r  tries to cancel partitions  %r "" , <TAB> <TAB> <TAB> self . _id , <TAB> <TAB> <TAB> to_cancel_partitions , <TAB> <TAB> ) <TAB> <TAB> for partition_id in to_cancel_partitions : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _consumers [ partition_id ] . stop = True <TAB> <TAB> <TAB> <TAB> _LOGGER . info ( <TAB> <TAB> <TAB> <TAB> <TAB> "" EventProcessor  %r  has cancelled partition  %r "" , <TAB> <TAB> <TAB> <TAB> <TAB> self . _id , <TAB> <TAB> <TAB> <TAB> <TAB> partition_id , <TAB> <TAB> <TAB> <TAB> ) ","if partition_id in self . _consumers : 
","if partition_id in self . _consumers :
",100.0,100.0,True
"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else : <TAB> <TAB> <TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB> <TAB> return None <TAB> elif len ( result ) == 1 : <TAB> <TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB> <TAB> solids = [ p . item for p in result ] <TAB> <TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB> <TAB> if refine : <TAB> <TAB> <TAB> solid = solid . removeSplitter ( ) <TAB> <TAB> return solid ","if result is None : 
","if result is None :
",100.0,100.0,True
"def geli_detach ( self , pool , clear = False ) : <TAB> failed = 0 <TAB> for ed in self . middleware . call_sync ( <TAB> <TAB> "" datastore.query "" , <TAB> <TAB> "" storage.encrypteddisk "" , <TAB> <TAB> [ ( "" encrypted_volume "" , "" = "" , pool [ "" id "" ] ) ] , <TAB> ) : <TAB> <TAB> dev = ed [ "" encrypted_provider "" ] <TAB> <TAB> try : <TAB> <TAB> <TAB> self . geli_detach_single ( dev ) <TAB> <TAB> except Exception as ee : <TAB> <TAB> <TAB> self . logger . warn ( str ( ee ) ) <TAB> <TAB> <TAB> failed + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . geli_clear ( dev ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> self . logger . warn ( "" Failed to clear  %s :  %s "" , dev , e ) <TAB> return failed ","if clear : 
","if clear :
",78.12,0.0,False
def compute_lengths ( batch_sizes ) : <TAB> tmp_batch_sizes = np . copy ( batch_sizes ) <TAB> lengths = [ ] <TAB> while True : <TAB> <TAB> c = np . count_nonzero ( tmp_batch_sizes > 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> lengths . append ( c ) <TAB> <TAB> tmp_batch_sizes = np . array ( [ b - 1 for b in tmp_batch_sizes ] ) <TAB> return np . array ( lengths ) ,"if c == 0 : 
","if c == 0 :
",100.0,100.0,True
"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flatten_items . append ( b "" "" ) <TAB> <TAB> elif isinstance ( item , bytes ) : <TAB> <TAB> <TAB> flatten_items . append ( item ) <TAB> <TAB> elif isinstance ( item , int ) : <TAB> <TAB> <TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB> <TAB> elif isinstance ( item , list ) : <TAB> <TAB> <TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items ) ","if item is None : 
","if isinstance ( item , str ) :
",27.52,7.27,False
"def update ( self , new_config ) : <TAB> jsonschema . validate ( new_config , self . schema ) <TAB> config = { } <TAB> for k , v in new_config . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> config [ k ] = self [ k ] <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ k ] = v <TAB> self . _config = config <TAB> self . changed ( ) ","if k in self . schema . get ( "" secret "" , [ ] ) and v == SECRET_PLACEHOLDER : 
","if k in self :
",31.4,1.58,False
"def _encode_numpy ( values , uniques = None , encode = False , check_unknown = True ) : <TAB> # only used in _encode below, see docstring there for details <TAB> if uniques is None : <TAB> <TAB> if encode : <TAB> <TAB> <TAB> uniques , encoded = np . unique ( values , return_inverse = True ) <TAB> <TAB> <TAB> return uniques , encoded <TAB> <TAB> else : <TAB> <TAB> <TAB> # unique sorts <TAB> <TAB> <TAB> return np . unique ( values ) <TAB> if encode : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> diff = _encode_check_unknown ( values , uniques ) <TAB> <TAB> <TAB> if diff : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" y contains previously unseen labels:  %s "" % str ( diff ) ) <TAB> <TAB> encoded = np . searchsorted ( uniques , values ) <TAB> <TAB> return uniques , encoded <TAB> else : <TAB> <TAB> return uniques ","if check_unknown : 
","if check_unknown :
",78.12,100.0,True
"def restore_dtype_and_merge ( arr , input_dtype ) : <TAB> if isinstance ( arr , list ) : <TAB> <TAB> arr = [ restore_dtype_and_merge ( arr_i , input_dtype ) for arr_i in arr ] <TAB> <TAB> shapes = [ arr_i . shape for arr_i in arr ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arr = np . array ( arr ) <TAB> if ia . is_np_array ( arr ) : <TAB> <TAB> arr = iadt . restore_dtypes_ ( arr , input_dtype ) <TAB> return arr ","if len ( set ( shapes ) ) == 1 : 
","if not np . allclose ( arr , shapes ) :
",27.6,8.61,False
"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB> <TAB> if diff_min is not None and diff_min != 0 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d ","if is_prev : 
","if diff_min < 59 :
",30.19,8.64,False
"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v ) ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def __createItemAttribute ( self , item , function , preload ) : <TAB> """"""Create the new widget, add it, and remove the old one"""""" <TAB> try : <TAB> <TAB> self . __stack . addWidget ( function ( item , preload ) ) <TAB> <TAB> # Remove the widget <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> oldWidget = self . __stack . widget ( 0 ) <TAB> <TAB> <TAB> self . __stack . removeWidget ( oldWidget ) <TAB> <TAB> <TAB> oldWidget . setParent ( QtWidgets . QWidget ( ) ) <TAB> except Exception as e : <TAB> <TAB> list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) ) ","if self . __stack . count ( ) > 1 : 
","if self . __stack . widget ( 0 ) is not None :
",50.38,43.75,False
"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url = url [ 8 : ] <TAB> <TAB> if not url . startswith ( "" http:// "" ) : <TAB> <TAB> <TAB> url = "" http:// "" + url <TAB> <TAB> if playlist : <TAB> <TAB> <TAB> download_playlist ( <TAB> <TAB> <TAB> <TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ","if url . startswith ( "" https:// "" ) : 
","if url . startswith ( "" http:// "" ) :
",83.03,76.12,False
"def add_enc_zero ( obj , enc_zero ) : <TAB> if isinstance ( obj , np . ndarray ) : <TAB> <TAB> return obj + enc_zero <TAB> elif isinstance ( obj , Iterable ) : <TAB> <TAB> return type ( obj ) ( <TAB> <TAB> <TAB> EncryptModeCalculator . add_enc_zero ( o , enc_zero ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else o + enc_zero <TAB> <TAB> <TAB> for o in obj <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return obj + enc_zero ","if isinstance ( o , Iterable ) 
","if isinstance ( o , np . ndarray )
",53.0,46.71,False
"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> if ( w , pos ) in self . composite_dict : <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> elif w in self . word_dict : <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas ","if lemma is None : 
","elif pred is None :
",46.76,39.76,False
"def replace_to_6hex ( color ) : <TAB> """"""Validate and replace 3hex colors to 6hex ones."""""" <TAB> if match ( r "" ^#(?:[0-9a-fA-F] {3} ) { 1,2}$ "" , color ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> color = "" # {0} {0} {1} {1} {2} {2} "" . format ( color [ 1 ] , color [ 2 ] , color [ 3 ] ) <TAB> <TAB> return color <TAB> else : <TAB> <TAB> exit ( _ ( "" Invalid color  {} "" ) . format ( color ) ) ","if len ( color ) == 4 : 
","if color [ 0 ] == "" # "" and color [ 1 ] != color [ 2 ] :
",26.4,4.34,False
"def computeMachineName ( self ) : <TAB> """"""Return the name of the current machine, i.e, HOSTNAME."""""" <TAB> # This is prepended to leoSettings.leo or myLeoSettings.leo <TAB> # to give the machine-specific setting name. <TAB> # How can this be worth doing?? <TAB> try : <TAB> <TAB> import os <TAB> <TAB> name = os . getenv ( "" HOSTNAME "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = os . getenv ( "" COMPUTERNAME "" ) <TAB> <TAB> if not name : <TAB> <TAB> <TAB> import socket <TAB> <TAB> <TAB> name = socket . gethostname ( ) <TAB> except Exception : <TAB> <TAB> name = "" "" <TAB> return name ","if not name : 
","if not name :
",100.0,100.0,True
"def _git_dirty_working_directory ( q , include_untracked ) : <TAB> try : <TAB> <TAB> cmd = [ "" git "" , "" status "" , "" --porcelain "" ] <TAB> <TAB> if include_untracked : <TAB> <TAB> <TAB> cmd + = [ "" --untracked-files=normal "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> cmd + = [ "" --untracked-files=no "" ] <TAB> <TAB> status = _run_git_cmd ( cmd ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> q . put ( bool ( status ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> q . put ( None ) <TAB> except ( subprocess . CalledProcessError , OSError , FileNotFoundError ) : <TAB> <TAB> q . put ( None ) ","if status is not None : 
","if status :
",29.58,0.0,False
"def runAndWaitWork ( server , work ) : <TAB> work . touch ( ) <TAB> thr = threading . Thread ( target = workThread , args = ( server , work ) ) <TAB> thr . setDaemon ( True ) <TAB> thr . start ( ) <TAB> # Wait around for done or timeout <TAB> while True : <TAB> <TAB> if work . isTimedOut ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> # If the thread is done, lets get out. <TAB> <TAB> if not thr . isAlive ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> # If our parent, or some thread closes stdin, <TAB> <TAB> # time to pack up and go. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( 2 ) ","if sys . stdin . closed : 
","if thr . isAlive ( ) :
",33.54,8.64,False
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> if DEBUG_COMM : <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise ","if ignore_non_errors and is_noerr ( e ) : 
","elif ignore_non_errors and is_errors ( e ) :
",60.1,69.98,False
"def PrintHeader ( self ) :<TAB> # print the header array <TAB> if self . draw == False : <TAB> <TAB> return <TAB> for val in self . parent . header : <TAB> <TAB> self . SetPrintFont ( val [ "" Font "" ] ) <TAB> <TAB> header_indent = val [ "" Indent "" ] * self . pwidth <TAB> <TAB> text = val [ "" Text "" ] <TAB> <TAB> htype = val [ "" Type "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> addtext = self . GetDate ( ) <TAB> <TAB> elif htype == "" Date & Time "" : <TAB> <TAB> <TAB> addtext = self . GetDateTime ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> addtext = "" "" <TAB> <TAB> self . OutTextPageWidth ( <TAB> <TAB> <TAB> text + addtext , self . pheader_margin , val [ "" Align "" ] , header_indent , True <TAB> <TAB> ) ","if htype == "" Date "" : 
","if htype == "" Date & Date "" :
",84.32,63.89,False
"def get_intersect_all ( self , refine = False ) : <TAB> result = None <TAB> for source , parts in self . _per_source . items ( ) : <TAB> <TAB> if result is None : <TAB> <TAB> <TAB> result = parts <TAB> <TAB> else : <TAB> <TAB> <TAB> result . intersection_update ( parts ) <TAB> if not result : <TAB> <TAB> return None <TAB> elif len ( result ) == 1 : <TAB> <TAB> return list ( result ) [ 0 ] . item <TAB> else : <TAB> <TAB> solids = [ p . item for p in result ] <TAB> <TAB> solid = solids [ 0 ] . fuse ( solids [ 1 : ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> solid = solid . removeSplitter ( ) <TAB> <TAB> return solid ","if refine : 
","if refine :
",78.12,0.0,False
"def captured_updateNode ( self , context ) : <TAB> if not self . updating_name_from_pointer : <TAB> <TAB> font_datablock = self . get_bpy_data_from_name ( self . fontname , bpy . data . fonts ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . font_pointer = font_datablock <TAB> <TAB> <TAB> updateNode ( self , context ) ","if font_datablock : 
","if font_datablock :
",78.12,100.0,True
"def __add__ ( self , other ) : <TAB> if isinstance ( other , Vector2 ) : <TAB> <TAB> # Vector + Vector -> Vector <TAB> <TAB> # Vector + Point -> Point <TAB> <TAB> # Point + Point -> Vector <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _class = Vector2 <TAB> <TAB> else : <TAB> <TAB> <TAB> _class = Point2 <TAB> <TAB> return _class ( self . x + other . x , self . y + other . y ) <TAB> else : <TAB> <TAB> assert hasattr ( other , "" __len__ "" ) and len ( other ) == 2 <TAB> <TAB> return Vector2 ( self . x + other [ 0 ] , self . y + other [ 1 ] ) ","if self . __class__ is other . __class__ : 
","if self . __class__ is other . __class__ :
",100.0,100.0,True
"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setting_values . update ( <TAB> <TAB> <TAB> <TAB> self . _flatten_settings_from_form ( <TAB> <TAB> <TAB> <TAB> <TAB> settings , field , form_values [ field . _name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif field . _name in settings : <TAB> <TAB> <TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values ","if isinstance ( field , _ContainerMixin ) : 
","if isinstance ( field , settings_field ) :
",79.9,46.71,False
"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> if hasattr ( a , "" includedirs "" ) : <TAB> <TAB> <TAB> a = a . includedirs <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidArguments ( <TAB> <TAB> <TAB> <TAB> "" Include directory to be added is not an include directory object. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids . append ( a ) <TAB> self . include_dirs + = ids ","if not isinstance ( a , IncludeDirs ) : 
","if not isinstance ( a , ( File , File ) ) :
",52.45,42.8,False
"def _clip_array ( array , config ) : <TAB> if "" threshold "" in config . keys ( ) : <TAB> <TAB> threshold = config [ "" threshold "" ] <TAB> else : <TAB> <TAB> abs_array = np . max ( np . abs ( array ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return array <TAB> <TAB> threshold = np . percentile ( np . abs ( array ) , 99.99 ) <TAB> return np . clip ( array , - threshold , threshold ) ","if abs_array < 1.0 : 
","if abs_array > = threshold :
",30.74,36.56,False
def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield from dfs ( w ) <TAB> <TAB> elif w not in identified : <TAB> <TAB> <TAB> while index [ w ] < boundaries [ - 1 ] : <TAB> <TAB> <TAB> <TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB> <TAB> boundaries . pop ( ) <TAB> <TAB> scc = set ( stack [ index [ v ] : ] ) <TAB> <TAB> del stack [ index [ v ] : ] <TAB> <TAB> identified . update ( scc ) <TAB> <TAB> yield scc ,"if w not in index : 
","if len ( boundaries ) == 1 :
",27.04,5.67,False
"def create_balancer ( <TAB> self , name , members , protocol = "" http "" , port = 80 , algorithm = DEFAULT_ALGORITHM ) : <TAB> balancer = self . ex_create_balancer_nowait ( name , members , protocol , port , algorithm ) <TAB> timeout = 60 * 20 <TAB> waittime = 0 <TAB> interval = 2 * 15 <TAB> if balancer . id is not None : <TAB> <TAB> return balancer <TAB> else : <TAB> <TAB> while waittime < timeout : <TAB> <TAB> <TAB> balancers = self . list_balancers ( ) <TAB> <TAB> <TAB> for i in balancers : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> waittime + = interval <TAB> <TAB> <TAB> time . sleep ( interval ) <TAB> raise Exception ( "" Failed to get id "" ) ","if i . name == balancer . name and i . id is not None : 
","if i . id is not None :
",58.84,30.7,False
"def handle ( self , scope : Scope , receive : Receive , send : Send ) - > None : <TAB> if self . methods and scope [ "" method "" ] not in self . methods : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise HTTPException ( status_code = 405 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = PlainTextResponse ( "" Method Not Allowed "" , status_code = 405 ) <TAB> <TAB> await response ( scope , receive , send ) <TAB> else : <TAB> <TAB> await self . app ( scope , receive , send ) ","if "" app "" in scope : 
","if self . http_error :
",27.14,7.81,False
"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB> if isinstance ( d , tuple ) and len ( d ) == 2 : <TAB> <TAB> <TAB> result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( d ) <TAB> return result ","elif isinstance ( d , basestring ) : 
","elif isinstance ( d , str ) :
",79.9,59.46,False
"def register_adapters ( ) : <TAB> global adapters_registered <TAB> if adapters_registered is True : <TAB> <TAB> return <TAB> try : <TAB> <TAB> import pkg_resources <TAB> <TAB> packageDir = pkg_resources . resource_filename ( "" pyamf "" , "" adapters "" ) <TAB> except : <TAB> <TAB> packageDir = os . path . dirname ( __file__ ) <TAB> for f in glob . glob ( os . path . join ( packageDir , "" *.py "" ) ) : <TAB> <TAB> mod = os . path . basename ( f ) . split ( os . path . extsep , 1 ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> register_adapter ( mod [ 1 : ] . replace ( "" _ "" , "" . "" ) , PackageImporter ( mod ) ) <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> pass <TAB> adapters_registered = True ","if mod == "" __init__ "" or not mod . startswith ( "" _ "" ) : 
","if not mod . startswith ( "" __ "" ) :
",58.07,35.68,False
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> if module is None or not hasattr ( module , attr ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr ( module , "" aliases "" ) : <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( ) ","if alias not in excluded_aliases : 
","if alias not in excluded_aliases :
",100.0,100.0,True
"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB> <TAB> if item . has_variations : <TAB> <TAB> <TAB> if not any ( var . item == item for var in variations ) : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) ","if event != item . event : 
","if not event . has_variations :
",33.71,7.81,False
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return element <TAB> <TAB> if element [ 3 ] and element [ 4 ] : <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> if not isinstance ( i , int ) : <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx ","if idx == num : 
","if idx == 0 :
",39.48,53.73,False
"def check ( chip , xeddb , chipdb ) : <TAB> all_inst = [ ] <TAB> undoc = [ ] <TAB> for inst in xeddb . recs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if inst . undocumented : <TAB> <TAB> <TAB> <TAB> undoc . append ( inst ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> all_inst . append ( inst ) <TAB> return ( all_inst , undoc ) ","if inst . isa_set in chipdb [ chip ] : 
","if inst . docid == chipdb . docid :
",35.98,14.53,False
"def get_all_topic_src_files ( self ) : <TAB> """"""Retrieves the file paths of all the topics in directory"""""" <TAB> topic_full_paths = [ ] <TAB> topic_names = os . listdir ( self . topic_dir ) <TAB> for topic_name in topic_names : <TAB> <TAB> # Do not try to load hidden files. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> topic_full_path = os . path . join ( self . topic_dir , topic_name ) <TAB> <TAB> <TAB> # Ignore the JSON Index as it is stored with topic files. <TAB> <TAB> <TAB> if topic_full_path != self . index_file : <TAB> <TAB> <TAB> <TAB> topic_full_paths . append ( topic_full_path ) <TAB> return topic_full_paths ","if not topic_name . startswith ( "" . "" ) : 
","if not topic_name . startswith ( "" JSON Index "" ) :
",83.58,69.98,False
"def _get_element ( dom_msi , tag_name , name = None , id_ = None ) : <TAB> """"""Get a xml element defined on Product."""""" <TAB> product = dom_msi . getElementsByTagName ( "" Product "" ) [ 0 ] <TAB> elements = product . getElementsByTagName ( tag_name ) <TAB> for element in elements : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> element . getAttribute ( "" Name "" ) == name <TAB> <TAB> <TAB> <TAB> and element . getAttribute ( "" Id "" ) == id_ <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return element <TAB> <TAB> elif id_ : <TAB> <TAB> <TAB> if element . getAttribute ( "" Id "" ) == id_ : <TAB> <TAB> <TAB> <TAB> return element ","if name and id_ : 
","if name :
",31.47,0.0,False
"def __init__ ( self , * models ) : <TAB> super ( ) . __init__ ( ) <TAB> self . models = ModuleList ( models ) <TAB> for m in models : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" IndependentModelList currently only supports models that have a likelihood (e.g. ExactGPs) "" <TAB> <TAB> <TAB> ) <TAB> self . likelihood = LikelihoodList ( * [ m . likelihood for m in models ] ) ","if not hasattr ( m , "" likelihood "" ) : 
","if isinstance ( m , IndependentModelList ) :
",31.15,18.59,False
"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as fileobj : <TAB> <TAB> <TAB> header = fileobj . read ( 4 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> fileobj . read ( 1 )<TAB> # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj . read ( 1 ) <TAB> <TAB> <TAB> <TAB> if binascii . hexlify ( ftype ) == oxlitype : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError : <TAB> <TAB> return False ","if header == b "" OXLI "" : 
","if header == b "" version "" :
",79.9,66.06,False
"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB> <TAB> key = str ( k ) <TAB> <TAB> if "" / "" not in key : <TAB> <TAB> <TAB> key + = "" /tcp "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result ","if isinstance ( v , list ) : 
","if isinstance ( v , list ) :
",100.0,100.0,True
"def input_data ( self ) : <TAB> gen = self . config . generator <TAB> # don't try running the generator if we specify an output file explicitly, <TAB> # otherwise generator may segfault and we end up returning the output file anyway <TAB> if gen and ( not self . config [ "" out "" ] or not self . config [ "" in "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _run_generator ( gen , args = self . config . generator_args ) <TAB> <TAB> if self . _generated [ 0 ] : <TAB> <TAB> <TAB> return self . _generated [ 0 ] <TAB> # in file is optional <TAB> return ( <TAB> <TAB> self . _normalize ( self . problem . problem_data [ self . config [ "" in "" ] ] ) <TAB> <TAB> if self . config [ "" in "" ] <TAB> <TAB> else b "" "" <TAB> ) ","if self . _generated is None : 
","if self . _generated :
",52.91,56.98,False
"def __new__ ( cls , * tasks , * * kwargs ) : <TAB> # This forces `chain(X, Y, Z)` to work the same way as `X | Y | Z` <TAB> if not kwargs and tasks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tasks = tasks [ 0 ] if len ( tasks ) == 1 else tasks <TAB> <TAB> <TAB> return reduce ( operator . or_ , tasks ) <TAB> return super ( chain , cls ) . __new__ ( cls , * tasks , * * kwargs ) ","if len ( tasks ) != 1 or is_list ( tasks [ 0 ] ) : 
","if isinstance ( tasks , list ) :
",26.83,4.37,False
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> if file_sources_as_dict is not None : <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources ","if file_sources is None : 
","if file_sources is None :
",100.0,100.0,True
"def InitializeColours ( self ) : <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB> <TAB> c = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _customColours [ i ] = wx . WHITE <TAB> <TAB> if c == curr : <TAB> <TAB> <TAB> self . _colourSelection = i ","if c . IsOk ( ) : 
","if c == wx . WHITE :
",34.28,13.13,False
"def convert_obj_into_marshallable ( self , obj ) : <TAB> if isinstance ( obj , self . marshalable_types ) : <TAB> <TAB> return obj <TAB> if isinstance ( obj , array . array ) : <TAB> <TAB> if obj . typecode == "" c "" : <TAB> <TAB> <TAB> return obj . tostring ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return obj . tounicode ( ) <TAB> <TAB> return obj . tolist ( ) <TAB> return self . class_to_dict ( obj ) ","if obj . typecode == "" u "" : 
","if obj . typecode == "" b "" :
",83.19,70.71,False
"def run ( self ) : <TAB> self . run_command ( "" egg_info "" ) <TAB> from glob import glob <TAB> for pattern in self . match : <TAB> <TAB> pattern = self . distribution . get_name ( ) + "" * "" + pattern <TAB> <TAB> files = glob ( os . path . join ( self . dist_dir , pattern ) ) <TAB> <TAB> files = [ ( os . path . getmtime ( f ) , f ) for f in files ] <TAB> <TAB> files . sort ( ) <TAB> <TAB> files . reverse ( ) <TAB> <TAB> log . info ( "" %d  file(s) matching  %s "" , len ( files ) , pattern ) <TAB> <TAB> files = files [ self . keep : ] <TAB> <TAB> for ( t , f ) in files : <TAB> <TAB> <TAB> log . info ( "" Deleting  %s "" , f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . unlink ( f ) ","if not self . dry_run : 
","if os . path . isfile ( f ) :
",33.29,5.52,False
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> if token . token_type == TOKEN_TEXT : <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars ","elif token . token_type == TOKEN_VAR : 
","elif token . token_type == TOKEN_VAR :
",100.0,100.0,True
"def _handle_raise ( self , values , is_NAs , origins ) : <TAB> for is_NA , origin in zip ( is_NAs , origins ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> "" Missing values detected. If you want rows with missing  "" <TAB> <TAB> <TAB> <TAB> "" values to be automatically deleted in a list-wise  "" <TAB> <TAB> <TAB> <TAB> "" manner (not recommended), please set dropna=True in  "" <TAB> <TAB> <TAB> <TAB> "" the Bambi Model initialization. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise PatsyError ( msg , origin ) <TAB> return values ","if np . any ( is_NA ) : 
","if not values or is_NA :
",26.98,18.19,False
"def add_node_data ( node_array , ntwk ) : <TAB> node_ntwk = nx . Graph ( ) <TAB> newdata = { } <TAB> for idx , data in ntwk . nodes ( data = True ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newdata [ "" value "" ] = node_array [ int ( idx ) - 1 ] <TAB> <TAB> <TAB> data . update ( newdata ) <TAB> <TAB> <TAB> node_ntwk . add_node ( int ( idx ) , * * data ) <TAB> return node_ntwk ","if not int ( idx ) == 0 : 
","if int ( idx ) > 0 :
",55.73,33.28,False
"def safe_parse_date ( date_hdr ) : <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try : <TAB> <TAB> if "" ; "" in date_hdr : <TAB> <TAB> <TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB> <TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB> <TAB> return None ","if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) : 
","if msg_ts < = 0 :
",25.73,3.56,False
"def _route_db ( self , model , * * hints ) : <TAB> chosen_db = None <TAB> for router in self . routers : <TAB> <TAB> try : <TAB> <TAB> <TAB> method = getattr ( router , action ) <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> # If the router doesn't have a method, skip to the next one. <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> chosen_db = method ( model , * * hints ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return chosen_db <TAB> try : <TAB> <TAB> return hints [ "" instance "" ] . _state . db or DEFAULT_DB_ALIAS <TAB> except KeyError : <TAB> <TAB> return DEFAULT_DB_ALIAS ","if chosen_db : 
","if chosen_db :
",78.12,100.0,True
"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB> <TAB> if not ignore_first_level : <TAB> <TAB> <TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB> <TAB> <TAB> res . extend ( keys ) <TAB> <TAB> for key in struct : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB> <TAB> for item in struct : <TAB> <TAB> <TAB> res . extend ( get_keys ( item ) ) <TAB> return res ","if key in IGNORED_KEYS : 
","if key in IGNORED_FIRST_LEVEL :
",64.55,46.71,False
"def launch_app ( self , fs_id ) : <TAB> if fs_id in self . app_infos : <TAB> <TAB> row = self . get_row_by_fsid ( fs_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> app_info = self . app_infos [ fs_id ] <TAB> <TAB> filepath = os . path . join ( row [ SAVEDIR_COL ] , row [ SAVENAME_COL ] ) <TAB> <TAB> gfile = Gio . File . new_for_path ( filepath ) <TAB> <TAB> app_info . launch ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> gfile , <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> None , <TAB> <TAB> ) <TAB> <TAB> self . app_infos . pop ( fs_id , None ) ","if not row : 
","if row is None :
",29.25,14.06,False
"def create_skipfile ( files_changed , skipfile ) : <TAB> # File is likely to contain some garbage values at start, <TAB> # only the corresponding json should be parsed. <TAB> json_pattern = re . compile ( r "" ^ \ { .* \ } "" ) <TAB> for line in files_changed . readlines ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for filename in json . loads ( line ) : <TAB> <TAB> <TAB> <TAB> if "" /COMMIT_MSG "" in filename : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> skipfile . write ( "" +*/ %s \n "" % filename ) <TAB> skipfile . write ( "" -* \n "" ) ","if re . match ( json_pattern , line ) : 
","if json_pattern . match ( line ) :
",39.68,29.93,False
"def zscore ( self , client , request , N ) : <TAB> check_input ( request , N != 2 ) <TAB> key = request [ 1 ] <TAB> db = client . db <TAB> value = db . get ( key ) <TAB> if value is None : <TAB> <TAB> client . reply_bulk ( None ) <TAB> elif not isinstance ( value , self . zset_type ) : <TAB> <TAB> client . reply_wrongtype ( ) <TAB> else : <TAB> <TAB> score = value . score ( request [ 2 ] , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> score = str ( score ) . encode ( "" utf-8 "" ) <TAB> <TAB> client . reply_bulk ( score ) ","if score is not None : 
","if isinstance ( score , bytes ) :
",27.11,7.27,False
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> if isinstance ( test , unittest . TestSuite ) : <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> elif isinstance ( test , unittest . TestCase ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) ) ","if support . match_test ( test ) : 
","if test . name ( ) == "" test_example "" :
",31.85,4.78,False
"def Run ( self ) : <TAB> """"""The main run method of the client."""""" <TAB> for thread in self . _threads . values ( ) : <TAB> <TAB> thread . start ( ) <TAB> logging . info ( START_STRING ) <TAB> while True : <TAB> <TAB> dead_threads = [ tn for ( tn , t ) in self . _threads . items ( ) if not t . isAlive ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise FatalError ( <TAB> <TAB> <TAB> <TAB> "" These threads are dead:  %r . Shutting down... "" % dead_threads <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 10 ) ","if dead_threads : 
","if dead_threads :
",78.12,100.0,True
"def _slice_queryset ( queryset , order_by , per_page , start ) : <TAB> page_len = int ( per_page ) + 1 <TAB> if start : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filter_name = "" %s __lte "" % order_by [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> filter_name = "" %s __gte "" % order_by <TAB> <TAB> return queryset . filter ( * * { filter_name : start } ) [ : page_len ] <TAB> return queryset [ : page_len ] ","if order_by . startswith ( "" - "" ) : 
","if order_by . startswith ( "" > "" ) :
",83.03,73.49,False
"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB> <TAB> for _ in XRANGE ( 10 ) : <TAB> <TAB> <TAB> t1 = timer ( ) <TAB> <TAB> <TAB> t2 = timer ( ) <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt < = 0.0 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if precision is not None : <TAB> <TAB> <TAB> precision = min ( precision , dt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points + = 1 <TAB> <TAB> previous = timer ( ) <TAB> return precision ","if 0 < dt : 
","if dt < = 0.0 :
",28.39,11.48,False
"def findWorkingDir ( ) : <TAB> frozen = getattr ( sys , "" frozen "" , "" "" ) <TAB> if not frozen : <TAB> <TAB> path = os . path . dirname ( __file__ ) <TAB> elif frozen in ( "" dll "" , "" console_exe "" , "" windows_exe "" , "" macosx_app "" ) : <TAB> <TAB> path = os . path . dirname ( <TAB> <TAB> <TAB> os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) ) <TAB> <TAB> ) <TAB> elif frozen :<TAB> # needed for PyInstaller <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = getattr ( sys , "" _MEIPASS "" , "" "" )<TAB> # --onefile <TAB> <TAB> else : <TAB> <TAB> <TAB> path = os . path . dirname ( sys . executable )<TAB> # --onedir <TAB> else : <TAB> <TAB> path = "" "" <TAB> return path ","if getattr ( sys , "" _MEIPASS "" , "" "" ) is not None : 
","if sys . platform == "" win32 "" :
",32.11,3.12,False
"def CreateDataType ( vmodlName , wsdlName , parent , version , props ) : <TAB> with _lazyLock : <TAB> <TAB> dic = [ vmodlName , wsdlName , parent , version , props ] <TAB> <TAB> names = vmodlName . split ( "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vmodlName = "" . "" . join ( name [ 0 ] . lower ( ) + name [ 1 : ] for name in names ) <TAB> <TAB> _AddToDependencyMap ( names ) <TAB> <TAB> typeNs = GetWsdlNamespace ( version ) <TAB> <TAB> _dataDefMap [ vmodlName ] = dic <TAB> <TAB> _wsdlDefMap [ ( typeNs , wsdlName ) ] = dic <TAB> <TAB> _wsdlTypeMapNSs . add ( typeNs ) ","if _allowCapitalizedNames : 
","if _AddToDependencyMap ( names ) :
",29.81,14.54,False
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> if not isinstance ( response , rdf_client_fs . StatEntry ) : <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB> <TAB> <TAB> homedir = response . pathspec . path <TAB> <TAB> <TAB> username = os . path . basename ( homedir ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield rdf_client . User ( username = username , homedir = homedir ) ","if username not in self . _ignore_users : 
","if username not in knowledge_base . _user_names :
",69.58,24.71,False
"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB> <TAB> if letter == "" < "" : <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "" > "" : <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if letter == "" "" : <TAB> <TAB> <TAB> <TAB> letter = "" _ "" <TAB> <TAB> <TAB> question + = letter . lower ( ) <TAB> return question ","if letter . isalnum ( ) or letter == "" "" : 
","if letter :
",26.42,0.0,False
"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB> <TAB> for line in lines : <TAB> <TAB> <TAB> if gap : <TAB> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> <TAB> self . process ( line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0 ","if not is_command ( line ) : 
","if len ( line ) > times :
",43.35,20.61,False
"def _get ( self , domain ) : <TAB> with self . lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> record = self . cache [ domain ] <TAB> <TAB> <TAB> time_now = time . time ( ) <TAB> <TAB> <TAB> if time_now - record [ "" update "" ] > self . ttl : <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> record = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record ","if not record : 
","if not record :
",100.0,100.0,True
"def gen_constant_folding ( cw ) : <TAB> types = [ "" Int32 "" , "" Double "" , "" BigInteger "" , "" Complex "" ] <TAB> for cur_type in types : <TAB> <TAB> cw . enter_block ( "" if (constLeft.Value.GetType() == typeof( %s )) "" % ( cur_type , ) ) <TAB> <TAB> cw . enter_block ( "" switch (_op) "" ) <TAB> <TAB> for op in ops : <TAB> <TAB> <TAB> gen = getattr ( op , "" genConstantFolding "" , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> gen ( cw , cur_type ) <TAB> <TAB> cw . exit_block ( ) <TAB> <TAB> cw . exit_block ( ) ","if gen is not None : 
","if gen is not None :
",100.0,100.0,True
"def unreferenced_dummy ( self ) : <TAB> for g , base in zip ( self . evgroups , self . evbases ) : <TAB> <TAB> for ind , j in enumerate ( g ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> debug_print ( <TAB> <TAB> <TAB> <TAB> <TAB> "" replacing unreferenced  %d %s  with dummy "" % ( ( base + ind ) , g [ ind ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> g [ ind ] = "" dummy "" <TAB> <TAB> <TAB> <TAB> self . evnum [ base + ind ] = "" dummy "" ","if not self . indexobj [ base + ind ] : 
","if j == base + ind :
",34.47,16.05,False
"def handle_signature ( self , sig : str , signode : desc_signature ) - > Tuple [ str , str ] : <TAB> for cls in self . __class__ . __mro__ : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" PyDecoratorMixin is deprecated.  "" <TAB> <TAB> <TAB> <TAB> "" Please check the implementation of  %s "" % cls , <TAB> <TAB> <TAB> <TAB> RemovedInSphinx50Warning , <TAB> <TAB> <TAB> <TAB> stacklevel = 2 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> "" PyDecoratorMixin is deprecated "" , RemovedInSphinx50Warning , stacklevel = 2 <TAB> <TAB> ) <TAB> ret = super ( ) . handle_signature ( sig , signode )<TAB> # type: ignore <TAB> signode . insert ( 0 , addnodes . desc_addname ( "" @ "" , "" @ "" ) ) <TAB> return ret ","if cls . __name__ != "" DirectiveAdapter "" : 
","if cls . __name__ == "" RemovedInSphinx50 "" :
",68.64,60.6,False
"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB> <TAB> path . responses . append ( response ) <TAB> <TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB> <TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> n + = 1 <TAB> <TAB> if n > max_next : <TAB> <TAB> <TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB> <TAB> response = requests . get ( src , stream = True ) ","if not src : 
","if not src :
",100.0,100.0,True
"def ordered_indices ( self ) : <TAB> with data_utils . numpy_seed ( self . seed , self . epoch ) : <TAB> <TAB> # Used to store the order of indices of each dataset to use <TAB> <TAB> indices = [ <TAB> <TAB> <TAB> np . random . permutation ( len ( dataset ) ) for dataset in self . datasets . values ( ) <TAB> <TAB> ] <TAB> <TAB> # Keep track of which samples we've  used for each dataset <TAB> <TAB> counters = [ 0 for _ in self . datasets ] <TAB> <TAB> sampled_indices = [ <TAB> <TAB> <TAB> self . _sample ( indices , counters ) for _ in range ( self . total_num_instances ) <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sampled_indices . sort ( key = lambda i : self . num_tokens ( i ) ) <TAB> <TAB> return np . array ( sampled_indices , dtype = np . int64 ) ","if self . sort_indices : 
","if self . sort_tokens :
",64.48,64.35,False
"def _build_columns ( self ) : <TAB> self . columns = [ Column ( ) for col in self . keys ] <TAB> for row in self : <TAB> <TAB> for ( col_idx , col_val ) in enumerate ( row ) : <TAB> <TAB> <TAB> col = self . columns [ col_idx ] <TAB> <TAB> <TAB> col . append ( col_val ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> col . is_quantity = False <TAB> for ( idx , key_name ) in enumerate ( self . keys ) : <TAB> <TAB> self . columns [ idx ] . name = key_name <TAB> self . x = Column ( ) <TAB> self . ys = [ ] ","if ( col_val is not None ) and ( not is_quantity ( col_val ) ) : 
","if len ( col ) == 1 :
",30.77,2.83,False
"def tearDown ( self ) : <TAB> subprocess_list = self . subprocess_list <TAB> processes = subprocess_list . processes <TAB> self . schedule . reset ( ) <TAB> del self . schedule <TAB> for proc in processes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = True ) <TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB> <TAB> for proc in processes : <TAB> <TAB> <TAB> if proc . is_alive ( ) : <TAB> <TAB> <TAB> <TAB> terminate_process ( proc . pid , kill_children = True , slow_stop = False ) <TAB> <TAB> subprocess_list . cleanup ( ) <TAB> processes = subprocess_list . processes <TAB> if processes : <TAB> <TAB> log . warning ( "" Processes left running:  %s "" , processes ) ","if proc . is_alive ( ) : 
","if proc . is_alive ( ) :
",100.0,100.0,True
"def colorNetwork ( cls , network , nodesInNetwork , nodeByID = None ) : <TAB> for node in nodesInNetwork : <TAB> <TAB> node . use_custom_color = True <TAB> <TAB> neededCopies = sum ( socket . execution . neededCopies for socket in node . outputs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> color = ( 0.7 , 0.9 , 0.7 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> color = ( 1.0 , 0.3 , 0.3 ) <TAB> <TAB> node . color = color ","if neededCopies == 0 : 
","if neededCopies > 0 :
",58.14,24.74,False
"def _init_warmup_scheduler ( self , optimizer , states ) : <TAB> updates_so_far = states . get ( "" number_training_updates "" , 0 ) <TAB> if self . warmup_updates > 0 and ( <TAB> <TAB> updates_so_far < = self . warmup_updates or self . hard_reset <TAB> ) : <TAB> <TAB> self . warmup_scheduler = optim . lr_scheduler . LambdaLR ( optimizer , self . _warmup_lr ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . warmup_scheduler . load_state_dict ( states [ "" warmup_scheduler "" ] ) <TAB> else : <TAB> <TAB> self . warmup_scheduler = None ","if states . get ( "" warmup_scheduler "" ) : 
","if "" warmup_scheduler "" in states :
",35.58,35.97,False
"def inner ( self , * iargs , * * ikwargs ) : <TAB> try : <TAB> <TAB> return getattr ( super ( VEXResilienceMixin , self ) , func ) ( * iargs , * * ikwargs ) <TAB> except excs as e : <TAB> <TAB> for exc , handler in zip ( excs , handlers ) : <TAB> <TAB> <TAB> if isinstance ( e , exc ) : <TAB> <TAB> <TAB> <TAB> v = getattr ( self , handler ) ( * iargs , * * ikwargs ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> assert False , "" this should be unreachable if Python is working correctly "" ","if v is raiseme : 
","if v is None :
",39.55,42.73,False
"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB> <TAB> if data [ "" items "" ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = len ( data ) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . context [ "" total "" ] = 0 <TAB> <TAB> <TAB> data = { "" items "" : [ ] } <TAB> <TAB> return data [ "" items "" ] <TAB> return data ","if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : 
","if data [ "" total "" ] == 0 :
",25.9,3.43,False
"def __subclasscheck__ ( self , cls ) : <TAB> if self . __origin__ is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" Parameterized generics cannot be used with class  "" "" or instance checks "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return False <TAB> if self is Generic : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" Class  %r  cannot be used with class  "" "" or instance checks "" % self <TAB> <TAB> ) <TAB> return super ( ) . __subclasscheck__ ( cls ) ","if sys . _getframe ( 1 ) . f_globals [ "" __name__ "" ] not in [ "" abc "" , "" functools "" ] : 
","if self is Parameterized :
",25.28,0.05,False
"def __init__ ( self , pyversions , coverage_service ) : <TAB> build_matrix = "" "" <TAB> for version in pyversions : <TAB> <TAB> build_matrix + = "" \n<TAB>  {} , "" . format ( <TAB> <TAB> <TAB> version <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else "" py {} "" . format ( "" "" . join ( version . split ( "" . "" ) ) ) <TAB> <TAB> ) <TAB> coverage_package = "" "" <TAB> if coverage_service : <TAB> <TAB> coverage_package + = "" \n<TAB>  {} "" . format ( coverage_service . package ) <TAB> coverage_package + = "" \n "" <TAB> super ( Tox , self ) . __init__ ( <TAB> <TAB> "" tox.ini "" , <TAB> <TAB> TEMPLATE . format ( build_matrix = build_matrix , coverage_package = coverage_package ) , <TAB> ) ","if version . startswith ( "" pypy "" ) 
","if "" . "" not in version
",31.04,7.38,False
"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> tasks = self . tasks . tasks<TAB> # is a group <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> tasks = self . tasks <TAB> <TAB> if len ( tasks ) : <TAB> <TAB> <TAB> app = tasks [ 0 ] . _app <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> app = body . _app <TAB> return app if app is not None else current_app ","if app is None and body is not None : 
","elif body :
",25.78,0.0,False
"def logic ( ) : <TAB> for v in [ True , False , None , 0 , True , None , None , 1 ] : <TAB> <TAB> yield clk . posedge <TAB> <TAB> xd . next = v <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yd . next = zd . next = None <TAB> <TAB> elif v : <TAB> <TAB> <TAB> yd . next = zd . next = 11 <TAB> <TAB> else : <TAB> <TAB> <TAB> yd . next = zd . next = 0 ","if v is None : 
","if v :
",31.27,0.0,False
"def run ( self ) : <TAB> eid = self . start_episode ( ) <TAB> obs = self . env . reset ( ) <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> action = self . env . action_space . sample ( ) <TAB> <TAB> <TAB> self . log_action ( eid , obs , action ) <TAB> <TAB> else : <TAB> <TAB> <TAB> action = self . get_action ( eid , obs ) <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> self . log_returns ( eid , reward , info = info ) <TAB> <TAB> if done : <TAB> <TAB> <TAB> self . end_episode ( eid , obs ) <TAB> <TAB> <TAB> obs = self . env . reset ( ) <TAB> <TAB> <TAB> eid = self . start_episode ( ) ","if random . random ( ) < self . off_pol_frac : 
","if self . env . action_space :
",34.73,6.44,False
"def tearDown ( self ) : <TAB> os . chdir ( self . orig_working_dir ) <TAB> sys . argv = self . orig_argv <TAB> sys . stdout = self . orig_stdout <TAB> sys . stderr = self . orig_stderr <TAB> for dirname in [ "" lv_LV "" , "" ja_JP "" ] : <TAB> <TAB> locale_dir = os . path . join ( self . datadir , "" project "" , "" i18n "" , dirname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutil . rmtree ( locale_dir ) ","if os . path . isdir ( locale_dir ) : 
","if os . path . exists ( locale_dir ) :
",83.03,73.49,False
"def sentry_set_scope ( process_context , entity , project , email = None , url = None ) : <TAB> # Using GLOBAL_HUB means these tags will persist between threads. <TAB> # Normally there is one hub per thread. <TAB> with sentry_sdk . hub . GLOBAL_HUB . configure_scope ( ) as scope : <TAB> <TAB> scope . set_tag ( "" process_context "" , process_context ) <TAB> <TAB> scope . set_tag ( "" entity "" , entity ) <TAB> <TAB> scope . set_tag ( "" project "" , project ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> scope . user = { "" email "" : email } <TAB> <TAB> if url : <TAB> <TAB> <TAB> scope . set_tag ( "" url "" , url ) ","if email : 
","if email :
",78.12,0.0,False
"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if c . getYAxis ( ) == Y_AXIS : <TAB> <TAB> <TAB> nPoints = c . getNPoints ( ) <TAB> <TAB> <TAB> for j in range ( nPoints ) : <TAB> <TAB> <TAB> <TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB> <TAB> return Double . NaN <TAB> return result ","if not c . isVisible ( ) : 
","if not c . isVisible ( ) :
",100.0,100.0,True
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" link "" and ( "" rel "" , "" icon "" ) in attrs or ( "" rel "" , "" shortcut icon "" ) in attrs : <TAB> <TAB> href = None <TAB> <TAB> icon_type = None <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> if attr == "" href "" : <TAB> <TAB> <TAB> <TAB> href = value <TAB> <TAB> <TAB> elif attr == "" type "" : <TAB> <TAB> <TAB> <TAB> icon_type = value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> mimetype = extension_to_mimetype ( href . rpartition ( "" . "" ) [ 2 ] ) <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> icon_type = mimetype <TAB> <TAB> <TAB> if icon_type : <TAB> <TAB> <TAB> <TAB> self . icons . append ( ( href , icon_type ) ) ","if href : 
","elif attr == "" mimetype "" :
",28.12,5.52,False
"def get_version ( version_file = STATIC_VERSION_FILE ) : <TAB> version_info = get_static_version_info ( version_file ) <TAB> version = version_info [ "" version "" ] <TAB> if version == "" __use_git__ "" : <TAB> <TAB> version = get_version_from_git ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> version = get_version_from_git_archive ( version_info ) <TAB> <TAB> if not version : <TAB> <TAB> <TAB> version = Version ( "" unknown "" , None , None ) <TAB> <TAB> return pep440_format ( version ) <TAB> else : <TAB> <TAB> return version ","if not version : 
","elif version == "" __archive__ "" :
",27.8,4.03,False
"def _Sleep ( self , seconds ) : <TAB> if threading . current_thread ( ) is not self . _worker_thread : <TAB> <TAB> return self . _original_sleep ( seconds ) <TAB> self . _time + = seconds <TAB> self . _budget - = seconds <TAB> while self . _budget < 0 : <TAB> <TAB> self . _worker_thread_turn . clear ( ) <TAB> <TAB> self . _owner_thread_turn . set ( ) <TAB> <TAB> self . _worker_thread_turn . wait ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise FakeTimeline . _WorkerThreadExit ( ) ","if self . _worker_thread_done : 
","if self . _owner_thread_turn . is_set ( ) :
",43.86,22.89,False
"def validate_attributes ( self ) : <TAB> if not ( self . has_variants or self . variant_of ) : <TAB> <TAB> return <TAB> if not self . variant_based_on : <TAB> <TAB> self . variant_based_on = "" Item Attribute "" <TAB> if self . variant_based_on == "" Item Attribute "" : <TAB> <TAB> attributes = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Attribute table is mandatory "" ) ) <TAB> <TAB> for d in self . attributes : <TAB> <TAB> <TAB> if d . attribute in attributes : <TAB> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Attribute  {0}  selected multiple times in Attributes Table "" <TAB> <TAB> <TAB> <TAB> <TAB> ) . format ( d . attribute ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attributes . append ( d . attribute ) ","if not self . attributes : 
","if not self . attributes :
",100.0,100.0,True
"def check_digest_auth ( user , passwd ) : <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB> <TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB> <TAB> if not credentails : <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response ( <TAB> <TAB> <TAB> credentails , <TAB> <TAB> <TAB> passwd , <TAB> <TAB> <TAB> dict ( <TAB> <TAB> <TAB> <TAB> uri = request . script_root + request . path , <TAB> <TAB> <TAB> <TAB> body = request . data , <TAB> <TAB> <TAB> <TAB> method = request . method , <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if credentails . get ( "" response "" ) == response_hash : 
","if response_hash . is_success :
",29.71,10.84,False
"def _get_index_type ( return_index_type , ctx ) : <TAB> if return_index_type is None :<TAB> # pragma: no cover <TAB> <TAB> if ctx . running_mode == RunningMode . local : <TAB> <TAB> <TAB> return_index_type = "" object "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return_index_type = "" filename "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return_index_type = "" bytes "" <TAB> return return_index_type ","elif ctx . running_mode == RunningMode . local_cluster : 
","elif ctx . running_mode == RunningMode . file :
",87.71,69.96,False
"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB> <TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB> <TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB> <TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB> <TAB> if not isinstance ( handler , handlers . ResourceWatchingHandler ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield handler ","elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) : 
","if handler . resource == resource and handler . event_cause is cause :
",28.88,3.3,False
"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB> <TAB> if completed_process . stderr is not None : <TAB> <TAB> <TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB> <TAB> if raise_error : <TAB> <TAB> <TAB> raise PipxError ( <TAB> <TAB> <TAB> <TAB> f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" ) ","if completed_process . stdout is not None : 
","if completed_process . stdout is not None :
",100.0,100.0,True
"def __pow__ ( self , power ) : <TAB> if power == 1 : <TAB> <TAB> return self <TAB> if power == - 1 : <TAB> <TAB> # HACK: break cycle <TAB> <TAB> from cirq . devices import line_qubit <TAB> <TAB> decomposed = protocols . decompose_once_with_qubits ( <TAB> <TAB> <TAB> self , qubits = line_qubit . LineQid . for_gate ( self ) , default = None <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> inverse_decomposed = protocols . inverse ( decomposed , None ) <TAB> <TAB> if inverse_decomposed is None : <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> return _InverseCompositeGate ( self ) <TAB> return NotImplemented ","if decomposed is None : 
","if decomposed is None :
",100.0,100.0,True
"def tearDown ( self ) : <TAB> """"""Close the application after tests"""""" <TAB> # set it back to it's old position so not to annoy users :-) <TAB> self . old_pos = self . dlg . rectangle <TAB> # close the application <TAB> self . dlg . menu_select ( "" File->Exit "" ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . app . UntitledNotepad [ "" Do&n ' t Save "" ] . click ( ) <TAB> <TAB> <TAB> self . app . UntitledNotepad . wait_not ( "" visible "" ) <TAB> except Exception : <TAB> <TAB> pass <TAB> finally : <TAB> <TAB> self . app . kill ( ) ","if self . app . UntitledNotepad [ "" Do&n ' t Save "" ] . exists ( ) : 
","if "" Do&n ' t Save "" in self . app . UntitledNotepad :
",56.25,51.1,False
"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> <MASK> <TAB> <TAB> if log : <TAB> <TAB> <TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB> <TAB> proc . terminate ( ) <TAB> <TAB> timeout_time = time . time ( ) + timeout <TAB> <TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB> <TAB> <TAB> time . sleep ( 0.02 ) <TAB> <TAB> if proc . poll ( ) is None : <TAB> <TAB> <TAB> if log : <TAB> <TAB> <TAB> <TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB> <TAB> <TAB> proc . kill ( ) <TAB> return proc . returncode ","if proc . poll ( ) is None : 
","if proc . poll ( ) is None :
",100.0,100.0,True
"def validate ( self , detection , expectation ) : <TAB> config = SigmaConfiguration ( ) <TAB> self . basic_rule [ "" detection "" ] = detection <TAB> with patch ( "" yaml.safe_load_all "" , return_value = [ self . basic_rule ] ) : <TAB> <TAB> parser = SigmaCollectionParser ( "" any sigma io "" , config , None ) <TAB> <TAB> backend = SQLiteBackend ( config , self . table ) <TAB> <TAB> assert len ( parser . parsers ) == 1 <TAB> <TAB> for p in parser . parsers : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( expectation , backend . generate ( p ) ) <TAB> <TAB> <TAB> elif isinstance ( expectation , Exception ) : <TAB> <TAB> <TAB> <TAB> self . assertRaises ( type ( expectation ) , backend . generate , p ) ","if isinstance ( expectation , str ) : 
","if isinstance ( expectation , str ) :
",100.0,100.0,True
"def makelist ( d ) : <TAB> """"""Convert d into a list if all the keys of d are integers."""""" <TAB> if isinstance ( d , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ makelist ( d [ k ] ) for k in sorted ( d , key = int ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return web . storage ( ( k , makelist ( v ) ) for k , v in d . items ( ) ) <TAB> else : <TAB> <TAB> return d ","if all ( isint ( k ) for k in d ) : 
","if isinstance ( d , list ) :
",27.0,7.43,False
"def __share_local_dir ( self , lpath , rpath , fast ) : <TAB> result = const . ENoError <TAB> for walk in self . __walk_normal_file ( lpath ) : <TAB> <TAB> ( dirpath , dirnames , filenames ) = walk <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> rpart = os . path . relpath ( dirpath , lpath ) <TAB> <TAB> <TAB> if rpart == "" . "" : <TAB> <TAB> <TAB> <TAB> rpart = "" "" <TAB> <TAB> <TAB> subr = self . __share_local_file ( <TAB> <TAB> <TAB> <TAB> joinpath ( dirpath , filename ) , <TAB> <TAB> <TAB> <TAB> posixpath . join ( rpath , rpart , filename ) , <TAB> <TAB> <TAB> <TAB> fast , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = subr <TAB> return result ","if subr != const . ENoError : 
","if subr != const . ENoError :
",100.0,100.0,True
"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set ( ) <TAB> for condfield in self . conditions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser . values [ condfield ] <TAB> <TAB> <TAB> for condvalue in self . conditions [ condfield ] : <TAB> <TAB> <TAB> <TAB> if condvalue in rulefieldvalues : <TAB> <TAB> <TAB> <TAB> <TAB> targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB> return targets ","if condfield in sigmaparser . values : 
","if condfield in sigmaparser . values :
",100.0,100.0,True
"def _wrapped_view ( request , * args , * * kwargs ) : <TAB> # based on authority/decorators.py <TAB> user = request . user <TAB> if user . is_authenticated ( ) : <TAB> <TAB> obj = _resolve_lookup ( obj_lookup , kwargs ) <TAB> <TAB> perm_obj = _resolve_lookup ( perm_obj_lookup , kwargs ) <TAB> <TAB> granted = access . has_perm_or_owns ( user , perm , obj , perm_obj , owner_attr ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return view_func ( request , * args , * * kwargs ) <TAB> # In all other cases, permission denied <TAB> return HttpResponseForbidden ( ) ","if granted or user . has_perm ( perm ) : 
","if granted :
",26.96,0.0,False
"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB> <TAB> earlier_part = earlier [ "" part "" ] <TAB> <TAB> earlier_step = earlier [ "" step "" ] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not found : <TAB> <TAB> <TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB> <TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint ) ","if earlier_part == current [ "" part "" ] and earlier_step == current [ "" step "" ] : 
","if current [ "" part "" ] == earlier_part and current [ "" step "" ] == earlier_step :
",64.09,53.02,False
"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB> <TAB> if self . named_windows [ wnd_name ] == 0 : <TAB> <TAB> <TAB> self . named_windows [ wnd_name ] = 1 <TAB> <TAB> <TAB> self . on_create_window ( wnd_name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . capture_mouse ( wnd_name ) <TAB> <TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB> <TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" ) ","if wnd_name in self . capture_mouse_windows : 
","elif self . named_windows [ wnd_name ] == 1 :
",34.29,14.87,False
"def readlines ( self , hint = None ) : <TAB> # Again, allow hint but ignore <TAB> body = self . _get_body ( ) <TAB> rest = body [ self . position : ] <TAB> self . position = len ( body ) <TAB> result = [ ] <TAB> while 1 : <TAB> <TAB> next = rest . find ( "" \r \n "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( rest ) <TAB> <TAB> <TAB> break <TAB> <TAB> result . append ( rest [ : next + 2 ] ) <TAB> <TAB> rest = rest [ next + 2 : ] <TAB> return result ","if next == - 1 : 
","if next == - 1 :
",100.0,100.0,True
"def __lt__ ( self , other ) : <TAB> olen = len ( other ) <TAB> for i in range ( olen ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> c = self [ i ] < other [ i ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> # self must be shorter <TAB> <TAB> <TAB> return True <TAB> <TAB> if c : <TAB> <TAB> <TAB> return c <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return len ( self ) < olen ","elif other [ i ] < self [ i ] : 
","if other [ i ] < self [ i ] :
",82.99,89.32,False
"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB> <TAB> if user and social . user != user : <TAB> <TAB> <TAB> msg = "" This account is already in use. "" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> user = social . user <TAB> return { <TAB> <TAB> "" social "" : social , <TAB> <TAB> "" user "" : user , <TAB> <TAB> "" is_new "" : user is None , <TAB> <TAB> "" new_association "" : social is None , <TAB> } ","elif not user : 
","if user is None :
",28.41,12.7,False
"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB> <TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB> <TAB> self . utexc = True <TAB> else : <TAB> <TAB> if self . utexc is False : <TAB> <TAB> <TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . utexc [ indices ] = True ","if self . utexc is not True : 
","elif indices is not None :
",33.42,12.87,False
"def destination ( self , type , name , arglist ) : <TAB> classname = "" ResFunction "" <TAB> listname = "" functions "" <TAB> if arglist : <TAB> <TAB> t , n , m = arglist [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> classname = "" ResMethod "" <TAB> <TAB> <TAB> listname = "" resmethods "" <TAB> return classname , listname ","if t == "" Handle "" and m == "" InMode "" : 
","if t == "" ResFunction "" and m == "" ResMethod "" :
",76.55,61.05,False
"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB> <TAB> self . view . sel ( ) . add ( r ) <TAB> <TAB> if register : <TAB> <TAB> <TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> if register : <TAB> <TAB> text = "" "" . join ( to_store ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = text + "" \n "" <TAB> <TAB> state = State ( self . view ) <TAB> <TAB> state . registers [ register ] = [ text ] ","if not text . endswith ( "" \n "" ) : 
","if self . view . full_line ( r ) . endswith ( "" \n "" ) :
",64.87,41.23,False
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> if self . _pos < start : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> if stop is not None and self . _pos > stop : <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( ) ","elif self . _pos == start : 
","if start is None :
",26.95,5.71,False
"def start ( self ) : <TAB> self . on_config_change ( ) <TAB> self . start_config_watch ( ) <TAB> try : <TAB> <TAB> if self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" tcp "" ] . lower ( ) == "" on "" : <TAB> <TAB> <TAB> self . startTCP ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . startUDP ( ) <TAB> except socket . error as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutdown ( <TAB> <TAB> <TAB> <TAB> "" \n [DNS] Unable to start DNS server on port  {} : port already in use "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> self . config [ "" MITMf "" ] [ "" DNS "" ] [ "" port "" ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","if "" Address already in use "" in e : 
","if e . errno == errno . EADDRINUSE :
",26.41,5.52,False
"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB> <TAB> if other not in self . ignoreExprs : <TAB> <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> if self . expr is not None : <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self ","if self . expr is not None : 
","if self . expr is not None :
",100.0,100.0,True
"def test_relative_deploy_path_override ( ) : <TAB> s = Site ( TEST_SITE_ROOT ) <TAB> s . load ( ) <TAB> res = s . content . resource_from_relative_path ( <TAB> <TAB> "" blog/2010/december/merry-christmas.html "" <TAB> ) <TAB> res . relative_deploy_path = "" blog/2010/december/happy-holidays.html "" <TAB> for page in s . content . walk_resources ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert page . relative_deploy_path == "" blog/2010/december/happy-holidays.html "" <TAB> <TAB> else : <TAB> <TAB> <TAB> assert page . relative_deploy_path == Folder ( page . relative_path ) ","if res . source_file == page . source_file : 
","if page . is_dir ( ) :
",38.2,6.88,False
"def _parser ( cls , buf ) : <TAB> tlvs = [ ] <TAB> while buf : <TAB> <TAB> tlv_type = LLDPBasicTLV . get_type ( buf ) <TAB> <TAB> tlv = cls . _tlv_parsers [ tlv_type ] ( buf ) <TAB> <TAB> tlvs . append ( tlv ) <TAB> <TAB> offset = LLDP_TLV_SIZE + tlv . len <TAB> <TAB> buf = buf [ offset : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> assert len ( buf ) > 0 <TAB> lldp_pkt = cls ( tlvs ) <TAB> assert lldp_pkt . _tlvs_len_valid ( ) <TAB> assert lldp_pkt . _tlvs_valid ( ) <TAB> return lldp_pkt , None , buf ","if tlv . tlv_type == LLDP_TLV_END : 
","if len ( buf ) < offset :
",26.98,3.1,False
"def _do_pull ( self , repo , pull_kwargs , silent , ignore_pull_failures ) : <TAB> try : <TAB> <TAB> output = self . client . pull ( repo , * * pull_kwargs ) <TAB> <TAB> if silent : <TAB> <TAB> <TAB> with open ( os . devnull , "" w "" ) as devnull : <TAB> <TAB> <TAB> <TAB> yield from stream_output ( output , devnull ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from stream_output ( output , sys . stdout ) <TAB> except ( StreamOutputError , NotFound ) as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> log . error ( str ( e ) ) ","if not ignore_pull_failures : 
","if ignore_pull_failures :
",34.18,72.9,False
def _collect_bytecode ( ordered_code ) : <TAB> bytecode_blocks = [ ] <TAB> stack = [ ordered_code ] <TAB> while stack : <TAB> <TAB> code = stack . pop ( ) <TAB> <TAB> bytecode_blocks . append ( code . co_code ) <TAB> <TAB> for const in code . co_consts : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> stack . append ( const ) <TAB> return bytecode_blocks ,"if isinstance ( const , blocks . OrderedCode ) : 
","if const . co_name == ordered_code :
",31.58,4.79,False
"def displayhook ( value ) : <TAB> if value is None : <TAB> <TAB> return <TAB> builtins = modules [ "" builtins "" ] <TAB> # Set '_' to None to avoid recursion <TAB> builtins . _ = None <TAB> text = repr ( value ) <TAB> try : <TAB> <TAB> local_stdout = stdout <TAB> except NameError as e : <TAB> <TAB> raise RuntimeError ( "" lost sys.stdout "" ) from e <TAB> try : <TAB> <TAB> local_stdout . write ( text ) <TAB> except UnicodeEncodeError : <TAB> <TAB> bytes = text . encode ( local_stdout . encoding , "" backslashreplace "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> local_stdout . buffer . write ( bytes ) <TAB> <TAB> else : <TAB> <TAB> <TAB> text = bytes . decode ( local_stdout . encoding , "" strict "" ) <TAB> <TAB> <TAB> local_stdout . write ( text ) <TAB> local_stdout . write ( "" \n "" ) <TAB> builtins . _ = value ","if hasattr ( local_stdout , "" buffer "" ) : 
","if hasattr ( local_stdout , "" buffer "" ) :
",100.0,100.0,True
"def _analyze ( self ) : <TAB> lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB> prev_line = None <TAB> for line in lines : <TAB> <TAB> if line . startswith ( "" ERROR: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB> <TAB> <TAB> self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB> <TAB> prev_line = line ","elif line . startswith ( "" FAIL: "" ) and prev_line and prev_line . startswith ( "" = "" ) : 
","if line . startswith ( "" FAIL: "" ) and prev_line . startswith ( "" = "" ) :
",69.53,79.3,False
"def _flush ( self ) : <TAB> if self . _data : <TAB> <TAB> if self . _last is not None : <TAB> <TAB> <TAB> text = "" "" . join ( self . _data ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> assert self . _last . tail is None , "" internal error (tail) "" <TAB> <TAB> <TAB> <TAB> self . _last . tail = text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert self . _last . text is None , "" internal error (text) "" <TAB> <TAB> <TAB> <TAB> self . _last . text = text <TAB> <TAB> self . _data = [ ] ","if self . _tail : 
","if self . _tail :
",100.0,100.0,True
"def write ( self , chunk ) : <TAB> consumer = self . _current_consumer <TAB> server_side = consumer . server_side <TAB> if server_side : <TAB> <TAB> server_side . data_received ( chunk ) <TAB> else : <TAB> <TAB> consumer . message + = chunk <TAB> <TAB> assert consumer . in_parser . execute ( chunk , len ( chunk ) ) == len ( chunk ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> consumer . finished ( ) ","if consumer . in_parser . is_message_complete ( ) : 
","if consumer . finished :
",35.84,5.78,False
"def _api_change_cat ( name , output , kwargs ) : <TAB> """"""API: accepts output, value(=nzo_id), value2(=category)"""""" <TAB> value = kwargs . get ( "" value "" ) <TAB> value2 = kwargs . get ( "" value2 "" ) <TAB> if value and value2 : <TAB> <TAB> nzo_id = value <TAB> <TAB> cat = value2 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cat = None <TAB> <TAB> result = sabnzbd . NzbQueue . change_cat ( nzo_id , cat ) <TAB> <TAB> return report ( output , keyword = "" status "" , data = bool ( result > 0 ) ) <TAB> else : <TAB> <TAB> return report ( output , _MSG_NO_VALUE ) ","if cat == "" None "" : 
","if cat == "" "" :
",74.27,61.3,False
"def get_allocated_address ( <TAB> self , config : ActorPoolConfig , allocated : allocated_type ) - > str : <TAB> addresses = config . get_external_addresses ( label = self . label ) <TAB> for addr in addresses : <TAB> <TAB> occupied = False <TAB> <TAB> for strategy , _ in allocated . get ( addr , dict ( ) ) . values ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> occupied = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if not occupied : <TAB> <TAB> <TAB> return addr <TAB> raise NoIdleSlot ( <TAB> <TAB> f "" No idle slot for creating actor  "" f "" with label  { self . label } , mark  { self . mark } "" <TAB> ) ","if strategy == self : 
","if strategy . is_idle ( ) :
",30.29,10.55,False
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> if key in LoggerFactory . schedule_logger_dict : <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id ) ","if delete : 
","if delete :
",78.12,0.0,False
"def quick_load ( tool_file , async_load = True ) : <TAB> try : <TAB> <TAB> tool = self . load_tool ( tool_file , tool_cache_data_dir ) <TAB> <TAB> self . __add_tool ( tool , load_panel_dict , elems ) <TAB> <TAB> # Always load the tool into the integrated_panel_dict, or it will not be included in the integrated_tool_panel.xml file. <TAB> <TAB> key = "" tool_ %s "" % str ( tool . id ) <TAB> <TAB> integrated_elems [ key ] = tool <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _load_tool_panel ( ) <TAB> <TAB> <TAB> self . _save_integrated_tool_panel ( ) <TAB> <TAB> return tool . id <TAB> except Exception : <TAB> <TAB> log . exception ( "" Failed to load potential tool  %s . "" , tool_file ) <TAB> <TAB> return None ","if async_load : 
","if async_load :
",78.12,100.0,True
"def _get_default_ordering ( self ) : <TAB> try : <TAB> <TAB> ordering = super ( DocumentChangeList , self ) . _get_default_ordering ( ) <TAB> except AttributeError : <TAB> <TAB> ordering = [ ] <TAB> <TAB> if self . model_admin . ordering : <TAB> <TAB> <TAB> ordering = self . model_admin . ordering <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ordering = self . lookup_opts . ordering <TAB> return ordering ","elif self . lookup_opts . ordering : 
","elif self . lookup_opts :
",54.34,63.19,False
"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB> <TAB> self . __storage ( None ) , <TAB> <TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB> <TAB> for b in s : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name not in u : <TAB> <TAB> <TAB> <TAB> result . append ( b . name ) <TAB> <TAB> <TAB> <TAB> u . add ( b . name ) <TAB> return result ","if persistent is not None and b . persistent != persistent : 
","if b . persistent or b . name in persistent :
",29.08,15.31,False
"def common_check_get_messages_query ( <TAB> self , query_params : Dict [ str , object ] , expected : str ) - > None : <TAB> user_profile = self . example_user ( "" hamlet "" ) <TAB> request = POSTRequestMock ( query_params , user_profile ) <TAB> with queries_captured ( ) as queries : <TAB> <TAB> get_messages_backend ( request , user_profile ) <TAB> for query in queries : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sql = str ( query [ "" sql "" ] ) . replace ( ""  /* get_messages */ "" , "" "" ) <TAB> <TAB> <TAB> self . assertEqual ( sql , expected ) <TAB> <TAB> <TAB> return <TAB> raise AssertionError ( "" get_messages query not found "" ) ","if "" /* get_messages */ "" in query [ "" sql "" ] : 
","if query [ "" sql "" ] :
",58.82,24.91,False
"def _activate_only_current_top_active ( ) : <TAB> for i in range ( 0 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> current_sequence ( ) . tracks [ i ] . active = True <TAB> <TAB> else : <TAB> <TAB> <TAB> current_sequence ( ) . tracks [ i ] . active = False <TAB> gui . tline_column . widget . queue_draw ( ) ","if i == current_sequence ( ) . get_first_active_track ( ) . id : 
","if current_sequence ( ) . tracks [ i ] . active :
",47.86,22.99,False
"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB> <TAB> if postdata != { } : <TAB> <TAB> <TAB> f = urllib . urlopen ( url , postdata ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = urllib . urlopen ( url ) <TAB> <TAB> response = f . read ( ) <TAB> except : <TAB> <TAB> import traceback <TAB> <TAB> import logging , sys <TAB> <TAB> cla , exc , tb = sys . exc_info ( ) <TAB> <TAB> logging . error ( url ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . error ( "" with post data "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . error ( "" without post data "" ) <TAB> <TAB> logging . error ( exc . args ) <TAB> <TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB> <TAB> response = "" "" <TAB> return response ","if postdata : 
","if exc . args [ 0 ] == 2 :
",29.22,4.46,False
"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> <MASK> <TAB> <TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval ) ","if not sys . platform . startswith ( "" java "" ) : 
","if not sys . platform . startswith ( "" java "" ) :
",100.0,100.0,True
"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB> <TAB> f = queue . popleft ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if block_end : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( None ) <TAB> <TAB> <TAB> for gf in f . filters : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( gf ) <TAB> <TAB> yield f ","if f is not None and f . type in ( "" or "" , "" and "" , "" not "" ) : 
","if isinstance ( f , Filter ) :
",25.75,1.97,False
"def smartsplit ( code ) : <TAB> """"""Split `code` at "" symbol, only if it is not escaped."""""" <TAB> strings = [ ] <TAB> pos = 0 <TAB> while pos < len ( code ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> word = "" ""<TAB> # new word <TAB> <TAB> <TAB> pos + = 1 <TAB> <TAB> <TAB> while pos < len ( code ) : <TAB> <TAB> <TAB> <TAB> if code [ pos ] == ' "" ' : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if code [ pos ] == "" \\ "" : <TAB> <TAB> <TAB> <TAB> <TAB> word + = "" \\ "" <TAB> <TAB> <TAB> <TAB> <TAB> pos + = 1 <TAB> <TAB> <TAB> <TAB> word + = code [ pos ] <TAB> <TAB> <TAB> <TAB> pos + = 1 <TAB> <TAB> <TAB> strings . append ( ' "" %s "" ' % word ) <TAB> <TAB> pos + = 1 <TAB> return strings ","if code [ pos ] == ' "" ' : 
","if code [ pos ] == ' "" ' :
",100.0,100.0,True
"def get_folder_content ( cls , name ) : <TAB> """"""Return (folders, files) for the given folder in the root dir."""""" <TAB> folders = set ( ) <TAB> files = set ( ) <TAB> for path in cls . LAYOUT : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> parts = path . split ( "" / "" ) <TAB> <TAB> if len ( parts ) == 2 : <TAB> <TAB> <TAB> files . add ( parts [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> folders . add ( parts [ 1 ] ) <TAB> folders = list ( folders ) <TAB> folders . sort ( ) <TAB> files = list ( files ) <TAB> files . sort ( ) <TAB> return ( folders , files ) ","if not path . startswith ( name + "" / "" ) : 
","if not path or path . startswith ( name ) :
",49.36,41.88,False
"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _tail <TAB> <TAB> node = self . _root <TAB> <TAB> level = self . _shift <TAB> <TAB> while level > 0 : <TAB> <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> <TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB> <TAB> <TAB> level - = 5 <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" ) ","if i > = self . tailoff ( ) : 
","if i > = self . tail_offset :
",59.74,53.73,False
"def __or__ ( self , other ) - > "" MultiVector "" : <TAB> r """"""``self | other``, the inner product :math:`M \cdot N`"""""" <TAB> other , mv = self . _checkOther ( other ) <TAB> if mv : <TAB> <TAB> newValue = self . layout . imt_func ( self . value , other . value ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> obj = self . __array__ ( ) <TAB> <TAB> <TAB> return obj | other <TAB> <TAB> # l * M = M * l = 0 for scalar l <TAB> <TAB> return self . _newMV ( dtype = np . result_type ( self . value . dtype , other ) ) <TAB> return self . _newMV ( newValue ) ","if isinstance ( other , np . ndarray ) : 
","if isinstance ( other , np . ndarray ) :
",100.0,100.0,True
"def parse_bzr_stats ( status ) : <TAB> stats = RepoStats ( ) <TAB> statustype = "" changed "" <TAB> for statusline in status : <TAB> <TAB> if statusline [ : 2 ] == ""<TAB> "" : <TAB> <TAB> <TAB> setattr ( stats , statustype , getattr ( stats , statustype ) + 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> statustype = "" staged "" <TAB> <TAB> elif statusline == "" unknown: "" : <TAB> <TAB> <TAB> statustype = "" new "" <TAB> <TAB> else :<TAB> # removed, missing, renamed, modified or kind changed <TAB> <TAB> <TAB> statustype = "" changed "" <TAB> return stats ","elif statusline == "" added: "" : 
","elif statusline == "" staged: "" :
",74.63,59.69,False
"def write ( self , timestamps , actualValues , predictedValues , predictionStep = 1 ) : <TAB> assert len ( timestamps ) == len ( actualValues ) == len ( predictedValues ) <TAB> for index in range ( len ( self . names ) ) : <TAB> <TAB> timestamp = timestamps [ index ] <TAB> <TAB> actual = actualValues [ index ] <TAB> <TAB> prediction = predictedValues [ index ] <TAB> <TAB> writer = self . outputWriters [ index ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> outputRow = [ timestamp , actual , prediction ] <TAB> <TAB> <TAB> writer . writerow ( outputRow ) <TAB> <TAB> <TAB> self . lineCounts [ index ] + = 1 ","if timestamp is not None : 
","if predictionStep > 0 :
",27.46,10.4,False
"def clean ( self ) : <TAB> """"""Delete old files in ""tmp""."""""" <TAB> now = time . time ( ) <TAB> for entry in os . listdir ( os . path . join ( self . _path , "" tmp "" ) ) : <TAB> <TAB> path = os . path . join ( self . _path , "" tmp "" , entry ) <TAB> <TAB> if now - os . path . getatime ( path ) > 129600 :<TAB> # 60 * 60 * 36 <TAB> <TAB> <TAB> os . remove ( path ) ","if now - os . path . getatime ( path ) > 129600 : 
","if now - os . path . getatime ( path ) > 129600 :
",100.0,100.0,True
"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB> <TAB> stdout = None <TAB> <TAB> try : <TAB> <TAB> <TAB> stdout , stderr = Popen ( <TAB> <TAB> <TAB> <TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB> <TAB> <TAB> <TAB> stdout = PIPE , <TAB> <TAB> <TAB> <TAB> stderr = PIPE , <TAB> <TAB> <TAB> ) . communicate ( ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for line in stdout . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> if len ( line ) == 2 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info ","if stdout : 
","if stdout :
",78.12,0.0,False
"def add ( meta_list , info_list = None ) : <TAB> if not info_list : <TAB> <TAB> info_list = meta_list <TAB> if not isinstance ( meta_list , ( list , tuple ) ) : <TAB> <TAB> meta_list = ( meta_list , ) <TAB> if not isinstance ( info_list , ( list , tuple ) ) : <TAB> <TAB> info_list = ( info_list , ) <TAB> for info_f in info_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for meta_f in meta_list : <TAB> <TAB> <TAB> <TAB> metadata [ meta_f ] = info [ info_f ] <TAB> <TAB> <TAB> break ","if info . get ( info_f ) is not None : 
","if info_f not in metadata :
",26.33,14.48,False
"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log_r_term = model_site [ "" log_prob "" ] <TAB> <TAB> <TAB> if not model_site [ "" is_observed "" ] : <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB> <TAB> <TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r ","if model_site [ "" type "" ] == "" sample "" : 
","if "" log_prob "" in model_site :
",34.59,11.99,False
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> if prog . match ( line ) : <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None ","if not line or not line [ 0 ] . isspace ( ) : 
","if not line :
",30.72,5.24,False
"def build_iterator ( data , infinite = True ) : <TAB> """"""Build the iterator for inputs."""""" <TAB> index = 0 <TAB> size = len ( data [ 0 ] ) <TAB> while True : <TAB> <TAB> if index + batch_size > size : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> index = 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield data [ 0 ] [ index : index + batch_size ] , data [ 1 ] [ index : index + batch_size ] <TAB> <TAB> index + = batch_size ","if infinite : 
","if infinite :
",78.12,0.0,False
"def checkall ( g , bg , dst_nodes , include_dst_in_src = True ) : <TAB> for etype in g . etypes : <TAB> <TAB> ntype = g . to_canonical_etype ( etype ) [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> check ( g , bg , ntype , etype , dst_nodes [ ntype ] , include_dst_in_src ) <TAB> <TAB> else : <TAB> <TAB> <TAB> check ( g , bg , ntype , etype , None , include_dst_in_src ) ","if dst_nodes is not None and ntype in dst_nodes : 
","if ntype in dst_nodes :
",42.16,30.93,False
"def minimalBases ( classes ) : <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3 :<TAB> # pragma: no cover <TAB> <TAB> classes = [ c for c in classes if c is not ClassType ] <TAB> candidates = [ ] <TAB> for m in classes : <TAB> <TAB> for n in classes : <TAB> <TAB> <TAB> if issubclass ( n , m ) and m is not n : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> candidates . remove ( m )<TAB> # ensure that we're later in the list <TAB> <TAB> <TAB> candidates . append ( m ) <TAB> return candidates ","if m in candidates : 
","if m in candidates :
",100.0,100.0,True
"def __keep_songs_enable ( self , enabled ) : <TAB> config . set ( "" memory "" , "" queue_keep_songs "" , enabled ) <TAB> if enabled : <TAB> <TAB> self . queue . set_first_column_type ( CurrentColumn ) <TAB> else : <TAB> <TAB> for col in self . queue . get_columns ( ) : <TAB> <TAB> <TAB> # Remove the CurrentColum if it exists <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . queue . set_first_column_type ( None ) <TAB> <TAB> <TAB> <TAB> break ","if isinstance ( col , CurrentColumn ) : 
","if col . name == CurrentColumn . NAME :
",26.9,5.93,False
"def outlineView_heightOfRowByItem_ ( self , tree , item ) - > float : <TAB> default_row_height = self . rowHeight <TAB> if item is self : <TAB> <TAB> return default_row_height <TAB> heights = [ default_row_height ] <TAB> for column in self . tableColumns : <TAB> <TAB> value = getattr ( item . attrs [ "" node "" ] , str ( column . identifier ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # if the cell value is a widget, use its height <TAB> <TAB> <TAB> heights . append ( value . _impl . native . intrinsicContentSize ( ) . height ) <TAB> return max ( heights ) ","if isinstance ( value , toga . Widget ) : 
","if isinstance ( value , Gtk . TableCell ) :
",73.56,46.71,False
"def condition ( self ) : <TAB> if self . __condition is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self . __condition = self . flat_conditions [ 0 ] <TAB> <TAB> elif len ( self . flat_conditions ) == 0 : <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self . __condition = lambda _ : True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB> return self . __condition ","if len ( self . flat_conditions ) == 1 : 
","if len ( self . flat_conditions ) == 1 :
",100.0,100.0,True
"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB> <TAB> return 0 <TAB> while True : <TAB> <TAB> b = f . read ( block_size ) <TAB> <TAB> if not b : <TAB> <TAB> <TAB> return f . tell ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1 ","elif delimiter in b : 
","if b [ - 1 ] . startswith ( delimiter ) :
",26.95,4.46,False
"def serialize ( self , name = None ) : <TAB> data = super ( SimpleText , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> data [ "" content "" ] = self . content <TAB> if self . width : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidWidthException ( self . width ) <TAB> <TAB> data [ "" inputOptions "" ] = { } <TAB> <TAB> data [ "" width "" ] = self . width <TAB> return data ","if self . width not in [ 100 , 50 , 33 , 25 ] : 
","if self . width not in [ 100 , 100 , 50 , 50 ] :
",84.58,68.65,False
"def inference ( self ) : <TAB> self . attention_weight_dim = self . input_dims [ 0 ] [ - 1 ] <TAB> if self . keep_dim : <TAB> <TAB> self . output_dim = copy . deepcopy ( self . input_dims [ 0 ] ) <TAB> else : <TAB> <TAB> self . output_dim = [ ] <TAB> <TAB> for idx , dim in enumerate ( self . input_dims [ 0 ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . output_dim . append ( dim ) <TAB> super ( <TAB> <TAB> LinearAttentionConf , self <TAB> ) . inference ( )<TAB> # PUT THIS LINE AT THE END OF inference() ","if idx != len ( self . input_dims [ 0 ] ) - 2 : 
","if dim is not None and idx != self . attention_weight_dim :
",30.39,11.35,False
"def __delete_hook ( self , rpc ) : <TAB> try : <TAB> <TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB> <TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB> <TAB> if status == MemcacheDeleteResponse . DELETED : <TAB> <TAB> <TAB> result . append ( DELETE_SUCCESSFUL ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( DELETE_ITEM_MISSING ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result ","elif status == MemcacheDeleteResponse . NOT_FOUND : 
","elif status == MemcacheDeleteResponse . ITEMMISSING :
",82.41,55.07,False
def identify_page_at_cursor ( self ) : <TAB> for region in self . view . sel ( ) : <TAB> <TAB> text_on_cursor = None <TAB> <TAB> pos = region . begin ( ) <TAB> <TAB> scope_region = self . view . extract_scope ( pos ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text_on_cursor = self . view . substr ( scope_region ) <TAB> <TAB> <TAB> return text_on_cursor . strip ( string . punctuation ) <TAB> return None ,"if not scope_region . empty ( ) : 
","if scope_region :
",26.66,16.62,False
"def from_elem ( cls , parent , when_elem ) : <TAB> """"""Loads the proper when by attributes of elem"""""" <TAB> when_value = when_elem . get ( "" value "" , None ) <TAB> <MASK> <TAB> <TAB> return ValueToolOutputActionConditionalWhen ( parent , when_elem , when_value ) <TAB> else : <TAB> <TAB> when_value = when_elem . get ( "" datatype_isinstance "" , None ) <TAB> <TAB> if when_value is not None : <TAB> <TAB> <TAB> return DatatypeIsInstanceToolOutputActionConditionalWhen ( <TAB> <TAB> <TAB> <TAB> parent , when_elem , when_value <TAB> <TAB> <TAB> ) <TAB> raise TypeError ( "" When type not implemented "" ) ","if when_value is not None : 
","if when_value is not None :
",100.0,100.0,True
"def test_insert_entity_empty_string_rk ( <TAB> self , tables_cosmos_account_name , tables_primary_cosmos_account_key ) : <TAB> # Arrange <TAB> await self . _set_up ( tables_cosmos_account_name , tables_primary_cosmos_account_key ) <TAB> try : <TAB> <TAB> entity = { "" PartitionKey "" : "" pk "" , "" RowKey "" : "" "" } <TAB> <TAB> # Act <TAB> <TAB> with pytest . raises ( HttpResponseError ) : <TAB> <TAB> <TAB> await self . table . create_entity ( entity = entity ) <TAB> <TAB> <TAB> # Assert <TAB> <TAB> #  assert resp is None <TAB> finally : <TAB> <TAB> await self . _tear_down ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sleep ( SLEEP_DELAY ) ","if self . is_live : 
","if self . is_live :
",100.0,100.0,True
"def provider_uris ( self ) : <TAB> login_urls = { } <TAB> continue_url = self . request . get ( "" continue_url "" ) <TAB> for provider in self . provider_info : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> login_url = self . uri_for ( <TAB> <TAB> <TAB> <TAB> "" social-login "" , provider_name = provider , continue_url = continue_url <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> login_url = self . uri_for ( "" social-login "" , provider_name = provider ) <TAB> <TAB> login_urls [ provider ] = login_url <TAB> return login_urls ","if continue_url : 
","if provider in continue_url :
",34.79,43.47,False
"def expand_extensions ( existing ) : <TAB> for name in extension_names : <TAB> <TAB> ext = ( <TAB> <TAB> <TAB> im ( "" lizard_ext.lizard "" + name . lower ( ) ) . LizardExtension ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else name <TAB> <TAB> ) <TAB> <TAB> existing . insert ( <TAB> <TAB> <TAB> len ( existing ) if not hasattr ( ext , "" ordering_index "" ) else ext . ordering_index , <TAB> <TAB> <TAB> ext , <TAB> <TAB> ) <TAB> return existing ","if isinstance ( name , str ) 
","if not hasattr ( ext , "" ordering_index "" )
",26.99,4.79,False
"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB> <TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB> <TAB> <TAB> uri = self . request . path + "" / "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs ) ","if self . request . query : 
","if self . request . query :
",100.0,100.0,True
"def subword_map_by_joiner ( subwords , marker = SubwordMarker . JOINER ) : <TAB> """"""Return word id for each subword token (annotate by joiner)."""""" <TAB> flags = [ 0 ] * len ( subwords ) <TAB> for i , tok in enumerate ( subwords ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flags [ i ] = 1 <TAB> <TAB> if tok . startswith ( marker ) : <TAB> <TAB> <TAB> assert i > = 1 and flags [ i - 1 ] != 1 , "" Sentence ` {} ` not correct! "" . format ( <TAB> <TAB> <TAB> <TAB> "" "" . join ( subwords ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> flags [ i - 1 ] = 1 <TAB> marker_acc = list ( accumulate ( [ 0 ] + flags [ : - 1 ] ) ) <TAB> word_group = [ ( i - maker_sofar ) for i , maker_sofar in enumerate ( marker_acc ) ] <TAB> return word_group ","if tok . endswith ( marker ) : 
","if tok . isspace ( ) :
",39.31,27.89,False
"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self . select ( start ) <TAB> <TAB> <TAB> break <TAB> <TAB> if i > = len ( self . items ) : <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0 : <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> i + = direction <TAB> <TAB> if start < 0 : <TAB> <TAB> <TAB> start = 0 ","if self . select ( i ) : 
","if i == start :
",26.99,7.65,False
"def get_config ( cls ) : <TAB> # FIXME: Replace this as soon as we have a config module <TAB> config = { } <TAB> # Try to get iflytek_yuyin config from config <TAB> profile_path = dingdangpath . config ( "" profile.yml "" ) <TAB> if os . path . exists ( profile_path ) : <TAB> <TAB> with open ( profile_path , "" r "" ) as f : <TAB> <TAB> <TAB> profile = yaml . safe_load ( f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if "" vid "" in profile [ "" iflytek_yuyin "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> config [ "" vid "" ] = profile [ "" iflytek_yuyin "" ] [ "" vid "" ] <TAB> return config ","if "" iflytek_yuyin "" in profile : 
","if "" iflytek_yuyin "" in profile :
",100.0,100.0,True
"def get_signed_in_user ( test_case ) : <TAB> playback = not ( test_case . is_live or test_case . in_recording ) <TAB> if playback : <TAB> <TAB> return MOCKED_USER_NAME <TAB> else : <TAB> <TAB> account_info = test_case . cmd ( "" account show "" ) . get_output_in_json ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return account_info [ "" user "" ] [ "" name "" ] <TAB> return None ","if account_info [ "" user "" ] [ "" type "" ] != "" servicePrincipal "" : 
","if account_info and "" user "" in account_info :
",37.91,16.88,False
"def rename_project ( self , project , new_name ) : <TAB> """"""Rename project, update the related projects if necessary"""""" <TAB> old_name = project . name <TAB> for proj in self . projects : <TAB> <TAB> relproj = proj . get_related_projects ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> relproj [ relproj . index ( old_name ) ] = new_name <TAB> <TAB> <TAB> proj . set_related_projects ( relproj ) <TAB> project . rename ( new_name ) <TAB> self . save ( ) ","if old_name in relproj : 
","if old_name in relproj :
",100.0,100.0,True
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None : <TAB> <TAB> <TAB> return True <TAB> <TAB> if len ( a ) != b . len : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0 ","if a . ptr == b . ptr : 
","if a . ptr != b . ptr :
",79.99,65.8,False
"def parse_variable ( self ) : <TAB> begin = self . _pos <TAB> while True : <TAB> <TAB> ch = self . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ScriptVariable ( self . _text [ begin : self . _pos - 1 ] ) <TAB> <TAB> elif ch is None : <TAB> <TAB> <TAB> self . __raise_eof ( ) <TAB> <TAB> elif not isidentif ( ch ) and ch != "" : "" : <TAB> <TAB> <TAB> self . __raise_char ( ch ) ","if ch == "" % "" : 
","if isidentif ( ch ) and self . _pos > 0 :
",26.76,4.07,False
"def h_file ( self ) : <TAB> filename = self . abspath ( ) <TAB> st = os . stat ( filename ) <TAB> cache = self . ctx . hashes_md5_tstamp <TAB> if filename in cache and cache [ filename ] [ 0 ] == st . st_mtime : <TAB> <TAB> return cache [ filename ] [ 1 ] <TAB> if STRONGEST : <TAB> <TAB> ret = Utils . h_file ( filename ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IOError ( "" Not a file "" ) <TAB> <TAB> ret = Utils . md5 ( str ( ( st . st_mtime , st . st_size ) ) . encode ( ) ) . digest ( ) <TAB> cache [ filename ] = ( st . st_mtime , ret ) <TAB> return ret ","if stat . S_ISDIR ( st [ stat . ST_MODE ] ) : 
","if not ( st . st_mtime < self . ctx . hash_md5_tstamp ) :
",34.77,6.63,False
"def add_widgets ( self , * widgets_or_spacings ) : <TAB> """"""Add widgets/spacing to dialog vertical layout"""""" <TAB> layout = self . layout ( ) <TAB> for widget_or_spacing in widgets_or_spacings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> layout . addSpacing ( widget_or_spacing ) <TAB> <TAB> else : <TAB> <TAB> <TAB> layout . addWidget ( widget_or_spacing ) ","if isinstance ( widget_or_spacing , int ) : 
","if isinstance ( widget_or_spacing , wx . StaticSpacing ) :
",51.33,64.5,False
"def _str_index ( self ) : <TAB> idx = self [ "" index "" ] <TAB> out = [ ] <TAB> if len ( idx ) == 0 : <TAB> <TAB> return out <TAB> out + = [ "" .. index::  %s "" % idx . get ( "" default "" , "" "" ) ] <TAB> for section , references in idx . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif section == "" refguide "" : <TAB> <TAB> <TAB> out + = [ ""<TAB> single:  %s "" % ( "" ,  "" . join ( references ) ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> out + = [ ""<TAB>  %s :  %s "" % ( section , "" , "" . join ( references ) ) ] <TAB> return out ","if section == "" default "" : 
","if section == "" default "" :
",100.0,100.0,True
"def dictify_CPPDEFINES ( env ) : <TAB> cppdefines = env . get ( "" CPPDEFINES "" , { } ) <TAB> if cppdefines is None : <TAB> <TAB> return { } <TAB> if SCons . Util . is_Sequence ( cppdefines ) : <TAB> <TAB> result = { } <TAB> <TAB> for c in cppdefines : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ c [ 0 ] ] = c [ 1 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result [ c ] = None <TAB> <TAB> return result <TAB> if not SCons . Util . is_Dict ( cppdefines ) : <TAB> <TAB> return { cppdefines : None } <TAB> return cppdefines ","if SCons . Util . is_Sequence ( c ) : 
","if SCons . Util . is_Sequence ( c ) :
",100.0,100.0,True
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> if c == "" & "" and not decode : <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> elif c == "" - "" and decode : <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) ) ","elif decode : 
","elif c in "" ~ "" :
",29.58,7.81,False
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed ","if not Placeholder . check_resolved ( v . size ) : 
","if not isinstance ( v , GraphVariable ) :
",28.62,10.59,False
"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB> <TAB> if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ "" v "" ] ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1 ","elif op_gprv ( op ) : 
","elif op_reg ( op ) and op . oc1 in [ "" gpr "" ] :
",45.08,13.97,False
"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir : <TAB> <TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB> <TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB> <TAB> if seq_file and os . path . exists ( seq_file ) : <TAB> <TAB> <TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB> <TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return gdirs [ 0 ] ","if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) : 
","if gdirs :
",25.37,0.0,False
"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB> <TAB> line = line and line . strip ( ) <TAB> <TAB> if not line or line . startswith ( "" - "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line . split ( ) <TAB> <TAB> for module in line_modules : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB> <TAB> <TAB> module_parts = module . split ( "" / "" ) <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len ( module_parts ) == 2 : <TAB> <TAB> <TAB> <TAB> module_version = module_parts [ 1 ] <TAB> <TAB> <TAB> module_name = module_parts [ 0 ] <TAB> <TAB> <TAB> yield module_name , module_version ","if module . endswith ( self . default_indicator ) : 
","if module . endswith ( self . default_indicator ) :
",100.0,100.0,True
"def save ( self ) : <TAB> updates = self . cinder_obj_get_changes ( ) <TAB> if updates : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> metadata = updates . pop ( "" metadata "" , None ) <TAB> <TAB> <TAB> self . metadata = db . backup_metadata_update ( <TAB> <TAB> <TAB> <TAB> self . _context , self . id , metadata , True <TAB> <TAB> <TAB> ) <TAB> <TAB> updates . pop ( "" parent "" , None ) <TAB> <TAB> db . backup_update ( self . _context , self . id , updates ) <TAB> self . obj_reset_changes ( ) ","if "" metadata "" in updates : 
","if "" metadata "" in updates :
",100.0,100.0,True
"def test_set_tag ( association_obj , sagemaker_session ) : <TAB> tag = { "" Key "" : "" foo "" , "" Value "" : "" bar "" } <TAB> association_obj . set_tag ( tag ) <TAB> while True : <TAB> <TAB> actual_tags = sagemaker_session . sagemaker_client . list_tags ( <TAB> <TAB> <TAB> ResourceArn = association_obj . source_arn <TAB> <TAB> ) [ "" Tags "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( 5 ) <TAB> # When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints, <TAB> # length of actual tags will be greater than 1 <TAB> assert len ( actual_tags ) > 0 <TAB> assert actual_tags [ 0 ] == tag ","if actual_tags : 
","if actual_tags :
",78.12,100.0,True
"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> "" flush "" , <TAB> <TAB> "" write "" , <TAB> <TAB> "" writelines "" , <TAB> ] : <TAB> <TAB> if not hasattr ( wsgi_errors , method ) : <TAB> <TAB> <TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB> <TAB> if error_msg : <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ] ","if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) : 
","elif not callable ( wsgi_errors [ method ] ) :
",29.57,19.07,False
"def current_dict ( cursor_offset , line ) : <TAB> """"""If in dictionary completion, return the dict that should be used"""""" <TAB> for m in current_dict_re . finditer ( line ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return LinePart ( m . start ( 1 ) , m . end ( 1 ) , m . group ( 1 ) ) <TAB> return None ","if m . start ( 2 ) < = cursor_offset and m . end ( 2 ) > = cursor_offset : 
","if m . start ( 1 ) < = cursor_offset and m . end ( 1 ) > = cursor_offset :
",86.34,77.49,False
"def show_file_browser ( self ) : <TAB> """"""Show/hide the file browser."""""" <TAB> if self . show_file_browser_action . isChecked ( ) : <TAB> <TAB> sizes = self . panel . sizes ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sizes [ 0 ] = sum ( sizes ) / / 4 <TAB> <TAB> <TAB> self . panel . setSizes ( sizes ) <TAB> <TAB> self . file_browser . show ( ) <TAB> else : <TAB> <TAB> self . file_browser . hide ( ) ","if sizes [ 0 ] == 0 : 
","if sizes :
",28.07,0.0,False
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . nameEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" ) ","if len ( items ) > 1 : 
","if len ( items ) > 1 :
",100.0,100.0,True
"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> if len ( root ) > 0 : <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self ","if not tag . text : 
","if tag . text == "" "" :
",40.53,20.16,False
"def getLabel ( self , address = None ) : <TAB> if address is None : <TAB> <TAB> address = self . address <TAB> label = address <TAB> if shared . config . has_section ( address ) : <TAB> <TAB> label = shared . config . get ( address , "" label "" ) <TAB> queryreturn = sqlQuery ( """""" select label from addressbook where address=? """""" , address ) <TAB> <MASK> <TAB> <TAB> for row in queryreturn : <TAB> <TAB> <TAB> ( label , ) = row <TAB> else : <TAB> <TAB> queryreturn = sqlQuery ( <TAB> <TAB> <TAB> """"""select label from subscriptions where address=?"""""" , address <TAB> <TAB> ) <TAB> <TAB> if queryreturn != [ ] : <TAB> <TAB> <TAB> for row in queryreturn : <TAB> <TAB> <TAB> <TAB> ( label , ) = row <TAB> return label ","if queryreturn != [ ] : 
","if queryreturn != [ ] :
",100.0,100.0,True
"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if "" momentum "" in self . args : 
","if "" momentum "" in self . args :
",100.0,100.0,True
"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB> <TAB> new_kwargs = dict ( kwargs ) <TAB> <TAB> if "" encoding "" in new_kwargs : <TAB> <TAB> <TAB> del new_kwargs [ "" encoding "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs ) ","if "" errors "" in kwargs : 
","if "" errors "" in new_kwargs :
",82.52,51.33,False
"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB> <TAB> if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] : <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( )<TAB> # Remove the current form. if it is at the end of the list <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self . setNextForm ( <TAB> <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( ) <TAB> <TAB> <TAB> )<TAB> # Switch to the previous form if one exists <TAB> except IndexError : <TAB> <TAB> self . setNextForm ( backup ) ","if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM : 
","if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] :
",71.96,55.56,False
"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB> <TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB> <TAB> <TAB> if current_word : <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [ char ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current_word . append ( char ) <TAB> if current_word : <TAB> <TAB> yield current_word ","elif current_word and self . char_begins_new_word ( current_word , char ) : 
","elif char [ "" text "" ] . isspace ( ) :
",27.37,3.87,False
"def get ( self ) : <TAB> """"""return a secret by name"""""" <TAB> results = self . _get ( "" secrets "" , self . name ) <TAB> results [ "" decoded "" ] = { } <TAB> results [ "" exists "" ] = False <TAB> if results [ "" returncode "" ] == 0 and results [ "" results "" ] [ 0 ] : <TAB> <TAB> results [ "" exists "" ] = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" data "" in results [ "" results "" ] [ 0 ] : <TAB> <TAB> <TAB> <TAB> for sname , value in results [ "" results "" ] [ 0 ] [ "" data "" ] . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> results [ "" decoded "" ] [ sname ] = base64 . b64decode ( value ) <TAB> if results [ "" returncode "" ] != 0 and ' "" %s ""  not found ' % self . name in results [ "" stderr "" ] : <TAB> <TAB> results [ "" returncode "" ] = 0 <TAB> return results ","if self . decode : 
","if results [ "" returncode "" ] == 0 and results [ "" results "" ] [ 0 ] [ "" type "" ] == "" secret "" :
",27.01,1.43,False
"def insert_use ( self , edit ) : <TAB> if self . is_first_use ( ) : <TAB> <TAB> for location in [ r "" ^ \ s*namespace \ s+[ \ w \\ ]+[; { ] "" , r "" < \ ?php "" ] : <TAB> <TAB> <TAB> inserted = self . insert_first_use ( location , edit ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> self . insert_use_among_others ( edit ) ","if inserted : 
","if inserted :
",78.12,0.0,False
"def _new_rsa_key ( spec ) : <TAB> if "" name "" not in spec : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ( head , tail ) = os . path . split ( spec [ "" key "" ] ) <TAB> <TAB> <TAB> spec [ "" path "" ] = head <TAB> <TAB> <TAB> spec [ "" name "" ] = tail <TAB> <TAB> else : <TAB> <TAB> <TAB> spec [ "" name "" ] = spec [ "" key "" ] <TAB> return rsa_init ( spec ) ","if "" / "" in spec [ "" key "" ] : 
","if spec [ "" key "" ] . startswith ( "" / "" ) :
",61.61,43.33,False
"def mimeData ( self , indexes ) : <TAB> if len ( indexes ) == 1 : <TAB> <TAB> index = indexes [ 0 ] <TAB> <TAB> model = song = index . data ( Qt . UserRole ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> model = song . album <TAB> <TAB> <TAB> except ( ProviderIOError , Exception ) : <TAB> <TAB> <TAB> <TAB> model = None <TAB> <TAB> return ModelMimeData ( model ) ","if index . column ( ) == Column . album : 
","if song :
",25.92,0.0,False
"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB> <TAB> if url . endswith ( "" ping "" ) and self . _first_ping : <TAB> <TAB> <TAB> self . _first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ErrorApiResponse ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = app . get ( url , * * kwargs ) <TAB> <TAB> <TAB> return TestingResponse ( response ) <TAB> else : <TAB> <TAB> return requests . get ( url , * * kwargs ) ","elif "" Hello0 "" in url and "" 1.2.1 "" in url and "" v1 "" in url : 
","elif url . endswith ( "" error "" ) :
",33.18,2.55,False
"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB> <TAB> if hasattr ( model , "" _create_content_base "" ) : <TAB> <TAB> <TAB> self . validate_base_model ( model ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . validate_content_type ( model ) ","if hasattr ( model , "" _feincms_content_models "" ) : 
","if hasattr ( model , "" _create_content_type "" ) :
",83.03,57.74,False
"def test_rules_widget ( self ) : <TAB> subreddit = self . reddit . subreddit ( pytest . placeholders . test_subreddit ) <TAB> widgets = subreddit . widgets <TAB> with self . use_cassette ( "" TestSubredditWidgets.fetch_widgets "" ) : <TAB> <TAB> rules = None <TAB> <TAB> for widget in widgets . sidebar : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> rules = widget <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert isinstance ( rules , RulesWidget ) <TAB> <TAB> assert rules == rules <TAB> <TAB> assert rules . id == rules <TAB> <TAB> assert rules . display <TAB> <TAB> assert len ( rules ) > 0 <TAB> <TAB> assert subreddit == rules . subreddit ","if isinstance ( widget , RulesWidget ) : 
","if isinstance ( widget , RulesWidget ) :
",100.0,100.0,True
"def __init__ ( self , exception ) : <TAB> message = str ( exception ) <TAB> with contextlib . suppress ( IndexError ) : <TAB> <TAB> underlying_exception = exception . args [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message = ( <TAB> <TAB> <TAB> <TAB> "" maximum retries exceeded trying to reach the store. \n "" <TAB> <TAB> <TAB> <TAB> "" Check your network connection, and check the store  "" <TAB> <TAB> <TAB> <TAB> "" status at  {} "" . format ( _STORE_STATUS_URL ) <TAB> <TAB> <TAB> ) <TAB> super ( ) . __init__ ( message = message ) ","if isinstance ( underlying_exception , urllib3 . exceptions . MaxRetryError ) : 
","if underlying_exception . args [ 0 ] == "" Rejected "" :
",30.44,11.63,False
"def wrapped ( self , request ) : <TAB> try : <TAB> <TAB> return self . _finished <TAB> except AttributeError : <TAB> <TAB> if self . node_ids : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> log . debug ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  is still going to be used, not terminating it.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Still in use on: \n %s "" , <TAB> <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> <TAB> <TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( request ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _finished = True ","if not request . session . shouldfail and not request . session . shouldstop : 
","if not self . _finished :
",32.04,4.98,False
"def get_min_vertical_scroll ( ) - > int : <TAB> # Make sure that the cursor line is not below the bottom. <TAB> # (Calculate how many lines can be shown between the cursor and the .) <TAB> used_height = 0 <TAB> prev_lineno = ui_content . cursor_position . y <TAB> for lineno in range ( ui_content . cursor_position . y , - 1 , - 1 ) : <TAB> <TAB> used_height + = get_line_height ( lineno ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return prev_lineno <TAB> <TAB> else : <TAB> <TAB> <TAB> prev_lineno = lineno <TAB> return 0 ","if used_height > height - scroll_offsets_bottom : 
","if used_height > scroll_height :
",34.45,35.05,False
"def cookies ( self ) : <TAB> # strip cookie_suffix from all cookies in the request, return result <TAB> cookies = flask . Request . cookies . __get__ ( self ) <TAB> result = { } <TAB> desuffixed = { } <TAB> for key , value in cookies . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> desuffixed [ key [ : - len ( self . cookie_suffix ) ] ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = value <TAB> result . update ( desuffixed ) <TAB> return result ","if key . endswith ( self . cookie_suffix ) : 
","if key . endswith ( self . cookie_suffix ) :
",100.0,100.0,True
"def update_vars ( state1 , state2 ) : <TAB> ops = [ ] <TAB> for name in state1 . _fields : <TAB> <TAB> state1_vs = getattr ( state1 , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ops + = [ <TAB> <TAB> <TAB> <TAB> tf . assign ( _v1 , _v2 ) <TAB> <TAB> <TAB> <TAB> for _v1 , _v2 in zip ( state1_vs , getattr ( state2 , name ) ) <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ops + = [ tf . assign ( state1_vs , getattr ( state2 , name ) ) ] <TAB> return tf . group ( * ops ) ","if isinstance ( state1_vs , list ) : 
","if isinstance ( state1_vs , tuple ) :
",79.9,70.71,False
"def manifest ( self ) : <TAB> """"""The current manifest dictionary."""""" <TAB> if self . reload : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return { } <TAB> <TAB> mtime = self . getmtime ( self . manifest_path ) <TAB> <TAB> if self . _mtime is None or mtime > self . _mtime : <TAB> <TAB> <TAB> self . _manifest = self . get_manifest ( ) <TAB> <TAB> <TAB> self . _mtime = mtime <TAB> return self . _manifest ","if not self . exists ( self . manifest_path ) : 
","if self . manifest_path is None :
",37.44,31.13,False
"def csvtitle ( self ) : <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> return ' "" ' + self . name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB> else : <TAB> <TAB> ret = "" "" <TAB> <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> <TAB> ret = ret + ' "" ' + name + ' "" ' + char [ "" sep "" ] * ( len ( self . nick ) - 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" sep "" ] <TAB> <TAB> return ret ","if i + 1 != len ( self . name ) : 
","if i < len ( self . nick ) - 1 :
",49.81,25.67,False
"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB> <TAB> for dst , src in viewitems ( assignblk ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if final_dst is not None : <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst ","if dst . is_id ( "" IRDst "" ) : 
","if dst == self . _dst :
",31.97,8.59,False
"def _ProcessName ( self , name , dependencies ) : <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if module_name in dependencies : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] . add ( base_name ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] = { base_name } <TAB> <TAB> else : <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging . warning ( "" Empty package name:  %s "" , name ) ","if module_name : 
","if self . _IsDot ( module_name ) :
",29.65,15.85,False
"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB> <TAB> if i == "" [ "" : <TAB> <TAB> <TAB> m = - 1 <TAB> <TAB> <TAB> aas . append ( "" "" ) <TAB> <TAB> elif i == "" ] "" : <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == - 1 : <TAB> <TAB> <TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> aas . append ( i ) <TAB> return aas ","elif m == 0 : 
","elif m == 1 :
",64.48,53.73,False
"def logic ( ) : <TAB> count = intbv ( 0 , min = 0 , max = MAXVAL + 1 ) <TAB> while True : <TAB> <TAB> yield clock . posedge , reset . posedge <TAB> <TAB> if reset == 1 : <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> flag . next = 0 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> flag . next = 1 <TAB> <TAB> <TAB> <TAB> count [ : ] = 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> count + = 1 ","if count == MAXVAL : 
","if enable :
",28.55,0.0,False
"def _history_define_metric ( <TAB> self , hkey : str ) - > Optional [ wandb_internal_pb2 . MetricRecord ] : <TAB> """"""check for hkey match in glob metrics, return defined metric."""""" <TAB> # Dont define metric for internal metrics <TAB> if hkey . startswith ( "" _ "" ) : <TAB> <TAB> return None <TAB> for k , mglob in six . iteritems ( self . _metric_globs ) : <TAB> <TAB> if k . endswith ( "" * "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> m = wandb_internal_pb2 . MetricRecord ( ) <TAB> <TAB> <TAB> <TAB> m . CopyFrom ( mglob ) <TAB> <TAB> <TAB> <TAB> m . ClearField ( "" glob_name "" ) <TAB> <TAB> <TAB> <TAB> m . name = hkey <TAB> <TAB> <TAB> <TAB> return m <TAB> return None ","if hkey . startswith ( k [ : - 1 ] ) : 
","if mglob . name == hkey :
",29.23,4.18,False
"def optimize_models ( args , use_cuda , models ) : <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models : <TAB> <TAB> model . make_generation_fast_ ( <TAB> <TAB> <TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB> <TAB> <TAB> need_attn = args . print_alignment , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> model . half ( ) <TAB> <TAB> if use_cuda : <TAB> <TAB> <TAB> model . cuda ( ) ","if args . fp16 : 
","if use_half :
",28.55,12.7,False
"def _Dynamic_Rollback ( self , transaction , transaction_response ) : <TAB> txid = transaction . handle ( ) <TAB> self . __local_tx_lock . acquire ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise apiproxy_errors . ApplicationError ( <TAB> <TAB> <TAB> <TAB> datastore_pb . Error . BAD_REQUEST , "" Transaction  %d  not found. "" % ( txid , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> txdata = self . __transactions [ txid ] <TAB> <TAB> assert ( <TAB> <TAB> <TAB> txdata . thread_id == thread . get_ident ( ) <TAB> <TAB> ) , "" Transactions are single-threaded. "" <TAB> <TAB> del self . __transactions [ txid ] <TAB> finally : <TAB> <TAB> self . __local_tx_lock . release ( ) ","if txid not in self . __transactions : 
","if txid not in self . __transactions :
",100.0,100.0,True
"def get_job_dirs ( path ) : <TAB> regex = re . compile ( "" [1-9][0-9]*- "" ) <TAB> jobdirs = [ ] <TAB> for d in os . listdir ( path ) : <TAB> <TAB> # skip directories not matching the job result dir pattern <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os . path . join ( options . resultsdir , d ) <TAB> <TAB> if os . path . isdir ( d ) and not os . path . exists ( os . path . join ( d , PUBLISH_FLAGFILE ) ) : <TAB> <TAB> <TAB> jobdirs . append ( d ) <TAB> return jobdirs ","if not regex . match ( d ) : 
","if regex . match ( d ) :
",74.74,76.73,False
"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB> <TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB> <TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB> <TAB> if node : <TAB> <TAB> <TAB> node . functions = list ( functions ) <TAB> <TAB> <TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB> <TAB> functions . append ( type ( node ) . __name__ ) <TAB> <TAB> for f in node . next_functions : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB> <TAB> <TAB> <TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB> <TAB> for t in node . saved_tensors : <TAB> <TAB> <TAB> traverse ( t ) ","if f [ 0 ] : 
","if hasattr ( f [ 0 ] , "" __call__ "" ) :
",52.74,15.84,False
"def get_all_snap_points ( self , forts ) : <TAB> points = [ ] <TAB> radius = Constants . MAX_DISTANCE_FORT_IS_REACHABLE <TAB> for i in range ( 0 , len ( forts ) ) : <TAB> <TAB> for j in range ( i + 1 , len ( forts ) ) : <TAB> <TAB> <TAB> c1 , c2 = self . get_enclosing_circles ( forts [ i ] , forts [ j ] , radius ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> points . append ( ( c1 , c2 , forts [ i ] , forts [ j ] ) ) <TAB> return points ","if c1 and c2 : 
","if c1 != c2 :
",32.78,22.96,False
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if not isinstance ( grandchild , minidom . Element ) : 
","if not isinstance ( grandchild , minidom . Element ) :
",100.0,100.0,True
"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB> <TAB> if ch == "" "" : <TAB> <TAB> <TAB> w + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return w ","elif ch == "" \t "" : 
","elif ch == "" \t "" :
",100.0,100.0,True
"def test_avg_group_by ( self ) : <TAB> ret = ( <TAB> <TAB> await Book . annotate ( avg = Avg ( "" rating "" ) ) <TAB> <TAB> . group_by ( "" author_id "" ) <TAB> <TAB> . values ( "" author_id "" , "" avg "" ) <TAB> ) <TAB> for item in ret : <TAB> <TAB> author_id = item . get ( "" author_id "" ) <TAB> <TAB> avg = item . get ( "" avg "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( avg , 4.5 ) <TAB> <TAB> elif author_id == self . a2 . pk : <TAB> <TAB> <TAB> self . assertEqual ( avg , 2.0 ) ","if author_id == self . a1 . pk : 
","if author_id == self . a1 . pk :
",100.0,100.0,True
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> if not expiration . tzinfo : <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ","if stored_session : 
","if stored_session :
",78.12,100.0,True
"def one_line_description ( self ) : <TAB> MAX_LINE_LENGTH = 120 <TAB> desc = util . remove_html_tags ( self . description or "" "" ) <TAB> desc = re . sub ( "" \ s+ "" , "" "" , desc ) . strip ( ) <TAB> if not desc : <TAB> <TAB> return _ ( "" No description available "" ) <TAB> else : <TAB> <TAB> # Decode the description to avoid gPodder bug 1277 <TAB> <TAB> desc = util . convert_bytes ( desc ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return desc [ : MAX_LINE_LENGTH ] + "" ... "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return desc ","if len ( desc ) > MAX_LINE_LENGTH : 
","if len ( desc ) > MAX_LINE_LENGTH :
",100.0,100.0,True
"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB> <TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB> <TAB> self . tag . append ( node ) <TAB> <TAB> name = getattr ( node , "" name "" , None ) <TAB> <TAB> if name is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> handler ( node ) ","if handler : 
","if handler :
",78.12,0.0,False
def get_supported_period_type_map ( cls ) : <TAB> if cls . supported_period_map is None : <TAB> <TAB> cls . supported_period_map = { } <TAB> <TAB> cls . supported_period_map . update ( cls . period_type_map ) <TAB> <TAB> try : <TAB> <TAB> <TAB> from dateutil import relativedelta <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cls . supported_period_map . update ( cls . optional_period_type_map ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass <TAB> return cls . supported_period_map ,"if relativedelta is not None : 
","if relativedelta ( cls . period_type_map ) is not None :
",53.33,19.56,False
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if redo : <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> if self . callback : <TAB> <TAB> <TAB> <TAB> self . callback ( ) ","if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : 
","if compare_id not in compares_done :
",26.2,7.69,False
"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB> <TAB> for field_name in field_names : <TAB> <TAB> <TAB> field_name = field_name . lower ( ) <TAB> <TAB> <TAB> if "" : "" in line : <TAB> <TAB> <TAB> <TAB> left , right = line . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> <TAB> left = left . strip ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> right = right . strip ( ) <TAB> <TAB> <TAB> <TAB> if left == field_name and len ( right ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None ","if not right . isdigit ( ) : 
","if field_name == "" actual "" :
",26.77,4.99,False
"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB> <TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB> <TAB> if not s . consume ( "" \\ "" ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB> <TAB> <TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> s . expect_re ( _escapes_re ) <TAB> <TAB> <TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res ) ","if s . consume_re ( _newline_esc_re ) : 
","elif s . consume ( "" @ "" ) :
",28.65,12.47,False
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB> <TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB> <TAB> except error_perm as error : <TAB> <TAB> <TAB> code , _ = _parse_ftp_error ( error ) <TAB> <TAB> <TAB> if code == "" 550 "" : <TAB> <TAB> <TAB> <TAB> if self . isfile ( path ) : <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryExpected ( path ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryNotEmpty ( path ) <TAB> <TAB> <TAB> raise<TAB> # pragma: no cover ","if not self . isempty ( path ) : 
","elif self . isdir ( path ) :
",54.14,36.28,False
"def _normalize_store_path ( self , resource_store ) : <TAB> if resource_store [ "" type "" ] == "" filesystem "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resource_store [ "" base_directory "" ] = os . path . join ( <TAB> <TAB> <TAB> <TAB> self . root_directory , resource_store [ "" base_directory "" ] <TAB> <TAB> <TAB> ) <TAB> return resource_store ","if not os . path . isabs ( resource_store [ "" base_directory "" ] ) : 
","if self . root_directory and resource_store [ "" base_directory "" ] :
",49.86,48.91,False
"def _apply_nested ( name , val , nested ) : <TAB> parts = name . split ( "" . "" ) <TAB> cur = nested <TAB> for i in range ( 0 , len ( parts ) - 1 ) : <TAB> <TAB> cur = cur . setdefault ( parts [ i ] , { } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conflicts_with = "" . "" . join ( parts [ 0 : i + 1 ] ) <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" %r  cannot be nested: conflicts with  { %r :  %s } "" <TAB> <TAB> <TAB> <TAB> % ( name , conflicts_with , cur ) <TAB> <TAB> <TAB> ) <TAB> cur [ parts [ - 1 ] ] = val ","if not isinstance ( cur , dict ) : 
","if cur . get ( parts [ i + 1 ] ) != val :
",26.38,3.66,False
"def build_packages ( targeted_packages , distribution_directory , is_dev_build = False ) : <TAB> # run the build and distribution <TAB> for package_root in targeted_packages : <TAB> <TAB> service_hierarchy = os . path . join ( os . path . basename ( package_root ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> verify_update_package_requirement ( package_root ) <TAB> <TAB> print ( "" Generating Package Using Python  {} "" . format ( sys . version ) ) <TAB> <TAB> run_check_call ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> sys . executable , <TAB> <TAB> <TAB> <TAB> build_packing_script_location , <TAB> <TAB> <TAB> <TAB> "" --dest "" , <TAB> <TAB> <TAB> <TAB> os . path . join ( distribution_directory , service_hierarchy ) , <TAB> <TAB> <TAB> <TAB> package_root , <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> root_dir , <TAB> <TAB> ) ","if is_dev_build : 
","if is_dev_build and os . path . isdir ( service_hierarchy ) :
",32.64,27.5,False
"def resolve_root_node_address ( self , root_node ) : <TAB> if "" [ "" in root_node : <TAB> <TAB> name , numbers = root_node . split ( "" [ "" , maxsplit = 1 ) <TAB> <TAB> number = numbers . split ( "" , "" , maxsplit = 1 ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> number = number . split ( "" - "" ) [ 0 ] <TAB> <TAB> number = re . sub ( "" [^0-9] "" , "" "" , number ) <TAB> <TAB> root_node = name + number <TAB> return root_node ","if "" - "" in number : 
","if "" - "" in number :
",100.0,100.0,True
"def _map_args ( maps : dict , * * kwargs ) : <TAB> # maps: key=old name, value= new name <TAB> output = { } <TAB> for name , val in kwargs . items ( ) : <TAB> <TAB> if name in maps : <TAB> <TAB> <TAB> assert isinstance ( maps [ name ] , str ) <TAB> <TAB> <TAB> output . update ( { maps [ name ] : val } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> output . update ( { name : val } ) <TAB> for keys in maps . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> return output ","if keys not in output . keys ( ) : 
","if keys in output :
",28.3,11.75,False
"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> if i == start : <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self . select ( start ) <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0 : <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self . select ( i ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i + = direction <TAB> <TAB> if start < 0 : <TAB> <TAB> <TAB> start = 0 ","if i > = len ( self . items ) : 
","if i > = len ( self . items ) - 1 :
",81.0,75.39,False
"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . KEY in function . context : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _explore ( function . entry_point , [ ] ) <TAB> <TAB> <TAB> function . context [ self . KEY ] = True ","if function . is_implemented : 
","if isinstance ( function , Function ) :
",27.8,7.27,False
"def load_model ( self ) : <TAB> if not os . path . exists ( self . get_filename ( absolute = True ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return { } , { } <TAB> <TAB> error ( <TAB> <TAB> <TAB> "" Model file with pre-trained convolution layers not found. Download it here... "" , <TAB> <TAB> <TAB> "" https://github.com/alexjc/neural-enhance/releases/download/v %s / %s "" <TAB> <TAB> <TAB> % ( __version__ , self . get_filename ( ) ) , <TAB> <TAB> ) <TAB> print ( ""   - Loaded file ` {} ` with trained model. "" . format ( self . get_filename ( ) ) ) <TAB> return pickle . load ( bz2 . open ( self . get_filename ( ) , "" rb "" ) ) ","if args . train : 
","if self . get_layer ( absolute = True ) == "" pretrained "" :
",35.69,3.01,False
"def get_nonexisting_check_definition_extends ( definition , indexed_oval_defs ) : <TAB> # TODO: handle multiple levels of referrals. <TAB> # OVAL checks that go beyond one level of extend_definition won't be properly identified <TAB> for extdefinition in definition . findall ( "" .// { %s }extend_definition "" % oval_ns ) : <TAB> <TAB> # Verify each extend_definition in the definition <TAB> <TAB> extdefinitionref = extdefinition . get ( "" definition_ref "" ) <TAB> <TAB> # Search the OVAL tree for a definition with the referred ID <TAB> <TAB> referreddefinition = indexed_oval_defs . get ( extdefinitionref ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # There is no oval satisfying the extend_definition referal <TAB> <TAB> <TAB> return extdefinitionref <TAB> return None ","if referreddefinition is None : 
","if referreddefinition is None :
",100.0,100.0,True
"def pause ( self ) : <TAB> if self . is_playing : <TAB> <TAB> self . state = MusicPlayerState . PAUSED <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _current_player . pause ( ) <TAB> <TAB> self . emit ( "" pause "" , player = self , entry = self . current_entry ) <TAB> <TAB> return <TAB> elif self . is_paused : <TAB> <TAB> return <TAB> raise ValueError ( "" Cannot pause a MusicPlayer in state  %s "" % self . state ) ","if self . _current_player : 
","if self . _current_player :
",100.0,100.0,True
"def setNextFormPrevious ( self , backup = STARTING_FORM ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( )<TAB> # Remove the current form. if it is at the end of the list <TAB> <TAB> if self . _THISFORM . FORM_NAME == self . NEXT_ACTIVE_FORM : <TAB> <TAB> <TAB> # take no action if it looks as if someone has already set the next form. <TAB> <TAB> <TAB> self . setNextForm ( <TAB> <TAB> <TAB> <TAB> self . _FORM_VISIT_LIST . pop ( ) <TAB> <TAB> <TAB> )<TAB> # Switch to the previous form if one exists <TAB> except IndexError : <TAB> <TAB> self . setNextForm ( backup ) ","if self . _THISFORM . FORM_NAME == self . _FORM_VISIT_LIST [ - 1 ] : 
","if self . _FORM_VISIT_LIST . get ( 0 ) != self . NEXT_FORM :
",40.43,41.76,False
"def get_expr_referrers ( schema : s_schema . Schema , obj : so . Object ) - > Dict [ so . Object , str ] : <TAB> """"""Return schema referrers with refs in expressions."""""" <TAB> refs = schema . get_referrers_ex ( obj ) <TAB> result = { } <TAB> for ( mcls , fn ) , referrers in refs . items ( ) : <TAB> <TAB> field = mcls . get_field ( fn ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . update ( { ref : fn for ref in referrers } ) <TAB> return result ","if issubclass ( field . type , ( Expression , ExpressionList ) ) : 
","if field . is_referrer :
",30.68,5.75,False
"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any ( <TAB> <TAB> <TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB> <TAB> ) <TAB> <TAB> if requires_index : <TAB> <TAB> <TAB> fields . append ( field ) <TAB> return fields ","if field . primary_key : 
","if field . name . startswith ( "" _ "" ) :
",42.93,14.32,False
"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> #<TAB>   not exposing attrs for now if orig_prefix is set.<TAB> <TAB> if not self . orig_prefix : <TAB> <TAB> <TAB> wrapped = self . wrapped <TAB> <TAB> <TAB> idents = getattr ( wrapped , "" ident_values "" , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ##<TAB> ident = self.ident<TAB> <TAB> <TAB> ##<TAB> if ident is not None:<TAB> <TAB> <TAB> ##<TAB> <TAB> value = [ident]<TAB> <TAB> self . _ident_values = value <TAB> return value ","if idents : 
","if idents is not None :
",34.04,17.97,False
"def apply_incpaths_ml ( self ) : <TAB> inc_lst = self . includes . split ( ) <TAB> lst = self . incpaths_lst <TAB> for dir in inc_lst : <TAB> <TAB> node = self . path . find_dir ( dir ) <TAB> <TAB> if not node : <TAB> <TAB> <TAB> error ( "" node not found:  "" + str ( dir ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lst . append ( node ) <TAB> <TAB> self . bld_incpaths_lst . append ( node ) ","if not node in lst : 
","if node not in lst :
",43.26,35.93,False
"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames : <TAB> <TAB> logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB> <TAB> if os . path . exists ( filename ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sabnzbd . add_nzbfile ( filename , keep = True ) ","if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES : 
","if nsapp == "" sabnzbd "" :
",25.92,1.26,False
"def check ( self , xp , nout ) : <TAB> input = xp . asarray ( self . x ) . astype ( numpy . float32 ) <TAB> with warnings . catch_warnings ( ) : <TAB> <TAB> if self . ignore_warning : <TAB> <TAB> <TAB> warnings . simplefilter ( "" ignore "" , self . ignore_warning ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . check_positive ( xp , self . func , input , self . eps , nout ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . check_negative ( xp , self . func , input , self . eps , nout ) ","if self . result : 
","if self . positive :
",64.48,42.73,False
"def _set_scheme ( url , newscheme ) : <TAB> scheme = _get_scheme ( url ) <TAB> newscheme = newscheme or "" "" <TAB> newseparator = "" : "" if newscheme in COLON_SEPARATED_SCHEMES else "" :// "" <TAB> if scheme == "" "" :<TAB> # Protocol relative URL. <TAB> <TAB> url = "" %s : %s "" % ( newscheme , url ) <TAB> elif scheme is None and url :<TAB> # No scheme. <TAB> <TAB> url = "" "" . join ( [ newscheme , newseparator , url ] ) <TAB> elif scheme :<TAB> # Existing scheme. <TAB> <TAB> remainder = url [ len ( scheme ) : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> remainder = remainder [ 3 : ] <TAB> <TAB> elif remainder . startswith ( "" : "" ) : <TAB> <TAB> <TAB> remainder = remainder [ 1 : ] <TAB> <TAB> url = "" "" . join ( [ newscheme , newseparator , remainder ] ) <TAB> return url ","if remainder . startswith ( "" :// "" ) : 
","if remainder . startswith ( "" : "" ) :
",83.03,64.32,False
"def parquet ( tables , data_directory , ignore_missing_dependency , * * params ) : <TAB> try : <TAB> <TAB> import pyarrow as pa<TAB> # noqa: F401 <TAB> <TAB> import pyarrow . parquet as pq<TAB> # noqa: F401 <TAB> except ImportError : <TAB> <TAB> msg = "" PyArrow dependency is missing "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( "" Ignored:  %s "" , msg ) <TAB> <TAB> <TAB> return 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> raise click . ClickException ( msg ) <TAB> data_directory = Path ( data_directory ) <TAB> for table , df in read_tables ( tables , data_directory ) : <TAB> <TAB> arrow_table = pa . Table . from_pandas ( df ) <TAB> <TAB> target_path = data_directory / "" {} .parquet "" . format ( table ) <TAB> <TAB> pq . write_table ( arrow_table , str ( target_path ) ) ","if ignore_missing_dependency : 
","if ignore_missing_dependency :
",78.12,100.0,True
"def h2i ( self , pkt , s ) : <TAB> t = ( ) <TAB> if type ( s ) is str : <TAB> <TAB> t = time . strptime ( s ) <TAB> <TAB> t = t [ : 2 ] + t [ 2 : - 3 ] <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y , m , d , h , min , sec , rest , rest , rest = time . gmtime ( time . time ( ) ) <TAB> <TAB> <TAB> t = ( y , m , d , h , min , sec ) <TAB> <TAB> else : <TAB> <TAB> <TAB> t = s <TAB> return t ","if not s : 
","if pkt . pkt_type == pkt . pkt_type_d :
",28.1,2.91,False
"def filter_episodes ( self , batch , cross_entropy ) : <TAB> """"""Filter the episodes for the cross_entropy method"""""" <TAB> accumulated_reward = [ sum ( rewards ) for rewards in batch [ "" rewards "" ] ] <TAB> percentile = cross_entropy * 100 <TAB> reward_bound = np . percentile ( accumulated_reward , percentile ) <TAB> # we save the batch with reward above the bound <TAB> result = { k : [ ] for k in self . data_keys } <TAB> episode_kept = 0 <TAB> for i in range ( len ( accumulated_reward ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k in self . data_keys : <TAB> <TAB> <TAB> <TAB> result [ k ] . append ( batch [ k ] [ i ] ) <TAB> <TAB> <TAB> episode_kept + = 1 <TAB> return result ","if accumulated_reward [ i ] > = reward_bound : 
","if episode_kept < reward_bound :
",27.99,21.18,False
"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB> <TAB> envvar = match . groups ( ) [ 0 ] <TAB> <TAB> if envvar in os . environ : <TAB> <TAB> <TAB> value = os . environ [ envvar ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> <TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB> <TAB> <TAB> <TAB> msg , var , _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if six . PY2 : 
","if isinstance ( value , bytes ) :
",27.64,6.57,False
"def _allocate_nbd ( self ) : <TAB> if not os . path . exists ( "" /sys/block/nbd0 "" ) : <TAB> <TAB> self . error = _ ( "" nbd unavailable: module not loaded "" ) <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> if not self . _DEVICES : <TAB> <TAB> <TAB> # really want to log this info, not raise <TAB> <TAB> <TAB> self . error = _ ( "" No free nbd devices "" ) <TAB> <TAB> <TAB> return None <TAB> <TAB> device = self . _DEVICES . pop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return device ","if not os . path . exists ( "" /sys/block/ %s /pid "" % os . path . basename ( device ) ) : 
","if not device :
",25.64,0.06,False
"def _expand_deps_java_generation ( self ) : <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB> <TAB> k = queue . popleft ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> keys . add ( k ) <TAB> <TAB> <TAB> dep = self . target_database [ k ] <TAB> <TAB> <TAB> if "" generate_java "" in dep . attr :<TAB> # Has this attribute <TAB> <TAB> <TAB> <TAB> dep . attr [ "" generate_java "" ] = True <TAB> <TAB> <TAB> <TAB> queue . extend ( dep . deps ) ","if k not in keys : 
","if k not in keys :
",100.0,100.0,True
"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB> <TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB> <TAB> if isinstance ( fstyle , basestring ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> key = fstyle [ 2 : - 2 ] <TAB> <TAB> <TAB> <TAB> fstyle = context [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats ","if fstyle . startswith ( "" % ( "" ) and fstyle . endswith ( "" )s "" ) : 
","if fstyle . startswith ( "" key= "" ) :
",56.8,23.68,False
"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values . remove ( ) <TAB> <TAB> elif operation == "" update "" : <TAB> <TAB> <TAB> old_value , new_value = values <TAB> <TAB> <TAB> if new_value . full_filename != old_value . full_filename : <TAB> <TAB> <TAB> <TAB> os . unlink ( new_value . full_filename ) <TAB> <TAB> <TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( ) ","if operation == "" insert "" : 
","if operation == "" delete "" :
",74.63,59.46,False
"def _buildOffsets ( offsetDict , localeData , indexStart ) : <TAB> o = indexStart <TAB> for key in localeData : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k in key . split ( "" | "" ) : <TAB> <TAB> <TAB> <TAB> offsetDict [ k ] = o <TAB> <TAB> else : <TAB> <TAB> <TAB> offsetDict [ key ] = o <TAB> <TAB> o + = 1 ","if "" | "" in key : 
","if "" | "" in key :
",100.0,100.0,True
"def _check_start_pipeline_execution_errors ( <TAB> graphene_info , execution_params , execution_plan ) : <TAB> if execution_params . step_keys : <TAB> <TAB> for step_key in execution_params . step_keys : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise UserFacingGraphQLError ( <TAB> <TAB> <TAB> <TAB> <TAB> graphene_info . schema . type_named ( "" InvalidStepError "" ) ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> invalid_step_key = step_key <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) ","if not execution_plan . has_step ( step_key ) : 
","if step_key not in execution_plan . step_keys :
",32.63,27.39,False
"def __setattr__ ( self , option_name , option_value ) : <TAB> if option_name in self . _options : <TAB> <TAB> # type checking <TAB> <TAB> sort = self . OPTIONS [ self . arch . name ] [ option_name ] [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _options [ option_name ] = option_value <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> ' Value for option  "" %s ""  must be of type  %s ' % ( option_name , sort ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> super ( CFGArchOptions , self ) . __setattr__ ( option_name , option_value ) ","if sort is None or isinstance ( option_value , sort ) : 
","if sort == "" & "" :
",26.94,5.77,False
"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB> <TAB> quote = True <TAB> else : <TAB> <TAB> for x in self : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote : <TAB> <TAB> pre = post = "" "" <TAB> <TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> if self [ - 1 ] . token_type == "" cfws "" or self [ - 1 ] [ - 1 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB> <TAB> return super ( DisplayName , self ) . value ","if x . token_type == "" quoted-string "" : 
","if x . token_type == "" quote "" :
",83.19,76.92,False
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename . startswith ( os . sep ) : <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> if data : <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories ","if isinstance ( filename_data , list ) : 
","if isinstance ( filename_data , tuple ) :
",79.9,70.71,False
"def _evaluateStack ( s ) : <TAB> op = s . pop ( ) <TAB> if op in "" +-*/@^ "" : <TAB> <TAB> op2 = _evaluateStack ( s ) <TAB> <TAB> op1 = _evaluateStack ( s ) <TAB> <TAB> result = opn [ op ] ( op1 , op2 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( result ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return op ","if debug_flag : 
","if result :
",56.98,0.0,False
"def reconnect_user ( self , user_id , host_id , server_id ) : <TAB> if host_id == settings . local . host_id : <TAB> <TAB> return <TAB> if server_id and self . server . id != server_id : <TAB> <TAB> return <TAB> for client in self . clients . find ( { "" user_id "" : user_id } ) : <TAB> <TAB> self . clients . update_id ( <TAB> <TAB> <TAB> client [ "" id "" ] , <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" ignore_routes "" : True , <TAB> <TAB> <TAB> } , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . instance . disconnect_wg ( client [ "" id "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . instance_com . client_kill ( client [ "" id "" ] ) ","if len ( client [ "" id "" ] ) > 32 : 
","if self . server . id == host_id :
",26.1,4.1,False
"def _get_library ( self , name , args ) : <TAB> library_database = self . _library_manager . get_new_connection_to_library_database ( ) <TAB> try : <TAB> <TAB> last_updated = library_database . get_library_last_updated ( name , args ) <TAB> <TAB> if last_updated : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _library_manager . fetch_keywords ( <TAB> <TAB> <TAB> <TAB> <TAB> name , args , self . _libraries_need_refresh_listener <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return library_database . fetch_library_keywords ( name , args ) <TAB> <TAB> return self . _library_manager . get_and_insert_keywords ( name , args ) <TAB> finally : <TAB> <TAB> library_database . close ( ) ","if time . time ( ) - last_updated > 10.0 : 
","if last_updated > self . _libraries_refresh_interval :
",31.15,20.45,False
"def get_paths ( self , path , commit ) : <TAB> """"""Return a generator of all filepaths under path at commit."""""" <TAB> _check_path_is_repo_relative ( path ) <TAB> git_path = _get_git_path ( path ) <TAB> tree = self . gl_repo . git_repo [ commit . tree [ git_path ] . id ] <TAB> assert tree . type == pygit2 . GIT_OBJ_TREE <TAB> for tree_entry in tree : <TAB> <TAB> tree_entry_path = os . path . join ( path , tree_entry . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for fp in self . get_paths ( tree_entry_path , commit ) : <TAB> <TAB> <TAB> <TAB> yield fp <TAB> <TAB> else : <TAB> <TAB> <TAB> yield tree_entry_path ","if tree_entry . type == "" tree "" : 
","if os . path . isdir ( tree_entry_path ) :
",31.53,12.57,False
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED ","if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : 
","if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] :
",100.0,100.0,True
"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self . _wb_parse_context : <TAB> <TAB> if tag == "" style "" : <TAB> <TAB> <TAB> self . _wb_parse_context = "" style "" <TAB> <TAB> elif tag == "" script "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _wb_parse_context = "" script "" ","if self . _allow_js_type ( tag_attrs ) : 
","if self . _wb_parse_context == "" script "" :
",37.16,18.92,False
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> if not isinstance ( op_list , list ) : <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> if dictionary . path in paths : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list ","if item is None : 
","if item . dictionary is None :
",38.5,30.74,False
def preorder ( root ) : <TAB> res = [ ] <TAB> if not root : <TAB> <TAB> return res <TAB> stack = [ ] <TAB> stack . append ( root ) <TAB> while stack : <TAB> <TAB> root = stack . pop ( ) <TAB> <TAB> res . append ( root . val ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stack . append ( root . right ) <TAB> <TAB> if root . left : <TAB> <TAB> <TAB> stack . append ( root . left ) <TAB> return res ,"if root . right : 
","if root . right :
",100.0,100.0,True
"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB> <TAB> self . context . log . info ( <TAB> <TAB> <TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB> <TAB> ) <TAB> <TAB> subject = self . derived_by_original . get ( <TAB> <TAB> <TAB> exported_python_target , exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB> <TAB> created [ exported_python_target ] = setup_dir <TAB> <TAB> if self . _recursive : <TAB> <TAB> <TAB> for dep in dependencies : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> create ( dep ) ","if is_exported_python_target ( dep ) : 
","if dep not in created :
",27.8,3.93,False
"def test_array_interface ( self , data ) : <TAB> result = np . array ( data ) <TAB> np . testing . assert_array_equal ( result [ 0 ] , data [ 0 ] ) <TAB> result = np . array ( data , dtype = object ) <TAB> expected = np . array ( list ( data ) , dtype = object ) <TAB> for a1 , a2 in zip ( result , expected ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert np . isnan ( a1 ) and np . isnan ( a2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tm . assert_numpy_array_equal ( a2 , a1 ) ","if np . isscalar ( a1 ) : 
","if a1 . ndim == 1 :
",32.07,7.81,False
"def valueChanged ( plug ) : <TAB> changed = plug . getInput ( ) is not None <TAB> if not changed and isinstance ( plug , Gaffer . ValuePlug ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> changed = not Gaffer . NodeAlgo . isSetToUserDefault ( plug ) <TAB> <TAB> else : <TAB> <TAB> <TAB> changed = not plug . isSetToDefault ( ) <TAB> return changed ","if Gaffer . NodeAlgo . hasUserDefault ( plug ) : 
","if Gaffer . NodeAlgo . isSetToUserDefault ( plug ) :
",83.03,65.8,False
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> if version is not None :<TAB> # if failed to get version bail <TAB> <TAB> <TAB> major , minor , _ = version <TAB> <TAB> <TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB> <TAB> <TAB> if arch is not None : <TAB> <TAB> <TAB> <TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB> <TAB> <TAB> <TAB> if exe_data is not None : <TAB> <TAB> <TAB> <TAB> <TAB> exe , args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company , major , minor , arch , exe , args ","if version is not None : 
","if version is not None :
",100.0,100.0,True
"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB> <TAB> if isinstance ( value , alias_flag_value ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( name , self . _has_flag ( value . flag ) ) ","if isinstance ( value , flag_value ) : 
","if isinstance ( value , alias_flag_value ) :
",79.9,63.4,False
"def connect ( self ) : <TAB> self . sock = sockssocket ( ) <TAB> self . sock . setproxy ( * proxy_args ) <TAB> if type ( self . timeout ) in ( int , float ) : <TAB> <TAB> self . sock . settimeout ( self . timeout ) <TAB> self . sock . connect ( ( self . host , self . port ) ) <TAB> if isinstance ( self , compat_http_client . HTTPSConnection ) : <TAB> <TAB> if hasattr ( self , "" _context "" ) :<TAB> # Python > 2.6 <TAB> <TAB> <TAB> self . sock = self . _context . wrap_socket ( self . sock , server_hostname = self . host ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . sock = ssl . wrap_socket ( self . sock ) ","if hasattr ( self , "" _context "" ) : 
","if hasattr ( self , "" _context "" ) :
",100.0,100.0,True
"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> if hasattr ( sys , "" getswitchinterval "" ) : <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval ) ","if hasattr ( sys , "" setswitchinterval "" ) : 
","if hasattr ( sys , "" setswitchinterval "" ) :
",100.0,100.0,True
"def vars ( self ) : <TAB> ret = [ ] <TAB> if op . intlist : <TAB> <TAB> varlist = op . intlist <TAB> else : <TAB> <TAB> varlist = self . discover <TAB> <TAB> for name in varlist : <TAB> <TAB> <TAB> if name in ( "" 0 "" , "" 1 "" , "" 2 "" , "" 8 "" , "" CPU0 "" , "" ERR "" , "" LOC "" , "" MIS "" , "" NMI "" ) : <TAB> <TAB> <TAB> <TAB> varlist . remove ( name ) <TAB> <TAB> if not op . full and len ( varlist ) > 3 : <TAB> <TAB> <TAB> varlist = varlist [ - 3 : ] <TAB> for name in varlist : <TAB> <TAB> if name in self . discover : <TAB> <TAB> <TAB> ret . append ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( self . intmap [ name . lower ( ) ] ) <TAB> return ret ","elif name . lower ( ) in self . intmap : 
","elif name . lower ( ) in self . intmap :
",100.0,100.0,True
"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB> <TAB> inst . add ( gadget . _gadget ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> count = len ( inst ) <TAB> <TAB> <TAB> toReturn . append ( gadget ) <TAB> <TAB> <TAB> added = True <TAB> <TAB> if callback : <TAB> <TAB> <TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB> <TAB> <TAB> added = False <TAB> return toReturn ","if len ( inst ) > count : 
","if count == len_gadgets :
",26.99,7.81,False
"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> #<TAB>   not exposing attrs for now if orig_prefix is set.<TAB> <TAB> if not self . orig_prefix : <TAB> <TAB> <TAB> wrapped = self . wrapped <TAB> <TAB> <TAB> ident = getattr ( wrapped , "" ident "" , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = self . _wrap_hash ( ident ) <TAB> <TAB> self . _ident = value <TAB> return value ","if ident is not None : 
","if ident is not None :
",100.0,100.0,True
"def _flatten_settings_from_form ( self , settings , form , form_values ) : <TAB> """"""Take a nested dict and return a flat dict of setting values."""""" <TAB> setting_values = { } <TAB> for field in form . c : <TAB> <TAB> if isinstance ( field , _ContainerMixin ) : <TAB> <TAB> <TAB> setting_values . update ( <TAB> <TAB> <TAB> <TAB> self . _flatten_settings_from_form ( <TAB> <TAB> <TAB> <TAB> <TAB> settings , field , form_values [ field . _name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setting_values [ field . _name ] = form_values [ field . _name ] <TAB> return setting_values ","elif field . _name in settings : 
","elif isinstance ( field , SettingsField ) :
",27.02,7.27,False
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != "" __init__ "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name in butnot : <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls ","if not private and name . startswith ( "" _ "" ) : 
","if name in self . __dict__ [ "" __init__ "" ] :
",32.45,6.23,False
"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB> <TAB> while True : <TAB> <TAB> <TAB> b1 = fp1 . read ( bufsize ) <TAB> <TAB> <TAB> b2 = fp2 . read ( bufsize ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> if not b1 : <TAB> <TAB> <TAB> <TAB> return True ","if b1 != b2 : 
","if b1 != b2 :
",100.0,100.0,True
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> if value : <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args ) ","if self . ctl : 
","if age > self . ctl or age > self . ttl :
",43.07,13.07,False
"def check ( self , hyperlinks : Dict [ str , Hyperlink ] ) - > Generator [ CheckResult , None , None ] : <TAB> self . invoke_threads ( ) <TAB> total_links = 0 <TAB> for hyperlink in hyperlinks . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield CheckResult ( <TAB> <TAB> <TAB> <TAB> hyperlink . uri , hyperlink . docname , hyperlink . lineno , "" ignored "" , "" "" , 0 <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . wqueue . put ( CheckRequest ( CHECK_IMMEDIATELY , hyperlink ) , False ) <TAB> <TAB> <TAB> total_links + = 1 <TAB> done = 0 <TAB> while done < total_links : <TAB> <TAB> yield self . rqueue . get ( ) <TAB> <TAB> done + = 1 <TAB> self . shutdown_threads ( ) ","if self . is_ignored_uri ( hyperlink . uri ) : 
","if hyperlink . is_external :
",36.03,11.84,False
"def remove_subscriber ( self , topic , subscriber ) : <TAB> if subscriber in self . subscribers [ topic ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subscriber . _pyroRelease ( ) <TAB> <TAB> if hasattr ( subscriber , "" _pyroUri "" ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> proxy = self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> <TAB> proxy . _pyroRelease ( ) <TAB> <TAB> <TAB> <TAB> del self . proxy_cache [ subscriber . _pyroUri ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . subscribers [ topic ] . discard ( subscriber ) ","if hasattr ( subscriber , "" _pyroRelease "" ) : 
","if hasattr ( subscriber , "" _pyroRelease "" ) :
",100.0,100.0,True
"def delete_arc ( collection , document , origin , target , type ) : <TAB> directory = collection <TAB> real_dir = real_directory ( directory ) <TAB> mods = ModificationTracker ( ) <TAB> projectconf = ProjectConfiguration ( real_dir ) <TAB> document = path_join ( real_dir , document ) <TAB> with TextAnnotations ( document ) as ann_obj : <TAB> <TAB> # bail as quick as possible if read-only <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AnnotationsIsReadOnlyError ( ann_obj . get_document ( ) ) <TAB> <TAB> _delete_arc_with_ann ( origin , target , type , mods , ann_obj , projectconf ) <TAB> <TAB> mods_json = mods . json_response ( ) <TAB> <TAB> mods_json [ "" annotations "" ] = _json_from_ann ( ann_obj ) <TAB> <TAB> return mods_json ","if ann_obj . _read_only : 
","if not ann_obj . get_document ( ) . is_read_only ( ) :
",37.87,25.35,False
"def _select_from ( self , parent_path , is_dir , exists , listdir ) : <TAB> if not is_dir ( parent_path ) : <TAB> <TAB> return <TAB> with _cached ( listdir ) as listdir : <TAB> <TAB> yielded = set ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> successor_select = self . successor . _select_from <TAB> <TAB> <TAB> for starting_point in self . _iterate_directories ( <TAB> <TAB> <TAB> <TAB> parent_path , is_dir , listdir <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> for p in successor_select ( starting_point , is_dir , exists , listdir ) : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield p <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yielded . add ( p ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> yielded . clear ( ) ","if p not in yielded : 
","if p not in yielded :
",100.0,100.0,True
"def _fractional_part ( self , n , expr , evaluation ) : <TAB> n_sympy = n . to_sympy ( ) <TAB> if n_sympy . is_constant ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> positive_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression ( "" Floor "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - positive_integer_part <TAB> <TAB> else : <TAB> <TAB> <TAB> negative_integer_part = ( <TAB> <TAB> <TAB> <TAB> Expression ( "" Ceiling "" , n ) . evaluate ( evaluation ) . to_python ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> result = n - negative_integer_part <TAB> else : <TAB> <TAB> return expr <TAB> return from_python ( result ) ","if n_sympy > = 0 : 
","if n_sympy . is_integer ( ) :
",29.53,24.81,False
"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB> <TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB> <TAB> if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) ","if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 : 
","if geometry [ 0 ] < - 180 or geometry [ 0 ] < - 180 :
",44.69,20.4,False
"def get_absolute_path ( self , root , path ) : <TAB> # find the first absolute path that exists <TAB> self . root = self . roots [ 0 ] <TAB> for root in self . roots : <TAB> <TAB> abspath = os . path . abspath ( os . path . join ( root , path ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . root = root<TAB> # make sure all the other methods in the base class know how to find the file <TAB> <TAB> <TAB> break <TAB> return abspath ","if os . path . exists ( abspath ) : 
","if abspath . startswith ( self . root ) :
",32.26,11.48,False
"def do_setflow ( self , l = "" "" ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> l = str ( self . flow_slider . GetValue ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l = l . lower ( ) <TAB> <TAB> flow = int ( l ) <TAB> <TAB> if self . p . online : <TAB> <TAB> <TAB> self . p . send_now ( "" M221 S "" + l ) <TAB> <TAB> <TAB> self . log ( _ ( "" Setting print flow factor to  %d %% . "" ) % flow ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logError ( _ ( "" Printer is not online. "" ) ) <TAB> except Exception as x : <TAB> <TAB> self . logError ( _ ( "" You must enter a flow. ( %s ) "" ) % ( repr ( x ) , ) ) ","if not isinstance ( l , str ) or not len ( l ) : 
","if self . flow_slider :
",25.65,2.49,False
"def sources ( ) : <TAB> for d in os . listdir ( base ) : <TAB> <TAB> #<TAB> <TAB> if d.startswith('talis'):<TAB> <TAB> #<TAB> <TAB> <TAB> continue<TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if d == "" indcat "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not os . path . isdir ( base + d ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield d ","if d . endswith ( "" old "" ) : 
","if d == "" .py "" :
",32.09,11.23,False
"def create_accumulator ( self ) - > tf_metric_accumulators . TFCompilableMetricsAccumulator : <TAB> configs = zip ( self . _metric_configs , self . _loss_configs ) <TAB> padding_options = None <TAB> if self . _eval_config is not None : <TAB> <TAB> model_spec = model_util . get_model_spec ( self . _eval_config , self . _model_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> padding_options = model_spec . padding_options <TAB> return tf_metric_accumulators . TFCompilableMetricsAccumulator ( <TAB> <TAB> padding_options , <TAB> <TAB> [ len ( m ) + len ( l ) for m , l in configs ] , <TAB> <TAB> desired_batch_size = self . _desired_batch_size , <TAB> ) ","if model_spec is not None and model_spec . HasField ( "" padding_options "" ) : 
","if model_spec is not None :
",42.2,17.12,False
"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB> <TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . expr . resultsName : <TAB> <TAB> <TAB> <TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB> <TAB> <TAB> <TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tokens = [ self . defaultValue ] <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens = [ ] <TAB> return loc , tokens ","if self . defaultValue is not self . __optionalNotMatched : 
","if self . defaultValue is not None :
",65.42,42.89,False
"def handleConnection ( self ) : <TAB> # connection handshake <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> self . csock . close ( ) <TAB> except : <TAB> <TAB> ex_t , ex_v , ex_tb = sys . exc_info ( ) <TAB> <TAB> tb = util . formatTraceback ( ex_t , ex_v , ex_tb ) <TAB> <TAB> log . warning ( "" error during connect/handshake:  %s ;  %s "" , ex_v , "" \n "" . join ( tb ) ) <TAB> <TAB> self . csock . close ( ) <TAB> return False ","if self . daemon . _handshake ( self . csock ) : 
","if self . _is_connected ( ) :
",37.71,17.01,False
"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 :<TAB> # have a one element wedge <TAB> <TAB> proc = ( "" first "" , "" last "" ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> proc = ( "" first "" , "" last "" )<TAB> # same element can be first and last <TAB> <TAB> elif su . isFirst ( innerTarget ) : <TAB> <TAB> <TAB> proc = ( "" first "" , ) <TAB> <TAB> elif su . isLast ( innerTarget ) : <TAB> <TAB> <TAB> proc = ( "" last "" , ) <TAB> <TAB> else : <TAB> <TAB> <TAB> proc = ( ) <TAB> return proc ","if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) : 
","if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) :
",100.0,100.0,True
"def get_color_dtype ( data , column_names ) : <TAB> has_color = all ( column in data [ "" points "" ] for column in column_names ) <TAB> if has_color : <TAB> <TAB> color_data_types = [ <TAB> <TAB> <TAB> data [ "" points "" ] [ column_name ] . dtype for column_name in column_names <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> f "" Data types of color values are inconsistent: got  { color_data_types } "" <TAB> <TAB> <TAB> ) <TAB> <TAB> color_data_type = color_data_types [ 0 ] <TAB> else : <TAB> <TAB> color_data_type = None <TAB> return color_data_type ","if len ( set ( color_data_types ) ) > 1 : 
","if len ( color_data_types ) != 1 :
",40.97,52.3,False
"def close ( self ) : <TAB> children = [ ] <TAB> for children_part , line_offset , last_line_offset_leaf in self . children_groups : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> _update_positions ( children_part , line_offset , last_line_offset_leaf ) <TAB> <TAB> <TAB> except _PositionUpdatingFinished : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> children + = children_part <TAB> self . tree_node . children = children <TAB> # Reset the parents <TAB> for node in children : <TAB> <TAB> node . parent = self . tree_node ","if line_offset != 0 : 
","if line_offset :
",31.77,38.81,False
"def get_multi ( self , keys , index = None ) : <TAB> with self . _lmdb . begin ( ) as txn : <TAB> <TAB> result = [ ] <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> packed = txn . get ( key . encode ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result . append ( ( key , cbor . loads ( packed ) ) ) <TAB> return result ","if packed is not None : 
","if packed :
",29.58,0.0,False
"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB> <TAB> if p [ 0 ] != "" . "" : <TAB> <TAB> <TAB> subp = os . path . join ( pth , p ) <TAB> <TAB> <TAB> p = os . path . join ( prefix , p ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , None ] ) <TAB> return res ","if recursive and os . path . isdir ( subp ) : 
","if recursive :
",26.42,0.0,False
"def __schedule ( self , workflow_scheduler_id , workflow_scheduler ) : <TAB> invocation_ids = self . __active_invocation_ids ( workflow_scheduler_id ) <TAB> for invocation_id in invocation_ids : <TAB> <TAB> log . debug ( "" Attempting to schedule workflow invocation [ %s ] "" , invocation_id ) <TAB> <TAB> self . __attempt_schedule ( invocation_id , workflow_scheduler ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ","if not self . monitor_running : 
","if not self . __is_scheduled ( invocation_id ) :
",52.94,18.21,False
"def write ( self , data ) : <TAB> self . size - = len ( data ) <TAB> passon = None <TAB> if self . size > 0 : <TAB> <TAB> self . data . append ( data ) <TAB> else : <TAB> <TAB> if self . size : <TAB> <TAB> <TAB> data , passon = data [ : self . size ] , data [ self . size : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> passon = b "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . data . append ( data ) <TAB> return passon ","if data : 
","if data :
",78.12,0.0,False
"def __getstate__ ( self ) : <TAB> try : <TAB> <TAB> store_func , load_func = self . store_function , self . load_function <TAB> <TAB> self . store_function , self . load_function = None , None <TAB> <TAB> # ignore analyses. we re-initialize analyses when restoring from pickling so that we do not lose any newly <TAB> <TAB> # added analyses classes <TAB> <TAB> d = dict ( <TAB> <TAB> <TAB> ( k , v ) <TAB> <TAB> <TAB> for k , v in self . __dict__ . items ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> not in { <TAB> <TAB> <TAB> <TAB> "" analyses "" , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> return d <TAB> finally : <TAB> <TAB> self . store_function , self . load_function = store_func , load_func ","if k 
","if k . startswith ( "" _ "" )
",34.17,9.54,False
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> if self . scrolling : <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event ) ","if self . scroll_up_rect ( ) . collidepoint ( p ) : 
","if self . scroll_up_rect ( ) . collidepoint ( p ) :
",100.0,100.0,True
"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB> <TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB> <TAB> <TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB> <TAB> if self . _prompt is None : <TAB> <TAB> <TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB> <TAB> choice = data [ "" choice "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return flask . abort ( <TAB> <TAB> <TAB> <TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _answer_prompt ( choice ) ","if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) : 
","if not isinstance ( choice , str ) :
",44.41,15.58,False
"def register_predictors ( self , model_data_arr ) : <TAB> for integration in self . _get_integrations ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> integration . register_predictors ( model_data_arr ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> f "" There is no connection to  { integration . name } . predictor wouldn ' t be registred. "" <TAB> <TAB> <TAB> ) ","if integration . check_connection ( ) : 
","if integration . connected :
",39.45,19.2,False
"def _pack_shears ( shearData ) : <TAB> shears = list ( ) <TAB> vidxs = list ( ) <TAB> for e_idx , entry in enumerate ( shearData ) : <TAB> <TAB> # Should be 3 entries <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shears . extend ( [ float ( "" nan "" ) , float ( "" nan "" ) ] ) <TAB> <TAB> <TAB> vidxs . extend ( [ 0 , 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> vidx1 , vidx2 , shear1 , shear2 = entry <TAB> <TAB> <TAB> shears . extend ( [ shear1 , shear2 ] ) <TAB> <TAB> <TAB> vidxs . extend ( [ vidx1 , vidx2 ] ) <TAB> return ( np . asarray ( shears , dtype = np . float32 ) , np . asarray ( vidxs , dtype = np . uint32 ) ) ","if entry is None : 
","if entry is None :
",100.0,100.0,True
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> if not fpath . exists ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( data , dict ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id ","if not isinstance ( inner , dict ) : 
","if cog_name != inner :
",26.63,6.41,False
"def subFeaName ( m , newNames , state ) : <TAB> try : <TAB> <TAB> int ( m [ 3 ] , 16 ) <TAB> except : <TAB> <TAB> return m [ 0 ] <TAB> name = m [ 2 ] <TAB> if name in newNames : <TAB> <TAB> # print('sub %r => %r' % (m[0], m[1] + newNames[name] + m[4])) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" sub  %r  =>  %r "" % ( m [ 0 ] , m [ 1 ] + newNames [ name ] + m [ 4 ] ) ) <TAB> <TAB> state [ "" didChange "" ] = True <TAB> <TAB> return m [ 1 ] + newNames [ name ] + m [ 4 ] <TAB> return m [ 0 ] ","if name == "" uni0402 "" : 
","if state [ "" didChange "" ] :
",33.47,7.81,False
"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB> <TAB> if input_array is None : <TAB> <TAB> <TAB> input_array = model . example_input_array <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB> <TAB> <TAB> self . experiment . add_graph ( model , input_array ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> "" Could not log computational graph since the "" <TAB> <TAB> <TAB> <TAB> ""  `model.example_input_array` attribute is not set "" <TAB> <TAB> <TAB> <TAB> ""  or `input_array` was not given "" , <TAB> <TAB> <TAB> <TAB> UserWarning , <TAB> <TAB> <TAB> ) ","if input_array is not None : 
","elif isinstance ( input_array , list ) :
",26.7,16.78,False
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_date_object ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not event . get_place_handle ( ) : 
","if not event :
",33.02,8.65,False
"def format ( m ) : <TAB> if m > 1000 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( str ( int ( m / 1000 ) ) , "" km "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ( str ( round ( m / 1000 , 1 ) ) , "" km "" ) <TAB> return ( str ( m ) , "" m "" ) ","if m % 1000 == 0 : 
","if m % 1000 == 0 :
",100.0,100.0,True
"def previous ( self ) : <TAB> try : <TAB> <TAB> idx = _jump_list_index <TAB> <TAB> next_index = idx + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> next_index = 100 <TAB> <TAB> next_index = min ( len ( _jump_list ) - 1 , next_index ) <TAB> <TAB> _jump_list_index = next_index <TAB> <TAB> return _jump_list [ next_index ] <TAB> except ( IndexError , KeyError ) as e : <TAB> <TAB> return None ","if next_index > 100 : 
","if next_index > 100 :
",100.0,100.0,True
"def _validate_and_set_default_hyperparameters ( self ) : <TAB> """"""Placeholder docstring"""""" <TAB> # Check if all the required hyperparameters are set. If there is a default value <TAB> # for one, set it. <TAB> for name , definition in self . hyperparameter_definitions . items ( ) : <TAB> <TAB> if name not in self . hyperparam_dict : <TAB> <TAB> <TAB> spec = definition [ "" spec "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . hyperparam_dict [ name ] = spec [ "" DefaultValue "" ] <TAB> <TAB> <TAB> elif "" IsRequired "" in spec and spec [ "" IsRequired "" ] : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Required hyperparameter:  %s  is not set "" % name ) ","if "" DefaultValue "" in spec : 
","if "" DefaultValue "" in spec and spec [ "" DefaultValue "" ] :
",67.61,36.36,False
"def _actions_read ( self , c ) : <TAB> self . action_input . handle_read ( c ) <TAB> if c in [ curses . KEY_ENTER , util . KEY_ENTER2 ] : <TAB> <TAB> # take action <TAB> <TAB> if self . action_input . selected_index == 0 :<TAB> # Cancel <TAB> <TAB> <TAB> self . back_to_parent ( ) <TAB> <TAB> elif self . action_input . selected_index == 1 :<TAB> # Apply <TAB> <TAB> <TAB> self . _apply_prefs ( ) <TAB> <TAB> <TAB> client . core . get_config ( ) . addCallback ( self . _update_preferences ) <TAB> <TAB> elif self . action_input . selected_index == 2 :<TAB> # OK <TAB> <TAB> <TAB> self . _apply_prefs ( ) <TAB> <TAB> <TAB> self . back_to_parent ( ) ","elif self . action_input . selected_index == 1 : 
","elif self . action_input . selected_index == 1 :
",100.0,100.0,True
"def _split_anonymous_function ( s ) : <TAB> # Regex is not sufficient to handle differences between anonymous <TAB> # functions and YAML encoded lists. We perform a sniff test to see <TAB> # if it might be an anonymous function and then confirm by <TAB> # decoding it as YAML and testing the result. <TAB> if s [ : 1 ] == "" [ "" and s [ - 1 : ] == "" ] "" and "" : "" in s : <TAB> <TAB> try : <TAB> <TAB> <TAB> l = yaml_util . decode_yaml ( s ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> return None , s [ 1 : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None , s [ 1 : - 1 ] <TAB> return None ","if len ( l ) == 1 and isinstance ( l [ 0 ] , ( six . string_types , int ) ) : 
","if "" : "" in s :
",25.37,0.45,False
"def test_source_address ( self ) : <TAB> for addr , is_ipv6 in VALID_SOURCE_ADDRESSES : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( "" No IPv6 support: skipping. "" , NoIPv6Warning ) <TAB> <TAB> <TAB> continue <TAB> <TAB> pool = HTTPConnectionPool ( <TAB> <TAB> <TAB> self . host , self . port , source_address = addr , retries = False <TAB> <TAB> ) <TAB> <TAB> self . addCleanup ( pool . close ) <TAB> <TAB> r = pool . request ( "" GET "" , "" /source_address "" ) <TAB> <TAB> self . assertEqual ( r . data , b ( addr [ 0 ] ) ) ","if is_ipv6 and not HAS_IPV6_AND_DNS : 
","if not is_ipv6 :
",34.42,9.47,False
"def vim_G ( self ) : <TAB> """"""Put the cursor on the last character of the file."""""" <TAB> if self . is_text_wrapper ( self . w ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . do ( "" end-of-buffer-extend-selection "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . do ( "" end-of-buffer "" ) <TAB> <TAB> self . done ( ) <TAB> else : <TAB> <TAB> self . quit ( ) ","if self . state == "" visual "" : 
","if self . state == "" visual "" :
",100.0,100.0,True
"def backend_supported ( module , manager , * * kwargs ) : <TAB> if CollectionNodeModule . backend_supported ( module , manager , * * kwargs ) : <TAB> <TAB> if "" tid "" not in kwargs : <TAB> <TAB> <TAB> return True <TAB> <TAB> conn = manager . connection ( did = kwargs [ "" did "" ] ) <TAB> <TAB> template_path = "" partitions/sql/ {0} /# {0} # {1} # "" . format ( <TAB> <TAB> <TAB> manager . server_type , manager . version <TAB> <TAB> ) <TAB> <TAB> SQL = render_template ( <TAB> <TAB> <TAB> "" / "" . join ( [ template_path , "" backend_support.sql "" ] ) , tid = kwargs [ "" tid "" ] <TAB> <TAB> ) <TAB> <TAB> status , res = conn . execute_scalar ( SQL ) <TAB> <TAB> # check if any errors <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return internal_server_error ( errormsg = res ) <TAB> <TAB> return res ","if not status : 
","if status != 200 :
",29.25,10.68,False
"def _get_regex_config ( self , data_asset_name : Optional [ str ] = None ) - > dict : <TAB> regex_config : dict = copy . deepcopy ( self . _default_regex ) <TAB> asset : Optional [ Asset ] = None <TAB> if data_asset_name : <TAB> <TAB> asset = self . _get_asset ( data_asset_name = data_asset_name ) <TAB> if asset is not None : <TAB> <TAB> # Override the defaults <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> regex_config [ "" pattern "" ] = asset . pattern <TAB> <TAB> if asset . group_names : <TAB> <TAB> <TAB> regex_config [ "" group_names "" ] = asset . group_names <TAB> return regex_config ","if asset . pattern : 
","if asset . pattern :
",100.0,100.0,True
"def resolve ( self , other ) : <TAB> if other == ANY_TYPE : <TAB> <TAB> return self <TAB> elif isinstance ( other , ComplexType ) : <TAB> <TAB> f = self . first . resolve ( other . first ) <TAB> <TAB> s = self . second . resolve ( other . second ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ComplexType ( f , s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> elif self == ANY_TYPE : <TAB> <TAB> return other <TAB> else : <TAB> <TAB> return None ","if f and s : 
","if f != s :
",32.78,22.96,False
"def collect_pages ( app ) : <TAB> new_images = { } <TAB> for full_path , basename in app . builder . images . iteritems ( ) : <TAB> <TAB> base , ext = os . path . splitext ( full_path ) <TAB> <TAB> retina_path = base + "" @2x "" + ext <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_images [ retina_path ] = app . env . images [ retina_path ] [ 1 ] <TAB> app . builder . images . update ( new_images ) <TAB> return [ ] ","if retina_path in app . env . images : 
","if retina_path in app . env . images :
",100.0,100.0,True
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len ( line . strip ( ) ) == 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not line : 
","if linenum < 0 and line [ 0 ] not in "" \t "" :
",28.31,3.46,False
"def reader ( ) : <TAB> try : <TAB> <TAB> imgs = mp4_loader ( video_path , seg_num , seglen , mode ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" {}  frame length  {}  less than 1. "" . format ( video_path , len ( imgs ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> yield None , None <TAB> except : <TAB> <TAB> logger . error ( "" Error when loading  {} "" . format ( mp4_path ) ) <TAB> <TAB> yield None , None <TAB> imgs_ret = imgs_transform ( <TAB> <TAB> imgs , mode , seg_num , seglen , short_size , target_size , img_mean , img_std <TAB> ) <TAB> label_ret = video_path <TAB> yield imgs_ret , label_ret ","if len ( imgs ) < 1 : 
","if len ( imgs ) < 1 :
",100.0,100.0,True
"def translate_from_sortname ( name , sortname ) : <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name : <TAB> <TAB> ctg = unicodedata . category ( c ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB> <TAB> <TAB> <TAB> if separator in sortname : <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname . split ( separator ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> parts = [ sortname ] <TAB> <TAB> <TAB> <TAB> separator = "" "" <TAB> <TAB> <TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name ","if ctg [ 0 ] == "" L "" and unicodedata . name ( c ) . find ( "" LATIN "" ) == - 1 : 
","if ctg == unicodedata . artist ( ) :
",27.6,2.41,False
"def _to_local_path ( path ) : <TAB> """"""Convert local path to SFTP path"""""" <TAB> if sys . platform == "" win32 "" :<TAB> # pragma: no cover <TAB> <TAB> path = os . fsdecode ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = path [ 1 : ] <TAB> <TAB> path = path . replace ( "" / "" , "" \\ "" ) <TAB> return path ","if path [ : 1 ] == "" / "" and path [ 2 : 3 ] == "" : "" : 
","if path [ 0 ] == "" / "" :
",39.65,19.14,False
"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB> <TAB> if t == "" tacotron "" : <TAB> <TAB> <TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = jaconv . normalize ( text ) <TAB> <TAB> elif t == "" vietnamese "" : <TAB> <TAB> <TAB> if vietnamese_cleaners is None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB> <TAB> <TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text ","elif t == "" jaconv "" : 
","elif t == "" jaconv "" :
",100.0,100.0,True
"def cb_syncthing_system_data ( self , daemon , mem , cpu , d_failed , d_total ) : <TAB> if self . daemon . get_my_id ( ) in self . devices : <TAB> <TAB> # Update my device display <TAB> <TAB> device = self . devices [ self . daemon . get_my_id ( ) ] <TAB> <TAB> device [ "" ram "" ] = sizeof_fmt ( mem ) <TAB> <TAB> device [ "" cpu "" ] = "" %3.2f %% "" % ( cpu ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> device [ "" announce "" ] = _ ( "" disabled "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> device [ "" announce "" ] = "" %s / %s "" % ( d_total - d_failed , d_total ) ","if d_total == 0 : 
","if d_failed == 0 :
",64.48,50.0,False
"def update_kls ( self , sampled_kls ) : <TAB> for i , kl in enumerate ( sampled_kls ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . kl_coeff_val [ i ] * = 0.5 <TAB> <TAB> elif kl > 1.5 * self . kl_target : <TAB> <TAB> <TAB> self . kl_coeff_val [ i ] * = 2.0 <TAB> return self . kl_coeff_val ","if kl < self . kl_target / 1.5 : 
","if kl < 0.5 * self . kl_target :
",40.48,48.33,False
"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB> <TAB> f = True <TAB> <TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB> <TAB> <TAB> if self . FindItemAtPosition ( ( r , c ) ) is not None : <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB> <TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB> <TAB> cols2delete = [ x - 1 for x in cols2delete ] ","if f : 
","if f :
",78.12,0.0,False
"def get_session ( self ) : <TAB> if self . _session is None : <TAB> <TAB> session = super ( ChildResourceManager , self ) . get_session ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> session = session . get_session_for_resource ( self . resource_type . resource ) <TAB> <TAB> self . _session = session <TAB> return self . _session ","if self . resource_type . resource != constants . RESOURCE_ACTIVE_DIRECTORY : 
","if self . resource_type is not None :
",46.26,24.14,False
"def _get_master_authorized_networks_config ( self , raw_cluster ) : <TAB> if raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) : <TAB> <TAB> config = raw_cluster . get ( "" masterAuthorizedNetworksConfig "" ) <TAB> <TAB> config [ "" includes_public_cidr "" ] = False <TAB> <TAB> for block in config [ "" cidrBlocks "" ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> config [ "" includes_public_cidr "" ] = True <TAB> <TAB> return config <TAB> else : <TAB> <TAB> return { "" enabled "" : False , "" cidrBlocks "" : [ ] , "" includes_public_cidr "" : False } ","if block [ "" cidrBlock "" ] == "" 0.0.0.0/0 "" : 
","if block [ "" enabled "" ] :
",50.8,17.81,False
"def scan_folder ( folder ) : <TAB> scanned_files = [ ] <TAB> for root , dirs , files in os . walk ( folder ) : <TAB> <TAB> dirs [ : ] = [ d for d in dirs if d != "" __pycache__ "" ] <TAB> <TAB> relative_path = os . path . relpath ( root , folder ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> relative_name = os . path . normpath ( os . path . join ( relative_path , f ) ) . replace ( <TAB> <TAB> <TAB> <TAB> "" \\ "" , "" / "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> scanned_files . append ( relative_name ) <TAB> return sorted ( scanned_files ) ","if f . endswith ( "" .pyc "" ) : 
","if f == "" __pycache__ "" :
",32.09,8.52,False
"def read_progress ( self ) : <TAB> while True : <TAB> <TAB> processed_file = self . queue . get ( ) <TAB> <TAB> self . threading_completed . append ( processed_file ) <TAB> <TAB> total_number = len ( self . file_list ) <TAB> <TAB> completed_number = len ( self . threading_completed ) <TAB> <TAB> # Just for the record, this slows down book searching by about 20% <TAB> <TAB> if _progress_emitter :<TAB> # Skip update in reading mode <TAB> <TAB> <TAB> _progress_emitter . update_progress ( completed_number * 100 / / total_number ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if total_number == completed_number : 
","if completed_number == total_number :
",54.02,51.33,False
"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if parser . is_quoted ( ) : <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) :<TAB> # empty line <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB> <TAB> <TAB> return True <TAB> <TAB> if line . startswith ( ( "" # "" , "" @ "" , "" "" , "" ) "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False ","if i > 0 and not lines [ i - 1 ] . strip ( ) : 
","if i == 0 :
",28.56,3.09,False
def __next__ ( self ) : <TAB> try : <TAB> <TAB> data = next ( self . iter_loader ) <TAB> except StopIteration : <TAB> <TAB> self . _epoch + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _dataloader . sampler . set_epoch ( self . _epoch ) <TAB> <TAB> self . iter_loader = iter ( self . _dataloader ) <TAB> <TAB> data = next ( self . iter_loader ) <TAB> return data ,"if hasattr ( self . _dataloader . sampler , "" set_epoch "" ) : 
","if self . _dataloader . sampler is not None :
",46.9,28.76,False
"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB> <TAB> data = zip ( * data ) <TAB> <TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB> <TAB> if dt is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB> <TAB> <TAB> elif isinstance ( dt , nd . NDArray ) : <TAB> <TAB> <TAB> <TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB> <TAB> <TAB> <TAB> data_list = [ dt for dt in data if dt is not None ] <TAB> <TAB> <TAB> <TAB> return pad ( data_list ) ","if isinstance ( dt , dgl . DGLGraph ) : 
","if isinstance ( dt , dgl . DGLBatchify ) :
",85.49,70.71,False
"def f ( self , info ) : <TAB> for k in keys : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k2 in list ( info . keys ( ) ) : <TAB> <TAB> <TAB> <TAB> if k ( k2 ) : <TAB> <TAB> <TAB> <TAB> <TAB> info . pop ( k2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> info . pop ( k , None ) ","if callable ( k ) : 
","if isinstance ( info . get ( k ) , dict ) :
",40.14,14.46,False
"def create ( path , binary = False ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> os . makedirs ( os . path . dirname ( path ) , exist_ok = True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return open ( path , "" wb "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return open ( path , "" w "" , encoding = "" utf-8 "" ) <TAB> <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> <TAB> log ( True , f "" Created  { path }  at attempt  { i + 1 } "" ) <TAB> <TAB> except : <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> else : <TAB> <TAB> raise Error ( f "" Failed to create  { path } "" ) ","if binary : 
","if binary :
",78.12,0.0,False
"def validate_update ( self , update_query ) : <TAB> structure = DotCollapsedDict ( self . doc_class . structure ) <TAB> for op , fields in update_query . iteritems ( ) : <TAB> <TAB> for field in fields : <TAB> <TAB> <TAB> if op != "" $unset "" and op != "" $rename "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise UpdateQueryError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" ' %s '  not found in  %s ' s structure "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> % ( field , self . doc_class . __name__ ) <TAB> <TAB> <TAB> <TAB> <TAB> ) ","if field not in structure : 
","if field not in structure :
",100.0,100.0,True
"def check_enums_ATLAS_ISAEXT ( lines ) : <TAB> for i , isaext in enumerate ( ATLAS_ISAEXT ) : <TAB> <TAB> got = lines . pop ( 0 ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> expect = "" none: 1 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> expect = "" {0} :  {1} "" . format ( isaext , 1 << i ) <TAB> <TAB> if got != expect : <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" ATLAS_ISAEXT mismatch at position  "" <TAB> <TAB> <TAB> <TAB> + str ( i ) <TAB> <TAB> <TAB> <TAB> + "" : got >> "" <TAB> <TAB> <TAB> <TAB> + got <TAB> <TAB> <TAB> <TAB> + "" <<, expected >> "" <TAB> <TAB> <TAB> <TAB> + expect <TAB> <TAB> <TAB> <TAB> + "" << "" <TAB> <TAB> <TAB> ) ","if i == 0 : 
","if isaext == "" none "" :
",27.97,13.13,False
"def _test_export_session_csv ( self , test_session = None ) : <TAB> with self . app . test_request_context ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> test_session = SessionFactory ( ) <TAB> <TAB> field_data = export_sessions_csv ( [ test_session ] ) <TAB> <TAB> session_row = field_data [ 1 ] <TAB> <TAB> self . assertEqual ( session_row [ 0 ] , "" example (accepted) "" ) <TAB> <TAB> self . assertEqual ( session_row [ 9 ] , "" accepted "" ) ","if not test_session : 
","if test_session is None :
",29.25,27.78,False
"def get_report_to_platform ( self , args , scan_reports ) : <TAB> if self . bc_api_key : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> repo_id = self . get_repository ( args ) <TAB> <TAB> <TAB> self . setup_bridgecrew_credentials ( <TAB> <TAB> <TAB> <TAB> bc_api_key = self . bc_api_key , repo_id = repo_id <TAB> <TAB> <TAB> ) <TAB> <TAB> if self . is_integration_configured ( ) : <TAB> <TAB> <TAB> self . _upload_run ( args , scan_reports ) ","if args . directory : 
","if self . is_bridgecrew_configured ( ) :
",36.31,4.93,False
"def test_fvalue ( self ) : <TAB> if not getattr ( self , "" skip_f "" , False ) : <TAB> <TAB> rtol = getattr ( self , "" rtol "" , 1e-10 ) <TAB> <TAB> assert_allclose ( self . res1 . fvalue , self . res2 . F , rtol = rtol ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # only available with ivreg2 <TAB> <TAB> <TAB> assert_allclose ( self . res1 . f_pvalue , self . res2 . Fp , rtol = rtol ) <TAB> else : <TAB> <TAB> raise pytest . skip ( "" TODO: document why this test is skipped "" ) ","if hasattr ( self . res2 , "" Fp "" ) : 
","if hasattr ( self , "" ivreg2 "" ) :
",46.55,34.67,False
"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self ","elif type ( e . value ) is not list : 
","if type ( e . value ) is str :
",57.53,59.78,False
"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . parent ( ) . touch ( ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB> <TAB> if not node . isdir : <TAB> <TAB> <TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . watcher . emit ( "" created "" , self ) ","if self . watcher : 
","if self . watcher :
",100.0,100.0,True
"def __init__ ( self , _inf = None , _tzinfos = None ) : <TAB> if _inf : <TAB> <TAB> self . _tzinfos = _tzinfos <TAB> <TAB> self . _utcoffset , self . _dst , self . _tzname = _inf <TAB> else : <TAB> <TAB> _tzinfos = { } <TAB> <TAB> self . _tzinfos = _tzinfos <TAB> <TAB> self . _utcoffset , self . _dst , self . _tzname = self . _transition_info [ 0 ] <TAB> <TAB> _tzinfos [ self . _transition_info [ 0 ] ] = self <TAB> <TAB> for inf in self . _transition_info [ 1 : ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _tzinfos [ inf ] = self . __class__ ( inf , _tzinfos ) ","if not _tzinfos . has_key ( inf ) : 
","if inf not in _tzinfos :
",26.9,8.46,False
"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with _file . open ( ) as f : <TAB> <TAB> <TAB> <TAB> if comment not in f . read ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB> <TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB> <TAB> for error in errors : <TAB> <TAB> <TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB> <TAB> print ( line [ : - 1 ] ) <TAB> <TAB> assert False ","if _file . suffix == "" .py "" and _file . name not in skip_files : 
","if _file . suffix == "" .py "" and _file . name not in skip_files :
",100.0,100.0,True
"def http_get ( url , target ) : <TAB> req = requests . get ( url , stream = True ) <TAB> content_length = req . headers . get ( "" Content-Length "" ) <TAB> total = int ( content_length ) if content_length is not None else None <TAB> progress = tqdm ( unit = "" B "" , total = total ) <TAB> with open ( target , "" wb "" ) as target_file : <TAB> <TAB> for chunk in req . iter_content ( chunk_size = 1024 ) : <TAB> <TAB> <TAB> if chunk :<TAB> # filter out keep-alive new chunks <TAB> <TAB> <TAB> <TAB> progress . update ( len ( chunk ) ) <TAB> <TAB> <TAB> <TAB> target_file . write ( chunk ) <TAB> progress . close ( ) ","if chunk : 
","if chunk :
",78.12,0.0,False
"def _elements_to_datasets ( self , elements , level = 0 ) : <TAB> for element in elements : <TAB> <TAB> extra_kwds = { "" identifier_ %d "" % level : element [ "" name "" ] } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for inner_element in self . _elements_to_datasets ( <TAB> <TAB> <TAB> <TAB> element [ "" elements "" ] , level = level + 1 <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> dataset = extra_kwds . copy ( ) <TAB> <TAB> <TAB> <TAB> dataset . update ( inner_element ) <TAB> <TAB> <TAB> <TAB> yield dataset <TAB> <TAB> else : <TAB> <TAB> <TAB> dataset = extra_kwds <TAB> <TAB> <TAB> extra_kwds . update ( element ) <TAB> <TAB> <TAB> yield extra_kwds ","if "" elements "" in element : 
","if "" elements "" in element :
",100.0,100.0,True
"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> a [ key ] = value <TAB> <TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB> <TAB> <TAB> update_dict ( a [ key ] , value ) <TAB> <TAB> elif isinstance ( a [ key ] , list ) : <TAB> <TAB> <TAB> a [ key ] . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> a [ key ] = [ a [ key ] , value ] ","if key not in a : 
","elif key not in a :
",68.57,75.98,False
"def scan ( self , targets ) : <TAB> for target in targets : <TAB> <TAB> target . print_infos ( ) <TAB> <TAB> if self . is_interesting ( target ) : <TAB> <TAB> <TAB> self . target [ "" other "" ] . append ( target ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return target <TAB> return None ","if self . match ( target ) : 
","if self . scan_for_interesting ( target ) :
",74.27,30.66,False
"def printConnections ( switches ) : <TAB> "" Compactly print connected nodes to each switch "" <TAB> for sw in switches : <TAB> <TAB> output ( "" %s :  "" % sw ) <TAB> <TAB> for intf in sw . intfList ( ) : <TAB> <TAB> <TAB> link = intf . link <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> intf1 , intf2 = link . intf1 , link . intf2 <TAB> <TAB> <TAB> <TAB> remote = intf1 if intf1 . node != sw else intf2 <TAB> <TAB> <TAB> <TAB> output ( "" %s ( %s )  "" % ( remote . node , sw . ports [ intf ] ) ) <TAB> <TAB> output ( "" \n "" ) ","if link : 
","if link :
",78.12,0.0,False
"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i , char in enumerate ( sentence ) : <TAB> <TAB> pos = pos_list [ i ] <TAB> <TAB> if pos == "" B "" : <TAB> <TAB> <TAB> begin = i <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield sentence [ begin : i + 1 ] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> elif pos == "" S "" : <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len ( sentence ) : <TAB> <TAB> yield sentence [ nexti : ] ","elif pos == "" E "" : 
","elif pos == "" S "" :
",74.63,59.46,False
"def check_files ( self , paths = None ) : <TAB> """"""Run all checks on the paths."""""" <TAB> if paths is None : <TAB> <TAB> paths = self . paths <TAB> report = self . options . report <TAB> runner = self . runner <TAB> report . start ( ) <TAB> try : <TAB> <TAB> for path in paths : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . input_dir ( path ) <TAB> <TAB> <TAB> elif not self . excluded ( path ) : <TAB> <TAB> <TAB> <TAB> runner ( path ) <TAB> except KeyboardInterrupt : <TAB> <TAB> print ( "" ... stopped "" ) <TAB> report . stop ( ) <TAB> return report ","if os . path . isdir ( path ) : 
","if os . path . isdir ( path ) :
",100.0,100.0,True
"def verts_of_loop ( edge_loop ) : <TAB> verts = [ ] <TAB> for e0 , e1 in iter_pairs ( edge_loop , False ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v0 = e0 . shared_vert ( e1 ) <TAB> <TAB> <TAB> verts + = [ e0 . other_vert ( v0 ) , v0 ] <TAB> <TAB> verts + = [ e1 . other_vert ( verts [ - 1 ] ) ] <TAB> if len ( verts ) > 1 and verts [ 0 ] == verts [ - 1 ] : <TAB> <TAB> return verts [ : - 1 ] <TAB> return verts ","if not verts : 
","if e0 . is_edge ( e1 ) :
",28.21,4.99,False
"def generator ( self , data ) : <TAB> for task in data : <TAB> <TAB> # Do we scan everything or just /bin/bash instances? <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for bucket in task . bash_hash_entries ( ) : <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int ( task . p_pid ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( task . p_comm ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( bucket . times_found ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( bucket . key ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( bucket . data . path ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) ","if not ( self . _config . SCAN_ALL or str ( task . p_comm ) == "" bash "" ) : 
","if not self . scan_task ( task ) :
",30.86,3.61,False
"def __get_ratio ( self ) : <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB> <TAB> w = free_layout . get_main_splitter ( ) <TAB> <TAB> if w : <TAB> <TAB> <TAB> aList = w . sizes ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> n1 , n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5 ","if len ( aList ) == 2 : 
","if len ( aList ) == 2 :
",100.0,100.0,True
"def geterrors ( self ) : <TAB> """"""Get all error messages."""""" <TAB> notes = self . getnotes ( origin = "" translator "" ) . split ( "" \n "" ) <TAB> errordict = { } <TAB> for note in notes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error = note . replace ( "" (pofilter)  "" , "" "" ) <TAB> <TAB> <TAB> errorname , errortext = error . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> errordict [ errorname ] = errortext <TAB> return errordict ","if "" (pofilter)  "" in note : 
","if "" (pofilter) "" in note :
",100.0,100.0,True
"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB> <TAB> if d in [ "" . "" , "" .. "" ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB> <TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB> <TAB> attr = self . getattr ( d_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . rename_path ( d_path , d_new_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True ) ","if stat . S_ISDIR ( attr [ "" st_mode "" ] ) : 
","if isinstance ( attr , dict ) :
",27.51,5.36,False
"def index ( self , url_id : int ) - > FlaskResponse :<TAB> # pylint: disable=no-self-use <TAB> url = db . session . query ( models . Url ) . get ( url_id ) <TAB> if url and url . url : <TAB> <TAB> explore_url = "" //superset/explore/? "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> explore_url + = f "" r= { url_id } "" <TAB> <TAB> <TAB> return redirect ( explore_url [ 1 : ] ) <TAB> <TAB> return redirect ( url . url [ 1 : ] ) <TAB> flash ( "" URL to nowhere... "" , "" danger "" ) <TAB> return redirect ( "" / "" ) ","if url . url . startswith ( explore_url ) : 
","if url_id < = 5 :
",26.38,7.97,False
"def testShortCircuit ( self ) : <TAB> """"""Test that creation short-circuits to reuse existing references"""""" <TAB> sd = { } <TAB> for s in self . ss : <TAB> <TAB> sd [ s ] = 1 <TAB> for t in self . ts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertTrue ( sd . has_key ( safeRef ( t . x ) ) ) <TAB> <TAB> <TAB> self . assertTrue ( safeRef ( t . x ) in sd ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertTrue ( sd . has_key ( safeRef ( t ) ) ) <TAB> <TAB> <TAB> self . assertTrue ( safeRef ( t ) in sd ) ","if hasattr ( t , "" x "" ) : 
","if isinstance ( t , SDFRef ) :
",32.11,21.07,False
"def wrapped ( request , * args , * * kwargs ) : <TAB> if not request . user . is_authenticated ( ) : <TAB> <TAB> request . session [ "" _next "" ] = request . get_full_path ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> redirect_uri = reverse ( <TAB> <TAB> <TAB> <TAB> "" sentry-auth-organization "" , args = [ kwargs [ "" organization_slug "" ] ] <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> redirect_uri = get_login_url ( ) <TAB> <TAB> return HttpResponseRedirect ( redirect_uri ) <TAB> return func ( request , * args , * * kwargs ) ","if "" organization_slug "" in kwargs : 
","if "" organization_slug "" in kwargs :
",100.0,100.0,True
"def read_info ( reader , dump = None ) : <TAB> line_number_table_length = reader . read_u2 ( ) <TAB> <MASK> <TAB> <TAB> reader . debug ( <TAB> <TAB> <TAB> ""<TAB>  "" * dump , "" Line numbers ( %s  total): "" % line_number_table_length <TAB> <TAB> ) <TAB> line_numbers = [ ] <TAB> for i in range ( 0 , line_number_table_length ) : <TAB> <TAB> start_pc = reader . read_u2 ( ) <TAB> <TAB> line_number = reader . read_u2 ( ) <TAB> <TAB> if dump is not None : <TAB> <TAB> <TAB> reader . debug ( ""<TAB>  "" * ( dump + 1 ) , "" %s :  %s "" % ( start_pc , line_number ) ) <TAB> <TAB> line_numbers . append ( ( start_pc , line_number ) ) <TAB> return LineNumberTable ( line_numbers ) ","if dump is not None : 
","if dump is not None :
",100.0,100.0,True
"def compute_timer_precision ( timer ) : <TAB> precision = None <TAB> points = 0 <TAB> timeout = timeout_timer ( ) + 1.0 <TAB> previous = timer ( ) <TAB> while timeout_timer ( ) < timeout or points < 5 : <TAB> <TAB> for _ in XRANGE ( 10 ) : <TAB> <TAB> <TAB> t1 = timer ( ) <TAB> <TAB> <TAB> t2 = timer ( ) <TAB> <TAB> <TAB> dt = t2 - t1 <TAB> <TAB> <TAB> if 0 < dt : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> dt = t2 - previous <TAB> <TAB> <TAB> if dt < = 0.0 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> precision = min ( precision , dt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> precision = dt <TAB> <TAB> points + = 1 <TAB> <TAB> previous = timer ( ) <TAB> return precision ","if precision is not None : 
","if precision is not None :
",100.0,100.0,True
def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB> <TAB> <TAB> if self . expr3 is None : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno ,"if self . expr2 is None : 
","if self . expr2 is None :
",100.0,100.0,True
"def validate_cluster_resource_group ( cmd , namespace ) : <TAB> if namespace . cluster_resource_group is not None : <TAB> <TAB> client = get_mgmt_service_client ( <TAB> <TAB> <TAB> cmd . cli_ctx , ResourceType . MGMT_RESOURCE_RESOURCES <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidArgumentValueError ( <TAB> <TAB> <TAB> <TAB> "" Invalid --cluster-resource-group  ' %s ' : resource group must not exist. "" <TAB> <TAB> <TAB> <TAB> % namespace . cluster_resource_group <TAB> <TAB> <TAB> ) ","if client . resource_groups . check_existence ( namespace . cluster_resource_group ) : 
","if not client . has_resource ( namespace . cluster_resource_group ) :
",60.25,51.91,False
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right ","if left == 0 : 
","if left == 0 and text [ left - 1 ] in allowed_chars :
",55.71,22.41,False
"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB> <TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB> <TAB> if len ( set ( lengths ) ) > 1 : <TAB> <TAB> <TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB> <TAB> x_len = lengths [ 0 ] <TAB> else : <TAB> <TAB> x_len = len ( X ) <TAB> if y is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB> <TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y ","if len ( y ) != x_len : 
","if x_len != len ( X ) :
",39.04,22.42,False
"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB> <TAB> if isinstance ( node , HtmlTag ) : <TAB> <TAB> <TAB> if node . tag_type == OPEN_TAG : <TAB> <TAB> <TAB> <TAB> open_tags + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> open_tags - = 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance ( node , HtmlDataFragment ) <TAB> <TAB> <TAB> and node . is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ) : <TAB> <TAB> <TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text ","elif node . tag_type == CLOSE_TAG : 
","elif node . tag_type == CLOSE_TAG :
",100.0,100.0,True
"def _get_spyne_type ( cls_name , k , v ) : <TAB> try : <TAB> <TAB> v = NATIVE_MAP . get ( v , v ) <TAB> except TypeError : <TAB> <TAB> return <TAB> try : <TAB> <TAB> subc = issubclass ( v , ModelBase ) or issubclass ( v , SelfReference ) <TAB> except : <TAB> <TAB> subc = False <TAB> if subc : <TAB> <TAB> if issubclass ( v , Array ) and len ( v . _type_info ) != 1 : <TAB> <TAB> <TAB> raise Exception ( "" Invalid Array definition in  %s . %s . "" % ( cls_name , k ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Please specify the number of dimensions "" ) <TAB> <TAB> return v ","elif issubclass ( v , Point ) and v . Attributes . dim is None : 
","if len ( v . _type_info ) != 1 :
",29.86,7.36,False
"def customize ( cls , * * kwargs ) : <TAB> """"""return a class with some existing attributes customized"""""" <TAB> for name , value in kwargs . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TransportError ( <TAB> <TAB> <TAB> <TAB> "" you cannot customize the protected attribute  %s "" % name <TAB> <TAB> <TAB> ) <TAB> <TAB> if not hasattr ( cls , name ) : <TAB> <TAB> <TAB> raise TransportError ( "" Transport has no attribute  %s "" % name ) <TAB> NewSubClass = type ( "" Customized_ {} "" . format ( cls . __name__ ) , ( cls , ) , kwargs ) <TAB> return NewSubClass ","if name in [ "" cookie "" , "" circuit "" , "" upstream "" , "" downstream "" , "" stream "" ] : 
","if name in cls . __dict__ or name in cls . __dict__ :
",27.06,6.0,False
"def test_UNrelativize ( self ) : <TAB> import URIlib <TAB> relative = self . relative + self . full_relativize <TAB> for base , rel , fullpath , common in relative : <TAB> <TAB> URI = uriparse . UnRelativizeURL ( base , rel ) <TAB> <TAB> fullURI = URIlib . URIParser ( URI ) <TAB> <TAB> # We need to canonicalize the result from unrelativize <TAB> <TAB> # compared to the original full path we expect to see. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fullpath = fullpath [ : - 1 ] <TAB> <TAB> self . failUnlessSamePath ( <TAB> <TAB> <TAB> os . path . normcase ( fullURI . path ) , os . path . normcase ( fullpath ) <TAB> <TAB> ) ","if fullpath [ - 1 ] in ( "" / "" , "" \\ "" ) : 
","if fullpath [ - 1 ] == "" / "" :
",51.17,33.07,False
"def get_release_info ( file_path = RELEASE_FILE ) : <TAB> RELEASE_TYPE_REGEX = re . compile ( r "" ^[Rr]elease [Tt]ype: (major|minor|patch)$ "" ) <TAB> with open ( file_path , "" r "" ) as f : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> match = RELEASE_TYPE_REGEX . match ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" The file RELEASE.md should start with `Release type`  "" <TAB> <TAB> <TAB> <TAB> "" and specify one of the following values: major, minor or patch. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 ) <TAB> <TAB> type_ = match . group ( 1 ) <TAB> <TAB> changelog = "" "" . join ( [ line for line in f . readlines ( ) ] ) . strip ( ) <TAB> return type_ , changelog ","if not match : 
","if match is None :
",29.35,14.06,False
"def _get_next_history_entry ( self ) : <TAB> if self . _history : <TAB> <TAB> hist_len = len ( self . _history ) - 1 <TAB> <TAB> self . history_index = min ( hist_len , self . history_index + 1 ) <TAB> <TAB> index = self . history_index <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . history_index + = 1 <TAB> <TAB> return self . _history [ index ] <TAB> return "" "" ","if self . history_index == hist_len : 
","if self . _history [ index ] . startswith ( "" .. "" ) :
",37.67,10.52,False
"def star_op ( self ) : <TAB> """"""Put a '*' op, with special cases for *args."""""" <TAB> val = "" * "" <TAB> if self . paren_level : <TAB> <TAB> i = len ( self . code_list ) - 1 <TAB> <TAB> if self . code_list [ i ] . kind == "" blank "" : <TAB> <TAB> <TAB> i - = 1 <TAB> <TAB> token = self . code_list [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . op_no_blanks ( val ) <TAB> <TAB> elif token . value == "" , "" : <TAB> <TAB> <TAB> self . blank ( ) <TAB> <TAB> <TAB> self . add_token ( "" op-no-blanks "" , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . op ( val ) <TAB> else : <TAB> <TAB> self . op ( val ) ","if token . kind == "" lt "" : 
","if token . value == "" * "" :
",58.81,29.85,False
"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if HIDDEN_SETTINGS . search ( k ) : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = "" ******************** "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict ","if k . isupper ( ) : 
","if not k . startswith ( "" _ "" ) and k not in RESERVED_SETTINGS :
",33.19,5.65,False
"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB> <TAB> if len ( self . _editableChildren ) : <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei > = len ( self . _editableChildren ) : <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable ","if ref in self . _editableChildren : 
","if ref in self . _editableChildren :
",100.0,100.0,True
"def _handle_dependents_type ( types , type_str , type_name , rel_name , row ) : <TAB> if types [ type_str [ 0 ] ] is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> type_name = "" index "" <TAB> <TAB> <TAB> rel_name = row [ "" indname "" ] + ""  ON  "" + rel_name <TAB> <TAB> elif type_str [ 0 ] == "" o "" : <TAB> <TAB> <TAB> type_name = "" operator "" <TAB> <TAB> <TAB> rel_name = row [ "" relname "" ] <TAB> else : <TAB> <TAB> type_name = types [ type_str [ 0 ] ] <TAB> return type_name , rel_name ","if type_str [ 0 ] == "" i "" : 
","if type_str [ 0 ] == "" i "" :
",100.0,100.0,True
"def streamErrorHandler ( self , conn , error ) : <TAB> name , text = "" error "" , error . getData ( ) <TAB> for tag in error . getChildren ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if tag . getName ( ) == "" text "" : <TAB> <TAB> <TAB> <TAB> text = tag . getData ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = tag . getName ( ) <TAB> if name in stream_exceptions . keys ( ) : <TAB> <TAB> exc = stream_exceptions [ name ] <TAB> else : <TAB> <TAB> exc = StreamError <TAB> raise exc ( ( name , text ) ) ","if tag . getNamespace ( ) == NS_XMPP_STREAMS : 
","if isinstance ( tag , StreamTag ) :
",26.86,3.9,False
"def _validate_names ( self , settings : _SettingsType ) - > None : <TAB> """"""Make sure all settings exist."""""" <TAB> unknown = [ ] <TAB> for name in settings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unknown . append ( name ) <TAB> if unknown : <TAB> <TAB> errors = [ <TAB> <TAB> <TAB> configexc . ConfigErrorDesc ( <TAB> <TAB> <TAB> <TAB> "" While loading options "" , "" Unknown option  {} "" . format ( e ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for e in sorted ( unknown ) <TAB> <TAB> ] <TAB> <TAB> raise configexc . ConfigFileErrors ( "" autoconfig.yml "" , errors ) ","if name not in configdata . DATA : 
","if not self . _has_option ( name ) :
",31.95,5.06,False
"def can_haz ( self , target , credentials ) : <TAB> """"""Check whether key-values in target are present in credentials."""""" <TAB> # TODO(termie): handle ANDs, probably by providing a tuple instead of a <TAB> #<TAB> <TAB> <TAB>    string<TAB> for requirement in target : <TAB> <TAB> key , match = requirement . split ( "" : "" , 1 ) <TAB> <TAB> check = credentials . get ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> check = [ check ] <TAB> <TAB> if match in check : <TAB> <TAB> <TAB> return True ","if check is None or isinstance ( check , basestring ) : 
","if not isinstance ( check , tuple ) :
",45.88,26.43,False
"def _recursive_fx_apply ( input : dict , fx ) : <TAB> for k , v in input . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = torch . tensor ( v ) <TAB> <TAB> if isinstance ( v , torch . Tensor ) : <TAB> <TAB> <TAB> v = fx ( v . float ( ) ) <TAB> <TAB> <TAB> input [ k ] = v <TAB> <TAB> else : <TAB> <TAB> <TAB> _recursive_fx_apply ( v , fx ) ","if isinstance ( v , list ) : 
","if isinstance ( v , ( float , int ) ) :
",49.15,36.46,False
"def get ( self , url , * * kwargs ) : <TAB> app , url = self . _prepare_call ( url , kwargs ) <TAB> if app : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _first_ping = False <TAB> <TAB> <TAB> return EmptyCapabilitiesResponse ( ) <TAB> <TAB> elif "" Hello0 "" in url and "" 1.2.1 "" in url and "" v1 "" in url : <TAB> <TAB> <TAB> return ErrorApiResponse ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = app . get ( url , * * kwargs ) <TAB> <TAB> <TAB> return TestingResponse ( response ) <TAB> else : <TAB> <TAB> return requests . get ( url , * * kwargs ) ","if url . endswith ( "" ping "" ) and self . _first_ping : 
","if "" https "" in url and "" v1 "" in url :
",29.3,3.55,False
"def server_thread_fn ( ) : <TAB> server_ctx = ssl . create_default_context ( ssl . Purpose . CLIENT_AUTH ) <TAB> server_ctx . load_cert_chain ( "" trio-test-1.pem "" ) <TAB> server = server_ctx . wrap_socket ( <TAB> <TAB> server_sock , <TAB> <TAB> server_side = True , <TAB> <TAB> suppress_ragged_eofs = False , <TAB> ) <TAB> while True : <TAB> <TAB> data = server . recv ( 4096 ) <TAB> <TAB> print ( "" server got: "" , data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" server waiting for client to finish everything "" ) <TAB> <TAB> <TAB> client_done . wait ( ) <TAB> <TAB> <TAB> print ( "" server attempting to send back close-notify "" ) <TAB> <TAB> <TAB> server . unwrap ( ) <TAB> <TAB> <TAB> print ( "" server ok "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> server . sendall ( data ) ","if not data : 
","if not data :
",100.0,100.0,True
"def find_hostnames ( data ) : <TAB> # sends back an array of hostnames <TAB> hostnames = [ ] <TAB> for i in re . finditer ( hostname_regex , data ) : <TAB> <TAB> h = string . lower ( i . group ( 1 ) ) <TAB> <TAB> tld = h . split ( "" . "" ) [ - 1 : ] [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hostnames . append ( h ) <TAB> return hostnames ","if tld in tlds : 
","if tld in hostnames :
",64.55,42.73,False
"def Validate ( self , win ) : <TAB> textCtrl = self . GetWindow ( ) <TAB> text = textCtrl . GetValue ( ) . strip ( ) <TAB> sChar = Character . getInstance ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( _t ( "" You must supply a name for the Character! "" ) ) <TAB> <TAB> elif text in [ x . name for x in sChar . getCharacterList ( ) ] : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> _t ( "" Character name already in use, please choose another. "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> except ValueError as e : <TAB> <TAB> pyfalog . error ( e ) <TAB> <TAB> wx . MessageBox ( "" {} "" . format ( e ) , _t ( "" Error "" ) ) <TAB> <TAB> textCtrl . SetFocus ( ) <TAB> <TAB> return False ","if len ( text ) == 0 : 
","if sChar . name is None :
",26.83,5.87,False
def get_random_user_agent ( agent_list = UA_CACHE ) : <TAB> if not len ( agent_list ) : <TAB> <TAB> ua_file = file ( UA_FILE ) <TAB> <TAB> for line in ua_file : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> agent_list . append ( line ) <TAB> ua = random . choice ( UA_CACHE ) <TAB> return ua ,"if line : 
","if line and not line . startswith ( "" # "" ) :
",32.56,6.84,False
"def _validate_action_like_for_prefixes ( self , key ) : <TAB> for statement in self . _statements : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( statement [ key ] , string_types ) : <TAB> <TAB> <TAB> <TAB> self . _validate_action_prefix ( statement [ key ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for action in statement [ key ] : <TAB> <TAB> <TAB> <TAB> <TAB> self . _validate_action_prefix ( action ) ","if key in statement : 
","if key in statement :
",100.0,100.0,True
"def predict ( self , X ) : <TAB> if self . regression : <TAB> <TAB> return self . predict_proba ( X ) <TAB> else : <TAB> <TAB> y_pred = np . argmax ( self . predict_proba ( X ) , axis = 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y_pred = self . enc_ . inverse_transform ( y_pred ) <TAB> <TAB> return y_pred ","if self . use_label_encoder : 
","if self . enc_ :
",64.48,20.82,False
"def _threaded_request_tracker ( self , builder ) : <TAB> while True : <TAB> <TAB> event_type = self . _read_q . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> payload = { "" body "" : b "" "" } <TAB> <TAB> request_id = builder . build_record ( event_type , payload , "" "" ) <TAB> <TAB> self . _write_q . put_nowait ( request_id ) ","if event_type is False : 
","if event_type is None :
",39.07,64.35,False
"def __call__ ( self , value ) : <TAB> try : <TAB> <TAB> super ( EmailValidator , self ) . __call__ ( value ) <TAB> except ValidationError as e : <TAB> <TAB> # Trivial case failed. Try for possible IDN domain-part <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts = value . split ( "" @ "" ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> parts [ - 1 ] = parts [ - 1 ] . encode ( "" idna "" ) . decode ( "" ascii "" ) <TAB> <TAB> <TAB> except UnicodeError : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> super ( EmailValidator , self ) . __call__ ( "" @ "" . join ( parts ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if value and "" @ "" in value : 
","if "" @ "" in value :
",65.74,63.19,False
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> if self . __Token : <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid : <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1 ","elif not IfList : 
","if x in IfList :
",31.07,21.36,False
"def _arg_with_type ( self ) : <TAB> for t in self . d [ "" Args "" ] : <TAB> <TAB> m = re . search ( "" ([A-Za-z0-9_-]+) \ s { 0,4}( \ (.+ \ )) \ s { 0,4}: "" , t ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . args [ m . group ( 1 ) ] = m . group ( 2 ) <TAB> return self . args ","if m : 
","if m :
",78.12,0.0,False
"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [ ] <TAB> <TAB> for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB> <TAB> <TAB> if new_id != - 1 : <TAB> <TAB> <TAB> <TAB> palette . append ( self . PALETTE [ old_id ] ) <TAB> <TAB> palette = type ( self . PALETTE ) ( palette ) <TAB> elif palette is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> palette = self . PALETTE <TAB> return palette ","if self . PALETTE is None : 
","if class_names :
",26.9,8.52,False
"def Visit_star_expr ( self , node ) :<TAB> # pylint: disable=invalid-name <TAB> # star_expr ::= '*' expr <TAB> for child in node . children : <TAB> <TAB> self . Visit ( child ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _AppendTokenSubtype ( child , format_token . Subtype . UNARY_OPERATOR ) <TAB> <TAB> <TAB> _AppendTokenSubtype ( child , format_token . Subtype . VARARGS_STAR ) ","if isinstance ( child , pytree . Leaf ) and child . value == "" * "" : 
","if isinstance ( child , pytree . Leaf ) and child . value == "" * "" :
",100.0,100.0,True
"def create_if_compatible ( cls , typ : Type , * , root : "" RootNode "" ) - > Optional [ "" Node "" ] : <TAB> if cls . compatible_types : <TAB> <TAB> target_type : Type = typ <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> target_type = getattr ( typ , "" __origin__ "" , None ) or typ <TAB> <TAB> if cls . _issubclass ( target_type , cls . compatible_types ) : <TAB> <TAB> <TAB> return cls ( typ , root = root ) <TAB> return None ","if cls . use_origin : 
","if not isinstance ( typ , target_type ) :
",27.53,4.93,False
"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB> <TAB> tokentype , token = tokens [ i ] <TAB> <TAB> i + = 1 <TAB> <TAB> if tokentype != "" id "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len ( tokens ) <TAB> <TAB> <TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB> <TAB> <TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB> <TAB> <TAB> i + = 2 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token [ 0 ] in "" .0123456789 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token ","if token == "" "" : 
","if token == "" op "" :
",77.33,59.46,False
"def create_config_filepath ( cls , visibility = None ) : <TAB> if cls . is_local ( visibility ) : <TAB> <TAB> # Local to this directory <TAB> <TAB> base_path = os . path . join ( "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Add it to the current ""./.polyaxon"" <TAB> <TAB> <TAB> base_path = os . path . join ( base_path , "" .polyaxon "" ) <TAB> <TAB> <TAB> cls . _create_dir ( base_path ) <TAB> elif cls . CONFIG_PATH :<TAB> # Custom path <TAB> <TAB> pass <TAB> else :<TAB> # Handle both global and all cases <TAB> <TAB> base_path = polyaxon_user_path ( ) <TAB> <TAB> cls . _create_dir ( base_path ) ","if cls . IS_POLYAXON_DIR : 
","if os . path . exists ( base_path ) :
",35.91,4.79,False
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ","elif size < = 3 : 
","elif size < = 3 :
",100.0,100.0,True
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> elif is_dict . match ( item ) : <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result ","if item . endswith ( "" / "" ) : 
","if is_dict . match ( item ) :
",32.21,11.04,False
"def api_read ( self ) : <TAB> result = { } <TAB> files = [ "" my.cnf "" , "" debian.cnf "" ] <TAB> directory_list = self . exec_payload ( "" mysql_config_directory "" ) [ "" directory "" ] <TAB> for _file in files : <TAB> <TAB> for directory in directory_list : <TAB> <TAB> <TAB> mysql_conf = directory + _file <TAB> <TAB> <TAB> content = self . shell . read ( mysql_conf ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ mysql_conf ] = content <TAB> return result ","if content : 
","if content :
",78.12,0.0,False
"def generate ( self , count = 100 ) : <TAB> self . pre_generate ( ) <TAB> counter = iter ( range ( count ) ) <TAB> created = 0 <TAB> while True : <TAB> <TAB> batch = list ( islice ( counter , self . batch_size ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> self . do_generate ( batch , self . batch_size ) <TAB> <TAB> from_size = created <TAB> <TAB> created + = len ( batch ) <TAB> <TAB> print ( "" Generate  %s :  %s - %s "" % ( self . resource , from_size , created ) ) <TAB> self . after_generate ( ) ","if not batch : 
","if len ( batch ) == 0 :
",28.4,6.27,False
"def _normalize_fields ( self , document , loader ) : <TAB> # type: (Dict[Text, Text], Loader) -> None <TAB> # Normalize fields which are prefixed or full URIn to vocabulary terms <TAB> for d in list ( document . keys ( ) ) : <TAB> <TAB> d2 = loader . expand_url ( d , u "" "" , scoped_id = False , vocab_term = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> document [ d2 ] = document [ d ] <TAB> <TAB> <TAB> del document [ d ] ","if d != d2 : 
","if d2 in document :
",53.65,11.51,False
"def load_cache ( filename , get_key = mangle_key ) : <TAB> cache = { } <TAB> if not os . path . exists ( filename ) : <TAB> <TAB> return cache <TAB> f = open ( filename , "" rb "" ) <TAB> l = 0 <TAB> for line in f . readlines ( ) : <TAB> <TAB> l + = 1 <TAB> <TAB> fields = line . split ( b "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sys . stderr . write ( "" Invalid file format in [ %s ], line  %d \n "" % ( filename , l ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> # put key:value in cache, key without ^: <TAB> <TAB> cache [ get_key ( fields [ 0 ] [ 1 : ] ) ] = fields [ 1 ] . split ( b "" \n "" ) [ 0 ] <TAB> f . close ( ) <TAB> return cache ","if fields == None or not len ( fields ) == 2 or fields [ 0 ] [ 0 : 1 ] != b "" : "" : 
","if len ( fields ) != 2 :
",33.25,3.6,False
"def __lshift__ ( self , other ) : <TAB> if not self . symbolic and type ( other ) is int : <TAB> <TAB> return RegisterOffset ( <TAB> <TAB> <TAB> self . _bits , self . reg , self . _to_signed ( self . offset << other ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return RegisterOffset ( self . _bits , self . reg , self . offset << other ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return RegisterOffset ( <TAB> <TAB> <TAB> <TAB> self . _bits , <TAB> <TAB> <TAB> <TAB> self . reg , <TAB> <TAB> <TAB> <TAB> ArithmeticExpression ( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression . LShift , <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . offset , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other , <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> ) ","if self . symbolic : 
","if self . symbolic :
",100.0,100.0,True
"def SaveSettings ( self , force = False ) : <TAB> if self . config is not None : <TAB> <TAB> frame . ShellFrameMixin . SaveSettings ( self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frame . Frame . SaveSettings ( self , self . config ) <TAB> <TAB> <TAB> self . shell . SaveSettings ( self . config ) ","if self . autoSaveSettings or force : 
","if force or not self . shell . IsEnabled ( ) :
",34.78,8.91,False
"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB> <TAB> if "" type "" in genename_element . attrib : <TAB> <TAB> <TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB> <TAB> <TAB> <TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB> <TAB> <TAB> <TAB> genename_element . attrib [ "" type "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> append_to_annotations ( ann_key , genename_element . text ) ","if genename_element . attrib [ "" type "" ] == "" primary "" : 
","if self . ParsedSeqRecord :
",29.38,1.28,False
"def _write_pkg_file ( self , file ) : <TAB> with TemporaryFile ( mode = "" w+ "" ) as tmpfd : <TAB> <TAB> _write_pkg_file_orig ( self , tmpfd ) <TAB> <TAB> tmpfd . seek ( 0 ) <TAB> <TAB> for line in tmpfd : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> file . write ( "" Metadata-Version: 2.1 \n "" ) <TAB> <TAB> <TAB> elif line . startswith ( "" Description:  "" ) : <TAB> <TAB> <TAB> <TAB> file . write ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Description-Content-Type:  %s ; charset=UTF-8 \n "" <TAB> <TAB> <TAB> <TAB> <TAB> % long_description_content_type <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> file . write ( line ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> file . write ( line ) ","if line . startswith ( "" Metadata-Version:  "" ) : 
","if line . startswith ( "" Metadata:  "" ) :
",83.03,70.17,False
"def get ( self ) : <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self . _exception is not _NONE : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . value <TAB> <TAB> getcurrent ( ) . throw ( * self . _exception )<TAB> # pylint:disable=undefined-variable <TAB> else : <TAB> <TAB> if self . greenlet is not None : <TAB> <TAB> <TAB> raise ConcurrentObjectUseError ( <TAB> <TAB> <TAB> <TAB> "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . greenlet = getcurrent ( )<TAB> # pylint:disable=undefined-variable <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . hub . switch ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . greenlet = None ","if self . _exception is None : 
","if isinstance ( self . value , ( list , tuple ) ) :
",34.07,6.75,False
"def connect ( self , * args ) : <TAB> """"""connects to the dropbox. args[0] is the username."""""" <TAB> if len ( args ) != 1 : <TAB> <TAB> return "" expected one argument! "" <TAB> try : <TAB> <TAB> dbci = get_dropbox_client ( args [ 0 ] , False , None , None ) <TAB> except Exception as e : <TAB> <TAB> return e . message <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" No Dropbox configured for  ' {u} ' . "" . format ( u = args [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . client = dbci <TAB> <TAB> return True ","if dbci is None : 
","if not dbci :
",28.67,16.37,False
"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text ","if "" \n "" in text : 
","if "" \n "" in text :
",100.0,100.0,True
def t ( ret ) : <TAB> with IPDB ( ) as ipdb : <TAB> <TAB> with ipdb . eventqueue ( ) as evq : <TAB> <TAB> <TAB> for msg in evq : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> ret . append ( msg ) <TAB> <TAB> <TAB> <TAB> <TAB> return ,"if msg . get_attr ( "" IFLA_IFNAME "" ) == "" test1984 "" : 
","if msg not in ret :
",26.6,2.06,False
"def check_stmt ( self , stmt ) : <TAB> if is_future ( stmt ) : <TAB> <TAB> for name , asname in stmt . names : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . found [ name ] = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise SyntaxError ( "" future feature  %s  is not defined "" % name ) <TAB> <TAB> stmt . valid_future = 1 <TAB> <TAB> return 1 <TAB> return 0 ","if name in self . features : 
","if asname == "" future "" :
",27.05,6.57,False
"def process_pypi_option ( option , option_str , option_value , parser ) : <TAB> if option_str . startswith ( "" --no "" ) : <TAB> <TAB> setattr ( parser . values , option . dest , [ ] ) <TAB> else : <TAB> <TAB> indexes = getattr ( parser . values , option . dest , [ ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> indexes . append ( _PYPI ) <TAB> <TAB> setattr ( parser . values , option . dest , indexes ) ","if _PYPI not in indexes : 
","if option_value . startswith ( "" -- "" ) :
",26.84,4.46,False
"def modify_address ( self , name , address , domain ) : <TAB> if not self . get_entries_by_name ( name , domain ) : <TAB> <TAB> raise exception . NotFound <TAB> infile = open ( self . filename , "" r "" ) <TAB> outfile = tempfile . NamedTemporaryFile ( "" w "" , delete = False ) <TAB> for line in infile : <TAB> <TAB> entry = self . parse_line ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> outfile . write ( <TAB> <TAB> <TAB> <TAB> "" %s<TAB>  %s<TAB>  %s \n "" % ( address , self . qualify ( name , domain ) , entry [ "" type "" ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> outfile . write ( line ) <TAB> infile . close ( ) <TAB> outfile . close ( ) <TAB> shutil . move ( outfile . name , self . filename ) ","if entry and entry [ "" name "" ] . lower ( ) == self . qualify ( name , domain ) . lower ( ) : 
","if entry :
",25.48,0.0,False
"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google : <TAB> <TAB> y = ( 2 * * z - 1 ) - y <TAB> for i in range ( z , 0 , - 1 ) : <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << ( i - 1 ) <TAB> <TAB> if ( x & mask ) != 0 : <TAB> <TAB> <TAB> digit + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> digit + = 2 <TAB> <TAB> quadKey + = str ( digit ) <TAB> return quadKey ","if ( y & mask ) != 0 : 
","if ( y & mask ) != 0 :
",100.0,100.0,True
"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> for typ , key in keys : <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> <TAB> <TAB> if _typ == typ and key is _key : <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] = keys ","if flag : 
","if flag :
",78.12,0.0,False
"def scan_error ( self ) : <TAB> "" A string describing why the last scan failed, or None if it didn ' t. "" <TAB> self . acquire_lock ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . _load_buf_data_once ( ) <TAB> <TAB> <TAB> except NotFoundInDatabase : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return self . _scan_error_cache <TAB> finally : <TAB> <TAB> self . release_lock ( ) ","if self . _scan_error_cache is None : 
","if self . _scan_error_cache is not None :
",82.54,79.11,False
"def _query ( self ) : <TAB> if self . _mongo_query is None : <TAB> <TAB> self . _mongo_query = self . _query_obj . to_query ( self . _document ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" _cls "" in self . _mongo_query : <TAB> <TAB> <TAB> <TAB> self . _mongo_query = { "" $and "" : [ self . _cls_query , self . _mongo_query ] } <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _mongo_query . update ( self . _cls_query ) <TAB> return self . _mongo_query ","if self . _cls_query : 
","if self . _query_obj is not None :
",44.36,29.0,False
"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self . HasCloseButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMaximizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n + = 1 <TAB> return n ","if self . HasPinButton ( ) : 
","if self . HasCheckBox ( ) :
",63.85,41.11,False
"def testBind ( self ) : <TAB> try : <TAB> <TAB> with socket . socket ( socket . PF_CAN , socket . SOCK_DGRAM , socket . CAN_J1939 ) as s : <TAB> <TAB> <TAB> addr = ( <TAB> <TAB> <TAB> <TAB> self . interface , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_NAME , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_PGN , <TAB> <TAB> <TAB> <TAB> socket . J1939_NO_ADDR , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> s . bind ( addr ) <TAB> <TAB> <TAB> self . assertEqual ( s . getsockname ( ) , addr ) <TAB> except OSError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" network interface ` %s ` does not exist "" % self . interface ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if e . errno == errno . ENODEV : 
","if e . errno == errno . EADDRINUSE :
",87.71,78.25,False
"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB> <TAB> pos = self . stream . searchBytes ( <TAB> <TAB> <TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB> <TAB> )<TAB> # seek forward by at most 1MB <TAB> <TAB> if pos is not None : <TAB> <TAB> <TAB> padsize = pos - self . current_size <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB> <TAB> chunk = Chunk ( self , "" chunk[] "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk [ "" content/data "" ] <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk ","if padsize : 
","if padsize > 0 :
",34.79,23.64,False
"def index_modulemd_files ( repo_path ) : <TAB> merger = Modulemd . ModuleIndexMerger ( ) <TAB> for fn in sorted ( os . listdir ( repo_path ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> yaml_path = os . path . join ( repo_path , fn ) <TAB> <TAB> mmd = Modulemd . ModuleIndex ( ) <TAB> <TAB> mmd . update_from_file ( yaml_path , strict = True ) <TAB> <TAB> merger . associate_index ( mmd , 0 ) <TAB> return merger . resolve ( ) ","if not fn . endswith ( "" .yaml "" ) : 
","if fn . startswith ( "" .yaml "" ) :
",65.62,59.21,False
"def set_visible ( self , visible = True ) : <TAB> self . _visible = visible <TAB> if self . _nswindow is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Not really sure why on_resize needs to be here, <TAB> <TAB> <TAB> # but it's what pyglet wants. <TAB> <TAB> <TAB> self . dispatch_event ( "" on_resize "" , self . _width , self . _height ) <TAB> <TAB> <TAB> self . dispatch_event ( "" on_show "" ) <TAB> <TAB> <TAB> self . dispatch_event ( "" on_expose "" ) <TAB> <TAB> <TAB> self . _nswindow . makeKeyAndOrderFront_ ( None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _nswindow . orderOut_ ( None ) ","if visible : 
","if visible :
",78.12,0.0,False
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> if self . is_computed ( ) : <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> if self . error ( ) is None : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False ","if self . value ( ) is self : 
","if self . value ( ) is None :
",75.3,75.06,False
"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB> <TAB> for key , value in segment . items ( ) : <TAB> <TAB> <TAB> if key == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if key . text == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB> <TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB> <TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB> <TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB> <TAB> raise Exception ( "" Invalid state "" ) ","if hasattr ( key , "" text "" ) : 
","elif index_type == "" text "" :
",35.44,16.78,False
"def _makeSafeAbsoluteURI ( base , rel = None ) : <TAB> # bail if ACCEPTABLE_URI_SCHEMES is empty <TAB> if not ACCEPTABLE_URI_SCHEMES : <TAB> <TAB> return _urljoin ( base , rel or u "" "" ) <TAB> if not base : <TAB> <TAB> return rel or u "" "" <TAB> if not rel : <TAB> <TAB> try : <TAB> <TAB> <TAB> scheme = urlparse . urlparse ( base ) [ 0 ] <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> return u "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return base <TAB> <TAB> return u "" "" <TAB> uri = _urljoin ( base , rel ) <TAB> if uri . strip ( ) . split ( "" : "" , 1 ) [ 0 ] not in ACCEPTABLE_URI_SCHEMES : <TAB> <TAB> return u "" "" <TAB> return uri ","if not scheme or scheme in ACCEPTABLE_URI_SCHEMES : 
","if scheme in ACCEPTABLE_URI_SCHEMES :
",48.52,63.71,False
"def _write_packet ( self , packet ) : <TAB> # Immediately writes the given packet to the network. The caller must <TAB> # have the write lock acquired before calling this method. <TAB> try : <TAB> <TAB> for listener in self . early_outgoing_packet_listeners : <TAB> <TAB> <TAB> listener . call_packet ( packet ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> packet . write ( self . socket , self . options . compression_threshold ) <TAB> <TAB> else : <TAB> <TAB> <TAB> packet . write ( self . socket ) <TAB> <TAB> for listener in self . outgoing_packet_listeners : <TAB> <TAB> <TAB> listener . call_packet ( packet ) <TAB> except IgnorePacket : <TAB> <TAB> pass ","if self . options . compression_enabled : 
","if self . options . compression_threshold is not None :
",64.1,53.32,False
"def rangelist_to_set ( rangelist ) : <TAB> result = set ( ) <TAB> if not rangelist : <TAB> <TAB> return result <TAB> for x in rangelist . split ( "" , "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . add ( int ( x ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re . match ( r "" ^( \ d+)-( \ d+)$ "" , x ) <TAB> <TAB> if m : <TAB> <TAB> <TAB> start = int ( m . group ( 1 ) ) <TAB> <TAB> <TAB> end = int ( m . group ( 2 ) ) <TAB> <TAB> <TAB> result . update ( set ( range ( start , end + 1 ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> msg = "" Cannot understand data input:  %s %s "" % ( x , rangelist ) <TAB> <TAB> raise ValueError ( msg ) <TAB> return result ","if re . match ( r "" ^( \ d+)$ "" , x ) : 
","if x . isdigit ( ) :
",29.8,3.11,False
"def test_device_property_logfile_isinstance ( self ) : <TAB> mock = MagicMock ( ) <TAB> with patch ( builtin_string + "" .open "" , mock ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> builtin_file = "" io.TextIOWrapper "" <TAB> <TAB> else : <TAB> <TAB> <TAB> builtin_file = builtin_string + "" .file "" <TAB> <TAB> with patch ( builtin_file , MagicMock ) : <TAB> <TAB> <TAB> handle = open ( "" filename "" , "" r "" ) <TAB> <TAB> <TAB> self . dev . logfile = handle <TAB> <TAB> <TAB> self . assertEqual ( self . dev . logfile , handle ) ","if sys . version > "" 3 "" : 
","if sys . version_info > ( 3 , 0 ) :
",36.43,22.24,False
"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines [ lidx ] : <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> if not start : <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs ","elif start : 
","if start and not end :
",28.95,9.65,False
"def reset_parameters ( self ) : <TAB> initialize = layers . get_initializer ( self . _hparams . initializer ) <TAB> if initialize is not None : <TAB> <TAB> # Do not re-initialize LayerNorm modules. <TAB> <TAB> for name , param in self . named_parameters ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> initialize ( param ) ","if name . split ( "" . "" ) [ - 1 ] == "" weight "" and "" layer_norm "" not in name : 
","if isinstance ( param , ( LayerNorm , LayerNorm ) ) :
",25.49,1.26,False
"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB> <TAB> RequiredArgumentMissingError , <TAB> <TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB> <TAB> if namespace . by_subscription is not None : <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> if namespace . by_subscription is not None : <TAB> <TAB> if namespace . name is None : <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) ","if namespace . name is None : 
","if namespace . name is None :
",100.0,100.0,True
"def DeleteDocuments ( self , document_ids , response ) : <TAB> """"""Deletes documents for the given document_ids."""""" <TAB> for document_id in document_ids : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> document = self . _documents [ document_id ] <TAB> <TAB> <TAB> self . _inverted_index . RemoveDocument ( document ) <TAB> <TAB> <TAB> del self . _documents [ document_id ] <TAB> <TAB> delete_status = response . add_status ( ) <TAB> <TAB> delete_status . set_code ( search_service_pb . SearchServiceError . OK ) ","if document_id in self . _documents : 
","if document_id in self . _documents :
",100.0,100.0,True
"def generate_new_element ( items , prefix , numeric = False ) : <TAB> """"""Creates a random string with prefix, that is not in 'items' list."""""" <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> candidate = prefix + generate_random_numeric ( 8 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> candidate = prefix + generate_random_alphanumeric ( 8 ) <TAB> <TAB> if not candidate in items : <TAB> <TAB> <TAB> return candidate <TAB> <TAB> LOG . debug ( "" Random collision on  %s "" % candidate ) ","if numeric : 
","if numeric :
",78.12,0.0,False
"def generate_text_for_vocab ( self , data_dir , tmp_dir ) : <TAB> for i , sample in enumerate ( <TAB> <TAB> self . generate_samples ( data_dir , tmp_dir , problem . DatasetSplit . TRAIN ) <TAB> ) : <TAB> <TAB> if self . has_inputs : <TAB> <TAB> <TAB> yield sample [ "" inputs "" ] <TAB> <TAB> yield sample [ "" targets "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if self . max_samples_for_vocab and ( i + 1 ) > = self . max_samples_for_vocab : 
","if i > = self . max_samples_for_vocab :
",48.15,32.06,False
"def _get_ccp ( config = None , config_path = None , saltenv = "" base "" ) : <TAB> """""" """""" <TAB> if config_path : <TAB> <TAB> config = __salt__ [ "" cp.get_file_str "" ] ( config_path , saltenv = saltenv ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise SaltException ( "" {}  is not available "" . format ( config_path ) ) <TAB> if isinstance ( config , six . string_types ) : <TAB> <TAB> config = config . splitlines ( ) <TAB> ccp = ciscoconfparse . CiscoConfParse ( config ) <TAB> return ccp ","if config is False : 
","if not config :
",28.67,16.37,False
"def rpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB> <TAB> _client . rpush ( key , * vals ) <TAB> else : <TAB> <TAB> pipe = _client . pipeline ( ) <TAB> <TAB> pipe . rpush ( key , * vals ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pipe . ltrim ( key , 0 , cap ) <TAB> <TAB> if ttl : <TAB> <TAB> <TAB> pipe . expire ( key , ttl ) <TAB> <TAB> pipe . execute ( ) ","if cap : 
","if cap :
",78.12,0.0,False
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","if mode == "" start "" : 
","if s . startswith ( "" Key-Type "" ) :
",33.24,5.93,False
"def _add_communication_type ( apps , schema_editor , communication_type ) : <TAB> Worker = apps . get_model ( "" orchestra "" , "" Worker "" ) <TAB> CommunicationPreference = apps . get_model ( "" orchestra "" , "" CommunicationPreference "" ) <TAB> for worker in Worker . objects . all ( ) : <TAB> <TAB> ( <TAB> <TAB> <TAB> communication_preference , <TAB> <TAB> <TAB> created , <TAB> <TAB> ) = CommunicationPreference . objects . get_or_create ( <TAB> <TAB> <TAB> worker = worker , communication_type = communication_type <TAB> <TAB> ) <TAB> <TAB> # By default set both Slack and Email notifications to True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> communication_preference . methods . slack = True <TAB> <TAB> <TAB> communication_preference . methods . email = True <TAB> <TAB> communication_preference . save ( ) ","if created : 
","if communication_preference . methods . email :
",29.58,5.67,False
"def get_postgresql_driver_name ( ) : <TAB> # pylint: disable=unused-variable <TAB> try : <TAB> <TAB> driver = os . getenv ( "" CODECHECKER_DB_DRIVER "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return driver <TAB> <TAB> try : <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import psycopg2 <TAB> <TAB> <TAB> return "" psycopg2 "" <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> # pylint: disable=W0611 <TAB> <TAB> <TAB> import pg8000 <TAB> <TAB> <TAB> return "" pg8000 "" <TAB> except Exception as ex : <TAB> <TAB> LOG . error ( str ( ex ) ) <TAB> <TAB> LOG . error ( "" Failed to import psycopg2 or pg8000 module. "" ) <TAB> <TAB> raise ","if driver : 
","if driver :
",78.12,0.0,False
"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB> <TAB> if entry is False : <TAB> <TAB> <TAB> continue <TAB> <TAB> code , tags , used , refname = entry <TAB> <TAB> for fullname in list ( used ) : <TAB> <TAB> <TAB> if used [ fullname ] == docname : <TAB> <TAB> <TAB> <TAB> used . pop ( fullname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> modules . pop ( modname ) ","if len ( used ) == 0 : 
","if modname in modules :
",26.86,5.71,False
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret ","if not is_iterable ( value ) : 
","if len ( q ) == 0 :
",37.13,6.74,False
"def _get_bucket_for_key ( self , key : bytes ) - > Optional [ _DBValueTuple ] : <TAB> dbs : Iterable [ PartitionDB ] <TAB> try : <TAB> <TAB> partition = self . _key_index [ key ] <TAB> <TAB> dbs = [ PartitionDB ( partition , self . _dbs [ partition ] ) ] <TAB> except KeyError : <TAB> <TAB> dbs = cast ( Iterable [ PartitionDB ] , self . _dbs . items ( ) ) <TAB> for partition , db in dbs : <TAB> <TAB> if db . key_may_exist ( key ) [ 0 ] : <TAB> <TAB> <TAB> value = db . get ( key ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _key_index [ key ] = partition <TAB> <TAB> <TAB> <TAB> return _DBValueTuple ( db , value ) <TAB> return None ","if value is not None : 
","if value is not None :
",100.0,100.0,True
"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB> <TAB> if self . _process . poll ( ) is None : <TAB> <TAB> <TAB> for _ in range ( 3 ) : <TAB> <TAB> <TAB> <TAB> self . _process . terminate ( ) <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _process . kill ( ) <TAB> <TAB> <TAB> <TAB> self . _process . wait ( ) <TAB> <TAB> <TAB> <TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB> <TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" ) ","if self . _process . poll ( ) is not None : 
","if self . _process . poll ( ) is None :
",85.01,79.79,False
"def _calculate_runtimes ( states ) : <TAB> results = { "" runtime "" : 0.00 , "" num_failed_states "" : 0 , "" num_passed_states "" : 0 } <TAB> for state , resultset in states . items ( ) : <TAB> <TAB> if isinstance ( resultset , dict ) and "" duration "" in resultset : <TAB> <TAB> <TAB> # Count the pass vs failures <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> results [ "" num_passed_states "" ] + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results [ "" num_failed_states "" ] + = 1 <TAB> <TAB> <TAB> # Count durations <TAB> <TAB> <TAB> results [ "" runtime "" ] + = resultset [ "" duration "" ] <TAB> log . debug ( "" Parsed state metrics:  {} "" . format ( results ) ) <TAB> return results ","if resultset [ "" result "" ] : 
","if resultset [ "" pass "" ] :
",75.15,50.0,False
"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB> <TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB> <TAB> if max != - 1 and spaces > max : <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB> <TAB> <TAB> ) ","elif min != - 1 and spaces < min : 
","if min != - 1 and spaces < min :
",74.97,89.32,False
"def getfileinfo ( name ) : <TAB> finfo = FInfo ( ) <TAB> with io . open ( name , "" rb "" ) as fp : <TAB> <TAB> # Quick check for textfile <TAB> <TAB> data = fp . read ( 512 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> finfo . Type = "" TEXT "" <TAB> <TAB> fp . seek ( 0 , 2 ) <TAB> <TAB> dsize = fp . tell ( ) <TAB> dir , file = os . path . split ( name ) <TAB> file = file . replace ( "" : "" , "" - "" , 1 ) <TAB> return file , finfo , dsize , 0 ","if 0 not in data : 
","if data == "" \x00 \x00 \x00 "" :
",27.05,4.07,False
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> if tag == "" layers "" : <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if tag == "" config "" : <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem ","elif isinstance ( val , MutableMapping ) : 
","elif tag == "" dict "" :
",26.83,6.57,False
"def _read_bytes ( self , length ) : <TAB> buffer = b "" "" <TAB> while length : <TAB> <TAB> chunk = self . request . recv ( length ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . debug ( "" Connection closed "" ) <TAB> <TAB> <TAB> return False <TAB> <TAB> length - = len ( chunk ) <TAB> <TAB> buffer + = chunk <TAB> return buffer ","if chunk == b "" "" : 
","if not chunk :
",27.45,7.73,False
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> if dep_cnt : <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB> <TAB> <TAB> deps . update ( new_deps ) <TAB> return deps ","if not dep_cnts : 
","if dep_cnts is None :
",29.25,27.78,False
"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self ","if type ( e ) is Argument or type ( e ) is Option and e . argcount : 
","if type ( e ) is Argument or type ( e ) is Option and e . argcount == 1 :
",86.22,81.52,False
"def do_cli ( manager , options ) : <TAB> header = [ "" Name "" , "" Description "" ] <TAB> table_data = [ header ] <TAB> for filter_name , filter in get_filters ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> filter_doc = inspect . getdoc ( filter ) or "" "" <TAB> <TAB> table_data . append ( [ filter_name , filter_doc ] ) <TAB> try : <TAB> <TAB> table = TerminalTable ( options . table_type , table_data ) <TAB> except TerminalTableError as e : <TAB> <TAB> console ( "" ERROR:  %s "" % str ( e ) ) <TAB> else : <TAB> <TAB> console ( table . output ) ","if options . name and not options . name in filter_name : 
","if filter is None :
",25.93,2.32,False
"def _do_cmp ( f1 , f2 ) : <TAB> bufsize = BUFSIZE <TAB> with open ( f1 , "" rb "" ) as fp1 , open ( f2 , "" rb "" ) as fp2 : <TAB> <TAB> while True : <TAB> <TAB> <TAB> b1 = fp1 . read ( bufsize ) <TAB> <TAB> <TAB> b2 = fp2 . read ( bufsize ) <TAB> <TAB> <TAB> if b1 != b2 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True ","if not b1 : 
","if b1 == b2 :
",29.25,10.68,False
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not father_handle : 
","if father_handle :
",34.18,57.89,False
"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB> <TAB> n = ord ( char ) <TAB> <TAB> if 64 < n < 91 : <TAB> <TAB> <TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB> <TAB> result = result + chr ( n ) <TAB> return result ","if 96 < n < 123 : 
","elif 97 < n < 126 :
",33.31,26.27,False
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> if i == index : <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file . description : <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None ","if composite_file . optional : 
","elif composite_file . optional :
",64.49,80.91,False
"def __str__ ( self ) : <TAB> t = ""<TAB>  "" <TAB> if self . _name != "" root "" : <TAB> <TAB> r = f "" { t * ( self . _level - 1 ) } { self . _name } : \n "" <TAB> else : <TAB> <TAB> r = "" "" <TAB> level = self . _level <TAB> for i , ( k , v ) in enumerate ( self . _pointer . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r + = f "" { t * ( self . _level ) } { v } \n "" <TAB> <TAB> <TAB> self . _level + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> r + = f "" { t * ( self . _level ) } { k } :  { v }  ( { type ( v ) . __name__ } ) \n "" <TAB> <TAB> self . _level = level <TAB> return r [ : - 1 ] ","if isinstance ( v , Config ) : 
","if i == level :
",26.86,6.92,False
"def __get_securitygroups ( vm_ ) : <TAB> vm_securitygroups = config . get_cloud_config_value ( <TAB> <TAB> "" securitygroups "" , vm_ , __opts__ , search_global = False <TAB> ) <TAB> if not vm_securitygroups : <TAB> <TAB> return [ ] <TAB> securitygroups = list_securitygroups ( ) <TAB> for i in range ( len ( vm_securitygroups ) ) : <TAB> <TAB> vm_securitygroups [ i ] = six . text_type ( vm_securitygroups [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise SaltCloudNotFound ( <TAB> <TAB> <TAB> <TAB> "" The specified securitygroups  ' {0} '  could not be found. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> vm_securitygroups [ i ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vm_securitygroups ","if vm_securitygroups [ i ] not in securitygroups : 
","if not vm_securitygroups [ i ] :
",47.29,52.05,False
"def assert_walk_snapshot ( <TAB> self , field , filespecs_or_globs , paths , ignore_patterns = None , prepare = None ) : <TAB> with self . mk_project_tree ( ignore_patterns = ignore_patterns ) as project_tree : <TAB> <TAB> scheduler = self . mk_scheduler ( <TAB> <TAB> <TAB> rules = create_fs_rules ( ) , project_tree = project_tree <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> prepare ( project_tree ) <TAB> <TAB> result = self . execute ( scheduler , Snapshot , self . specs ( filespecs_or_globs ) ) [ 0 ] <TAB> <TAB> self . assertEqual ( sorted ( getattr ( result , field ) ) , sorted ( paths ) ) ","if prepare : 
","if prepare :
",78.12,0.0,False
"def _parse_rowids ( self , rowids ) : <TAB> xploded = [ ] <TAB> rowids = [ x . strip ( ) for x in rowids . split ( "" , "" ) ] <TAB> for rowid in rowids : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> start = int ( rowid . split ( "" - "" ) [ 0 ] . strip ( ) ) <TAB> <TAB> <TAB> <TAB> end = int ( rowid . split ( "" - "" ) [ - 1 ] . strip ( ) ) <TAB> <TAB> <TAB> <TAB> xploded + = range ( start , end + 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> xploded . append ( int ( rowid ) ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> continue <TAB> return sorted ( list ( set ( xploded ) ) ) ","if "" - "" in rowid : 
","if "" - "" in rowid :
",100.0,100.0,True
"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> elif w in self . word_dict : <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None : <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas ","if ( w , pos ) in self . composite_dict : 
","if ( w , pos ) in self . composite_dict :
",100.0,100.0,True
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add : <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( ) ","if box == self . level . bounds : 
","if remove and add :
",26.57,4.67,False
"def _ensure_max_size ( cls , image , max_size , interpolation ) : <TAB> if max_size is not None : <TAB> <TAB> size = max ( image . shape [ 0 ] , image . shape [ 1 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resize_factor = max_size / size <TAB> <TAB> <TAB> new_height = int ( image . shape [ 0 ] * resize_factor ) <TAB> <TAB> <TAB> new_width = int ( image . shape [ 1 ] * resize_factor ) <TAB> <TAB> <TAB> image = ia . imresize_single_image ( <TAB> <TAB> <TAB> <TAB> image , ( new_height , new_width ) , interpolation = interpolation <TAB> <TAB> <TAB> ) <TAB> return image ","if size > max_size : 
","if size > max_size :
",100.0,100.0,True
"def _1_0_cloud_ips ( self , method , url , body , headers ) : <TAB> if method == "" GET "" : <TAB> <TAB> return self . test_response ( httplib . OK , self . fixtures . load ( "" list_cloud_ips.json "" ) ) <TAB> elif method == "" POST "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> body = json . loads ( body ) <TAB> <TAB> node = json . loads ( self . fixtures . load ( "" create_cloud_ip.json "" ) ) <TAB> <TAB> if "" reverse_dns "" in body : <TAB> <TAB> <TAB> node [ "" reverse_dns "" ] = body [ "" reverse_dns "" ] <TAB> <TAB> return self . test_response ( httplib . ACCEPTED , json . dumps ( node ) ) ","if body : 
","if body :
",78.12,0.0,False
"def get_formatted_stats ( self ) : <TAB> """"""Get percentage or number of rar's done"""""" <TAB> if self . cur_setname and self . cur_setname in self . total_volumes : <TAB> <TAB> # This won't work on obfuscated posts <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" %02d / %02d "" % ( self . cur_volume , self . total_volumes [ self . cur_setname ] ) <TAB> return self . cur_volume ","if self . total_volumes [ self . cur_setname ] > = self . cur_volume and self . cur_volume : 
","if self . cur_volume != "" "" :
",38.3,10.47,False
"def wdayset ( self , year , month , day ) : <TAB> # We need to handle cross-year weeks here. <TAB> dset = [ None ] * ( self . yearlen + 7 ) <TAB> i = datetime . date ( year , month , day ) . toordinal ( ) - self . yearordinal <TAB> start = i <TAB> for j in range ( 7 ) : <TAB> <TAB> dset [ i ] = i <TAB> <TAB> i + = 1 <TAB> <TAB> # if (not (0 <= i < self.yearlen) or <TAB> <TAB> #<TAB> self.wdaymask[i] == self.rrule._wkst):<TAB> <TAB> # This will cross the year boundary, if necessary. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return dset , start , i ","if self . wdaymask [ i ] == self . rrule . _wkst : 
","if self . wdaymask [ i ] == self . rrule . _wkst :
",100.0,100.0,True
"def do_acquire_read_lock ( self , wait = True ) : <TAB> self . condition . acquire ( ) <TAB> try : <TAB> <TAB> # see if a synchronous operation is waiting to start <TAB> <TAB> # or is already running, in which case we wait (or just <TAB> <TAB> # give up and return) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> while self . current_sync_operation is not None : <TAB> <TAB> <TAB> <TAB> self . condition . wait ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if self . current_sync_operation is not None : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> self . asynch + = 1 <TAB> finally : <TAB> <TAB> self . condition . release ( ) <TAB> if not wait : <TAB> <TAB> return True ","if wait : 
","if wait :
",78.12,0.0,False
"def _blend ( x , y ) :<TAB> # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB> <TAB> if not isinstance ( y , ( list , tuple ) ) : <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB> <TAB> if len ( x ) > len ( y ) : <TAB> <TAB> <TAB> result + = x [ len ( y ) : ] <TAB> <TAB> elif len ( x ) < len ( y ) : <TAB> <TAB> <TAB> result + = y [ len ( x ) : ] <TAB> <TAB> return result <TAB> return y ","if not isinstance ( y , ( dict , OrderedDict ) ) : 
","if not isinstance ( y , dict ) :
",47.37,43.62,False
"def update_forum_nums_topic_post ( modeladmin , request , queryset ) : <TAB> for forum in queryset : <TAB> <TAB> forum . num_topics = forum . count_nums_topic ( ) <TAB> <TAB> forum . num_posts = forum . count_nums_post ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> forum . last_post = forum . topic_set . order_by ( "" -last_reply_on "" ) [ 0 ] . last_post <TAB> <TAB> else : <TAB> <TAB> <TAB> forum . last_post = "" "" <TAB> <TAB> forum . save ( ) ","if forum . num_topics : 
","if forum . last_post :
",64.48,27.78,False
"def get_docname_for_node ( self , node : Node ) - > str : <TAB> while node : <TAB> <TAB> if isinstance ( node , nodes . document ) : <TAB> <TAB> <TAB> return self . env . path2doc ( node [ "" source "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return node [ "" docname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> node = node . parent <TAB> return None<TAB> # never reached here. only for type hinting ","elif isinstance ( node , addnodes . start_of_file ) : 
","elif isinstance ( node , nodes . name ) :
",73.56,31.31,False
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> if self . _args . host and self . _args . host == machine . name : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines ","if self . locations and machine . location in self . locations : 
","if self . _args . port and self . _args . port == machine . port :
",40.94,11.15,False
"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB> <TAB> if value is True : <TAB> <TAB> <TAB> return [ "" - %s "" % name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if split_single_char_options : <TAB> <TAB> <TAB> <TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB> <TAB> if value is True : <TAB> <TAB> <TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB> <TAB> elif value is not False and value is not None : <TAB> <TAB> <TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ] ","elif value not in ( False , None ) : 
","elif isinstance ( value , str ) :
",27.77,11.32,False
"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * ""<TAB> "" <TAB> if len ( elem ) : <TAB> <TAB> if not elem . text or not elem . text . strip ( ) : <TAB> <TAB> <TAB> elem . text = i + ""<TAB> "" <TAB> <TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB> <TAB> <TAB> elem . tail = i <TAB> <TAB> for elem in elem : <TAB> <TAB> <TAB> indent ( elem , level + 1 ) <TAB> <TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB> <TAB> <TAB> elem . tail = i <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elem . tail = i ","if level and ( not elem . tail or not elem . tail . strip ( ) ) : 
","if level and ( not elem . tail or not elem . tail . strip ( ) ) :
",100.0,100.0,True
"def _run_instances_op ( self , op , instance_ids , * * kwargs ) : <TAB> while instance_ids : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . manager . retry ( op , InstanceIds = instance_ids , * * kwargs ) <TAB> <TAB> except ClientError as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> instance_ids . remove ( extract_instance_id ( e ) ) <TAB> <TAB> <TAB> raise ","if e . response [ "" Error "" ] [ "" Code "" ] == "" IncorrectInstanceState "" : 
","if e . response [ "" Error "" ] [ "" Code "" ] == "" NoSuchEntity "" :
",93.37,87.39,False
"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB> <TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB> <TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB> <TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB> <TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bomb_count + = 1 <TAB> <TAB> <TAB> if bomb_count > 3 : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> fish . click ( ) <TAB> <TAB> time . sleep ( 2.5 ) ","if fish is bomb : 
","if fish . get_state ( ) == "" bomb "" :
",29.35,6.75,False
"def lineWidth ( self , lw = None ) : <TAB> """"""Set/get width of mesh edges. Same as `lw()`."""""" <TAB> if lw is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOff ( ) <TAB> <TAB> <TAB> self . GetProperty ( ) . SetRepresentationToSurface ( ) <TAB> <TAB> <TAB> return self <TAB> <TAB> self . GetProperty ( ) . EdgeVisibilityOn ( ) <TAB> <TAB> self . GetProperty ( ) . SetLineWidth ( lw ) <TAB> else : <TAB> <TAB> return self . GetProperty ( ) . GetLineWidth ( ) <TAB> return self ","if lw == 0 : 
","if lw == 1 :
",64.48,53.73,False
"def _current_date_updater ( doc , field_name , value ) : <TAB> if isinstance ( doc , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # TODO(juannyg): get_current_timestamp should also be using helpers utcnow, <TAB> <TAB> <TAB> # as it currently using time.time internally <TAB> <TAB> <TAB> doc [ field_name ] = helpers . get_current_timestamp ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> doc [ field_name ] = mongomock . utcnow ( ) ","if value == { "" $type "" : "" timestamp "" } : 
","if "" current_timestamp "" in value :
",33.3,6.44,False
"def fill_members ( self ) : <TAB> if self . _get_retrieve ( ) : <TAB> <TAB> after = self . after . id if self . after else None <TAB> <TAB> data = await self . get_members ( self . guild . id , self . retrieve , after ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # no data, terminate <TAB> <TAB> <TAB> return <TAB> <TAB> if len ( data ) < 1000 : <TAB> <TAB> <TAB> self . limit = 0<TAB> # terminate loop <TAB> <TAB> self . after = Object ( id = int ( data [ - 1 ] [ "" user "" ] [ "" id "" ] ) ) <TAB> <TAB> for element in reversed ( data ) : <TAB> <TAB> <TAB> await self . members . put ( self . create_member ( element ) ) ","if not data : 
","if not data :
",100.0,100.0,True
"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB> <TAB> extracted = extractor . extract ( <TAB> <TAB> <TAB> page , start_index , end_index , self . template . ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter ( extracted ) : <TAB> <TAB> <TAB> if item : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> item [ u "" _template "" ] = self . template . id <TAB> <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items ","if isinstance ( item , ( ItemProcessor , dict ) ) : 
","if u "" _template "" not in item :
",26.21,4.52,False
"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB> <TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB> <TAB> if node_type not in self . available_node_types : <TAB> <TAB> <TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB> <TAB> node_specific_config = self . available_node_types [ node_type ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fields = node_specific_config [ fields_key ] <TAB> return fields ","if fields_key in node_specific_config : 
","if fields_key in node_specific_config :
",100.0,100.0,True
"def _write_all ( self , writer ) : <TAB> """"""Writes messages and insert comments here and there."""""" <TAB> # Note: we make no assumptions about the length of original_messages and original_comments <TAB> for msg , comment in zip_longest ( <TAB> <TAB> self . original_messages , self . original_comments , fillvalue = None <TAB> ) : <TAB> <TAB> # msg and comment might be None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" writing comment:  "" , comment ) <TAB> <TAB> <TAB> writer . log_event ( comment )<TAB> # we already know that this method exists <TAB> <TAB> if msg is not None : <TAB> <TAB> <TAB> print ( "" writing message:  "" , msg ) <TAB> <TAB> <TAB> writer ( msg ) ","if comment is not None : 
","if comment is not None :
",100.0,100.0,True
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> elif case ( 1 , 2 ) : <TAB> <TAB> <TAB> print ( "" one or two "" ) <TAB> <TAB> elif case ( 3 , 4 ) : <TAB> <TAB> <TAB> print ( "" three or four "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" default "" ) <TAB> <TAB> <TAB> print ( "" another "" ) ","if case ( 0 ) : 
","if case ( 0 , 1 ) == 0 :
",46.33,25.97,False
"def date_to_format ( value , target_format ) : <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str : <TAB> <TAB> if isinstance ( value , datetime . date ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . time ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB> <TAB> ret = value <TAB> return ret ","elif isinstance ( value , datetime . datetime ) : 
","elif isinstance ( value , datetime . date ) :
",85.49,70.71,False
"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB> <TAB> if not which ( "" initdb "" ) : <TAB> <TAB> <TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB> <TAB> if not os . environ . get ( "" GALAXY_TEST_AMQP_INTERNAL_CONNECTION "" ) : <TAB> <TAB> <TAB> pytest . skip ( <TAB> <TAB> <TAB> <TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB> <TAB> <TAB> ) <TAB> return request . getfixturevalue ( request . param ) ","if not psycopg2 : 
","if not which ( "" psycopg2 "" ) :
",31.56,11.34,False
"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> <MASK> <TAB> <TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB> <TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB> <TAB> if not os . check_error ( n ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if timeout > = 0 : <TAB> <TAB> <TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB> <TAB> <TAB> if timeout < 0 : <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB> <TAB> vals = struct . unpack ( epoll_event , s ) <TAB> <TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res ","if timeout > = 0 : 
","if timeout > = 0 :
",100.0,100.0,True
"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> if name is None : <TAB> <TAB> <TAB> all_plugins + = [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name , plugin in self . plugins . items ( ) <TAB> <TAB> <TAB> <TAB> if name not in self . plugins_callback_order and plugin . is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> plugin = self . plugins [ name ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> all_plugins . append ( plugin ) <TAB> return all_plugins ","if plugin . is_activated : 
","if plugin . is_activated :
",100.0,100.0,True
"def get_expected_sql ( self ) : <TAB> sql_base_path = path . join ( path . dirname ( path . realpath ( __file__ ) ) , "" sql "" ) <TAB> # Iterate the version mapping directories. <TAB> for version_mapping in get_version_mapping_directories ( self . server [ "" type "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> complete_path = path . join ( sql_base_path , version_mapping [ "" name "" ] ) <TAB> <TAB> if not path . exists ( complete_path ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> data_sql = "" "" <TAB> with open ( path . join ( complete_path , "" test_sql_output.sql "" ) ) as fp : <TAB> <TAB> data_sql = fp . read ( ) <TAB> return data_sql ","if version_mapping [ "" number "" ] > self . server_information [ "" server_version "" ] : 
","if version_mapping [ "" type "" ] != "" version "" :
",43.87,24.57,False
"def _validate_headers ( self , headers ) : <TAB> if headers is None : <TAB> <TAB> return headers <TAB> res = { } <TAB> for key , value in headers . items ( ) : <TAB> <TAB> if isinstance ( value , ( int , float ) ) : <TAB> <TAB> <TAB> value = str ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ScriptError ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" message "" : "" headers must be a table "" <TAB> <TAB> <TAB> <TAB> <TAB> ""  with strings as keys and values. "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Header: ` {!r} : {!r} ` is not valid "" . format ( key , value ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> res [ key ] = value <TAB> return res ","if not isinstance ( key , ( bytes , str ) ) or not isinstance ( value , ( bytes , str ) ) : 
","if not isinstance ( key , str ) or key not in self . _table_keys :
",21.37,25.17,False
"def _get_literal_value ( self , pyval ) : <TAB> if pyval == self . vm . lookup_builtin ( "" builtins.True "" ) : <TAB> <TAB> return True <TAB> elif pyval == self . vm . lookup_builtin ( "" builtins.False "" ) : <TAB> <TAB> return False <TAB> elif isinstance ( pyval , str ) : <TAB> <TAB> prefix , value = parser_constants . STRING_RE . match ( pyval ) . groups ( ) [ : 2 ] <TAB> <TAB> value = value [ 1 : - 1 ]<TAB> # remove quotation marks <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = compat . bytestring ( value ) <TAB> <TAB> elif "" u "" in prefix and self . vm . PY2 : <TAB> <TAB> <TAB> value = compat . UnicodeType ( value ) <TAB> <TAB> return value <TAB> else : <TAB> <TAB> return pyval ","if "" b "" in prefix and not self . vm . PY2 : 
","if "" q "" in prefix and self . vm . PY1 :
",57.52,40.3,False
"def decode_query_ids ( self , trans , conditional ) : <TAB> if conditional . operator == "" and "" : <TAB> <TAB> self . decode_query_ids ( trans , conditional . left ) <TAB> <TAB> self . decode_query_ids ( trans , conditional . right ) <TAB> else : <TAB> <TAB> left_base = conditional . left . split ( "" . "" ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field = self . FIELDS [ left_base ] <TAB> <TAB> <TAB> if field . id_decode : <TAB> <TAB> <TAB> <TAB> conditional . right = trans . security . decode_id ( conditional . right ) ","if left_base in self . FIELDS : 
","if left_base in self . FIELDS :
",100.0,100.0,True
"def testLastPhrases ( self ) : <TAB> for day in ( 11 , 12 , 13 , 14 , 15 , 16 , 17 ) : <TAB> <TAB> start = datetime . datetime ( 2012 , 11 , day , 9 , 0 , 0 ) <TAB> <TAB> ( yr , mth , dy , _ , _ , _ , wd , yd , isdst ) = start . timetuple ( ) <TAB> <TAB> n = 4 - wd <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n - = 7 <TAB> <TAB> target = start + datetime . timedelta ( days = n ) <TAB> <TAB> self . assertExpectedResult ( <TAB> <TAB> <TAB> self . cal . parse ( "" last friday "" , start . timetuple ( ) ) , <TAB> <TAB> <TAB> ( target . timetuple ( ) , 1 ) , <TAB> <TAB> <TAB> dateOnly = True , <TAB> <TAB> ) ","if n > = 0 : 
","if n > 7 :
",36.53,34.98,False
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> if isinstance ( nbChars , int ) : <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> if nbChars [ 1 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit ) ","if nbChars [ 0 ] is not None : 
","if nbChars [ 0 ] is not None :
",100.0,100.0,True
"def getpystone ( ) : <TAB> # Start calculation <TAB> maxpystone = 0 <TAB> # Start with a short run, find the the pystone, and increase runtime until duration took > 0.1 second <TAB> for pyseed in [ 1000 , 2000 , 5000 , 10000 , 20000 , 50000 , 100000 , 200000 ] : <TAB> <TAB> duration , pystonefloat = pystones ( pyseed ) <TAB> <TAB> maxpystone = max ( maxpystone , int ( pystonefloat ) ) <TAB> <TAB> # Stop when pystone() has been running for at least 0.1 second <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return maxpystone ","if duration > 0.1 : 
","if duration < 0.1 :
",58.14,30.21,False
"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB> for part in parts : <TAB> <TAB> if part :<TAB> # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re . split ( <TAB> <TAB> <TAB> <TAB> "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> if block : <TAB> <TAB> <TAB> <TAB> <TAB> self . _queued_io_events . append ( ( block , stream_name ) ) ","if part : 
","if part :
",78.12,0.0,False
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = str ( val ) <TAB> <TAB> if len ( val ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver . needsQuoting ( val , True ) : <TAB> <TAB> <TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB> <TAB> <TAB> value = ' "" ' + value + ' "" ' <TAB> <TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res ","if not hasattr ( val , "" __len__ "" ) : 
","if not hasattr ( val , "" __len__ "" ) :
",100.0,100.0,True
"def SetVerbose ( self , level ) : <TAB> """"""Sets the verbose level."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> level = int ( level ) <TAB> <TAB> if ( level > = 0 ) and ( level < = 3 ) : <TAB> <TAB> <TAB> self . _verbose = level <TAB> <TAB> <TAB> return <TAB> except ValueError : <TAB> <TAB> pass <TAB> self . Error ( "" Verbose level ( %s ) must be between 0 and 3 inclusive. "" % level ) ","if type ( level ) != types . IntType : 
","if isinstance ( level , ( int , long ) ) :
",27.54,8.52,False
"def step ( self ) - > None : <TAB> """"""Performs a single optimization step."""""" <TAB> for group in self . param_groups : <TAB> <TAB> for p in group [ "" params "" ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> p . add_ ( p . grad , alpha = ( - group [ "" lr "" ] * self . num_data ) ) <TAB> return None ","if p . grad is None : 
","if p . grad is None :
",100.0,100.0,True
"def fill ( self , values ) : <TAB> if lupa . lua_type ( values ) != "" table "" : <TAB> <TAB> raise ScriptError ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" argument "" : "" values "" , <TAB> <TAB> <TAB> <TAB> "" message "" : "" element:fill values is not a table "" , <TAB> <TAB> <TAB> <TAB> "" splash_method "" : "" fill "" , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> # marking all tables as arrays by default <TAB> for key , value in values . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _mark_table_as_array ( self . lua , value ) <TAB> values = self . lua . lua2python ( values ) <TAB> return self . element . fill ( values ) ","if lupa . lua_type ( value ) == "" table "" : 
","if key == "" array "" :
",31.3,11.28,False
"def _gen_repr ( self , buf ) : <TAB> print >> buf , ""<TAB>  def __repr__(self):"" <TAB> if self . argnames : <TAB> <TAB> fmt = COMMA . join ( [ "" %s "" ] * self . nargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fmt = "" ( %s ) "" % fmt <TAB> <TAB> vals = [ "" repr(self. %s ) "" % name for name in self . argnames ] <TAB> <TAB> vals = COMMA . join ( vals ) <TAB> <TAB> if self . nargs == 1 : <TAB> <TAB> <TAB> vals = vals + "" , "" <TAB> <TAB> print >> buf , '<TAB> <TAB>  return "" %s ( %s ) "" %%  ( %s ) ' % ( self . name , fmt , vals ) <TAB> else : <TAB> <TAB> print >> buf , '<TAB> <TAB>  return "" %s () "" ' % self . name ","if "" ( "" in self . args : 
","if self . nargs == 2 :
",33.09,11.59,False
"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid<TAB> : "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x_str + = "" "" * len ( label ) <TAB> <TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB> <TAB> <TAB> if i == x [ 0 ] and j == x [ 1 ] : <TAB> <TAB> <TAB> <TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB> <TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str ","if j != - 1 : 
","if i != j :
",28.07,17.28,False
"def get_module_comment ( self , attrname : str ) - > Optional [ List [ str ] ] : <TAB> try : <TAB> <TAB> analyzer = ModuleAnalyzer . for_module ( self . modname ) <TAB> <TAB> analyzer . analyze ( ) <TAB> <TAB> key = ( "" "" , attrname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return list ( analyzer . attr_docs [ key ] ) <TAB> except PycodeError : <TAB> <TAB> pass <TAB> return None ","if key in analyzer . attr_docs : 
","if key in analyzer . attr_docs :
",100.0,100.0,True
"def tms_to_quadkey ( self , tms , google = False ) : <TAB> quadKey = "" "" <TAB> x , y , z = tms <TAB> # this algorithm works with google tiles, rather than tms, so convert <TAB> # to those first. <TAB> if not google : <TAB> <TAB> y = ( 2 * * z - 1 ) - y <TAB> for i in range ( z , 0 , - 1 ) : <TAB> <TAB> digit = 0 <TAB> <TAB> mask = 1 << ( i - 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> digit + = 1 <TAB> <TAB> if ( y & mask ) != 0 : <TAB> <TAB> <TAB> digit + = 2 <TAB> <TAB> quadKey + = str ( digit ) <TAB> return quadKey ","if ( x & mask ) != 0 : 
","if ( x & mask ) != 0 :
",100.0,100.0,True
"def test_enumerate ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB> <TAB> for i in range ( 100 ) : <TAB> <TAB> <TAB> await stream . channel . deliver ( message ( key = i , value = i * 4 ) ) <TAB> <TAB> async for i , value in stream . enumerate ( ) : <TAB> <TAB> <TAB> current_event = stream . current_event <TAB> <TAB> <TAB> assert i == current_event . key <TAB> <TAB> <TAB> assert value == i * 4 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty ( stream . channel ) ","if i > = 99 : 
","if current_event . key == message . EWOULDBLOCK :
",27.12,4.46,False
"def print_messages ( self ) : <TAB> output_reports = self . config . get_output_report ( ) <TAB> for report in output_reports : <TAB> <TAB> output_format , output_files = report <TAB> <TAB> self . summary [ "" formatter "" ] = output_format <TAB> <TAB> formatter = FORMATTERS [ output_format ] ( <TAB> <TAB> <TAB> self . summary , self . messages , self . config . profile <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . write_to ( formatter , sys . stdout ) <TAB> <TAB> for output_file in output_files : <TAB> <TAB> <TAB> with open ( output_file , "" w+ "" ) as target : <TAB> <TAB> <TAB> <TAB> self . write_to ( formatter , target ) ","if not output_files : 
","if sys . stdout :
",28.99,10.4,False
"def eval_metrics ( self ) : <TAB> for task in self . task_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ACC , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ROUGE_2_F , <TAB> <TAB> <TAB> <TAB> metrics . Metrics . ROUGE_L_F , <TAB> <TAB> <TAB> ] <TAB> return [ <TAB> <TAB> metrics . Metrics . ACC , <TAB> <TAB> metrics . Metrics . NEG_LOG_PERPLEXITY , <TAB> ] ","if "" summarize "" in task . name : 
","if task . metrics_enabled :
",33.05,11.74,False
"def _getBuildRequestForBrdict ( self , brdict ) : <TAB> # Turn a brdict into a BuildRequest into a brdict. This is useful <TAB> # for API like 'nextBuild', which operate on BuildRequest objects. <TAB> breq = self . breqCache . get ( brdict [ "" buildrequestid "" ] ) <TAB> if not breq : <TAB> <TAB> breq = yield BuildRequest . fromBrdict ( self . master , brdict ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . breqCache [ brdict [ "" buildrequestid "" ] ] = breq <TAB> defer . returnValue ( breq ) ","if breq : 
","if breq :
",78.12,0.0,False
"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB> <TAB> for s in states : <TAB> <TAB> <TAB> ns = state_func ( s ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> split . append ( ns ) <TAB> <TAB> <TAB> elif isinstance ( ns , ( list , tuple , set ) ) : <TAB> <TAB> <TAB> <TAB> split . extend ( ns ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB> <TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB> <TAB> keep = states <TAB> return keep , split ","if isinstance ( ns , SimState ) : 
","if isinstance ( ns , ( str , bytes ) ) :
",49.15,36.46,False
"def sequence_to_text ( sequence ) : <TAB> """"""Converts a sequence of IDs back to a string"""""" <TAB> result = "" "" <TAB> for symbol_id in sequence : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s = _id_to_symbol [ symbol_id ] <TAB> <TAB> <TAB> # Enclose ARPAbet back in curly braces: <TAB> <TAB> <TAB> if len ( s ) > 1 and s [ 0 ] == "" @ "" : <TAB> <TAB> <TAB> <TAB> s = "" { %s } "" % s [ 1 : ] <TAB> <TAB> <TAB> result + = s <TAB> return result . replace ( "" } { "" , "" "" ) ","if symbol_id in _id_to_symbol : 
","if symbol_id in _id_to_symbol :
",100.0,100.0,True
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> elif mod_type == imp . PY_COMPILED : <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code ","if mod_type == imp . PY_SOURCE : 
","if mod_type == imp . PY_COMPILED :
",82.41,82.65,False
"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB> <TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB> <TAB> return detected <TAB> for wafvendor in self . checklist : <TAB> <TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB> <TAB> if self . wafdetections [ wafvendor ] ( self ) : <TAB> <TAB> <TAB> detected . append ( wafvendor ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected ","if not findall : 
","if findall :
",34.18,0.0,False
"def SessionId ( self ) : <TAB> """"""Returns the Session ID of the process"""""" <TAB> if self . Session . is_valid ( ) : <TAB> <TAB> process_space = self . get_process_address_space ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return obj . Object ( <TAB> <TAB> <TAB> <TAB> "" _MM_SESSION_SPACE "" , offset = self . Session , vm = process_space <TAB> <TAB> <TAB> ) . SessionId <TAB> return obj . NoneObject ( "" Cannot find process session "" ) ","if process_space : 
","if process_space :
",78.12,100.0,True
"def _convert_java_pattern_to_python ( pattern ) : <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB> <TAB> c = s [ i ] <TAB> <TAB> if c == "" $ "" and s [ i + 1 ] in "" 0123456789 "" : <TAB> <TAB> <TAB> s [ i ] = "" \\ "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s [ i ] = "" "" <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s ) ","elif c == "" \\ "" and s [ i + 1 ] == "" $ "" : 
","elif c == "" \\ "" and s [ i + 1 ] in "" 0123456789 "" :
",87.53,73.8,False
"def __init__ ( self , coverage ) : <TAB> self . coverage = coverage <TAB> self . config = self . coverage . config <TAB> self . source_paths = set ( ) <TAB> if self . config . source : <TAB> <TAB> for src in self . config . source : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not self . config . relative_files : <TAB> <TAB> <TAB> <TAB> <TAB> src = files . canonical_filename ( src ) <TAB> <TAB> <TAB> <TAB> self . source_paths . add ( src ) <TAB> self . packages = { } <TAB> self . xml_out = None ","if os . path . exists ( src ) : 
","if isinstance ( src , str ) :
",28.49,12.86,False
"def populate_vol_format ( self ) : <TAB> rhel6_file_whitelist = [ "" raw "" , "" qcow2 "" , "" qed "" ] <TAB> model = self . widget ( "" vol-format "" ) . get_model ( ) <TAB> model . clear ( ) <TAB> formats = self . vol_class . formats <TAB> if hasattr ( self . vol_class , "" create_formats "" ) : <TAB> <TAB> formats = getattr ( self . vol_class , "" create_formats "" ) <TAB> if self . vol_class == Storage . FileVolume and not self . conn . rhel6_defaults_caps ( ) : <TAB> <TAB> newfmts = [ ] <TAB> <TAB> for f in rhel6_file_whitelist : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> newfmts . append ( f ) <TAB> <TAB> formats = newfmts <TAB> for f in formats : <TAB> <TAB> model . append ( [ f , f ] ) ","if f in formats : 
","if f not in formats :
",64.71,37.99,False
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> if file_sources_as_dict is not None : <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> if file_sources is None : <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources ","if os . path . exists ( "" file_sources.json "" ) : 
","if os . path . exists ( "" file_sources.json "" ) :
",100.0,100.0,True
"def _blend ( x , y ) :<TAB> # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB> <TAB> if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB> <TAB> if not isinstance ( y , ( list , tuple ) ) : <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result + = x [ len ( y ) : ] <TAB> <TAB> elif len ( x ) < len ( y ) : <TAB> <TAB> <TAB> result + = y [ len ( x ) : ] <TAB> <TAB> return result <TAB> return y ","if len ( x ) > len ( y ) : 
","if len ( x ) < len ( y ) :
",85.2,70.17,False
"def copy_dicts ( dct ) : <TAB> if "" _remote_data "" in dct : <TAB> <TAB> dsindex = dct [ "" _remote_data "" ] [ "" _content "" ] . dsindex <TAB> <TAB> newdct = dct . copy ( ) <TAB> <TAB> newdct [ "" _remote_data "" ] = { "" _content "" : dsindex } <TAB> <TAB> return list ( newdct . items ( ) ) <TAB> elif "" _data "" in dct : <TAB> <TAB> newdct = dct . copy ( ) <TAB> <TAB> newdata = copy_dicts ( dct [ "" _data "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newdct [ "" _data "" ] = newdata <TAB> <TAB> return list ( newdct . items ( ) ) <TAB> return None ","if newdata : 
","if newdata :
",78.12,0.0,False
"def _import_epic_activity ( self , project_data , taiga_epic , epic , options ) : <TAB> offset = 0 <TAB> while True : <TAB> <TAB> activities = self . _client . get ( <TAB> <TAB> <TAB> "" /projects/ {} /epics/ {} /activity "" . format ( <TAB> <TAB> <TAB> <TAB> project_data [ "" id "" ] , <TAB> <TAB> <TAB> <TAB> epic [ "" id "" ] , <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> { "" envelope "" : "" true "" , "" limit "" : 300 , "" offset "" : offset } , <TAB> <TAB> ) <TAB> <TAB> offset + = 300 <TAB> <TAB> for activity in activities [ "" data "" ] : <TAB> <TAB> <TAB> self . _import_activity ( taiga_epic , activity , options ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if len ( activities [ "" data "" ] ) < 300 : 
","if len ( activities [ "" data "" ] ) < 300 :
",100.0,100.0,True
"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rel_obj = self . get_obj ( instance ) <TAB> <TAB> <TAB> if rel_obj : <TAB> <TAB> <TAB> <TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB> <TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self ","if self . att_name not in instance . _obj_cache : 
","if self . att_name not in instance . _obj_cache :
",100.0,100.0,True
"def download_main ( <TAB> download , download_playlist , urls , playlist , output_dir , merge , info_only ) : <TAB> for url in urls : <TAB> <TAB> if url . startswith ( "" https:// "" ) : <TAB> <TAB> <TAB> url = url [ 8 : ] <TAB> <TAB> if not url . startswith ( "" http:// "" ) : <TAB> <TAB> <TAB> url = "" http:// "" + url <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> download_playlist ( <TAB> <TAB> <TAB> <TAB> url , output_dir = output_dir , merge = merge , info_only = info_only <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> download ( url , output_dir = output_dir , merge = merge , info_only = info_only ) ","if playlist : 
","if playlist :
",78.12,0.0,False
"def _mksubs ( self ) : <TAB> self . _subs = { } <TAB> commit_dir = CommitDir ( self , "" .commit "" ) <TAB> self . _subs [ "" .commit "" ] = commit_dir <TAB> tag_dir = TagDir ( self , "" .tag "" ) <TAB> self . _subs [ "" .tag "" ] = tag_dir <TAB> for ( name , sha ) in git . list_refs ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = name [ 11 : ] <TAB> <TAB> <TAB> date = git . rev_get_date ( sha . encode ( "" hex "" ) ) <TAB> <TAB> <TAB> n1 = BranchList ( self , name , sha ) <TAB> <TAB> <TAB> n1 . ctime = n1 . mtime = date <TAB> <TAB> <TAB> self . _subs [ name ] = n1 ","if name . startswith ( "" refs/heads/ "" ) : 
","if name . startswith ( "" git- "" ) :
",83.03,48.75,False
"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB> <TAB> rlen = size - len ( ret ) <TAB> <TAB> x = self . fd . read ( rlen ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not shortok : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret + = x <TAB> return ret ","if x == b "" "" : 
","if not x :
",27.45,7.73,False
"def remove_indent ( self ) : <TAB> """"""Remove one tab-width of blanks from the previous token."""""" <TAB> w = abs ( self . tab_width ) <TAB> if self . result : <TAB> <TAB> s = self . result [ - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . result . pop ( ) <TAB> <TAB> <TAB> s = s . replace ( "" \t "" , "" "" * w ) <TAB> <TAB> <TAB> if s . startswith ( "" \n "" ) : <TAB> <TAB> <TAB> <TAB> s2 = s [ 1 : ] <TAB> <TAB> <TAB> <TAB> self . result . append ( "" \n "" + s2 [ : - w ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . result . append ( s [ : - w ] ) ","if s . isspace ( ) : 
","if not s . startswith ( "" \t "" ) :
",34.33,10.6,False
"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB> <TAB> self . _last_updated = time . time ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if kwargs . get ( "" in_place "" , False ) : <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . _last_updated = time . time ( ) ","if "" _create_temporary "" in traceback . format_exc ( ) : 
","if kwargs . get ( "" in_place "" , False ) :
",34.71,8.53,False
"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB> <TAB> elif act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_COMP_CODES : <TAB> <TAB> <TAB> manual_intervention_nodes . add ( act [ "" id "" ] ) ","if act [ "" type "" ] == "" SubProcess "" : 
","if act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_RUN_CODES :
",49.64,14.96,False
"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB> <TAB> return <TAB> if authed ( ) : <TAB> <TAB> user = get_current_user_attrs ( ) <TAB> <TAB> team = get_current_team_attrs ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) <TAB> <TAB> if team and team . banned : <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , <TAB> <TAB> <TAB> <TAB> <TAB> error = "" Your team has been banned from this CTF "" , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) ","if user and user . banned : 
","if user and team :
",34.57,28.64,False
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> if isinstance ( self . _definition , dict ) : <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> if v == "" ANY "" : <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ","elif v in self . _definition : 
","elif v in self . _definition :
",100.0,100.0,True
"def save ( self , learner , file_name ) : <TAB> """"""Save the model to location specified in file_name."""""" <TAB> with open ( file_name , "" wb "" ) as f : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # don't store the large inference cache! <TAB> <TAB> <TAB> learner . inference_cache_ , tmp = ( None , learner . inference_cache_ ) <TAB> <TAB> <TAB> pickle . dump ( learner , f , - 1 ) <TAB> <TAB> <TAB> learner . inference_cache_ = tmp <TAB> <TAB> else : <TAB> <TAB> <TAB> pickle . dump ( learner , f , - 1 ) ","if hasattr ( learner , "" inference_cache_ "" ) : 
","if learner . inference_cache_ :
",26.51,21.28,False
"def __init__ ( self , exprs , savelist = False ) : <TAB> super ( ParseExpression , self ) . __init__ ( savelist ) <TAB> if isinstance ( exprs , _generatorType ) : <TAB> <TAB> exprs = list ( exprs ) <TAB> if isinstance ( exprs , basestring ) : <TAB> <TAB> self . exprs = [ ParserElement . _literalStringClass ( exprs ) ] <TAB> elif isinstance ( exprs , collections . Iterable ) : <TAB> <TAB> exprs = list ( exprs ) <TAB> <TAB> # if sequence of strings provided, wrap with Literal <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exprs = map ( ParserElement . _literalStringClass , exprs ) <TAB> <TAB> self . exprs = list ( exprs ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . exprs = list ( exprs ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> self . exprs = [ exprs ] <TAB> self . callPreparse = False ","if all ( isinstance ( expr , basestring ) for expr in exprs ) : 
","if isinstance ( exprs , ( list , tuple ) ) :
",27.36,9.14,False
"def find ( self , back = False ) : <TAB> flags = 0 <TAB> <MASK> <TAB> <TAB> flags = QTextDocument . FindBackward <TAB> if self . csBox . isChecked ( ) : <TAB> <TAB> flags = flags | QTextDocument . FindCaseSensitively <TAB> text = self . searchEdit . text ( ) <TAB> if not self . findMain ( text , flags ) : <TAB> <TAB> if text in self . editBoxes [ self . ind ] . toPlainText ( ) : <TAB> <TAB> <TAB> cursor = self . editBoxes [ self . ind ] . textCursor ( ) <TAB> <TAB> <TAB> if back : <TAB> <TAB> <TAB> <TAB> cursor . movePosition ( QTextCursor . End ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> cursor . movePosition ( QTextCursor . Start ) <TAB> <TAB> <TAB> self . editBoxes [ self . ind ] . setTextCursor ( cursor ) <TAB> <TAB> <TAB> self . findMain ( text , flags ) ","if back : 
","if self . csBox . isChecked ( ) :
",29.31,5.67,False
"def _load_storage ( self ) : <TAB> self . _storage = { } <TAB> for row in self ( "" SELECT object, resource, amount FROM storage "" ) : <TAB> <TAB> ownerid = int ( row [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _storage [ ownerid ] . append ( row [ 1 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _storage [ ownerid ] = [ row [ 1 : ] ] ","if ownerid in self . _storage : 
","if ownerid in self . _storage :
",100.0,100.0,True
"def parse_chunked ( self , unreader ) : <TAB> ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB> while size > 0 : <TAB> <TAB> while size > len ( rest ) : <TAB> <TAB> <TAB> size - = len ( rest ) <TAB> <TAB> <TAB> yield rest <TAB> <TAB> <TAB> rest = unreader . read ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise NoMoreData ( ) <TAB> <TAB> yield rest [ : size ] <TAB> <TAB> # Remove \r\n after chunk <TAB> <TAB> rest = rest [ size : ] <TAB> <TAB> while len ( rest ) < 2 : <TAB> <TAB> <TAB> rest + = unreader . read ( ) <TAB> <TAB> if rest [ : 2 ] != b "" \r \n "" : <TAB> <TAB> <TAB> raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB> <TAB> ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] ) ","if not rest : 
","if len ( rest ) < size :
",28.4,7.27,False
"def _augment_batch_ ( self , batch , random_state , parents , hooks ) : <TAB> for column in batch . columns : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for i , cbaoi in enumerate ( column . value ) : <TAB> <TAB> <TAB> <TAB> column . value [ i ] = cbaoi . clip_out_of_image_ ( ) <TAB> return batch ","if column . name in [ "" keypoints "" , "" bounding_boxes "" , "" polygons "" , "" line_strings "" ] : 
","if column . name == "" clip_out_of_image_ "" :
",43.78,9.74,False
"def to_nim ( self ) : <TAB> if self . is_pointer == 2 : <TAB> <TAB> s = "" cstringArray "" if self . type == "" GLchar "" else "" ptr pointer "" <TAB> else : <TAB> <TAB> s = self . type <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> default = "" ptr  "" + s <TAB> <TAB> <TAB> s = self . NIM_POINTER_MAP . get ( s , default ) <TAB> return s ","if self . is_pointer == 1 : 
","if s not in self . NIM_POINTER_MAP :
",35.2,8.52,False
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> if self . match_function ( path ) : <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> if self . match_function ( file ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file ) ","if os . path . isfile ( file ) or os . path . islink ( file ) : 
","if os . path . isfile ( file ) or os . path . islink ( file ) :
",100.0,100.0,True
"def remove ( self , event ) : <TAB> try : <TAB> <TAB> self . _events_current_sweep . remove ( event ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert event . in_sweep == True <TAB> <TAB> <TAB> assert event . other . in_sweep == True <TAB> <TAB> <TAB> event . in_sweep = False <TAB> <TAB> <TAB> event . other . in_sweep = False <TAB> <TAB> return True <TAB> except KeyError : <TAB> <TAB> if USE_DEBUG : <TAB> <TAB> <TAB> assert event . in_sweep == False <TAB> <TAB> <TAB> assert event . other . in_sweep == False <TAB> <TAB> return False ","if USE_DEBUG : 
","if USE_DEBUG :
",78.12,100.0,True
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass ","if attrname == "" salt_version "" : 
","if attrname == "" version "" :
",74.63,53.85,False
"def _init_auxiliary_head ( self , auxiliary_head ) : <TAB> """"""Initialize ``auxiliary_head``"""""" <TAB> if auxiliary_head is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . auxiliary_head = nn . ModuleList ( ) <TAB> <TAB> <TAB> for head_cfg in auxiliary_head : <TAB> <TAB> <TAB> <TAB> self . auxiliary_head . append ( builder . build_head ( head_cfg ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . auxiliary_head = builder . build_head ( auxiliary_head ) ","if isinstance ( auxiliary_head , list ) : 
","if isinstance ( auxiliary_head , list ) :
",100.0,100.0,True
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> if param . name : <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out ","if param . type : 
","if param . type :
",100.0,100.0,True
"def _set_handler ( <TAB> self , name , handle = None , obj = None , constructor_args = ( ) , constructor_kwds = { } ) : <TAB> if handle is None : <TAB> <TAB> handle = obj is not None <TAB> if handle : <TAB> <TAB> handler_class = self . handler_classes [ name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newhandler = handler_class ( obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newhandler = handler_class ( * constructor_args , * * constructor_kwds ) <TAB> else : <TAB> <TAB> newhandler = None <TAB> self . _replace_handler ( name , newhandler ) ","if obj is not None : 
","if obj is not None :
",100.0,100.0,True
"def _extract_subtitles ( src ) : <TAB> subtitles = { } <TAB> for caption in try_get ( src , lambda x : x [ "" captions "" ] , list ) or [ ] : <TAB> <TAB> subtitle_url = url_or_none ( caption . get ( "" uri "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lang = caption . get ( "" language "" , "" deu "" ) <TAB> <TAB> <TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" url "" : subtitle_url , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return subtitles ","if subtitle_url : 
","if subtitle_url :
",78.12,100.0,True
"def get_keys ( struct , ignore_first_level = False ) : <TAB> res = [ ] <TAB> if isinstance ( struct , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> keys = [ x . split ( "" ( "" ) [ 0 ] for x in struct . keys ( ) ] <TAB> <TAB> <TAB> res . extend ( keys ) <TAB> <TAB> for key in struct : <TAB> <TAB> <TAB> if key in IGNORED_KEYS : <TAB> <TAB> <TAB> <TAB> logging . debug ( "" Ignored:  %s :  %s "" , key , struct [ key ] ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> res . extend ( get_keys ( struct [ key ] , key in IGNORED_FIRST_LEVEL ) ) <TAB> elif isinstance ( struct , list ) : <TAB> <TAB> for item in struct : <TAB> <TAB> <TAB> res . extend ( get_keys ( item ) ) <TAB> return res ","if not ignore_first_level : 
","if ignore_first_level :
",34.18,72.9,False
"def create_dir ( path ) : <TAB> curr_path = None <TAB> for p in path : <TAB> <TAB> if curr_path is None : <TAB> <TAB> <TAB> curr_path = os . path . abspath ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> curr_path = os . path . join ( curr_path , p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . mkdir ( curr_path ) ","if not os . path . exists ( curr_path ) : 
","if not os . path . exists ( curr_path ) :
",100.0,100.0,True
"def dataToDumpFile ( dumpFile , data ) : <TAB> try : <TAB> <TAB> dumpFile . write ( data ) <TAB> <TAB> dumpFile . flush ( ) <TAB> except IOError as ex : <TAB> <TAB> if "" No space left "" in getUnicode ( ex ) : <TAB> <TAB> <TAB> errMsg = "" no space left on output device "" <TAB> <TAB> <TAB> logger . error ( errMsg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errMsg = "" permission denied when flushing dump data "" <TAB> <TAB> <TAB> logger . error ( errMsg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> errMsg = ( <TAB> <TAB> <TAB> <TAB> "" error occurred when writing dump data to file ( ' %s ' ) "" % getUnicode ( ex ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> logger . error ( errMsg ) ","elif "" Permission denied "" in getUnicode ( ex ) : 
","elif "" PermissionDenied "" in getUnicode ( ex ) :
",82.14,63.98,False
"def elements ( self , top ) : <TAB> res = [ ] <TAB> # try: <TAB> #<TAB>  string = ""== %s (%s)"" % (self.name,self.__class__)<TAB> # except AttributeError: <TAB> #<TAB>  string = ""== (%s)"" % (self.__class__,)<TAB> # print(string) <TAB> for part in self . parts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res . append ( name_or_ref ( part , top ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if isinstance ( part , Extension ) : <TAB> <TAB> <TAB> <TAB> res . append ( part . base ) <TAB> <TAB> <TAB> res . extend ( part . elements ( top ) ) <TAB> return res ","if isinstance ( part , Element ) : 
","if isinstance ( part , Name ) :
",79.9,59.46,False
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> if default . lower ( ) == "" true "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> if type ( default ) == float : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default ) ","elif default . lower ( ) == "" false "" : 
","elif default . lower ( ) == "" false "" :
",100.0,100.0,True
"def dvmethod ( c , dx , doAST = False ) : <TAB> for m in c . get_methods ( ) : <TAB> <TAB> mx = dx . get_method ( m ) <TAB> <TAB> ms = DvMethod ( mx ) <TAB> <TAB> ms . process ( doAST = doAST ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert ms . get_ast ( ) is not None <TAB> <TAB> <TAB> assert isinstance ( ms . get_ast ( ) , dict ) <TAB> <TAB> <TAB> assert "" body "" in ms . get_ast ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert ms . get_source ( ) is not None ","if doAST : 
","if doAST :
",78.12,0.0,False
"def _repr_pretty_ ( self , p , cycle ) : <TAB> if cycle : <TAB> <TAB> return "" {{ ...} "" <TAB> with p . group ( 2 , "" { "" , "" } "" ) : <TAB> <TAB> p . breakable ( "" "" ) <TAB> <TAB> for idx , key in enumerate ( self . _items ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> p . text ( "" , "" ) <TAB> <TAB> <TAB> <TAB> p . breakable ( ) <TAB> <TAB> <TAB> value = self . _items [ key ] <TAB> <TAB> <TAB> p . pretty ( key ) <TAB> <TAB> <TAB> p . text ( "" :  "" ) <TAB> <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> <TAB> value = trimmed_repr ( value ) <TAB> <TAB> <TAB> p . pretty ( value ) <TAB> <TAB> p . breakable ( "" "" ) ","if idx : 
","if idx :
",78.12,0.0,False
"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB> <TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB> <TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB> <TAB> if "" ~#rating "" in song : <TAB> <TAB> <TAB> del song [ "" ~#rating "" ] <TAB> <TAB> <TAB> reset . append ( song ) <TAB> librarian . changed ( reset ) ","if dialog . run ( ) != Gtk . ResponseType . YES : 
","if not dialog . run ( ) :
",53.26,26.56,False
"def get_or_create_place ( self , place_name ) : <TAB> "" Return the requested place object tuple-packed with a new indicator. "" <TAB> LOG . debug ( "" get_or_create_place: looking for:  %s "" , place_name ) <TAB> for place_handle in self . db . iter_place_handles ( ) : <TAB> <TAB> place = self . db . get_place_from_handle ( place_handle ) <TAB> <TAB> place_title = place_displayer . display ( self . db , place ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( 0 , place ) <TAB> place = Place ( ) <TAB> place . set_title ( place_name ) <TAB> place . name = PlaceName ( value = place_name ) <TAB> self . db . add_place ( place , self . trans ) <TAB> return ( 1 , place ) ","if place_title == place_name : 
","if place_title :
",31.77,26.01,False
def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if constraint_data . variables is None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> if constraint_data . body . polynomial_degree ( ) == 0 : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ,"if isinstance ( constraint_data , LinearCanonicalRepn ) : 
","if isinstance ( constraint_data . body , Linear ) :
",43.92,48.33,False
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> if item < 0 : <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> if is_tuple : <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None ","if i < len ( data ) and i > - 1 : 
","if abs ( i ) < item :
",32.44,4.63,False
"def test_case_insensitivity ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB> <TAB> env . set ( "" PYTHONCASEOK "" , "" 1 "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB> <TAB> loader = self . find_module ( ) <TAB> <TAB> self . assertTrue ( hasattr ( loader , "" load_module "" ) ) ","if b "" PYTHONCASEOK "" not in _bootstrap . _os . environ : 
","if not hasattr ( _os , "" environ "" ) :
",29.41,7.46,False
def field_spec ( self ) : <TAB> <MASK> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . field_spec_ is None : <TAB> <TAB> <TAB> <TAB> self . field_spec_ = FieldSpec ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . field_spec_ ,"if self . field_spec_ is None : 
","if self . field_spec_ is None :
",100.0,100.0,True
"def reduce ( self , f , init ) : <TAB> for x in range ( self . _idx , rt . count ( self . _w_array ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return rt . deref ( init ) <TAB> <TAB> init = f . invoke ( [ init , rt . nth ( self . _w_array , rt . wrap ( x ) ) ] ) <TAB> return init ","if rt . reduced_QMARK_ ( init ) : 
","if rt . reduced_QMARK_ ( init ) :
",100.0,100.0,True
"def _find ( event : E ) - > None : <TAB> # We first check values after the selected value, then all values. <TAB> values = list ( self . values ) <TAB> for value in values [ self . _selected_index + 1 : ] + values : <TAB> <TAB> text = fragment_list_to_text ( to_formatted_text ( value [ 1 ] ) ) . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _selected_index = self . values . index ( value ) <TAB> <TAB> <TAB> return ","if text . startswith ( event . data . lower ( ) ) : 
","if text in self . values :
",32.32,5.75,False
"def check_permissions ( ) : <TAB> if platform_os ( ) != "" Windows "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( localization . lang_check_permissions [ "" permissions_granted "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( localization . lang_check_permissions [ "" permissions_denied "" ] ) <TAB> <TAB> <TAB> exit ( ) <TAB> else : <TAB> <TAB> print ( localization . lang_check_permissions [ "" windows_warning "" ] ) <TAB> <TAB> exit ( ) ","if getuid ( ) == 0 : 
","if localization . lang_check_permissions [ "" permissions_granted "" ] :
",26.78,2.91,False
"def _ProcessName ( self , name , dependencies ) : <TAB> """"""Retrieve a module name from a node name."""""" <TAB> module_name , dot , base_name = name . rpartition ( "" . "" ) <TAB> if dot : <TAB> <TAB> if module_name : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] . add ( base_name ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dependencies [ module_name ] = { base_name } <TAB> <TAB> else : <TAB> <TAB> <TAB> # If we have a relative import that did not get qualified (usually due <TAB> <TAB> <TAB> # to an empty package_name), don't insert module_name='' into the <TAB> <TAB> <TAB> # dependencies; we get a better error message if we filter it out here <TAB> <TAB> <TAB> # and fail later on. <TAB> <TAB> <TAB> logging . warning ( "" Empty package name:  %s "" , name ) ","if module_name in dependencies : 
","if base_name in dependencies :
",64.55,64.35,False
"def _load_db ( self ) : <TAB> try : <TAB> <TAB> with open ( self . db ) as db : <TAB> <TAB> <TAB> content = db . read ( 8 ) <TAB> <TAB> <TAB> db . seek ( 0 ) <TAB> <TAB> <TAB> if content == ( "" Salted__ "" ) : <TAB> <TAB> <TAB> <TAB> data = StringIO ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . encryptor . decrypt ( db , data ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json . loads ( data . getvalue ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return json . load ( db ) <TAB> except : <TAB> <TAB> return { "" creds "" : [ ] } ","if self . encryptor : 
","if self . encryptor :
",100.0,100.0,True
"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB> <TAB> context_for_subcon = context <TAB> <TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB> <TAB> <TAB> context_for_subcon = context . __copy__ ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context_for_subcon ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> except ConstructError as ex : <TAB> <TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj ","if self . predicate ( subobj , context ) : 
","if not subobj :
",26.38,4.69,False
"def is_active_for_user ( self , user ) : <TAB> is_active = super ( AbstractUserFlag , self ) . is_active_for_user ( user ) <TAB> if is_active : <TAB> <TAB> return is_active <TAB> user_ids = self . _get_user_ids ( ) <TAB> if hasattr ( user , "" pk "" ) and user . pk in user_ids : <TAB> <TAB> return True <TAB> if hasattr ( user , "" groups "" ) : <TAB> <TAB> group_ids = self . _get_group_ids ( ) <TAB> <TAB> if group_ids : <TAB> <TAB> <TAB> user_groups = set ( user . groups . all ( ) . values_list ( "" pk "" , flat = True ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return None ","if group_ids . intersection ( user_groups ) : 
","if user_groups and user_groups . issubset ( group_ids ) :
",43.56,18.84,False
"def lookup_member ( self , member_name ) : <TAB> document_choices = self . choices or [ ] <TAB> for document_choice in document_choices : <TAB> <TAB> doc_and_subclasses = [ document_choice ] + document_choice . __subclasses__ ( ) <TAB> <TAB> for doc_type in doc_and_subclasses : <TAB> <TAB> <TAB> field = doc_type . _fields . get ( member_name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return field ","if field : 
","if field :
",78.12,0.0,False
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> if not father_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not mother_handle : 
","if not mother_handle :
",100.0,100.0,True
"def init_weights ( self ) : <TAB> for m in self . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Linear ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 ) <TAB> <TAB> if isinstance ( m , nn . Conv3d ) : <TAB> <TAB> <TAB> xavier_init ( m , distribution = "" uniform "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> constant_init ( m , 1 ) ","if isinstance ( m , nn . BatchNorm3d ) : 
","if isinstance ( m , nn . BatchNorm3d ) :
",100.0,100.0,True
"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn <TAB> <TAB> elif step_num < 30000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 10 <TAB> <TAB> elif step_num < 35000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 100 <TAB> <TAB> else : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB> <TAB> fd [ model . lrn_rate ] = lrn_rate ","if step_num < hparams . lrn_step : 
","if step_num < 10000 :
",34.45,36.34,False
"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB> <TAB> if is_push_data_token ( token ) : <TAB> <TAB> <TAB> yield DataToken ( read_data ( token , source ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Token ( token ) <TAB> <TAB> token = source . read_uint8 ( ) ","elif is_small_integer ( token ) : 
","elif is_small_integer_token ( token ) :
",77.13,63.4,False
"def user_info ( oicsrv , userdb , sub , client_id = "" "" , user_info_claims = None ) : <TAB> identity = userdb [ sub ] <TAB> if user_info_claims : <TAB> <TAB> result = { } <TAB> <TAB> for key , restr in user_info_claims [ "" claims "" ] . items ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> result [ key ] = identity [ key ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise Exception ( "" Missing property  ' %s ' "" % key ) <TAB> else : <TAB> <TAB> result = identity <TAB> return OpenIDSchema ( * * result ) ","if restr == { "" essential "" : True } : 
","if restr [ "" type "" ] == "" error "" :
",32.12,11.12,False
"def _helpSlot ( self , * args ) : <TAB> help_text = "" Filters are applied to packets in both direction. \n \n "" <TAB> filter_nb = 0 <TAB> for filter in self . _filters : <TAB> <TAB> help_text + = "" {} :  {} "" . format ( filter [ "" name "" ] , filter [ "" description "" ] ) <TAB> <TAB> filter_nb + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> help_text + = "" \n \n "" <TAB> QtWidgets . QMessageBox . information ( self , "" Help for filters "" , help_text ) ","if len ( self . _filters ) != filter_nb : 
","if filter_nb == self . _nb_filters :
",32.09,21.51,False
"def find_user_theme ( self , name : str ) - > Theme : <TAB> """"""Find a theme named as *name* from latex_theme_path."""""" <TAB> for theme_path in self . theme_paths : <TAB> <TAB> config_path = path . join ( theme_path , name , "" theme.conf "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return UserTheme ( name , config_path ) <TAB> <TAB> <TAB> except ThemeError as exc : <TAB> <TAB> <TAB> <TAB> logger . warning ( exc ) <TAB> return None ","if path . isfile ( config_path ) : 
","if path . exists ( config_path ) :
",75.15,65.8,False
"def decompress ( self , value ) : <TAB> if value : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value . country_code and value . national_number : <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> "" + %d "" % value . country_code , <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number ( value ) , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ] ","if type ( value ) == PhoneNumber : 
","if self . _is_national ( value ) :
",37.71,15.85,False
"def update_prevdoc_status ( self , flag ) : <TAB> for quotation in list ( set ( [ d . prevdoc_docname for d in self . get ( "" items "" ) ] ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> doc = frappe . get_doc ( "" Quotation "" , quotation ) <TAB> <TAB> <TAB> if doc . docstatus == 2 : <TAB> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Quotation  {0}  is cancelled "" ) . format ( quotation ) ) <TAB> <TAB> <TAB> doc . set_status ( update = True ) <TAB> <TAB> <TAB> doc . update_opportunity ( ) ","if quotation : 
","if flag :
",56.98,0.0,False
"def map ( item ) : <TAB> if item . deleted : <TAB> <TAB> return <TAB> exploration = exp_fetchers . get_exploration_from_model ( item ) <TAB> for state_name , state in exploration . states . items ( ) : <TAB> <TAB> hints_length = len ( state . interaction . hints ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exp_and_state_key = "" %s %s "" % ( item . id , state_name . encode ( "" utf-8 "" ) ) <TAB> <TAB> <TAB> yield ( python_utils . UNICODE ( hints_length ) , exp_and_state_key ) ","if hints_length > 0 : 
","if hints_length > 0 :
",100.0,100.0,True
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> if self . _args . host and self . _args . host == machine . name : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . locations and machine . location in self . locations : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines ","if self . tags and self . _tags_match ( machine . tags , self . tags ) : 
","if self . _args . port and self . _args . port == machine . port :
",33.34,19.75,False
"def _ripple_trim_compositors_move ( self , delta ) : <TAB> comp_ids = self . multi_data . moved_compositors_destroy_ids <TAB> tracks_compositors = _get_tracks_compositors_list ( ) <TAB> track_moved = self . multi_data . track_affected <TAB> for i in range ( 1 , len ( current_sequence ( ) . tracks ) - 1 ) : <TAB> <TAB> if not track_moved [ i - 1 ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> track_comps = tracks_compositors [ i - 1 ] <TAB> <TAB> for comp in track_comps : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> comp . move ( delta ) ","if comp . destroy_id in comp_ids : 
","if comp . id in comp_ids :
",63.89,59.87,False
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> elif "" error "" in line : <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError ","elif "" status "" in line : 
","elif "" status "" in line :
",100.0,100.0,True
"def create_keyfile ( self , keyfile , size = 64 , force = False ) : <TAB> if force or not os . path . exists ( keyfile ) : <TAB> <TAB> keypath = os . path . dirname ( keyfile ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( keypath ) <TAB> <TAB> subprocess . run ( <TAB> <TAB> <TAB> [ "" dd "" , "" if=/dev/random "" , f "" of= { keyfile } "" , f "" bs= { size } "" , "" count=1 "" ] , <TAB> <TAB> <TAB> check = True , <TAB> <TAB> <TAB> stdout = subprocess . DEVNULL , <TAB> <TAB> <TAB> stderr = subprocess . DEVNULL , <TAB> <TAB> ) ","if not os . path . exists ( keypath ) : 
","if not os . path . exists ( keypath ) :
",100.0,100.0,True
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res ","elif self . op == "" * "" : 
","elif self . op == "" * "" :
",100.0,100.0,True
"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB> <TAB> if - delta < expr . get_float_value ( ) < delta : <TAB> <TAB> <TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB> <TAB> real , imag = expr . real , expr . imag <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> real = Integer ( 0 ) <TAB> <TAB> if - delta < imag . get_float_value ( ) < delta : <TAB> <TAB> <TAB> imag = Integer ( 0 ) <TAB> <TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB> <TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr ","if - delta < real . get_float_value ( ) < delta : 
","if - delta < real . get_float_value ( ) < delta :
",100.0,100.0,True
"def get_file_sources ( ) : <TAB> global _file_sources <TAB> if _file_sources is None : <TAB> <TAB> from galaxy . files import ConfiguredFileSources <TAB> <TAB> file_sources = None <TAB> <TAB> if os . path . exists ( "" file_sources.json "" ) : <TAB> <TAB> <TAB> file_sources_as_dict = None <TAB> <TAB> <TAB> with open ( "" file_sources.json "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> file_sources_as_dict = json . load ( f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> file_sources = ConfiguredFileSources . from_dict ( file_sources_as_dict ) <TAB> <TAB> if file_sources is None : <TAB> <TAB> <TAB> ConfiguredFileSources . from_dict ( [ ] ) <TAB> <TAB> _file_sources = file_sources <TAB> return _file_sources ","if file_sources_as_dict is not None : 
","if file_sources_as_dict is not None :
",100.0,100.0,True
"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if tag . user : <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> if tag . internal : <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts ","if tag . has_sort : 
","if isinstance ( tag , SortMapTag ) :
",27.8,7.27,False
"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB> <TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name , ( description , default ) in self . options . items ( ) : <TAB> <TAB> if not name in self . option_values : <TAB> <TAB> <TAB> self . option_values [ name ] = default ","if not key in self . options : 
","if key not in self . options :
",64.07,58.14,False
"def modify_bottle_params ( self , output_stride = None ) : <TAB> if output_stride is not None and output_stride % 2 != 0 : <TAB> <TAB> raise Exception ( "" output stride must to be even number "" ) <TAB> if output_stride is None : <TAB> <TAB> return <TAB> else : <TAB> <TAB> stride = 2 <TAB> <TAB> for i , _cfg in enumerate ( self . cfg ) : <TAB> <TAB> <TAB> stride = stride * _cfg [ - 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB> <TAB> self . cfg [ i ] [ - 1 ] = s ","if stride > output_stride : 
","if stride > output_stride :
",100.0,100.0,True
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret ","elif is_iterable ( value ) : 
","elif isinstance ( value , list ) :
",30.49,16.52,False
"def make_shares ( self , plaintext ) : <TAB> share_arrays = [ ] <TAB> for i , p in enumerate ( plaintext ) : <TAB> <TAB> share_array = self . make_byte_shares ( p ) <TAB> <TAB> for sa in share_array : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> share_arrays . append ( array . array ( "" H "" ) ) <TAB> <TAB> <TAB> current_share_array = sa <TAB> <TAB> <TAB> current_share_array . append ( sa ) <TAB> return share_arrays ","if i == 0 : 
","if i == len ( p ) - 1 :
",35.14,24.81,False
"def populate ( self , item ) : <TAB> # log.message('populate: %s', item) <TAB> path = self . getItemPath ( item ) <TAB> # log.message('populate: path=%s', path) <TAB> value = self . getValue ( path ) <TAB> for name in sorted ( value . __dict__ . keys ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> child = getattr ( value , name , None ) <TAB> <TAB> if hasattr ( child , "" __dict__ "" ) : <TAB> <TAB> <TAB> item . addChild ( name , True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> item . addChild ( name , False ) ","if name [ : 2 ] == "" __ "" and name [ - 2 : ] == "" __ "" : 
","if name == "" __dict__ "" :
",30.36,17.98,False
"def __repr__ ( self ) : <TAB> try : <TAB> <TAB> if self . _semlock . _is_mine ( ) : <TAB> <TAB> <TAB> name = current_process ( ) . name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> name + = "" | "" + threading . current_thread ( ) . name <TAB> <TAB> elif self . _semlock . _get_value ( ) == 1 : <TAB> <TAB> <TAB> name = "" None "" <TAB> <TAB> elif self . _semlock . _count ( ) > 0 : <TAB> <TAB> <TAB> name = "" SomeOtherThread "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = "" SomeOtherProcess "" <TAB> except Exception : <TAB> <TAB> name = "" unknown "" <TAB> return "" <Lock(owner= %s )> "" % name ","if threading . current_thread ( ) . name != "" MainThread "" : 
","if threading . current_thread ( ) . name != threading . current_thread ( ) . name :
",66.73,52.03,False
"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB> <TAB> elif scroll_if_editing : <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) ","if not self . editing : 
","if self . _my_widgets [ 0 ] . is_visible ( ) :
",34.79,5.44,False
"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB> <TAB> if dep . repo is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep . repo . repos : <TAB> <TAB> <TAB> if repo . from_config : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) ) ","if not isinstance ( dep . repo , WarehouseBaseRepo ) : 
","if not isinstance ( dep . repo , WarehouseBaseRepo ) :
",100.0,100.0,True
"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef ( "" "" , { } , None ) <TAB> for name in dir ( src_flag ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> dest_val = getattr ( dest_flag , name , None ) <TAB> <TAB> baseline_val = getattr ( baseline_flag , name , None ) <TAB> <TAB> if dest_val == baseline_val : <TAB> <TAB> <TAB> setattr ( dest_flag , name , getattr ( src_flag , name ) ) ","if name [ : 1 ] == "" _ "" : 
","if name . startswith ( "" _ "" ) :
",35.5,16.83,False
"def out ( parent , attr , indent = 0 ) : <TAB> val = getattr ( parent , attr ) <TAB> prefix = "" %s %s : "" % ( "" "" * indent , attr . replace ( "" _ "" , "" - "" ) ) <TAB> if val is None : <TAB> <TAB> cli . out ( prefix ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = [ flag_util . encode_flag_val ( c . value ) for c in val ] <TAB> <TAB> cli . out ( "" %s %s "" % ( prefix , flag_util . encode_flag_val ( val ) ) ) ","if attr == "" choices "" : 
","if isinstance ( val , list ) :
",26.98,6.57,False
"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB> <TAB> x = cand . creator <TAB> <TAB> if x is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB> <TAB> fan_out [ x ] + = 1 ","if x not in fan_out : 
","if x < 0 :
",29.82,12.98,False
"def task_tree_lines ( task = None ) : <TAB> if task is None : <TAB> <TAB> task = current_root_task ( ) <TAB> rendered_children = [ ] <TAB> nurseries = list ( task . child_nurseries ) <TAB> while nurseries : <TAB> <TAB> nursery = nurseries . pop ( ) <TAB> <TAB> nursery_children = _rendered_nursery_children ( nursery ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nested = _render_subtree ( "" (nested nursery) "" , rendered_children ) <TAB> <TAB> <TAB> nursery_children . append ( nested ) <TAB> <TAB> rendered_children = nursery_children <TAB> return _render_subtree ( task . name , rendered_children ) ","if rendered_children : 
","if nursery_children :
",56.98,42.73,False
"def lock_workspace ( build_dir ) : <TAB> _BUILDING_LOCK_FILE = "" .blade.building.lock "" <TAB> lock_file_fd , ret_code = lock_file ( os . path . join ( build_dir , _BUILDING_LOCK_FILE ) ) <TAB> if lock_file_fd == - 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> console . fatal ( "" There is already an active building in current workspace. "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> console . fatal ( "" Lock exception, please try it later. "" ) <TAB> return lock_file_fd ","if ret_code == errno . EAGAIN : 
","if ret_code == 0 :
",34.45,55.07,False
"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB> <TAB> self . assertIn ( "" bbox "" , feature ) <TAB> <TAB> fid = feature [ "" id "" ] <TAB> <TAB> if fid == 1 : <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( ) ","elif fid == 2 : 
","elif fid == 2 :
",100.0,100.0,True
"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R , V = rays , virtual_rays <TAB> if V is not None : <TAB> <TAB> if normalize : <TAB> <TAB> <TAB> V = normalize_rays ( V , lattice ) <TAB> <TAB> if check : <TAB> <TAB> <TAB> R = PointCollection ( V , lattice ) <TAB> <TAB> <TAB> V = PointCollection ( V , lattice ) <TAB> <TAB> <TAB> d = lattice . dimension ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" virtual rays must be linearly  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" independent and with other rays span the ambient space. "" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan ( cones , R , lattice , is_complete , V ) ","if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d : 
","if d > 1 :
",25.3,0.14,False
"def search_host ( self , search_string ) : <TAB> results = [ ] <TAB> for host_entry in self . config_data : <TAB> <TAB> if host_entry . get ( "" type "" ) != "" entry "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if host_entry . get ( "" host "" ) == "" * "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> searchable_information = host_entry . get ( "" host "" ) <TAB> <TAB> for key , value in six . iteritems ( host_entry . get ( "" options "" ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = "" "" . join ( value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> value = str ( value ) <TAB> <TAB> <TAB> searchable_information + = "" "" + value <TAB> <TAB> if search_string in searchable_information : <TAB> <TAB> <TAB> results . append ( host_entry ) <TAB> return results ","if isinstance ( value , list ) : 
","if isinstance ( value , list ) :
",100.0,100.0,True
"def test_async_iterator ( app ) : <TAB> async with new_stream ( app ) as stream : <TAB> <TAB> for i in range ( 100 ) : <TAB> <TAB> <TAB> await stream . channel . deliver ( message ( key = i , value = i ) ) <TAB> <TAB> received = 0 <TAB> <TAB> async for value in stream : <TAB> <TAB> <TAB> assert value == received <TAB> <TAB> <TAB> received + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> assert await channel_empty ( stream . channel ) ","if received > = 100 : 
","if received > = 10 :
",77.13,53.73,False
"def has_google_credentials ( ) : <TAB> global _HAS_GOOGLE_CREDENTIALS <TAB> if _HAS_GOOGLE_CREDENTIALS is None : <TAB> <TAB> provider = Provider ( "" google "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = False <TAB> <TAB> else : <TAB> <TAB> <TAB> _HAS_GOOGLE_CREDENTIALS = True <TAB> return _HAS_GOOGLE_CREDENTIALS ","if provider . get_access_key ( ) is None or provider . get_secret_key ( ) is None : 
","if provider . has_credentials ( ) :
",41.63,4.1,False
"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB> <TAB> a = self . _d . getTime ( ) <TAB> <TAB> b = other . _d . getTime ( ) <TAB> <TAB> if a < b : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 0 <TAB> else : <TAB> <TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1 ","elif a == b : 
","elif a == b :
",100.0,100.0,True
"def validate_weight ( self , weight ) : <TAB> try : <TAB> <TAB> add_acl_to_obj ( self . context [ "" user_acl "" ] , self . category ) <TAB> except AttributeError : <TAB> <TAB> return weight<TAB> # don't validate weight further if category failed <TAB> if weight > self . category . acl . get ( "" can_pin_threads "" , 0 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> "" You don ' t have permission to pin threads globally  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" in this category. "" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> _ ( "" You don ' t have permission to pin threads in this category. "" ) <TAB> <TAB> <TAB> ) <TAB> return weight ","if weight == 2 : 
","if self . category . acl . get ( "" can_pin_threads "" , True ) :
",27.18,2.28,False
"def effective ( line ) : <TAB> for b in line : <TAB> <TAB> if not b . cond : <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> val = 5 <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if b . ignore : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> b . ignore - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return ( b , True ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> return ( b , False ) <TAB> return ","if val : 
","if val < = 0 :
",34.04,17.97,False
"def wheelEvent ( self , event ) : <TAB> """"""Handle a wheel event."""""" <TAB> if QtCore . Qt . ControlModifier & event . modifiers ( ) : <TAB> <TAB> d = { "" c "" : self . leo_c } <TAB> <TAB> if isQt5 : <TAB> <TAB> <TAB> point = event . angleDelta ( ) <TAB> <TAB> <TAB> delta = point . y ( ) or point . x ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> delta = event . delta ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> zoom_out ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> zoom_in ( d ) <TAB> <TAB> event . accept ( ) <TAB> <TAB> return <TAB> QtWidgets . QTextBrowser . wheelEvent ( self , event ) ","if delta < 0 : 
","if delta > 0.5 :
",31.5,23.64,False
"def test_evname_in_mp_events_testcases ( ) : <TAB> ok = True <TAB> for evname in ins . mp_events : <TAB> <TAB> if evname == "" version "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> for i , args in enumerate ( ins . mp_events [ evname ] [ "" test_cases "" ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> msg = "" Error, for evname  %s  the testase # %d  does not match evname "" <TAB> <TAB> <TAB> <TAB> print ( msg % ( evname , i ) ) <TAB> <TAB> <TAB> <TAB> ok = False <TAB> if ok : <TAB> <TAB> print ( "" test_evname_in_mp_events_testcases: passed "" ) ","if evname != args [ 0 ] : 
","if args != [ "" test_case "" , "" test_testcase_1 "" ] :
",28.07,6.23,False
"def check_database ( ) : <TAB> if len ( EmailAddress . objects . all ( ) ) > 0 : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" Are you sure you want to wipe the existing development database and reseed it? (Y/N) "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> destroy_database ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return True ","if raw_input ( ) . lower ( ) == "" y "" : 
","if settings . DEBUG :
",25.95,1.56,False
"def _get_requested_databases ( self ) : <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB> <TAB> for requested_namespace in self . _requested_namespaces : <TAB> <TAB> <TAB> if requested_namespace [ 0 ] is "" * "" : <TAB> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases ","elif requested_namespace [ 0 ] not in IGNORE_DBS : 
","if requested_namespace [ 1 ] not in [ "" * "" , "" * "" ] :
",40.78,18.95,False
"def decorated ( self , * args , * * kwargs ) : <TAB> start_time = time . perf_counter ( ) <TAB> stderr = "" "" <TAB> saved_exception = None <TAB> try : <TAB> <TAB> yield from fn ( self , * args , * * kwargs ) <TAB> except GitSavvyError as e : <TAB> <TAB> stderr = e . stderr <TAB> <TAB> saved_exception = e <TAB> finally : <TAB> <TAB> end_time = time . perf_counter ( ) <TAB> <TAB> util . debug . log_git ( args , None , "" <SNIP> "" , stderr , end_time - start_time ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise saved_exception from None ","if saved_exception : 
","if saved_exception :
",78.12,100.0,True
"def is_suppressed_warning ( <TAB> type : str , subtype : str , suppress_warnings : List [ str ] ) - > bool : <TAB> """"""Check the warning is suppressed or not."""""" <TAB> if type is None : <TAB> <TAB> return False <TAB> for warning_type in suppress_warnings : <TAB> <TAB> if "" . "" in warning_type : <TAB> <TAB> <TAB> target , subtarget = warning_type . split ( "" . "" , 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target , subtarget = warning_type , None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> subtype is None <TAB> <TAB> <TAB> <TAB> or subtarget is None <TAB> <TAB> <TAB> <TAB> or subtarget == subtype <TAB> <TAB> <TAB> <TAB> or subtarget == "" * "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if target == type : 
","if target == type :
",100.0,100.0,True
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> if j == - 1 : <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return r ","if reply == "" !done "" : 
","if len ( r ) == self . max_reply_len :
",26.89,6.61,False
"def encrypt ( self , plaintext ) : <TAB> encrypted = [ ] <TAB> for p in _string_to_bytes ( plaintext ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _remaining_block = self . _aes . encrypt ( self . _last_precipherblock ) <TAB> <TAB> <TAB> self . _last_precipherblock = [ ] <TAB> <TAB> precipherbyte = self . _remaining_block . pop ( 0 ) <TAB> <TAB> self . _last_precipherblock . append ( precipherbyte ) <TAB> <TAB> cipherbyte = p ^ precipherbyte <TAB> <TAB> encrypted . append ( cipherbyte ) <TAB> return _bytes_to_string ( encrypted ) ","if len ( self . _remaining_block ) == 0 : 
","if self . _last_precipherblock :
",31.86,11.55,False
"def find_symbol ( self , r , globally = False ) : <TAB> query = self . view . substr ( self . view . word ( r ) ) <TAB> fname = self . view . file_name ( ) . replace ( "" \\ "" , "" / "" ) <TAB> locations = self . view . window ( ) . lookup_symbol_in_index ( query ) <TAB> if not locations : <TAB> <TAB> return <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> location = [ hit [ 2 ] for hit in locations if fname . endswith ( hit [ 1 ] ) ] [ 0 ] <TAB> <TAB> <TAB> return location [ 0 ] - 1 , location [ 1 ] - 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> # TODO: There might be many symbols with the same name. <TAB> <TAB> <TAB> return locations [ 0 ] <TAB> except IndexError : <TAB> <TAB> return ","if not globally : 
","if globally :
",34.18,0.0,False
"def __getslice__ ( self , i , j ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # handle the case where the right bound is unspecified <TAB> <TAB> <TAB> j = len ( self ) <TAB> <TAB> if i < 0 or j < 0 : <TAB> <TAB> <TAB> raise dns . exception . FormError <TAB> <TAB> # If it's not an empty slice, access left and right bounds <TAB> <TAB> # to make sure they're valid <TAB> <TAB> if i != j : <TAB> <TAB> <TAB> super ( WireData , self ) . __getitem__ ( i ) <TAB> <TAB> <TAB> super ( WireData , self ) . __getitem__ ( j - 1 ) <TAB> <TAB> return WireData ( super ( WireData , self ) . __getslice__ ( i , j ) ) <TAB> except IndexError : <TAB> <TAB> raise dns . exception . FormError ","if j == sys . maxint : 
","if i == 0 :
",27.38,13.83,False
"def main ( ) : <TAB> r = redis . StrictRedis ( ) <TAB> curr_memory = prev_memory = r . info ( ) [ "" used_memory "" ] <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Delta Memory :  %d , Total Memory :  %d "" <TAB> <TAB> <TAB> <TAB> % ( ( curr_memory - prev_memory ) , curr_memory ) <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> prev_memory = curr_memory <TAB> <TAB> curr_memory = r . info ( ) [ "" used_memory "" ] ","if prev_memory != curr_memory : 
","if curr_memory > prev_memory :
",53.85,33.58,False
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> if self . _flags [ fname ] == 1 : <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if output == input : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func ) ","if fname not in self . _flags : 
","if fname not in self . _flags :
",100.0,100.0,True
"def urls ( self , version = None ) : <TAB> """"""Returns all URLS that are mapped to this interface"""""" <TAB> urls = [ ] <TAB> for _base_url , routes in self . api . http . routes . items ( ) : <TAB> <TAB> for url , methods in routes . items ( ) : <TAB> <TAB> <TAB> for _method , versions in methods . items ( ) : <TAB> <TAB> <TAB> <TAB> for interface_version , interface in versions . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not url in urls : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> urls . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ( "" /v {0} "" . format ( version ) if version else "" "" ) + url <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return urls ","if interface_version == version and interface == self : 
","if interface_version == version :
",50.74,46.54,False
"def _handle_data ( self , text ) : <TAB> if self . _translate : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _data . append ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _translate = False <TAB> <TAB> <TAB> self . _data = [ ] <TAB> <TAB> <TAB> self . _comments = [ ] ","if not text . startswith ( "" gtk- "" ) : 
","if text :
",25.93,0.0,False
"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB> <TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB> <TAB> if not self . dry_run : <TAB> <TAB> <TAB> os . chmod ( dirpath , mode ) ","if os . path . islink ( dirpath ) : 
","if not self . allow_directories and not self . allow_directories ( dirpath ) :
",46.22,15.46,False
"def language ( self ) : <TAB> if self . lang_data : <TAB> <TAB> lang_data = [ s if s != "" None "" else None for s in self . lang_data ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return Language ( lang_data [ 0 ] , country = lang_data [ 1 ] , script = lang_data [ 2 ] ) ","if lang_data [ 0 ] : 
","if lang_data :
",30.04,38.81,False
"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB> <TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol : <TAB> <TAB> for col in range ( 0 , nCol , 2 ) : <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if col + 2 == nCol : <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row + = 1 <TAB> self . layout . addItem ( sample , row , col ) <TAB> self . layout . addItem ( label , row , col + 1 ) ","if not self . layout . itemAt ( row , col ) : 
","if self . _getItemAtPosition ( sample , col ) :
",44.42,25.0,False
"def align_comments ( tlist ) : <TAB> tidx , token = tlist . token_next_by ( i = sql . Comment ) <TAB> while token : <TAB> <TAB> pidx , prev_ = tlist . token_prev ( tidx ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tlist . group_tokens ( sql . TokenList , pidx , tidx , extend = True ) <TAB> <TAB> <TAB> tidx = pidx <TAB> <TAB> tidx , token = tlist . token_next_by ( i = sql . Comment , idx = tidx ) ","if isinstance ( prev_ , sql . TokenList ) : 
","if prev_ and prev_ . i == sql . Comment :
",32.75,8.89,False
"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB> <TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB> <TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB> <TAB> if params [ "" Attributes "" ] != 0 : <TAB> <TAB> <TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB> <TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params [ "" Data "" ] != 0 : <TAB> <TAB> <TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND ","if read_len < len ( var ) : 
","if read_len < 0 :
",32.89,41.92,False
"def _PromptMySQL ( self , config ) : <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True : <TAB> <TAB> self . _PromptMySQLOnce ( config ) <TAB> <TAB> if self . _CheckMySQLConnection ( ) : <TAB> <TAB> <TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ConfigInitError ( ) ","if not retry : 
","if retry :
",34.18,0.0,False
"def split_long_line_with_indent ( line , max_per_line , indent ) : <TAB> """"""Split the `line` so that it doesn't go over `max_per_line` and adds `indent` to new lines."""""" <TAB> words = line . split ( "" "" ) <TAB> lines = [ ] <TAB> current_line = words [ 0 ] <TAB> for word in words [ 1 : ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines . append ( current_line ) <TAB> <TAB> <TAB> current_line = "" "" * indent + word <TAB> <TAB> else : <TAB> <TAB> <TAB> current_line = f "" { current_line } { word } "" <TAB> lines . append ( current_line ) <TAB> return "" \n "" . join ( lines ) ","if len ( f "" { current_line } { word } "" ) > max_per_line : 
","if len ( word ) > max_per_line :
",35.75,32.64,False
"def gen_cli ( docs_dir ) : <TAB> with open ( os . path . join ( docs_dir , "" CLI_template.md "" ) , "" r "" ) as cli_temp_file : <TAB> <TAB> temp_lines = cli_temp_file . readlines ( ) <TAB> lines = [ ] <TAB> for line in temp_lines : <TAB> <TAB> matched = re . match ( r "" { onnx-tf.*} "" , line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> command = matched . string . strip ( ) [ 1 : - 1 ] <TAB> <TAB> <TAB> output = subprocess . check_output ( command . split ( "" "" ) ) . decode ( "" UTF-8 "" ) <TAB> <TAB> <TAB> lines . append ( output ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lines . append ( line ) <TAB> with open ( os . path . join ( docs_dir , "" CLI.md "" ) , "" w "" ) as cli_file : <TAB> <TAB> cli_file . writelines ( lines ) ","if matched : 
","if matched :
",78.12,0.0,False
"def read ( self , size = None ) : <TAB> if size == 0 : <TAB> <TAB> return "" "" <TAB> data = list ( ) <TAB> while size is None or size > 0 : <TAB> <TAB> line = self . readline ( size or - 1 ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size - = len ( line ) <TAB> <TAB> data . append ( line ) <TAB> return "" "" . join ( data ) ","if size is not None : 
","if size is not None and len ( line ) > size :
",64.95,30.27,False
"def _get_format_and_pattern ( file_path ) : <TAB> file_path = Path ( file_path ) <TAB> with file_path . open ( ) as f : <TAB> <TAB> first_line = f . readline ( ) . strip ( ) <TAB> <TAB> match = re . match ( r "" format *: *(.+) "" , first_line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" gztar "" , first_line , 1 <TAB> <TAB> return match . group ( 1 ) , f . readline ( ) . strip ( ) , 2 ","if match is None : 
","if match is None :
",100.0,100.0,True
"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if os . path . isfile ( file ) : <TAB> <TAB> <TAB> <TAB> os . unlink ( file ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( file ) <TAB> <TAB> except Exception as error : <TAB> <TAB> <TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB> <TAB> <TAB> sys . exit ( 1 ) ","elif os . path . isdir ( file ) : 
","elif os . path . isdir ( file ) :
",100.0,100.0,True
"def _test_forever ( self , tests ) : <TAB> while True : <TAB> <TAB> for test_name in tests : <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB> if self . bad : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return ","if self . ns . fail_env_changed and self . environment_changed : 
","if not self . _test_forever ( ) :
",35.76,5.72,False
"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB> <TAB> if line . startswith ( "" #include "" ) or line . startswith ( "" %i nclude "" ) : <TAB> <TAB> <TAB> line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ] ","if not ( "" < "" in line or line in dep ) : 
","if line :
",25.56,0.0,False
"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB> <TAB> with db_transaction ( ) : <TAB> <TAB> <TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> key . name = name <TAB> <TAB> <TAB> if metadata is not None : <TAB> <TAB> <TAB> <TAB> key . metadata . update ( metadata ) <TAB> <TAB> <TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB> <TAB> raise ServiceKeyDoesNotExist ","if name is not None : 
","if name is not None :
",100.0,100.0,True
"def range ( self , dimension , data_range = True , dimension_range = True ) : <TAB> if self . nodes and dimension in self . nodes . dimensions ( ) : <TAB> <TAB> node_range = self . nodes . range ( dimension , data_range , dimension_range ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path_range = self . _edgepaths . range ( dimension , data_range , dimension_range ) <TAB> <TAB> <TAB> return max_range ( [ node_range , path_range ] ) <TAB> <TAB> return node_range <TAB> return super ( Graph , self ) . range ( dimension , data_range , dimension_range ) ","if self . _edgepaths : 
","if self . _edgepaths and dimension in self . _edgepaths . dimensions ( ) :
",55.36,22.41,False
"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB> <TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB> <TAB> if verbose == True : <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> return <TAB> while True : <TAB> <TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB> <TAB> if sock in r : <TAB> <TAB> <TAB> data = sock . recv ( 1024 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan . send ( data ) <TAB> <TAB> if chan in r : <TAB> <TAB> <TAB> data = chan . recv ( 1024 ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( ) ","if len ( data ) == 0 : 
","if len ( data ) == 0 :
",100.0,100.0,True
"def output_layer ( self , features , * * kwargs ) : <TAB> """"""Project features to the vocabulary size."""""" <TAB> if self . adaptive_softmax is None : <TAB> <TAB> # project back to size of vocabulary <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return F . linear ( features , self . embed_tokens . weight ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return F . linear ( features , self . embed_out ) <TAB> else : <TAB> <TAB> return features ","if self . share_input_output_embed : 
","if self . embed_tokens :
",64.48,16.42,False
"def generate ( self , dest , vars ) : <TAB> util . ensure_dir ( dest ) <TAB> for relpath , src , template in self . _file_templates : <TAB> <TAB> file_dest = os . path . join ( dest , relpath ) <TAB> <TAB> util . ensure_dir ( os . path . dirname ( file_dest ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutil . copyfile ( src , file_dest ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _render_template ( template , vars , file_dest ) ","if template is None : 
","if template == "" .py "" :
",29.79,10.55,False
"def _py_matching_callback ( self , context , result , sender , device ) : <TAB> d = HIDDevice . get_device ( c_void_p ( device ) ) <TAB> if d not in self . devices : <TAB> <TAB> self . devices . add ( d ) <TAB> <TAB> for x in self . matching_observers : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> x . device_discovered ( d ) ","if hasattr ( x , "" device_discovered "" ) : 
","if x . device_discovered ( d ) :
",28.04,18.09,False
"def urlquote ( * args , * * kwargs ) : <TAB> new_kwargs = dict ( kwargs ) <TAB> if not PY3 : <TAB> <TAB> new_kwargs = dict ( kwargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del new_kwargs [ "" encoding "" ] <TAB> <TAB> if "" errors "" in kwargs : <TAB> <TAB> <TAB> del new_kwargs [ "" errors "" ] <TAB> return quote ( * args , * * new_kwargs ) ","if "" encoding "" in new_kwargs : 
","if "" encoding "" in kwargs :
",82.52,53.14,False
"def Set ( self , attr , value ) : <TAB> hook = getattr ( self , "" _set_ %s "" % attr , None ) <TAB> if hook : <TAB> <TAB> # If there is a set hook we must use the context manager. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Can only update attribute  %s  using the context manager. "" % attr <TAB> <TAB> <TAB> ) <TAB> <TAB> if attr not in self . _pending_hooks : <TAB> <TAB> <TAB> self . _pending_hooks . append ( attr ) <TAB> <TAB> self . _pending_parameters [ attr ] = value <TAB> else : <TAB> <TAB> super ( Configuration , self ) . Set ( attr , value ) ","if self . _lock > 0 : 
","if not getattr ( hook , "" context_manager "" , None ) :
",26.62,3.46,False
"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB> <TAB> name = f . get_basename ( ) <TAB> <TAB> if name . endswith ( "" .mod "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = name [ 0 : - 11 ] <TAB> <TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 ) ","if name . endswith ( "" .sccprofile "" ) : 
","if name . endswith ( "" .py "" ) :
",83.03,70.17,False
"def get_eval_task ( self , worker_id ) : <TAB> """"""Return next evaluation (task_id, Task) tuple"""""" <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - 1 , None <TAB> <TAB> self . _task_id + = 1 <TAB> <TAB> task = self . _eval_todo . pop ( ) <TAB> <TAB> self . _doing [ self . _task_id ] = ( worker_id , task , time . time ( ) ) <TAB> <TAB> return self . _task_id , task ","if not self . _eval_todo : 
","if not self . _eval_todo :
",100.0,100.0,True
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not cmd . stdout . strip ( ) : <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( ) ","if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : 
","if cmd . run ( ) :
",29.26,2.78,False
"def disjoined ( data ) : <TAB> # create marginalized distributions and multiple them together <TAB> data_disjoined = None <TAB> dim = len ( data . shape ) <TAB> for d in range ( dim ) : <TAB> <TAB> axes = list ( range ( dim ) ) <TAB> <TAB> axes . remove ( d ) <TAB> <TAB> data1d = multisum ( data , axes ) <TAB> <TAB> shape = [ 1 for k in range ( dim ) ] <TAB> <TAB> shape [ d ] = len ( data1d ) <TAB> <TAB> data1d = data1d . reshape ( tuple ( shape ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data_disjoined = data1d <TAB> <TAB> else : <TAB> <TAB> <TAB> data_disjoined = data_disjoined * data1d <TAB> return data_disjoined ","if d == 0 : 
","if data_disjoined is None :
",28.41,7.81,False
"def safe_repr ( val ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # We special case dicts to have a sorted repr. This makes testing <TAB> <TAB> <TAB> # significantly easier <TAB> <TAB> <TAB> val = _obj_with_safe_repr ( val ) <TAB> <TAB> ret = repr ( val ) <TAB> <TAB> if six . PY2 : <TAB> <TAB> <TAB> ret = ret . decode ( "" utf-8 "" ) <TAB> except UnicodeEncodeError : <TAB> <TAB> ret = red ( "" a  %r  that cannot be represented "" % type ( val ) ) <TAB> else : <TAB> <TAB> ret = green ( ret ) <TAB> return ret ","if isinstance ( val , dict ) : 
","if isinstance ( val , dict ) :
",100.0,100.0,True
"def wrapper ( * args , * * kwargs ) : <TAB> resp = view_func ( * args , * * kwargs ) <TAB> if isinstance ( resp , dict ) : <TAB> <TAB> ctx_params = request . environ . get ( "" webrec.template_params "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resp . update ( ctx_params ) <TAB> <TAB> template = self . jinja_env . jinja_env . get_or_select_template ( template_name ) <TAB> <TAB> return template . render ( * * resp ) <TAB> else : <TAB> <TAB> return resp ","if ctx_params : 
","if ctx_params :
",78.12,100.0,True
"def post ( self , request , * args , * * kwargs ) : <TAB> contact_id = kwargs . get ( "" pk "" ) <TAB> self . object = get_object_or_404 ( Contact , id = contact_id ) <TAB> if ( <TAB> <TAB> self . request . user . role != "" ADMIN "" <TAB> <TAB> and not self . request . user . is_superuser <TAB> <TAB> and self . request . user != self . object . created_by <TAB> ) or self . object . company != self . request . company : <TAB> <TAB> raise PermissionDenied <TAB> else : <TAB> <TAB> if self . object . address_id : <TAB> <TAB> <TAB> self . object . address . delete ( ) <TAB> <TAB> self . object . delete ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return JsonResponse ( { "" error "" : False } ) <TAB> <TAB> return redirect ( "" contacts:list "" ) ","if self . request . is_ajax ( ) : 
","if not self . object . contact_list :
",36.65,9.99,False
"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text ","if "" < "" in text : 
","if "" < "" in text :
",100.0,100.0,True
"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True ","if not everythingIsUnicode ( v ) : 
","if not all ( [ isinstance ( v , dict ) and not everythingIsUnicode ( v ) ) :
",64.21,22.81,False
"def fill ( self ) : <TAB> try : <TAB> <TAB> while ( <TAB> <TAB> <TAB> not self . stopping . wait ( self . sample_wait ) <TAB> <TAB> <TAB> and len ( self . queue ) < self . queue . maxlen <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . queue . append ( self . parent . _read ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . parent . _fire_events ( ) <TAB> <TAB> self . full . set ( ) <TAB> <TAB> while not self . stopping . wait ( self . sample_wait ) : <TAB> <TAB> <TAB> self . queue . append ( self . parent . _read ( ) ) <TAB> <TAB> <TAB> if isinstance ( self . parent , EventsMixin ) : <TAB> <TAB> <TAB> <TAB> self . parent . _fire_events ( ) <TAB> except ReferenceError : <TAB> <TAB> # Parent is dead; time to die! <TAB> <TAB> pass ","if self . partial and isinstance ( self . parent , EventsMixin ) : 
","if isinstance ( self . parent , EventsMixin ) :
",69.28,60.57,False
"def _SetListviewTextItems ( self , items ) : <TAB> self . listview . DeleteAllItems ( ) <TAB> index = - 1 <TAB> for item in items : <TAB> <TAB> index = self . listview . InsertItem ( index + 1 , item [ 0 ] ) <TAB> <TAB> data = item [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = "" "" <TAB> <TAB> self . listview . SetItemText ( index , 1 , data ) ","if data is None : 
","if data == "" "" :
",30.25,14.54,False
"def process_request ( self , request ) : <TAB> for old , new in self . names_name : <TAB> <TAB> request . uri = request . uri . replace ( old , new ) <TAB> <TAB> if is_text_payload ( request ) and request . body : <TAB> <TAB> <TAB> body = six . ensure_str ( request . body ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> request . body = body . replace ( old , new ) <TAB> return request ","if old in body : 
","if body :
",31.47,0.0,False
"def serialize ( cls , value , * args , * * kwargs ) : <TAB> if value is None : <TAB> <TAB> return "" "" <TAB> value_as_string = six . text_type ( value ) <TAB> if SHOULD_NOT_USE_LOCALE : <TAB> <TAB> return value_as_string <TAB> else : <TAB> <TAB> grouping = kwargs . get ( "" grouping "" , None ) <TAB> <TAB> has_decimal_places = value_as_string . find ( "" . "" ) != - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> string_format = "" %d "" <TAB> <TAB> else : <TAB> <TAB> <TAB> decimal_places = len ( value_as_string . split ( "" . "" ) [ 1 ] ) <TAB> <TAB> <TAB> string_format = "" % . {} f "" . format ( decimal_places ) <TAB> <TAB> return locale . format ( string_format , value , grouping = grouping ) ","if not has_decimal_places : 
","if has_decimal_places :
",34.18,72.9,False
"def review_link ( request , path_obj ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if check_permission ( "" translate "" , request ) : <TAB> <TAB> <TAB> <TAB> text = _ ( "" Review Suggestions "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> text = _ ( "" View Suggestions "" ) <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> "" href "" : dispatch . translate ( <TAB> <TAB> <TAB> <TAB> <TAB> request , path_obj . pootle_path , matchnames = [ "" hassuggestion "" ] <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> "" text "" : text , <TAB> <TAB> <TAB> } <TAB> except IOError : <TAB> <TAB> pass ","if path_obj . has_suggestions ( ) : 
","if path_obj . pootle_path :
",39.45,38.88,False
"def _migrate_key ( self , key ) : <TAB> """"""migrate key from old .dat file"""""" <TAB> key_path = os . path . join ( self . home_path , "" keys.dat "" ) <TAB> if os . path . exists ( key_path ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> key_data = json . loads ( open ( key_path , "" rb "" ) . read ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . add_key ( key , key_data . get ( key ) ) <TAB> <TAB> except : <TAB> <TAB> <TAB> self . error ( f "" Corrupt key file. Manual migration of  ' { key } '  required. "" ) ","if key_data . get ( key ) : 
","if key in key_data :
",27.1,20.96,False
"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB> <TAB> backref = callback . backref <TAB> <TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB> <TAB> if root_objs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> root_objs = [ root_objs ] <TAB> <TAB> <TAB> with session . no_autoflush : <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs : <TAB> <TAB> <TAB> <TAB> <TAB> if root_obj : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self . get_callback_args ( root_obj , callback ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args ","if not isinstance ( root_objs , Iterable ) : 
","if not isinstance ( root_objs , list ) :
",83.27,74.19,False
"def GetDefFile ( self , gyp_to_build_path ) : <TAB> """"""Returns the .def file from sources, if any.  Otherwise returns None."""""" <TAB> spec = self . spec <TAB> if spec [ "" type "" ] in ( "" shared_library "" , "" loadable_module "" , "" executable "" ) : <TAB> <TAB> def_files = [ s for s in spec . get ( "" sources "" , [ ] ) if s . endswith ( "" .def "" ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return gyp_to_build_path ( def_files [ 0 ] ) <TAB> <TAB> elif len ( def_files ) > 1 : <TAB> <TAB> <TAB> raise Exception ( "" Multiple .def files "" ) <TAB> return None ","if len ( def_files ) == 1 : 
","if len ( def_files ) == 1 :
",100.0,100.0,True
"def _validate_gallery ( images ) : <TAB> for image in images : <TAB> <TAB> image_path = image . get ( "" image_path "" , "" "" ) <TAB> <TAB> if image_path : <TAB> <TAB> <TAB> if not isfile ( image_path ) : <TAB> <TAB> <TAB> <TAB> raise TypeError ( f "" { image_path !r}  is not a valid image path. "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise TypeError ( "" ' image_path '  is required. "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( "" Caption must be 180 characters or less. "" ) ","if not len ( image . get ( "" caption "" , "" "" ) ) < = 180 : 
","if not is_angle ( image_path ) or ( len ( image_path ) < 180 ) :
",27.06,10.58,False
"def VType ( self ) : <TAB> if "" DW_AT_type "" in self . attributes : <TAB> <TAB> target = self . types [ self . type_id ] <TAB> <TAB> target_type = target . VType ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> target_type = [ target_type , None ] <TAB> <TAB> return [ "" Pointer "" , dict ( target = target_type [ 0 ] , target_args = target_type [ 1 ] ) ] <TAB> return [ "" Pointer "" , dict ( target = "" Void "" ) ] ","if not isinstance ( target_type , list ) : 
","if not isinstance ( target_type , list ) :
",100.0,100.0,True
"def addInPlace ( self , value1 , value2 ) : <TAB> for group in value2 : <TAB> <TAB> for key in value2 [ group ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value1 [ group ] [ key ] = value2 [ group ] [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> value1 [ group ] [ key ] + = value2 [ group ] [ key ] <TAB> return value1 ","if key not in value1 [ group ] : 
","if key not in value1 [ group ] :
",100.0,100.0,True
"def _mongo_query_and ( self , queries ) : <TAB> if len ( queries ) == 1 : <TAB> <TAB> return queries [ 0 ] <TAB> query = { } <TAB> for q in queries : <TAB> <TAB> for k , v in q . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> query [ k ] = { } <TAB> <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> <TAB> # TODO check exists of k in query, may be it should be update <TAB> <TAB> <TAB> <TAB> query [ k ] = v <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> query [ k ] . update ( v ) <TAB> return query ","if k not in query : 
","if k not in query :
",100.0,100.0,True
"def _handled_eventtype ( self , eventtype , handler ) : <TAB> if eventtype not in known_events : <TAB> <TAB> log . error ( ' The event  "" %s ""  is not known ' , eventtype ) <TAB> <TAB> return False <TAB> if known_events [ eventtype ] . __module__ . startswith ( "" deluge.event "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> log . error ( <TAB> <TAB> <TAB> "" You cannot register custom notification providers  "" <TAB> <TAB> <TAB> "" for built-in event types. "" <TAB> <TAB> ) <TAB> <TAB> return False <TAB> return True ","if handler . __self__ is self : 
","if handler is known_events [ eventtype ] :
",29.01,9.55,False
"def get_ax_arg ( uri ) : <TAB> if not ax_ns : <TAB> <TAB> return u "" "" <TAB> prefix = "" openid. "" + ax_ns + "" .type. "" <TAB> ax_name = None <TAB> for name , values in self . request . arguments . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> part = name [ len ( prefix ) : ] <TAB> <TAB> <TAB> ax_name = "" openid. "" + ax_ns + "" .value. "" + part <TAB> <TAB> <TAB> break <TAB> if not ax_name : <TAB> <TAB> return u "" "" <TAB> return self . get_argument ( ax_name , u "" "" ) ","if values [ - 1 ] == uri and name . startswith ( prefix ) : 
","if uri . startswith ( prefix ) :
",48.15,23.74,False
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB> <TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . strip : <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace ( value ) <TAB> <TAB> <TAB> <TAB> url = self . process_attr ( value ) <TAB> <TAB> <TAB> <TAB> link = Link ( url = url ) <TAB> <TAB> <TAB> <TAB> self . links . append ( link ) <TAB> <TAB> <TAB> <TAB> self . current_link = link ","if self . scan_attr ( attr ) : 
","if attr == "" href "" :
",26.96,5.66,False
"def test_long_steadystate_queue_popright ( self ) : <TAB> for size in ( 0 , 1 , 2 , 100 , 1000 ) : <TAB> <TAB> d = deque ( reversed ( range ( size ) ) ) <TAB> <TAB> append , pop = d . appendleft , d . pop <TAB> <TAB> for i in range ( size , BIG ) : <TAB> <TAB> <TAB> append ( i ) <TAB> <TAB> <TAB> x = pop ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( x , i - size ) <TAB> <TAB> self . assertEqual ( list ( reversed ( list ( d ) ) ) , list ( range ( BIG - size , BIG ) ) ) ","if x != i - size : 
","if x != i - size :
",100.0,100.0,True
"def _update_read ( self ) : <TAB> """"""Update state when there is read event"""""" <TAB> try : <TAB> <TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . on_message ( msg ) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self . close ( ) <TAB> except socket . error as err : <TAB> <TAB> if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> self . on_error ( err ) <TAB> return False ","if msg : 
","if msg :
",78.12,0.0,False
"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> if not tag . text : <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self ","if len ( root ) > 0 : 
","if i == 0 :
",28.54,12.87,False
"def cmp ( self , other ) : <TAB> v_is_ptr = not isinstance ( self , CTypesGenericPrimitive ) <TAB> w_is_ptr = isinstance ( other , CTypesData ) and not isinstance ( <TAB> <TAB> other , CTypesGenericPrimitive <TAB> ) <TAB> if v_is_ptr and w_is_ptr : <TAB> <TAB> return cmpfunc ( self . _convert_to_address ( None ) , other . _convert_to_address ( None ) ) <TAB> elif v_is_ptr or w_is_ptr : <TAB> <TAB> return NotImplemented <TAB> else : <TAB> <TAB> if isinstance ( self , CTypesGenericPrimitive ) : <TAB> <TAB> <TAB> self = self . _value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> other = other . _value <TAB> <TAB> return cmpfunc ( self , other ) ","if isinstance ( other , CTypesGenericPrimitive ) : 
","if isinstance ( other , CTypesGenericPrimitive ) :
",100.0,100.0,True
"def get_external_addresses ( self , label = None ) - > List [ str ] : <TAB> result = [ ] <TAB> for c in self . _conf [ "" pools "" ] . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if label == c [ "" label "" ] : <TAB> <TAB> <TAB> <TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( c [ "" external_address "" ] [ 0 ] ) <TAB> return result ","if label is not None : 
","if label is not None and c [ "" external_address "" ] [ 0 ] != label :
",62.64,17.79,False
"def coerce_text ( v ) : <TAB> if not isinstance ( v , basestring_ ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attr = "" __unicode__ "" <TAB> <TAB> else : <TAB> <TAB> <TAB> attr = "" __str__ "" <TAB> <TAB> if hasattr ( v , attr ) : <TAB> <TAB> <TAB> return unicode ( v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return bytes ( v ) <TAB> return v ","if sys . version_info [ 0 ] < 3 : 
","if sys . version_info > ( 3 , 0 ) :
",44.52,42.12,False
"def check_localhost ( self ) : <TAB> """"""Warn if any socket_host is 'localhost'. See #711."""""" <TAB> for k , v in cherrypy . config . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" The use of  ' localhost '  as a socket host can  "" <TAB> <TAB> <TAB> <TAB> "" cause problems on newer systems, since  "" <TAB> <TAB> <TAB> <TAB> "" ' localhost '  can map to either an IPv4 or an  "" <TAB> <TAB> <TAB> <TAB> "" IPv6 address. You should use  ' 127.0.0.1 ' "" <TAB> <TAB> <TAB> <TAB> "" or  ' [::1] '  instead. "" <TAB> <TAB> <TAB> ) ","if k == "" server.socket_host "" and v == "" localhost "" : 
","if k == "" localhost "" :
",60.03,25.28,False
"def add_songs ( self , filenames , library ) : <TAB> changed = [ ] <TAB> for i in range ( len ( self ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> song = library [ self . _list [ i ] ] <TAB> <TAB> <TAB> self . _list [ i ] = song <TAB> <TAB> <TAB> changed . append ( song ) <TAB> if changed : <TAB> <TAB> self . _emit_changed ( changed , msg = "" add "" ) <TAB> return bool ( changed ) ","if isinstance ( self [ i ] , str ) and self . _list [ i ] in filenames : 
","if self . _list [ i ] in filenames :
",52.26,36.85,False
"def _expand_deps_java_generation ( self ) : <TAB> """"""Ensure that all multilingual dependencies such as proto_library generate java code."""""" <TAB> queue = collections . deque ( self . deps ) <TAB> keys = set ( ) <TAB> while queue : <TAB> <TAB> k = queue . popleft ( ) <TAB> <TAB> if k not in keys : <TAB> <TAB> <TAB> keys . add ( k ) <TAB> <TAB> <TAB> dep = self . target_database [ k ] <TAB> <TAB> <TAB> if "" generate_java "" in dep . attr :<TAB> # Has this attribute <TAB> <TAB> <TAB> <TAB> dep . attr [ "" generate_java "" ] = True <TAB> <TAB> <TAB> <TAB> queue . extend ( dep . deps ) ","if "" generate_java "" in dep . attr : 
","if "" generate_java "" in dep . attr :
",100.0,100.0,True
"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB> <TAB> opts = dict ( ) <TAB> <TAB> opts [ "" type "" ] = "" episode "" <TAB> <TAB> result = guessit ( name , options = opts ) <TAB> <TAB> res = dict ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" episode "" ] = 0 <TAB> <TAB> if "" season "" in result : <TAB> <TAB> <TAB> res [ "" season "" ] = result [ "" season "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" season "" ] = 0 <TAB> <TAB> if "" subtitle_language "" in result : <TAB> <TAB> <TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB> <TAB> return jsonify ( data = res ) <TAB> else : <TAB> <TAB> return "" "" , 400 ","if "" episode "" in result : 
","if "" episode "" in result :
",100.0,100.0,True
def _get_error_file ( self ) - > Optional [ str ] : <TAB> error_file = None <TAB> min_timestamp = sys . maxsize <TAB> for replicas in self . role_replicas . values ( ) : <TAB> <TAB> for replica in replicas : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> mtime = os . path . getmtime ( replica . error_file ) <TAB> <TAB> <TAB> if mtime < min_timestamp : <TAB> <TAB> <TAB> <TAB> min_timestamp = mtime <TAB> <TAB> <TAB> <TAB> error_file = replica . error_file <TAB> return error_file ,"if not os . path . exists ( replica . error_file ) : 
","if not replica . error_file :
",36.09,25.63,False
"def findChapterNameForPosition ( self , p ) : <TAB> """"""Return the name of a chapter containing p or None if p does not exist."""""" <TAB> cc , c = self , self . c <TAB> if not p or not c . positionExists ( p ) : <TAB> <TAB> return None <TAB> for name in cc . chaptersDict : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> theChapter = cc . chaptersDict . get ( name ) <TAB> <TAB> <TAB> if theChapter . positionIsInChapter ( p ) : <TAB> <TAB> <TAB> <TAB> return name <TAB> return "" main "" ","if name != "" main "" : 
","if name . startswith ( "" _ "" ) :
",34.92,10.55,False
"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB> <TAB> f_path = os . path . join ( folder , f ) <TAB> <TAB> if os . path . isfile ( f_path ) : <TAB> <TAB> <TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . remove ( f_path ) ","if extension in file_extensions : 
","if extension in file_extensions :
",100.0,100.0,True
"def execute_uncomment ( self , event ) : <TAB> cursor = self . _editor . GetCurrentPos ( ) <TAB> line , pos = self . _editor . GetCurLine ( ) <TAB> spaces = "" "" * self . _tab_size <TAB> comment = "" Comment "" + spaces <TAB> cpos = cursor - len ( comment ) <TAB> lenline = len ( line ) <TAB> if lenline > 0 : <TAB> <TAB> idx = 0 <TAB> <TAB> while idx < lenline and line [ idx ] == "" "" : <TAB> <TAB> <TAB> idx + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _editor . DeleteRange ( cursor - pos + idx , len ( comment ) ) <TAB> <TAB> <TAB> self . _editor . SetCurrentPos ( cpos ) <TAB> <TAB> <TAB> self . _editor . SetSelection ( cpos , cpos ) <TAB> <TAB> <TAB> self . store_position ( ) ","if ( line [ idx : len ( comment ) + idx ] ) . lower ( ) == comment . lower ( ) : 
","if idx < lenline :
",25.33,0.21,False
"def test_batch_kwarg_path_relative_dot_slash_is_modified_and_found_in_a_code_cell ( <TAB> critical_suite_with_citations , empty_data_context ) : <TAB> obs = SuiteEditNotebookRenderer . from_data_context ( empty_data_context ) . render ( <TAB> <TAB> critical_suite_with_citations , { "" path "" : "" ./foo/data "" } <TAB> ) <TAB> assert isinstance ( obs , dict ) <TAB> found_expected = False <TAB> for cell in obs [ "" cells "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source_code = cell [ "" source "" ] <TAB> <TAB> <TAB> if ' batch_kwargs =  { "" path "" :  "" ../.././foo/data "" } ' in source_code : <TAB> <TAB> <TAB> <TAB> found_expected = True <TAB> <TAB> <TAB> <TAB> break <TAB> assert found_expected ","if cell [ "" cell_type "" ] == "" code "" : 
","if cell [ "" cell_type "" ] == "" code "" :
",100.0,100.0,True
"def _get_file ( self ) : <TAB> if self . _file is None : <TAB> <TAB> self . _file = SpooledTemporaryFile ( <TAB> <TAB> <TAB> max_size = self . _storage . max_memory_size , <TAB> <TAB> <TAB> suffix = "" .S3Boto3StorageFile "" , <TAB> <TAB> <TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB> <TAB> ) <TAB> <TAB> if "" r "" in self . _mode : <TAB> <TAB> <TAB> self . _is_dirty = False <TAB> <TAB> <TAB> self . obj . download_fileobj ( self . _file ) <TAB> <TAB> <TAB> self . _file . seek ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file ","if self . _storage . gzip and self . obj . content_encoding == "" gzip "" : 
","if self . _is_dirty :
",32.86,7.53,False
"def _parse_filters ( f_strs ) : <TAB> filters = [ ] <TAB> if not f_strs : <TAB> <TAB> return filters <TAB> for f_str in f_strs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fname , fopts = f_str . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> filters . append ( ( fname , _parse_options ( [ fopts ] ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> filters . append ( ( f_str , { } ) ) <TAB> return filters ","if "" : "" in f_str : 
","if "" : "" in f_str :
",100.0,100.0,True
"def update_completion ( self ) : <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if orig_text [ - 1 ] not in ( "" , "" , "" "" ) : <TAB> <TAB> <TAB> <TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB> <TAB> <TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB> <TAB> self . completer_model . setStringList ( tags ) ","if "" , "" in orig_text : 
","if tag not in tags :
",27.38,6.48,False
"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB> <TAB> name = path . name <TAB> <TAB> if name == "" __pycache__ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB> <TAB> elif path . is_dir ( ) and "" . "" not in name : <TAB> <TAB> <TAB> names . add ( name ) <TAB> if packages : <TAB> <TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB> <TAB> if len ( names & packages ) == len ( packages ) : <TAB> <TAB> <TAB> return packages <TAB> return names ","if name . endswith ( "" .py "" ) : 
","elif path . is_file ( ) and "" . "" in name :
",34.75,7.43,False
"def get_cloud_credential ( self ) : <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if cred . kind == self . source . replace ( "" ec2 "" , "" aws "" ) : <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred . credential_type . kind != "" vault "" : <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential ","if self . source in CLOUD_PROVIDERS : 
","if self . source :
",53.5,31.77,False
"def newickize ( clade ) : <TAB> """"""Convert a node tree to a Newick tree string, recursively."""""" <TAB> label = clade . name or "" "" <TAB> if label : <TAB> <TAB> unquoted_label = re . match ( token_dict [ "" unquoted node label "" ] , label ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> label = "" ' %s ' "" % label . replace ( "" \\ "" , "" \\ \\ "" ) . replace ( "" ' "" , "" \\ ' "" ) <TAB> if clade . is_terminal ( ) :<TAB> # terminal <TAB> <TAB> return label + make_info_string ( clade , terminal = True ) <TAB> else : <TAB> <TAB> subtrees = ( newickize ( sub ) for sub in clade ) <TAB> <TAB> return "" ( %s ) %s "" % ( "" , "" . join ( subtrees ) , label + make_info_string ( clade ) ) ","if ( not unquoted_label ) or ( unquoted_label . end ( ) < len ( label ) ) : 
","if unquoted_label :
",25.38,1.23,False
"def __iter__ ( self ) : <TAB> for name , value in self . _vars . store . data . items ( ) : <TAB> <TAB> source = self . _sources [ name ] <TAB> <TAB> prefix = self . _get_prefix ( value ) <TAB> <TAB> name = u "" {0} {{ {1} }} "" . format ( prefix , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ArgumentInfo ( name , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield VariableInfo ( name , value , source ) ","if source == self . ARGUMENT_SOURCE : 
","if source is None :
",29.24,8.7,False
"def filepath_enumerate ( paths ) : <TAB> """"""Enumerate the file paths of all subfiles of the list of paths"""""" <TAB> out = [ ] <TAB> for path in paths : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for root , dirs , files in os . walk ( path ) : <TAB> <TAB> <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( os . path . normpath ( os . path . join ( root , name ) ) ) <TAB> return out ","if os . path . isfile ( path ) : 
","if os . path . isdir ( path ) :
",83.03,65.8,False
"def del_ ( self , key ) : <TAB> hash_ = self . hash ( key ) <TAB> node_ = self . _table [ hash_ ] <TAB> pre_node = None <TAB> while node_ is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if pre_node is None : <TAB> <TAB> <TAB> <TAB> self . _table [ hash_ ] = node_ . next <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> pre_node . next = node_ . next <TAB> <TAB> <TAB> self . _len - = 1 <TAB> <TAB> pre_node = node_ <TAB> <TAB> node_ = node_ . next ","if node_ . key == key : 
","if node_ . key == key :
",100.0,100.0,True
"def _recurse ( self , base_path , rel_source , rel_zip ) : <TAB> submodules_path = Path ( base_path ) / "" submodules "" <TAB> if not submodules_path . is_dir ( ) : <TAB> <TAB> return <TAB> for submodule in submodules_path . iterdir ( ) : <TAB> <TAB> source_path = submodule / rel_source <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> output_path = submodule / rel_zip <TAB> <TAB> self . _build_lambdas ( source_path , output_path ) <TAB> <TAB> self . _recurse ( submodule , rel_source , rel_zip ) ","if not source_path . is_dir ( ) : 
","if not source_path . is_file ( ) :
",75.22,73.49,False
"def find_test_functions ( collections ) : <TAB> if not isinstance ( collections , list ) : <TAB> <TAB> collections = [ collections ] <TAB> functions = [ ] <TAB> for collection in collections : <TAB> <TAB> if not isinstance ( collection , dict ) : <TAB> <TAB> <TAB> collection = vars ( collection ) <TAB> <TAB> keys = collection . keys ( ) <TAB> <TAB> keys . sort ( ) <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> value = collection [ key ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> functions . append ( value ) <TAB> return functions ","if isinstance ( value , types . FunctionType ) and hasattr ( value , "" unittest "" ) : 
","if callable ( value ) and value . __name__ == "" TestFunction "" :
",32.51,7.2,False
"def __init__ ( <TAB> self , <TAB> classifier , <TAB> layer_name = None , <TAB> transpose = None , <TAB> distance = None , <TAB> copy_weights = True , ) : <TAB> super ( ) . __init__ ( ) <TAB> self . copy_weights = copy_weights <TAB> ### set layer weights ### <TAB> if layer_name is not None : <TAB> <TAB> self . set_weights ( getattr ( classifier , layer_name ) ) <TAB> else : <TAB> <TAB> for x in self . possible_layer_names : <TAB> <TAB> <TAB> layer = getattr ( classifier , x , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . set_weights ( layer ) <TAB> <TAB> <TAB> <TAB> break <TAB> ### set distance measure ### <TAB> self . distance = classifier . distance if distance is None else distance <TAB> self . transpose = transpose ","if layer is not None : 
","if layer is not None :
",100.0,100.0,True
def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB> <TAB> if len ( self . _tail_data ) < self . _base_number : <TAB> <TAB> <TAB> self . _tail_data + = data <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield self . _tail_data <TAB> <TAB> <TAB> self . _tail_data = [ ] ,"if len ( self . _tail_data ) == self . _base_number : 
","if len ( self . _tail_data ) == self . _max_size :
",91.44,79.48,False
"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB> <TAB> for setting , edge in self . Conflicts : <TAB> <TAB> <TAB> answer = self . AskUser ( self . Setting , setting ) <TAB> <TAB> <TAB> if answer == Gtk . ResponseType . YES : <TAB> <TAB> <TAB> <TAB> value = setting . Value . split ( "" | "" ) <TAB> <TAB> <TAB> <TAB> value . remove ( edge ) <TAB> <TAB> <TAB> <TAB> setting . Value = "" | "" . join ( value ) <TAB> <TAB> <TAB> <TAB> if updater : <TAB> <TAB> <TAB> <TAB> <TAB> updater . UpdateSetting ( setting ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if answer == Gtk . ResponseType . NO : 
","elif answer == Gtk . ResponseType . NO :
",81.27,88.01,False
"def _post_process_ttl ( zone ) : <TAB> for name in zone : <TAB> <TAB> for record_type in zone [ name ] : <TAB> <TAB> <TAB> records = zone [ name ] [ record_type ] <TAB> <TAB> <TAB> if isinstance ( records , list ) : <TAB> <TAB> <TAB> <TAB> ttl = min ( [ x [ "" ttl "" ] for x in records ] ) <TAB> <TAB> <TAB> <TAB> for record in records : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Using lowest TTL  {}  for the record set. Ignoring value  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ttl , record [ "" ttl "" ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> record [ "" ttl "" ] = ttl ","if record [ "" ttl "" ] != ttl : 
","if ttl < record [ "" ttl "" ] :
",63.72,51.77,False
"def __init__ ( self , cmds , env , cleanup = [ ] ) : <TAB> self . handle = None <TAB> self . cmds = cmds <TAB> self . env = env <TAB> if cleanup : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cleanup = [ cleanup ] <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cleanup = [ c for c in cleanup if callable ( c ) ] <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> cleanup = [ ] <TAB> self . cleanup = cleanup ","if callable ( cleanup ) : 
","if isinstance ( cleanup , ( list , tuple ) ) :
",29.64,10.13,False
"def _parse_data_of_birth ( cls , data_of_birth_string ) : <TAB> if data_of_birth_string : <TAB> <TAB> format = "" % m/ %d / % Y "" <TAB> <TAB> try : <TAB> <TAB> <TAB> parsed_date = datetime . datetime . strptime ( data_of_birth_string , format ) <TAB> <TAB> <TAB> return parsed_date <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> # Facebook sometimes provides a partial date format <TAB> <TAB> <TAB> # ie 04/07 (ignore those) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ","if data_of_birth_string . count ( "" / "" ) != 1 : 
","if not data_of_birth_string . endswith ( "" % "" ) :
",42.71,45.09,False
"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB> <TAB> var = d . upper ( ) <TAB> <TAB> if var == "" QTCORE "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env [ "" LIBPATH_ "" + var ] <TAB> <TAB> if value : <TAB> <TAB> <TAB> core = env [ coreval ] <TAB> <TAB> <TAB> accu = [ ] <TAB> <TAB> <TAB> for lib in value : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu . append ( lib ) <TAB> <TAB> <TAB> env [ "" LIBPATH_ "" + var ] = accu ","if lib in core : 
","if not lib . startswith ( core ) :
",27.63,6.74,False
"def throttle_status ( server = None ) : <TAB> result = AmonStruct ( ) <TAB> result . allow = False <TAB> last_check = server . get ( "" last_check "" ) <TAB> server_check_period = server . get ( "" check_every "" , 60 ) <TAB> if last_check : <TAB> <TAB> period_since_last_check = unix_utc_now ( ) - last_check <TAB> <TAB> # Add 15 seconds buffer, for statsd <TAB> <TAB> period_since_last_check = period_since_last_check + 15 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . allow = True <TAB> else : <TAB> <TAB> result . allow = True<TAB> # Never checked <TAB> return result ","if period_since_last_check > = server_check_period : 
","if server_check_period < = period_since_last_check :
",53.08,63.72,False
"def fetch_scatter_outputs ( self , task ) : <TAB> scatteroutputs = [ ] <TAB> for var in task [ "" body "" ] : <TAB> <TAB> # TODO variable support <TAB> <TAB> if var . startswith ( "" call "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for output in self . tasks_dictionary [ task [ "" body "" ] [ var ] [ "" task "" ] ] [ <TAB> <TAB> <TAB> <TAB> <TAB> "" outputs "" <TAB> <TAB> <TAB> <TAB> ] : <TAB> <TAB> <TAB> <TAB> <TAB> scatteroutputs . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> { "" task "" : task [ "" body "" ] [ var ] [ "" alias "" ] , "" output "" : output [ 0 ] } <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return scatteroutputs ","if "" outputs "" in self . tasks_dictionary [ task [ "" body "" ] [ var ] [ "" task "" ] ] : 
","if task [ "" body "" ] [ var ] [ "" task "" ] in self . tasks_dictionary [ task [ "" body "" ] [ "" task "" ] ] :
",78.39,66.12,False
"def _add_constant_node ( self , source_node ) : <TAB> parent_ids = range ( len ( source_node . in_edges ) ) <TAB> for idx in parent_ids : <TAB> <TAB> parent_node = self . tf_graph . get_node ( source_node . in_edges [ idx ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _rename_Const ( parent_node ) ","if parent_node . type == "" Const "" : 
","if parent_node . type == "" constant "" :
",83.27,76.92,False
"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self . storySettingsData : <TAB> <TAB> name = data [ "" name "" ] <TAB> <TAB> if name in self . ctrls : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> set = self . getSetting ( data [ "" requires "" ] ) <TAB> <TAB> <TAB> <TAB> for i in self . ctrls [ name ] : <TAB> <TAB> <TAB> <TAB> <TAB> i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] ) ","if "" requires "" in data : 
","if data [ "" requires "" ] :
",39.9,24.45,False
"def update_realtime ( self , stdout = "" "" , stderr = "" "" , delete = False ) : <TAB> wooey_cache = wooey_settings . WOOEY_REALTIME_CACHE <TAB> if delete == False and wooey_cache is None : <TAB> <TAB> self . stdout = stdout <TAB> <TAB> self . stderr = stderr <TAB> <TAB> self . save ( ) <TAB> elif wooey_cache is not None : <TAB> <TAB> cache = django_cache [ wooey_cache ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cache . delete ( self . get_realtime_key ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cache . set ( <TAB> <TAB> <TAB> <TAB> self . get_realtime_key ( ) , <TAB> <TAB> <TAB> <TAB> json . dumps ( { "" stdout "" : stdout , "" stderr "" : stderr } ) , <TAB> <TAB> <TAB> ) ","if delete : 
","if delete :
",78.12,0.0,False
"def _check_for_batch_clashes ( xs ) : <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB> <TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB> <TAB> if batches : <TAB> <TAB> <TAB> if not isinstance ( batches , ( list , tuple ) ) : <TAB> <TAB> <TAB> <TAB> batches = [ batches ] <TAB> <TAB> <TAB> for batch in batches : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB> <TAB> <TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB> <TAB> ) ","if batch in names : 
","if batch [ "" description "" ] not in names :
",36.29,17.54,False
"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 100 <TAB> <TAB> if self . split > 20 : <TAB> <TAB> <TAB> self . save = self . split <TAB> <TAB> <TAB> self . split = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . save <TAB> else : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 0.3 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . split = self . save <TAB> <TAB> elif self . split < 0.5 : <TAB> <TAB> <TAB> self . split = self . min <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . max <TAB> self . placeChilds ( ) ","if self . split < = self . min or self . split > = self . max : 
","if self . split > 0.3 :
",42.15,11.59,False
"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB> <TAB> iterator = iter ( self . file ) <TAB> <TAB> head = next ( iterator , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . repaired = [ ] <TAB> <TAB> <TAB> return True <TAB> <TAB> if isinstance ( head , str ) : <TAB> <TAB> <TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError ( <TAB> <TAB> <TAB> <TAB> "" Could not open source:  %r  (mode:  %r ) "" <TAB> <TAB> <TAB> <TAB> % ( self . file , self . options [ "" mode "" ] ) <TAB> <TAB> <TAB> ) <TAB> return False ","if head is None : 
","if head is None :
",100.0,100.0,True
"def _print_message_content ( self , peer , data ) : <TAB> inheaders = 1 <TAB> lines = data . splitlines ( ) <TAB> for line in lines : <TAB> <TAB> # headers first <TAB> <TAB> if inheaders and not line : <TAB> <TAB> <TAB> peerheader = "" X-Peer:  "" + peer [ 0 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # decoded_data=false; make header match other binary output <TAB> <TAB> <TAB> <TAB> peerheader = repr ( peerheader . encode ( "" utf-8 "" ) ) <TAB> <TAB> <TAB> print ( peerheader ) <TAB> <TAB> <TAB> inheaders = 0 <TAB> <TAB> if not isinstance ( data , str ) : <TAB> <TAB> <TAB> # Avoid spurious 'str on bytes instance' warning. <TAB> <TAB> <TAB> line = repr ( line ) <TAB> <TAB> print ( line ) ","if not isinstance ( data , str ) : 
","if not isinstance ( peerheader , bytes ) :
",68.74,36.89,False
"def connect ( self ) : <TAB> # Makes connection with MySQL server <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> connection = pymysql . connect ( read_default_file = "" /etc/mysql/conf.d/my.cnf "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> connection = pymysql . connect ( read_default_file = "" ~/.my.cnf "" ) <TAB> <TAB> return connection <TAB> except ValueError as e : <TAB> <TAB> Log . debug ( self , str ( e ) ) <TAB> <TAB> raise MySQLConnectionError <TAB> except pymysql . err . InternalError as e : <TAB> <TAB> Log . debug ( self , str ( e ) ) <TAB> <TAB> raise MySQLConnectionError ","if os . path . exists ( "" /etc/mysql/conf.d/my.cnf "" ) : 
","if sys . platform == "" win32 "" :
",33.47,1.71,False
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> if not dest . parent . is_dir ( ) : <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> if dest . exists ( ) : <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutil . copy ( src , dest ) ","if src . exists ( ) : 
","if not src . is_symlink ( ) :
",49.98,20.56,False
"def update ( self , x , who = None , metadata = None ) : <TAB> self . _retain_refs ( metadata ) <TAB> y = self . _get_key ( x ) <TAB> if self . keep == "" last "" : <TAB> <TAB> # remove key if already present so that emitted value <TAB> <TAB> # will reflect elements' actual relative ordering <TAB> <TAB> self . _buffer . pop ( y , None ) <TAB> <TAB> self . _metadata_buffer . pop ( y , None ) <TAB> <TAB> self . _buffer [ y ] = x <TAB> <TAB> self . _metadata_buffer [ y ] = metadata <TAB> else :<TAB> # self.keep == ""first"" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _buffer [ y ] = x <TAB> <TAB> <TAB> self . _metadata_buffer [ y ] = metadata <TAB> return self . last ","if y not in self . _buffer : 
","if self . keep == "" first "" :
",33.16,9.98,False
"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB> <TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB> <TAB> <TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB> <TAB> <TAB> for ak in keys : <TAB> <TAB> <TAB> <TAB> if c_date == ak [ "" CreateDate "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict ( ak ) <TAB> <TAB> <TAB> <TAB> <TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ak ) <TAB> <TAB> elif k not in res : <TAB> <TAB> <TAB> res . append ( k ) <TAB> return res ","if ak not in res : 
","if ak [ "" c7n:match-type "" ] == "" access "" :
",28.24,5.82,False
"def _apply_flag_attrs ( src_flag , dest_flag ) : <TAB> # Use a baseline flag def to get default values for empty data. <TAB> baseline_flag = FlagDef ( "" "" , { } , None ) <TAB> for name in dir ( src_flag ) : <TAB> <TAB> if name [ : 1 ] == "" _ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> dest_val = getattr ( dest_flag , name , None ) <TAB> <TAB> baseline_val = getattr ( baseline_flag , name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( dest_flag , name , getattr ( src_flag , name ) ) ","if dest_val == baseline_val : 
","if dest_val is None or baseline_val == dest_flag :
",38.5,35.58,False
"def _ws_keep_reading ( self ) : <TAB> import websockets . exceptions <TAB> while not self . _reader_stopped : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = await self . _ws . recv ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = data . encode ( "" UTF-8 "" ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> self . _error = "" EOF "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except websockets . exceptions . ConnectionClosedError : <TAB> <TAB> <TAB> # TODO: try to reconnect in case of Ctrl+D <TAB> <TAB> <TAB> self . _error = "" EOF "" <TAB> <TAB> <TAB> break <TAB> <TAB> self . num_bytes_received + = len ( data ) <TAB> <TAB> self . _make_output_available ( data , block = False ) ","if isinstance ( data , str ) : 
","if isinstance ( data , str ) :
",100.0,100.0,True
"def to_dict ( self ) - > Dict [ str , Any ] : <TAB> result = { } <TAB> for field_name in self . API_FIELDS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" stream_id "" ] = self . id <TAB> <TAB> <TAB> continue <TAB> <TAB> elif field_name == "" date_created "" : <TAB> <TAB> <TAB> result [ "" date_created "" ] = datetime_to_timestamp ( self . date_created ) <TAB> <TAB> <TAB> continue <TAB> <TAB> result [ field_name ] = getattr ( self , field_name ) <TAB> result [ "" is_announcement_only "" ] = ( <TAB> <TAB> self . stream_post_policy == Stream . STREAM_POST_POLICY_ADMINS <TAB> ) <TAB> return result ","if field_name == "" id "" : 
","if field_name == "" stream_id "" :
",74.63,63.4,False
"def all_masks ( <TAB> cls , <TAB> images , <TAB> run , <TAB> run_key , <TAB> step , ) : <TAB> all_mask_groups = [ ] <TAB> for image in images : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mask_group = { } <TAB> <TAB> <TAB> for k in image . _masks : <TAB> <TAB> <TAB> <TAB> mask = image . _masks [ k ] <TAB> <TAB> <TAB> <TAB> mask_group [ k ] = mask . to_json ( run ) <TAB> <TAB> <TAB> all_mask_groups . append ( mask_group ) <TAB> <TAB> else : <TAB> <TAB> <TAB> all_mask_groups . append ( None ) <TAB> if all_mask_groups and not all ( x is None for x in all_mask_groups ) : <TAB> <TAB> return all_mask_groups <TAB> else : <TAB> <TAB> return False ","if image . _masks : 
","if image . _masks :
",100.0,100.0,True
"def disconnect_all ( listener ) : <TAB> """"""Disconnect from all signals"""""" <TAB> for emitter in listener . _signal_data . emitters : <TAB> <TAB> for signal in emitter . _signal_data . listeners : <TAB> <TAB> <TAB> emitter . _signal_data . listeners [ signal ] = [ <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> <TAB> for i in emitter . _signal_data . listeners [ signal ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ] ","if getattr ( i , "" __self__ "" , None ) != listener 
","if i . _signal_data . type == type ( listener . _signal_data . listeners [ signal ] )
",26.0,2.68,False
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> if timeout is None : <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode ","if code == TERMINATE : 
","if code == _subprocess . WAIT_TERM :
",36.73,24.81,False
"def set_pbar_fraction ( self , frac , progress , stage = None ) : <TAB> gtk . gdk . threads_enter ( ) <TAB> try : <TAB> <TAB> self . is_pulsing = False <TAB> <TAB> self . set_stage_text ( stage or _ ( "" Processing... "" ) ) <TAB> <TAB> self . pbar . set_text ( progress ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frac = 1.0 <TAB> <TAB> if frac < 0 : <TAB> <TAB> <TAB> frac = 0 <TAB> <TAB> self . pbar . set_fraction ( frac ) <TAB> finally : <TAB> <TAB> gtk . gdk . threads_leave ( ) ","if frac > 1 : 
","if frac > 1.0 :
",39.48,42.73,False
"def get_aa_from_codonre ( re_aa ) : <TAB> aas = [ ] <TAB> m = 0 <TAB> for i in re_aa : <TAB> <TAB> if i == "" [ "" : <TAB> <TAB> <TAB> m = - 1 <TAB> <TAB> <TAB> aas . append ( "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> m = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> elif m == - 1 : <TAB> <TAB> <TAB> aas [ - 1 ] = aas [ - 1 ] + i <TAB> <TAB> elif m == 0 : <TAB> <TAB> <TAB> aas . append ( i ) <TAB> return aas ","elif i == "" ] "" : 
","elif i == "" ] "" :
",100.0,100.0,True
"def link ( token , base_url ) : <TAB> """"""Validation for ``link``."""""" <TAB> if get_keyword ( token ) == "" none "" : <TAB> <TAB> return "" none "" <TAB> parsed_url = get_url ( token , base_url ) <TAB> if parsed_url : <TAB> <TAB> return parsed_url <TAB> function = parse_function ( token ) <TAB> if function : <TAB> <TAB> name , args = function <TAB> <TAB> prototype = ( name , [ a . type for a in args ] ) <TAB> <TAB> args = [ getattr ( a , "" value "" , a ) for a in args ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( "" attr() "" , args [ 0 ] ) ","if prototype == ( "" attr "" , [ "" ident "" ] ) : 
","if prototype in ( "" attr "" , "" attr_async "" ) :
",48.94,31.02,False
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB> <TAB> <TAB> return self . current_provider . on_file ( query ) ","elif self . current_provider . kind == directory . Provider . PROVIDER_URL : 
","elif self . current_provider . kind == directory . Provider . PROVIDER_URL :
",100.0,100.0,True
"def test_handle_single ( self ) : <TAB> self . skipTest ( <TAB> <TAB> "" Pops up windows and needs user input.. so disabled. "" <TAB> <TAB> "" Still worth keeping whilst we don ' t have unit tests  "" <TAB> <TAB> "" for all plugins. "" <TAB> ) <TAB> # Ignored... <TAB> for id_ , plugin in self . plugins . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . h . plugin_enable ( plugin , None ) <TAB> <TAB> <TAB> self . h . handle ( id_ , self . lib , self . parent , SONGS ) <TAB> <TAB> <TAB> self . h . plugin_disable ( plugin ) ","if self . h . plugin_handle ( plugin ) : 
","if self . h . plugin_is_enabled ( plugin ) :
",83.03,61.63,False
"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . _keydata : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB> <TAB> elif hasattr ( self , k ) : <TAB> <TAB> <TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB> <TAB> attrs . append ( "" private "" ) <TAB> # PY3K: This is meant to be text, do not change to bytes (data) <TAB> return "" < %s  @0x %x %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) ) ","if k == "" p "" : 
","if k == "" p "" :
",100.0,100.0,True
"def apply ( self , node , code , required ) : <TAB> yield "" try: "" <TAB> yield from self . iterIndented ( code ) <TAB> yield ""<TAB>  pass"" <TAB> yield "" except  {} : "" . format ( self . exceptionString ) <TAB> outputVariables = node . getOutputSocketVariables ( ) <TAB> for i , s in enumerate ( node . outputs ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if hasattr ( s , "" getDefaultValueCode "" ) : <TAB> <TAB> <TAB> <TAB> yield f ""<TAB>  { outputVariables [ s . identifier ] }  =  { s . getDefaultValueCode ( ) } "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield f ""<TAB>  { outputVariables [ s . identifier ] }  = self.outputs[ { i } ].getDefaultValue() "" <TAB> yield ""<TAB>  pass"" ","if s . identifier in required : 
","if s . identifier in outputVariables :
",82.52,64.35,False
"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB> <TAB> if "" * "" in fromlist : <TAB> <TAB> <TAB> fromlist = list ( fromlist ) <TAB> <TAB> <TAB> fromlist . remove ( "" * "" ) <TAB> <TAB> <TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB> <TAB> for x in fromlist : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB> <TAB> <TAB> <TAB> if from_name in modules : <TAB> <TAB> <TAB> <TAB> <TAB> importlib . import_module ( from_name ) <TAB> return module ","if isinstance ( getattr ( module , x , None ) , types . ModuleType ) : 
","if x is not None :
",25.72,1.84,False
"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r = await ws . recv ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> r = r . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> msg = json . loads ( r ) <TAB> <TAB> <TAB> stream = msg . get ( "" stream "" ) <TAB> <TAB> <TAB> if stream is not None : <TAB> <TAB> <TAB> <TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB> <TAB> logging . warn ( wse ) <TAB> <TAB> await self . close ( ) <TAB> <TAB> asyncio . ensure_future ( self . _ensure_ws ( ) ) ","if isinstance ( r , bytes ) : 
","if isinstance ( r , bytes ) :
",100.0,100.0,True
"def add_source ( self , source , name = None ) : <TAB> """"""Adds a new data source to an existing provider."""""" <TAB> if self . randomize : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Cannot add a non-shuffleable source to an  "" <TAB> <TAB> <TAB> <TAB> "" already shuffled provider. "" <TAB> <TAB> <TAB> ) <TAB> super ( ) . add_source ( source , name = name ) <TAB> if self . randomize is True : <TAB> <TAB> self . _shuffle_len = self . entries ","if not source . can_shuffle ( ) : 
","if source in self . shuffled_sources :
",31.16,6.38,False
"def __str__ ( self ) : <TAB> buf = [ "" "" ] <TAB> if self . fileName : <TAB> <TAB> buf . append ( self . fileName + "" : "" ) <TAB> if self . line != - 1 : <TAB> <TAB> if not self . fileName : <TAB> <TAB> <TAB> buf . append ( "" line  "" ) <TAB> <TAB> buf . append ( str ( self . line ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> buf . append ( "" : "" + str ( self . column ) ) <TAB> <TAB> buf . append ( "" : "" ) <TAB> buf . append ( "" "" ) <TAB> return str ( "" "" ) . join ( buf ) ","if self . column != - 1 : 
","if not self . column != - 1 :
",80.5,78.25,False
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if linenum > 0 and line [ 0 ] not in "" \t "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if len ( line . strip ( ) ) == 0 : 
","if linenum == 0 and line [ 0 ] not in "" \t "" :
",27.1,10.12,False
"def scanHexEscape ( self , prefix ) : <TAB> code = 0 <TAB> leng = 4 if ( prefix == "" u "" ) else 2 <TAB> for i in xrange ( leng ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ch = self . source [ self . index ] <TAB> <TAB> <TAB> self . index + = 1 <TAB> <TAB> <TAB> code = code * 16 + HEX_CONV [ ch ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" "" <TAB> return unichr ( code ) ","if self . index < self . length and isHexDigit ( self . source [ self . index ] ) : 
","if self . index < leng :
",40.93,8.71,False
"def _get_table_info ( self , table_name ) : <TAB> table_addr = self . addr_space . profile . get_symbol ( table_name ) <TAB> table_size = self . _get_table_info_distorm ( ) <TAB> <MASK> <TAB> <TAB> table_size = self . _get_table_info_other ( table_addr , table_name ) <TAB> <TAB> if table_size == 0 : <TAB> <TAB> <TAB> debug . error ( "" Unable to get system call table size "" ) <TAB> return [ table_addr , table_size ] ","if table_size == 0 : 
","if table_size == 0 :
",100.0,100.0,True
"def format_file_path ( filepath ) : <TAB> """"""Formats a path as absolute and with the correct platform separator."""""" <TAB> try : <TAB> <TAB> is_windows_network_mount = WINDOWS_NETWORK_MOUNT_PATTERN . match ( filepath ) <TAB> <TAB> filepath = os . path . realpath ( os . path . abspath ( filepath ) ) <TAB> <TAB> filepath = re . sub ( BACKSLASH_REPLACE_PATTERN , "" / "" , filepath ) <TAB> <TAB> is_windows_drive = WINDOWS_DRIVE_PATTERN . match ( filepath ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filepath = filepath . capitalize ( ) <TAB> <TAB> if is_windows_network_mount : <TAB> <TAB> <TAB> # Add back a / to the front, since the previous modifications <TAB> <TAB> <TAB> # will have replaced any double slashes with single <TAB> <TAB> <TAB> filepath = "" / "" + filepath <TAB> except : <TAB> <TAB> pass <TAB> return filepath ","if is_windows_drive : 
","if is_windows_drive :
",78.12,100.0,True
"def _match ( self , cre , s ) : <TAB> # Run compiled regular expression match method on 's'. <TAB> # Save result, return success. <TAB> self . mo = cre . match ( s ) <TAB> if __debug__ : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _mesg ( "" \t matched r ' %r '  =>  %r "" % ( cre . pattern , self . mo . groups ( ) ) ) <TAB> return self . mo is not None ","if self . mo is not None and self . debug > = 5 : 
","if self . mo :
",37.02,9.57,False
"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB> <TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB> <TAB> <TAB> for line in f . readlines ( ) : <TAB> <TAB> <TAB> <TAB> if not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist_file , <TAB> <TAB> <TAB> ) ","if explicit : 
","if explicit :
",78.12,0.0,False
"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB> <TAB> if not self . flags . forc : <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> order = "" F "" <TAB> <TAB> else : <TAB> <TAB> <TAB> order = "" C "" <TAB> <TAB> result = self . _new_like_me ( order = order ) <TAB> <TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB> <TAB> func . prepared_async_call ( <TAB> <TAB> <TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return self ","if self . flags . f_contiguous : 
","elif self . flags . f :
",58.07,48.35,False
"def scan_spec_conf ( self , conf ) : <TAB> if "" metadata "" in conf : <TAB> <TAB> if "" annotations "" in conf [ "" metadata "" ] and conf [ "" metadata "" ] . get ( "" annotations "" ) : <TAB> <TAB> <TAB> for annotation in conf [ "" metadata "" ] [ "" annotations "" ] : <TAB> <TAB> <TAB> <TAB> for key in annotation : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" docker/default "" in annotation [ key ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> or "" runtime/default "" in annotation [ key ] <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED ","if "" seccomp.security.alpha.kubernetes.io/defaultProfileName "" in key : 
","if key . startswith ( "" docker/ "" ) :
",33.22,3.53,False
"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self . CloseFailureIO ( ) <TAB> with support . catch_unraisable_exception ( ) as cm : <TAB> <TAB> with self . assertRaises ( AttributeError ) : <TAB> <TAB> <TAB> self . tp ( rawio ) . xyzzy <TAB> <TAB> if not IOBASE_EMITS_UNRAISABLE : <TAB> <TAB> <TAB> self . assertIsNone ( cm . unraisable ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( cm . unraisable . exc_type , OSError ) ","elif cm . unraisable is not None : 
","elif cm . unraisable is not None :
",100.0,100.0,True
"def _dumpf ( frame ) : <TAB> if frame is None : <TAB> <TAB> return "" <None> "" <TAB> else : <TAB> <TAB> addn = "" (with trace!) "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> addn = ""  **No Trace Set ** "" <TAB> <TAB> return "" Frame at  %d , file  %s , line:  %d %s "" % ( <TAB> <TAB> <TAB> id ( frame ) , <TAB> <TAB> <TAB> frame . f_code . co_filename , <TAB> <TAB> <TAB> frame . f_lineno , <TAB> <TAB> <TAB> addn , <TAB> <TAB> ) ","if frame . f_trace is None : 
","if not frame . f_trace :
",40.3,49.63,False
"def containsBadbytes ( self , value , bytecount = 4 ) : <TAB> for b in self . badbytes : <TAB> <TAB> tmp = value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> b = ord ( b ) <TAB> <TAB> for i in range ( bytecount ) : <TAB> <TAB> <TAB> if ( tmp & 0xFF ) == b : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> tmp >> = 8 <TAB> return False ","if type ( b ) == str : 
","if isinstance ( b , six . string_types ) :
",28.2,8.52,False
"def _set_peer_statuses ( self ) : <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> peer . status = PEER_BAD <TAB> <TAB> elif peer . last_good > cutoff : <TAB> <TAB> <TAB> peer . status = PEER_GOOD <TAB> <TAB> elif peer . last_good : <TAB> <TAB> <TAB> peer . status = PEER_STALE <TAB> <TAB> else : <TAB> <TAB> <TAB> peer . status = PEER_NEVER ","if peer . bad : 
","if peer . last_good < cutoff :
",45.06,19.07,False
"def afterTest ( self , test ) : <TAB> try : <TAB> <TAB> # If the browser window is still open, close it now. <TAB> <TAB> self . driver . quit ( ) <TAB> except AttributeError : <TAB> <TAB> pass <TAB> except Exception : <TAB> <TAB> pass <TAB> if self . options . headless : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . display . stop ( ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass ","if self . headless_active : 
","if self . display :
",64.48,28.64,False
"def _written_variables_in_proxy ( self , contract ) : <TAB> variables = [ ] <TAB> if contract . is_upgradeable : <TAB> <TAB> variables_name_written_in_proxy = self . _variable_written_in_proxy ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> variables_in_contract = [ <TAB> <TAB> <TAB> <TAB> contract . get_state_variable_from_name ( v ) <TAB> <TAB> <TAB> <TAB> for v in variables_name_written_in_proxy <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> variables_in_contract = [ v for v in variables_in_contract if v ] <TAB> <TAB> <TAB> variables + = variables_in_contract <TAB> return list ( set ( variables ) ) ","if variables_name_written_in_proxy : 
","if variables_name_written_in_proxy :
",78.12,100.0,True
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> if name . startswith ( expr ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> if not scoperef : <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ","if name not in found_names : 
","if name not in found_names :
",100.0,100.0,True
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not name . startswith ( "" wait_until "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action ( member ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods ","if not name [ 0 ] . isupper ( ) : 
","if not is_resource_action ( member ) :
",28.13,11.21,False
def UpdateControlState ( self ) : <TAB> active = self . demoModules . GetActiveID ( ) <TAB> # Update the radio/restore buttons <TAB> for moduleID in self . radioButtons : <TAB> <TAB> btn = self . radioButtons [ moduleID ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> btn . SetValue ( True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> btn . SetValue ( False ) <TAB> <TAB> if self . demoModules . Exists ( moduleID ) : <TAB> <TAB> <TAB> btn . Enable ( True ) <TAB> <TAB> <TAB> if moduleID == modModified : <TAB> <TAB> <TAB> <TAB> self . btnRestore . Enable ( True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> btn . Enable ( False ) <TAB> <TAB> <TAB> if moduleID == modModified : <TAB> <TAB> <TAB> <TAB> self . btnRestore . Enable ( False ) ,"if moduleID == active : 
","if moduleID == active :
",100.0,100.0,True
"def test_controlcharacters ( self ) : <TAB> for i in range ( 128 ) : <TAB> <TAB> c = chr ( i ) <TAB> <TAB> testString = "" string containing  %s "" % c <TAB> <TAB> if i > = 32 or c in "" \r \n \t "" : <TAB> <TAB> <TAB> # \r, \n and \t are the only legal control chars in XML <TAB> <TAB> <TAB> data = plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( plistlib . loads ( data ) , testString ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with self . assertRaises ( ValueError ) : <TAB> <TAB> <TAB> <TAB> plistlib . dumps ( testString , fmt = plistlib . FMT_XML ) <TAB> <TAB> plistlib . dumps ( testString , fmt = plistlib . FMT_BINARY ) ","if c != "" \r "" : 
","if data != "" "" :
",30.43,24.18,False
"def remove_usernames ( self , username : SLT [ str ] ) - > None : <TAB> with self . __lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> f "" Can ' t set  { self . username_name }  in conjunction with (already set)  "" <TAB> <TAB> <TAB> <TAB> f "" { self . chat_id_name } s. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> parsed_username = self . _parse_username ( username ) <TAB> <TAB> self . _usernames - = parsed_username ","if self . _chat_ids : 
","if self . _usernames :
",64.48,38.5,False
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB> <TAB> if isinstance ( elem , str ) : <TAB> <TAB> <TAB> size + = len ( elem ) <TAB> <TAB> elif isinstance ( elem , np . ndarray ) : <TAB> <TAB> <TAB> size + = elem . size * elem . itemsize <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB> <TAB> elif isinstance ( elem , float ) : <TAB> <TAB> <TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( ) <TAB> return size ","elif isinstance ( elem , int ) : 
","elif isinstance ( elem , int ) :
",100.0,100.0,True
"def before_step ( self , step , feed_dict ) : <TAB> if step == 0 : <TAB> <TAB> for _type , mem in self . memories . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . gan . session . run ( tf . assign ( mem [ "" var "" ] , mem [ "" source "" ] ) ) ","if "" var "" in mem and "" source "" in mem : 
","if isinstance ( mem , dict ) and "" var "" in mem :
",60.56,40.53,False
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> if not self . bytestream : <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1 ","if self . bitnum == 8 : 
","if byte :
",27.04,0.0,False
"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB> <TAB> parameter_range_key , <TAB> <TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB> <TAB> if parameter_range_key == "" scaling_type "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for categorical_value in parameter_range_value : <TAB> <TAB> <TAB> <TAB> value_hp . validate ( categorical_value ) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else : <TAB> <TAB> <TAB> value_hp . validate ( parameter_range_value ) ","if isinstance ( parameter_range_value , list ) : 
","elif parameter_range_key == "" categorical_ranges "" :
",26.34,18.8,False
"def _trackA ( self , tracks ) : <TAB> try : <TAB> <TAB> track , start , end = self . featureA <TAB> <TAB> assert track in tracks <TAB> <TAB> return track <TAB> except TypeError : <TAB> <TAB> for track in tracks : <TAB> <TAB> <TAB> for feature_set in track . get_sets ( ) : <TAB> <TAB> <TAB> <TAB> if hasattr ( feature_set , "" features "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return track <TAB> <TAB> return None ","if self . featureA in feature_set . features . values ( ) : 
","if feature_set . features == self . featureA :
",38.1,34.92,False
"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB> <TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB> <TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( directory , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for file_path in walk ( full_name , path ) : <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> elif os . path . isfile ( full_name ) : <TAB> <TAB> <TAB> yield path ","if os . path . isdir ( full_name ) : 
","if os . path . isdir ( full_name ) :
",100.0,100.0,True
"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> while not self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> args = self . _ipc_requests . get ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> for filename in args : <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB> <TAB> self . become_active_window ( ) <TAB> finally : <TAB> <TAB> self . after ( 50 , self . _poll_ipc_requests ) ","if self . _ipc_requests . empty ( ) : 
","if self . _ipc_requests . empty ( ) :
",100.0,100.0,True
"def test_read1 ( self ) : <TAB> self . test_write ( ) <TAB> blocks = [ ] <TAB> nread = 0 <TAB> with gzip . GzipFile ( self . filename , "" r "" ) as f : <TAB> <TAB> while True : <TAB> <TAB> <TAB> d = f . read1 ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> blocks . append ( d ) <TAB> <TAB> <TAB> nread + = len ( d ) <TAB> <TAB> <TAB> # Check that position was updated correctly (see issue10791). <TAB> <TAB> <TAB> self . assertEqual ( f . tell ( ) , nread ) <TAB> self . assertEqual ( b "" "" . join ( blocks ) , data1 * 50 ) ","if not d : 
","if not d :
",100.0,100.0,True
"def _target_generator ( self ) : <TAB> if self . _internal_target_generator is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> from . . . . model_zoo . rcnn . rpn . rpn_target import RPNTargetGenerator <TAB> <TAB> self . _internal_target_generator = RPNTargetGenerator ( <TAB> <TAB> <TAB> num_sample = self . _num_sample , <TAB> <TAB> <TAB> pos_iou_thresh = self . _pos_iou_thresh , <TAB> <TAB> <TAB> neg_iou_thresh = self . _neg_iou_thresh , <TAB> <TAB> <TAB> pos_ratio = self . _pos_ratio , <TAB> <TAB> <TAB> stds = self . _box_norm , <TAB> <TAB> <TAB> * * self . _kwargs <TAB> <TAB> ) <TAB> <TAB> return self . _internal_target_generator <TAB> else : <TAB> <TAB> return self . _internal_target_generator ","if self . _net_none : 
","if self . _kwargs . get ( "" sample_zoo "" , False ) is None :
",42.3,14.03,False
"def time_left ( self ) : <TAB> """"""Return how many seconds are left until the timeout expires"""""" <TAB> if self . is_non_blocking : <TAB> <TAB> return 0 <TAB> elif self . is_infinite : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> delta = self . target_time - self . TIME ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # clock jumped, recalculate <TAB> <TAB> <TAB> self . target_time = self . TIME ( ) + self . duration <TAB> <TAB> <TAB> return self . duration <TAB> <TAB> else : <TAB> <TAB> <TAB> return max ( 0 , delta ) ","if delta > self . duration : 
","if delta < 0 :
",29.24,15.85,False
"def _decorator ( cls ) : <TAB> for name , meth in inspect . getmembers ( cls , inspect . isroutine ) : <TAB> <TAB> if name not in cls . __dict__ : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name != "" __init__ "" : <TAB> <TAB> <TAB> if not private and name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> setattr ( cls , name , decorator ( meth ) ) <TAB> return cls ","if name in butnot : 
","if not meth :
",28.52,14.79,False
"def load_vocab ( vocab_file : str ) - > List : <TAB> """"""Loads a vocabulary file into a dictionary."""""" <TAB> vocab = collections . OrderedDict ( ) <TAB> with io . open ( vocab_file , "" r "" , encoding = "" UTF-8 "" ) as file : <TAB> <TAB> for num , line in enumerate ( file ) : <TAB> <TAB> <TAB> items = convert_to_unicode ( line . strip ( ) ) . split ( "" \t "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> token = items [ 0 ] <TAB> <TAB> <TAB> index = items [ 1 ] if len ( items ) == 2 else num <TAB> <TAB> <TAB> token = token . strip ( ) <TAB> <TAB> <TAB> vocab [ token ] = int ( index ) <TAB> <TAB> return vocab ","if len ( items ) > 2 : 
","if len ( items ) > 2 :
",100.0,100.0,True
"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB> <TAB> new_slice_ = [ 0 ] <TAB> <TAB> offset = 0 <TAB> else : <TAB> <TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB> <TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_slice_ . append ( 0 ) <TAB> <TAB> elif offset < len ( slice_ ) : <TAB> <TAB> <TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB> <TAB> <TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_ ","if self . squeeze_dims [ i ] : 
","if self . nums [ i ] == 0 :
",48.14,24.38,False
"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB> <TAB> local_version = get_local_timestamp ( folder ) <TAB> <TAB> if remote_version > local_version : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> update_setter . set_value ( True ) <TAB> <TAB> <TAB> version_setter . set_value ( remote_version ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return False ","if auto : 
","if auto :
",78.12,0.0,False
"def iter_content ( self , chunk_size_bytes ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = self . _fp . read ( chunk_size_bytes ) <TAB> <TAB> except IOError as e : <TAB> <TAB> <TAB> raise Fetcher . PermanentError ( <TAB> <TAB> <TAB> <TAB> "" Problem reading chunk from  {} :  {} "" . format ( self . _fp . name , e ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> yield data ","if not data : 
","if not data :
",100.0,100.0,True
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> if isinstance ( arg , bool ) : <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> elif isinstance ( arg , ( int , float ) ) : <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( ) ","elif isinstance ( arg , str ) : 
","elif isinstance ( arg , str ) :
",100.0,100.0,True
"def _element_keywords ( cls , backend , elements = None ) : <TAB> "" Returns a dictionary of element names to allowed keywords "" <TAB> if backend not in Store . loaded_backends ( ) : <TAB> <TAB> return { } <TAB> mapping = { } <TAB> backend_options = Store . options ( backend ) <TAB> elements = elements if elements is not None else backend_options . keys ( ) <TAB> for element in elements : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> element = element if isinstance ( element , tuple ) else ( element , ) <TAB> <TAB> element_keywords = [ ] <TAB> <TAB> options = backend_options [ "" . "" . join ( element ) ] <TAB> <TAB> for group in Options . _option_groups : <TAB> <TAB> <TAB> element_keywords . extend ( options [ group ] . allowed_keywords ) <TAB> <TAB> mapping [ element [ 0 ] ] = element_keywords <TAB> return mapping ","if "" . "" in element : 
","if element is None :
",27.3,9.42,False
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> if self . use_prop or self . get_prop_name ( ) : <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> elif isinstance ( value , float ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value ","if isinstance ( value , int ) : 
","if isinstance ( value , int ) :
",100.0,100.0,True
"def _get_oshape ( indices_shape , depth , axis ) : <TAB> oshape = [ ] <TAB> true_axis = len ( indices_shape ) if axis == - 1 else axis <TAB> ndim = len ( indices_shape ) + 1 <TAB> indices_index = 0 <TAB> for i in range ( 0 , ndim ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> oshape . append ( depth ) <TAB> <TAB> else : <TAB> <TAB> <TAB> oshape . append ( indices_shape [ indices_index ] ) <TAB> <TAB> <TAB> indices_index + = 1 <TAB> return oshape ","if i == true_axis : 
","if indices_index == true_axis :
",64.48,53.73,False
"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB> <TAB> value = value . upper ( ) <TAB> <TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value [ len ( prefix ) : ] <TAB> <TAB> <TAB> value = value . lstrip ( "" _ "" ) <TAB> <TAB> if hasattr ( self . group , value ) : <TAB> <TAB> <TAB> return getattr ( self . group , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB> else : <TAB> <TAB> return value ","if value . startswith ( prefix ) : 
","if value . startswith ( prefix ) :
",100.0,100.0,True
"def shuffle_unison_inplace ( list_of_lists , random_state = None ) : <TAB> if list_of_lists : <TAB> <TAB> assert all ( len ( l ) == len ( list_of_lists [ 0 ] ) for l in list_of_lists ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> random_state . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p = np . random . permutation ( len ( list_of_lists [ 0 ] ) ) <TAB> <TAB> return [ l [ p ] for l in list_of_lists ] <TAB> return None ","if random_state is not None : 
","if random_state :
",29.58,38.81,False
"def _load_module ( self ) : <TAB> spec = self . default_module_spec <TAB> module_identifier = self . module_identifier <TAB> if module_identifier : <TAB> <TAB> impls = self . get_module_implementation_map ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ModuleNotFound ( <TAB> <TAB> <TAB> <TAB> "" Invalid module identifier  %r  in  %s "" <TAB> <TAB> <TAB> <TAB> % ( module_identifier , force_ascii ( repr ( self ) ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> spec = impls [ module_identifier ] <TAB> cls = load ( <TAB> <TAB> spec , context_explanation = "" Loading module for  %s "" % force_ascii ( repr ( self ) ) <TAB> ) <TAB> options = getattr ( self , self . module_options_field , None ) or { } <TAB> return cls ( self , options ) ","if module_identifier not in impls : 
","if module_identifier not in impls :
",100.0,100.0,True
"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB> <TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB> <TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( request , numbers . Integral ) : <TAB> <TAB> <TAB> <TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for j in range ( len ( data [ i ] ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data ) ","if shapes [ i ] is not None : 
","if i in shapes :
",26.63,6.79,False
"def resolve_credential_keys ( m_keys , keys ) : <TAB> res = [ ] <TAB> for k in m_keys : <TAB> <TAB> if k [ "" c7n:match-type "" ] == "" credential "" : <TAB> <TAB> <TAB> c_date = parse_date ( k [ "" last_rotated "" ] ) <TAB> <TAB> <TAB> for ak in keys : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> ak = dict ( ak ) <TAB> <TAB> <TAB> <TAB> <TAB> ak [ "" c7n:match-type "" ] = "" access "" <TAB> <TAB> <TAB> <TAB> <TAB> if ak not in res : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ak ) <TAB> <TAB> elif k not in res : <TAB> <TAB> <TAB> res . append ( k ) <TAB> return res ","if c_date == ak [ "" CreateDate "" ] : 
","if c_date > ak [ "" last_rotated "" ] :
",60.07,32.86,False
"def _is_legacy_mode ( self , node ) : <TAB> """"""Checks if the ``ast.Call`` node's keywords signal using legacy mode."""""" <TAB> script_mode = False <TAB> py_version = "" py2 "" <TAB> for kw in node . keywords : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> script_mode = ( <TAB> <TAB> <TAB> <TAB> bool ( kw . value . value ) if isinstance ( kw . value , ast . NameConstant ) else True <TAB> <TAB> <TAB> ) <TAB> <TAB> if kw . arg == "" py_version "" : <TAB> <TAB> <TAB> py_version = kw . value . s if isinstance ( kw . value , ast . Str ) else "" py3 "" <TAB> return not ( py_version . startswith ( "" py3 "" ) or script_mode ) ","if kw . arg == "" script_mode "" : 
","if kw . arg == "" script_mode "" :
",100.0,100.0,True
"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ]<TAB> # type: List[V1EventTrigger] <TAB> for e in events : <TAB> <TAB> entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB> <TAB> if not entity_ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e . kinds : <TAB> <TAB> <TAB> status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB> <TAB> <TAB> if status : <TAB> <TAB> <TAB> <TAB> statuses_by_refs [ entity_ref ] . append ( status ) <TAB> return statuses_by_refs ","if entity_ref not in statuses_by_refs : 
","if entity_ref in statuses_by_refs :
",56.72,74.26,False
"def items ( self ) : <TAB> dict = { } <TAB> for userdir in self . XDG_DIRS . keys ( ) : <TAB> <TAB> prefix = self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = ( <TAB> <TAB> <TAB> <TAB> os . getenv ( "" HOME "" ) <TAB> <TAB> <TAB> <TAB> + "" / "" <TAB> <TAB> <TAB> <TAB> + "" / "" . join ( self . get ( userdir ) . strip ( ' "" ' ) . split ( "" / "" ) [ 1 : ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> path = self . get ( userdir ) . strip ( ' "" ' ) <TAB> <TAB> dict [ userdir ] = path <TAB> return dict . items ( ) ","if prefix : 
","if prefix == "" / "" :
",33.58,12.22,False
"def clean_objects ( string , common_attributes ) : <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words [ : - 1 ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB> if prefix_words_are_adj : <TAB> <TAB> <TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ string ] , [ ] <TAB> else : <TAB> <TAB> return [ string ] , [ ] ","if att not in common_attributes : 
","if att in common_attributes :
",56.72,61.3,False
"def extract_custom ( extractor , * args , * * kw ) : <TAB> for match in extractor ( * args , * * kw ) : <TAB> <TAB> msg = match [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unused = ( <TAB> <TAB> <TAB> <TAB> "" <unused singular (hash= %s )> "" % md5 ( msg [ 1 ] . encode ( "" utf8 "" ) ) . hexdigest ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> msg = ( unused , msg [ 1 ] , msg [ 2 ] ) <TAB> <TAB> <TAB> match = ( match [ 0 ] , match [ 1 ] , msg , match [ 3 ] ) <TAB> <TAB> yield match ","if isinstance ( msg , tuple ) and msg [ 0 ] == "" "" : 
","if msg [ 0 ] == "" <unused singular (hash= %s )> "" % msg [ 1 ] :
",46.75,26.77,False
"def test_convex_decomposition ( self ) : <TAB> mesh = g . get_mesh ( "" quadknot.obj "" ) <TAB> engines = [ ( "" vhacd "" , g . trimesh . interfaces . vhacd . exists ) ] <TAB> for engine , exists in engines : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . log . warning ( "" skipping convex decomposition engine  %s "" , engine ) <TAB> <TAB> <TAB> continue <TAB> <TAB> g . log . info ( "" Testing convex decomposition with engine  %s "" , engine ) <TAB> <TAB> meshes = mesh . convex_decomposition ( engine = engine ) <TAB> <TAB> self . assertTrue ( len ( meshes ) > 1 ) <TAB> <TAB> for m in meshes : <TAB> <TAB> <TAB> self . assertTrue ( m . is_watertight ) <TAB> <TAB> g . log . info ( "" convex decomposition succeeded with  %s "" , engine ) ","if not exists : 
","if not exists :
",100.0,100.0,True
"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB> <TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB> <TAB> ) <TAB> <TAB> if hasConst : <TAB> <TAB> <TAB> idx - = 1 <TAB> <TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB> <TAB> _lt = _l . __class__ <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ostream . write ( ""  -  "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ostream . write ( ""  +  "" ) ","if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) : 
","if _lt is float :
",34.09,3.16,False
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> if item < 0 : <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> if i < len ( data ) and i > - 1 : <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None ","if is_tuple : 
","if is_tuple :
",78.12,100.0,True
"def process_error ( self , data ) : <TAB> if data . get ( "" error "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AuthCanceled ( self , data . get ( "" error_description "" , "" "" ) ) <TAB> <TAB> raise AuthFailed ( self , data . get ( "" error_description "" ) or data [ "" error "" ] ) <TAB> elif "" denied "" in data : <TAB> <TAB> raise AuthCanceled ( self , data [ "" denied "" ] ) ","if "" denied "" in data [ "" error "" ] or "" cancelled "" in data [ "" error "" ] : 
","if "" error_description "" in data :
",36.1,5.51,False
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> if char == "" > "" : <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" < "" : <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval ","elif char == "" "" : 
","elif char == "" - "" :
",77.33,59.46,False
"def retry_http_digest_auth ( self , req , auth ) : <TAB> token , challenge = auth . split ( "" "" , 1 ) <TAB> chal = parse_keqv_list ( parse_http_list ( challenge ) ) <TAB> auth = self . get_authorization ( req , chal ) <TAB> if auth : <TAB> <TAB> auth_val = "" Digest  %s "" % auth <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> req . add_unredirected_header ( self . auth_header , auth_val ) <TAB> <TAB> resp = self . parent . open ( req ) <TAB> <TAB> return resp ","if req . headers . get ( self . auth_header , None ) == auth_val : 
","if req . headers . get ( self . auth_header , None ) == auth_val :
",100.0,100.0,True
"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB> <TAB> sockname = None <TAB> <TAB> try : <TAB> <TAB> <TAB> sockname = self . sock . getsockname ( ) <TAB> <TAB> except ( socket . error , OSError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> self . sock . close ( ) <TAB> <TAB> if type ( sockname ) is str : <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . remove ( sockname ) <TAB> self . sock = None ","if os . path . exists ( sockname ) : 
","if os . path . exists ( sockname ) :
",100.0,100.0,True
"def to_nurbs ( self , curves ) : <TAB> result = [ ] <TAB> for i , c in enumerate ( curves ) : <TAB> <TAB> nurbs = SvNurbsCurve . to_nurbs ( c ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( f "" Curve # { i }  -  { c }  - can not be converted to NURBS! "" ) <TAB> <TAB> result . append ( nurbs ) <TAB> return result ","if nurbs is None : 
","if not nurbs :
",28.67,16.37,False
"def handle_1_roomid_raffle ( self , i ) : <TAB> if i [ 1 ] in [ "" handle_1_room_TV "" , "" handle_1_room_captain "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . notify ( "" post_watching_history "" , i [ 0 ] ) <TAB> <TAB> <TAB> await self . notify ( i [ 1 ] , i [ 0 ] , i [ 2 ] ) <TAB> else : <TAB> <TAB> print ( "" hhjjkskddrsfvsfdfvdfvvfdvdvdfdfffdfsvh "" , i ) ","if await self . notify ( "" check_if_normal_room "" , i [ 0 ] , - 1 ) : 
","if i [ 2 ] :
",28.81,0.86,False
"def init_ps_var_partition ( self ) : <TAB> ps_vars = { } <TAB> for v in self . _non_embed_vars . values ( ) : <TAB> <TAB> if v . name not in self . _var_to_ps : <TAB> <TAB> <TAB> self . _var_to_ps [ v . name ] = string_to_id ( v . name , self . _ps_num ) <TAB> <TAB> ps_id = self . _var_to_ps [ v . name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ps_vars [ ps_id ] = [ v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ps_vars [ ps_id ] . append ( v ) <TAB> self . _ps_vars = ps_vars ","if ps_id not in ps_vars : 
","if ps_id not in ps_vars :
",100.0,100.0,True
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" qemux86copy- "" in root or "" qemux86- "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f ","if "" do_build "" not in name and "" do_populate_sdk "" not in name : 
","if name . endswith ( "" .py "" ) :
",31.48,2.26,False
"def setSelectedLabelState ( self , p ) :<TAB> # selected, disabled <TAB> c = self . c <TAB> # g.trace(p,c.edit_widget(p)) <TAB> if p and c . edit_widget ( p ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . trace ( self . trace_n , c . edit_widget ( p ) , p ) <TAB> <TAB> <TAB> # g.trace(g.callers(6)) <TAB> <TAB> <TAB> self . trace_n + = 1 <TAB> <TAB> self . setDisabledHeadlineColors ( p ) ","if 0 : 
","if self . trace_n < self . trace_len :
",29.31,3.67,False
"def filter_tasks ( self , task_types = None , task_states = None , task_text = None ) : <TAB> tasks = self . api . tasks ( self . id ) . get ( "" tasks "" , { } ) <TAB> if tasks and tasks . get ( "" task "" ) : <TAB> <TAB> return [ <TAB> <TAB> <TAB> Task ( self , task ) <TAB> <TAB> <TAB> for task in tasks . get ( "" task "" , [ ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> and ( not task_states or task [ "" state "" ] . lower ( ) in task_states ) <TAB> <TAB> <TAB> and ( not task_text or task_text . lower ( ) in str ( task ) . lower ( ) ) <TAB> <TAB> ] <TAB> else : <TAB> <TAB> return [ ] ","if ( not task_types or task [ "" type "" ] . lower ( ) in task_types ) 
","if task [ "" type "" ] . lower ( ) in task_types
",70.28,59.04,False
"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if item < vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> if level + 1 == len ( hits ) : <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result ","if vector : 
","if vector :
",78.12,0.0,False
def _transmit_from_storage ( self ) - > None : <TAB> for blob in self . storage . gets ( ) : <TAB> <TAB> # give a few more seconds for blob lease operation <TAB> <TAB> # to reduce the chance of race (for perf consideration) <TAB> <TAB> if blob . lease ( self . _timeout + 5 ) : <TAB> <TAB> <TAB> envelopes = [ TelemetryItem ( * * x ) for x in blob . get ( ) ] <TAB> <TAB> <TAB> result = self . _transmit ( list ( envelopes ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> blob . lease ( 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> blob . delete ( ) ,"if result == ExportResult . FAILED_RETRYABLE : 
","if result :
",28.89,0.0,False
"def load_dictionary ( file ) : <TAB> oui = { } <TAB> with open ( file , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = line . split ( "" (hex) "" ) <TAB> <TAB> <TAB> <TAB> key = data [ 0 ] . replace ( "" - "" , "" : "" ) . lower ( ) . strip ( ) <TAB> <TAB> <TAB> <TAB> company = data [ 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> oui [ key ] = company <TAB> return oui ","if "" (hex) "" in line : 
","if line . startswith ( "" # "" ) :
",33.22,6.83,False
"def _yield_minibatches_idx ( self , rgen , n_batches , data_ary , shuffle = True ) : <TAB> indices = np . arange ( data_ary . shape [ 0 ] ) <TAB> if shuffle : <TAB> <TAB> indices = rgen . permutation ( indices ) <TAB> if n_batches > 1 : <TAB> <TAB> remainder = data_ary . shape [ 0 ] % n_batches <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> minis = np . array_split ( indices [ : - remainder ] , n_batches ) <TAB> <TAB> <TAB> minis [ - 1 ] = np . concatenate ( ( minis [ - 1 ] , indices [ - remainder : ] ) , axis = 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> minis = np . array_split ( indices , n_batches ) <TAB> else : <TAB> <TAB> minis = ( indices , ) <TAB> for idx_batch in minis : <TAB> <TAB> yield idx_batch ","if remainder : 
","if remainder :
",78.12,0.0,False
"def canonical_custom_headers ( self , headers ) : <TAB> hoi = [ ] <TAB> custom_headers = { } <TAB> for key in headers : <TAB> <TAB> lk = key . lower ( ) <TAB> <TAB> if headers [ key ] is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> custom_headers [ lk ] = "" , "" . join ( v . strip ( ) for v in headers . get_all ( key ) ) <TAB> sorted_header_keys = sorted ( custom_headers . keys ( ) ) <TAB> for key in sorted_header_keys : <TAB> <TAB> hoi . append ( "" %s : %s "" % ( key , custom_headers [ key ] ) ) <TAB> return "" \n "" . join ( hoi ) ","if lk . startswith ( "" x-amz- "" ) : 
","if lk not in custom_headers :
",27.63,9.52,False
"def validate ( self , data ) : <TAB> if not data . get ( "" reason "" ) : <TAB> <TAB> # If reason is not provided, message is required and can not be <TAB> <TAB> # null or blank. <TAB> <TAB> message = data . get ( "" message "" ) <TAB> <TAB> if not message : <TAB> <TAB> <TAB> if "" message "" not in data : <TAB> <TAB> <TAB> <TAB> msg = serializers . Field . default_error_messages [ "" required "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> msg = serializers . Field . default_error_messages [ "" null "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> msg = serializers . CharField . default_error_messages [ "" blank "" ] <TAB> <TAB> <TAB> raise serializers . ValidationError ( { "" message "" : [ msg ] } ) <TAB> return data ","elif message is None : 
","elif "" can not be "" in data :
",27.26,5.67,False
def tearDown ( self ) : <TAB> try : <TAB> <TAB> os . chdir ( self . cwd ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . remove ( self . pythonexe ) <TAB> <TAB> test_support . rmtree ( self . parent_dir ) <TAB> finally : <TAB> <TAB> BaseTestCase . tearDown ( self ) ,"if self . pythonexe != sys . executable : 
","if self . pythonexe :
",51.28,26.01,False
"def update ( self , value , label ) : <TAB> if self . _disabled : <TAB> <TAB> return <TAB> try : <TAB> <TAB> self . _progress . value = value <TAB> <TAB> self . _label . value = label <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _displayed = True <TAB> <TAB> <TAB> display_widget ( self . _widget ) <TAB> except Exception as e : <TAB> <TAB> self . _disabled = True <TAB> <TAB> logger . exception ( e ) <TAB> <TAB> wandb . termwarn ( "" Unable to render progress bar, see the user log for details "" ) ","if not self . _displayed : 
","if not self . _displayed :
",100.0,100.0,True
"def GetBinaryOperationBinder ( self , op ) : <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _binaryOperationBinders [ op ] <TAB> <TAB> b = runtime . SymplBinaryOperationBinder ( op ) <TAB> <TAB> self . _binaryOperationBinders [ op ] = b <TAB> return b ","if self . _binaryOperationBinders . ContainsKey ( op ) : 
","if op in self . _binaryOperationBinders :
",35.58,27.33,False
"def apply ( self , l , b , evaluation ) : <TAB> "" FromDigits[l_, b_] "" <TAB> if l . get_head_name ( ) == "" System`List "" : <TAB> <TAB> value = Integer ( 0 ) <TAB> <TAB> for leaf in l . leaves : <TAB> <TAB> <TAB> value = Expression ( "" Plus "" , Expression ( "" Times "" , value , b ) , leaf ) <TAB> <TAB> return value <TAB> elif isinstance ( l , String ) : <TAB> <TAB> value = FromDigits . _parse_string ( l . get_string_value ( ) , b ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> evaluation . message ( "" FromDigits "" , "" nlst "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value <TAB> else : <TAB> <TAB> evaluation . message ( "" FromDigits "" , "" nlst "" ) ","if value is None : 
","if value is None :
",100.0,100.0,True
"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self . send_queue . get ( True , 6.0 ) <TAB> <TAB> <TAB> if self . socket is not None : <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self . socket . sendall ( request ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . send_queue . task_done ( ) <TAB> <TAB> except queue . Empty : <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> self . stop_event . set ( ) ","if self . send_queue is not None : 
","elif request is not None :
",48.39,26.09,False
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if eline not in rline : 
","if not rline . startswith ( eline ) :
",27.37,7.13,False
"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 , bias = 0 ) ","if isinstance ( m , nn . ConvTranspose2d ) : 
","if isinstance ( m , nn . ConvTranspose2d ) :
",100.0,100.0,True
"def filter_rel_attrs ( field_name , * * rel_attrs ) : <TAB> clean_dict = { } <TAB> for k , v in rel_attrs . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> splitted_key = k . split ( "" __ "" ) <TAB> <TAB> <TAB> key = "" __ "" . join ( splitted_key [ 1 : ] ) <TAB> <TAB> <TAB> clean_dict [ key ] = v <TAB> <TAB> else : <TAB> <TAB> <TAB> clean_dict [ k ] = v <TAB> return clean_dict ","if k . startswith ( field_name + "" __ "" ) : 
","if field_name == "" __ "" :
",33.6,25.12,False
"def cancel ( self ) : <TAB> with self . _condition : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _squash ( <TAB> <TAB> <TAB> <TAB> state_root = self . _previous_state_hash , <TAB> <TAB> <TAB> <TAB> context_ids = [ self . _previous_context_id ] , <TAB> <TAB> <TAB> <TAB> persist = False , <TAB> <TAB> <TAB> <TAB> clean_up = True , <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _cancelled = True <TAB> <TAB> self . _condition . notify_all ( ) ","if not self . _cancelled and not self . _final and self . _previous_context_id : 
","if not self . _cancelled :
",49.76,9.87,False
"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB> <TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> level_ref + = len ( levels ) <TAB> <TAB> if not ( 0 < = level_ref < len ( levels ) ) : <TAB> <TAB> <TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB> <TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) ) ","if level_ref < 0 : 
","if level_ref < 0 :
",100.0,100.0,True
"def parse_node ( self , node , alias_map = None , conv = None ) : <TAB> sql , params , unknown = self . _parse ( node , alias_map , conv ) <TAB> if unknown and conv and params : <TAB> <TAB> params = [ conv . db_value ( i ) for i in params ] <TAB> if isinstance ( node , Node ) : <TAB> <TAB> if node . _negated : <TAB> <TAB> <TAB> sql = "" NOT  %s "" % sql <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sql = "" "" . join ( ( sql , "" AS "" , node . _alias ) ) <TAB> <TAB> if node . _ordering : <TAB> <TAB> <TAB> sql = "" "" . join ( ( sql , node . _ordering ) ) <TAB> return sql , params ","if node . _alias : 
","if node . _alias :
",100.0,100.0,True
"def parse_object_id ( _ , values ) : <TAB> if values : <TAB> <TAB> for key in values : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> val = values [ key ] <TAB> <TAB> <TAB> <TAB> if len ( val ) > 10 : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values [ key ] = utils . ObjectIdSilent ( val ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> values [ key ] = None ","if key . endswith ( "" _id "" ) : 
","if key in ( "" _id "" , "" _id_key "" ) :
",47.19,30.65,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB> rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB> if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB> <TAB> for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not checks . is_cce_value_valid ( "" CCE- "" + str ( i_value ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if i_type [ 0 : 3 ] == "" cce "" : 
","if i_type == "" string "" :
",32.3,25.68,False
"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB> <TAB> <TAB> simple_colorize ( todesc , "" description "" ) , <TAB> <TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB> <TAB> if line is None : <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield line ","if i > 0 : 
","elif i == 0 :
",30.86,17.97,False
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> if "" % "" not in pattern : <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template ","elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : 
","elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" ) :
",72.95,73.15,False
"def ref_max_pooling_2d ( x , kernel , stride , ignore_border , pad ) : <TAB> y = [ ] <TAB> for xx in x . reshape ( ( - 1 , ) + x . shape [ - 3 : ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> xx = xx [ np . newaxis ] <TAB> <TAB> y + = [ <TAB> <TAB> <TAB> refs . pooling_2d ( xx , "" max "" , kernel , stride , pad , ignore_border ) [ np . newaxis ] <TAB> <TAB> ] <TAB> y = np . vstack ( y ) <TAB> if x . ndim == 2 : <TAB> <TAB> y = np . squeeze ( y , 1 ) <TAB> return y . reshape ( x . shape [ : - 3 ] + y . shape [ 1 : ] ) ","if xx . ndim == 2 : 
","if xx . ndim == 2 :
",100.0,100.0,True
"def show_topics ( ) : <TAB> """"""prints all available miscellaneous help topics."""""" <TAB> print ( _stash . text_color ( "" Miscellaneous Topics: "" , "" yellow "" ) ) <TAB> for pp in PAGEPATHS : <TAB> <TAB> if not os . path . isdir ( pp ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> content = os . listdir ( pp ) <TAB> <TAB> for pn in content : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> name = pn [ : pn . index ( "" . "" ) ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = pn <TAB> <TAB> <TAB> print ( name ) ","if "" . "" in pn : 
","if pn . startswith ( "" . "" ) :
",38.92,18.58,False
"def justify_toggle_auto ( self , event = None ) : <TAB> c = self <TAB> if c . editCommands . autojustify == 0 : <TAB> <TAB> c . editCommands . autojustify = abs ( c . config . getInt ( "" autojustify "" ) or 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . es ( "" Autojustify on, @int autojustify ==  %s "" % c . editCommands . autojustify ) <TAB> <TAB> else : <TAB> <TAB> <TAB> g . es ( "" Set @int autojustify in @settings "" ) <TAB> else : <TAB> <TAB> c . editCommands . autojustify = 0 <TAB> <TAB> g . es ( "" Autojustify off "" ) ","if c . editCommands . autojustify : 
","if c . editCommands . autojustify :
",100.0,100.0,True
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> elif token . token_type == TOKEN_VAR : <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> return "" "" . join ( result ) , vars ","if token . token_type == TOKEN_TEXT : 
","if token . token_type == TOKEN_TEXT :
",100.0,100.0,True
"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB> <TAB> if operation [ "" type "" ] == "" crop "" : <TAB> <TAB> <TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB> <TAB> <TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> width = operation [ "" width "" ] <TAB> <TAB> <TAB> height = operation [ "" height "" ] <TAB> return ( width , height ) ","if operation [ "" type "" ] == "" resize "" : 
","elif operation [ "" type "" ] == "" crop_image "" :
",74.47,59.69,False
"def get_eval_matcher ( self ) : <TAB> if isinstance ( self . data [ "" match "" ] , str ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values = [ "" explicitDeny "" , "" implicitDeny "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> values = [ "" allowed "" ] <TAB> <TAB> vf = ValueFilter ( <TAB> <TAB> <TAB> { "" type "" : "" value "" , "" key "" : "" EvalDecision "" , "" value "" : values , "" op "" : "" in "" } <TAB> <TAB> ) <TAB> else : <TAB> <TAB> vf = ValueFilter ( self . data [ "" match "" ] ) <TAB> vf . annotate = False <TAB> return vf ","if self . data [ "" match "" ] == "" denied "" : 
","if self . data [ "" match "" ] . startswith ( "" [ "" ) :
",68.41,51.54,False
"def test_training ( self ) : <TAB> if not self . model_tester . is_training : <TAB> <TAB> return <TAB> config , inputs_dict = self . model_tester . prepare_config_and_inputs_for_common ( ) <TAB> config . return_dict = True <TAB> for model_class in self . all_model_classes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> model = model_class ( config ) <TAB> <TAB> model . to ( torch_device ) <TAB> <TAB> model . train ( ) <TAB> <TAB> inputs = self . _prepare_for_class ( inputs_dict , model_class , return_labels = True ) <TAB> <TAB> loss = model ( * * inputs ) . loss <TAB> <TAB> loss . backward ( ) ","if model_class in MODEL_MAPPING . values ( ) : 
","if model_class . __name__ == "" torch "" :
",32.2,17.61,False
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> elif self . arch == "" amd64 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True ) ","if self . arch == "" i386 "" : 
","if self . arch == "" i386 "" :
",100.0,100.0,True
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize ) ","if size == 0 : 
","if size == 0 :
",100.0,100.0,True
"def __new__ ( cls , dependencies ) : <TAB> deps = check . list_param ( dependencies , "" dependencies "" , of_type = DependencyDefinition ) <TAB> seen = { } <TAB> for dep in deps : <TAB> <TAB> key = dep . solid + "" : "" + dep . output <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise DagsterInvalidDefinitionError ( <TAB> <TAB> <TAB> <TAB> ' Duplicate dependencies on solid  "" {dep.solid} ""  output  "" {dep.output} "" ' <TAB> <TAB> <TAB> <TAB> "" used in the same MultiDependencyDefinition. "" . format ( dep = dep ) <TAB> <TAB> <TAB> ) <TAB> <TAB> seen [ key ] = True <TAB> return super ( MultiDependencyDefinition , cls ) . __new__ ( cls , deps ) ","if key in seen : 
","if key in seen :
",100.0,100.0,True
"def get_explanation ( self , spec ) : <TAB> """"""Expand an explanation."""""" <TAB> if spec : <TAB> <TAB> try : <TAB> <TAB> <TAB> a = self . dns_txt ( spec ) <TAB> <TAB> <TAB> if len ( a ) == 1 : <TAB> <TAB> <TAB> <TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB> <TAB> except PermError : <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise<TAB> # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> elif self . strict > 1 : <TAB> <TAB> raise PermError ( "" Empty domain-spec on exp= "" ) <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None ","if self . strict > 1 : 
","if self . strict == 1 :
",74.63,41.11,False
"def build ( self ) : <TAB> if self . args . get ( "" sle_id "" ) : <TAB> <TAB> self . process_sle_against_current_voucher ( ) <TAB> else : <TAB> <TAB> entries_to_fix = self . get_future_entries_to_fix ( ) <TAB> <TAB> i = 0 <TAB> <TAB> while i < len ( entries_to_fix ) : <TAB> <TAB> <TAB> sle = entries_to_fix [ i ] <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> self . process_sle ( sle ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . get_dependent_entries_to_fix ( entries_to_fix , sle ) <TAB> if self . exceptions : <TAB> <TAB> self . raise_exceptions ( ) <TAB> self . update_bin ( ) ","if sle . dependant_sle_voucher_detail_no : 
","if self . args . get ( "" dependent "" ) :
",35.78,4.1,False
"def ValidateStopLatitude ( self , problems ) : <TAB> if self . stop_lat is not None : <TAB> <TAB> value = self . stop_lat <TAB> <TAB> try : <TAB> <TAB> <TAB> if not isinstance ( value , ( float , int ) ) : <TAB> <TAB> <TAB> <TAB> self . stop_lat = util . FloatStringToFloat ( value , problems ) <TAB> <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> <TAB> problems . InvalidValue ( "" stop_lat "" , value ) <TAB> <TAB> <TAB> del self . stop_lat <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> problems . InvalidValue ( "" stop_lat "" , value ) ","if self . stop_lat > 90 or self . stop_lat < - 90 : 
","if self . stop_lat < 0 :
",47.35,27.61,False
"def set ( self , obj , * * kwargs ) : <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB> <TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k1 in self . combinations [ k ] : <TAB> <TAB> <TAB> <TAB> if not hasattr ( self , k1 ) : <TAB> <TAB> <TAB> <TAB> <TAB> setattr ( self , k1 , ignore ) ","if k in self . combinations : 
","if k in self . combinations :
",100.0,100.0,True
"def split ( self , duration , include_remainder = True ) : <TAB> # Convert seconds to timedelta, if appropriate. <TAB> duration = _seconds_or_timedelta ( duration ) <TAB> if duration < = timedelta ( seconds = 0 ) : <TAB> <TAB> raise ValueError ( "" cannot call split with a non-positive timedelta "" ) <TAB> start = self . start <TAB> while start < self . end : <TAB> <TAB> if start + duration < = self . end : <TAB> <TAB> <TAB> yield MayaInterval ( start , start + duration ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield MayaInterval ( start , self . end ) <TAB> <TAB> start + = duration ","elif include_remainder : 
","if include_remainder and start > self . end :
",28.45,14.99,False
"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB> <TAB> if issubclass ( layout_object . __class__ , clz ) : <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gf = get_first_field ( layout_object , clz ) <TAB> <TAB> <TAB> if gf : <TAB> <TAB> <TAB> <TAB> return gf ","elif hasattr ( layout_object , "" get_field_names "" ) : 
","elif issubclass ( layout_object , clz ) :
",32.11,25.64,False
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> if "" % "" not in pattern : <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template ","if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : 
","if key == "" EPOCH "" :
",38.65,4.7,False
"def findOwningViewController ( self , object ) : <TAB> while object : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> description = fb . evaluateExpressionValue ( object ) . GetObjectDescription ( ) <TAB> <TAB> <TAB> print ( "" Found the owning view controller. \n {} "" . format ( description ) ) <TAB> <TAB> <TAB> cmd = ' echo  {}  | tr -d  "" \n ""  | pbcopy ' . format ( object ) <TAB> <TAB> <TAB> os . system ( cmd ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> object = self . nextResponder ( object ) <TAB> print ( "" Could not find an owning view controller "" ) ","if self . isViewController ( object ) : 
","if fb . evaluateExpressionValue ( object ) :
",69.39,38.26,False
"def __get_file_by_num ( self , num , file_list , idx = 0 ) : <TAB> for element in file_list : <TAB> <TAB> if idx == num : <TAB> <TAB> <TAB> return element <TAB> <TAB> if element [ 3 ] and element [ 4 ] : <TAB> <TAB> <TAB> i = self . __get_file_by_num ( num , element [ 3 ] , idx + 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return i <TAB> <TAB> <TAB> idx = i <TAB> <TAB> else : <TAB> <TAB> <TAB> idx + = 1 <TAB> return idx ","if not isinstance ( i , int ) : 
","if not isinstance ( i , int ) :
",100.0,100.0,True
"def promtool ( * * kwargs ) : <TAB> key = "" prometheus:promtool "" <TAB> try : <TAB> <TAB> path = pathlib . Path ( util . setting ( key ) ) <TAB> except TypeError : <TAB> <TAB> yield checks . Warning ( <TAB> <TAB> <TAB> "" Missing setting for  %s  in  %s "" % ( key , settings . PROMGEN_CONFIG_FILE ) , <TAB> <TAB> <TAB> id = "" promgen.W001 "" , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield checks . Warning ( "" Unable to execute file  %s "" % path , id = "" promgen.W003 "" ) ","if not os . access ( path , os . X_OK ) : 
","if not os . path . exists ( path ) :
",45.94,22.7,False
"def parse_config ( schema , config ) : <TAB> schemaparser = ConfigParser ( ) <TAB> schemaparser . readfp ( StringIO ( schema ) ) <TAB> cfgparser = ConfigParser ( ) <TAB> cfgparser . readfp ( StringIO ( config ) ) <TAB> result = { } <TAB> for section in cfgparser . sections ( ) : <TAB> <TAB> result_section = { } <TAB> <TAB> schema = { } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> schema = dict ( schemaparser . items ( section ) ) <TAB> <TAB> for key , value in cfgparser . items ( section ) : <TAB> <TAB> <TAB> converter = converters [ schema . get ( key , "" string "" ) ] <TAB> <TAB> <TAB> result_section [ key ] = converter ( value ) <TAB> <TAB> result [ section ] = result_section <TAB> return result ","if section in schemaparser . sections ( ) : 
","if section . startswith ( "" schema "" ) :
",32.84,13.13,False
"def validate_arguments ( args ) : <TAB> if args . num_pss < 1 : <TAB> <TAB> print ( "" Value error: must have ore than one parameter servers. "" ) <TAB> <TAB> exit ( 1 ) <TAB> if not GPU_IDS : <TAB> <TAB> num_cpus = multiprocessing . cpu_count ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Value error: there are  %s  available CPUs but you are requiring  %s . "" <TAB> <TAB> <TAB> <TAB> % ( num_cpus , args . cpu_trainers ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> exit ( 1 ) <TAB> if not os . path . isfile ( args . file ) : <TAB> <TAB> print ( "" Value error: model trainning file does not exist "" ) <TAB> <TAB> exit ( 1 ) ","if args . cpu_trainers > num_cpus : 
","if num_cpus != args . cpu_trainers :
",41.04,44.83,False
"def infer_dataset_impl ( path ) : <TAB> if IndexedRawTextDataset . exists ( path ) : <TAB> <TAB> return "" raw "" <TAB> elif IndexedDataset . exists ( path ) : <TAB> <TAB> with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB> <TAB> <TAB> magic = f . read ( 8 ) <TAB> <TAB> <TAB> if magic == IndexedDataset . _HDR_MAGIC : <TAB> <TAB> <TAB> <TAB> return "" cached "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return "" mmap "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return None <TAB> elif FastaDataset . exists ( path ) : <TAB> <TAB> return "" fasta "" <TAB> else : <TAB> <TAB> return None ","elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] : 
","elif magic == FastaDataset . _HDR_MAGIC :
",33.54,34.97,False
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> if item_key != "" sourceVault "" : <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] ) ","if obj [ "" id "" ] : 
","if "" id "" in obj :
",39.66,25.2,False
"def reformatBody ( self , event = None ) : <TAB> """"""Reformat all paragraphs in the body."""""" <TAB> c , p = self , self . p <TAB> undoType = "" reformat-body "" <TAB> w = c . frame . body . wrapper <TAB> c . undoer . beforeChangeGroup ( p , undoType ) <TAB> w . setInsertPoint ( 0 ) <TAB> while 1 : <TAB> <TAB> progress = w . getInsertPoint ( ) <TAB> <TAB> c . reformatParagraph ( event , undoType = undoType ) <TAB> <TAB> ins = w . getInsertPoint ( ) <TAB> <TAB> s = w . getAllText ( ) <TAB> <TAB> w . setInsertPoint ( ins ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> c . undoer . afterChangeGroup ( p , undoType ) ","if ins < = progress or ins > = len ( s ) : 
","if s == ins :
",25.85,3.35,False
"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB> <TAB> content . append ( project . readme . path . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB> <TAB> if ( path / fname ) . exists ( ) : <TAB> <TAB> <TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB> <TAB> for fpath in package : <TAB> <TAB> <TAB> fpath = fpath . relative_to ( project . package . path ) <TAB> <TAB> <TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content ) ","if project . readme . markup != "" rst "" : 
","if project . package :
",34.08,10.54,False
"def __init__ ( self , response ) : <TAB> error = "" {} {} "" . format ( response . status_code , response . reason ) <TAB> extra = [ ] <TAB> try : <TAB> <TAB> response_json = response . json ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error = "" "" . join ( error [ "" message "" ] for error in response_json [ "" error_list "" ] ) <TAB> <TAB> <TAB> extra = [ <TAB> <TAB> <TAB> <TAB> error [ "" extra "" ] <TAB> <TAB> <TAB> <TAB> for error in response_json [ "" error_list "" ] <TAB> <TAB> <TAB> <TAB> if "" extra "" in error <TAB> <TAB> <TAB> ] <TAB> except JSONDecodeError : <TAB> <TAB> pass <TAB> super ( ) . __init__ ( response = response , error = error , extra = extra ) ","if "" error_list "" in response_json : 
","if "" error_list "" in response_json :
",100.0,100.0,True
"def handle_event ( self , fileno = None , events = None ) : <TAB> if self . _state == RUN : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _it = self . _process_result ( 0 )<TAB> # non-blocking <TAB> <TAB> try : <TAB> <TAB> <TAB> next ( self . _it ) <TAB> <TAB> except ( StopIteration , CoroStop ) : <TAB> <TAB> <TAB> self . _it = None ","if self . _it is None : 
","if self . _it is None :
",100.0,100.0,True
"def find_query ( self , needle , haystack ) : <TAB> try : <TAB> <TAB> import pinyin <TAB> <TAB> haystack_py = pinyin . get_initial ( haystack , "" "" ) <TAB> <TAB> needle_len = len ( needle ) <TAB> <TAB> start = 0 <TAB> <TAB> result = [ ] <TAB> <TAB> while True : <TAB> <TAB> <TAB> found = haystack_py . find ( needle , start ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> result . append ( ( found , needle_len ) ) <TAB> <TAB> <TAB> start = found + needle_len <TAB> <TAB> return result <TAB> except : <TAB> <TAB> return None ","if found < 0 : 
","if found == - 1 :
",30.74,14.54,False
"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable ( result ) : <TAB> <TAB> <TAB> <TAB> result = result ( rv ) <TAB> <TAB> <TAB> if not isinstance ( result , basestring ) : <TAB> <TAB> <TAB> <TAB> from werkzeug . http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date ( result ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> rv . headers [ "" Last-Modified "" ] = result <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . getLogger ( __name__ ) . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv ","if result : 
","if result > = date . today ( ) :
",32.88,9.29,False
"def check_require ( require_modules , require_lines ) : <TAB> for require_module in require_modules : <TAB> <TAB> st = try_import ( require_module ) <TAB> <TAB> if st == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" installed  {} :  {} \n "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> require_module , require_lines [ require_module ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif st == 2 : <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" failed installed  {} :  {} \n "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> require_module , require_lines [ require_module ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","elif st == 1 : 
","elif st == 1 :
",100.0,100.0,True
"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> if nm . startswith ( "" . "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . bundle_module ( itempath ) ","elif nm . endswith ( "" .py "" ) : 
","elif os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) :
",38.37,11.43,False
"def _find_root ( ) : <TAB> test_dirs = [ "" Src "" , "" Build "" , "" Package "" , "" Tests "" , "" Util "" ] <TAB> root = os . getcwd ( ) <TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> while not test : <TAB> <TAB> last_root = root <TAB> <TAB> root = os . path . dirname ( root ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Root not found "" ) <TAB> <TAB> test = all ( [ os . path . exists ( os . path . join ( root , x ) ) for x in test_dirs ] ) <TAB> return root ","if root == last_root : 
","if root == last_root :
",100.0,100.0,True
"def findMarkForUnitTestNodes ( self ) : <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB> <TAB> if p . v in seen : <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> seen . append ( p . v ) <TAB> <TAB> <TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result . append ( p . copy ( ) ) <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> p . moveToThreadNext ( ) <TAB> return result ","elif p . h . startswith ( "" @mark-for-unit-tests "" ) : 
","elif g . match_word ( p . h , 0 , "" @mark-for-unit-test "" ) :
",41.36,15.59,False
"def startTagFrameset ( self , token ) : <TAB> self . parser . parseError ( "" unexpected-start-tag "" , { "" name "" : "" frameset "" } ) <TAB> if len ( self . tree . openElements ) == 1 or self . tree . openElements [ 1 ] . name != "" body "" : <TAB> <TAB> assert self . parser . innerHTML <TAB> elif not self . parser . framesetOK : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . tree . openElements [ 1 ] . parent . removeChild ( self . tree . openElements [ 1 ] ) <TAB> <TAB> while self . tree . openElements [ - 1 ] . name != "" html "" : <TAB> <TAB> <TAB> self . tree . openElements . pop ( ) <TAB> <TAB> self . tree . insertElement ( token ) <TAB> <TAB> self . parser . phase = self . parser . phases [ "" inFrameset "" ] ","if self . tree . openElements [ 1 ] . parent : 
","if self . tree . openElements [ 1 ] . parent :
",100.0,100.0,True
"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int ( i , 2 ) <TAB> <TAB> if val > 255 or val < 0 : <TAB> <TAB> <TAB> return None <TAB> <TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB> <TAB> ret = bytes ( ret ) <TAB> <TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB> <TAB> return ret ","if len ( i ) == 0 : 
","if i == "" "" :
",27.09,12.41,False
"def generator ( self , data ) : <TAB> for sock in data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> offset = sock . obj_offset <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = sock . obj_vm . vtop ( sock . obj_offset ) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> Address ( offset ) , <TAB> <TAB> <TAB> <TAB> int ( sock . Pid ) , <TAB> <TAB> <TAB> <TAB> int ( sock . LocalPort ) , <TAB> <TAB> <TAB> <TAB> int ( sock . Protocol ) , <TAB> <TAB> <TAB> <TAB> str ( protos . protos . get ( sock . Protocol . v ( ) , "" - "" ) ) , <TAB> <TAB> <TAB> <TAB> str ( sock . LocalIpAddress ) , <TAB> <TAB> <TAB> <TAB> str ( sock . CreateTime ) , <TAB> <TAB> <TAB> ] , <TAB> <TAB> ) ","if not self . _config . PHYSICAL_OFFSET : 
","if isinstance ( sock . obj_vm , vm_base . VirtAddress ) :
",31.58,3.83,False
"def __init__ ( self , num_bits = 4 , always_apply = False , p = 0.5 ) : <TAB> super ( Posterize , self ) . __init__ ( always_apply , p ) <TAB> if isinstance ( num_bits , ( list , tuple ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . num_bits = [ to_tuple ( i , 0 ) for i in num_bits ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . num_bits = to_tuple ( num_bits , 0 ) <TAB> else : <TAB> <TAB> self . num_bits = to_tuple ( num_bits , num_bits ) ","if len ( num_bits ) == 3 : 
","if len ( num_bits ) == 2 :
",85.56,80.71,False
"def tearDown ( self ) : <TAB> """"""Just in case yn00 creates some junk files, do a clean-up."""""" <TAB> del_files = [ self . out_file , "" 2YN.dN "" , "" 2YN.dS "" , "" 2YN.t "" , "" rst "" , "" rst1 "" , "" rub "" ] <TAB> for filename in del_files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> if os . path . exists ( self . working_dir ) : <TAB> <TAB> for filename in os . listdir ( self . working_dir ) : <TAB> <TAB> <TAB> filepath = os . path . join ( self . working_dir , filename ) <TAB> <TAB> <TAB> os . remove ( filepath ) <TAB> <TAB> os . rmdir ( self . working_dir ) ","if os . path . exists ( filename ) : 
","if os . path . exists ( filename ) :
",100.0,100.0,True
"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB> if startpos is None : <TAB> <TAB> startpos = self . history_cursor <TAB> if _ignore_leading_spaces : <TAB> <TAB> res = [ <TAB> <TAB> <TAB> ( idx , line . lstrip ( ) ) <TAB> <TAB> <TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> else : <TAB> <TAB> res = [ <TAB> <TAB> <TAB> ( idx , line ) <TAB> <TAB> <TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB> <TAB> <TAB> if line . startswith ( searchfor ) <TAB> <TAB> ] <TAB> if res : <TAB> <TAB> self . history_cursor - = res [ 0 ] [ 0 ] <TAB> <TAB> return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB> return "" "" ","if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ) 
","if line . startswith ( searchfor . lstrip ( ) )
",72.75,62.81,False
"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB> <TAB> if not win . ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) : <TAB> <TAB> <TAB> bugs . append ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win , <TAB> <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> <TAB> <TAB> { } , <TAB> <TAB> <TAB> <TAB> <TAB> testname , <TAB> <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs ","if win . Class ( ) != "" ComboBox "" or win . ref . Class ( ) != "" ComboBox "" : 
","if win . ref . ComboBoxHeight ( ) == 0 :
",42.62,11.35,False
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> if result == self . source : <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not self . _is_expression ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( ) ","if start < last_end : 
","if end != last_end :
",56.5,36.56,False
"def unpickle_from_file ( file_path , gzip = False ) : <TAB> """"""Unpickle obj from file_path with gzipping."""""" <TAB> with tf . io . gfile . GFile ( file_path , "" rb "" ) as f : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> obj = pickle . load ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with gzip_lib . GzipFile ( fileobj = f , compresslevel = 2 ) as gzipf : <TAB> <TAB> <TAB> <TAB> obj = pickle . load ( gzipf ) <TAB> return obj ","if not gzip : 
","if gzip :
",34.18,0.0,False
"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB> <TAB> user = getattr ( request , "" user "" , None ) <TAB> <TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB> <TAB> if user and user . is_authenticated ( ) : <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" email "" : user . email , <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : user . id , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ "" name "" ] = user . name <TAB> else : <TAB> <TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) ) ","if user . name : 
","if escape :
",28.55,0.0,False
"def get_item_address ( self , item ) : <TAB> """"""Get an item's address as a collection of names"""""" <TAB> result = [ ] <TAB> while True : <TAB> <TAB> name = self . tree_ctrl . GetItemPyData ( item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> result . insert ( 0 , name ) <TAB> <TAB> <TAB> item = self . tree_ctrl . GetItemParent ( item ) <TAB> return result ","if name is None : 
","if not name :
",28.67,16.37,False
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB> <TAB> for col in range ( self . width ) : <TAB> <TAB> <TAB> if filter is None or ( row , col ) not in filter : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen ","if self . map [ row ] [ col ] == UNSEEN : 
","if self . distance is not None :
",33.44,10.43,False
"def log_graph ( self , model : LightningModule , input_array = None ) : <TAB> if self . _log_graph : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> input_array = model . example_input_array <TAB> <TAB> if input_array is not None : <TAB> <TAB> <TAB> input_array = model . _apply_batch_transfer_handler ( input_array ) <TAB> <TAB> <TAB> self . experiment . add_graph ( model , input_array ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> "" Could not log computational graph since the "" <TAB> <TAB> <TAB> <TAB> ""  `model.example_input_array` attribute is not set "" <TAB> <TAB> <TAB> <TAB> ""  or `input_array` was not given "" , <TAB> <TAB> <TAB> <TAB> UserWarning , <TAB> <TAB> <TAB> ) ","if input_array is None : 
","if input_array is None :
",100.0,100.0,True
"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB> <TAB> if not len ( scene_exception ) == 2 : <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions ","if season == scene_season : 
","if scene_season == self . scene_season or scene_season == season :
",36.05,14.4,False
def _clean_temp_files ( ) : <TAB> for pattern in _temp_files : <TAB> <TAB> for path in glob . glob ( pattern ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . remove ( path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( path ) ,"if os . path . islink ( path ) or os . path . isfile ( path ) : 
","if os . path . isfile ( path ) :
",48.7,40.66,False
"def wait_for_completion ( self , job_id , offset , max_results , start_time , timeout ) : <TAB> """"""Wait for job completion and return the first page."""""" <TAB> while True : <TAB> <TAB> result = self . get_query_results ( <TAB> <TAB> <TAB> job_id = job_id , page_token = None , start_index = offset , max_results = max_results <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return result <TAB> <TAB> if ( time . time ( ) - start_time ) > timeout : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Timeout: the query doesn ' t finish within  %d  seconds. "" % timeout <TAB> <TAB> <TAB> ) <TAB> <TAB> time . sleep ( 1 ) ","if result [ "" jobComplete "" ] : 
","if result :
",28.07,0.0,False
"def get_data ( self , element , ranges , style ) : <TAB> <MASK> <TAB> <TAB> groups = element . groupby ( element . kdims ) . items ( ) <TAB> else : <TAB> <TAB> groups = [ ( element . label , element ) ] <TAB> plots = [ ] <TAB> axis = "" x "" if self . invert_axes else "" y "" <TAB> for key , group in groups : <TAB> <TAB> if element . kdims : <TAB> <TAB> <TAB> label = "" , "" . join ( [ d . pprint_value ( v ) for d , v in zip ( element . kdims , key ) ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> label = key <TAB> <TAB> data = { axis : group . dimension_values ( group . vdims [ 0 ] ) , "" name "" : label } <TAB> <TAB> plots . append ( data ) <TAB> return plots ","if element . kdims : 
","if element . kdims :
",100.0,100.0,True
"def get_files ( self , dirname ) : <TAB> if not self . _data . has_key ( dirname ) : <TAB> <TAB> self . _create ( dirname ) <TAB> else : <TAB> <TAB> new_time = self . _changed ( dirname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _update ( dirname , new_time ) <TAB> <TAB> <TAB> dcLog . debug ( "" ==>  "" + "" \t \n "" . join ( self . _data [ dirname ] [ "" flist "" ] ) ) <TAB> return self . _data [ dirname ] [ "" flist "" ] ","if new_time : 
","if new_time is not None :
",34.04,36.56,False
"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . module_names . add ( name [ : - 3 ] ) <TAB> <TAB> elif "" . "" not in name : <TAB> <TAB> <TAB> self . module_names . add ( name ) ","if name . endswith ( "" .py "" ) : 
","if name . endswith ( "" .py "" ) and "" __init__ "" in name :
",77.42,44.32,False
"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> if enable : <TAB> <TAB> <TAB> <TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation ","if reset == ACTIVE_LOW : 
","if reset == ACTIVE_LOW :
",100.0,100.0,True
"def sortkeypicker ( keynames ) : <TAB> negate = set ( ) <TAB> for i , k in enumerate ( keynames ) : <TAB> <TAB> if k [ : 1 ] == "" - "" : <TAB> <TAB> <TAB> keynames [ i ] = k [ 1 : ] <TAB> <TAB> <TAB> negate . add ( k [ 1 : ] ) <TAB> def getit ( adict ) : <TAB> <TAB> composite = [ adict [ k ] for k in keynames ] <TAB> <TAB> for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> composite [ i ] = - v <TAB> <TAB> return composite <TAB> return getit ","if k in negate : 
","if k not in negate :
",64.71,37.99,False
"def show_image ( self , wnd_name , img ) : <TAB> if wnd_name in self . named_windows : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . named_windows [ wnd_name ] = 1 <TAB> <TAB> <TAB> self . on_create_window ( wnd_name ) <TAB> <TAB> <TAB> if wnd_name in self . capture_mouse_windows : <TAB> <TAB> <TAB> <TAB> self . capture_mouse ( wnd_name ) <TAB> <TAB> self . on_show_image ( wnd_name , img ) <TAB> else : <TAB> <TAB> print ( "" show_image: named_window  "" , wnd_name , ""  not found. "" ) ","if self . named_windows [ wnd_name ] == 0 : 
","if not self . named_windows [ wnd_name ] :
",63.25,66.06,False
"def check_action_permitted ( self ) : <TAB> if ( <TAB> <TAB> self . _action == "" sts:GetCallerIdentity "" <TAB> ) :<TAB> # always allowed, even if there's an explicit Deny for it <TAB> <TAB> return True <TAB> policies = self . _access_key . collect_policies ( ) <TAB> permitted = False <TAB> for policy in policies : <TAB> <TAB> iam_policy = IAMPolicy ( policy ) <TAB> <TAB> permission_result = iam_policy . is_action_permitted ( self . _action ) <TAB> <TAB> if permission_result == PermissionResult . DENIED : <TAB> <TAB> <TAB> self . _raise_access_denied ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> permitted = True <TAB> if not permitted : <TAB> <TAB> self . _raise_access_denied ( ) ","elif permission_result == PermissionResult . PERMITTED : 
","elif permission_result == PermissionResult . ALLOWED :
",82.41,78.25,False
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB> <TAB> <TAB> if config [ key ] [ "" inverse "" ] is True : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) - limit <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if ( datetime . now ( ) + limit ) < value : <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) + limit <TAB> <TAB> elif value > limit : <TAB> <TAB> <TAB> value = limit <TAB> return value ","if ( datetime . now ( ) - limit ) > value : 
","if ( datetime . now ( ) - limit ) > value :
",100.0,100.0,True
"def replace_dataset_ids ( path , key , value ) : <TAB> """"""Exchanges dataset_ids (HDA, LDA, HDCA, not Dataset) in input_values with dataset ids used in job."""""" <TAB> current_case = input_values <TAB> if key == "" id "" : <TAB> <TAB> for i , p in enumerate ( path ) : <TAB> <TAB> <TAB> if isinstance ( current_case , ( list , dict ) ) : <TAB> <TAB> <TAB> <TAB> current_case = current_case [ p ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return key , translate_values . get ( current_case [ "" id "" ] , value ) <TAB> return key , value ","if src == current_case . get ( "" src "" ) : 
","if i == len ( path ) - 1 :
",26.33,6.86,False
"def load_ext ( name , funcs ) : <TAB> ExtModule = namedtuple ( "" ExtModule "" , funcs ) <TAB> ext_list = [ ] <TAB> lib_root = os . path . dirname ( os . path . dirname ( os . path . realpath ( __file__ ) ) ) <TAB> for fun in funcs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ext_list . append ( extension . load ( fun , name , lib_dir = lib_root ) . op_ ) <TAB> return ExtModule ( * ext_list ) ","if fun in [ "" nms "" , "" softnms "" ] : 
","if isinstance ( fun , str ) :
",26.11,4.18,False
"def execute_action ( self ) : <TAB> selected_actions = self . model_action . get_selected_results_with_index ( ) <TAB> if selected_actions and self . args_for_action : <TAB> <TAB> for name , _ , act_idx in selected_actions : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> action = self . actions [ act_idx ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> action . act ( [ arg for arg , _ , _ in self . args_for_action ] , self ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> debug . log ( "" execute_action "" , e ) ","if action : 
","if action :
",78.12,0.0,False
"def __getattr__ ( self , attr ) : <TAB> proxy = self . __proxy <TAB> if proxy and hasattr ( proxy , attr ) : <TAB> <TAB> return getattr ( proxy , attr ) <TAB> attrmap = self . __attrmap <TAB> if attr in attrmap : <TAB> <TAB> source = attrmap [ attr ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = source ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = _import_object ( source ) <TAB> <TAB> setattr ( self , attr , value ) <TAB> <TAB> self . __log . debug ( "" loaded lazy attr  %r :  %r "" , attr , value ) <TAB> <TAB> return value <TAB> raise AttributeError ( "" ' module '  object has no attribute  ' %s ' "" % ( attr , ) ) ","if callable ( source ) : 
","if callable ( source ) :
",100.0,100.0,True
"def forward ( self , x ) : <TAB> # BxT -> BxCxT <TAB> x = x . unsqueeze ( 1 ) <TAB> for conv in self . conv_layers : <TAB> <TAB> residual = x <TAB> <TAB> x = conv ( x ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tsz = x . size ( 2 ) <TAB> <TAB> <TAB> r_tsz = residual . size ( 2 ) <TAB> <TAB> <TAB> residual = residual [ . . . , : : r_tsz / / tsz ] [ . . . , : tsz ] <TAB> <TAB> <TAB> x = ( x + residual ) * self . residual_scale <TAB> if self . log_compression : <TAB> <TAB> x = x . abs ( ) <TAB> <TAB> x = x + 1 <TAB> <TAB> x = x . log ( ) <TAB> return x ","if self . skip_connections and x . size ( 1 ) == residual . size ( 1 ) : 
","if self . log_compression :
",33.73,3.26,False
"def __Prefix_Step2a ( self , token ) : <TAB> for prefix in self . __prefix_step2a : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> token = token [ len ( prefix ) : ] <TAB> <TAB> <TAB> self . prefix_step2a_success = True <TAB> <TAB> <TAB> break <TAB> return token ","if token . startswith ( prefix ) and len ( token ) > 5 : 
","if token . startswith ( prefix ) :
",55.46,36.24,False
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> if s is None : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : 
","elif isinstance ( s , str ) and s . name != "" __class__ "" :
",39.79,21.89,False
"def get_all_comments ( self , gallery_id , post_no , comment_cnt ) : <TAB> comment_page_cnt = ( comment_cnt - 1 ) / / self . options . comments_per_page + 1 <TAB> comments = [ ] <TAB> headers = { "" X-Requested-With "" : "" XMLHttpRequest "" } <TAB> data = { "" ci_t "" : self . _session . cookies [ "" ci_c "" ] , "" id "" : gallery_id , "" no "" : post_no } <TAB> for i in range ( comment_page_cnt ) : <TAB> <TAB> data [ "" comment_page "" ] = i + 1 <TAB> <TAB> response = self . request_comment ( headers , data ) <TAB> <TAB> batch = self . parse_comments ( response . text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> comments = batch + comments <TAB> return comments ","if not batch : 
","if not batch :
",100.0,100.0,True
def run_on_module ( self ) : <TAB> try : <TAB> <TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if e . no_match_group_specs or e . error_group_specs : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e . module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e . module_depsolv_errors [ 1 ] <TAB> <TAB> <TAB> <TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger . error ( str ( e ) ) ,"if self . base . conf . strict : 
","if self . opts . module_spec :
",42.05,20.16,False
"def find_field_notnull_differ ( self , meta , table_description , table_name ) : <TAB> if not self . can_detect_notnull_differ : <TAB> <TAB> return <TAB> for field in all_local_fields ( meta ) : <TAB> <TAB> attname = field . db_column or field . attname <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> null = self . get_field_db_nullable ( field , table_name ) <TAB> <TAB> if field . null != null : <TAB> <TAB> <TAB> action = field . null and "" DROP "" or "" SET "" <TAB> <TAB> <TAB> self . add_difference ( "" notnull-differ "" , table_name , attname , action ) ","if ( table_name , attname ) in self . new_db_fields : 
","if attname in self . ignore_fields :
",35.73,13.19,False
"def _change_moving_module ( self , changes , dest ) : <TAB> if not self . source . is_folder ( ) : <TAB> <TAB> pymodule = self . pycore . resource_to_pyobject ( self . source ) <TAB> <TAB> source = self . import_tools . relatives_to_absolutes ( pymodule ) <TAB> <TAB> pymodule = self . tools . new_pymodule ( pymodule , source ) <TAB> <TAB> source = self . _change_occurrences_in_module ( dest , pymodule ) <TAB> <TAB> source = self . tools . new_source ( pymodule , source ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> changes . add_change ( ChangeContents ( self . source , source ) ) ","if source != self . source . read ( ) : 
","if self . source != source :
",35.03,22.53,False
"def get ( quality_name ) : <TAB> """"""Returns a quality object based on canonical quality name."""""" <TAB> found_components = { } <TAB> for part in quality_name . lower ( ) . split ( ) : <TAB> <TAB> component = _registry . get ( part ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" ` %s ` is not a valid quality string "" % part ) <TAB> <TAB> if component . type in found_components : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" ` %s ` cannot be defined twice in a quality "" % component . type <TAB> <TAB> <TAB> ) <TAB> <TAB> found_components [ component . type ] = component <TAB> if not found_components : <TAB> <TAB> raise ValueError ( "" No quality specified "" ) <TAB> result = Quality ( ) <TAB> for type , component in found_components . items ( ) : <TAB> <TAB> setattr ( result , type , component ) <TAB> return result ","if not component : 
","if not component :
",100.0,100.0,True
def _unselected ( self ) : <TAB> selected = self . _selected <TAB> k = 0 <TAB> z = selected [ k ] <TAB> k + = 1 <TAB> for i in range ( self . _n ) : <TAB> <TAB> if i == z : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> z = selected [ k ] <TAB> <TAB> <TAB> <TAB> k + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> z = - 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> yield i ,"if k < len ( selected ) : 
","if selected [ k ] > 0 :
",27.04,7.81,False
"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b "" Content-Disposition: form-data;  "" , <TAB> <TAB> <TAB> format_form_param ( "" name "" , self . name ) , <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB> <TAB> <TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB> <TAB> if self . content_type is not None : <TAB> <TAB> <TAB> content_type = self . content_type . encode ( ) <TAB> <TAB> <TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB> <TAB> parts . append ( b "" \r \n \r \n "" ) <TAB> <TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers ","if self . filename : 
","if self . filename is not None :
",60.15,36.56,False
"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB> <TAB> if not hasattr ( request , "" app "" ) : <TAB> <TAB> <TAB> request . app = None <TAB> <TAB> <TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> auth_prefix , auth_token = auth <TAB> <TAB> <TAB> <TAB> if auth_prefix . lower ( ) == prefix : <TAB> <TAB> <TAB> <TAB> <TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs ) ","if len ( auth ) == 2 : 
","if len ( auth ) == 2 :
",100.0,100.0,True
"def _shortest_hypernym_paths ( self , simulate_root ) : <TAB> if self . offset == "" 00000000 "" : <TAB> <TAB> return { self : 0 } <TAB> queue = deque ( [ ( self , 0 ) ] ) <TAB> path = { } <TAB> while queue : <TAB> <TAB> s , depth = queue . popleft ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> path [ s ] = depth <TAB> <TAB> depth + = 1 <TAB> <TAB> queue . extend ( ( hyp , depth ) for hyp in s . _hypernyms ( ) ) <TAB> if simulate_root : <TAB> <TAB> root = Synset ( self . _wordnet_corpus_reader , None , self . pos ( ) , "" 00000000 "" , "" "" ) <TAB> <TAB> path [ root ] = max ( path . values ( ) ) + 1 <TAB> return path ","if s in path : 
","if s is None :
",31.2,23.64,False
"def _populate_class_variables ( ) : <TAB> lookup = { } <TAB> reverse_lookup = { } <TAB> characters_for_re = [ ] <TAB> for codepoint , name in list ( codepoint2name . items ( ) ) : <TAB> <TAB> character = chr ( codepoint ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # There's no point in turning the quotation mark into <TAB> <TAB> <TAB> # &quot;, unless it happens within an attribute value, which <TAB> <TAB> <TAB> # is handled elsewhere. <TAB> <TAB> <TAB> characters_for_re . append ( character ) <TAB> <TAB> <TAB> lookup [ character ] = name <TAB> <TAB> # But we do want to turn &quot; into the quotation mark. <TAB> <TAB> reverse_lookup [ name ] = character <TAB> re_definition = "" [ %s ] "" % "" "" . join ( characters_for_re ) <TAB> return lookup , reverse_lookup , re . compile ( re_definition ) ","if codepoint != 34 : 
","if codepoint > 0 :
",56.5,19.36,False
"def prepare_data_status ( self , view : sublime . View , data : Dict [ str , Any ] ) - > Any : <TAB> """"""Prepare the returned data for status"""""" <TAB> if ( <TAB> <TAB> data [ "" success "" ] <TAB> <TAB> and "" No docstring "" not in data [ "" doc "" ] <TAB> <TAB> and data [ "" doc "" ] != "" list \n "" <TAB> ) : <TAB> <TAB> self . signature = data [ "" doc "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> try : <TAB> <TAB> <TAB> self . signature = self . signature . splitlines ( ) [ 2 ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return <TAB> <TAB> return self . _show_status ( view ) ","if self . _signature_excluded ( self . signature ) : 
","if not self . signature :
",39.44,10.69,False
"def _setup_once_tables ( cls ) : <TAB> if cls . run_define_tables == "" once "" : <TAB> <TAB> cls . define_tables ( cls . metadata ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . metadata . create_all ( cls . bind ) <TAB> <TAB> cls . tables . update ( cls . metadata . tables ) ","if cls . run_create_tables == "" once "" : 
","if not cls . metadata . has_create_all :
",33.18,14.6,False
"def _send_recursive ( self , files ) : <TAB> for base in files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # filename mixed into the bunch <TAB> <TAB> <TAB> self . _send_files ( [ base ] ) <TAB> <TAB> <TAB> continue <TAB> <TAB> last_dir = asbytes ( base ) <TAB> <TAB> for root , dirs , fls in os . walk ( base ) : <TAB> <TAB> <TAB> self . _chdir ( last_dir , asbytes ( root ) ) <TAB> <TAB> <TAB> self . _send_files ( [ os . path . join ( root , f ) for f in fls ] ) <TAB> <TAB> <TAB> last_dir = asbytes ( root ) <TAB> <TAB> # back out of the directory <TAB> <TAB> for i in range ( len ( os . path . split ( last_dir ) ) ) : <TAB> <TAB> <TAB> self . _send_popd ( ) ","if not os . path . isdir ( base ) : 
","if isinstance ( base , str ) :
",28.01,11.35,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ) . __init__ ( * args , * * kwargs ) <TAB> # Automatically register models if required. <TAB> if not is_registered ( self . model ) : <TAB> <TAB> inline_fields = ( ) <TAB> <TAB> for inline in self . inlines : <TAB> <TAB> <TAB> inline_model , follow_field = self . _reversion_introspect_inline_admin ( inline ) <TAB> <TAB> <TAB> if inline_model : <TAB> <TAB> <TAB> <TAB> self . _reversion_autoregister ( inline_model , ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> inline_fields + = ( follow_field , ) <TAB> <TAB> self . _reversion_autoregister ( self . model , inline_fields ) ","if follow_field : 
","if follow_field :
",78.12,100.0,True
"def dispatch_hook ( key , hooks , hook_data , * * kwargs ) : <TAB> """"""Dispatches a hook dictionary on a given piece of data."""""" <TAB> hooks = hooks or dict ( ) <TAB> hooks = hooks . get ( key ) <TAB> if hooks : <TAB> <TAB> if hasattr ( hooks , "" __call__ "" ) : <TAB> <TAB> <TAB> hooks = [ hooks ] <TAB> <TAB> for hook in hooks : <TAB> <TAB> <TAB> _hook_data = hook ( hook_data , * * kwargs ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> hook_data = _hook_data <TAB> return hook_data ","if _hook_data is not None : 
","if _hook_data is not None :
",100.0,100.0,True
"def __call__ ( self , image , crop = True ) : <TAB> if isinstance ( image , PTensor ) : <TAB> <TAB> return self . crop_to_output ( <TAB> <TAB> <TAB> numpy_to_paddle ( self ( paddle_to_numpy ( image ) , crop = False ) ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> warp = cv . warpAffine ( <TAB> <TAB> <TAB> image , <TAB> <TAB> <TAB> self . transform_matrix , <TAB> <TAB> <TAB> image . shape [ 1 : : - 1 ] , <TAB> <TAB> <TAB> borderMode = cv . BORDER_REPLICATE , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . crop_to_output ( warp ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return warp ","if crop : 
","if crop :
",78.12,0.0,False
"def _analyze ( self ) : <TAB> lines = open ( self . log_path , "" r "" ) . readlines ( ) <TAB> prev_line = None <TAB> for line in lines : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . errors . append ( line [ len ( "" ERROR: "" ) : ] . strip ( ) ) <TAB> <TAB> elif line . startswith ( "" FAIL: "" ) and prev_line and prev_line . startswith ( "" = "" ) : <TAB> <TAB> <TAB> self . failures . append ( line [ len ( "" FAIL: "" ) : ] . strip ( ) ) <TAB> <TAB> prev_line = line ","if line . startswith ( "" ERROR: "" ) and prev_line and prev_line . startswith ( "" = "" ) : 
","if line . startswith ( "" ERROR: "" ) and prev_line . startswith ( "" = "" ) :
",72.83,83.38,False
"def end ( self , name ) : <TAB> self . soup . endData ( ) <TAB> completed_tag = self . soup . tagStack [ - 1 ] <TAB> namespace , name = self . _getNsTag ( name ) <TAB> nsprefix = None <TAB> if namespace is not None : <TAB> <TAB> for inverted_nsmap in reversed ( self . nsmaps ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> nsprefix = inverted_nsmap [ namespace ] <TAB> <TAB> <TAB> <TAB> break <TAB> self . soup . handle_endtag ( name , nsprefix ) <TAB> if len ( self . nsmaps ) > 1 : <TAB> <TAB> # This tag, or one of its parents, introduced a namespace <TAB> <TAB> # mapping, so pop it off the stack. <TAB> <TAB> self . nsmaps . pop ( ) ","if inverted_nsmap is not None and namespace in inverted_nsmap : 
","if inverted_nsmap [ namespace ] != completed_tag :
",27.52,20.6,False
"def _bind_parameters ( operation , parameters ) : <TAB> # inspired by MySQL Python Connector (conversion.py) <TAB> string_parameters = { } <TAB> for ( name , value ) in parameters . iteritems ( ) : <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> string_parameters [ name ] = "" NULL "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> string_parameters [ name ] = "" ' "" + _escape ( value ) + "" ' "" <TAB> <TAB> else : <TAB> <TAB> <TAB> string_parameters [ name ] = str ( value ) <TAB> return operation % string_parameters ","elif isinstance ( value , basestring ) : 
","elif isinstance ( value , str ) :
",79.9,59.46,False
"def plugin_on_song_ended ( self , song , skipped ) : <TAB> if song is not None : <TAB> <TAB> rating = song ( "" ~#rating "" ) <TAB> <TAB> invrating = 1.0 - rating <TAB> <TAB> delta = min ( rating , invrating ) / 2.0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rating - = delta <TAB> <TAB> else : <TAB> <TAB> <TAB> rating + = delta <TAB> <TAB> song [ "" ~#rating "" ] = rating ","if skipped : 
","if self . is_reverse :
",30.19,7.81,False
"def on_activated_async ( self , view ) : <TAB> if settings [ "" modified_lines_only "" ] : <TAB> <TAB> self . freeze_last_version ( view ) <TAB> if settings [ "" enabled "" ] : <TAB> <TAB> match_trailing_spaces ( view ) <TAB> <TAB> # continuously watch view for changes to the visible region <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # track <TAB> <TAB> <TAB> active_views [ view . id ( ) ] = view . visible_region ( ) <TAB> <TAB> <TAB> self . update_on_region_change ( view ) ","if not view . id ( ) in active_views : 
","if view . id ( ) in active_views :
",78.01,83.52,False
"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" -  "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB> <TAB> <TAB> newdiff . append ( u ( ""<TAB> "" ) + line [ 2 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newdiff . append ( line ) <TAB> return newdiff ","if line . startswith ( u ( "" Skipping "" ) ) : 
","if line . startswith ( u ( ""  "" ) ) :
",88.31,76.77,False
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> if os . path . isdir ( fn ) : <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .png "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path ) ","elif fn . endswith ( "" .md "" ) : 
","elif fn . endswith ( "" .png "" ) :
",83.03,70.17,False
"def reward ( self ) : <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB> if ts . raw_reward is not None : <TAB> <TAB> <TAB> raw_rewards + = ts . raw_reward <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> processed_rewards + = ts . processed_reward <TAB> return raw_rewards , processed_rewards ","if ts . processed_reward is not None : 
","if ts . processed_reward is not None :
",100.0,100.0,True
"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB> <TAB> s = month_name [ themonth ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s = s . decode ( encoding ) <TAB> <TAB> if withyear : <TAB> <TAB> <TAB> s = "" %s %s "" % ( s , theyear ) <TAB> <TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s ","if encoding is not None : 
","if encoding :
",29.58,0.0,False
"def check_digest_auth ( user , passwd ) : <TAB> """"""Check user authentication using HTTP Digest auth"""""" <TAB> if request . headers . get ( "" Authorization "" ) : <TAB> <TAB> credentails = parse_authorization_header ( request . headers . get ( "" Authorization "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> response_hash = response ( <TAB> <TAB> <TAB> credentails , <TAB> <TAB> <TAB> passwd , <TAB> <TAB> <TAB> dict ( <TAB> <TAB> <TAB> <TAB> uri = request . script_root + request . path , <TAB> <TAB> <TAB> <TAB> body = request . data , <TAB> <TAB> <TAB> <TAB> method = request . method , <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> if credentails . get ( "" response "" ) == response_hash : <TAB> <TAB> <TAB> return True <TAB> return False ","if not credentails : 
","if not credentails or not user . is_authenticated ( credentails ) :
",46.28,11.36,False
"def wrapped ( self , request ) : <TAB> try : <TAB> <TAB> return self . _finished <TAB> except AttributeError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not request . session . shouldfail and not request . session . shouldstop : <TAB> <TAB> <TAB> <TAB> log . debug ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  is still going to be used, not terminating it.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Still in use on: \n %s "" , <TAB> <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> <TAB> <TAB> pprint . pformat ( list ( self . node_ids ) ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> log . debug ( "" Finish called on  %s "" , self ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return func ( request ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _finished = True ","if self . node_ids : 
","if not self . _finished :
",39.37,16.52,False
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB> <TAB> if case ( 0 ) : <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> elif case ( 1 , 2 ) : <TAB> <TAB> <TAB> print ( "" one or two "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" three or four "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" default "" ) <TAB> <TAB> <TAB> print ( "" another "" ) ","elif case ( 3 , 4 ) : 
","elif case ( 3 , 4 ) :
",100.0,100.0,True
"def task_done ( self ) : <TAB> with self . _cond : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB> <TAB> if self . _unfinished_tasks . _semlock . _is_zero ( ) : <TAB> <TAB> <TAB> self . _cond . notify_all ( ) ","if not self . _unfinished_tasks . acquire ( False ) : 
","if self . _unfinished_tasks . _semlock . _is_zero ( ) :
",46.54,38.05,False
"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB> <TAB> <TAB> val = None <TAB> <TAB> elif isinstance ( val , text_or_bytes ) : <TAB> <TAB> <TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val ","if pwd is None : 
","if pwd is None :
",100.0,100.0,True
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> if version is not None :<TAB> # if failed to get version bail <TAB> <TAB> <TAB> major , minor , _ = version <TAB> <TAB> <TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB> <TAB> <TAB> if arch is not None : <TAB> <TAB> <TAB> <TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> exe , args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company , major , minor , arch , exe , args ","if exe_data is not None : 
","if exe_data is not None :
",100.0,100.0,True
"def run ( algs ) : <TAB> for alg in algs : <TAB> <TAB> vcs = alg . get ( "" variantcaller "" ) <TAB> <TAB> if vcs : <TAB> <TAB> <TAB> if isinstance ( vcs , dict ) : <TAB> <TAB> <TAB> <TAB> vcs = reduce ( operator . add , vcs . values ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> vcs = [ vcs ] <TAB> <TAB> <TAB> return any ( vc . startswith ( prefix ) for vc in vcs if vc ) ","if not isinstance ( vcs , ( list , tuple ) ) : 
","elif not isinstance ( vcs , list ) :
",41.95,34.03,False
"def wrapper ( self , * args , * * kwargs ) : <TAB> if not self . request . path . endswith ( "" / "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> uri = self . request . path + "" / "" <TAB> <TAB> <TAB> if self . request . query : <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> return <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs ) ","if self . request . method in ( "" GET "" , "" HEAD "" ) : 
","if self . request . method == "" GET "" :
",55.34,35.94,False
"def check_response ( self , response ) : <TAB> """"""Specialized version of check_response()."""""" <TAB> for line in response : <TAB> <TAB> # Skip blank lines: <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( b "" OK "" ) : <TAB> <TAB> <TAB> return <TAB> <TAB> elif line . startswith ( b "" Benutzer/Passwort Fehler "" ) : <TAB> <TAB> <TAB> raise BadLogin ( line ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise FailedPost ( "" Server returned  ' %s ' "" % six . ensure_text ( line ) ) ","if not line . strip ( ) : 
","if line . startswith ( b "" "" ) :
",33.11,13.13,False
"def Walk ( self , hMenu = None ) : <TAB> if not hMenu : <TAB> <TAB> hMenu = self . handle <TAB> n = user32 . GetMenuItemCount ( hMenu ) <TAB> mi = MENUITEMINFO ( ) <TAB> for i in range ( n ) : <TAB> <TAB> mi . fMask = 2<TAB> #  MIIM_ID <TAB> <TAB> user32 . GetMenuItemInfoA ( hMenu , i , 1 , byref ( mi ) ) <TAB> <TAB> handle = user32 . GetSubMenu ( hMenu , i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield handle , self . ListItems ( handle ) <TAB> <TAB> <TAB> for i in self . Walk ( handle ) : <TAB> <TAB> <TAB> <TAB> yield i ","if handle : 
","if self . IsShown ( handle ) :
",29.65,7.27,False
"def setSelection ( self , labels ) : <TAB> input = self . __validateInput ( labels ) <TAB> if len ( input ) == 0 and not self . __allowEmptySelection : <TAB> <TAB> return <TAB> if self . __allowMultipleSelection : <TAB> <TAB> self . __selectedLabels [ : ] = input <TAB> <TAB> self . __selectionChanged ( ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Parameter must be single item or a list with one element. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __selectedLabels [ : ] = input <TAB> <TAB> <TAB> self . __selectionChanged ( ) <TAB> # Remove all selected labels that are not in the menu, emit signals if necessary and update the button. <TAB> self . __validateState ( ) ","if len ( input ) > 1 : 
","if len ( input ) == 1 :
",79.9,51.33,False
"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if not isinstance ( self . momentum , ( int , float ) ) : 
","if not isinstance ( self . momentum , int ) :
",55.5,52.82,False
"def get_order ( self , aBuf ) : <TAB> if not aBuf : <TAB> <TAB> return - 1 , 1 <TAB> # find out current char's byte length <TAB> first_char = wrap_ord ( aBuf [ 0 ] ) <TAB> if ( 0x81 < = first_char < = 0x9F ) or ( 0xE0 < = first_char < = 0xFC ) : <TAB> <TAB> charLen = 2 <TAB> else : <TAB> <TAB> charLen = 1 <TAB> # return its order if it is hiragana <TAB> if len ( aBuf ) > 1 : <TAB> <TAB> second_char = wrap_ord ( aBuf [ 1 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return second_char - 0x9F , charLen <TAB> return - 1 , charLen ","if ( first_char == 202 ) and ( 0x9F < = second_char < = 0xF1 ) : 
","if ( 0x81 < = second_char < = 0x9F ) or ( 0xE0 < = second_char < = 0xFC ) :
",49.16,32.14,False
"def saveSpecial ( self , * * kwargs ) : <TAB> for kw in SPECIAL_BOOL_LIST + SPECIAL_VALUE_LIST + SPECIAL_LIST_LIST : <TAB> <TAB> item = config . get_config ( "" misc "" , kw ) <TAB> <TAB> value = kwargs . get ( kw ) <TAB> <TAB> msg = item . set ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return badParameterResponse ( msg ) <TAB> config . save_config ( ) <TAB> raise Raiser ( self . __root ) ","if msg : 
","if msg :
",78.12,0.0,False
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB> <TAB> if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB> <TAB> <TAB> if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB> <TAB> <TAB> <TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> ) ","if key not in valid_keys : 
","if key not in valid_keys :
",100.0,100.0,True
"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fit . calculated : <TAB> <TAB> <TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> <TAB> <TAB> fit . clearFactorReloadDependentData ( ) <TAB> <TAB> <TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs ","if fit is None : 
","if fit . ID == 0 :
",29.79,12.22,False
"def closest_unseen ( self , row1 , col1 , filter = None ) : <TAB> # find the closest unseen from this row/col <TAB> min_dist = maxint <TAB> closest_unseen = None <TAB> for row in range ( self . height ) : <TAB> <TAB> for col in range ( self . width ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . map [ row ] [ col ] == UNSEEN : <TAB> <TAB> <TAB> <TAB> <TAB> dist = self . distance ( row1 , col1 , row , col ) <TAB> <TAB> <TAB> <TAB> <TAB> if dist < min_dist : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> min_dist = dist <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> closest_unseen = ( row , col ) <TAB> return closest_unseen ","if filter is None or ( row , col ) not in filter : 
","if filter is None or filter [ row ] == col :
",44.09,31.02,False
"def getAlphaClone ( lookfor , eager = None ) : <TAB> if isinstance ( lookfor , int ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> item = get_gamedata_session ( ) . query ( AlphaClone ) . get ( lookfor ) <TAB> <TAB> else : <TAB> <TAB> <TAB> item = ( <TAB> <TAB> <TAB> <TAB> get_gamedata_session ( ) <TAB> <TAB> <TAB> <TAB> . query ( AlphaClone ) <TAB> <TAB> <TAB> <TAB> . options ( * processEager ( eager ) ) <TAB> <TAB> <TAB> <TAB> . filter ( AlphaClone . ID == lookfor ) <TAB> <TAB> <TAB> <TAB> . first ( ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise TypeError ( "" Need integer as argument "" ) <TAB> return item ","if eager is None : 
","if eager is None :
",100.0,100.0,True
"def _rle_encode ( string ) : <TAB> new = b "" "" <TAB> count = 0 <TAB> for cur in string : <TAB> <TAB> if not cur : <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> new + = b "" \0 "" + bytes ( [ count ] ) <TAB> <TAB> <TAB> <TAB> count = 0 <TAB> <TAB> <TAB> new + = bytes ( [ cur ] ) <TAB> return new ","if count : 
","if count :
",78.12,0.0,False
def result_iterator ( ) : <TAB> try : <TAB> <TAB> for future in fs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield future . result ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield future . result ( end_time - time . time ( ) ) <TAB> finally : <TAB> <TAB> for future in fs : <TAB> <TAB> <TAB> future . cancel ( ) ,"if timeout is None : 
","if end_time is None :
",64.58,26.27,False
"def _individual_get ( self , segment , index_type , index , strictdoc ) : <TAB> if index_type == "" val "" : <TAB> <TAB> for key , value in segment . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> <TAB> if hasattr ( key , "" text "" ) : <TAB> <TAB> <TAB> <TAB> if key . text == index [ 0 ] : <TAB> <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> raise Exception ( "" Invalid state "" ) <TAB> elif index_type == "" index "" : <TAB> <TAB> return segment [ index ] <TAB> elif index_type == "" textslice "" : <TAB> <TAB> return segment [ index [ 0 ] : index [ 1 ] ] <TAB> elif index_type == "" key "" : <TAB> <TAB> return index [ 1 ] if strictdoc else index [ 0 ] <TAB> else : <TAB> <TAB> raise Exception ( "" Invalid state "" ) ","if key == index [ 0 ] : 
","if strictdoc and key . doc == index [ 0 ] :
",60.74,50.09,False
"def _reset_sequences ( self , db_name ) : <TAB> conn = connections [ db_name ] <TAB> if conn . features . supports_sequence_reset : <TAB> <TAB> sql_list = conn . ops . sequence_reset_by_name_sql ( <TAB> <TAB> <TAB> no_style ( ) , conn . introspection . sequence_list ( ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cursor = conn . cursor ( ) <TAB> <TAB> <TAB> <TAB> for sql in sql_list : <TAB> <TAB> <TAB> <TAB> <TAB> cursor . execute ( sql ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> transaction . rollback_unless_managed ( using = db_name ) <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> transaction . commit_unless_managed ( using = db_name ) ","if sql_list : 
","if sql_list :
",78.12,100.0,True
"def translate_to_statements ( self , statements , conditional_write_vars ) : <TAB> lines = [ ] <TAB> for stmt in statements : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . temporary_vars . add ( ( stmt . var , stmt . dtype ) ) <TAB> <TAB> line = self . translate_statement ( stmt ) <TAB> <TAB> if stmt . var in conditional_write_vars : <TAB> <TAB> <TAB> subs = { } <TAB> <TAB> <TAB> condvar = conditional_write_vars [ stmt . var ] <TAB> <TAB> <TAB> lines . append ( "" if  %s : "" % condvar ) <TAB> <TAB> <TAB> lines . append ( indent ( line ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lines . append ( line ) <TAB> return lines ","if stmt . op == "" := "" and not stmt . var in self . variables : 
","if not stmt . temporary_vars :
",34.92,5.21,False
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB> <TAB> if ext != PYTHON_SOURCE_EXTENSION : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" c "" ) <TAB> <TAB> if self . optimize > 0 : <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files ","if self . compile : 
","if self . compile > 0 :
",61.88,43.47,False
"def logic ( ) : <TAB> for i in range ( 100 ) : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> if reset == ACTIVE_LOW : <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> count . next = ( count + 1 ) % n <TAB> raise StopSimulation ","if enable : 
","if enable :
",78.12,0.0,False
"def _is_subnet_of ( a , b ) : <TAB> try : <TAB> <TAB> # Always false if one is v4 and the other is v6. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( "" %s  and  %s  are not of the same version "" % ( a , b ) ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> b . network_address < = a . network_address <TAB> <TAB> <TAB> and b . broadcast_address > = a . broadcast_address <TAB> <TAB> ) <TAB> except AttributeError : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" Unable to test subnet containment  "" "" between  %s  and  %s "" % ( a , b ) <TAB> <TAB> ) ","if a . _version != b . _version : 
","if a . version != b . version :
",60.48,47.27,False
"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude : <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> if item . endswith ( "" / "" ) and not is_dir : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item . startswith ( "" / "" ) else basename <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if fnmatch . fnmatch ( match , item . strip ( "" / "" ) ) : 
","if match in item :
",25.66,1.37,False
"def __recv_null ( self ) : <TAB> """"""Receive a null byte."""""" <TAB> while 1 : <TAB> <TAB> c = self . sock . recv ( 1 ) <TAB> <TAB> if c == "" "" : <TAB> <TAB> <TAB> self . close ( ) <TAB> <TAB> <TAB> raise EOFError ( "" Socket Closed "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ","if c == "" \0 "" : 
","if c == "" null "" :
",49.63,52.47,False
"def onMessage ( self , payload , isBinary ) : <TAB> if isBinary : <TAB> <TAB> self . result = "" Expected text message with payload, but got binary. "" <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . result = ( <TAB> <TAB> <TAB> <TAB> "" Expected text message with payload of length  %d , but got  %d . "" <TAB> <TAB> <TAB> <TAB> % ( self . DATALEN , len ( payload ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self . behavior = Case . OK <TAB> <TAB> <TAB> self . result = "" Received text message of length  %d . "" % len ( payload ) <TAB> self . p . createWirelog = True <TAB> self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL ) ","if len ( payload ) != self . DATALEN : 
","if len ( payload ) != self . DATALEN :
",100.0,100.0,True
"def rename_path ( self , path , new_path ) : <TAB> logger . debug ( "" rename_path  ' %s '  ->  ' %s ' "" % ( path , new_path ) ) <TAB> dirs = self . readdir ( path ) <TAB> for d in dirs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> d_path = "" "" . join ( [ path , "" / "" , d ] ) <TAB> <TAB> d_new_path = "" "" . join ( [ new_path , "" / "" , d ] ) <TAB> <TAB> attr = self . getattr ( d_path ) <TAB> <TAB> if stat . S_ISDIR ( attr [ "" st_mode "" ] ) : <TAB> <TAB> <TAB> self . rename_path ( d_path , d_new_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rename_item ( d_path , d_new_path ) <TAB> self . rename_item ( path , new_path , dir = True ) ","if d in [ "" . "" , "" .. "" ] : 
","if not d . endswith ( "" .yml "" ) :
",34.56,7.84,False
"def dir_box_click ( self , double ) : <TAB> if double : <TAB> <TAB> name = self . list_box . get_selected_name ( ) <TAB> <TAB> path = os . path . join ( self . directory , name ) <TAB> <TAB> suffix = os . path . splitext ( name ) [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . directory = path <TAB> <TAB> else : <TAB> <TAB> <TAB> self . double_click_file ( name ) <TAB> self . update ( ) ","if suffix not in self . suffixes and os . path . isdir ( path ) : 
","if suffix == "" .dir "" :
",26.17,4.66,False
"def __getattr__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return value . mod_ns <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB> <TAB> <TAB> <TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB> <TAB> "" Module  %r  has no mapped classes  "" <TAB> <TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> ) ","if isinstance ( value , _ModuleMarker ) : 
","if isinstance ( value , _Module ) :
",79.9,66.06,False
"def poll_thread ( ) : <TAB> time . sleep ( 0.5 ) <TAB> if process . wait ( ) and process_state : <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stdout , stderr = process . _communicate ( None ) <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" Web server process exited unexpectedly "" , <TAB> <TAB> <TAB> <TAB> "" app "" , <TAB> <TAB> <TAB> <TAB> stdout = stdout , <TAB> <TAB> <TAB> <TAB> stderr = stderr , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> <TAB> restart_server ( 1 ) ","if not check_global_interrupt ( ) : 
","if process . poll ( ) is not None :
",34.19,10.55,False
"def apply_dateparser_timezone ( utc_datetime , offset_or_timezone_abb ) : <TAB> for name , info in _tz_offsets : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tz = StaticTzInfo ( name , info [ "" offset "" ] ) <TAB> <TAB> <TAB> return utc_datetime . astimezone ( tz ) ","if info [ "" regex "" ] . search ( "" %s "" % offset_or_timezone_abb ) : 
","if offset_or_timezone_abb [ name ] :
",25.72,21.24,False
"def _load_wordlist ( filename ) : <TAB> if filename is None : <TAB> <TAB> return { } <TAB> path = None <TAB> for dir in ( CONFIG_DIR , ASSETS_DIR ) : <TAB> <TAB> path = os . path . realpath ( os . path . join ( dir , filename ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> words = { } <TAB> with open ( path , encoding = "" utf-8 "" ) as f : <TAB> <TAB> pairs = [ word . strip ( ) . rsplit ( "" "" , 1 ) for word in f ] <TAB> <TAB> pairs . sort ( reverse = True , key = lambda x : int ( x [ 1 ] ) ) <TAB> <TAB> words = { p [ 0 ] : int ( p [ 1 ] ) for p in pairs } <TAB> return words ","if os . path . exists ( path ) : 
","if path is None :
",26.44,5.17,False
"def terminate_processes_matching_names ( match_strings , kill = False ) : <TAB> """"""Terminates processes matching particular names (case sensitive)."""""" <TAB> if isinstance ( match_strings , str ) : <TAB> <TAB> match_strings = [ match_strings ] <TAB> for process in psutil . process_iter ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> process_info = process . as_dict ( attrs = [ "" name "" , "" pid "" ] ) <TAB> <TAB> <TAB> process_name = process_info [ "" name "" ] <TAB> <TAB> except ( psutil . AccessDenied , psutil . NoSuchProcess , OSError ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> terminate_process ( process_info [ "" pid "" ] , kill ) ","if any ( x == process_name for x in match_strings ) : 
","if match_strings == process_name :
",31.15,27.59,False
"def has_scheme ( self , inp ) : <TAB> if "" :// "" in inp : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> authority = inp . replace ( "" / "" , "" # "" ) . replace ( "" ? "" , "" # "" ) . split ( "" # "" ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _ , host_or_port = authority . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> # Assert it's not a port number <TAB> <TAB> <TAB> if re . match ( r "" ^ \ d+$ "" , host_or_port ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return True ","if "" : "" in authority : 
","if "" : "" in authority :
",100.0,100.0,True
"def close ( self ) : <TAB> with BrowserContext . _BROWSER_LOCK : <TAB> <TAB> BrowserContext . _BROWSER_REFCNT - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . info ( "" Destroying browser main loop "" ) <TAB> <TAB> <TAB> BrowserContext . _BROWSER_LOOP . destroy ( ) <TAB> <TAB> <TAB> BrowserContext . _BROWSER_LOOP = None ","if BrowserContext . _BROWSER_REFCNT == 0 : 
","if BrowserContext . _BROWSER_REFCNT == 0 :
",100.0,100.0,True
"def _mock_get_merge_ticks ( self , order_book_id_list , trading_date , last_dt = None ) : <TAB> for tick in self . _ticks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> self . env . data_proxy . get_future_trading_date ( tick . datetime ) . date ( ) <TAB> <TAB> <TAB> != trading_date . date ( ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if last_dt and tick . datetime < = last_dt : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield tick ","if tick . order_book_id not in order_book_id_list : 
","if not tick . order_book_id_list or not tick . order_book_id_list :
",33.82,56.64,False
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> if ss [ "" revision "" ] : <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> if ss [ "" patch "" ] is not None : <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text ","if ss [ "" branch "" ] : 
","if ss [ "" branch "" ] :
",100.0,100.0,True
"def test_open_read_bytes ( self , sftp ) : <TAB> """"""Test reading bytes from a file"""""" <TAB> f = None <TAB> try : <TAB> <TAB> self . _create_file ( "" file "" , "" xxx "" ) <TAB> <TAB> f = yield from sftp . open ( "" file "" , "" rb "" ) <TAB> <TAB> self . assertEqual ( ( yield from f . read ( ) ) , b "" xxx "" ) <TAB> finally : <TAB> <TAB> if f :<TAB> # pragma: no branch <TAB> <TAB> <TAB> yield from f . close ( ) <TAB> <TAB> remove ( "" file "" ) ","if f : 
","if f :
",78.12,0.0,False
"def handler ( chan , host , port ) : <TAB> sock = socket ( ) <TAB> try : <TAB> <TAB> sock . connect ( ( host , port ) ) <TAB> except Exception as e : <TAB> <TAB> if verbose == True : <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> return <TAB> while True : <TAB> <TAB> r , w , x = select . select ( [ sock , chan ] , [ ] , [ ] ) <TAB> <TAB> if sock in r : <TAB> <TAB> <TAB> data = sock . recv ( 1024 ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> chan . send ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = chan . recv ( 1024 ) <TAB> <TAB> <TAB> if len ( data ) == 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> sock . send ( data ) <TAB> chan . close ( ) <TAB> sock . close ( ) ","if chan in r : 
","if chan in r :
",100.0,100.0,True
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = re . search ( r "" url \ ( ' /ks-waf-error \ .png ' \ ) "" , page , re . I ) is not None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return retval ","if retval : 
","if retval :
",78.12,0.0,False
"def __init__ ( self , raw ) : <TAB> ticker_ticks = { } <TAB> for tick in raw [ "" results "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ticker_ticks [ tick [ "" T "" ] ] . append ( tick ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ticker_ticks [ tick [ "" T "" ] ] = [ tick ] <TAB> super ( ) . __init__ ( <TAB> <TAB> { ticker : Aggsv2 ( { "" results "" : ticks } ) for ticker , ticks in ticker_ticks . items ( ) } <TAB> ) ","if ticker_ticks . get ( tick [ "" T "" ] ) : 
","if tick [ "" T "" ] in ticker_ticks :
",53.53,43.49,False
"def _makefiles ( self , f ) : <TAB> if isinstance ( f , dict ) : <TAB> <TAB> for k , v in list ( f . items ( ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . makedir ( dirname = k , content = v ) <TAB> <TAB> <TAB> elif isinstance ( v , str ) : <TAB> <TAB> <TAB> <TAB> self . make_file ( filename = k , content = v ) <TAB> <TAB> <TAB> else :<TAB> # pragma: nocover <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected: "" , k , v ) <TAB> elif isinstance ( f , str ) : <TAB> <TAB> self . _make_empty_file ( f ) <TAB> elif isinstance ( f , list ) : <TAB> <TAB> self . make_list ( f ) <TAB> else :<TAB> # pragma: nocover <TAB> <TAB> raise ValueError ( "" Unknown type: "" , f ) ","if isinstance ( v , list ) : 
","if isinstance ( v , ( int , long ) ) :
",49.15,36.46,False
"def migrate_command_storage ( apps , schema_editor ) : <TAB> model = apps . get_model ( "" terminal "" , "" CommandStorage "" ) <TAB> init_storage_data ( model ) <TAB> setting = get_setting ( apps , schema_editor , "" TERMINAL_COMMAND_STORAGE "" ) <TAB> if not setting : <TAB> <TAB> return <TAB> values = get_storage_data ( setting ) <TAB> for name , meta in values . items ( ) : <TAB> <TAB> tp = meta . pop ( "" TYPE "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> model . objects . create ( name = name , type = tp , meta = meta ) ","if not tp or name in [ "" default "" , "" null "" ] : 
","if tp == "" DELETE "" :
",32.04,3.04,False
"def build_vertices ( self , ulines ) : <TAB> vertex_idx = 0 <TAB> vertices = collections . OrderedDict ( ) <TAB> for line in ulines : <TAB> <TAB> for vt in line : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_vertex = ( vt . u , vt . v , 0.0 ) <TAB> <TAB> <TAB> if new_vertex in vertices : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> vt . index = vertex_idx <TAB> <TAB> <TAB> vertex_idx + = 1 <TAB> <TAB> <TAB> vertices [ new_vertex ] = 1 <TAB> return vertex_idx , list ( vertices . keys ( ) ) ","if vt . replacement is not None : 
","if vt . index != vertex_idx :
",37.14,16.78,False
"def get_quarantine_count ( self ) : <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB> <TAB> for qtype in qcounts : <TAB> <TAB> <TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB> <TAB> <TAB> if os . path . exists ( qtgt ) : <TAB> <TAB> <TAB> <TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts ","if linkcount > 2 : 
","if linkcount > 2 :
",100.0,100.0,True
"def _format_arg ( self , name , trait_spec , value ) : <TAB> if name == "" mask_file "" : <TAB> <TAB> return "" "" <TAB> if name == "" op_string "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isdefined ( self . inputs . mask_file ) : <TAB> <TAB> <TAB> <TAB> return self . inputs . op_string % self . inputs . mask_file <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" -k  %s  option in op_string requires mask_file "" ) <TAB> return super ( ImageStats , self ) . _format_arg ( name , trait_spec , value ) ","if "" -k  %s "" in self . inputs . op_string : 
","if self . inputs . mask_file :
",44.77,17.63,False
"def _update_theme_style ( self , * args ) : <TAB> self . line_color_normal = self . theme_cls . divider_color <TAB> if not any ( [ self . error , self . _text_len_error ] ) : <TAB> <TAB> if not self . focus : <TAB> <TAB> <TAB> self . _current_hint_text_color = self . theme_cls . disabled_hint_text_color <TAB> <TAB> <TAB> self . _current_right_lbl_color = self . theme_cls . disabled_hint_text_color <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _current_error_color = self . theme_cls . disabled_hint_text_color ","if self . helper_text_mode == "" persistent "" : 
","if not self . focus :
",33.19,5.09,False
"def createFields ( self ) : <TAB> for item in self . format : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield item [ 0 ] ( self , * item [ 1 : - 1 ] , * * item [ - 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield item [ 0 ] ( self , * item [ 1 : ] ) ","if isinstance ( item [ - 1 ] , dict ) : 
","if item [ - 1 ] . type == "" * "" :
",50.18,28.92,False
"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement , arguments ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement ) <TAB> <TAB> except sqlite3 . OperationalError as ex : <TAB> <TAB> <TAB> if "" locked "" not in getSafeExString ( ex ) : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB> <TAB> return self . cursor . fetchall ( ) ","if arguments : 
","if arguments :
",78.12,0.0,False
"def set_income_account_for_fixed_assets ( self ) : <TAB> disposal_account = depreciation_cost_center = None <TAB> for d in self . get ( "" items "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not disposal_account : <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> disposal_account , <TAB> <TAB> <TAB> <TAB> <TAB> depreciation_cost_center , <TAB> <TAB> <TAB> <TAB> ) = get_disposal_account_and_cost_center ( self . company ) <TAB> <TAB> <TAB> d . income_account = disposal_account <TAB> <TAB> <TAB> if not d . cost_center : <TAB> <TAB> <TAB> <TAB> d . cost_center = depreciation_cost_center ","if d . is_fixed_asset : 
","if d . income_account :
",64.48,20.87,False
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> if isinstance ( nbChars , int ) : <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> if nbChars [ 0 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit ) ","if nbChars [ 1 ] is not None : 
","if nbChars [ 1 ] is not None :
",100.0,100.0,True
"def _get_service_full_name ( self , name , help_command_table ) : <TAB> if help_command_table and name not in self . _NON_SERVICE_COMMANDS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _HIGH_LEVEL_SERVICE_FULL_NAMES [ name ] <TAB> <TAB> service = help_command_table . get ( name ) <TAB> <TAB> if service : <TAB> <TAB> <TAB> return service . service_model . metadata [ "" serviceFullName "" ] ","if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES : 
","if name in self . _HIGH_LEVEL_SERVICE_FULL_NAMES :
",100.0,100.0,True
"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 :<TAB> # at least one complete IP address <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp_str + = "" # "" <TAB> <TAB> <TAB> tmp_str + = self . get_ip_address ( p ) <TAB> <TAB> <TAB> p + = 4 <TAB> <TAB> <TAB> if p > = self . get_len ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tmp_str + = "" ,  "" <TAB> tmp_str + = "" ]  "" <TAB> if self . get_ptr ( ) % 4 :<TAB> # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str + = "" nonsense ptr field:  %d "" % self . get_ptr ( ) <TAB> return tmp_str ","if p + 1 == self . get_ptr ( ) : 
","if self . get_ptr ( ) % 4 :
",55.32,46.26,False
"def run ( self ) : <TAB> for _ in range ( self . n ) : <TAB> <TAB> error = True <TAB> <TAB> try : <TAB> <TAB> <TAB> self . collection . insert_one ( { "" test "" : "" insert "" } ) <TAB> <TAB> <TAB> error = False <TAB> <TAB> except : <TAB> <TAB> <TAB> if not self . expect_exception : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert error ","if self . expect_exception : 
","if self . assert_error :
",64.48,27.78,False
"def create_composite_mounter_by_args ( args ) : <TAB> """"""Creates a CompositeMounter by the images in given args."""""" <TAB> logging . info ( "" Mount images... "" ) <TAB> mounter = composite_mounter . CompositeMounter ( ) <TAB> for partition in composite_mounter . SUPPORTED_PARTITIONS : <TAB> <TAB> image_source = vars ( args ) [ partition ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . info ( ""<TAB> %s = %s "" , partition , image_source ) <TAB> <TAB> <TAB> mounter . add_by_mount_target ( partition , image_source ) <TAB> if mounter . is_empty ( ) : <TAB> <TAB> raise RuntimeError ( "" Must give at least one image source. "" ) <TAB> return mounter ","if image_source : 
","if image_source . is_image ( ) :
",33.58,24.81,False
"def _get_containing_class ( self , pyname ) : <TAB> if isinstance ( pyname , pynames . DefinedName ) : <TAB> <TAB> scope = pyname . get_object ( ) . get_scope ( ) <TAB> <TAB> parent = scope . parent <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return parent . pyobject ","if parent is not None and parent . get_kind ( ) == "" Class "" : 
","if parent and isinstance ( parent , pynames . ContainingClass ) :
",29.31,5.35,False
"def test_chunkcoding ( self ) : <TAB> tstring_lines = [ ] <TAB> for b in self . tstring : <TAB> <TAB> lines = b . split ( b "" \n "" ) <TAB> <TAB> last = lines . pop ( ) <TAB> <TAB> assert last == b "" "" <TAB> <TAB> lines = [ line + b "" \n "" for line in lines ] <TAB> <TAB> tstring_lines . append ( lines ) <TAB> for native , utf8 in zip ( * tstring_lines ) : <TAB> <TAB> u = self . decode ( native ) [ 0 ] <TAB> <TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] ) ","if self . roundtriptest : 
","if PY2 :
",28.55,0.0,False
"def set_default_variants ( apps , schema_editor ) : <TAB> Product = apps . get_model ( "" product "" , "" Product "" ) <TAB> for product in Product . objects . iterator ( ) : <TAB> <TAB> first_variant = product . variants . first ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> product . default_variant = first_variant <TAB> <TAB> <TAB> product . save ( update_fields = [ "" default_variant "" , "" updated_at "" ] ) ","if first_variant : 
","if first_variant is not None :
",34.04,36.56,False
"def json ( self ) : <TAB> try : <TAB> <TAB> if self . is_json ( ) : <TAB> <TAB> <TAB> raw_data = self . raw_data ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raw_data = raw_data . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> return json . loads ( raw_data ) <TAB> except ValueError : <TAB> <TAB> pass ","if not isinstance ( raw_data , text_type ) : 
","if isinstance ( raw_data , bytes ) :
",53.23,44.36,False
"def clear_react ( self , message : discord . Message , emoji : MutableMapping = None ) - > None : <TAB> try : <TAB> <TAB> await message . clear_reactions ( ) <TAB> except discord . Forbidden : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> with contextlib . suppress ( discord . HTTPException ) : <TAB> <TAB> <TAB> async for key in AsyncIter ( emoji . values ( ) , delay = 0.2 ) : <TAB> <TAB> <TAB> <TAB> await message . remove_reaction ( key , self . bot . user ) <TAB> except discord . HTTPException : <TAB> <TAB> return ","if not emoji : 
","if self . bot . is_anonymous ( ) :
",28.1,4.46,False
"def check ( self , value ) : <TAB> value = String . check ( self , value ) <TAB> if isinstance ( value , str ) : <TAB> <TAB> value = value . upper ( ) <TAB> <TAB> for prefix in ( self . prefix , self . prefix . split ( "" _ "" , 1 ) [ 1 ] ) : <TAB> <TAB> <TAB> # e.g. PANGO_WEIGHT_BOLD --> BOLD but also WEIGHT_BOLD --> BOLD <TAB> <TAB> <TAB> if value . startswith ( prefix ) : <TAB> <TAB> <TAB> <TAB> value = value [ len ( prefix ) : ] <TAB> <TAB> <TAB> value = value . lstrip ( "" _ "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return getattr ( self . group , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" No such constant:  %s _ %s "" % ( self . prefix , value ) ) <TAB> else : <TAB> <TAB> return value ","if hasattr ( self . group , value ) : 
","if hasattr ( self . group , value ) :
",100.0,100.0,True
"def value ( self ) : <TAB> quote = False <TAB> if self . defects : <TAB> <TAB> quote = True <TAB> else : <TAB> <TAB> for x in self : <TAB> <TAB> <TAB> if x . token_type == "" quoted-string "" : <TAB> <TAB> <TAB> <TAB> quote = True <TAB> if quote : <TAB> <TAB> pre = post = "" "" <TAB> <TAB> if self [ 0 ] . token_type == "" cfws "" or self [ 0 ] [ 0 ] . token_type == "" cfws "" : <TAB> <TAB> <TAB> pre = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> post = "" "" <TAB> <TAB> return pre + quote_string ( self . display_name ) + post <TAB> else : <TAB> <TAB> return super ( DisplayName , self ) . value ","if self [ - 1 ] . token_type == "" cfws "" or self [ - 1 ] [ - 1 ] . token_type == "" cfws "" : 
","if self [ 1 ] . token_type == "" cfws "" or self [ 1 ] [ 0 ] . token_type == "" cfws "" :
",62.07,73.46,False
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> if root_path : <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path : <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive ","elif volume_guid_path : 
","if volume_guid_path :
",35.87,80.91,False
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> if bbox is None : <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox ","if parsed_drawing : 
","if parsed_drawing :
",78.12,100.0,True
"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k ) ","elif k is None : 
","elif k is None :
",100.0,100.0,True
"def find_multiple_stats ( stats , name , _found = None , _on_found = None ) : <TAB> if _found is None : <TAB> <TAB> _found = [ ] <TAB> for child_stats in stats : <TAB> <TAB> if child_stats . name == name : <TAB> <TAB> <TAB> _found . append ( child_stats ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _on_found ( _found ) <TAB> <TAB> find_multiple_stats ( child_stats , name , _found ) <TAB> return _found ","if callable ( _on_found ) : 
","if _on_found is not None :
",27.8,33.03,False
"def _run_generated_code ( <TAB> self , <TAB> code , <TAB> globs , <TAB> locs , <TAB> fails_under_py3k = True , ) : <TAB> import warnings <TAB> from zope . interface . _compat import PYTHON3 <TAB> with warnings . catch_warnings ( record = True ) as log : <TAB> <TAB> warnings . resetwarnings ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exec ( code , globs , locs ) <TAB> <TAB> <TAB> self . assertEqual ( len ( log ) , 0 )<TAB> # no longer warn <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> exec ( code , globs , locs ) <TAB> <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if fails_under_py3k : <TAB> <TAB> <TAB> <TAB> <TAB> self . fail ( "" Didn ' t raise TypeError "" ) ","if not PYTHON3 : 
","if PYTHON3 :
",34.18,0.0,False
"def _get_node ( self , node_id ) : <TAB> self . non_terminated_nodes ( { } )<TAB> # Side effect: updates cache <TAB> with self . lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . cached_nodes [ node_id ] <TAB> <TAB> instance = ( <TAB> <TAB> <TAB> self . compute . instances ( ) <TAB> <TAB> <TAB> . get ( <TAB> <TAB> <TAB> <TAB> project = self . provider_config [ "" project_id "" ] , <TAB> <TAB> <TAB> <TAB> zone = self . provider_config [ "" availability_zone "" ] , <TAB> <TAB> <TAB> <TAB> instance = node_id , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> . execute ( ) <TAB> <TAB> ) <TAB> <TAB> return instance ","if node_id in self . cached_nodes : 
","if node_id in self . cached_nodes :
",100.0,100.0,True
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> if ttype == SCE_PL_UNUSED : <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount < = 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break ","if self . opHash . has_key ( tval ) : 
","if tval in self . opHash :
",35.58,14.23,False
"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len ( kwargs ) > 0 <TAB> kwargs . update ( infer_mode = infer_mode ) <TAB> is_training = not infer_mode if infer_mode is not None else self . training <TAB> helper = self . _train_helper if is_training else self . _infer_helper <TAB> if prefer_new or helper is None : <TAB> <TAB> helper = self . create_helper ( * * kwargs ) <TAB> <TAB> if is_training and self . _train_helper is None : <TAB> <TAB> <TAB> self . _train_helper = helper <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _infer_helper = helper <TAB> return helper ","elif not is_training and self . _infer_helper is None : 
","if is_training and self . _infer_helper is None :
",69.61,85.59,False
"def get_ldset ( self , ldsets ) : <TAB> ldset = None <TAB> if self . _properties [ "" ldset_name "" ] == "" "" : <TAB> <TAB> nldset = len ( ldsets ) <TAB> <TAB> if nldset == 0 : <TAB> <TAB> <TAB> msg = _ ( "" Logical Disk Set could not be found. "" ) <TAB> <TAB> <TAB> raise exception . NotFound ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ldset = None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = ( <TAB> <TAB> <TAB> <TAB> _ ( "" Logical Disk Set ` %s ` could not be found. "" ) <TAB> <TAB> <TAB> <TAB> % self . _properties [ "" ldset_name "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise exception . NotFound ( msg ) <TAB> <TAB> ldset = ldsets [ self . _properties [ "" ldset_name "" ] ] <TAB> return ldset ","if self . _properties [ "" ldset_name "" ] not in ldsets : 
","if self . _properties [ "" ldset_name "" ] not in ldsets :
",100.0,100.0,True
"def calc_fractal_serial ( q , maxiter ) : <TAB> # calculate z using pure python on a numpy array <TAB> # note that, unlike the other two implementations, <TAB> # the number of iterations per point is NOT constant <TAB> z = np . zeros ( q . shape , complex ) <TAB> output = np . resize ( <TAB> <TAB> np . array ( <TAB> <TAB> <TAB> 0 , <TAB> <TAB> ) , <TAB> <TAB> q . shape , <TAB> ) <TAB> for i in range ( len ( q ) ) : <TAB> <TAB> for iter in range ( maxiter ) : <TAB> <TAB> <TAB> z [ i ] = z [ i ] * z [ i ] + q [ i ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> output [ i ] = iter <TAB> <TAB> <TAB> <TAB> break <TAB> return output ","if abs ( z [ i ] ) > 2.0 : 
","if np . allclose ( z [ i ] , 0 ) :
",47.4,32.52,False
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not inst . modctxt : <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ","if isinstance ( inst , ( _Block , _Instantiator ) ) : 
","if isinstance ( inst , _Instance ) :
",43.51,31.87,False
"def walks_generator ( ) : <TAB> if filelist is not None : <TAB> <TAB> bucket = [ ] <TAB> <TAB> for filename in filelist : <TAB> <TAB> <TAB> with io . open ( filename ) as inf : <TAB> <TAB> <TAB> <TAB> for line in inf : <TAB> <TAB> <TAB> <TAB> <TAB> walk = [ int ( x ) for x in line . strip ( "" \n "" ) . split ( "" "" ) ] <TAB> <TAB> <TAB> <TAB> <TAB> bucket . append ( walk ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield bucket <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> bucket = [ ] <TAB> <TAB> if len ( bucket ) : <TAB> <TAB> <TAB> yield bucket <TAB> else : <TAB> <TAB> for _ in range ( epoch ) : <TAB> <TAB> <TAB> for nodes in graph . node_batch_iter ( batch_size ) : <TAB> <TAB> <TAB> <TAB> walks = graph . random_walk ( nodes , walk_len ) <TAB> <TAB> <TAB> <TAB> yield walks ","if len ( bucket ) == batch_size : 
","if len ( bucket ) == batch_size :
",100.0,100.0,True
def _traverse ( op ) : <TAB> if op in visited : <TAB> <TAB> return <TAB> visited . add ( op ) <TAB> if tag . is_injective ( op . tag ) : <TAB> <TAB> if op not in s . outputs : <TAB> <TAB> <TAB> s [ op ] . compute_inline ( ) <TAB> <TAB> for tensor in op . input_tensors : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _traverse ( tensor . op ) <TAB> callback ( op ) ,"if isinstance ( tensor . op , tvm . te . ComputeOp ) : 
","if isinstance ( tensor . op , Tensor ) :
",56.31,47.4,False
"def unwatch_run ( self , run_id , handler ) : <TAB> with self . _dict_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _handlers_dict [ run_id ] = [ <TAB> <TAB> <TAB> <TAB> ( start_cursor , callback ) <TAB> <TAB> <TAB> <TAB> for ( start_cursor , callback ) in self . _handlers_dict [ run_id ] <TAB> <TAB> <TAB> <TAB> if callback != handler <TAB> <TAB> <TAB> ] <TAB> <TAB> if not self . _handlers_dict [ run_id ] : <TAB> <TAB> <TAB> del self . _handlers_dict [ run_id ] <TAB> <TAB> <TAB> run_id_dict = self . _run_id_dict <TAB> <TAB> <TAB> del run_id_dict [ run_id ] <TAB> <TAB> <TAB> self . _run_id_dict = run_id_dict ","if run_id in self . _run_id_dict : 
","if run_id not in self . _handlers_dict :
",60.02,44.06,False
"def _PromptMySQL ( self , config ) : <TAB> """"""Prompts the MySQL configuration, retrying if the configuration is invalid."""""" <TAB> while True : <TAB> <TAB> self . _PromptMySQLOnce ( config ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Successfully connected to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Error: Could not connect to MySQL with the given configuration. "" ) <TAB> <TAB> <TAB> retry = RetryBoolQuestion ( "" Do you want to retry MySQL configuration? "" , True ) <TAB> <TAB> <TAB> if not retry : <TAB> <TAB> <TAB> <TAB> raise ConfigInitError ( ) ","if self . _CheckMySQLConnection ( ) : 
","if self . _IsConnected ( ) :
",63.85,50.0,False
"def get_courses_without_topic ( topic ) : <TAB> data = [ ] <TAB> for entry in frappe . db . get_all ( "" Course "" ) : <TAB> <TAB> course = frappe . get_doc ( "" Course "" , entry . name ) <TAB> <TAB> topics = [ t . topic for t in course . topics ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data . append ( course . name ) <TAB> return data ","if not topics or topic not in topics : 
","if topic not in topics :
",56.86,48.24,False
"def _error_handler ( action , * * keywords ) : <TAB> if keywords : <TAB> <TAB> file_type = keywords . get ( "" file_type "" , None ) <TAB> <TAB> if file_type : <TAB> <TAB> <TAB> raise exceptions . FileTypeNotSupported ( <TAB> <TAB> <TAB> <TAB> constants . FILE_TYPE_NOT_SUPPORTED_FMT % ( file_type , action ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> keywords . pop ( "" on_demand "" ) <TAB> <TAB> <TAB> msg = "" Please check if there were typos in  "" <TAB> <TAB> <TAB> msg + = "" function parameters:  %s . Otherwise  "" <TAB> <TAB> <TAB> msg + = "" unrecognized parameters were given. "" <TAB> <TAB> <TAB> raise exceptions . UnknownParameters ( msg % keywords ) <TAB> else : <TAB> <TAB> raise exceptions . UnknownParameters ( "" No parameters found! "" ) ","if "" on_demand "" in keywords : 
","if "" on_demand "" in keywords :
",100.0,100.0,True
"def select ( self , regions , register ) : <TAB> self . view . sel ( ) . clear ( ) <TAB> to_store = [ ] <TAB> for r in regions : <TAB> <TAB> self . view . sel ( ) . add ( r ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> to_store . append ( self . view . substr ( self . view . full_line ( r ) ) ) <TAB> if register : <TAB> <TAB> text = "" "" . join ( to_store ) <TAB> <TAB> if not text . endswith ( "" \n "" ) : <TAB> <TAB> <TAB> text = text + "" \n "" <TAB> <TAB> state = State ( self . view ) <TAB> <TAB> state . registers [ register ] = [ text ] ","if register : 
","if self . view . full_line ( r ) != self . view . full_line ( r ) :
",28.9,1.87,False
"def has_actor ( self , message : HasActorMessage ) - > ResultMessage : <TAB> actor_ref = message . actor_ref <TAB> # lookup allocated <TAB> for address , item in self . _allocated_actors . items ( ) : <TAB> <TAB> ref = create_actor_ref ( address , actor_ref . uid ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ResultMessage ( message . message_id , True , protocol = message . protocol ) <TAB> return ResultMessage ( message . message_id , False , protocol = message . protocol ) ","if ref in item : 
","if ref == item . ref :
",30.24,13.13,False
"def toggleMetaButton ( self , event ) : <TAB> """"""Process clicks on toggle buttons"""""" <TAB> clickedBtn = event . EventObject <TAB> if wx . GetMouseState ( ) . GetModifiers ( ) == wx . MOD_CONTROL : <TAB> <TAB> activeBtns = [ btn for btn in self . metaButtons if btn . GetValue ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> clickedBtn . setUserSelection ( clickedBtn . GetValue ( ) ) <TAB> <TAB> <TAB> self . itemView . filterItemStore ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Do 'nothing' if we're trying to turn last active button off <TAB> <TAB> <TAB> # Keep button in the same state <TAB> <TAB> <TAB> clickedBtn . setUserSelection ( True ) <TAB> else : <TAB> <TAB> for btn in self . metaButtons : <TAB> <TAB> <TAB> btn . setUserSelection ( btn == clickedBtn ) <TAB> <TAB> self . itemView . filterItemStore ( ) ","if activeBtns : 
","if len ( activeBtns ) > 0 :
",29.65,7.27,False
"def __init__ ( self , hub = None ) :<TAB> # pylint: disable=unused-argument <TAB> if resolver . _resolver is None : <TAB> <TAB> _resolver = resolver . _resolver = _DualResolver ( ) <TAB> <TAB> if config . resolver_nameservers : <TAB> <TAB> <TAB> _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _resolver . network_resolver . lifetime = config . resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance ( resolver . _resolver , _DualResolver ) <TAB> self . _resolver = resolver . _resolver ","if config . resolver_timeout : 
","if config . resolver_timeout :
",100.0,100.0,True
"def sub_paragraph ( self , li ) : <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len ( li ) : <TAB> <TAB> first = list ( li ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> m = RE_CHECKBOX . match ( first . text ) <TAB> <TAB> <TAB> if m is not None : <TAB> <TAB> <TAB> <TAB> first . text = self . markdown . htmlStash . store ( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB> <TAB> <TAB> <TAB> ) + m . group ( "" line "" ) <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found ","if first . tag == "" p "" and first . text is not None : 
","if first . text :
",33.81,5.39,False
"def _check_mswin_locale ( locale ) : <TAB> msloc = None <TAB> try : <TAB> <TAB> msloc = _LOCALE_NAMES [ locale [ : 5 ] ] [ : 2 ] <TAB> <TAB> locale = locale [ : 5 ] <TAB> except KeyError : <TAB> <TAB> try : <TAB> <TAB> <TAB> msloc = _LOCALE_NAMES [ locale [ : 2 ] ] [ : 2 ] <TAB> <TAB> <TAB> locale = locale [ : 2 ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> # US English is the outlier, all other English locales want <TAB> <TAB> <TAB> # real English: <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return ( "" en_GB "" , "" 1252 "" ) <TAB> <TAB> <TAB> return ( None , None ) <TAB> return ( locale , msloc ) ","if locale [ : 2 ] == ( "" en "" ) and locale [ : 5 ] != "" en_US "" : 
","if locale == "" en_GB "" and locale == "" en_1252 "" :
",30.84,14.79,False
"def setLabel ( self , s , protect = False ) : <TAB> """"""Set the label of the minibuffer."""""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . app . gui . set_minibuffer_label ( c , s ) <TAB> <TAB> w . setAllText ( s ) <TAB> <TAB> n = len ( s ) <TAB> <TAB> w . setSelectionRange ( n , n , insert = n ) <TAB> <TAB> if protect : <TAB> <TAB> <TAB> k . mb_prefix = s ","if hasattr ( g . app . gui , "" set_minibuffer_label "" ) : 
","if hasattr ( g . app , "" gui "" ) and g . app . gui . is_curses ( ) :
",61.3,35.82,False
"def getProc ( su , innerTarget ) : <TAB> if len ( su ) == 1 :<TAB> # have a one element wedge <TAB> <TAB> proc = ( "" first "" , "" last "" ) <TAB> else : <TAB> <TAB> if su . isFirst ( innerTarget ) and su . isLast ( innerTarget ) : <TAB> <TAB> <TAB> proc = ( "" first "" , "" last "" )<TAB> # same element can be first and last <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> proc = ( "" first "" , ) <TAB> <TAB> elif su . isLast ( innerTarget ) : <TAB> <TAB> <TAB> proc = ( "" last "" , ) <TAB> <TAB> else : <TAB> <TAB> <TAB> proc = ( ) <TAB> return proc ","elif su . isFirst ( innerTarget ) : 
","elif su . isFirst ( innerTarget ) :
",100.0,100.0,True
"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB> <TAB> if iterations > 100 : <TAB> <TAB> <TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> status = self . master . get_status ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> iterations + = 1 <TAB> <TAB> time . sleep ( 1.0 ) ","if status . get ( "" status "" ) == "" ENDED "" : 
","if status . is_running ( ) :
",32.16,10.84,False
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> elif isinstance ( text , ShellText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( ) ","if isinstance ( text , CodeViewText ) : 
","if isinstance ( text , CodeViewText ) :
",100.0,100.0,True
"def validate_party_details ( self ) : <TAB> if self . party : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB> <TAB> if self . party_account and self . party_type in ( "" Customer "" , "" Supplier "" ) : <TAB> <TAB> <TAB> self . validate_account_type ( <TAB> <TAB> <TAB> <TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB> <TAB> <TAB> ) ","if not frappe . db . exists ( self . party_type , self . party ) : 
","if not self . party_type in ( "" Customer "" , "" Supplier "" ) :
",37.94,25.63,False
"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB> <TAB> elif piece : <TAB> <TAB> <TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces ) ","if i % 2 : 
","if i % 2 :
",100.0,100.0,True
"def _convert_java_pattern_to_python ( pattern ) : <TAB> """"""Convert a replacement pattern from the Java-style `$5` to the Python-style `\\5`."""""" <TAB> s = list ( pattern ) <TAB> i = 0 <TAB> while i < len ( s ) - 1 : <TAB> <TAB> c = s [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s [ i ] = "" \\ "" <TAB> <TAB> elif c == "" \\ "" and s [ i + 1 ] == "" $ "" : <TAB> <TAB> <TAB> s [ i ] = "" "" <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> i + = 1 <TAB> return pattern [ : 0 ] . join ( s ) ","if c == "" $ "" and s [ i + 1 ] in "" 0123456789 "" : 
","if c == "" \\ "" and s [ i + 1 ] == "" $ "" :
",71.82,63.64,False
"def download ( self , url , filename , * * kwargs ) : <TAB> try : <TAB> <TAB> r = self . get ( url , timeout = 10 , stream = True , * * kwargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> with open ( filename , "" wb "" ) as f : <TAB> <TAB> <TAB> for chunk in r . iter_content ( chunk_size = 1024 ) : <TAB> <TAB> <TAB> <TAB> if chunk : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( chunk ) <TAB> <TAB> helpers . chmod_as_parent ( filename ) <TAB> except Exception as e : <TAB> <TAB> sickrage . app . log . debug ( <TAB> <TAB> <TAB> "" Failed to download file from  {}  - ERROR:  {} "" . format ( url , e ) <TAB> <TAB> ) <TAB> <TAB> if os . path . exists ( filename ) : <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> <TAB> return False <TAB> return True ","if r . status_code > = 400 : 
","if not r :
",26.99,4.69,False
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedFilesWithExtension ( "" js "" ) : <TAB> <TAB> items . append ( <TAB> <TAB> <TAB> ' <script type= "" text/javascript ""  src= "" ' <TAB> <TAB> <TAB> + item . pathAbsoluteFromProjectEncoded ( ) <TAB> <TAB> <TAB> + ' "" ></script> ' <TAB> <TAB> ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" ) ","if len ( items ) > 1 : 
","if len ( items ) > 1 :
",100.0,100.0,True
"def work ( self ) : <TAB> while True : <TAB> <TAB> timeout = self . timeout <TAB> <TAB> if idle . is_set ( ) : <TAB> <TAB> <TAB> timeout = self . idle_timeout <TAB> <TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB> <TAB> fetch . wait ( timeout ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Stop fetch worker "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . fetch ( ) ","if shutting_down . is_set ( ) : 
","if fetch . is_set ( ) :
",82.41,60.11,False
"def check_apns_certificate ( ss ) : <TAB> mode = "" start "" <TAB> for s in ss . split ( "" \n "" ) : <TAB> <TAB> if mode == "" start "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> mode = "" key "" <TAB> <TAB> elif mode == "" key "" : <TAB> <TAB> <TAB> if "" END RSA PRIVATE KEY "" in s or "" END PRIVATE KEY "" in s : <TAB> <TAB> <TAB> <TAB> mode = "" end "" <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif s . startswith ( "" Proc-Type "" ) and "" ENCRYPTED "" in s : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrypted APNS private keys are not supported "" <TAB> <TAB> <TAB> <TAB> ) <TAB> if mode != "" end "" : <TAB> <TAB> raise ImproperlyConfigured ( "" The APNS certificate doesn ' t contain a private key "" ) ","if "" BEGIN RSA PRIVATE KEY "" in s or "" BEGIN PRIVATE KEY "" in s : 
","if "" RSA PRIVATE KEY "" in s or "" PRIVATE KEY "" in s :
",84.83,69.33,False
"def compare_lists ( self , l1 , l2 , key ) : <TAB> l2_lookup = { o . get ( key ) : o for o in l2 } <TAB> for obj1 in l1 : <TAB> <TAB> obj2 = l2_lookup . get ( obj1 . get ( key ) ) <TAB> <TAB> for k in obj1 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( obj1 . get ( k ) , obj2 . get ( k ) ) ","if k not in "" id "" and obj1 . get ( k ) : 
","if k in obj2 :
",26.37,3.44,False
"def before_get_object ( self , view_kwargs ) : <TAB> if view_kwargs . get ( "" id "" ) is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> user_favourite_event = find_user_favourite_event_by_id ( <TAB> <TAB> <TAB> <TAB> event_id = view_kwargs [ "" id "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> except NoResultFound : <TAB> <TAB> <TAB> raise ObjectNotFound ( <TAB> <TAB> <TAB> <TAB> { "" source "" : "" /data/relationships/event "" } , "" Object: not found "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> view_kwargs [ "" id "" ] = user_favourite_event . id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> view_kwargs [ "" id "" ] = None ","if user_favourite_event is not None : 
","if user_favourite_event :
",29.58,54.78,False
"def close ( self ) : <TAB> super ( ) . close ( ) <TAB> if not sys . is_finalizing ( ) : <TAB> <TAB> for sig in list ( self . _signal_handlers ) : <TAB> <TAB> <TAB> self . remove_signal_handler ( sig ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> f "" Closing the loop  { self !r} "" <TAB> <TAB> <TAB> <TAB> f "" on interpreter shutdown  "" <TAB> <TAB> <TAB> <TAB> f "" stage, skipping signal handlers removal "" , <TAB> <TAB> <TAB> <TAB> ResourceWarning , <TAB> <TAB> <TAB> <TAB> source = self , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _signal_handlers . clear ( ) ","if self . _signal_handlers : 
","if not self . _signal_handlers :
",64.44,75.06,False
"def install_script ( self , script , install_options = None ) : <TAB> try : <TAB> <TAB> fname = utils . do_script ( <TAB> <TAB> <TAB> script , <TAB> <TAB> <TAB> python_exe = osp . join ( self . target , "" python.exe "" ) , <TAB> <TAB> <TAB> architecture = self . architecture , <TAB> <TAB> <TAB> verbose = self . verbose , <TAB> <TAB> <TAB> install_options = install_options , <TAB> <TAB> ) <TAB> except RuntimeError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Failed! "" ) <TAB> <TAB> <TAB> raise ","if not self . verbose : 
","if self . verbose :
",58.31,57.89,False
"def GetRouterForUser ( self , username ) : <TAB> """"""Returns a router corresponding to a given username."""""" <TAB> for index , router in enumerate ( self . routers ) : <TAB> <TAB> router_id = str ( index ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . debug ( <TAB> <TAB> <TAB> <TAB> "" Matched router  %s  to user  %s "" , router . __class__ . __name__ , username <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return router <TAB> logging . debug ( <TAB> <TAB> "" No router ACL rule match for user  %s . Using default  "" "" router  %s "" , <TAB> <TAB> username , <TAB> <TAB> self . default_router . __class__ . __name__ , <TAB> ) <TAB> return self . default_router ","if self . auth_manager . CheckPermissions ( username , router_id ) : 
","if router . username == username :
",30.4,3.04,False
"def charset ( self ) : <TAB> """"""The charset from the content type."""""" <TAB> header = self . environ . get ( "" CONTENT_TYPE "" ) <TAB> if header : <TAB> <TAB> ct , options = parse_options_header ( header ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if is_known_charset ( charset ) : <TAB> <TAB> <TAB> <TAB> return charset <TAB> <TAB> <TAB> return self . unknown_charset ( charset ) <TAB> return self . default_charset ","if charset : 
","if charset :
",78.12,0.0,False
def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self . count > self . epiLen : <TAB> <TAB> self . res ( ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> if self . count == 1 : <TAB> <TAB> <TAB> self . pertGlasPos ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . env . reset ( ) <TAB> <TAB> <TAB> self . pertGlasPos ( 1 ) <TAB> <TAB> self . count + = 1 <TAB> <TAB> return False ,"if self . count == self . epiLen / 2 + 1 : 
","elif self . count == 2 :
",41.97,26.56,False
"def mtimes_of_files ( dirnames : List [ str ] , suffix : str ) - > Iterator [ float ] : <TAB> for dirname in dirnames : <TAB> <TAB> for root , dirs , files in os . walk ( dirname ) : <TAB> <TAB> <TAB> for sfile in files : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield path . getmtime ( path . join ( root , sfile ) ) <TAB> <TAB> <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass ","if sfile . endswith ( suffix ) : 
","if sfile . endswith ( suffix ) :
",100.0,100.0,True
"def get_all_hashes ( self ) : <TAB> event_hashes = [ ] <TAB> sample_hashes = [ ] <TAB> for a in self . event . attributes : <TAB> <TAB> h = None <TAB> <TAB> if a . type in ( "" md5 "" , "" sha1 "" , "" sha256 "" ) : <TAB> <TAB> <TAB> h = a . value <TAB> <TAB> <TAB> event_hashes . append ( h ) <TAB> <TAB> elif a . type in ( "" filename|md5 "" , "" filename|sha1 "" , "" filename|sha256 "" ) : <TAB> <TAB> <TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB> <TAB> <TAB> event_hashes . append ( h ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> h = a . value . split ( "" | "" ) [ 1 ] <TAB> <TAB> <TAB> sample_hashes . append ( h ) <TAB> return event_hashes , sample_hashes ","elif a . type == "" malware-sample "" : 
","elif a . type in ( "" sample|sample "" , "" sample "" ) :
",51.09,16.47,False
"def _validate ( self , event ) : <TAB> if self . type is None : <TAB> <TAB> return <TAB> new = self . value <TAB> if not isinstance ( new , self . type ) and new is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . value = event . old <TAB> <TAB> types = repr ( self . type ) if isinstance ( self . type , tuple ) else self . type . __name__ <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" LiteralInput expected  %s  type but value  %s "" <TAB> <TAB> <TAB> "" is of type  %s . "" % ( types , new , type ( new ) . __name__ ) <TAB> <TAB> ) ","if event : 
","if new != event . old :
",29.83,7.27,False
"def update_dict ( a , b ) : <TAB> for key , value in b . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if key not in a : <TAB> <TAB> <TAB> a [ key ] = value <TAB> <TAB> elif isinstance ( a [ key ] , dict ) and isinstance ( value , dict ) : <TAB> <TAB> <TAB> update_dict ( a [ key ] , value ) <TAB> <TAB> elif isinstance ( a [ key ] , list ) : <TAB> <TAB> <TAB> a [ key ] . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> a [ key ] = [ a [ key ] , value ] ","if value is None : 
","if key == "" __class__ "" :
",27.53,4.03,False
"def on_pre_save ( self , view ) : <TAB> extOrClause = "" | "" . join ( s . get ( "" format_on_save_extensions "" ) ) <TAB> extRegex = "" \\ .( "" + extOrClause + "" )$ "" <TAB> if s . get ( "" format_on_save "" ) and re . search ( extRegex , view . file_name ( ) ) : <TAB> <TAB> # only auto-format on save if there are no ""lint errors"" <TAB> <TAB> # here are some named regions from sublimelint see https://github.com/lunixbochs/sublimelint/tree/st3 <TAB> <TAB> lints_regions = [ "" lint-keyword-underline "" , "" lint-keyword-outline "" ] <TAB> <TAB> for linter in lints_regions : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> view . run_command ( "" js_format "" ) ","if len ( view . get_regions ( linter ) ) : 
","if not linter . check_for_format ( view . file_name ( ) ) :
",36.55,14.4,False
"def readMemory ( self , va , size ) : <TAB> for mva , mmaxva , mmap , mbytes in self . _map_defs : <TAB> <TAB> if mva < = va < mmaxva : <TAB> <TAB> <TAB> mva , msize , mperms , mfname = mmap <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise envi . SegmentationViolation ( va ) <TAB> <TAB> <TAB> offset = va - mva <TAB> <TAB> <TAB> return mbytes [ offset : offset + size ] <TAB> raise envi . SegmentationViolation ( va ) ","if not mperms & MM_READ : 
","if not mperms & self . FLAG_READ :
",47.94,37.99,False
"def assertFilepathsEqual ( self , p1 , p2 ) : <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p1 = [ normcase ( normpath ( x ) ) for x in p1 ] <TAB> <TAB> <TAB> p2 = [ normcase ( normpath ( x ) ) for x in p2 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> assert isinstance ( p1 , ( str , unicode ) ) <TAB> <TAB> <TAB> p1 = normcase ( normpath ( p1 ) ) <TAB> <TAB> <TAB> p2 = normcase ( normpath ( p2 ) ) <TAB> self . assertEqual ( p1 , p2 ) ","if isinstance ( p1 , ( list , tuple ) ) : 
","if isinstance ( p1 , ( list , tuple ) ) :
",100.0,100.0,True
"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB> <TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB> <TAB> path = join ( dir_path , p ) <TAB> <TAB> if isdir ( path ) : <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files ( path , paths ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths . append ( path ) <TAB> return paths ","elif isfile ( path ) and path . endswith ( "" .csv "" ) : 
","elif isfile ( path ) :
",42.2,15.88,False
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB> <TAB> <TAB> if not inst . modctxt : <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ","if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : 
","if not isinstance ( inst , ( _Block , _Instantiator ) ) :
",61.59,76.68,False
"def __annotations_bytes ( self ) : <TAB> if self . annotations : <TAB> <TAB> a = [ ] <TAB> <TAB> for k , v in self . annotations . items ( ) : <TAB> <TAB> <TAB> if len ( k ) != 4 : <TAB> <TAB> <TAB> <TAB> raise errors . ProtocolError ( "" annotation key must be of length 4 "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> k = k . encode ( "" ASCII "" ) <TAB> <TAB> <TAB> a . append ( struct . pack ( "" !4sH "" , k , len ( v ) ) ) <TAB> <TAB> <TAB> a . append ( v ) <TAB> <TAB> return b "" "" . join ( a ) <TAB> return b "" "" ","if sys . version_info > = ( 3 , 0 ) : 
","if isinstance ( k , str ) :
",27.34,6.56,False
"def session ( self , profile : str = "" default "" , region : str = None ) - > boto3 . Session : <TAB> region = self . _get_region ( region , profile ) <TAB> try : <TAB> <TAB> session = self . _cache_lookup ( <TAB> <TAB> <TAB> self . _session_cache , <TAB> <TAB> <TAB> [ profile , region ] , <TAB> <TAB> <TAB> self . _boto3 . Session , <TAB> <TAB> <TAB> [ ] , <TAB> <TAB> <TAB> { "" region_name "" : region , "" profile_name "" : profile } , <TAB> <TAB> ) <TAB> except ProfileNotFound : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> session = self . _boto3 . Session ( region_name = region ) <TAB> <TAB> self . _cache_set ( self . _session_cache , [ profile , region ] , session ) <TAB> return session ","if profile != "" default "" : 
","if region is None :
",27.23,6.97,False
"def spans_score ( gold_spans , system_spans ) : <TAB> correct , gi , si = 0 , 0 , 0 <TAB> while gi < len ( gold_spans ) and si < len ( system_spans ) : <TAB> <TAB> if system_spans [ si ] . start < gold_spans [ gi ] . start : <TAB> <TAB> <TAB> si + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gi + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> correct + = gold_spans [ gi ] . end == system_spans [ si ] . end <TAB> <TAB> <TAB> si + = 1 <TAB> <TAB> <TAB> gi + = 1 <TAB> return Score ( len ( gold_spans ) , len ( system_spans ) , correct ) ","elif gold_spans [ gi ] . start < system_spans [ si ] . start : 
","elif gold_spans [ si ] . end > system_spans [ si ] . end :
",68.69,54.02,False
"def to_api ( tag , raw_value ) : <TAB> try : <TAB> <TAB> api_tag , converter = _QL_TO_SC [ tag ] if tag else ( "" q "" , None ) <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise self . error ( <TAB> <TAB> <TAB> <TAB> "" Unsupported  ' %s '  tag. Try:  %s "" % ( tag , "" ,  "" . join ( SUPPORTED ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None , None <TAB> else : <TAB> <TAB> value = str ( converter ( raw_value ) if converter else raw_value ) <TAB> <TAB> return api_tag , value ","if tag not in SUPPORTED : 
","if tag not in SUPPORTED :
",100.0,100.0,True
"def unpack ( self , buf ) : <TAB> dpkt . Packet . unpack ( self , buf ) <TAB> buf = buf [ self . __hdr_len__ : ] <TAB> # single-byte IE <TAB> if self . type & 0x80 : <TAB> <TAB> self . len = 0 <TAB> <TAB> self . data = b "" "" <TAB> # multi-byte IE <TAB> else : <TAB> <TAB> # special PER-encoded UUIE <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . len = struct . unpack ( "" >H "" , buf [ : 2 ] ) [ 0 ] <TAB> <TAB> <TAB> buf = buf [ 2 : ] <TAB> <TAB> # normal TLV-like IE <TAB> <TAB> else : <TAB> <TAB> <TAB> self . len = struct . unpack ( "" B "" , buf [ : 1 ] ) [ 0 ] <TAB> <TAB> <TAB> buf = buf [ 1 : ] <TAB> <TAB> self . data = buf [ : self . len ] ","if self . type == USER_TO_USER : 
","if len ( buf ) > 2 :
",26.89,3.98,False
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : <TAB> <TAB> <TAB> return self . current_provider . on_file ( query ) ","if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : 
","if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH :
",100.0,100.0,True
"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB> <TAB> if not typ : <TAB> <TAB> <TAB> out + = text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out + = "" \\ fI %s \\ fR "" % text <TAB> <TAB> elif typ in [ "" strong "" , "" code "" ] : <TAB> <TAB> <TAB> out + = "" \\ fB %s \\ fR "" % text <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out ","elif typ == "" em "" : 
","elif typ in [ "" usenet "" , "" stime "" ] :
",38.3,7.77,False
"def process ( self , buckets ) : <TAB> with self . executor_factory ( max_workers = 3 ) as w : <TAB> <TAB> futures = { } <TAB> <TAB> results = [ ] <TAB> <TAB> for b in buckets : <TAB> <TAB> <TAB> futures [ w . submit ( self . process_bucket , b ) ] = b <TAB> <TAB> for f in as_completed ( futures ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> b = futures [ f ] <TAB> <TAB> <TAB> <TAB> self . log . error ( <TAB> <TAB> <TAB> <TAB> <TAB> "" error modifying bucket: %s \n %s "" , b [ "" Name "" ] , f . exception ( ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> results + = filter ( None , [ f . result ( ) ] ) <TAB> <TAB> return results ","if f . exception ( ) : 
","if f . exception ( ) :
",100.0,100.0,True
"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB> <TAB> <TAB> <TAB> "" False. "" % self . alias <TAB> <TAB> <TAB> ) <TAB> <TAB> elif self . features . supports_timezones : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB> <TAB> <TAB> <TAB> "" handles time zones conversions natively. "" % self . alias <TAB> <TAB> <TAB> ) ","if not settings . USE_TZ : 
","if self . settings_dict [ "" USE_TZ "" ] is True :
",33.24,11.25,False
"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB> <TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB> <TAB> if each : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> key , value = each . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> key , value = each , "" "" <TAB> <TAB> <TAB> result [ key ] = value <TAB> namespace . webhook_properties = result ","if "" = "" in each : 
","if "" = "" in each :
",100.0,100.0,True
"def _expand_query_values ( original_query_list ) : <TAB> query_list = [ ] <TAB> for key , value in original_query_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> query_list . append ( ( key , value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> key_fmt = key + "" [ %s ] "" <TAB> <TAB> <TAB> value_list = _to_kv_list ( value ) <TAB> <TAB> <TAB> query_list . extend ( ( key_fmt % k , v ) for k , v in value_list ) <TAB> return query_list ","if isinstance ( value , basestring ) : 
","if isinstance ( value , dict ) :
",79.9,59.46,False
"def tags ( ) : <TAB> """"""Return a dictionary of all tags in the form {hash: [tag_names, ...]}."""""" <TAB> tags = { } <TAB> for ( n , c ) in list_refs ( ) : <TAB> <TAB> if n . startswith ( "" refs/tags/ "" ) : <TAB> <TAB> <TAB> name = n [ 10 : ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tags [ c ] = [ ] <TAB> <TAB> <TAB> tags [ c ] . append ( name )<TAB> # more than one tag can point at 'c' <TAB> return tags ","if not c in tags : 
","if c not in tags :
",43.26,35.93,False
"def test_colorspiral ( self ) : <TAB> """"""Set of 625 colours, with jitter, using get_colors()."""""" <TAB> boxedge = 20 <TAB> boxes_per_row = 25 <TAB> rows = 0 <TAB> for i , c in enumerate ( get_colors ( 625 ) ) : <TAB> <TAB> self . c . setFillColor ( c ) <TAB> <TAB> x1 = boxedge * ( i % boxes_per_row ) <TAB> <TAB> y1 = rows * boxedge <TAB> <TAB> self . c . rect ( x1 , y1 , boxedge , boxedge , fill = 1 , stroke = 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rows + = 1 <TAB> self . finish ( ) ","if not ( i + 1 ) % boxes_per_row : 
","if i % boxes_per_row == 0 :
",27.83,39.09,False
"def oldest_pending_update_in_days ( ) : <TAB> """"""Return the datestamp of the oldest pending update"""""" <TAB> pendingupdatespath = os . path . join ( <TAB> <TAB> prefs . pref ( "" ManagedInstallDir "" ) , "" UpdateNotificationTracking.plist "" <TAB> ) <TAB> try : <TAB> <TAB> pending_updates = FoundationPlist . readPlist ( pendingupdatespath ) <TAB> except FoundationPlist . NSPropertyListSerializationException : <TAB> <TAB> return 0 <TAB> oldest_date = now = NSDate . date ( ) <TAB> for category in pending_updates : <TAB> <TAB> for name in pending_updates [ category ] : <TAB> <TAB> <TAB> this_date = pending_updates [ category ] [ name ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> oldest_date = this_date <TAB> return now . timeIntervalSinceDate_ ( oldest_date ) / ( 24 * 60 * 60 ) ","if this_date < oldest_date : 
","if this_date . is_valid ( ) and this_date . is_valid ( ) :
",29.26,14.05,False
"def _try_read_gpg ( path ) : <TAB> path = os . path . expanduser ( path ) <TAB> cmd = _gpg_cmd ( ) + [ path ] <TAB> log . debug ( "" gpg cmd:  %s "" , cmd ) <TAB> try : <TAB> <TAB> p = subprocess . Popen ( <TAB> <TAB> <TAB> cmd , env = os . environ , stdout = subprocess . PIPE , stderr = subprocess . PIPE <TAB> <TAB> ) <TAB> except OSError as e : <TAB> <TAB> log . error ( "" cannot decode  %s  with command  ' %s '  ( %s ) "" , path , "" "" . join ( cmd ) , e ) <TAB> else : <TAB> <TAB> out , err = p . communicate ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . error ( err . decode ( errors = "" replace "" ) . strip ( ) ) <TAB> <TAB> <TAB> return None <TAB> <TAB> return out . decode ( errors = "" replace "" ) ","if p . returncode != 0 : 
","if err :
",27.04,0.0,False
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( v [ i ] , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d ","if isinstance ( v , list ) : 
","if isinstance ( v , dict ) :
",79.9,59.46,False
"def _the_callback ( widget , event_id ) : <TAB> point = widget . GetCenter ( ) <TAB> index = widget . WIDGET_INDEX <TAB> if hasattr ( callback , "" __call__ "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args = [ point , index ] <TAB> <TAB> else : <TAB> <TAB> <TAB> args = [ point ] <TAB> <TAB> if pass_widget : <TAB> <TAB> <TAB> args . append ( widget ) <TAB> <TAB> try_callback ( callback , * args ) <TAB> return ","if num > 1 : 
","if pass_widget :
",28.55,12.7,False
"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB> <TAB> new_parameter = copy . deepcopy ( hp ) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_parameter . name = prefix <TAB> <TAB> elif not prefix == "" "" : <TAB> <TAB> <TAB> new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB> <TAB> new_parameters . append ( new_parameter ) <TAB> for hp in new_parameters : <TAB> <TAB> _add_hp ( master_cs , hp ) ","if new_parameter . name == "" "" : 
","if new_parameter . name == "" "" :
",100.0,100.0,True
"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . server . stop ( ) <TAB> <TAB> if self . sl_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self ) ","if self . server : 
","if self . server :
",100.0,100.0,True
"def app_uninstall_all ( self , excludes = [ ] , verbose = False ) : <TAB> """"""Uninstall all apps"""""" <TAB> our_apps = [ "" com.github.uiautomator "" , "" com.github.uiautomator.test "" ] <TAB> output , _ = self . shell ( [ "" pm "" , "" list "" , "" packages "" , "" -3 "" ] ) <TAB> pkgs = re . findall ( r "" package:([^ \ s]+) "" , output ) <TAB> pkgs = set ( pkgs ) . difference ( our_apps + excludes ) <TAB> pkgs = list ( pkgs ) <TAB> for pkg_name in pkgs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" uninstalling "" , pkg_name , "" "" , end = "" "" , flush = True ) <TAB> <TAB> ok = self . app_uninstall ( pkg_name ) <TAB> <TAB> if verbose : <TAB> <TAB> <TAB> print ( "" OK "" if ok else "" FAIL "" ) <TAB> return pkgs ","if verbose : 
","if verbose :
",78.12,0.0,False
"def httpapi ( self , arg , opts ) : <TAB> sc = HttpAPIStatsCollector ( ) <TAB> headers = [ "" #Item "" , "" Value "" ] <TAB> table = [ ] <TAB> for k , v in sc . get ( ) . getStats ( ) . items ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = json . dumps ( v ) <TAB> <TAB> row = [ ] <TAB> <TAB> row . append ( "" # %s "" % k ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> row . append ( formatDateTime ( v ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> row . append ( v ) <TAB> <TAB> table . append ( row ) <TAB> self . protocol . sendData ( <TAB> <TAB> tabulate ( table , headers , tablefmt = "" plain "" , numalign = "" left "" ) . encode ( "" ascii "" ) <TAB> ) ","if k [ - 3 : ] == "" _at "" : 
","if k == "" timestamp "" :
",31.7,14.27,False
"def Get_Gene ( self , id ) : <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self . Get ( id ) <TAB> if not entry : <TAB> <TAB> return None <TAB> GN = "" "" <TAB> for line in string . split ( entry , "" \n "" ) : <TAB> <TAB> if line [ 0 : 5 ] == "" GN<TAB> "" : <TAB> <TAB> <TAB> GN = string . strip ( line [ 5 : ] ) <TAB> <TAB> <TAB> if GN [ - 1 ] == "" . "" : <TAB> <TAB> <TAB> <TAB> GN = GN [ 0 : - 1 ] <TAB> <TAB> <TAB> return GN <TAB> <TAB> if line [ 0 : 2 ] == "" // "" : <TAB> <TAB> <TAB> break <TAB> return GN ","if line [ 0 : 5 ] == "" GN    "" : 
","if line [ 0 : 5 ] == "" GN    "" :
",100.0,100.0,True
"def replace_dir_vars ( path , d ) : <TAB> """"""Replace common directory paths with appropriate variable references (e.g. /etc becomes ${sysconfdir})"""""" <TAB> dirvars = { } <TAB> # Sort by length so we get the variables we're interested in first <TAB> for var in sorted ( list ( d . keys ( ) ) , key = len ) : <TAB> <TAB> if var . endswith ( "" dir "" ) and var . lower ( ) == var : <TAB> <TAB> <TAB> value = d . getVar ( var ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dirvars [ value ] = var <TAB> for dirpath in sorted ( list ( dirvars . keys ( ) ) , reverse = True ) : <TAB> <TAB> path = path . replace ( dirpath , "" $ { %s } "" % dirvars [ dirpath ] ) <TAB> return path ","if value . startswith ( "" / "" ) and not "" \n "" in value and value not in dirvars : 
","if value :
",25.52,0.0,False
"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> source = os . path . join ( root , filename ) <TAB> <TAB> <TAB> with open ( source , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> lines = f . readlines ( ) <TAB> <TAB> <TAB> if len ( lines ) < 1 : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open ( source , "" w "" ) as f : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( lines [ 0 ] ) <TAB> <TAB> <TAB> <TAB> for line in lines [ 1 : ] : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( line ) ","if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) : 
","if lines [ 0 ] . endswith ( "" .py "" ) :
",39.51,14.57,False
"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> all_plugins + = [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name , plugin in self . plugins . items ( ) <TAB> <TAB> <TAB> <TAB> if name not in self . plugins_callback_order and plugin . is_activated <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> plugin = self . plugins [ name ] <TAB> <TAB> <TAB> if plugin . is_activated : <TAB> <TAB> <TAB> <TAB> all_plugins . append ( plugin ) <TAB> return all_plugins ","if name is None : 
","if name is None :
",100.0,100.0,True
"def test_query_level ( self ) : <TAB> "" Tests querying at a level other than max "" <TAB> # level 2 <TAB> l2 = set ( ) <TAB> for p in self . tile_paths : <TAB> <TAB> l2 . add ( p [ 0 : 2 ] ) <TAB> for path in iterate_base4 ( 2 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertTrue ( self . tree . query_path ( path ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertFalse ( self . tree . query_path ( path ) ) <TAB> # level 1: <TAB> self . assertTrue ( self . tree . query_path ( ( 0 , ) ) ) <TAB> self . assertTrue ( self . tree . query_path ( ( 1 , ) ) ) <TAB> self . assertTrue ( self . tree . query_path ( ( 2 , ) ) ) <TAB> self . assertFalse ( self . tree . query_path ( ( 3 , ) ) ) ","if path in l2 : 
","if path in l2 :
",100.0,100.0,True
"def program_exists ( name ) : <TAB> paths = ( os . getenv ( "" PATH "" ) or os . defpath ) . split ( os . pathsep ) <TAB> for p in paths : <TAB> <TAB> fn = "" %s / %s "" % ( p , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return not os . path . isdir ( fn ) and os . access ( fn , os . X_OK ) ","if os . path . exists ( fn ) : 
","if os . path . exists ( fn ) :
",100.0,100.0,True
"def decoration_helper ( self , patched , args , keywargs ) : <TAB> extra_args = [ ] <TAB> with contextlib . ExitStack ( ) as exit_stack : <TAB> <TAB> for patching in patched . patchings : <TAB> <TAB> <TAB> arg = exit_stack . enter_context ( patching ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> keywargs . update ( arg ) <TAB> <TAB> <TAB> elif patching . new is DEFAULT : <TAB> <TAB> <TAB> <TAB> extra_args . append ( arg ) <TAB> <TAB> args + = tuple ( extra_args ) <TAB> <TAB> yield ( args , keywargs ) ","if patching . attribute_name is not None : 
","if patching . new is KEY :
",37.79,18.09,False
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . CONNECT_MODE : <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets ) ","if k == neighbors . ENABLED : 
","if k == neighbors . neighbor_enabled :
",82.41,53.73,False
"def calcUniqueStates ( self ) : <TAB> # Here we show which colors can be relied on to map to an <TAB> # internal state.  The current position will be at the first <TAB> # character in the buffer styled that color, so this might not <TAB> # work in all cases. <TAB> self . uniqueStates = { } <TAB> for k in self . holdUniqueStates . keys ( ) : <TAB> <TAB> v = self . holdUniqueStates [ k ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . uniqueStates [ k ] = v . keys ( ) [ 0 ] <TAB> <TAB> <TAB> log . debug ( "" Map style [ %s ] to state [ %s ] "" , k , v . keys ( ) [ 0 ] ) <TAB> <TAB> log . debug ( "" Style [ %s ] maps to states [ %s ] "" , k , "" ,  "" . join ( v . keys ( ) ) ) <TAB> self . holdUniqueStates = None ","if len ( v . keys ( ) ) == 1 : 
","if isinstance ( v , dict ) :
",27.34,7.43,False
"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB> <TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB> <TAB> elif "" filename "" in handler . keys ( ) : <TAB> <TAB> <TAB> filename = handler [ "" filename "" ] <TAB> <TAB> <TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB> <TAB> <TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config ) ","if handler_id not in used_handlers : 
","if handler_id in used_handlers :
",56.72,66.9,False
"def _selected_machines ( self , virtual_machines ) : <TAB> selected_machines = [ ] <TAB> for machine in virtual_machines : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . tags and self . _tags_match ( machine . tags , self . tags ) : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> <TAB> if self . locations and machine . location in self . locations : <TAB> <TAB> <TAB> selected_machines . append ( machine ) <TAB> return selected_machines ","if self . _args . host and self . _args . host == machine . name : 
","if self . _match ( machine . device , self . device ) :
",29.34,16.4,False
"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB> <TAB> key = "" pocsuite_target "" <TAB> <TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB> <TAB> logger . info ( info_msg ) <TAB> <TAB> targets = r . get ( key ) <TAB> <TAB> count = 0 <TAB> <TAB> if targets : <TAB> <TAB> <TAB> for target in targets : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB> <TAB> logger . info ( info_msg ) ","if self . add_target ( target ) : 
","if target [ "" name "" ] == "" pocsuite_target "" :
",26.58,6.61,False
"def tearDown ( self ) : <TAB> suffix = str ( os . getgid ( ) ) <TAB> cli = monitoring_v3 . MetricServiceClient ( ) <TAB> for md in cli . list_metric_descriptors ( "" projects/ {} "" . format ( PROJECT ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> cli . delete_metric_descriptor ( md . name ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass ","if "" OpenCensus "" in md . name and suffix in md . name : 
","if md . name . endswith ( suffix ) :
",35.1,11.71,False
"def InitializeColours ( self ) : <TAB> """"""Initializes the 16 custom colours in :class:`CustomPanel`."""""" <TAB> curr = self . _colourData . GetColour ( ) <TAB> self . _colourSelection = - 1 <TAB> for i in range ( 16 ) : <TAB> <TAB> c = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> if c . IsOk ( ) : <TAB> <TAB> <TAB> self . _customColours [ i ] = self . _colourData . GetCustomColour ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _customColours [ i ] = wx . WHITE <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _colourSelection = i ","if c == curr : 
","if c == curr :
",100.0,100.0,True
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> if index < 0 or index > = len ( self . features ) : <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ","if feature : 
","if len ( feature ) > 2 :
",29.65,7.27,False
"def _get_data_from_buffer ( obj ) : <TAB> try : <TAB> <TAB> view = memoryview ( obj ) <TAB> except TypeError : <TAB> <TAB> # try to use legacy buffer protocol if 2.7, otherwise re-raise <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> view = memoryview ( buffer ( obj ) ) <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" using old buffer interface to unpack  %s ;  "" <TAB> <TAB> <TAB> <TAB> "" this leads to unpacking errors if slicing is used and  "" <TAB> <TAB> <TAB> <TAB> "" will be removed in a future version "" % type ( obj ) , <TAB> <TAB> <TAB> <TAB> RuntimeWarning , <TAB> <TAB> <TAB> <TAB> stacklevel = 3 , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise <TAB> if view . itemsize != 1 : <TAB> <TAB> raise ValueError ( "" cannot unpack from multi-byte object "" ) <TAB> return view ","if PY2 : 
","if sys . version_info > = ( 2 , 7 , 0 ) :
",29.02,2.91,False
"def import_modules ( modules , safe = True ) : <TAB> """"""Safely import a list of *modules*"""""" <TAB> all = [ ] <TAB> for mname in modules : <TAB> <TAB> if mname . endswith ( "" .* "" ) : <TAB> <TAB> <TAB> to_load = expand_star ( mname ) <TAB> <TAB> else : <TAB> <TAB> <TAB> to_load = [ mname ] <TAB> <TAB> for module in to_load : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> all . append ( import_module ( module ) ) <TAB> <TAB> <TAB> except ImportError : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> return all ","if not safe : 
","if not safe :
",100.0,100.0,True
"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB> <TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB> <TAB> if type == "" V "" : <TAB> <TAB> <TAB> write_vuint ( port , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> write_vint ( port , value ) <TAB> <TAB> elif type == "" s "" : <TAB> <TAB> <TAB> write_bvec ( port , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( ) ","elif type == "" v "" : 
","elif type == "" v "" :
",100.0,100.0,True
"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB> <TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . mkdir ( folder ) <TAB> <TAB> <TAB> init_path = join ( folder , "" __init__.py "" ) <TAB> <TAB> <TAB> if not exists ( init_path ) : <TAB> <TAB> <TAB> <TAB> create_file ( init_path ) ","if not exists ( folder ) : 
","if not exists ( os . path . join ( folder , "" __init__.py "" ) ) :
",42.82,12.87,False
"def _get_node_type_specific_fields ( self , node_id : str , fields_key : str ) - > Any : <TAB> fields = self . config [ fields_key ] <TAB> node_tags = self . provider . node_tags ( node_id ) <TAB> if TAG_RAY_USER_NODE_TYPE in node_tags : <TAB> <TAB> node_type = node_tags [ TAG_RAY_USER_NODE_TYPE ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( f "" Unknown node type tag:  { node_type } . "" ) <TAB> <TAB> node_specific_config = self . available_node_types [ node_type ] <TAB> <TAB> if fields_key in node_specific_config : <TAB> <TAB> <TAB> fields = node_specific_config [ fields_key ] <TAB> return fields ","if node_type not in self . available_node_types : 
","if node_type not in self . available_node_types :
",100.0,100.0,True
"def _maybe_fix_sequence_in_union ( <TAB> aliases : List [ Alias ] , typecst : cst . SubscriptElement ) - > cst . SubscriptElement : <TAB> slc = typecst . slice <TAB> if isinstance ( slc , cst . Index ) : <TAB> <TAB> val = slc . value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return cst . ensure_type ( <TAB> <TAB> <TAB> <TAB> typecst . deep_replace ( val , _get_clean_type_from_subscript ( aliases , val ) ) , <TAB> <TAB> <TAB> <TAB> cst . SubscriptElement , <TAB> <TAB> <TAB> ) <TAB> return typecst ","if isinstance ( val , cst . Subscript ) : 
","if isinstance ( val , cst . SubscriptElement ) :
",85.49,70.71,False
"def cancel_download ( self , downloads ) : <TAB> # Make sure we're always dealing with a list <TAB> if isinstance ( downloads , Download ) : <TAB> <TAB> downloads = [ downloads ] <TAB> for download in downloads : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . cancel_current_download ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __paused = True <TAB> <TAB> <TAB> new_queue = queue . Queue ( ) <TAB> <TAB> <TAB> while not self . __queue . empty ( ) : <TAB> <TAB> <TAB> <TAB> queued_download = self . __queue . get ( ) <TAB> <TAB> <TAB> <TAB> if download == queued_download : <TAB> <TAB> <TAB> <TAB> <TAB> download . cancel ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> new_queue . put ( queued_download ) <TAB> <TAB> <TAB> self . __queue = new_queue <TAB> <TAB> <TAB> self . __paused = False ","if download == self . __current_download : 
","if not download . is_paused :
",33.71,5.01,False
"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB> <TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB> <TAB> if account . discriminator == "" easaccount "" : <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB> <TAB> else : <TAB> <TAB> <TAB> create_categories_for_folders ( account , db_session ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> set_labels_for_imapuids ( account , db_session ) <TAB> <TAB> db_session . commit ( ) ","if account . discriminator == "" gmailaccount "" : 
","if account . discriminator == ""imapuids "" :
",76.23,70.71,False
"def __init__ ( self , fmt = None , * args ) : <TAB> if not isinstance ( fmt , BaseException ) : <TAB> <TAB> Error . __init__ ( self , fmt , * args ) <TAB> else : <TAB> <TAB> e = fmt <TAB> <TAB> cls = e . __class__ <TAB> <TAB> fmt = "" %s . %s :  %s "" % ( cls . __module__ , cls . __name__ , e ) <TAB> <TAB> tb = sys . exc_info ( ) [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fmt + = "" \n "" <TAB> <TAB> <TAB> fmt + = "" "" . join ( traceback . format_tb ( tb ) ) <TAB> <TAB> Error . __init__ ( self , fmt ) ","if tb : 
","if tb :
",78.12,0.0,False
"def setLabel ( self , label ) : <TAB> if label is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . label . scene ( ) . removeItem ( self . label ) <TAB> <TAB> <TAB> self . label = None <TAB> else : <TAB> <TAB> if self . label is None : <TAB> <TAB> <TAB> self . label = TextItem ( ) <TAB> <TAB> <TAB> self . label . setParentItem ( self ) <TAB> <TAB> self . label . setText ( label ) <TAB> <TAB> self . _updateLabel ( ) ","if self . label is not None : 
","if self . label is not None :
",100.0,100.0,True
"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB> <TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . handle_request ( ) <TAB> <TAB> if self . event is not None and self . event . is_set ( ) : <TAB> <TAB> <TAB> break ","if rd : 
","if rd :
",78.12,0.0,False
"def generateCompressedFile ( inputfile , outputfile , formatstring ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> in_file = open ( inputfile , "" rb "" ) <TAB> <TAB> <TAB> in_data = in_file . read ( ) <TAB> <TAB> <TAB> out_file = open ( inputfile + "" .xz "" , "" wb "" ) <TAB> <TAB> <TAB> out_file . write ( xz . compress ( in_data ) ) <TAB> <TAB> <TAB> in_file . close ( ) <TAB> <TAB> <TAB> out_file . close ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tarout = tarfile . open ( outputfile , formatstring ) <TAB> <TAB> <TAB> tarout . add ( inputfile , arcname = os . path . basename ( inputfile ) ) <TAB> <TAB> <TAB> tarout . close ( ) <TAB> except Exception as e : <TAB> <TAB> print ( e ) <TAB> <TAB> return False <TAB> return True ","if formatstring == "" w:xz "" : 
","if formatstring == "" gzip "" :
",74.63,46.31,False
"def _datastore_get_handler ( signal , sender , keys , * * kwargs ) : <TAB> txn = current_transaction ( ) <TAB> if txn : <TAB> <TAB> for key in keys : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise PreventedReadError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Attempted to read key ( %s : %s ) inside a transaction  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" where it was marked protected "" % ( key . kind ( ) , key . id_or_name ( ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> txn . _fetched_keys . update ( set ( keys ) ) ","if key in txn . _protected_keys : 
","if key . protected :
",35.56,9.88,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def write_vuint ( port , x ) : <TAB> if x < 0 : <TAB> <TAB> raise Exception ( "" vuints must not be negative "" ) <TAB> elif x == 0 : <TAB> <TAB> port . write ( "" \0 "" ) <TAB> else : <TAB> <TAB> while x : <TAB> <TAB> <TAB> seven_bits = x & 0x7F <TAB> <TAB> <TAB> x >> = 7 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> port . write ( chr ( 0x80 | seven_bits ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> port . write ( chr ( seven_bits ) ) ","if x : 
","if x & 0x80 :
",34.79,23.64,False
"def _expand_srcs ( self ) : <TAB> """"""Expand src to [(src, full_path)]"""""" <TAB> result = [ ] <TAB> for src in self . srcs : <TAB> <TAB> full_path = self . _source_file_path ( src ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Assume generated <TAB> <TAB> <TAB> full_path = self . _target_file_path ( src ) <TAB> <TAB> result . append ( ( src , full_path ) ) <TAB> return result ","if not os . path . exists ( full_path ) : 
","if not full_path :
",27.24,12.38,False
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/ops "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if "" init "" not in item . keywords : 
","if "" init "" not in item . keywords :
",100.0,100.0,True
"def set_shape ( self , shape ) : <TAB> """"""Sets a shape."""""" <TAB> if self . _shape is not None : <TAB> <TAB> logger . warning ( ' Modifying the shape of Placeholder  "" %s "" . ' , self . name ) <TAB> if not isinstance ( shape , ( list , tuple ) ) : <TAB> <TAB> shape = ( shape , ) <TAB> shape = tuple ( x if x != "" None "" else None for x in shape ) <TAB> for x in shape : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ParsingError ( <TAB> <TAB> <TAB> <TAB> ' All entries in  "" shape ""  must be integers, or in special  ' <TAB> <TAB> <TAB> <TAB> "" cases None. Shape is:  {} "" . format ( shape ) <TAB> <TAB> <TAB> ) <TAB> self . _shape = shape ","if not isinstance ( x , ( int , type ( None ) ) ) : 
","if not isinstance ( shape , ( int , float ) ) :
",43.52,37.78,False
"def _get_field_actual ( cant_be_number , raw_string , field_names ) : <TAB> for line in raw_string . splitlines ( ) : <TAB> <TAB> for field_name in field_names : <TAB> <TAB> <TAB> field_name = field_name . lower ( ) <TAB> <TAB> <TAB> if "" : "" in line : <TAB> <TAB> <TAB> <TAB> left , right = line . split ( "" : "" , 1 ) <TAB> <TAB> <TAB> <TAB> left = left . strip ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> right = right . strip ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if cant_be_number : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if not right . isdigit ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return right <TAB> return None ","if left == field_name and len ( right ) > 0 : 
","if left . lower ( ) == field_name :
",27.92,31.05,False
"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB> <TAB> value = getattr ( self , attribute . code , None ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> attribute . validate_value ( value ) <TAB> <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB> <TAB> <TAB> <TAB> ) ","if attribute . required : 
","if not attribute . is_blank :
",39.37,13.13,False
"def append ( self , s ) : <TAB> buf = self . buf <TAB> if buf is None : <TAB> <TAB> strbuf = self . strbuf <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . strbuf = strbuf + s <TAB> <TAB> <TAB> return <TAB> <TAB> buf = self . _create_buffer ( ) <TAB> buf . append ( s ) <TAB> # use buf.__len__ rather than len(buf) FBO of not getting <TAB> # OverflowError on Python 2 <TAB> sz = buf . __len__ ( ) <TAB> if not self . overflowed : <TAB> <TAB> if sz > = self . overflow : <TAB> <TAB> <TAB> self . _set_large_buffer ( ) ","if len ( strbuf ) + len ( s ) < STRBUF_LIMIT : 
","if strbuf is not None :
",26.01,2.38,False
"def billing_invoice_show_validator ( namespace ) : <TAB> from azure . cli . core . azclierror import ( <TAB> <TAB> RequiredArgumentMissingError , <TAB> <TAB> MutuallyExclusiveArgumentError , <TAB> ) <TAB> valid_combs = ( <TAB> <TAB> "" only --account-name, --name / --name / --name, --by-subscription is valid "" <TAB> ) <TAB> if namespace . account_name is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise MutuallyExclusiveArgumentError ( valid_combs ) <TAB> <TAB> if namespace . name is None : <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) <TAB> if namespace . by_subscription is not None : <TAB> <TAB> if namespace . name is None : <TAB> <TAB> <TAB> raise RequiredArgumentMissingError ( "" --name is also required "" ) ","if namespace . by_subscription is not None : 
","if namespace . name is None and namespace . by_subscription not in valid_combs :
",43.75,27.17,False
"def Handle ( self , args , context = None ) : <TAB> for client_id in args . client_ids : <TAB> <TAB> cid = str ( client_id ) <TAB> <TAB> data_store . REL_DB . RemoveClientLabels ( cid , context . username , args . labels ) <TAB> <TAB> labels_to_remove = set ( args . labels ) <TAB> <TAB> existing_labels = data_store . REL_DB . ReadClientLabels ( cid ) <TAB> <TAB> for label in existing_labels : <TAB> <TAB> <TAB> labels_to_remove . discard ( label . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> idx = client_index . ClientIndex ( ) <TAB> <TAB> <TAB> idx . RemoveClientLabels ( cid , labels_to_remove ) ","if labels_to_remove : 
","if len ( labels_to_remove ) > 0 :
",29.65,34.48,False
"def delete_snapshot ( self , snapshot ) : <TAB> snap_name = self . _get_snap_name ( snapshot [ "" id "" ] ) <TAB> LOG . debug ( "" Deleting snapshot ( %s ) "" , snapshot [ "" id "" ] ) <TAB> self . client_login ( ) <TAB> try : <TAB> <TAB> self . client . delete_snapshot ( snap_name , self . backend_type ) <TAB> except exception . DotHillRequestError as ex : <TAB> <TAB> # if the volume wasn't found, ignore the error <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> LOG . exception ( "" Deleting snapshot  %s  failed "" , snapshot [ "" id "" ] ) <TAB> <TAB> raise exception . Invalid ( ex ) <TAB> finally : <TAB> <TAB> self . client_logout ( ) ","if "" The volume was not found on this system. "" in ex . args : 
","if ex . status == 404 :
",31.37,4.26,False
"def jobs ( self ) : <TAB> # How many jobs have we done? <TAB> total_processed = 0 <TAB> for jobEntity in self . jobItems . query_entities ( ) : <TAB> <TAB> # Process the items in the page <TAB> <TAB> yield AzureJob . fromEntity ( jobEntity ) <TAB> <TAB> total_processed + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Produce some feedback for the user, because this can take <TAB> <TAB> <TAB> # a long time on, for example, Azure <TAB> <TAB> <TAB> logger . debug ( "" Processed  %d  total jobs "" % total_processed ) <TAB> logger . debug ( "" Processed  %d  total jobs "" % total_processed ) ","if total_processed % 1000 == 0 : 
","if total_processed % 100 == 0 :
",63.85,65.8,False
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> if dt > self . timeout : <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . stop ( ) ,"if self . counter == self . count : 
","elif dt < self . timeout :
",37.73,9.47,False
"def get_instance ( cls , pool_size = None ) : <TAB> if cls . _instance is not None : <TAB> <TAB> return cls . _instance <TAB> # Lazy init <TAB> with cls . _SINGLETON_LOCK : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _instance = cls ( <TAB> <TAB> <TAB> <TAB> ARCTIC_ASYNC_NWORKERS if pool_size is None else pool_size <TAB> <TAB> <TAB> ) <TAB> return cls . _instance ","if cls . _instance is None : 
","if cls . _instance is None :
",100.0,100.0,True
"def set_state ( self , state ) : <TAB> if self . _inhibit_play : <TAB> <TAB> # PLAYING, PAUSED change the state for after buffering is finished, <TAB> <TAB> # everything else aborts buffering <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # abort <TAB> <TAB> <TAB> self . __set_inhibit_play ( False ) <TAB> <TAB> <TAB> self . bin . set_state ( state ) <TAB> <TAB> <TAB> return <TAB> <TAB> self . _wanted_state = state <TAB> else : <TAB> <TAB> self . bin . set_state ( state ) ","if state not in ( Gst . State . PLAYING , Gst . State . PAUSED ) : 
","if state == self . _wanted_state :
",31.7,4.72,False
"def seen_add ( options ) : <TAB> seen_name = options . add_value <TAB> if is_imdb_url ( seen_name ) : <TAB> <TAB> console ( "" IMDB url detected, try to parse ID "" ) <TAB> <TAB> imdb_id = extract_id ( seen_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seen_name = imdb_id <TAB> <TAB> else : <TAB> <TAB> <TAB> console ( "" Could not parse IMDB ID "" ) <TAB> db . add ( seen_name , "" cli_add "" , { "" cli_add "" : seen_name } ) <TAB> console ( "" Added  %s  as seen. This will affect all tasks. "" % seen_name ) ","if imdb_id : 
","if imdb_id :
",78.12,100.0,True
"def test_204_invalid_content_length ( self ) : <TAB> # 204 status with non-zero content length is malformed <TAB> with ExpectLog ( gen_log , "" .*Response with code 204 should not have body "" ) : <TAB> <TAB> response = self . fetch ( "" /?error=1 "" ) <TAB> <TAB> if not self . http1 : <TAB> <TAB> <TAB> self . skipTest ( "" requires HTTP/1.x "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" curl client accepts invalid headers "" ) <TAB> <TAB> self . assertEqual ( response . code , 599 ) ","if self . http_client . configured_class != SimpleAsyncHTTPClient : 
","if not self . http1 . get ( "" content-length "" ) :
",37.72,7.19,False
"def set_related_perm ( _mapper : Mapper , _connection : Connection , target : Slice ) - > None : <TAB> src_class = target . cls_model <TAB> id_ = target . datasource_id <TAB> if id_ : <TAB> <TAB> ds = db . session . query ( src_class ) . filter_by ( id = int ( id_ ) ) . first ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> target . perm = ds . perm <TAB> <TAB> <TAB> target . schema_perm = ds . schema_perm ","if ds : 
","if ds :
",78.12,0.0,False
"def on_modified_async ( self , view ) : <TAB> if self . is_command_line ( view ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> view . run_command ( "" text_pastry_selection_preview "" ) ","if view . size ( ) > 6 and view . substr ( sublime . Region ( 0 , 6 ) ) . lower ( ) == "" search "" : 
","if view . command_line ( ) == "" text_pastry_selection_preview "" :
",39.39,14.46,False
"def _improve_answer_span ( <TAB> doc_tokens , input_start , input_end , tokenizer , orig_answer_text ) : <TAB> """"""Returns tokenized answer spans that better match the annotated answer."""""" <TAB> tok_answer_text = "" "" . join ( tokenizer . tokenize ( orig_answer_text ) ) <TAB> for new_start in range ( input_start , input_end + 1 ) : <TAB> <TAB> for new_end in range ( input_end , new_start - 1 , - 1 ) : <TAB> <TAB> <TAB> text_span = "" "" . join ( doc_tokens [ new_start : ( new_end + 1 ) ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return new_start , new_end <TAB> return input_start , input_end ","if text_span == tok_answer_text : 
","if text_span == tok_answer_text :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18 : <TAB> <TAB> <TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26 : <TAB> <TAB> <TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34 : <TAB> <TAB> <TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def _add_resource_group ( obj ) : <TAB> if isinstance ( obj , list ) : <TAB> <TAB> for array_item in obj : <TAB> <TAB> <TAB> _add_resource_group ( array_item ) <TAB> elif isinstance ( obj , dict ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if obj [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> obj [ "" resourceGroup "" ] = _parse_id ( obj [ "" id "" ] ) [ "" resource-group "" ] <TAB> <TAB> except ( KeyError , IndexError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> for item_key in obj : <TAB> <TAB> <TAB> if item_key != "" sourceVault "" : <TAB> <TAB> <TAB> <TAB> _add_resource_group ( obj [ item_key ] ) ","if "" resourcegroup "" not in [ x . lower ( ) for x in obj . keys ( ) ] : 
","if "" resourceGroup "" not in obj :
",31.45,5.25,False
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , DECODE ) <TAB> version = DECODE_VERSION <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data . remove_dir ( dpath ) <TAB> <TAB> build_data . make_dir ( dpath ) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES : <TAB> <TAB> <TAB> downloadable_file . download_file ( dpath ) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data . mark_done ( dpath , version_string = version ) ","if build_data . built ( dpath ) : 
","if build_data . built ( dpath ) :
",100.0,100.0,True
"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i , entry in enumerate ( self . reprentries ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tw . line ( "" "" ) <TAB> <TAB> entry . toterminal ( tw ) <TAB> <TAB> if i < len ( self . reprentries ) - 1 : <TAB> <TAB> <TAB> next_entry = self . reprentries [ i + 1 ] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry . style == "" long "" <TAB> <TAB> <TAB> <TAB> or entry . style == "" short "" <TAB> <TAB> <TAB> <TAB> and next_entry . style == "" long "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> tw . sep ( self . entrysep ) <TAB> if self . extraline : <TAB> <TAB> tw . line ( self . extraline ) ","if entry . style == "" long "" : 
","if last_style is not None :
",26.59,5.66,False
"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB> <TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> found + = 1 <TAB> <TAB> <TAB> if found == 2 : <TAB> <TAB> <TAB> <TAB> if division in "" \n "" . join ( lines ) : <TAB> <TAB> <TAB> <TAB> <TAB> break<TAB> # already in the right place <TAB> <TAB> <TAB> <TAB> lines . insert ( i + 1 , "" "" ) <TAB> <TAB> <TAB> <TAB> lines . insert ( i + 2 , division ) <TAB> <TAB> <TAB> <TAB> break <TAB> return "" \n "" . join ( lines ) ","if line . startswith ( ' "" "" "" ' ) : 
","if line . startswith ( "" # "" ) :
",69.75,39.39,False
def run_on_module ( self ) : <TAB> try : <TAB> <TAB> self . module_base . disable ( self . opts . module_spec ) <TAB> except dnf . exceptions . MarkingErrors as e : <TAB> <TAB> if self . base . conf . strict : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> e . module_depsolv_errors <TAB> <TAB> <TAB> <TAB> and e . module_depsolv_errors [ 1 ] <TAB> <TAB> <TAB> <TAB> != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> logger . error ( str ( e ) ) ,"if e . no_match_group_specs or e . error_group_specs : 
","if e . module_spec != libdnf . module . ModulePackageContainer . ModuleErrorType_ERROR_IN_DEFAULTS :
",40.52,8.46,False
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64mime . base64_len ( "" hello "" ) , len ( base64mime . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> elif size < = 6 : <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64mime . base64_len ( "" x "" * size ) , bsize ) ","elif size < = 9 : 
","elif size < = 9 :
",100.0,100.0,True
"def is_valid ( self ) : <TAB> """"""Determines whether file is valid for this reader"""""" <TAB> blocklist = self . open ( ) <TAB> valid = True <TAB> for line in blocklist : <TAB> <TAB> line = decode_bytes ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ( start , end ) = self . parse ( line ) <TAB> <TAB> <TAB> <TAB> if not re . match ( r "" ^( \ d { 1,3} \ .) {4} $ "" , start + "" . "" ) or not re . match ( <TAB> <TAB> <TAB> <TAB> <TAB> r "" ^( \ d { 1,3} \ .) {4} $ "" , end + "" . "" <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> valid = False <TAB> <TAB> <TAB> break <TAB> blocklist . close ( ) <TAB> return valid ","if not self . is_ignored ( line ) : 
","if line :
",26.34,0.0,False
"def next ( self ) : <TAB> while self . index < len ( self . data ) : <TAB> <TAB> uid = self . _read_next_word ( ) <TAB> <TAB> dont_care = self . _read_next_word ( ) <TAB> <TAB> entry = self . _read_next_string ( ) <TAB> <TAB> total_size = int ( 4 + 4 + len ( entry ) ) <TAB> <TAB> count = int ( total_size / self . SIZE ) <TAB> <TAB> if count == 0 : <TAB> <TAB> <TAB> mod = self . SIZE - total_size <TAB> <TAB> else : <TAB> <TAB> <TAB> mod = self . SIZE - int ( total_size - ( count * self . SIZE ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> remainder = self . _read_next_block ( mod ) <TAB> <TAB> yield ( uid , entry ) ","if mod > 0 : 
","if mod > 0 :
",100.0,100.0,True
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> if param . name : <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> if param . type : <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out ","if param . desc and "" "" . join ( param . desc ) . strip ( ) : 
","if param . desc :
",33.8,4.3,False
"def assert_backend ( self , expected_translated , language = "" cs "" ) : <TAB> """"""Check that backend has correct data."""""" <TAB> translation = self . get_translation ( language ) <TAB> translation . commit_pending ( "" test "" , None ) <TAB> store = translation . component . file_format_cls ( translation . get_filename ( ) , None ) <TAB> messages = set ( ) <TAB> translated = 0 <TAB> for unit in store . content_units : <TAB> <TAB> id_hash = unit . id_hash <TAB> <TAB> self . assertFalse ( id_hash in messages , "" Duplicate string in in backend file! "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> translated + = 1 <TAB> self . assertEqual ( <TAB> <TAB> translated , <TAB> <TAB> expected_translated , <TAB> <TAB> "" Did not found expected number of translations ( {}  !=  {} ). "" . format ( <TAB> <TAB> <TAB> translated , expected_translated <TAB> <TAB> ) , <TAB> ) ","if unit . is_translated ( ) : 
","if unit . is_translated :
",53.09,63.19,False
"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . script_running [ 1 : ] <TAB> <TAB> elif self . script_last and self . script_last [ 1 ] == name : <TAB> <TAB> <TAB> return self . script_last [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( error ) ","if self . script_running and self . script_running [ 1 ] == name : 
","if self . script_running and self . script_running [ 0 ] == name :
",89.26,84.92,False
"def dict_no_value_from_proto_list ( obj_list ) : <TAB> d = dict ( ) <TAB> for item in obj_list : <TAB> <TAB> possible_dict = json . loads ( item . value_json ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # (tss) TODO: This is protecting against legacy 'wandb_version' field. <TAB> <TAB> <TAB> # Should investigate why the config payload even has 'wandb_version'. <TAB> <TAB> <TAB> logger . warning ( "" key  ' {} '  has no  ' value '  attribute "" . format ( item . key ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> d [ item . key ] = possible_dict [ "" value "" ] <TAB> return d ","if not isinstance ( possible_dict , dict ) or "" value "" not in possible_dict : 
","if "" value "" not in possible_dict :
",51.21,33.24,False
"def visit ( self , node ) : <TAB> """"""dispatcher on node's class/bases name."""""" <TAB> cls = node . __class__ <TAB> try : <TAB> <TAB> visitmethod = self . cache [ cls ] <TAB> except KeyError : <TAB> <TAB> for subclass in cls . __mro__ : <TAB> <TAB> <TAB> visitmethod = getattr ( self , subclass . __name__ , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> visitmethod = self . __object <TAB> <TAB> self . cache [ cls ] = visitmethod <TAB> visitmethod ( node ) ","if visitmethod is not None : 
","if visitmethod is None :
",56.83,40.94,False
"def _get_adapter ( <TAB> mcls , <TAB> reversed_mro : Tuple [ type , . . . ] , <TAB> collection : Dict [ Any , Dict [ type , Adapter ] ] , <TAB> kwargs : Dict [ str , Any ] , ) - > Optional [ Adapter ] : <TAB> registry_key = mcls . get_registry_key ( kwargs ) <TAB> adapters = collection . get ( registry_key ) <TAB> if adapters is None : <TAB> <TAB> return None <TAB> result = None <TAB> seen : Set [ Adapter ] = set ( ) <TAB> for base in reversed_mro : <TAB> <TAB> for adaptee , adapter in adapters . items ( ) : <TAB> <TAB> <TAB> found = mcls . _match_adapter ( base , adaptee , adapter ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = found <TAB> <TAB> <TAB> <TAB> seen . add ( found ) <TAB> return result ","if found and found not in seen : 
","if found not in seen :
",64.37,60.25,False
"def test_pt_BR_rg ( self ) : <TAB> for _ in range ( 100 ) : <TAB> <TAB> to_test = self . fake . rg ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert re . search ( r "" ^ \ d {8} X "" , to_test ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert re . search ( r "" ^ \ d {9} $ "" , to_test ) ","if "" X "" in to_test : 
","if sys . platform == "" win32 "" :
",33.25,5.93,False
"def get_user_extra_data_by_client_id ( self , client_id , username ) : <TAB> extra_data = { } <TAB> current_client = self . clients . get ( client_id , None ) <TAB> if current_client : <TAB> <TAB> for readable_field in current_client . get_readable_fields ( ) : <TAB> <TAB> <TAB> attribute = list ( <TAB> <TAB> <TAB> <TAB> filter ( <TAB> <TAB> <TAB> <TAB> <TAB> lambda f : f [ "" Name "" ] == readable_field , <TAB> <TAB> <TAB> <TAB> <TAB> self . users . get ( username ) . attributes , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> extra_data . update ( { attribute [ 0 ] [ "" Name "" ] : attribute [ 0 ] [ "" Value "" ] } ) <TAB> return extra_data ","if len ( attribute ) > 0 : 
","if attribute :
",26.73,0.0,False
"def augment ( self , resources ) : <TAB> super ( ) . augment ( resources ) <TAB> for r in resources : <TAB> <TAB> md = r . get ( "" SAMLMetadataDocument "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> root = sso_metadata ( md ) <TAB> <TAB> r [ "" IDPSSODescriptor "" ] = root [ "" IDPSSODescriptor "" ] <TAB> return resources ","if not md : 
","if not md :
",100.0,100.0,True
"def __init__ ( self , mode = 0 , decode = None ) : <TAB> self . regex = self . REGEX [ mode ] <TAB> self . decode = decode <TAB> if decode : <TAB> <TAB> self . header = _ ( <TAB> <TAB> <TAB> "" ### This log has been decoded with automatic search pattern \n "" <TAB> <TAB> <TAB> "" ### If some paths are not decoded you can manually decode them with: \n "" <TAB> <TAB> ) <TAB> <TAB> self . header + = "" ###  ' backintime --quiet  "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . header + = ' --profile  "" %s "" ' % decode . config . profileName ( ) <TAB> <TAB> self . header + = "" --decode <path> ' \n \n "" <TAB> else : <TAB> <TAB> self . header = "" "" ","if int ( decode . config . currentProfile ( ) ) > 1 : 
","if decode . config :
",31.21,7.47,False
"def _get_dynamic_attr ( self , attname , obj , default = None ) : <TAB> try : <TAB> <TAB> attr = getattr ( self , attname ) <TAB> except AttributeError : <TAB> <TAB> return default <TAB> if callable ( attr ) : <TAB> <TAB> # Check co_argcount rather than try/excepting the function and <TAB> <TAB> # catching the TypeError, because something inside the function <TAB> <TAB> # may raise the TypeError. This technique is more accurate. <TAB> <TAB> try : <TAB> <TAB> <TAB> code = six . get_function_code ( attr ) <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> code = six . get_function_code ( attr . __call__ ) <TAB> <TAB> if code . co_argcount == 2 :<TAB> # one argument is 'self' <TAB> <TAB> <TAB> return attr ( obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return attr ( ) <TAB> return attr ","if code . co_argcount == 2 : 
","if code . co_argcount == 2 :
",100.0,100.0,True
"def grep_full_py_identifiers ( tokens ) : <TAB> global pykeywords <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while i < len ( tokens ) : <TAB> <TAB> tokentype , token = tokens [ i ] <TAB> <TAB> i + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> while ( <TAB> <TAB> <TAB> i + 1 < len ( tokens ) <TAB> <TAB> <TAB> and tokens [ i ] == ( "" op "" , "" . "" ) <TAB> <TAB> <TAB> and tokens [ i + 1 ] [ 0 ] == "" id "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> token + = "" . "" + tokens [ i + 1 ] [ 1 ] <TAB> <TAB> <TAB> i + = 2 <TAB> <TAB> if token == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token in pykeywords : <TAB> <TAB> <TAB> continue <TAB> <TAB> if token [ 0 ] in "" .0123456789 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield token ","if tokentype != "" id "" : 
","if tokentype == "" ident "" :
",55.31,19.13,False
"def _add_disk_config ( self , context , images ) : <TAB> for image in images : <TAB> <TAB> metadata = image [ "" metadata "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raw_value = metadata [ INTERNAL_DISK_CONFIG ] <TAB> <TAB> <TAB> value = utils . bool_from_str ( raw_value ) <TAB> <TAB> <TAB> image [ API_DISK_CONFIG ] = disk_config_to_api ( value ) ","if INTERNAL_DISK_CONFIG in metadata : 
","if INTERNAL_DISK_CONFIG in metadata :
",100.0,100.0,True
"def test_edgeql_expr_valid_setop_07 ( self ) : <TAB> expected_error_msg = "" cannot be applied to operands "" <TAB> # IF ELSE with every scalar as the condition <TAB> for val in get_test_values ( ) : <TAB> <TAB> query = f """""" SELECT 1 IF  { val }  ELSE 2; """""" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . assert_query_result ( query , [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # every other combination must produce an error <TAB> <TAB> <TAB> with self . assertRaisesRegex ( <TAB> <TAB> <TAB> <TAB> edgedb . QueryError , expected_error_msg , msg = query <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> async with self . con . transaction ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> await self . con . execute ( query ) ","if val == "" <bool>True "" : 
","if val == "" 1 "" :
",74.63,40.87,False
"def get_all_url_infos ( ) - > Dict [ str , UrlInfo ] : <TAB> """"""Returns dict associating URL to UrlInfo."""""" <TAB> url_infos = { } <TAB> for path in _checksum_paths ( ) . values ( ) : <TAB> <TAB> dataset_url_infos = load_url_infos ( path ) <TAB> <TAB> for url , url_info in dataset_url_infos . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" URL  {}  is registered with 2+ distinct size/checksum tuples.  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" {}  vs  {} "" . format ( url , url_info , url_infos [ url ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> url_infos . update ( dataset_url_infos ) <TAB> return url_infos ","if url_infos . get ( url , url_info ) != url_info : 
","if url not in url_infos :
",26.2,6.84,False
"def global_fixes ( ) : <TAB> """"""Yield multiple (code, function) tuples."""""" <TAB> for function in list ( globals ( ) . values ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arguments = _get_parameters ( function ) <TAB> <TAB> <TAB> if arguments [ : 1 ] != [ "" source "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> code = extract_code_from_function ( function ) <TAB> <TAB> <TAB> if code : <TAB> <TAB> <TAB> <TAB> yield ( code , function ) ","if inspect . isfunction ( function ) : 
","if isinstance ( function , types . FunctionType ) :
",34.11,13.13,False
"def createSocket ( self ) : <TAB> skt = Port . createSocket ( self ) <TAB> if self . listenMultiple : <TAB> <TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEADDR , 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> skt . setsockopt ( socket . SOL_SOCKET , socket . SO_REUSEPORT , 1 ) <TAB> return skt ","if hasattr ( socket , "" SO_REUSEPORT "" ) : 
","if self . listenMax :
",26.35,3.13,False
"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB> <TAB> if out and sep : <TAB> <TAB> <TAB> out . append ( sep ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out + = item . _asStringList ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out . append ( str ( item ) ) <TAB> return out ","if isinstance ( item , ParseResults ) : 
","if isinstance ( item , ParseResults ) :
",100.0,100.0,True
"def parse_c_comments ( lexer , tok , ntok ) : <TAB> if tok != "" / "" or ntok != "" * "" : <TAB> <TAB> return False <TAB> quotes = lexer . quotes <TAB> lexer . quotes = "" "" <TAB> while True : <TAB> <TAB> tok = lexer . get_token ( ) <TAB> <TAB> ntok = lexer . get_token ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lexer . quotes = quotes <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> lexer . push_token ( ntok ) <TAB> return True ","if tok == "" * "" and ntok == "" / "" : 
","if tok == "" , "" and ntok == "" , "" :
",76.55,61.05,False
"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB> <TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB> <TAB> if c1 : <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> if sibling . getFirstChild ( ) : <TAB> <TAB> <TAB> sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB> <TAB> sibling = sibling . getNextSibling ( ) ","if c2 : 
","if c2 :
",78.12,0.0,False
"def __view_beside ( self , onsideof , * * kwargs ) : <TAB> bounds = self . info [ "" bounds "" ] <TAB> min_dist , found = - 1 , None <TAB> for ui in UiObject ( self . session , Selector ( * * kwargs ) ) : <TAB> <TAB> dist = onsideof ( bounds , ui . info [ "" bounds "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> min_dist , found = dist , ui <TAB> return found ","if dist > = 0 and ( min_dist < 0 or dist < min_dist ) : 
","if dist < min_dist :
",30.63,11.04,False
"def __eq__ ( self , other ) : <TAB> if isinstance ( other , numeric_range ) : <TAB> <TAB> empty_self = not bool ( self ) <TAB> <TAB> empty_other = not bool ( other ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return empty_self and empty_other<TAB> # True if both empty <TAB> <TAB> else : <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> self . _start == other . _start <TAB> <TAB> <TAB> <TAB> and self . _step == other . _step <TAB> <TAB> <TAB> <TAB> and self . _get_by_index ( - 1 ) == other . _get_by_index ( - 1 ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return False ","if empty_self or empty_other : 
","if self == empty_self and other is not None :
",27.41,13.67,False
"def _buffered_generator ( self , size ) : <TAB> buf = [ ] <TAB> c_size = 0 <TAB> push = buf . append <TAB> while 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> while c_size < size : <TAB> <TAB> <TAB> <TAB> c = next ( self . _gen ) <TAB> <TAB> <TAB> <TAB> push ( c ) <TAB> <TAB> <TAB> <TAB> if c : <TAB> <TAB> <TAB> <TAB> <TAB> c_size + = 1 <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> yield concat ( buf ) <TAB> <TAB> del buf [ : ] <TAB> <TAB> c_size = 0 ","if not c_size : 
","if not self . _gen :
",32.33,15.62,False
"def connect ( self ) : <TAB> with self . _conn_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Error, database not properly initialized  "" "" before opening connection "" <TAB> <TAB> <TAB> ) <TAB> <TAB> with self . exception_wrapper ( ) : <TAB> <TAB> <TAB> self . __local . conn = self . _connect ( self . database , * * self . connect_kwargs ) <TAB> <TAB> <TAB> self . __local . closed = False <TAB> <TAB> <TAB> self . initialize_connection ( self . __local . conn ) ","if self . deferred : 
","if self . connection_initialized :
",64.48,26.27,False
"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB> <TAB> for name , var in new_subst . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> subst [ name ] = var <TAB> <TAB> <TAB> elif subst [ name ] is not var : <TAB> <TAB> <TAB> <TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst ","if name not in subst : 
","if name not in subst :
",100.0,100.0,True
"def remove ( self , tag ) : <TAB> """"""Removes a tag recursively from all containers."""""" <TAB> new_contents = [ ] <TAB> self . content_size = 0 <TAB> for element in self . contents : <TAB> <TAB> if element . name != tag : <TAB> <TAB> <TAB> new_contents . append ( element ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> element . remove ( tag ) <TAB> <TAB> <TAB> self . content_size + = element . size ( ) <TAB> self . contents = new_contents ","if isinstance ( element , Container ) : 
","if isinstance ( element , Container ) :
",100.0,100.0,True
"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB> <TAB> if isinstance ( prop_value , dict ) and prop_value : <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> func = getattr ( self , func_name ) <TAB> <TAB> <TAB> <TAB> props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB> if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB> <TAB> return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB> else : <TAB> <TAB> return props ","if func_name . startswith ( "" _ "" ) : 
","if func_name in self . fake_func_mapping :
",31.97,22.24,False
"def visit_try_stmt ( self , o : "" mypy.nodes.TryStmt "" ) - > str : <TAB> a = [ o . body ]<TAB> # type: List[Any] <TAB> for i in range ( len ( o . vars ) ) : <TAB> <TAB> a . append ( o . types [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> a . append ( o . vars [ i ] ) <TAB> <TAB> a . append ( o . handlers [ i ] ) <TAB> if o . else_body : <TAB> <TAB> a . append ( ( "" Else "" , o . else_body . body ) ) <TAB> if o . finally_body : <TAB> <TAB> a . append ( ( "" Finally "" , o . finally_body . body ) ) <TAB> return self . dump ( a , o ) ","if o . vars [ i ] : 
","if i in o . handlers :
",35.09,14.32,False
"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True ","elif isinstance ( i , _bytes ) : 
","elif not isinstance ( i , bytes ) and not all ( ord ( ord ( i ) ) :
",52.01,16.2,False
"def msg_ser ( inst , sformat , lev = 0 ) : <TAB> if sformat in [ "" urlencoded "" , "" json "" ] : <TAB> <TAB> if isinstance ( inst , Message ) : <TAB> <TAB> <TAB> res = inst . serialize ( sformat , lev ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res = inst <TAB> elif sformat == "" dict "" : <TAB> <TAB> if isinstance ( inst , Message ) : <TAB> <TAB> <TAB> res = inst . serialize ( sformat , lev ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res = inst <TAB> <TAB> elif isinstance ( inst , str ) :<TAB> # Iff ID Token <TAB> <TAB> <TAB> res = inst <TAB> <TAB> else : <TAB> <TAB> <TAB> raise MessageException ( "" Wrong type:  %s "" % type ( inst ) ) <TAB> else : <TAB> <TAB> raise PyoidcError ( "" Unknown sformat "" , inst ) <TAB> return res ","elif isinstance ( inst , dict ) : 
","elif isinstance ( inst , ( int , float ) ) :
",49.15,36.46,False
"def start_container_if_stopped ( self , container , attach_logs = False , quiet = False ) : <TAB> if not container . is_running : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Starting  %s "" % container . name ) <TAB> <TAB> if attach_logs : <TAB> <TAB> <TAB> container . attach_log_stream ( ) <TAB> <TAB> return self . start_container ( container ) ","if not quiet : 
","if not quiet :
",100.0,100.0,True
"def layer_op ( self , input_image , mask = None ) : <TAB> if not isinstance ( input_image , dict ) : <TAB> <TAB> self . _set_full_border ( input_image ) <TAB> <TAB> input_image = np . pad ( input_image , self . full_border , mode = self . mode ) <TAB> <TAB> return input_image , mask <TAB> for name , image in input_image . items ( ) : <TAB> <TAB> self . _set_full_border ( image ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tf . logging . warning ( <TAB> <TAB> <TAB> <TAB> "" could not pad, dict name  %s  not in  %s "" , name , self . image_name <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> input_image [ name ] = np . pad ( image , self . full_border , mode = self . mode ) <TAB> return input_image , mask ","if name not in self . image_name : 
","if name not in self . image_names :
",85.72,78.25,False
"def __Suffix_Noun_Step2b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step2b : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> token = token [ : - 2 ] <TAB> <TAB> <TAB> self . suffix_noun_step2b_success = True <TAB> <TAB> <TAB> break <TAB> return token ","if token . endswith ( suffix ) and len ( token ) > = 5 : 
","if token . endswith ( suffix ) :
",52.62,31.98,False
"def replace_header_items ( ps , replacments ) : <TAB> match = read_while ( ps , header_item_or_end_re . match , lambda match : match is None ) <TAB> while not ps . current_line . startswith ( "" */ "" ) : <TAB> <TAB> match = header_item_re . match ( ps . current_line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = match . groupdict ( ) [ "" key "" ] <TAB> <TAB> <TAB> if key in replacments : <TAB> <TAB> <TAB> <TAB> ps . current_line = match . expand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" \ g<key> \ g<space> %s \n "" % replacments [ key ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> ps . read_line ( ) ","if match is not None : 
","if match :
",29.74,0.0,False
"def __projectBookmark ( widget , location ) : <TAB> script = None <TAB> while widget is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> script = widget . scriptNode ( ) <TAB> <TAB> <TAB> if isinstance ( script , Gaffer . ScriptNode ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> widget = widget . parent ( ) <TAB> if script is not None : <TAB> <TAB> p = script . context ( ) . substitute ( location ) <TAB> <TAB> if not os . path . exists ( p ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . makedirs ( p ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> return p <TAB> else : <TAB> <TAB> return os . getcwd ( ) ","if hasattr ( widget , "" scriptNode "" ) : 
","if isinstance ( widget , Gaffer . GafferWidget ) :
",32.03,20.56,False
"def events_to_str ( event_field , all_events ) : <TAB> result = [ ] <TAB> for ( flag , string ) in all_events : <TAB> <TAB> c_flag = flag <TAB> <TAB> if event_field & c_flag : <TAB> <TAB> <TAB> result . append ( string ) <TAB> <TAB> <TAB> event_field = event_field & ( ~ c_flag ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> if event_field : <TAB> <TAB> result . append ( hex ( event_field ) ) <TAB> return "" | "" . join ( result ) ","if not event_field : 
","if not event_field :
",100.0,100.0,True
"def get_s3_bucket_locations ( buckets , self_log = False ) : <TAB> """"""return (bucket_name, prefix) for all s3 logging targets"""""" <TAB> for b in buckets : <TAB> <TAB> if b . get ( "" Logging "" ) : <TAB> <TAB> <TAB> if self_log : <TAB> <TAB> <TAB> <TAB> if b [ "" Name "" ] != b [ "" Logging "" ] [ "" TargetBucket "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( b [ "" Logging "" ] [ "" TargetBucket "" ] , b [ "" Logging "" ] [ "" TargetPrefix "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( b [ "" Name "" ] , "" "" ) ","if not self_log and b [ "" Name "" ] . startswith ( "" cf-templates- "" ) : 
","elif b . get ( "" Name "" ) :
",36.99,10.98,False
"def extract_file ( tgz , tarinfo , dst_path , buffer_size = 10 << 20 , log_function = None ) : <TAB> """"""Extracts 'tarinfo' from 'tgz' and writes to 'dst_path'."""""" <TAB> src = tgz . extractfile ( tarinfo ) <TAB> if src is None : <TAB> <TAB> return <TAB> dst = tf . compat . v1 . gfile . GFile ( dst_path , "" wb "" ) <TAB> while 1 : <TAB> <TAB> buf = src . read ( buffer_size ) <TAB> <TAB> if not buf : <TAB> <TAB> <TAB> break <TAB> <TAB> dst . write ( buf ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log_function ( len ( buf ) ) <TAB> dst . close ( ) <TAB> src . close ( ) ","if log_function is not None : 
","if log_function :
",29.58,38.81,False
"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB> <TAB> if k in ( "" lccn "" , "" oclc "" , "" isbn "" ) : <TAB> <TAB> <TAB> fields [ k ] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields ","if k == "" full_title "" : 
","if k == "" title "" :
",74.63,53.85,False
"def disconnect_application ( self ) : <TAB> if not self . is_app_running ( self . APP_BACKDROP ) : <TAB> <TAB> self . socket . send ( commands . CloseCommand ( destination_id = False ) ) <TAB> <TAB> start_time = time . time ( ) <TAB> <TAB> while not self . is_app_running ( None ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . socket . send_and_wait ( commands . StatusCommand ( ) ) <TAB> <TAB> <TAB> except cast_socket . ConnectionTerminatedException : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_time = time . time ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise TimeoutException ( ) <TAB> <TAB> <TAB> time . sleep ( self . WAIT_INTERVAL ) <TAB> else : <TAB> <TAB> logger . debug ( "" Closing not necessary. Backdrop is running ... "" ) ","if current_time - start_time > self . timeout : 
","if current_time - start_time > self . timeout :
",100.0,100.0,True
"def matches ( self , cursor_offset , line , * * kwargs ) : <TAB> cs = lineparts . current_string ( cursor_offset , line ) <TAB> if cs is None : <TAB> <TAB> return None <TAB> matches = set ( ) <TAB> username = cs . word . split ( os . path . sep , 1 ) [ 0 ] <TAB> user_dir = os . path . expanduser ( username ) <TAB> for filename in self . safe_glob ( os . path . expanduser ( cs . word ) ) : <TAB> <TAB> if os . path . isdir ( filename ) : <TAB> <TAB> <TAB> filename + = os . path . sep <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = username + filename [ len ( user_dir ) : ] <TAB> <TAB> matches . add ( filename ) <TAB> return matches ","if cs . word . startswith ( "" ~ "" ) : 
","if filename . startswith ( user_dir ) :
",34.25,16.83,False
"def eventFilter ( self , obj , event ) : <TAB> if event . type ( ) == QEvent . MouseButtonPress : <TAB> <TAB> button = event . button ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _app . browser . back ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> elif button == Qt . ForwardButton : <TAB> <TAB> <TAB> self . _app . browser . forward ( ) <TAB> <TAB> <TAB> return True <TAB> return False ","if button == Qt . BackButton : 
","if button == Qt . BackButton :
",100.0,100.0,True
"def reset_parameters ( self ) : <TAB> for m in self . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Embedding ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nn . init . constant_ ( m . weight , 0.1 ) <TAB> <TAB> <TAB> nn . init . constant_ ( m . bias , 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for p in m . parameters ( ) : <TAB> <TAB> <TAB> <TAB> nn . init . normal_ ( p , 0 , 0.1 ) ","elif isinstance ( m , nn . LayerNorm ) : 
","if isinstance ( m , nn . Linear ) :
",67.9,58.14,False
"def get_scalding_core ( self ) : <TAB> lib_dir = os . path . join ( self . scalding_home , "" lib "" ) <TAB> for j in os . listdir ( lib_dir ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p = os . path . join ( lib_dir , j ) <TAB> <TAB> <TAB> logger . debug ( "" Found scalding-core:  %s "" , p ) <TAB> <TAB> <TAB> return p <TAB> raise luigi . contrib . hadoop . HadoopJobError ( "" Could not find scalding-core. "" ) ","if j . startswith ( "" scalding-core- "" ) : 
","if os . path . splitext ( j ) [ 1 ] == "" .scalding-core "" :
",34.72,3.4,False
"def save ( self ) : <TAB> """"""Saves a new set of golden output frames to disk."""""" <TAB> for pixels , ( relative_to_assets , filename ) in zip ( <TAB> <TAB> self . iter_render ( ) , self . _iter_paths ( ) <TAB> ) : <TAB> <TAB> full_directory_path = os . path . join ( self . _ASSETS_DIR , relative_to_assets ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( full_directory_path ) <TAB> <TAB> path = os . path . join ( full_directory_path , filename ) <TAB> <TAB> _save_pixels ( pixels , path ) ","if not os . path . exists ( full_directory_path ) : 
","if not os . path . exists ( full_directory_path ) :
",100.0,100.0,True
"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> iter = op . inputs <TAB> <TAB> else : <TAB> <TAB> <TAB> iter = op . outputs <TAB> <TAB> for i in iter : <TAB> <TAB> <TAB> for name in names : <TAB> <TAB> <TAB> <TAB> if i . raw_name == name and name not in map : <TAB> <TAB> <TAB> <TAB> <TAB> map [ i . raw_name ] = i . full_name <TAB> <TAB> if len ( map ) == len ( names ) : <TAB> <TAB> <TAB> break <TAB> for name in names : <TAB> <TAB> new_names . append ( map [ name ] ) <TAB> return new_names ","if mod == "" input "" : 
","if mod == "" input "" :
",100.0,100.0,True
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast ( TupleStr4 , item ) <TAB> <TAB> if item [ 0 ] : <TAB> <TAB> <TAB> typ = "" number "" <TAB> <TAB> <TAB> val = item [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> typ = "" name "" <TAB> <TAB> <TAB> val = item [ 1 ] <TAB> <TAB> elif item [ 2 ] : <TAB> <TAB> <TAB> typ = item [ 2 ] <TAB> <TAB> <TAB> val = item [ 2 ] <TAB> <TAB> elif item [ 3 ] : <TAB> <TAB> <TAB> typ = item [ 3 ] <TAB> <TAB> <TAB> val = item [ 3 ] <TAB> <TAB> yield Token ( typ , val ) ","elif item [ 1 ] : 
","elif item [ 1 ] :
",100.0,100.0,True
"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions : <TAB> <TAB> if ex < 500 : <TAB> <TAB> <TAB> app . register_error_handler ( ex , error_http ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> app . register_error_handler ( ex , internal_error ) <TAB> if services . ldap : <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app . errorhandler ( services . ldap . LDAPException ) <TAB> <TAB> def handle_exception ( e ) : <TAB> <TAB> <TAB> log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB> <TAB> <TAB> return error_http ( FailedDependency ( ) ) ","elif ex == 500 : 
","if internal_error :
",27.62,8.75,False
"def decode ( self , ids ) : <TAB> ids = pad_decr ( ids ) <TAB> tokens = [ ] <TAB> for int_id in ids : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tokens . append ( self . _vocab_list [ int_id ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens . append ( self . _oov_token ) <TAB> return self . _decode_token_separator . join ( tokens ) ","if int_id < len ( self . _vocab_list ) : 
","if int_id in self . _vocab_list :
",36.26,50.57,False
"def remove_contest ( contest_id ) : <TAB> with SessionGen ( ) as session : <TAB> <TAB> contest = session . query ( Contest ) . filter ( Contest . id == contest_id ) . first ( ) <TAB> <TAB> if not contest : <TAB> <TAB> <TAB> print ( "" No contest with id  %s  found. "" % contest_id ) <TAB> <TAB> <TAB> return False <TAB> <TAB> contest_name = contest . name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Not removing contest ` %s ' . "" % contest_name ) <TAB> <TAB> <TAB> return False <TAB> <TAB> session . delete ( contest ) <TAB> <TAB> session . commit ( ) <TAB> <TAB> print ( "" Contest ` %s '  removed. "" % contest_name ) <TAB> return True ","if not ask ( contest ) : 
","if not contest_name in session . query ( Contest ) . all ( ) :
",33.79,7.16,False
def get_hi_lineno ( self ) : <TAB> lineno = Node . get_hi_lineno ( self ) <TAB> if self . expr1 is None : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> lineno = self . expr1 . get_hi_lineno ( ) <TAB> <TAB> if self . expr2 is None : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> lineno = self . expr2 . get_hi_lineno ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> lineno = self . expr3 . get_hi_lineno ( ) <TAB> return lineno ,"if self . expr3 is None : 
","if self . expr3 is None :
",100.0,100.0,True
"def _send_internal ( self , bytes_ ) : <TAB> # buffering <TAB> if self . pendings : <TAB> <TAB> self . pendings + = bytes_ <TAB> <TAB> bytes_ = self . pendings <TAB> try : <TAB> <TAB> # reconnect if possible <TAB> <TAB> self . _reconnect ( ) <TAB> <TAB> # send message <TAB> <TAB> self . socket . sendall ( bytes_ ) <TAB> <TAB> # send finished <TAB> <TAB> self . pendings = None <TAB> except Exception :<TAB> # pylint: disable=broad-except <TAB> <TAB> # close socket <TAB> <TAB> self . _close ( ) <TAB> <TAB> # clear buffer if it exceeds max bufer size <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # TODO: add callback handler here <TAB> <TAB> <TAB> self . pendings = None <TAB> <TAB> else : <TAB> <TAB> <TAB> self . pendings = bytes_ ","if self . pendings and ( len ( self . pendings ) > self . bufmax ) : 
","if len ( bytes_ ) > self . bufer_size :
",40.61,16.82,False
"def _unpack ( self , fmt , byt ) : <TAB> d = unpack ( self . _header [ "" byteorder "" ] + fmt , byt ) [ 0 ] <TAB> if fmt [ - 1 ] in self . MISSING_VALUES : <TAB> <TAB> nmin , nmax = self . MISSING_VALUES [ fmt [ - 1 ] ] <TAB> <TAB> if d < nmin or d > nmax : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return StataMissingValue ( nmax , d ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return None <TAB> return d ","if self . _missing_values : 
","if nmin == 0 :
",28.41,6.92,False
"def tuple_iter ( self ) : <TAB> for x in range ( <TAB> <TAB> self . center . x - self . max_radius , self . center . x + self . max_radius + 1 <TAB> ) : <TAB> <TAB> for y in range ( <TAB> <TAB> <TAB> self . center . y - self . max_radius , self . center . y + self . max_radius + 1 <TAB> <TAB> ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield ( x , y ) ","if self . min_radius < = self . center . distance ( ( x , y ) ) < = self . max_radius : 
","if self . _points [ x , y ] . is_valid ( ) :
",34.86,8.91,False
"def _parse_gene ( element ) : <TAB> for genename_element in element : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ann_key = "" gene_ %s _ %s "" % ( <TAB> <TAB> <TAB> <TAB> genename_element . tag . replace ( NS , "" "" ) , <TAB> <TAB> <TAB> <TAB> genename_element . attrib [ "" type "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if genename_element . attrib [ "" type "" ] == "" primary "" : <TAB> <TAB> <TAB> <TAB> self . ParsedSeqRecord . annotations [ ann_key ] = genename_element . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> append_to_annotations ( ann_key , genename_element . text ) ","if "" type "" in genename_element . attrib : 
","if genename_element . tag . startswith ( NS ) :
",32.78,23.46,False
"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self . isSystemCurveIndex ( iFirstCurve ) : <TAB> <TAB> return <TAB> nCurves = self . getNCurves ( ) <TAB> for i in range ( iFirstCurve , nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) : <TAB> <TAB> <TAB> c . invalidate ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices ","elif i == iFirstCurve : 
","elif c . getSymbol ( ) . getSymbolType ( ) == SymbolType . PieCurveType :
",33.57,5.82,False
"def gen_app_versions ( self ) : <TAB> for app_config in apps . get_app_configs ( ) : <TAB> <TAB> name = app_config . verbose_name <TAB> <TAB> app = app_config . module <TAB> <TAB> version = self . get_app_version ( app ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield app . __name__ , name , version ","if version : 
","if version :
",78.12,0.0,False
"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB> <TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB> <TAB> if part in ( "" . "" , "" .. "" ) : <TAB> <TAB> <TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB> <TAB> checkpath = os . path . join ( checkpath , part ) <TAB> <TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB> <TAB> if os . path . islink ( checkpath ) : <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" ) ","if not os . path . exists ( checkpath ) : 
","if not os . path . exists ( checkpath ) :
",100.0,100.0,True
"def create_or_update_tag_at_scope ( cmd , resource_id = None , tags = None , tag_name = None ) : <TAB> rcf = _resource_client_factory ( cmd . cli_ctx ) <TAB> if resource_id is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IncorrectUsageError ( "" Tags could not be empty. "" ) <TAB> <TAB> Tags = cmd . get_models ( "" Tags "" ) <TAB> <TAB> tag_obj = Tags ( tags = tags ) <TAB> <TAB> return rcf . tags . create_or_update_at_scope ( scope = resource_id , properties = tag_obj ) <TAB> return rcf . tags . create_or_update ( tag_name = tag_name ) ","if not tags : 
","if tags is None :
",29.25,14.06,False
"def generate_auto_complete ( self , base , iterable_var ) : <TAB> sugg = [ ] <TAB> for entry in iterable_var : <TAB> <TAB> compare_entry = entry <TAB> <TAB> compare_base = base <TAB> <TAB> if self . settings . get ( IGNORE_CASE_SETTING ) : <TAB> <TAB> <TAB> compare_entry = compare_entry . lower ( ) <TAB> <TAB> <TAB> compare_base = compare_base . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if entry not in sugg : <TAB> <TAB> <TAB> <TAB> sugg . append ( entry ) <TAB> return sugg ","if self . compare_entries ( compare_entry , compare_base ) : 
","if compare_entry == compare_base :
",26.51,15.49,False
"def createFields ( self ) : <TAB> yield String ( self , "" dict_start "" , 2 ) <TAB> while not self . eof : <TAB> <TAB> addr = self . absolute_address + self . current_size <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for field in parsePDFType ( self ) : <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> yield String ( self , "" dict_end "" , 2 ) ","if self . stream . readBytes ( addr , 2 ) != "" >> "" : 
","if self . is_PDF_type ( addr ) :
",32.06,10.46,False
"def Visit_and_test ( self , node ) :<TAB> # pylint: disable=invalid-name <TAB> # and_test ::= not_test ('and' not_test)* <TAB> for child in node . children : <TAB> <TAB> self . Visit ( child ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _AppendTokenSubtype ( child , format_token . Subtype . BINARY_OPERATOR ) ","if isinstance ( child , pytree . Leaf ) and child . value == "" and "" : 
","if isinstance ( child , pytree . Leaf ) and child . value == "" and "" :
",100.0,100.0,True
"def getfiledata ( directories ) : <TAB> columns = None <TAB> data = [ ] <TAB> counter = 1 <TAB> for directory in directories : <TAB> <TAB> for f in os . listdir ( directory ) : <TAB> <TAB> <TAB> if not os . path . isfile ( os . path . join ( directory , f ) ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> counter + = 1 <TAB> <TAB> <TAB> st = os . stat ( os . path . join ( directory , f ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> columns = [ "" rowid "" , "" name "" , "" directory "" ] + [ <TAB> <TAB> <TAB> <TAB> <TAB> x for x in dir ( st ) if x . startswith ( "" st_ "" ) <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> data . append ( [ counter , f , directory ] + [ getattr ( st , x ) for x in columns [ 3 : ] ] ) <TAB> return columns , data ","if columns is None : 
","if columns is None :
",100.0,100.0,True
"def copy_attributes ( info_add , obj , name_fmt , attributes , formatter = None ) : <TAB> for attr in attributes : <TAB> <TAB> value = getattr ( obj , attr , None ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> name = name_fmt % attr <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = formatter ( attr , value ) <TAB> <TAB> info_add ( name , value ) ","if formatter is not None : 
","if formatter is not None :
",100.0,100.0,True
"def main ( args ) : <TAB> ap = argparse . ArgumentParser ( ) <TAB> ap . add_argument ( "" job_ids "" , nargs = "" + "" , type = int , help = "" ID of a running job "" ) <TAB> ns = ap . parse_args ( args ) <TAB> _stash = globals ( ) [ "" _stash "" ] <TAB> """""":type : StaSh"""""" <TAB> for job_id in ns . job_ids : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" killing job  {}  ... "" . format ( job_id ) ) <TAB> <TAB> <TAB> worker = _stash . runtime . worker_registry . get_worker ( job_id ) <TAB> <TAB> <TAB> worker . kill ( ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" error: no such job with id:  {} "" . format ( job_id ) ) <TAB> <TAB> <TAB> break ","if job_id in _stash . runtime . worker_registry : 
","if job_id not in _stash . runtime . workers :
",75.14,54.84,False
"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB> <TAB> if self . choices is None : <TAB> <TAB> <TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise OptionError ( <TAB> <TAB> <TAB> <TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB> <TAB> <TAB> <TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> ) <TAB> elif self . choices is not None : <TAB> <TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self ) ","elif type ( self . choices ) not in ( types . TupleType , types . ListType ) : 
","elif not isinstance ( self . choices , str ) :
",40.43,14.92,False
"def add_file ( pipe , srcpath , tgtpath ) : <TAB> with open ( srcpath , "" rb "" ) as handle : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> write ( pipe , enc ( "" M 100755 inline  %s \n "" % tgtpath ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> write ( pipe , enc ( "" M 100644 inline  %s \n "" % tgtpath ) ) <TAB> <TAB> data = handle . read ( ) <TAB> <TAB> write ( pipe , enc ( "" data  %d \n "" % len ( data ) ) ) <TAB> <TAB> write ( pipe , enc ( data ) ) <TAB> <TAB> write ( pipe , enc ( "" \n "" ) ) ","if os . access ( srcpath , os . X_OK ) : 
","if os . path . exists ( tgtpath ) :
",39.26,14.32,False
"def cdf ( self , x ) : <TAB> if x == numpy . inf : <TAB> <TAB> return 1.0 <TAB> else :<TAB> # Inefficient sum. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" Invalid value. "" ) <TAB> <TAB> c = 0.0 <TAB> <TAB> for i in xrange ( x + 1 ) : <TAB> <TAB> <TAB> c + = self . probability ( i ) <TAB> <TAB> return c ","if x != int ( x ) : 
","if numpy . abs ( x ) > numpy . abs ( self . mean ) :
",36.31,10.7,False
"def convert_to_strings ( self , out , seq_len ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( out ) : <TAB> <TAB> utterances = [ ] <TAB> <TAB> for p , utt in enumerate ( batch ) : <TAB> <TAB> <TAB> size = seq_len [ b ] [ p ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> transcript = "" "" . join ( <TAB> <TAB> <TAB> <TAB> <TAB> map ( lambda x : self . int_to_char [ x . item ( ) ] , utt [ 0 : size ] ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> transcript = "" "" <TAB> <TAB> <TAB> utterances . append ( transcript ) <TAB> <TAB> results . append ( utterances ) <TAB> return results ","if size > 0 : 
","if size > 0 :
",100.0,100.0,True
"def get_date_range ( self ) : <TAB> if not hasattr ( self , "" start "" ) or not hasattr ( self , "" end "" ) : <TAB> <TAB> args = ( self . today . year , self . today . month ) <TAB> <TAB> form = self . get_form ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args = ( int ( form . cleaned_data [ "" year "" ] ) , int ( form . cleaned_data [ "" month "" ] ) ) <TAB> <TAB> self . start = self . get_start ( * args ) <TAB> <TAB> self . end = self . get_end ( * args ) <TAB> return self . start , self . end ","if form . is_valid ( ) : 
","if form . is_valid ( ) :
",100.0,100.0,True
"def save_stats ( self ) : <TAB> LOGGER . info ( "" Saving task-level statistics. "" ) <TAB> has_headers = os . path . isfile ( paths . TABLE_COUNT_PATH ) <TAB> with open ( paths . TABLE_COUNT_PATH , "" a "" ) as csvfile : <TAB> <TAB> headers = [ "" start_time "" , "" database_name "" , "" number_tables "" ] <TAB> <TAB> writer = csv . DictWriter ( <TAB> <TAB> <TAB> csvfile , delimiter = "" , "" , lineterminator = "" \n "" , fieldnames = headers <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> writer . writeheader ( ) <TAB> <TAB> writer . writerow ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" start_time "" : self . start_time , <TAB> <TAB> <TAB> <TAB> "" database_name "" : self . database_name , <TAB> <TAB> <TAB> <TAB> "" number_tables "" : self . count , <TAB> <TAB> <TAB> } <TAB> <TAB> ) ","if not has_headers : 
","if has_headers :
",34.18,57.89,False
"def _CheckCanaryCommand ( self ) : <TAB> if OpenStackVirtualMachine . command_works :<TAB> # fast path <TAB> <TAB> return <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> logging . info ( "" Testing OpenStack CLI command is installed and working "" ) <TAB> <TAB> cmd = os_utils . OpenStackCLICommand ( self , "" image "" , "" list "" ) <TAB> <TAB> stdout , stderr , _ = cmd . Issue ( ) <TAB> <TAB> if stderr : <TAB> <TAB> <TAB> raise errors . Config . InvalidValue ( <TAB> <TAB> <TAB> <TAB> "" OpenStack CLI test command failed. Please make sure the OpenStack  "" <TAB> <TAB> <TAB> <TAB> "" CLI client is installed and properly configured "" <TAB> <TAB> <TAB> ) <TAB> <TAB> OpenStackVirtualMachine . command_works = True ","if OpenStackVirtualMachine . command_works : 
","if not OpenStackVirtualMachine . command_works :
",64.44,70.71,False
"def test_windows_hidden ( self ) : <TAB> if not sys . platform == "" win32 "" : <TAB> <TAB> self . skipTest ( "" sys.platform is not windows "" ) <TAB> <TAB> return <TAB> # FILE_ATTRIBUTE_HIDDEN = 2 (0x2) from GetFileAttributes documentation. <TAB> hidden_mask = 2 <TAB> with tempfile . NamedTemporaryFile ( ) as f : <TAB> <TAB> # Hide the file using <TAB> <TAB> success = ctypes . windll . kernel32 . SetFileAttributesW ( f . name , hidden_mask ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" unable to set file attributes "" ) <TAB> <TAB> self . assertTrue ( hidden . is_hidden ( f . name ) ) ","if not success : 
","if not success :
",100.0,100.0,True
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> if r is None : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return b "" "" . join ( y ) ","elif r : 
","if e :
",30.14,0.0,False
"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB> <TAB> has_xml = accepts . find ( b "" xml "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> semicolon = accepts . find ( b "" ; "" ) <TAB> <TAB> <TAB> if semicolon < 0 or has_xml < semicolon : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if has_xml > 0 : 
","if has_xml > 0 :
",100.0,100.0,True
"def times ( self , value : int ) : <TAB> if value is None : <TAB> <TAB> self . _times = None <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> candidate = int ( value ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> # pylint: disable:raise-missing-from <TAB> <TAB> <TAB> raise BarException ( f "" cannot set repeat times to:  { value !r} "" ) <TAB> <TAB> if candidate < 0 : <TAB> <TAB> <TAB> raise BarException ( <TAB> <TAB> <TAB> <TAB> f "" cannot set repeat times to a value less than zero:  { value } "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise BarException ( "" cannot set repeat times on a start Repeat "" ) <TAB> <TAB> self . _times = candidate ","if self . direction == "" start "" : 
","if candidate > self . _start_repeat :
",33.2,10.55,False
"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB> <TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB> <TAB> if "" self "" in stack [ 0 ] . f_locals : <TAB> <TAB> <TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB> <TAB> <TAB> <TAB> print ( layer_names [ layer ] ) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> #<TAB>  out=[out]<TAB> return out ","if layer in layer_names : 
","if layer in layer_names :
",100.0,100.0,True
"def do_begin ( self , byte ) : <TAB> if byte . isspace ( ) : <TAB> <TAB> return <TAB> if byte != "" < "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _leadingBodyData = byte <TAB> <TAB> <TAB> return "" bodydata "" <TAB> <TAB> self . _parseError ( "" First char of document [ {!r} ] wasn ' t < "" . format ( byte ) ) <TAB> return "" tagstart "" ","if self . beExtremelyLenient : 
","if self . _leadingBodyData is None :
",45.06,22.09,False
"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB> <TAB> r = repr ( n ) <TAB> <TAB> if not comment :<TAB> # then it can be inside a comment! <TAB> <TAB> <TAB> r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB> <TAB> return r <TAB> if not isinstance ( n , six . integer_types ) : <TAB> <TAB> return n <TAB> if isinstance ( n , constants . Constant ) : <TAB> <TAB> if comment : <TAB> <TAB> <TAB> return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB> elif abs ( n ) < 10 : <TAB> <TAB> return str ( n ) <TAB> else : <TAB> <TAB> return hex ( n ) ","if not comment : 
","if not comment :
",100.0,100.0,True
"def test_training_script_with_max_history_set ( tmpdir ) : <TAB> train_dialogue_model ( <TAB> <TAB> DEFAULT_DOMAIN_PATH , <TAB> <TAB> DEFAULT_STORIES_FILE , <TAB> <TAB> tmpdir . strpath , <TAB> <TAB> interpreter = RegexInterpreter ( ) , <TAB> <TAB> policy_config = "" data/test_config/max_hist_config.yml "" , <TAB> <TAB> kwargs = { } , <TAB> ) <TAB> agent = Agent . load ( tmpdir . strpath ) <TAB> for policy in agent . policy_ensemble . policies : <TAB> <TAB> if hasattr ( policy . featurizer , "" max_history "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 2 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert policy . featurizer . max_history == 5 ","if type ( policy ) == FormPolicy : 
","if policy . featurizer . max_history > 1 :
",26.74,4.93,False
"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB> <TAB> user_input = read_input_uninstall ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> <TAB> if index == user_input : <TAB> <TAB> <TAB> <TAB> <TAB> config . uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro ( ) <TAB> else : <TAB> <TAB> log ( "" No distro installed on  "" + config . usb_disk ) ","if user_input is not False : 
","if user_input :
",29.58,38.81,False
"def set_random_avatar ( user ) : <TAB> galleries = get_available_galleries ( include_default = True ) <TAB> if not galleries : <TAB> <TAB> raise RuntimeError ( "" no avatar galleries are set "" ) <TAB> avatars_list = [ ] <TAB> for gallery in galleries : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> avatars_list = gallery [ "" images "" ] <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> avatars_list + = gallery [ "" images "" ] <TAB> random_avatar = random . choice ( avatars_list ) <TAB> store . store_new_avatar ( user , Image . open ( random_avatar . image ) ) ","if gallery [ "" name "" ] == DEFAULT_GALLERY : 
","if "" images "" in gallery :
",31.64,4.17,False
"def make_query ( self , key , filters ) : <TAB> meta = self . get_meta ( key ) <TAB> q = { meta . facet_key : self . normalize_key ( meta . path ) } <TAB> if filters : <TAB> <TAB> if filters . get ( "" has_fulltext "" ) == "" true "" : <TAB> <TAB> <TAB> q [ "" has_fulltext "" ] = "" true "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> q [ "" publish_year "" ] = filters [ "" publish_year "" ] <TAB> return q ","if filters . get ( "" publish_year "" ) : 
","if filters . get ( "" publish_year "" ) :
",100.0,100.0,True
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","elif name == "" mean_module.constant "" : 
","elif name == "" likelihood.output_covar.raw_output "" :
",74.63,28.04,False
"def _test_pooling ( input_shape , * * kwargs ) : <TAB> _test_pooling_iteration ( input_shape , * * kwargs ) <TAB> if is_gpu_available ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> input_shape = [ input_shape [ ii ] for ii in ( 0 , 3 , 1 , 2 ) ] <TAB> <TAB> <TAB> kwargs [ "" data_format "" ] = "" NCHW "" <TAB> <TAB> <TAB> _test_pooling_iteration ( input_shape , * * kwargs ) ","if len ( input_shape ) == 4 : 
","if isinstance ( input_shape , list ) :
",28.78,27.34,False
"def init ( self ) : <TAB> r = self . get_redis ( ) <TAB> if r : <TAB> <TAB> key = "" pocsuite_target "" <TAB> <TAB> info_msg = "" [PLUGIN] try fetch targets from redis... "" <TAB> <TAB> logger . info ( info_msg ) <TAB> <TAB> targets = r . get ( key ) <TAB> <TAB> count = 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for target in targets : <TAB> <TAB> <TAB> <TAB> if self . add_target ( target ) : <TAB> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> info_msg = "" [PLUGIN] get  {0}  target(s) from redis "" . format ( count ) <TAB> <TAB> logger . info ( info_msg ) ","if targets : 
","if targets :
",78.12,0.0,False
"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> setattr ( json_api_settings , setting , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> delattr ( json_api_settings , setting ) ","elif hasattr ( json_api_settings , setting ) : 
","elif setting in DEFAULTS . keys ( ) :
",28.53,8.59,False
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass ","elif hasattr ( self . metadata , attrname ) : 
","elif hasattr ( self . metadata , attrname ) :
",100.0,100.0,True
"def test_02_looking_at_listdir_path_ ( name ) : <TAB> for dline in listdir . json ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert dline [ "" type "" ] in ( "" DIRECTORY "" , "" FILE "" ) , listdir . text <TAB> <TAB> <TAB> assert dline [ "" uid "" ] == 0 , listdir . text <TAB> <TAB> <TAB> assert dline [ "" gid "" ] == 0 , listdir . text <TAB> <TAB> <TAB> assert dline [ "" name "" ] == name , listdir . text <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( f "" / { path } / { name }  not found "" ) ","if dline [ "" path "" ] == f "" { path } / { name } "" : 
","if dline [ "" path "" ] == path :
",53.93,36.47,False
"def DeletePlugin ( ) : <TAB> oid = request . form . get ( "" oid "" , "" "" ) <TAB> if oid : <TAB> <TAB> result = Mongo . coll [ "" Plugin "" ] . find_one_and_delete ( <TAB> <TAB> <TAB> { "" _id "" : ObjectId ( oid ) } , remove = True <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" filename "" ] = result [ "" filename "" ] + "" .py "" <TAB> <TAB> if os . path . exists ( file_path + result [ "" filename "" ] ) : <TAB> <TAB> <TAB> os . remove ( file_path + result [ "" filename "" ] ) <TAB> <TAB> <TAB> return "" success "" <TAB> return "" fail "" ","if not result [ "" filename "" ] . find ( "" . "" ) > - 1 : 
","if result :
",25.4,0.0,False
"def iterparent ( self , node ) : <TAB> """"""Iterator wrapper to get allowed parent and child all at once."""""" <TAB> # We do not allow the marker inside a header as that <TAB> # would causes an enless loop of placing a new TOC <TAB> # inside previously generated TOC. <TAB> for child in node : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield node , child <TAB> <TAB> <TAB> yield from self . iterparent ( child ) ","if not self . header_rgx . match ( child . tag ) and child . tag not in [ "" pre "" , "" code "" ] : 
","if self . marker and child . name == "" TOC "" :
",35.43,4.91,False
"def _get_matched_layout ( command ) : <TAB> # don't use command.split_script here because a layout mismatch will likely <TAB> # result in a non-splitable script as per shlex <TAB> cmd = command . script . split ( "" "" ) <TAB> for source_layout in source_layouts : <TAB> <TAB> is_all_match = True <TAB> <TAB> for cmd_part in cmd : <TAB> <TAB> <TAB> if not all ( [ ch in source_layout or ch in "" -_ "" for ch in cmd_part ] ) : <TAB> <TAB> <TAB> <TAB> is_all_match = False <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return source_layout ","if is_all_match : 
","if is_all_match :
",78.12,100.0,True
"def _update_tileable_and_chunk_shape ( self , tileable_graph , chunk_result , failed_ops ) : <TAB> for n in tileable_graph : <TAB> <TAB> if n . op in failed_ops : <TAB> <TAB> <TAB> continue <TAB> <TAB> tiled_n = get_tiled ( n ) <TAB> <TAB> if has_unknown_shape ( tiled_n ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # some of the chunks has been fused <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_nsplits = self . get_tileable_nsplits ( n , chunk_result = chunk_result ) <TAB> <TAB> <TAB> for node in ( n , tiled_n ) : <TAB> <TAB> <TAB> <TAB> node . _update_shape ( tuple ( sum ( nsplit ) for nsplit in new_nsplits ) ) <TAB> <TAB> <TAB> tiled_n . _nsplits = new_nsplits ","if any ( c . key not in chunk_result for c in tiled_n . chunks ) : 
","if chunk_result is not None and tiled_n . chunk_result :
",13.35,17.71,False
"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB> <TAB> if len ( all_items ) < target : <TAB> <TAB> <TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> on . append ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> off . append ( o ) <TAB> return on , off ","if o . selected : 
","if o . disabled :
",64.48,42.73,False
def parse_flow_sequence_entry_mapping_value ( self ) : <TAB> if self . check_token ( ValueToken ) : <TAB> <TAB> token = self . get_token ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . states . append ( self . parse_flow_sequence_entry_mapping_end ) <TAB> <TAB> <TAB> return self . parse_flow_node ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB> <TAB> <TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> else : <TAB> <TAB> self . state = self . parse_flow_sequence_entry_mapping_end <TAB> <TAB> token = self . peek_token ( ) <TAB> <TAB> return self . process_empty_scalar ( token . start_mark ) ,"if not self . check_token ( FlowEntryToken , FlowSequenceEndToken ) : 
","if self . check_token ( FlowEndToken , FlowEndToken ) :
",52.33,45.65,False
"def serialize_config ( self , session , key , tid , language ) : <TAB> cache_key = gen_cache_key ( key , tid , language ) <TAB> cache_obj = None <TAB> if cache_key not in self . cache : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cache_obj = db_admin_serialize_node ( session , tid , language ) <TAB> <TAB> elif key == "" notification "" : <TAB> <TAB> <TAB> cache_obj = db_get_notification ( session , tid , language ) <TAB> <TAB> self . cache [ cache_key ] = cache_obj <TAB> return self . cache [ cache_key ] ","if key == "" node "" : 
","if key == "" node "" :
",100.0,100.0,True
"def get_lldp_neighbors ( self ) : <TAB> commands = [ "" show lldp neighbors "" ] <TAB> output = self . device . run_commands ( commands ) [ 0 ] [ "" lldpNeighbors "" ] <TAB> lldp = { } <TAB> for n in output : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lldp [ n [ "" port "" ] ] = [ ] <TAB> <TAB> lldp [ n [ "" port "" ] ] . append ( <TAB> <TAB> <TAB> { "" hostname "" : n [ "" neighborDevice "" ] , "" port "" : n [ "" neighborPort "" ] } <TAB> <TAB> ) <TAB> return lldp ","if n [ "" port "" ] not in lldp . keys ( ) : 
","if "" port "" not in lldp :
",36.35,15.49,False
"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB> <TAB> name = venv . path . name <TAB> <TAB> if self . option ( "" full-path "" ) : <TAB> <TAB> <TAB> name = str ( venv . path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> self . line ( name ) ","if venv == current_env : 
","if name != current_env :
",56.5,54.11,False
"def resolve_env_secrets ( config , environ ) : <TAB> """"""Create copy that recursively replaces {""$env"": ""NAME""} with values from environ"""""" <TAB> if isinstance ( config , dict ) : <TAB> <TAB> if list ( config . keys ( ) ) == [ "" $env "" ] : <TAB> <TAB> <TAB> return environ . get ( list ( config . values ( ) ) [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return open ( list ( config . values ( ) ) [ 0 ] ) . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return { <TAB> <TAB> <TAB> <TAB> key : resolve_env_secrets ( value , environ ) <TAB> <TAB> <TAB> <TAB> for key , value in config . items ( ) <TAB> <TAB> <TAB> } <TAB> elif isinstance ( config , list ) : <TAB> <TAB> return [ resolve_env_secrets ( value , environ ) for value in config ] <TAB> else : <TAB> <TAB> return config ","elif list ( config . keys ( ) ) == [ "" $file "" ] : 
","elif isinstance ( config . keys ( ) , str ) :
",49.41,28.01,False
"def _is_valid_16bit_as_path ( cls , buf ) : <TAB> two_byte_as_size = struct . calcsize ( "" !H "" ) <TAB> while buf : <TAB> <TAB> ( type_ , num_as ) = struct . unpack_from ( <TAB> <TAB> <TAB> cls . _SEG_HDR_PACK_STR , six . binary_type ( buf ) <TAB> <TAB> ) <TAB> <TAB> if type_ is not cls . _AS_SET and type_ is not cls . _AS_SEQUENCE : <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf [ struct . calcsize ( cls . _SEG_HDR_PACK_STR ) : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> buf = buf [ num_as * two_byte_as_size : ] <TAB> return True ","if len ( buf ) < num_as * two_byte_as_size : 
","if num_as * two_byte_as_size > 2 :
",35.35,59.86,False
"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB> <TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newParent . _element . text = "" "" <TAB> <TAB> if self . _element . text is not None : <TAB> <TAB> <TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent ) ","if not newParent . _element . text : 
","if not newParent . _element . text :
",100.0,100.0,True
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation : <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation ","elif definition . name and definition . name . value == operation_name : 
","elif definition . name == operation_name :
",45.4,43.12,False
"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return str ( item ) <TAB> <TAB> elif vw . isValidPointer ( item ) : <TAB> <TAB> <TAB> return vw . reprPointer ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB> <TAB> return reprComplex ( vw , item )<TAB> # recurse <TAB> elif ptype is dict : <TAB> <TAB> return "" { %s } "" % "" , "" . join ( <TAB> <TAB> <TAB> [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return repr ( item ) ","if - 1024 < item < 1024 : 
","if vw . isValidHex ( item ) :
",26.93,7.27,False
"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cmds = cmd . split ( "" & "" ) <TAB> <TAB> <TAB> for c in cmds : <TAB> <TAB> <TAB> <TAB> if len ( c ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB> <TAB> else : <TAB> <TAB> <TAB> b64cmd = base64 . b64encode ( cmd ) <TAB> <TAB> <TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB> <TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd ","if reverseConn not in cmd : 
","if "" & "" in cmd :
",34.82,26.27,False
"def render_tasks ( self ) - > List : <TAB> results = [ ] <TAB> for task in self . tasks . values ( ) : <TAB> <TAB> job_entry = self . jobs . get ( task . job_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not self . should_render_job ( job_entry ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> files = self . get_file_counts ( [ task ] ) <TAB> <TAB> entry = ( <TAB> <TAB> <TAB> task . job_id , <TAB> <TAB> <TAB> task . task_id , <TAB> <TAB> <TAB> task . state , <TAB> <TAB> <TAB> task . type . name , <TAB> <TAB> <TAB> task . target , <TAB> <TAB> <TAB> files , <TAB> <TAB> <TAB> task . pool , <TAB> <TAB> <TAB> task . end_time , <TAB> <TAB> ) <TAB> <TAB> results . append ( entry ) <TAB> return results ","if job_entry : 
","if job_entry :
",78.12,100.0,True
"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB> <TAB> if key not in environ : <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote ( environ [ key ] ) <TAB> <TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> break <TAB> return self . app ( environ , start_response ) ","if request_uri . startswith ( script_name ) : 
","if request_uri . startswith ( script_name ) :
",100.0,100.0,True
"def _add_role_information ( self , function_dict , role_id ) : <TAB> # Make it easier to build rules based on policies attached to execution roles <TAB> function_dict [ "" role_arn "" ] = role_id <TAB> role_name = role_id . split ( "" / "" ) [ - 1 ] <TAB> function_dict [ <TAB> <TAB> "" execution_role "" <TAB> ] = await self . facade . awslambda . get_role_with_managed_policies ( role_name ) <TAB> if function_dict . get ( "" execution_role "" ) : <TAB> <TAB> statements = [ ] <TAB> <TAB> for policy in function_dict [ "" execution_role "" ] . get ( "" policies "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> statements + = policy [ "" Document "" ] [ "" Statement "" ] <TAB> <TAB> function_dict [ "" execution_role "" ] [ "" policy_statements "" ] = statements ","if "" Document "" in policy and "" Statement "" in policy [ "" Document "" ] : 
","if policy [ "" PolicyType "" ] == "" policy_policy "" :
",39.79,11.98,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 8 : <TAB> <TAB> <TAB> self . set_ts ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def format_counts ( results , json_output = False , human_readable = False ) : <TAB> if json_output : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> yield json . dumps ( result ) <TAB> else : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> space_consumed = result . get ( "" spaceConsumed "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> space_consumed = _sizeof_fmt ( int ( result . get ( "" spaceConsumed "" ) ) ) <TAB> <TAB> <TAB> yield "" %12s %12s %18s %s "" % ( <TAB> <TAB> <TAB> <TAB> result . get ( "" directoryCount "" ) , <TAB> <TAB> <TAB> <TAB> result . get ( "" fileCount "" ) , <TAB> <TAB> <TAB> <TAB> space_consumed , <TAB> <TAB> <TAB> <TAB> result . get ( "" path "" ) , <TAB> <TAB> <TAB> ) ","if human_readable : 
","if human_readable :
",78.12,100.0,True
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> if d . GetLayer ( ) == pcbnew . Edge_Cuts : <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> if parsed_drawing : <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox ","if bbox is None : 
","if bbox is None :
",100.0,100.0,True
"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB> <TAB> if k . step is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Must specify start index "" ) <TAB> <TAB> elif k . stop is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB> <TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB> <TAB> addr = k <TAB> return self . _deeper ( addr = addr ) ","elif k . start is None : 
","elif k . start is None :
",100.0,100.0,True
"def _parse ( self , stream , context ) : <TAB> obj = [ ] <TAB> try : <TAB> <TAB> if self . subcon . conflags & self . FLAG_COPY_CONTEXT : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context . __copy__ ( ) ) <TAB> <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> subobj = self . subcon . _parse ( stream , context ) <TAB> <TAB> <TAB> <TAB> obj . append ( subobj ) <TAB> <TAB> <TAB> <TAB> if self . predicate ( subobj , context ) : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> except ConstructError as ex : <TAB> <TAB> raise ArrayError ( "" missing terminator "" , ex ) <TAB> return obj ","if self . predicate ( subobj , context ) : 
","if self . predicate ( subobj , context ) :
",100.0,100.0,True
"def before_run ( self , run_context ) : <TAB> if "" featurizer "" in self . model_portion and ( <TAB> <TAB> self . need_to_refresh or self . refresh_base_model <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . refresh_base_model = True <TAB> <TAB> self . init_fn ( <TAB> <TAB> <TAB> None , run_context . session , self . model_portion , self . refresh_base_model <TAB> <TAB> ) <TAB> <TAB> self . need_to_refresh = False <TAB> <TAB> self . refresh_base_model = False ","if self . model_portion == "" whole_featurizer "" : 
","if self . need_to_refresh :
",36.67,12.11,False
"def run ( self ) : <TAB> while True : <TAB> <TAB> task = self . requestQueue . get ( ) <TAB> <TAB> if task is None : <TAB> <TAB> <TAB> # The ""None"" value is used as a sentinel by <TAB> <TAB> <TAB> # ThreadPool.cleanup().  This indicates that there <TAB> <TAB> <TAB> # are no more tasks, so we should quit. <TAB> <TAB> <TAB> break <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise SCons . Errors . BuildError ( task . targets [ 0 ] , errstr = interrupt_msg ) <TAB> <TAB> <TAB> task . execute ( ) <TAB> <TAB> except : <TAB> <TAB> <TAB> task . exception_set ( ) <TAB> <TAB> <TAB> ok = False <TAB> <TAB> else : <TAB> <TAB> <TAB> ok = True <TAB> <TAB> self . resultsQueue . put ( ( task , ok ) ) ","if self . interrupted ( ) : 
","if task . targets :
",32.38,9.42,False
"def get_overdue_evergreen_documents ( * , db_session ) - > List [ Optional [ Document ] ] : <TAB> """"""Returns all documents that have need had a recent evergreen notification."""""" <TAB> documents = ( <TAB> <TAB> db_session . query ( Document ) . filter ( Document . evergreen == True ) <TAB> ) . all ( )<TAB> # noqa <TAB> overdue_documents = [ ] <TAB> now = datetime . utcnow ( ) <TAB> for d in documents : <TAB> <TAB> next_reminder = d . evergreen_last_reminder_at + timedelta ( <TAB> <TAB> <TAB> days = d . evergreen_reminder_interval <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> overdue_documents . append ( d ) <TAB> return overdue_documents ","if now > next_reminder : 
","if next_reminder < now or next_reminder > now :
",36.24,14.21,False
"def create_local_app_folder ( local_app_path ) : <TAB> if exists ( local_app_path ) : <TAB> <TAB> raise ValueError ( "" There is already a  ' %s '  folder! Aborting! "" % local_app_path ) <TAB> for folder in subfolders ( local_app_path ) : <TAB> <TAB> if not exists ( folder ) : <TAB> <TAB> <TAB> os . mkdir ( folder ) <TAB> <TAB> <TAB> init_path = join ( folder , "" __init__.py "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> create_file ( init_path ) ","if not exists ( init_path ) : 
","if not exists ( init_path ) :
",100.0,100.0,True
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> if leaf == SymbolTrue : <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse : <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector ","if isinstance ( leaf , Integer ) : 
","if isinstance ( leaf , Integer ) :
",100.0,100.0,True
"def replace ( self , old , new ) : <TAB> v_m = self . var_map <TAB> size = v_m [ self . size ] <TAB> if not ( size . is_const ( ) or size . is_ident ( ) ) : <TAB> <TAB> size . replace ( old , new ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v_m [ new . value ( ) ] = new <TAB> <TAB> <TAB> self . size = new . value ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v_m [ old ] = new ","if new . is_ident ( ) : 
","if new . is_ident ( ) :
",100.0,100.0,True
"def method_for_doctype ( doctype ) : <TAB> method = "" xhtml "" <TAB> if doctype : <TAB> <TAB> if doctype . startswith ( "" html "" ) : <TAB> <TAB> <TAB> method = "" html "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> method = "" xhtml "" <TAB> <TAB> elif doctype . startswith ( "" svg "" ) : <TAB> <TAB> <TAB> method = "" xml "" <TAB> <TAB> else : <TAB> <TAB> <TAB> method = "" xhtml "" <TAB> return method ","elif doctype . startswith ( "" xhtml "" ) : 
","elif doctype . startswith ( "" xhtml "" ) :
",100.0,100.0,True
"def delete ( self , trans , * * kwd ) : <TAB> idnum = kwd [ self . tagged_item_id ] <TAB> item = self . _get_item_from_id ( trans , idnum , check_writable = True ) <TAB> if item is not None : <TAB> <TAB> ex_obj = self . get_item_extended_metadata_obj ( trans , item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . unset_item_extended_metadata_obj ( trans , item ) <TAB> <TAB> <TAB> self . delete_extended_metadata ( trans , ex_obj ) ","if ex_obj is not None : 
","if ex_obj is not None :
",100.0,100.0,True
"def check_testv ( self , testv ) : <TAB> test_good = True <TAB> f = open ( self . home , "" rb+ "" ) <TAB> for ( offset , length , operator , specimen ) in testv : <TAB> <TAB> data = self . _read_share_data ( f , offset , length ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> test_good = False <TAB> <TAB> <TAB> break <TAB> f . close ( ) <TAB> return test_good ","if not testv_compare ( data , operator , specimen ) : 
","if not data :
",27.24,4.0,False
"def get_history_user ( self , instance ) : <TAB> """"""Get the modifying user from instance or middleware."""""" <TAB> try : <TAB> <TAB> return instance . _history_user <TAB> except AttributeError : <TAB> <TAB> request = None <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> request = self . thread . request <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> pass <TAB> return self . get_user ( instance = instance , request = request ) ","if self . thread . request . user . is_authenticated : 
","if self . thread is not None :
",42.1,20.48,False
"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB> <TAB> for width in VALUES : <TAB> <TAB> <TAB> strlen = abs ( width * height ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> strlen * = size <TAB> <TAB> <TAB> if strlen < MAX_LEN : <TAB> <TAB> <TAB> <TAB> data = "" A "" * strlen <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> if size : <TAB> <TAB> <TAB> <TAB> arguments = ( data , size , width , height ) + extra <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arguments = ( data , width , height ) + extra <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> func ( * arguments ) <TAB> <TAB> <TAB> except ( ValueError , imageop . error ) : <TAB> <TAB> <TAB> <TAB> pass ","if size : 
","if size :
",78.12,0.0,False
"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB> <TAB> if value and value != "" "" : <TAB> <TAB> <TAB> if value [ 0 ] != "" / "" : <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == "" load_time "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Page load time must be specified in integer milliseconds. "" <TAB> <TAB> <TAB> ) <TAB> object . __setattr__ ( self , name , value ) ","if value and not isinstance ( value , int ) : 
","if not isinstance ( value , int ) :
",72.33,71.2,False
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> if self . is_computed ( ) : <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . value ( ) is self : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False ","if self . error ( ) is None : 
","if self . is_callable ( ) :
",45.13,24.27,False
"def _exclude_node ( self , name ) : <TAB> if "" exclude_nodes "" in self . node_filters : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . loggit . info ( ' Excluding node  "" {0} ""  due to node_filters ' . format ( name ) ) <TAB> <TAB> <TAB> return True <TAB> return False ","if name in self . node_filters [ "" exclude_nodes "" ] : 
","if self . node_filters [ "" exclude_nodes "" ] ( name ) :
",68.43,71.41,False
"def enumerate_projects ( ) : <TAB> """"""List projects in _DEFAULT_APP_DIR."""""" <TAB> src_path = os . path . join ( _DEFAULT_APP_DIR , "" src "" ) <TAB> projects = { } <TAB> for project in os . listdir ( src_path ) : <TAB> <TAB> projects [ project ] = [ ] <TAB> <TAB> project_path = os . path . join ( src_path , project ) <TAB> <TAB> for file in os . listdir ( project_path ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> projects [ project ] . append ( file [ : - 8 ] ) <TAB> return projects ","if file . endswith ( "" .gwt.xml "" ) : 
","if file . endswith ( "" .py "" ) :
",83.03,58.5,False
"def zip_readline_read_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile . ZipFile ( f , "" r "" ) as zipfp , zipfp . open ( TESTFN ) as zipopen : <TAB> <TAB> data = b "" "" <TAB> <TAB> while True : <TAB> <TAB> <TAB> read = zipopen . readline ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data + = read <TAB> <TAB> <TAB> read = zipopen . read ( 100 ) <TAB> <TAB> <TAB> if not read : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data + = read <TAB> self . assertEqual ( data , self . data ) ","if not read : 
","if not read :
",100.0,100.0,True
"def f ( view , s ) : <TAB> if mode == modes . NORMAL : <TAB> <TAB> return sublime . Region ( 0 ) <TAB> elif mode == modes . VISUAL : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return sublime . Region ( s . a + 1 , 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return sublime . Region ( s . a , 0 ) <TAB> elif mode == modes . INTERNAL_NORMAL : <TAB> <TAB> return sublime . Region ( view . full_line ( s . b ) . b , 0 ) <TAB> elif mode == modes . VISUAL_LINE : <TAB> <TAB> if s . a < s . b : <TAB> <TAB> <TAB> return sublime . Region ( 0 , s . b ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return sublime . Region ( 0 , s . a ) <TAB> return s ","if s . a < s . b : 
","if s . a < s . b :
",100.0,100.0,True
def response ( self ) : <TAB> try : <TAB> <TAB> response = requests . get ( str ( self ) ) <TAB> <TAB> rjson = response . json ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( response . text ) <TAB> <TAB> return rjson <TAB> except Exception as e : <TAB> <TAB> raise ResponseFanartError ( str ( e ) ) ,"if not isinstance ( rjson , dict ) : 
","if response . status_code != 200 :
",26.54,4.99,False
"def __get_type ( self , cexpr ) : <TAB> """"""Returns one of the following types: 'R' - read value, 'W' - write value, 'A' - function argument"""""" <TAB> child = cexpr <TAB> for p in reversed ( self . parents ) : <TAB> <TAB> assert p , "" Failed to get type at  "" + helper . to_hex ( self . __function_address ) <TAB> <TAB> if p . cexpr . op == idaapi . cot_call : <TAB> <TAB> <TAB> return "" Arg "" <TAB> <TAB> if not p . is_expr ( ) : <TAB> <TAB> <TAB> return "" R "" <TAB> <TAB> if p . cexpr . op == idaapi . cot_asg : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return "" W "" <TAB> <TAB> <TAB> return "" R "" <TAB> <TAB> child = p . cexpr ","if p . cexpr . x == child : 
","if child . op == idaapi . cot_write :
",31.91,9.26,False
"def _extract_lemma ( self , parse : Parse ) - > str : <TAB> special_feats = [ x for x in self . SPECIAL_FEATURES if x in parse . tag ] <TAB> if len ( special_feats ) == 0 : <TAB> <TAB> return parse . normal_form <TAB> # here we process surnames and patronyms since PyMorphy lemmatizes them incorrectly <TAB> for other in parse . lexeme : <TAB> <TAB> tag = other . tag <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> tag . case == "" nomn "" <TAB> <TAB> <TAB> and tag . gender == parse . tag . gender <TAB> <TAB> <TAB> and tag . number == "" sing "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> return other . word <TAB> return parse . normal_form ","if any ( x not in tag for x in special_feats ) : 
","if tag . case == "" special "" and tag . gender in special_feats :
",10.25,15.46,False
"def evaluateWord ( self , argument ) : <TAB> wildcard_count = argument [ 0 ] . count ( "" * "" ) <TAB> if wildcard_count > 0 : <TAB> <TAB> if wildcard_count == 1 and argument [ 0 ] . startswith ( "" * "" ) : <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ 1 : ] , method = "" endswith "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . GetWordWildcard ( argument [ 0 ] [ : - 1 ] , method = "" startswith "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _regex = argument [ 0 ] . replace ( "" * "" , "" .+ "" ) <TAB> <TAB> <TAB> matched = False <TAB> <TAB> <TAB> for w in self . words : <TAB> <TAB> <TAB> <TAB> matched = bool ( re . search ( _regex , w ) ) <TAB> <TAB> <TAB> <TAB> if matched : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> return matched <TAB> return self . GetWord ( argument [ 0 ] ) ","if wildcard_count == 1 and argument [ 0 ] . endswith ( "" * "" ) : 
","elif wildcard_count == 0 and argument [ 0 ] . endswith ( "" * "" ) :
",82.87,80.32,False
def getAllEntries ( self ) : <TAB> entries = [ ] <TAB> for bucket in self . buckets : <TAB> <TAB> last = None <TAB> <TAB> for entry in bucket . entries : <TAB> <TAB> <TAB> if last is not None : <TAB> <TAB> <TAB> <TAB> last . size = entry . virtualOffset - last . virtualOffset <TAB> <TAB> <TAB> last = entry <TAB> <TAB> <TAB> entries . append ( entry ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> entries [ - 1 ] . size = bucket . endOffset - entries [ - 1 ] . virtualOffset <TAB> return entries ,"if len ( entries ) != 0 : 
","if len ( entries ) > 1 and bucket . endOffset > entries [ - 1 ] . virtualOffset :
",58.58,18.76,False
def clean ( self ) : <TAB> if self . _ctx : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) <TAB> <TAB> else : <TAB> <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_reset ( self . _ctx ) <TAB> <TAB> libcrypto . EVP_CIPHER_CTX_free ( self . _ctx ) ,"if hasattr ( libcrypto , "" EVP_CIPHER_CTX_cleanup "" ) : 
","if libcrypto . EVP_CIPHER_CTX_cleanup ( self . _ctx ) :
",28.0,41.41,False
"def _addTab ( self , name , label , idx = None ) : <TAB> label = getLanguageString ( label ) <TAB> tab = Tab ( self , name , label ) <TAB> tab . idx = self . _makeTab ( tab , idx ) <TAB> if idx != None : <TAB> <TAB> # Update index list when inserting tabs at arbitrary positions <TAB> <TAB> newIdxList = { } <TAB> <TAB> for tIdx , t in list ( self . _tabs_by_idx . items ( ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> t . idx + = 1 <TAB> <TAB> <TAB> newIdxList [ t . idx ] = t <TAB> <TAB> self . _tabs_by_idx = newIdxList <TAB> self . _tabs_by_idx [ tab . idx ] = tab <TAB> self . _tabs_by_name [ tab . name ] = tab <TAB> return tab ","if int ( tIdx ) > = idx : 
","if t . idx < idx :
",28.03,10.92,False
"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB> <TAB> user = self . users . get ( current_user . id , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if _new_login : <TAB> <TAB> <TAB> <TAB> user [ "" session_count "" ] + = 1 <TAB> <TAB> <TAB> user [ "" key "" ] = _key ","if user is None : 
","if user is None :
",100.0,100.0,True
"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try : <TAB> <TAB> self . rpcserver . stop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . backend_rpcserver . stop ( ) <TAB> <TAB> if self . cluster_rpcserver : <TAB> <TAB> <TAB> self . cluster_rpcserver . stop ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> if self . coordination : <TAB> <TAB> try : <TAB> <TAB> <TAB> coordination . COORDINATOR . stop ( ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass <TAB> super ( Service , self ) . stop ( graceful = True ) ","if self . backend_rpcserver : 
","if self . backend_rpcserver :
",100.0,100.0,True
"def __genmenuOnlyAllocated ( menu ) : <TAB> for submenu in menu . Submenus : <TAB> <TAB> __genmenuOnlyAllocated ( submenu ) <TAB> if menu . OnlyUnallocated == True : <TAB> <TAB> tmp [ "" cache "" ] . addMenuEntries ( menu . AppDirs ) <TAB> <TAB> menuentries = [ ] <TAB> <TAB> for rule in menu . Rules : <TAB> <TAB> <TAB> menuentries = rule . do ( <TAB> <TAB> <TAB> <TAB> tmp [ "" cache "" ] . getMenuEntries ( menu . AppDirs ) , rule . Type , 2 <TAB> <TAB> <TAB> ) <TAB> <TAB> for menuentry in menuentries : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> menuentry . Parents . append ( menu ) <TAB> <TAB> <TAB> <TAB> #   menuentry.Add = False <TAB> <TAB> <TAB> <TAB> #   menuentry.Allocated = True <TAB> <TAB> <TAB> <TAB> menu . MenuEntries . append ( menuentry ) ","if menuentry . Add == True : 
","if menuentry . Add == True :
",100.0,100.0,True
"def __init__ ( self , * * options ) : <TAB> self . func_name_highlighting = get_bool_opt ( options , "" func_name_highlighting "" , True ) <TAB> self . disabled_modules = get_list_opt ( options , "" disabled_modules "" , [ ] ) <TAB> self . _functions = set ( ) <TAB> if self . func_name_highlighting : <TAB> <TAB> from pygments . lexers . _lua_builtins import MODULES <TAB> <TAB> for mod , func in iteritems ( MODULES ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _functions . update ( func ) <TAB> RegexLexer . __init__ ( self , * * options ) ","if mod not in self . disabled_modules : 
","if not mod in self . disabled_modules :
",64.07,69.85,False
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> elif r : <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y ) ","if r is None : 
","if r is None or e :
",61.88,43.47,False
"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB> <TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB> <TAB> <TAB> if child . h . startswith ( tag ) : <TAB> <TAB> <TAB> <TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList ","if tag == "" @menu "" : 
","if child . b :
",27.23,5.71,False
"def import_suffix_generator ( a_block , datatype = False ) : <TAB> if datatype is False : <TAB> <TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield name , suffix <TAB> else : <TAB> <TAB> for name , suffix in iteritems ( a_block . component_map ( Suffix ) ) : <TAB> <TAB> <TAB> if ( suffix . import_enabled ( ) is True ) and ( <TAB> <TAB> <TAB> <TAB> suffix . get_datatype ( ) is datatype <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> yield name , suffix ","if suffix . import_enabled ( ) is True : 
","if suffix . import_enabled ( ) is True :
",100.0,100.0,True
"def verify_relative_valid_path ( root , path ) : <TAB> if len ( path ) < 1 : <TAB> <TAB> raise PackagerError ( "" Empty chown path "" ) <TAB> checkpath = root <TAB> parts = path . split ( os . sep ) <TAB> for part in parts : <TAB> <TAB> if part in ( "" . "" , "" .. "" ) : <TAB> <TAB> <TAB> raise PackagerError ( "" . and .. is not allowed in chown path "" ) <TAB> <TAB> checkpath = os . path . join ( checkpath , part ) <TAB> <TAB> relpath = checkpath [ len ( root ) + 1 : ] <TAB> <TAB> if not os . path . exists ( checkpath ) : <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  does not exist "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PackagerError ( f "" chown path  { relpath }  is a soft link "" ) ","if os . path . islink ( checkpath ) : 
","if not os . path . islink ( checkpath ) :
",84.43,80.71,False
"def load_syntax ( syntax ) : <TAB> context = _create_scheme ( ) or { } <TAB> partition_scanner = PartitionScanner ( syntax . get ( "" partitions "" , [ ] ) ) <TAB> scanners = { } <TAB> for part_name , part_scanner in list ( syntax . get ( "" scanner "" , { } ) . items ( ) ) : <TAB> <TAB> scanners [ part_name ] = Scanner ( part_scanner ) <TAB> formats = [ ] <TAB> for fname , fstyle in list ( syntax . get ( "" formats "" , { } ) . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if fstyle . startswith ( "" % ( "" ) and fstyle . endswith ( "" )s "" ) : <TAB> <TAB> <TAB> <TAB> key = fstyle [ 2 : - 2 ] <TAB> <TAB> <TAB> <TAB> fstyle = context [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> fstyle = fstyle % context <TAB> <TAB> formats . append ( ( fname , fstyle ) ) <TAB> return partition_scanner , scanners , formats ","if isinstance ( fstyle , basestring ) : 
","if fstyle :
",26.73,0.0,False
"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB> <TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB> <TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB> <TAB> <TAB> if len ( ci_names ) == 0 or ci . lower ( ) in ci_names : <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result ","if key == "" CI_KEEP_ALIVE "" : 
","if key == "" ci "" :
",74.63,36.06,False
"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB> <TAB> fn = mo . groups ( ) [ 0 ] <TAB> <TAB> fn = fn . replace ( "" "" , "" _ "" ) <TAB> <TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB> <TAB> if not fn : <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn = unicode ( fn ) <TAB> <TAB> if note_markdown ( note ) : <TAB> <TAB> <TAB> fn + = "" .mkdn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> fn + = "" .txt "" <TAB> <TAB> return fn <TAB> else : <TAB> <TAB> return "" "" ","if isinstance ( fn , str ) : 
","if sys . version_info > ( 3 , 0 ) :
",28.19,7.77,False
"def post ( self , orgname , teamname ) : <TAB> if _syncing_setup_allowed ( orgname ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> team = model . team . get_organization_team ( orgname , teamname ) <TAB> <TAB> except model . InvalidTeamException : <TAB> <TAB> <TAB> raise NotFound ( ) <TAB> <TAB> config = request . get_json ( ) <TAB> <TAB> # Ensure that the specified config points to a valid group. <TAB> <TAB> status , err = authentication . check_group_lookup_args ( config ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidRequest ( "" Could not sync to group:  %s "" % err ) <TAB> <TAB> # Set the team's syncing config. <TAB> <TAB> model . team . set_team_syncing ( team , authentication . federated_service , config ) <TAB> <TAB> return team_view ( orgname , team ) <TAB> raise Unauthorized ( ) ","if not status : 
","if status != 200 :
",29.25,10.68,False
"def _marshalData ( self ) : <TAB> if self . _cache == None : <TAB> <TAB> d = self . _data <TAB> <TAB> s = "" "" <TAB> <TAB> s = time . strftime ( "" % H: % M: % S "" , ( 0 , 0 , 0 ) + d + ( 0 , 0 , - 1 ) ) <TAB> <TAB> f = d [ 2 ] - int ( d [ 2 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s + = ( "" %g "" % f ) [ 1 : ] <TAB> <TAB> s + = "" Z "" <TAB> <TAB> self . _cache = s <TAB> return self . _cache ","if f != 0 : 
","if f > 0 :
",58.14,24.74,False
"def _get_level ( levels , level_ref ) : <TAB> if level_ref in levels : <TAB> <TAB> return levels . index ( level_ref ) <TAB> if isinstance ( level_ref , six . integer_types ) : <TAB> <TAB> if level_ref < 0 : <TAB> <TAB> <TAB> level_ref + = len ( levels ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PatsyError ( "" specified level  %r  is out of range "" % ( level_ref , ) ) <TAB> <TAB> return level_ref <TAB> raise PatsyError ( "" specified level  %r  not found "" % ( level_ref , ) ) ","if not ( 0 < = level_ref < len ( levels ) ) : 
","if level_ref > = len ( levels ) :
",45.46,24.65,False
"def iterfieldselect ( source , field , where , complement , missing ) : <TAB> it = iter ( source ) <TAB> hdr = next ( it ) <TAB> yield tuple ( hdr ) <TAB> indices = asindices ( hdr , field ) <TAB> getv = operator . itemgetter ( * indices ) <TAB> for row in it : <TAB> <TAB> try : <TAB> <TAB> <TAB> v = getv ( row ) <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> v = missing <TAB> <TAB> if bool ( where ( v ) ) != complement :<TAB> # XOR <TAB> <TAB> <TAB> yield tuple ( row ) ","if bool ( where ( v ) ) != complement : 
","if bool ( where ( v ) ) != complement :
",100.0,100.0,True
"def _test_wait_read_invalid_switch ( self , sleep ) : <TAB> sock1 , sock2 = socket . socketpair ( ) <TAB> try : <TAB> <TAB> p = gevent . spawn ( <TAB> <TAB> <TAB> util . wrap_errors ( <TAB> <TAB> <TAB> <TAB> AssertionError , socket . wait_read <TAB> <TAB> <TAB> ) ,<TAB> # pylint:disable=no-member <TAB> <TAB> <TAB> sock1 . fileno ( ) , <TAB> <TAB> ) <TAB> <TAB> gevent . get_hub ( ) . loop . run_callback ( switch_None , p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gevent . sleep ( sleep ) <TAB> <TAB> result = p . get ( ) <TAB> <TAB> assert isinstance ( result , AssertionError ) , result <TAB> <TAB> assert "" Invalid switch "" in str ( result ) , repr ( str ( result ) ) <TAB> finally : <TAB> <TAB> sock1 . close ( ) <TAB> <TAB> sock2 . close ( ) ","if sleep is not None : 
","if sleep is not None :
",100.0,100.0,True
"def train ( config , args ) : <TAB> gan = setup_gan ( config , inputs , args ) <TAB> test_batches = [ ] <TAB> for i in range ( args . steps ) : <TAB> <TAB> gan . step ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> correct_prediction = 0 <TAB> <TAB> <TAB> total = 0 <TAB> <TAB> <TAB> for ( x , y ) in gan . inputs . testdata ( ) : <TAB> <TAB> <TAB> <TAB> prediction = gan . generator ( x ) <TAB> <TAB> <TAB> <TAB> correct_prediction + = ( <TAB> <TAB> <TAB> <TAB> <TAB> torch . argmax ( prediction , 1 ) == torch . argmax ( y , 1 ) <TAB> <TAB> <TAB> <TAB> ) . sum ( ) <TAB> <TAB> <TAB> <TAB> total + = y . shape [ 0 ] <TAB> <TAB> <TAB> accuracy = ( float ( correct_prediction ) / total ) * 100 <TAB> <TAB> <TAB> print ( "" accuracy:  "" , accuracy ) <TAB> return sum_metrics ","if i % args . sample_every == 0 and i > 0 : 
","if i % 10 == 0 :
",30.19,13.98,False
"def process_response ( self , request , response , spider ) : <TAB> if not response . body : <TAB> <TAB> return response <TAB> for fmt , func in six . iteritems ( self . _formats ) : <TAB> <TAB> new_response = func ( response ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> "" Decompressed response with format:  %(responsefmt)s "" , <TAB> <TAB> <TAB> <TAB> { "" responsefmt "" : fmt } , <TAB> <TAB> <TAB> <TAB> extra = { "" spider "" : spider } , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return new_response <TAB> return response ","if new_response : 
","if new_response is not None :
",34.04,36.56,False
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> if option != other_option : <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option ","if scan_argv ( self . argv , option ) is not None : 
","if option . startswith ( "" -- "" ) :
",29.75,3.98,False
"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr ( storefile , "" read "" ) : <TAB> <TAB> storefile = open ( storefile , "" rb "" ) <TAB> # Adjust store to have translations <TAB> store = cls . convertfile ( storefile , template_store ) <TAB> for unit in store . units : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB> if cls . needs_target_sync : <TAB> <TAB> <TAB> unit . target = unit . source <TAB> <TAB> <TAB> unit . rich_target = unit . rich_source <TAB> return store ","if unit . isheader ( ) : 
","if unit . istag :
",39.45,28.64,False
"def _pre_get_table ( self , _ctx , table_name ) : <TAB> vsctl_table = self . _get_table ( table_name ) <TAB> schema_helper = self . schema_helper <TAB> schema_helper . register_table ( vsctl_table . table_name ) <TAB> for row_id in vsctl_table . row_ids : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> schema_helper . register_table ( row_id . table ) <TAB> <TAB> if row_id . name_column : <TAB> <TAB> <TAB> schema_helper . register_columns ( row_id . table , [ row_id . name_column ] ) <TAB> <TAB> if row_id . uuid_column : <TAB> <TAB> <TAB> schema_helper . register_columns ( row_id . table , [ row_id . uuid_column ] ) <TAB> return vsctl_table ","if row_id . table : 
","if row_id . table :
",100.0,100.0,True
"def __init__ ( self , pin = None , pull_up = False ) : <TAB> super ( InputDevice , self ) . __init__ ( pin ) <TAB> try : <TAB> <TAB> self . pin . function = "" input "" <TAB> <TAB> pull = "" up "" if pull_up else "" down "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . pin . pull = pull <TAB> except : <TAB> <TAB> self . close ( ) <TAB> <TAB> raise <TAB> self . _active_state = False if pull_up else True <TAB> self . _inactive_state = True if pull_up else False ","if self . pin . pull != pull : 
","if self . pin . pull != pull :
",100.0,100.0,True
"def _increment_operations_count ( self , operation , executed ) : <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _executed_operations + = 1 <TAB> <TAB> <TAB> self . _executed [ operation . job_type ] + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _skipped [ operation . job_type ] + = 1 ","if executed : 
","if executed :
",78.12,0.0,False
"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super ( ) . emit ( type , info ) <TAB> if self . _has_proxy is True and self . _session . status > 0 : <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB> <TAB> elif type in self . __event_types_at_proxy : <TAB> <TAB> <TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) ","if type in self . __proxy_properties__ : 
","if type in self . __event_types_at_proxy :
",82.58,47.59,False
"def validate_pull_secret ( namespace ) : <TAB> if namespace . pull_secret is None : <TAB> <TAB> # TODO: add aka.ms link here <TAB> <TAB> warning = ( <TAB> <TAB> <TAB> "" No --pull-secret provided: cluster will not include samples or operators from  "" <TAB> <TAB> <TAB> + "" Red Hat or from certified partners. "" <TAB> <TAB> ) <TAB> <TAB> logger . warning ( warning ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Exception ( ) <TAB> <TAB> except : <TAB> <TAB> <TAB> raise InvalidArgumentValueError ( "" Invalid --pull-secret. "" ) ","if not isinstance ( json . loads ( namespace . pull_secret ) , dict ) : 
","if namespace . pull_secret not in [ "" samples "" , "" operators "" ] :
",34.49,23.29,False
"def pack ( types , * args ) : <TAB> if len ( types ) != len ( args ) : <TAB> <TAB> raise Exception ( "" number of arguments does not match format string "" ) <TAB> port = StringIO ( ) <TAB> for ( type , value ) in zip ( types , args ) : <TAB> <TAB> if type == "" V "" : <TAB> <TAB> <TAB> write_vuint ( port , value ) <TAB> <TAB> elif type == "" v "" : <TAB> <TAB> <TAB> write_vint ( port , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> write_bvec ( port , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( ' unknown xpack format string item  "" ' + type + ' "" ' ) <TAB> return port . getvalue ( ) ","elif type == "" s "" : 
","elif type == "" b "" :
",74.71,59.46,False
"def data ( self ) : <TAB> if self . _data is not None : <TAB> <TAB> return self . _data <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with open ( self . path , "" rb "" ) as jsonfile : <TAB> <TAB> <TAB> <TAB> data = jsonfile . read ( ) . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> <TAB> data = json . loads ( data ) <TAB> <TAB> <TAB> <TAB> self . _data = data <TAB> <TAB> <TAB> <TAB> return self . _data <TAB> <TAB> else : <TAB> <TAB> <TAB> return dict ( ) ","if os . path . exists ( self . path ) : 
","if os . path . exists ( self . path ) :
",100.0,100.0,True
"def interact ( self ) : <TAB> self . output . write ( "" \n "" ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> request = self . getline ( "" help>  "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except ( KeyboardInterrupt , EOFError ) : <TAB> <TAB> <TAB> break <TAB> <TAB> request = strip ( request ) <TAB> <TAB> # Make sure significant trailing quotation marks of literals don't <TAB> <TAB> # get deleted while cleaning input <TAB> <TAB> if ( <TAB> <TAB> <TAB> len ( request ) > 2 <TAB> <TAB> <TAB> and request [ 0 ] == request [ - 1 ] in ( "" ' "" , ' "" ' ) <TAB> <TAB> <TAB> and request [ 0 ] not in request [ 1 : - 1 ] <TAB> <TAB> ) : <TAB> <TAB> <TAB> request = request [ 1 : - 1 ] <TAB> <TAB> if lower ( request ) in ( "" q "" , "" quit "" ) : <TAB> <TAB> <TAB> break <TAB> <TAB> self . help ( request ) ","if not request : 
","if not request :
",100.0,100.0,True
"def api_attachment_metadata ( self ) : <TAB> resp = [ ] <TAB> for part in self . parts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> k = { <TAB> <TAB> <TAB> "" content_type "" : part . block . content_type , <TAB> <TAB> <TAB> "" size "" : part . block . size , <TAB> <TAB> <TAB> "" filename "" : part . block . filename , <TAB> <TAB> <TAB> "" id "" : part . block . public_id , <TAB> <TAB> } <TAB> <TAB> content_id = part . content_id <TAB> <TAB> if content_id : <TAB> <TAB> <TAB> if content_id [ 0 ] == "" < "" and content_id [ - 1 ] == "" > "" : <TAB> <TAB> <TAB> <TAB> content_id = content_id [ 1 : - 1 ] <TAB> <TAB> <TAB> k [ "" content_id "" ] = content_id <TAB> <TAB> resp . append ( k ) <TAB> return resp ","if not part . is_attachment : 
","if not part . block :
",77.23,38.5,False
"def _notin_text ( term , text , verbose = False ) : <TAB> index = text . find ( term ) <TAB> head = text [ : index ] <TAB> tail = text [ index + len ( term ) : ] <TAB> correct_text = head + tail <TAB> diff = _diff_text ( correct_text , text , verbose ) <TAB> newdiff = [ u ( "" %s  is contained here: "" ) % py . io . saferepr ( term , maxsize = 42 ) ] <TAB> for line in diff : <TAB> <TAB> if line . startswith ( u ( "" Skipping "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( u ( "" +  "" ) ) : <TAB> <TAB> <TAB> newdiff . append ( u ( ""<TAB> "" ) + line [ 2 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newdiff . append ( line ) <TAB> return newdiff ","if line . startswith ( u ( "" -  "" ) ) : 
","if line . startswith ( u ( "" -  "" ) ) :
",100.0,100.0,True
"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB> <TAB> API_CACHE_LOCK . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> API_CACHE = { } <TAB> <TAB> <TAB> if API_CACHE . get ( url ) is None : <TAB> <TAB> <TAB> <TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api ","if API_CACHE is None : 
","if url not in API_CACHE :
",27.95,23.36,False
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> if self . has_index_name_ : <TAB> <TAB> res + = prefix + ( "" index_name:  %s \n "" % self . DebugFormatString ( self . index_name_ ) ) <TAB> cnt = 0 <TAB> for e in self . prefix_value_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" prefix_value %s :  %s \n "" % ( elm , self . DebugFormatString ( e ) ) ) <TAB> <TAB> cnt + = 1 <TAB> if self . has_value_prefix_ : <TAB> <TAB> res + = prefix + ( <TAB> <TAB> <TAB> "" value_prefix:  %s \n "" % self . DebugFormatBool ( self . value_prefix_ ) <TAB> <TAB> ) <TAB> return res ","if printElemNumber : 
","if printElemNumber :
",78.12,0.0,False
"def add_group ( x , nl , in_group , mw ) : <TAB> if len ( x ) == 0 : <TAB> <TAB> return x <TAB> if len ( x ) > 1 and not in_group : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ "" [[ "" ] + x + [ "" ]] "" ] <TAB> <TAB> mw . warn ( <TAB> <TAB> <TAB> "" Equation will multiplex and may produce inaccurate results (see manual) "" <TAB> <TAB> ) <TAB> return [ "" [ "" ] + x + [ "" ] "" ] ","if supports_group ( x , nl ) : 
","if nl :
",26.73,0.0,False
"def unfulfilled_items ( self ) : <TAB> unfulfilled_items = 0 <TAB> for order_item in self . items . all ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> aggr = order_item . deliver_item . aggregate ( delivered = Sum ( "" quantity "" ) ) <TAB> <TAB> <TAB> unfulfilled_items + = order_item . quantity - ( aggr [ "" delivered "" ] or 0 ) <TAB> return unfulfilled_items ","if not order_item . canceled : 
","if order_item . quantity > 0 :
",35.8,33.03,False
"def _get_pattern ( self , pattern_id ) : <TAB> """"""Get pattern item by id."""""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = self . tagged_blocks . get_data ( key ) <TAB> <TAB> <TAB> for pattern in data : <TAB> <TAB> <TAB> <TAB> if pattern . pattern_id == pattern_id : <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None ","if key in self . tagged_blocks : 
","if self . tagged_blocks . has_data ( key ) :
",38.92,29.9,False
"def query_lister ( domain , query = "" "" , max_items = None , attr_names = None ) : <TAB> more_results = True <TAB> num_results = 0 <TAB> next_token = None <TAB> while more_results : <TAB> <TAB> rs = domain . connection . query_with_attributes ( <TAB> <TAB> <TAB> domain , query , attr_names , next_token = next_token <TAB> <TAB> ) <TAB> <TAB> for item in rs : <TAB> <TAB> <TAB> if max_items : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> yield item <TAB> <TAB> <TAB> num_results + = 1 <TAB> <TAB> next_token = rs . next_token <TAB> <TAB> more_results = next_token != None ","if num_results == max_items : 
","if num_results == max_items :
",100.0,100.0,True
"def find_deprecated_settings ( source ) :<TAB> # pragma: no cover <TAB> from celery . utils import deprecated <TAB> for name , opt in flatten ( NAMESPACES ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> deprecated . warn ( <TAB> <TAB> <TAB> <TAB> description = "" The  {0!r}  setting "" . format ( name ) , <TAB> <TAB> <TAB> <TAB> deprecation = opt . deprecate_by , <TAB> <TAB> <TAB> <TAB> removal = opt . remove_by , <TAB> <TAB> <TAB> <TAB> alternative = "" Use the  {0.alt}  instead "" . format ( opt ) , <TAB> <TAB> <TAB> ) <TAB> return source ","if ( opt . deprecate_by or opt . remove_by ) and getattr ( source , name , None ) : 
","if opt . deprecate_by in source :
",32.7,9.48,False
"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> if self . sl_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self ) ","if self . server : 
","if self . server :
",100.0,100.0,True
"def broadcast_events ( self , events ) : <TAB> LOGGER . debug ( "" Broadcasting events:  %s "" , events ) <TAB> with self . _subscribers_cv : <TAB> <TAB> # Copy the subscribers <TAB> <TAB> subscribers = { conn : sub . copy ( ) for conn , sub in self . _subscribers . items ( ) } <TAB> if subscribers : <TAB> <TAB> for connection_id , subscriber in subscribers . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> subscriber_events = [ <TAB> <TAB> <TAB> <TAB> <TAB> event for event in events if subscriber . is_subscribed ( event ) <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <TAB> event_list = EventList ( events = subscriber_events ) <TAB> <TAB> <TAB> <TAB> self . _send ( connection_id , event_list . SerializeToString ( ) ) ","if subscriber . is_listening ( ) : 
","if isinstance ( subscriber , Subscriber ) :
",29.12,12.26,False
"def _get_info ( self , path ) : <TAB> info = OrderedDict ( ) <TAB> if not self . _is_mac ( ) or self . _has_xcode_tools ( ) : <TAB> <TAB> stdout = None <TAB> <TAB> try : <TAB> <TAB> <TAB> stdout , stderr = Popen ( <TAB> <TAB> <TAB> <TAB> [ self . _find_binary ( ) , "" info "" , os . path . realpath ( path ) ] , <TAB> <TAB> <TAB> <TAB> stdout = PIPE , <TAB> <TAB> <TAB> <TAB> stderr = PIPE , <TAB> <TAB> <TAB> ) . communicate ( ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> if stdout : <TAB> <TAB> <TAB> <TAB> for line in stdout . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = u ( line ) . split ( "" :  "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info [ line [ 0 ] ] = line [ 1 ] <TAB> return info ","if len ( line ) == 2 : 
","if len ( line ) > 1 :
",77.42,47.75,False
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> if len ( a ) != b . len : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a . ptr == b . ptr : <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0 ","if a is None : 
","if a . ptr == b . ptr :
",29.26,9.29,False
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> if type ( item ) is ActionHandle : <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> if type ( ah ) is not ActionHandle :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB> <TAB> <TAB> <TAB> <TAB> ahs . add ( ah ) <TAB> <TAB> <TAB> else :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs ","if type ( ah ) is not ActionHandle : 
","if type ( ah ) is not ActionHandle :
",100.0,100.0,True
"def startElement ( self , name , attrs , connection ) : <TAB> if name == "" Parameter "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self [ self . _current_param . name ] = self . _current_param <TAB> <TAB> self . _current_param = Parameter ( self ) <TAB> <TAB> return self . _current_param ","if self . _current_param : 
","if self . _current_param :
",100.0,100.0,True
"def _find_class_in_descendants ( self , search_key ) : <TAB> for cls in self . primitive_classes : <TAB> <TAB> cls_key = ( cls . __name__ , cls . __module__ ) <TAB> <TAB> self . class_cache [ cls_key ] = cls <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return cls ","if cls_key == search_key : 
","if cls_key == search_key :
",100.0,100.0,True
"def doWorkForFindAll ( self , v , target , partialMatch ) : <TAB> sibling = self <TAB> while sibling : <TAB> <TAB> c1 = partialMatch and sibling . equalsTreePartial ( target ) <TAB> <TAB> if c1 : <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c2 = not partialMatch and sibling . equalsTree ( target ) <TAB> <TAB> <TAB> if c2 : <TAB> <TAB> <TAB> <TAB> v . append ( sibling ) <TAB> <TAB> ### regardless of match or not, check any children for matches <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sibling . getFirstChild ( ) . doWorkForFindAll ( v , target , partialMatch ) <TAB> <TAB> sibling = sibling . getNextSibling ( ) ","if sibling . getFirstChild ( ) : 
","if sibling . hasChildNodes ( ) :
",63.85,41.11,False
"def forward ( self , inputs : paddle . Tensor ) : <TAB> outputs = [ ] <TAB> blocks = self . block ( inputs ) <TAB> route = None <TAB> for i , block in enumerate ( blocks ) : <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> block = paddle . concat ( [ route , block ] , axis = 1 ) <TAB> <TAB> route , tip = self . yolo_blocks [ i ] ( block ) <TAB> <TAB> block_out = self . block_outputs [ i ] ( tip ) <TAB> <TAB> outputs . append ( block_out ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> route = self . route_blocks_2 [ i ] ( route ) <TAB> <TAB> <TAB> route = self . upsample ( route ) <TAB> return outputs ","if i < 2 : 
","if i < len ( blocks ) - 1 :
",35.14,16.78,False
"def _filter_paths ( basename , path , is_dir , exclude ) : <TAB> """""".gitignore style file filtering."""""" <TAB> for item in exclude : <TAB> <TAB> # Items ending in '/' apply only to directories. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Items starting with '/' apply to the whole path. <TAB> <TAB> # In any other cases just the basename is used. <TAB> <TAB> match = path if item . startswith ( "" / "" ) else basename <TAB> <TAB> if fnmatch . fnmatch ( match , item . strip ( "" / "" ) ) : <TAB> <TAB> <TAB> return True <TAB> return False ","if item . endswith ( "" / "" ) and not is_dir : 
","if is_dir and not item . startswith ( "" / "" ) :
",57.51,40.67,False
"def reposition_division ( f1 ) : <TAB> lines = f1 . splitlines ( ) <TAB> if lines [ 2 ] == division : <TAB> <TAB> lines . pop ( 2 ) <TAB> found = 0 <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if line . startswith ( ' "" "" "" ' ) : <TAB> <TAB> <TAB> found + = 1 <TAB> <TAB> <TAB> if found == 2 : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break<TAB> # already in the right place <TAB> <TAB> <TAB> <TAB> lines . insert ( i + 1 , "" "" ) <TAB> <TAB> <TAB> <TAB> lines . insert ( i + 2 , division ) <TAB> <TAB> <TAB> <TAB> break <TAB> return "" \n "" . join ( lines ) ","if division in "" \n "" . join ( lines ) : 
","if lines [ i + 1 ] == division :
",26.24,4.42,False
"def buildImage ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" COCO-IMG-2015 "" ) <TAB> version = "" 1 "" <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building image data:  "" + dpath + "" ] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data . remove_dir ( dpath ) <TAB> <TAB> build_data . make_dir ( dpath ) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES [ : 1 ] : <TAB> <TAB> <TAB> downloadable_file . download_file ( dpath ) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data . mark_done ( dpath , version_string = version ) ","if build_data . built ( dpath ) : 
","if build_data . built ( dpath ) :
",100.0,100.0,True
"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB> <TAB> col = text [ 1 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return col <TAB> <TAB> elif len ( col ) == 3 : <TAB> <TAB> <TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB> <TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text ","if len ( col ) == 6 : 
","if len ( col ) == 6 :
",100.0,100.0,True
"def tree_print ( tree ) : <TAB> for key in tree : <TAB> <TAB> print ( key , end = "" "" )<TAB> # end=' ' prevents a newline character <TAB> <TAB> tree_element = tree [ key ]<TAB> # multiple lookups is expensive, even amortized O(1)! <TAB> <TAB> for subElem in tree_element : <TAB> <TAB> <TAB> print ( ""  ->  "" , subElem , end = "" "" ) <TAB> <TAB> <TAB> if type ( subElem ) != str :<TAB> # OP wants indenting after digits <TAB> <TAB> <TAB> <TAB> print ( "" \n "" )<TAB> # newline and a space to match indenting <TAB> <TAB> print ( )<TAB> # forces a newline ","if type ( subElem ) != str : 
","if type ( subElem ) != str :
",100.0,100.0,True
"def is_dse_cluster ( path ) : <TAB> try : <TAB> <TAB> with open ( os . path . join ( path , "" CURRENT "" ) , "" r "" ) as f : <TAB> <TAB> <TAB> name = f . readline ( ) . strip ( ) <TAB> <TAB> <TAB> cluster_path = os . path . join ( path , name ) <TAB> <TAB> <TAB> filename = os . path . join ( cluster_path , "" cluster.conf "" ) <TAB> <TAB> <TAB> with open ( filename , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> data = yaml . load ( f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> except IOError : <TAB> <TAB> return False ","if "" dse_dir "" in data : 
","if "" dse_cluster_configuration "" in data :
",74.71,46.92,False
"def delete_old_target_output_files ( classpath_prefix ) : <TAB> """"""Delete existing output files or symlinks for target."""""" <TAB> directory , basename = os . path . split ( classpath_prefix ) <TAB> pattern = re . compile ( <TAB> <TAB> r "" ^ {basename} (([0-9]+)( \ .jar)?|classpath \ .txt)$ "" . format ( <TAB> <TAB> <TAB> basename = re . escape ( basename ) <TAB> <TAB> ) <TAB> ) <TAB> files = [ filename for filename in os . listdir ( directory ) if pattern . match ( filename ) ] <TAB> for rel_path in files : <TAB> <TAB> path = os . path . join ( directory , rel_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> safe_delete ( path ) ","if os . path . islink ( path ) or os . path . isfile ( path ) : 
","if os . path . islink ( path ) :
",48.7,40.66,False
"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB> names = [ ] <TAB> for d in self . test_directories : <TAB> <TAB> test_dir = os . path . join ( dist_dir , d ) <TAB> <TAB> for n in os . listdir ( test_dir ) : <TAB> <TAB> <TAB> if n . endswith ( "" .py "" ) and not n . startswith ( "" bad "" ) : <TAB> <TAB> <TAB> <TAB> names . append ( os . path . join ( test_dir , n ) ) <TAB> for filename in names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Testing  %s "" % filename ) <TAB> <TAB> source = read_pyfile ( filename ) <TAB> <TAB> self . check_roundtrip ( source ) ","if test_support . verbose : 
","if self . verbose :
",64.48,28.64,False
"def __str__ ( self ) : <TAB> if self . HasError ( ) : <TAB> <TAB> return self . ErrorAsStr ( ) <TAB> else : <TAB> <TAB> # Format is: {action} ""{target}"" ({filename}:{lineno}) <TAB> <TAB> string = self . _action <TAB> <TAB> if self . _target is not None : <TAB> <TAB> <TAB> string + = ' "" {target} "" ' . format ( target = self . _target ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = self . _filename <TAB> <TAB> <TAB> if self . _lineno is not None : <TAB> <TAB> <TAB> <TAB> path + = "" : {lineno} "" . format ( lineno = self . _lineno ) <TAB> <TAB> <TAB> string + = ""  ( {path} ) "" . format ( path = path ) <TAB> <TAB> return string ","if self . _filename is not None : 
","if self . _filename is not None :
",100.0,100.0,True
"def extra_action_out ( self , input_dict , state_batches , model , action_dist ) : <TAB> with self . _no_grad_context ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stats_dict = extra_action_out_fn ( <TAB> <TAB> <TAB> <TAB> self , input_dict , state_batches , model , action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stats_dict = parent_cls . extra_action_out ( <TAB> <TAB> <TAB> <TAB> self , input_dict , state_batches , model , action_dist <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _convert_to_non_torch_type ( stats_dict ) ","if extra_action_out_fn : 
","if extra_action_out_fn :
",78.12,100.0,True
"def _retract_bindings ( fstruct , inv_bindings , fs_class , visited ) : <TAB> # Visit each node only once: <TAB> if id ( fstruct ) in visited : <TAB> <TAB> return <TAB> visited . add ( id ( fstruct ) ) <TAB> if _is_mapping ( fstruct ) : <TAB> <TAB> items = fstruct . items ( ) <TAB> elif _is_sequence ( fstruct ) : <TAB> <TAB> items = enumerate ( fstruct ) <TAB> else : <TAB> <TAB> raise ValueError ( "" Expected mapping or sequence "" ) <TAB> for ( fname , fval ) in items : <TAB> <TAB> if isinstance ( fval , fs_class ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> fstruct [ fname ] = inv_bindings [ id ( fval ) ] <TAB> <TAB> <TAB> _retract_bindings ( fval , inv_bindings , fs_class , visited ) ","if id ( fval ) in inv_bindings : 
","if id ( fval ) in inv_bindings :
",100.0,100.0,True
"def warehouses ( self ) - > tuple : <TAB> from . . repositories import WarehouseBaseRepo <TAB> repos = dict ( ) <TAB> for dep in chain ( self . dependencies , [ self ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( dep . repo , WarehouseBaseRepo ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> for repo in dep . repo . repos : <TAB> <TAB> <TAB> if repo . from_config : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> repos [ repo . name ] = repo <TAB> return tuple ( repos . values ( ) ) ","if dep . repo is None : 
","if dep . repo is None :
",100.0,100.0,True
"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB> <TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB> <TAB> if not isinstance ( key , str ) : <TAB> <TAB> <TAB> key = str ( key ) <TAB> <TAB> detyper = self . get_detyper ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper ( val ) <TAB> <TAB> if deval is None : <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx [ key ] = deval <TAB> self . _detyped = ctx <TAB> return ctx ","if detyper is None : 
","if detyper is None :
",100.0,100.0,True
"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field . delete ( ) <TAB> <TAB> <TAB> return <TAB> <TAB> if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) : <TAB> <TAB> <TAB> if not field . grid_id : <TAB> <TAB> <TAB> <TAB> func = field . put <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> func = field . replace <TAB> <TAB> <TAB> func ( <TAB> <TAB> <TAB> <TAB> self . data . stream , <TAB> <TAB> <TAB> <TAB> filename = self . data . filename , <TAB> <TAB> <TAB> <TAB> content_type = self . data . content_type , <TAB> <TAB> <TAB> ) ","if self . _should_delete : 
","if field . deleted :
",53.65,7.72,False
"def _load ( container ) : <TAB> if isinstance ( container , str ) : <TAB> <TAB> # If container is a filename. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with open ( container , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> return pickle . load ( f ) <TAB> <TAB> # If container is a pickle string. <TAB> <TAB> else : <TAB> <TAB> <TAB> return pickle . loads ( container ) <TAB> # If container is an open file <TAB> elif isinstance ( container , IOBase ) : <TAB> <TAB> return pickle . load ( container ) <TAB> # What else could it be? <TAB> else : <TAB> <TAB> l . error ( "" Cannot unpickle container of type  %s "" , type ( container ) ) <TAB> <TAB> return None ","if all ( c in string . printable for c in container ) and os . path . exists ( container ) : 
","if os . path . isfile ( container ) :
",44.08,14.75,False
"def append_row ( self , row ) : <TAB> self . allocate_future_payments ( row ) <TAB> self . set_invoice_details ( row ) <TAB> self . set_party_details ( row ) <TAB> self . set_ageing ( row ) <TAB> if self . filters . get ( "" group_by_party "" ) : <TAB> <TAB> self . update_sub_total_row ( row , row . party ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . append_subtotal_row ( self . previous_party ) <TAB> <TAB> self . previous_party = row . party <TAB> self . data . append ( row ) ","if self . previous_party and ( self . previous_party != row . party ) : 
","if self . previous_party is not None :
",42.71,19.77,False
"def gg1 ( ) : <TAB> while 1 : <TAB> <TAB> tt = 3 <TAB> <TAB> while tt > 0 : <TAB> <TAB> <TAB> trace . append ( tt ) <TAB> <TAB> <TAB> val = yield <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tt = 10<TAB> # <= uncomment this line <TAB> <TAB> <TAB> <TAB> trace . append ( "" breaking early... "" ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> tt - = 1 <TAB> <TAB> trace . append ( "" try! "" ) ","if val is not None : 
","if val is not None :
",100.0,100.0,True
"def migrate_common_facts ( facts ) : <TAB> """"""Migrate facts from various roles into common"""""" <TAB> params = { "" node "" : ( "" portal_net "" ) , "" master "" : ( "" portal_net "" ) } <TAB> if "" common "" not in facts : <TAB> <TAB> facts [ "" common "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB> <TAB> if role in facts : <TAB> <TAB> <TAB> for param in params [ role ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> facts [ "" common "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts ","if param in facts [ role ] : 
","if param in facts [ role ] :
",100.0,100.0,True
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> if self . do_manders : <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> if self . do_costes : <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ] ","if self . do_corr_and_slope : 
","if self . do_correlations :
",64.48,36.34,False
"def access_modes ( self ) : <TAB> """"""access_modes property"""""" <TAB> if self . _access_modes is None : <TAB> <TAB> self . _access_modes = self . get_access_modes ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _access_modes = list ( self . _access_modes ) <TAB> return self . _access_modes ","if not isinstance ( self . _access_modes , list ) : 
","if isinstance ( self . _access_modes , list ) :
",77.08,86.17,False
"def unwrap_envelope ( self , data , many ) : <TAB> if many : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( data , InstrumentedList ) or isinstance ( data , list ) : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = len ( data ) <TAB> <TAB> <TAB> <TAB> return data <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . context [ "" total "" ] = data [ "" total "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . context [ "" total "" ] = 0 <TAB> <TAB> <TAB> data = { "" items "" : [ ] } <TAB> <TAB> return data [ "" items "" ] <TAB> return data ","if data [ "" items "" ] : 
","if "" total "" not in data :
",33.38,8.26,False
"def to_string ( self , fmt = "" {:.4f} "" ) : <TAB> result_str = "" "" <TAB> for key in self . measures : <TAB> <TAB> result = self . m_dict [ key ] [ 0 ] ( ) <TAB> <TAB> result_str + = ( <TAB> <TAB> <TAB> "" , "" . join ( fmt . format ( x ) for x in result ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else fmt . format ( result ) <TAB> <TAB> ) <TAB> <TAB> result_str + = "" , "" <TAB> return result_str [ : - 1 ]<TAB> # trim the last comma ","if isinstance ( result , tuple ) 
","if isinstance ( result , list )
",82.41,64.35,False
"def on_torrent_created ( self , result ) : <TAB> if not result : <TAB> <TAB> return <TAB> self . dialog_widget . btn_create . setEnabled ( True ) <TAB> self . dialog_widget . edit_channel_create_torrent_progress_label . setText ( <TAB> <TAB> "" Created torrent "" <TAB> ) <TAB> if "" torrent "" in result : <TAB> <TAB> self . create_torrent_notification . emit ( { "" msg "" : "" Torrent successfully created "" } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_torrent_to_channel ( result [ "" torrent "" ] ) <TAB> <TAB> self . close_dialog ( ) ","if self . dialog_widget . add_to_channel_checkbox . isChecked ( ) : 
","if result [ "" torrent "" ] :
",26.25,1.66,False
"def save ( self ) : <TAB> for var_name in self . default_config : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if var_name in self . file_config : <TAB> <TAB> <TAB> <TAB> del self . file_config [ var_name ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . file_config [ var_name ] = getattr ( self , var_name ) <TAB> with open ( self . config_path , "" w "" ) as f : <TAB> <TAB> f . write ( json . dumps ( self . file_config , indent = 2 ) ) ","if getattr ( self , var_name , None ) == self . default_config [ var_name ] : 
","if not hasattr ( self , var_name ) :
",32.71,15.67,False
"def get_class_parameters ( kwarg ) : <TAB> ret = { "" attrs "" : [ ] } <TAB> for key in ( "" rsc "" , "" fsc "" , "" usc "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret [ "" attrs "" ] . append ( <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> "" TCA_HFSC_ %s "" % key . upper ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" m1 "" : get_rate ( kwarg [ key ] . get ( "" m1 "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" d "" : get_time ( kwarg [ key ] . get ( "" d "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" m2 "" : get_rate ( kwarg [ key ] . get ( "" m2 "" , 0 ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> return ret ","if key in kwarg : 
","if kwarg [ key ] :
",28.22,11.48,False
"def forward ( self , x ) : <TAB> f_x = x <TAB> if self . exp : <TAB> <TAB> f_x = self . exp_swish ( self . exp_bn ( self . exp ( f_x ) ) ) <TAB> f_x = self . dwise_swish ( self . dwise_bn ( self . dwise ( f_x ) ) ) <TAB> f_x = self . se ( f_x ) <TAB> f_x = self . lin_proj_bn ( self . lin_proj ( f_x ) ) <TAB> if self . has_skip : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f_x = drop_connect ( f_x , effnet_cfg . EN . DC_RATIO ) <TAB> <TAB> f_x = x + f_x <TAB> return f_x ","if self . training and effnet_cfg . EN . DC_RATIO > 0.0 : 
","if self . skip :
",35.76,3.88,False
"def cli_uninstall_distro ( ) : <TAB> distro_list = install_distro_list ( ) <TAB> if distro_list is not None : <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> log ( str ( index ) + ""   --->>   "" + _distro_dir ) <TAB> <TAB> user_input = read_input_uninstall ( ) <TAB> <TAB> if user_input is not False : <TAB> <TAB> <TAB> for index , _distro_dir in enumerate ( distro_list ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> config . uninstall_distro_dir_name = _distro_dir <TAB> <TAB> <TAB> <TAB> <TAB> unin_distro ( ) <TAB> else : <TAB> <TAB> log ( "" No distro installed on  "" + config . usb_disk ) ","if index == user_input : 
","if user_input == _distro_dir :
",53.85,19.08,False
"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> if alias . name == "" * "" : <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation ) ","if not self . futuresAllowed : 
","if self . futuresAllowed :
",58.31,57.89,False
"def _split_and_load ( batch , ctx_list ) : <TAB> """"""Split data to 1 batch each device."""""" <TAB> new_batch = [ ] <TAB> for _ , data in enumerate ( batch ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_data = [ x . as_in_context ( ctx ) for x , ctx in zip ( data , ctx_list ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_data = [ data . as_in_context ( ctx_list [ 0 ] ) ] <TAB> <TAB> new_batch . append ( new_data ) <TAB> return new_batch ","if isinstance ( data , ( list , tuple ) ) : 
","if isinstance ( data , ( list , tuple ) ) :
",100.0,100.0,True
"def wait_success ( self , timeout = 60 * 10 ) : <TAB> for i in range ( timeout / / 10 ) : <TAB> <TAB> time . sleep ( 10 ) <TAB> <TAB> status = self . query_job ( ) <TAB> <TAB> print ( "" job  {}  status is  {} "" . format ( self . job_id , status ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> if status and status in [ <TAB> <TAB> <TAB> StatusSet . CANCELED , <TAB> <TAB> <TAB> StatusSet . TIMEOUT , <TAB> <TAB> <TAB> StatusSet . FAILED , <TAB> <TAB> ] : <TAB> <TAB> <TAB> return False <TAB> return False ","if status and status == StatusSet . SUCCESS : 
","if status :
",27.38,0.0,False
"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rel_root = "" "" <TAB> <TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB> <TAB> if not os . path . exists ( dst_root ) : <TAB> <TAB> <TAB> os . makedirs ( dst_root ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) ) ","if src_root != src_dir : 
","if os . path . isfile ( src_root ) :
",27.58,14.32,False
"def _make_padded_shapes ( self , dataset , decoders ) : <TAB> padded_shapes = dataset . output_shapes <TAB> for i , hparams_i in enumerate ( self . _hparams . datasets ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not hparams_i [ "" pad_to_max_seq_length "" ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> text_and_id_shapes = MonoTextData . _make_padded_text_and_id_shapes ( <TAB> <TAB> <TAB> dataset , hparams_i , decoders [ i ] , self . text_name ( i ) , self . text_id_name ( i ) <TAB> <TAB> ) <TAB> <TAB> padded_shapes . update ( text_and_id_shapes ) <TAB> return padded_shapes ","if not _is_text_data ( hparams_i [ "" data_type "" ] ) : 
","if hparams_i [ "" pad_to_min_seq_length "" ] == 0 :
",37.91,22.83,False
"def format_errors ( messages ) : <TAB> errors = { } <TAB> for k , v in messages . items ( ) : <TAB> <TAB> key = camelize ( k , uppercase_first_letter = False ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errors [ key ] = format_errors ( v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> errors [ key ] = v [ 0 ] <TAB> return errors ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def generic_visit ( self , node , parents = None ) : <TAB> parents = ( parents or [ ] ) + [ node ] <TAB> for field , value in iter_fields ( node ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for item in value : <TAB> <TAB> <TAB> <TAB> if isinstance ( item , AST ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . visit ( item , parents ) <TAB> <TAB> elif isinstance ( value , AST ) : <TAB> <TAB> <TAB> self . visit ( value , parents ) ","if isinstance ( value , list ) : 
","if isinstance ( value , list ) :
",100.0,100.0,True
"def get_override_css ( self ) : <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB> <TAB> filename = self . view . file_name ( ) <TAB> <TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB> <TAB> if filename and filetypes : <TAB> <TAB> <TAB> for filetype in filetypes : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( css_filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" "" ","if filename . endswith ( filetype ) : 
","if filetype == "" css "" :
",26.96,7.27,False
"def clean ( self ) : <TAB> super ( ) . clean ( ) <TAB> # If the Cluster is assigned to a Site, all Devices must be assigned to that Site. <TAB> if self . cluster . site is not None : <TAB> <TAB> for device in self . cleaned_data . get ( "" devices "" , [ ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" devices "" : "" {}  belongs to a different site ( {} ) than the cluster ( {} ) "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> device , device . site , self . cluster . site <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> ) ","if device . site != self . cluster . site : 
","if not self . is_assigned_to_site ( device ) :
",35.95,6.92,False
"def _setProcessPriority ( process , nice_val , disable_gc ) : <TAB> org_nice_val = Computer . _process_original_nice_value <TAB> try : <TAB> <TAB> process . nice ( nice_val ) <TAB> <TAB> Computer . in_high_priority_mode = nice_val != org_nice_val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gc . disable ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> gc . enable ( ) <TAB> <TAB> return True <TAB> except psutil . AccessDenied : <TAB> <TAB> print2err ( <TAB> <TAB> <TAB> "" WARNING: Could not set process  {}  priority  "" <TAB> <TAB> <TAB> "" to  {} "" . format ( process . pid , nice_val ) <TAB> <TAB> ) <TAB> <TAB> return False ","if disable_gc : 
","if disable_gc :
",78.12,100.0,True
"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB> <TAB> <TAB> <TAB> "" may only return a single token for an And alternative,  "" <TAB> <TAB> <TAB> <TAB> "" in future will return the full list of tokens "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> stacklevel = 3 , <TAB> <TAB> <TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches ) ","if any ( isinstance ( e , And ) for e in self . exprs ) : 
","if name in self . _named_tokens :
",31.03,8.81,False
"def make_sources ( project : RootDependency ) - > str : <TAB> content = [ ] <TAB> if project . readme : <TAB> <TAB> content . append ( project . readme . path . name ) <TAB> <TAB> if project . readme . markup != "" rst "" : <TAB> <TAB> <TAB> content . append ( project . readme . to_rst ( ) . path . name ) <TAB> path = project . package . path <TAB> for fname in ( "" setup.cfg "" , "" setup.py "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> content . append ( fname ) <TAB> for package in chain ( project . package . packages , project . package . data ) : <TAB> <TAB> for fpath in package : <TAB> <TAB> <TAB> fpath = fpath . relative_to ( project . package . path ) <TAB> <TAB> <TAB> content . append ( "" / "" . join ( fpath . parts ) ) <TAB> return "" \n "" . join ( content ) ","if ( path / fname ) . exists ( ) : 
","if fname . startswith ( path ) :
",28.32,12.35,False
"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB> <TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB> <TAB> for j , s in enumerate ( c ) : <TAB> <TAB> <TAB> if j < segmentCount : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices [ index ] = 1 <TAB> <TAB> <TAB> index + = s [ 1 ] <TAB> return controlPointIndices ","if glyph . contours [ i ] . segments [ j ] . type == "" line "" : 
","if s [ 0 ] == va :
",25.67,3.7,False
"def MergeFrom ( self , other ) : <TAB> if self . message_class is not None : <TAB> <TAB> if other . Parse ( self . message_class ) : <TAB> <TAB> <TAB> self . message . MergeFrom ( other . message ) <TAB> elif other . message_class is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . message = other . message_class ( ) <TAB> <TAB> <TAB> self . message_class = other . message_class <TAB> <TAB> self . message . MergeFrom ( other . message ) <TAB> else : <TAB> <TAB> self . message + = other . message ","if not self . Parse ( other . message_class ) : 
","if not self . message :
",44.85,18.82,False
"def remove_old_snapshot ( install_dir ) : <TAB> logging . info ( "" Removing any old files in  {} "" . format ( install_dir ) ) <TAB> for file in glob . glob ( "" {} /* "" . format ( install_dir ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . unlink ( file ) <TAB> <TAB> <TAB> elif os . path . isdir ( file ) : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( file ) <TAB> <TAB> except Exception as error : <TAB> <TAB> <TAB> logging . error ( "" Error:  {} "" . format ( error ) ) <TAB> <TAB> <TAB> sys . exit ( 1 ) ","if os . path . isfile ( file ) : 
","if os . path . isfile ( file ) :
",100.0,100.0,True
"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB> <TAB> val = self . nodeValue <TAB> <TAB> if not isinstance ( val , str ) : <TAB> <TAB> <TAB> val = str ( self . nodeValue ) <TAB> else : <TAB> <TAB> v = self . nodeValue <TAB> <TAB> if not isinstance ( v , str ) : <TAB> <TAB> <TAB> v = str ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = "" "" . join ( v . split ( ) ) <TAB> <TAB> val = escape ( v ) <TAB> w ( val ) ","if strip : 
","if "" \t "" in v :
",29.58,6.57,False
"def validate_attributes ( self ) : <TAB> for attribute in self . get_all_attributes ( ) : <TAB> <TAB> value = getattr ( self , attribute . code , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if attribute . required : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute cannot be blank "" ) % { "" attr "" : attribute . code } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> attribute . validate_value ( value ) <TAB> <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" %(attr)s  attribute  %(err)s "" ) % { "" attr "" : attribute . code , "" err "" : e } <TAB> <TAB> <TAB> <TAB> ) ","if value is None : 
","if value is None :
",100.0,100.0,True
"def PyJsHoisted_BinaryExpression_ ( node , parent , this , arguments , var = var ) : <TAB> var = Scope ( <TAB> <TAB> { u "" node "" : node , u "" this "" : this , u "" arguments "" : arguments , u "" parent "" : parent } , var <TAB> ) <TAB> var . registers ( [ u "" node "" , u "" parent "" ] ) <TAB> if PyJsStrictEq ( var . get ( u "" node "" ) . get ( u "" operator "" ) , Js ( u "" in "" ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return var . get ( u "" true "" ) <TAB> <TAB> if var . get ( u "" t "" ) . callprop ( u "" isFor "" , var . get ( u "" parent "" ) ) : <TAB> <TAB> <TAB> return var . get ( u "" true "" ) <TAB> return Js ( False ) ","if var . get ( u "" t "" ) . callprop ( u "" isVariableDeclarator "" , var . get ( u "" parent "" ) ) : 
","if var . get ( u "" isFor "" ) . callprop ( u "" isFor "" , var . get ( u "" parent "" ) ) :
",90.53,80.96,False
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> if n . _child . isidentical ( expr ) : <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> elif n not in fields : <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) ) ","if not isinstance ( n , _strtypes ) : 
","elif not isinstance ( n , ( str , unicode ) ) :
",45.57,33.26,False
"def encode ( self , msg ) : <TAB> """"""Encodes the message to the stream encoding."""""" <TAB> stream = self . stream <TAB> rv = msg + "" \n "" <TAB> if ( PY2 and is_unicode ( rv ) ) or not ( <TAB> <TAB> PY2 or is_unicode ( rv ) or _is_text_stream ( stream ) <TAB> ) : <TAB> <TAB> enc = self . encoding <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> enc = getattr ( stream , "" encoding "" , None ) or "" utf-8 "" <TAB> <TAB> rv = rv . encode ( enc , "" replace "" ) <TAB> return rv ","if enc is None : 
","if enc is None :
",100.0,100.0,True
"def color_convert ( self , to_color_space , preserve_alpha = True ) : <TAB> if to_color_space == self . color_space and preserve_alpha : <TAB> <TAB> return self <TAB> else : <TAB> <TAB> pixels = pixels_as_float ( self . pixels ) <TAB> <TAB> converted = convert_color ( <TAB> <TAB> <TAB> pixels , self . color_space , to_color_space , preserve_alpha <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> return Image ( converted , to_color_space ) ","if converted is None : 
","if converted is None :
",100.0,100.0,True
"def seek ( self , pos ) : <TAB> if self . closed : <TAB> <TAB> raise IOError ( "" Cannot seek on a closed file "" ) <TAB> for n , idx in enumerate ( self . _indexes [ : : - 1 ] ) : <TAB> <TAB> if idx . offset < = pos : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _idxiter = iter ( self . _indexes [ - ( n + 1 ) : ] ) <TAB> <TAB> <TAB> <TAB> self . _nextidx ( ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise Exception ( "" Cannot seek to pos "" ) <TAB> self . _curfile . seek ( pos - self . _curidx . offset ) ","if idx != self . _curidx : 
","if n + 1 < len ( self . _indexes ) :
",34.53,13.07,False
"def load_from_json ( self , node_data : dict , import_version : float ) : <TAB> if import_version < = 0.08 : <TAB> <TAB> self . image_pointer = unpack_pointer_property_name ( <TAB> <TAB> <TAB> bpy . data . images , node_data , "" image_name "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> proposed_name = node_data . get ( "" image_name "" ) <TAB> <TAB> <TAB> self . info ( f "" image data not found in current  { proposed_name } "" ) ","if not self . image_pointer : 
","if self . image_pointer is None :
",41.27,48.55,False
"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB> <TAB> if operator == "" Average "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB> <TAB> elif operator == "" Max "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB> <TAB> elif operator == "" Min "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB> <TAB> elif operator == "" Sum "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _SumAggregator ( ) ) ","elif operator == "" Count "" : 
","elif operator == "" Count "" :
",100.0,100.0,True
"def attrgetter ( item ) : <TAB> items = [ None ] * len ( attribute ) <TAB> for i , attribute_part in enumerate ( attribute ) : <TAB> <TAB> item_i = item <TAB> <TAB> for part in attribute_part : <TAB> <TAB> <TAB> item_i = environment . getitem ( item_i , part ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> item_i = postprocess ( item_i ) <TAB> <TAB> items [ i ] = item_i <TAB> return items ","if postprocess is not None : 
","if postprocess :
",29.58,0.0,False
"def work ( self ) : <TAB> while True : <TAB> <TAB> timeout = self . timeout <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> timeout = self . idle_timeout <TAB> <TAB> log . debug ( "" Wait for  {} "" . format ( timeout ) ) <TAB> <TAB> fetch . wait ( timeout ) <TAB> <TAB> if shutting_down . is_set ( ) : <TAB> <TAB> <TAB> log . info ( "" Stop fetch worker "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . fetch ( ) ","if idle . is_set ( ) : 
","if self . idle_timeout is not None :
",32.11,6.57,False
"def testCoreInterfaceIntInputData ( ) : <TAB> result_testing = False <TAB> for _ in range ( 10 ) : <TAB> <TAB> hsyncnet_instance = hsyncnet ( <TAB> <TAB> <TAB> [ [ 1 ] , [ 2 ] , [ 3 ] , [ 20 ] , [ 21 ] , [ 22 ] ] , 2 , initial_type . EQUIPARTITION , ccore = True <TAB> <TAB> ) <TAB> <TAB> analyser = hsyncnet_instance . process ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result_testing = True <TAB> <TAB> <TAB> break <TAB> assert result_testing ","if len ( analyser . allocate_clusters ( 0.1 ) ) == 2 : 
","if analyser . interface_int_data == initial_type . EQUIPARTITION :
",30.27,7.96,False
"def _gen ( ) : <TAB> buf = [ ] <TAB> iterable = dataset ( ) <TAB> try : <TAB> <TAB> while len ( buf ) < buffer_size : <TAB> <TAB> <TAB> buf . append ( next ( iterable ) ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> i = random . randint ( 0 , buffer_size - 1 ) <TAB> <TAB> <TAB> n = next ( iterable ) <TAB> <TAB> <TAB> yield buf [ i ] <TAB> <TAB> <TAB> buf [ i ] = n <TAB> except StopIteration : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> random . shuffle ( buf ) <TAB> <TAB> <TAB> for i in buf : <TAB> <TAB> <TAB> <TAB> yield i ","if len ( buf ) : 
","if shuffle :
",27.65,0.0,False
"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB> <TAB> if isinstance ( elt , ( int , long ) ) : <TAB> <TAB> <TAB> l . append ( _names . get ( elt , elt ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> l . append ( elt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l . append ( debug_tree ( elt ) ) <TAB> return l ","elif isinstance ( elt , str ) : 
","elif isinstance ( elt , str ) :
",100.0,100.0,True
"def reverse_code ( apps : StateApps , schema_editor : DatabaseSchemaEditor ) - > None : <TAB> PreregistrationUser = apps . get_model ( "" zerver "" , "" PreregistrationUser "" ) <TAB> for user in PreregistrationUser . objects . all ( ) : <TAB> <TAB> if user . invited_as == 2 :<TAB> # PreregistrationUser.INVITE_AS['REALM_ADMIN'] <TAB> <TAB> <TAB> user . invited_as_admin = True <TAB> <TAB> else :<TAB> # PreregistrationUser.INVITE_AS['MEMBER'] <TAB> <TAB> <TAB> user . invited_as_admin = False <TAB> <TAB> user . save ( update_fields = [ "" invited_as_admin "" ] ) ","if user . invited_as == 2 : 
","if user . invited_as == 2 :
",100.0,100.0,True
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out ","if line . startswith ( "" >>END "" ) : 
","if line . startswith ( "" >> %s "" % section_name ) :
",59.44,46.37,False
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints ","if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : 
","elif text [ 0 ] in "" \n \x85 \u2028 \u2029 "" :
",57.1,64.88,False
"def database_app ( request ) : <TAB> if request . param == "" postgres_app "" : <TAB> <TAB> if not which ( "" initdb "" ) : <TAB> <TAB> <TAB> pytest . skip ( "" initdb must be on PATH for postgresql fixture "" ) <TAB> <TAB> if not psycopg2 : <TAB> <TAB> <TAB> pytest . skip ( "" psycopg2 must be installed for postgresql fixture "" ) <TAB> if request . param == "" sqlite_rabbitmq_app "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pytest . skip ( <TAB> <TAB> <TAB> <TAB> "" rabbitmq tests will be skipped if GALAXY_TEST_AMQP_INTERNAL_CONNECTION env var is unset "" <TAB> <TAB> <TAB> ) <TAB> return request . getfixturevalue ( request . param ) ","if not os . environ . get ( "" GALAXY_TEST_AMQP_INTERNAL_CONNECTION "" ) : 
","if GALAXY_TEST_AMQP_INTERNAL_CONNECTION is not None :
",26.09,38.82,False
"def do_rollout ( agent , env , num_steps , render = False ) : <TAB> total_rew = 0 <TAB> ob = env . reset ( ) <TAB> for t in range ( num_steps ) : <TAB> <TAB> a = agent . act ( ob ) <TAB> <TAB> ( ob , reward , done , _info ) = env . step ( a ) <TAB> <TAB> total_rew + = reward <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> env . render ( ) <TAB> <TAB> if done : <TAB> <TAB> <TAB> break <TAB> return total_rew , t + 1 ","if render and t % 3 == 0 : 
","if render :
",27.38,0.0,False
"def _handle_subrepos ( self , ctx , dirty_trees ) : <TAB> substate = util . parse_hgsubstate ( ctx [ "" .hgsubstate "" ] . data ( ) . splitlines ( ) ) <TAB> sub = util . OrderedDict ( ) <TAB> if "" .hgsub "" in ctx : <TAB> <TAB> sub = util . parse_hgsub ( ctx [ "" .hgsub "" ] . data ( ) . splitlines ( ) ) <TAB> for path , sha in substate . iteritems ( ) : <TAB> <TAB> # Ignore non-Git repositories keeping state in .hgsubstate. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> d = os . path . dirname ( path ) <TAB> <TAB> dirty_trees . add ( d ) <TAB> <TAB> tree = self . _dirs . setdefault ( d , dulobjs . Tree ( ) ) <TAB> <TAB> tree . add ( os . path . basename ( path ) , dulobjs . S_IFGITLINK , sha ) ","if path in sub and not sub [ path ] . startswith ( "" [git] "" ) : 
","if not self . _ignore_git_repository ( path , sha , sub ) :
",26.61,5.6,False
"def get_property_file_image_choices ( self , pipeline ) : <TAB> columns = pipeline . get_measurement_columns ( ) <TAB> image_names = [ ] <TAB> for column in columns : <TAB> <TAB> object_name , feature , coltype = column [ : 3 ] <TAB> <TAB> choice = feature [ ( len ( C_FILE_NAME ) + 1 ) : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> image_names . append ( choice ) <TAB> return image_names ","if object_name == "" Image "" and ( feature . startswith ( C_FILE_NAME ) ) : 
","if choice in C_FILE_NAME :
",25.65,10.25,False
"def check_all_decorator_order ( ) : <TAB> """"""Check that in all test files, the slow decorator is always last."""""" <TAB> errors = [ ] <TAB> for fname in os . listdir ( PATH_TO_TESTS ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = os . path . join ( PATH_TO_TESTS , fname ) <TAB> <TAB> <TAB> new_errors = check_decorator_order ( filename ) <TAB> <TAB> <TAB> errors + = [ f "" -  { filename } , line  { i } "" for i in new_errors ] <TAB> if len ( errors ) > 0 : <TAB> <TAB> msg = "" \n "" . join ( errors ) <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> f "" The parameterized decorator (and its variants) should always be first, but this is not the case in the following files: \n { msg } "" <TAB> <TAB> ) ","if fname . endswith ( "" .py "" ) : 
","if fname . endswith ( "" .py "" ) and not fname . startswith ( "" __init__ "" ) :
",76.7,38.87,False
"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB> <TAB> if col and col . get_title ( ) == _ ( "" Active "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id ) ","if self . watchdirs [ watchdir_id ] [ "" enabled "" ] : 
","if client . autoadd . get_active ( watchdir_id ) :
",30.33,11.7,False
"def get_conv_output_size ( input_size , kernel_size , stride , padding , dilation ) : <TAB> ndim = len ( input_size ) <TAB> output_size = [ ] <TAB> for i in range ( ndim ) : <TAB> <TAB> size = ( <TAB> <TAB> <TAB> input_size [ i ] + 2 * padding [ i ] - dilation [ i ] * ( kernel_size [ i ] - 1 ) - 1 <TAB> <TAB> ) / / stride [ i ] + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> output_size . append ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> output_size . append ( size ) <TAB> return output_size ","if kernel_size [ i ] == - 1 : 
","if size == 0 :
",26.68,7.51,False
"def from_location ( cls , location , basename , metadata = None , * * kw ) : <TAB> project_name , version , py_version , platform = [ None ] * 4 <TAB> basename , ext = os . path . splitext ( basename ) <TAB> if ext . lower ( ) in ( "" .egg "" , "" .egg-info "" ) : <TAB> <TAB> match = EGG_NAME ( basename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> project_name , version , py_version , platform = match . group ( <TAB> <TAB> <TAB> <TAB> "" name "" , "" ver "" , "" pyver "" , "" plat "" <TAB> <TAB> <TAB> ) <TAB> return cls ( <TAB> <TAB> location , <TAB> <TAB> metadata , <TAB> <TAB> project_name = project_name , <TAB> <TAB> version = version , <TAB> <TAB> py_version = py_version , <TAB> <TAB> platform = platform , <TAB> <TAB> * * kw <TAB> ) ","if match : 
","if match :
",78.12,0.0,False
"def __new__ ( metacls , typename , bases , namespace ) : <TAB> annotations = namespace . get ( "" __annotations__ "" , { } ) <TAB> for t in annotations . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for ut in t . __args__ : <TAB> <TAB> <TAB> <TAB> _assert_tensorizer_type ( ut ) <TAB> <TAB> else : <TAB> <TAB> <TAB> _assert_tensorizer_type ( t ) <TAB> return super ( ) . __new__ ( metacls , typename , bases , namespace ) ","if getattr ( t , "" __origin__ "" , "" "" ) is Union : 
","if hasattr ( t , "" __args__ "" ) :
",42.46,34.62,False
"def decode_content ( self ) : <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB> <TAB> ct , options = parse_options_header ( ct ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . json ( charset ) <TAB> <TAB> elif ct . startswith ( "" text/ "" ) : <TAB> <TAB> <TAB> return self . text ( charset ) <TAB> <TAB> elif ct == FORM_URL_ENCODED : <TAB> <TAB> <TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content ","if ct in JSON_CONTENT_TYPES : 
","if ct . startswith ( "" json/ "" ) :
",29.29,8.3,False
"def get_full_path ( path ) : <TAB> if "" :// "" not in path : <TAB> <TAB> path = os . path . join ( self . AUTO_COLL_TEMPL , path , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = os . path . join ( abs_path , path ) <TAB> return path ","if abs_path : 
","if os . path . isabs ( path ) :
",29.22,5.52,False
"def __getitem__ ( self , name_or_path ) : <TAB> if isinstance ( name_or_path , integer_types ) : <TAB> <TAB> return list . __getitem__ ( self , name_or_path ) <TAB> elif isinstance ( name_or_path , tuple ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> val = self <TAB> <TAB> <TAB> for fid in name_or_path : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise KeyError<TAB> # path contains base value <TAB> <TAB> <TAB> <TAB> val = val [ fid ] <TAB> <TAB> <TAB> return val <TAB> <TAB> except ( KeyError , IndexError ) : <TAB> <TAB> <TAB> raise KeyError ( name_or_path ) <TAB> else : <TAB> <TAB> raise TypeError ( self . _INDEX_ERROR % name_or_path ) ","if not isinstance ( val , FeatStruct ) : 
","if fid not in val :
",26.83,6.96,False
"def scan ( scope ) : <TAB> for s in scope . children : <TAB> <TAB> if s . start_pos < = position < = s . end_pos : <TAB> <TAB> <TAB> if isinstance ( s , ( tree . Scope , tree . Flow ) ) : <TAB> <TAB> <TAB> <TAB> return scan ( s ) or s <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return scan ( s ) <TAB> return None ","elif s . type in ( "" suite "" , "" decorated "" ) : 
","elif isinstance ( s , tree . Scope ) :
",26.85,6.96,False
"def _get_key ( self ) : <TAB> if not self . key : <TAB> <TAB> self . _channel . send ( u "" pake "" , self . msg1 ) <TAB> <TAB> pake_msg = self . _channel . get ( u "" pake "" ) <TAB> <TAB> self . key = self . sp . finish ( pake_msg ) <TAB> <TAB> self . verifier = self . derive_key ( u "" wormhole:verifier "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> confkey = self . derive_key ( u "" wormhole:confirmation "" ) <TAB> <TAB> nonce = os . urandom ( CONFMSG_NONCE_LENGTH ) <TAB> <TAB> confmsg = make_confmsg ( confkey , nonce ) <TAB> <TAB> self . _channel . send ( u "" _confirm "" , confmsg ) ","if not self . _send_confirm : 
","if not self . verifier :
",77.23,32.59,False
"def executeScript ( self , script ) : <TAB> if len ( script ) > 0 : <TAB> <TAB> commands = [ ] <TAB> <TAB> for l in script : <TAB> <TAB> <TAB> extracted = self . extract_command ( l ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> commands . append ( extracted ) <TAB> <TAB> for command in commands : <TAB> <TAB> <TAB> cmd , argv = command <TAB> <TAB> <TAB> self . dispatch_command ( cmd , argv ) ","if extracted : 
","if extracted is not None :
",34.04,17.97,False
"def create_path ( n , fullname , meta ) : <TAB> if meta : <TAB> <TAB> meta . create_path ( fullname ) <TAB> else : <TAB> <TAB> # These fallbacks are important -- meta could be null if, for <TAB> <TAB> # example, save created a ""fake"" item, i.e. a new strip/graft <TAB> <TAB> # path element, etc.  You can find cases like that by <TAB> <TAB> # searching for ""Metadata()"". <TAB> <TAB> unlink ( fullname ) <TAB> <TAB> if stat . S_ISDIR ( n . mode ) : <TAB> <TAB> <TAB> mkdirp ( fullname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . symlink ( n . readlink ( ) , fullname ) ","elif stat . S_ISLNK ( n . mode ) : 
","elif stat . S_ISLINK ( n . mode ) :
",83.03,73.49,False
def get_cycle ( self ) : <TAB> if self . has_cycle ( ) : <TAB> <TAB> cross_node = self . path [ - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . path [ self . path . index ( cross_node ) : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . path <TAB> return [ ] ,"if self . path . count ( cross_node ) > 1 : 
","if cross_node in self . path :
",33.6,18.4,False
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif str_in [ pos ] == end_tag : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel ","if str_in [ pos ] == start_tag : 
","if str_in [ pos ] == start_tag :
",100.0,100.0,True
"def device ( self ) : <TAB> """"""Device on which the data array of this variable reside."""""" <TAB> # lazy initialization for performance <TAB> if self . _device is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _device = backend . CpuDevice ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _device = backend . get_device_from_array ( self . _data [ 0 ] ) <TAB> return self . _device ","if self . _data [ 0 ] is None : 
","if self . _data is None :
",49.69,47.52,False
"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB> <TAB> <TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB> <TAB> if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) : <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB> <TAB> raise ","if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT : 
","if e . get_dbus_name ( ) == DBUS_NOT_FOUND :
",87.71,69.97,False
"def run ( self ) : <TAB> """"""Continual loop evaluating when_statements"""""" <TAB> while len ( self . library ) > 0 : <TAB> <TAB> for name , expression in self . library . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del self . library [ name ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> expression . evaluate ( ) <TAB> <TAB> sleep ( 0.01 ) <TAB> return ","if expression . remove_me == True : 
","if expression . is_statement ( ) :
",39.96,18.04,False
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" < "" : <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" "" : <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval ","if char == "" > "" : 
","if char == "" > "" :
",100.0,100.0,True
"def _source_target_path ( source , source_path , source_location ) : <TAB> target_path_attr = source . target_path or source . resdef . target_path <TAB> if source . preserve_path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" target-path  ' %s '  specified with preserve-path - ignoring "" , <TAB> <TAB> <TAB> <TAB> target_path_attr , <TAB> <TAB> <TAB> ) <TAB> <TAB> return os . path . relpath ( os . path . dirname ( source_path ) , source_location ) <TAB> else : <TAB> <TAB> return target_path_attr or source . resdef . target_path or "" "" ","if target_path_attr : 
","if target_path_attr :
",78.12,100.0,True
"def _load_user_from_header ( self , header ) : <TAB> if self . _header_callback : <TAB> <TAB> user = self . _header_callback ( header ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> app = current_app . _get_current_object ( ) <TAB> <TAB> <TAB> user_loaded_from_header . send ( app , user = user ) <TAB> <TAB> <TAB> return user <TAB> return None ","if user is not None : 
","if user is not None :
",100.0,100.0,True
"def setup ( cls ) : <TAB> "" Check dependencies and warn about firewalling "" <TAB> pathCheck ( "" brctl "" , moduleName = "" bridge-utils "" ) <TAB> # Disable Linux bridge firewalling so that traffic can flow! <TAB> for table in "" arp "" , "" ip "" , "" ip6 "" : <TAB> <TAB> cmd = "" sysctl net.bridge.bridge-nf-call- %s tables "" % table <TAB> <TAB> out = quietRun ( cmd ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warn ( "" Warning: Linux bridge may not work with "" , out , "" \n "" ) ","if out . endswith ( "" 1 "" ) : 
","if out :
",27.05,0.0,False
"def _browse_your_music ( web_client , variant ) : <TAB> if not web_client . logged_in : <TAB> <TAB> return [ ] <TAB> if variant in ( "" tracks "" , "" albums "" ) : <TAB> <TAB> items = flatten ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> page . get ( "" items "" , [ ] ) <TAB> <TAB> <TAB> <TAB> for page in web_client . get_all ( <TAB> <TAB> <TAB> <TAB> <TAB> f "" me/ { variant } "" , <TAB> <TAB> <TAB> <TAB> <TAB> params = { "" market "" : "" from_token "" , "" limit "" : 50 } , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if page <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return list ( translator . web_to_track_refs ( items ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return list ( translator . web_to_album_refs ( items ) ) <TAB> else : <TAB> <TAB> return [ ] ","if variant == "" tracks "" : 
","if variant == "" tracks "" :
",100.0,100.0,True
"def reset_styling ( self ) : <TAB> for edge in self . fsm_graph . edges_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" edge "" , { } ) . get ( "" default "" ) <TAB> <TAB> edge . attr . update ( style_attr ) <TAB> for node in self . fsm_graph . nodes_iter ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" node "" , { } ) . get ( "" inactive "" ) <TAB> <TAB> <TAB> node . attr . update ( style_attr ) <TAB> for sub_graph in self . fsm_graph . subgraphs_iter ( ) : <TAB> <TAB> style_attr = self . fsm_graph . style_attributes . get ( "" graph "" , { } ) . get ( "" default "" ) <TAB> <TAB> sub_graph . graph_attr . update ( style_attr ) ","if "" point "" not in node . attr [ "" shape "" ] : 
","if node . state == "" inactive "" :
",36.13,6.7,False
"def set_message_type_visibility ( self , message_type : MessageType ) : <TAB> try : <TAB> <TAB> rows = { <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> for i , msg in enumerate ( self . proto_analyzer . messages ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> } <TAB> <TAB> if message_type . show : <TAB> <TAB> <TAB> self . ui . tblViewProtocol . show_rows ( rows ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . ui . tblViewProtocol . hide_rows ( rows ) <TAB> except Exception as e : <TAB> <TAB> logger . exception ( e ) ","if msg . message_type == message_type 
","if msg . visibility == MessageType . visibility
",40.62,17.87,False
"def POP ( cpu , * regs ) : <TAB> for reg in regs : <TAB> <TAB> val = cpu . stack_pop ( cpu . address_bit_size / / 8 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cpu . _set_mode_by_val ( val ) <TAB> <TAB> <TAB> val = val & ~ 0x1 <TAB> <TAB> reg . write ( val ) ","if reg . reg in ( "" PC "" , "" R15 "" ) : 
","if cpu . _mode_by_val ( val ) == 0 :
",29.56,3.66,False
"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB> <TAB> if "" track "" in field : <TAB> <TAB> <TAB> self . processTrack ( field [ "" track "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] ) ","if "" movie_hdr "" in field : 
","if "" movie_hdr "" in field :
",100.0,100.0,True
"def check_update_function ( url , folder , update_setter , version_setter , auto ) : <TAB> remote_version = urllib . urlopen ( url ) . read ( ) <TAB> if remote_version . isdigit ( ) : <TAB> <TAB> local_version = get_local_timestamp ( folder ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if auto : <TAB> <TAB> <TAB> <TAB> update_setter . set_value ( True ) <TAB> <TAB> <TAB> version_setter . set_value ( remote_version ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> return False ","if remote_version > local_version : 
","if local_version < remote_version :
",53.85,37.53,False
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> if idx > = len ( selections ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB> <TAB> if len ( values ) + 1 < idx : <TAB> <TAB> <TAB> values . append ( value ) <TAB> self . stack = values ","if i > = 0 and i < len ( selections ) : 
","if i > = 0 :
",45.07,24.76,False
"def find_int_identifiers ( directory ) : <TAB> results = find_rules ( directory , has_int_identifier ) <TAB> print ( "" Number of rules with integer identifiers:  %d "" % len ( results ) ) <TAB> for result in results : <TAB> <TAB> rule_path = result [ 0 ] <TAB> <TAB> product_yaml_path = result [ 1 ] <TAB> <TAB> product_yaml = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> product_yaml = yaml . open_raw ( product_yaml_path ) <TAB> <TAB> fix_file ( rule_path , product_yaml , fix_int_identifier ) ","if product_yaml_path is not None : 
","if product_yaml_path is not None :
",100.0,100.0,True
"def condition ( self ) : <TAB> if self . __condition is None : <TAB> <TAB> if len ( self . flat_conditions ) == 1 : <TAB> <TAB> <TAB> # Avoid an extra indirection in the common case of only one condition. <TAB> <TAB> <TAB> self . __condition = self . flat_conditions [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Possible, if unlikely, due to filter predicate rewriting <TAB> <TAB> <TAB> self . __condition = lambda _ : True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __condition = lambda x : all ( cond ( x ) for cond in self . flat_conditions ) <TAB> return self . __condition ","elif len ( self . flat_conditions ) == 0 : 
","elif isinstance ( self . flat_conditions [ 0 ] , Condition ) :
",42.27,36.79,False
"def get_scene_exceptions_by_season ( self , season = - 1 ) : <TAB> scene_exceptions = [ ] <TAB> for scene_exception in self . scene_exceptions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> scene_name , scene_season = scene_exception . split ( "" | "" ) <TAB> <TAB> if season == scene_season : <TAB> <TAB> <TAB> scene_exceptions . append ( scene_name ) <TAB> return scene_exceptions ","if not len ( scene_exception ) == 2 : 
","if not scene_exception :
",28.14,14.63,False
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i > = 0 and i < len ( selections ) : <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB> <TAB> if len ( values ) + 1 < idx : <TAB> <TAB> <TAB> values . append ( value ) <TAB> self . stack = values ","if idx > = len ( selections ) : 
","if index == 0 :
",26.57,6.48,False
"def to_tool_path ( self , path_or_uri_like , * * kwds ) : <TAB> if "" :// "" not in path_or_uri_like : <TAB> <TAB> path = path_or_uri_like <TAB> else : <TAB> <TAB> uri_like = path_or_uri_like <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Invalid URI passed to get_tool_source "" ) <TAB> <TAB> scheme , rest = uri_like . split ( "" : "" , 2 ) <TAB> <TAB> if scheme not in self . resolver_classes : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Unknown tool scheme [ {} ] for URI [ {} ] "" . format ( scheme , uri_like ) <TAB> <TAB> <TAB> ) <TAB> <TAB> path = self . resolver_classes [ scheme ] ( ) . get_tool_source_path ( uri_like ) <TAB> return path ","if "" : "" not in path_or_uri_like : 
","if not uri_like :
",26.98,14.82,False
def mainWindow ( ) : <TAB> global MW <TAB> if not MW : <TAB> <TAB> for i in qApp . topLevelWidgets ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> MW = i <TAB> <TAB> <TAB> <TAB> return MW <TAB> <TAB> return None <TAB> else : <TAB> <TAB> return MW ,"if i . objectName ( ) == "" MainWindow "" : 
","if i . isWindowVisible ( ) :
",41.98,15.75,False
"def async_get_service ( hass , config , discovery_info = None ) : <TAB> # pylint: disable=unused-argument <TAB> """"""Get the demo notification service."""""" <TAB> for account , account_dict in hass . data [ DATA_ALEXAMEDIA ] [ "" accounts "" ] . items ( ) : <TAB> <TAB> for key , _ in account_dict [ "" devices "" ] [ "" media_player "" ] . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _LOGGER . debug ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s : Media player  %s  not loaded yet; delaying load "" , <TAB> <TAB> <TAB> <TAB> <TAB> hide_email ( account ) , <TAB> <TAB> <TAB> <TAB> <TAB> hide_serial ( key ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return False <TAB> return AlexaNotificationService ( hass ) ","if key not in account_dict [ "" entities "" ] [ "" media_player "" ] : 
","if not hass . data [ DATA_ALEXAMEDIA ] [ "" accounts "" ] [ key ] :
",36.9,13.99,False
"def _migrate_bool ( self , name : str , true_value : str , false_value : str ) - > None : <TAB> if name not in self . _settings : <TAB> <TAB> return <TAB> values = self . _settings [ name ] <TAB> if not isinstance ( values , dict ) : <TAB> <TAB> return <TAB> for scope , val in values . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_value = true_value if val else false_value <TAB> <TAB> <TAB> self . _settings [ name ] [ scope ] = new_value <TAB> <TAB> <TAB> self . changed . emit ( ) ","if isinstance ( val , bool ) : 
","if isinstance ( val , bool ) :
",100.0,100.0,True
"def send ( self , data , flags = 0 ) : <TAB> self . _checkClosed ( ) <TAB> if self . _sslobj : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" non-zero flags not allowed in calls to send() on  %s "" % self . __class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _sslobj . write ( data ) <TAB> else : <TAB> <TAB> return socket . send ( self , data , flags ) ","if flags != 0 : 
","if flags != 0 :
",100.0,100.0,True
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> if not dep_cnts : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> if init_service and init_service in dep_cnt [ "" _deps "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB> <TAB> <TAB> deps . update ( new_deps ) <TAB> return deps ","if dep_cnt : 
","if dep_cnt :
",78.12,100.0,True
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> if item . endswith ( "" / "" ) : <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result ","elif is_dict . match ( item ) : 
","elif item . startswith ( "" / "" ) :
",33.32,11.04,False
"def PrintColGroup ( col_names , schema ) : <TAB> """"""Print HTML colgroup element, used for JavaScript sorting."""""" <TAB> print ( ""   <colgroup> "" ) <TAB> for i , col in enumerate ( col_names ) : <TAB> <TAB> if col . endswith ( "" _HREF "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> # CSS class is used for sorting <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> css_class = "" number "" <TAB> <TAB> else : <TAB> <TAB> <TAB> css_class = "" case-insensitive "" <TAB> <TAB> # NOTE: id is a comment only; not used <TAB> <TAB> print ( '<TAB>  <col id="" {} ""  type= "" {} ""  /> ' . format ( col , css_class ) ) <TAB> print ( ""   </colgroup> "" ) ","if schema . IsNumeric ( col ) : 
","if i == 0 :
",26.86,6.92,False
"def check_region ( self , region ) : <TAB> for other in self . regions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( other . start < region . start < other . end ) or ( <TAB> <TAB> <TAB> other . start < region . end < other . end <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise Exception ( "" %r  overlaps with  %r "" % ( region , other ) ) ","if other is region : 
","if region . same ( other ) :
",27.76,7.81,False
"def _write_value ( self , rng , value , scalar ) : <TAB> if rng . api and value : <TAB> <TAB> # it is assumed by this stage that value is a list of lists <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value [ 0 ] [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> rng = rng . resize ( len ( value ) , len ( value [ 0 ] ) ) <TAB> <TAB> rng . raw_value = value ","if scalar : 
","if isinstance ( value [ 0 ] , list ) :
",29.16,4.46,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24 : <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [ ] <TAB> for i , face in enumerate ( dcel_mesh . faces ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face . outer or del_flag in face . flags : <TAB> <TAB> <TAB> continue <TAB> <TAB> if only_select and not face . select : <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB> return sv_faces ","if face . inners and face . outer : 
","if del_flag is not None :
",26.54,5.8,False
"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> x_value = str ( xValue ) <TAB> for anime in self . xmlMap . findall ( "" anime "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return int ( anime . get ( y , 0 ) ) <TAB> <TAB> except ValueError as e : <TAB> <TAB> <TAB> continue <TAB> return 0 ","if anime . get ( x , False ) == x_value : 
","if xValue == anime . get ( x , 0 ) :
",52.36,39.74,False
"def dir_copy ( src_dir , dest_dir , merge_if_exists = True ) : <TAB> try : <TAB> <TAB> if not os . path . exists ( dest_dir ) : <TAB> <TAB> <TAB> shutil . copytree ( src_dir , dest_dir ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> merge_dir ( src_dir , dest_dir ) <TAB> except OSError as e : <TAB> <TAB> # If source is not a directory, copy with shutil.copy <TAB> <TAB> if e . errno == errno . ENOTDIR : <TAB> <TAB> <TAB> shutil . copy ( src_dir , dest_dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . error ( "" Could not copy  %s  to  %s "" , src_dir , dest_dir ) ","elif merge_if_exists : 
","elif merge_if_exists :
",78.12,100.0,True
"def mapping ( self ) : <TAB> m = { } <TAB> if getGdriveCredentialsFile ( ) is not None : <TAB> <TAB> m [ "" gdrive "" ] = "" "" <TAB> unknown = 0 <TAB> for f in self . scan : <TAB> <TAB> bits = f . split ( "" # "" , 2 ) <TAB> <TAB> if len ( bits ) == 1 : <TAB> <TAB> <TAB> label = os . path . basename ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> label = bits [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> label = "" L "" + str ( unknown ) <TAB> <TAB> <TAB> unknown + = 1 <TAB> <TAB> m [ label ] = bits [ 0 ] <TAB> return m ","if not label or len ( label ) == 0 or label == "" "" : 
","if unknown < len ( bits ) :
",31.48,3.98,False
"def get_tag_values ( self , event ) : <TAB> http = event . interfaces . get ( "" sentry.interfaces.Http "" ) <TAB> if not http : <TAB> <TAB> return [ ] <TAB> if not http . headers : <TAB> <TAB> return [ ] <TAB> headers = http . headers <TAB> # XXX: transitional support for workers <TAB> if isinstance ( headers , dict ) : <TAB> <TAB> headers = headers . items ( ) <TAB> output = [ ] <TAB> for key , value in headers : <TAB> <TAB> if key != "" User-Agent "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> ua = Parse ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> result = self . get_tag_from_ua ( ua ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> output . append ( result ) <TAB> return output ","if not ua : 
","if not ua :
",100.0,100.0,True
"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB> <TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB> <TAB> for i , g in enumerate ( groups ) : <TAB> <TAB> <TAB> if g : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [ ] <TAB> <TAB> <TAB> <TAB> <TAB> for _ , vs in g : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1 . extend ( vs ) <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g1 <TAB> <TAB> yield k , tuple ( t ) ","if i in direct_upstreams : 
","if not direct_upstreams :
",31.72,45.48,False
"def process_question ( qtxt ) : <TAB> question = "" "" <TAB> skip = False <TAB> for letter in qtxt : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> skip = True <TAB> <TAB> if letter == "" > "" : <TAB> <TAB> <TAB> skip = False <TAB> <TAB> if skip : <TAB> <TAB> <TAB> continue <TAB> <TAB> if letter . isalnum ( ) or letter == "" "" : <TAB> <TAB> <TAB> if letter == "" "" : <TAB> <TAB> <TAB> <TAB> letter = "" _ "" <TAB> <TAB> <TAB> question + = letter . lower ( ) <TAB> return question ","if letter == "" < "" : 
","if letter == "" < "" :
",100.0,100.0,True
"def _module_repr_from_spec ( spec ) : <TAB> """"""Return the repr to use for the module."""""" <TAB> # We mostly replicate _module_repr() using the spec attributes. <TAB> name = "" ? "" if spec . name is None else spec . name <TAB> if spec . origin is None : <TAB> <TAB> if spec . loader is None : <TAB> <TAB> <TAB> return "" <module  {!r} > "" . format ( name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" <module  {!r}  ( {!r} )> "" . format ( name , spec . loader ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" <module  {!r}  from  {!r} > "" . format ( name , spec . origin ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" <module  {!r}  ( {} )> "" . format ( spec . name , spec . origin ) ","if spec . has_location : 
","if spec . name is None :
",45.06,26.27,False
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> if self . any_match : <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return not self . inverse<TAB> # True <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . inverse<TAB> # False <TAB> if self . any_match : <TAB> <TAB> return self . inverse<TAB> # False <TAB> else : <TAB> <TAB> return not self . inverse<TAB> # True ","if not result : 
","if result :
",34.18,0.0,False
"def frequent_thread_switches ( ) : <TAB> """"""Make concurrency bugs more likely to manifest."""""" <TAB> interval = None <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> interval = sys . getswitchinterval ( ) <TAB> <TAB> <TAB> sys . setswitchinterval ( 1e-6 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> interval = sys . getcheckinterval ( ) <TAB> <TAB> <TAB> sys . setcheckinterval ( 1 ) <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> if not sys . platform . startswith ( "" java "" ) : <TAB> <TAB> <TAB> if hasattr ( sys , "" setswitchinterval "" ) : <TAB> <TAB> <TAB> <TAB> sys . setswitchinterval ( interval ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . setcheckinterval ( interval ) ","if hasattr ( sys , "" getswitchinterval "" ) : 
","if hasattr ( sys , "" setswitchinterval "" ) :
",83.03,65.8,False
"def record_expected_exportable_production ( self , ticks ) : <TAB> """"""Record the amount of production that should be transferred to other islands."""""" <TAB> for ( quota_holder , resource_id ) , amount in self . _low_priority_requests . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _settlement_manager_id [ quota_holder ] = WorldObject . get_object_by_id ( <TAB> <TAB> <TAB> <TAB> int ( quota_holder [ 1 : ] . split ( "" , "" ) [ 0 ] ) <TAB> <TAB> <TAB> ) . settlement_manager . worldid <TAB> <TAB> self . trade_storage [ self . _settlement_manager_id [ quota_holder ] ] [ resource_id ] + = ( <TAB> <TAB> <TAB> ticks * amount <TAB> <TAB> ) ","if quota_holder not in self . _settlement_manager_id : 
","if quota_holder not in self . _settlement_manager_id :
",100.0,100.0,True
"def _method_events_callback ( self , values ) : <TAB> try : <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" echo foo2 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB> <TAB> <TAB> return "" echo foo3 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo3 "" ) : <TAB> <TAB> <TAB> return "" exit \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB> <TAB> return "" echo foo1 \n "" ","if previous_echoed . endswith ( "" foo1 "" ) : 
","if previous_echoed . endswith ( "" foo1 "" ) :
",100.0,100.0,True
"def describe_cluster_snapshots ( self , cluster_identifier = None , snapshot_identifier = None ) : <TAB> if cluster_identifier : <TAB> <TAB> cluster_snapshots = [ ] <TAB> <TAB> for snapshot in self . snapshots . values ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cluster_snapshots . append ( snapshot ) <TAB> <TAB> if cluster_snapshots : <TAB> <TAB> <TAB> return cluster_snapshots <TAB> if snapshot_identifier : <TAB> <TAB> if snapshot_identifier in self . snapshots : <TAB> <TAB> <TAB> return [ self . snapshots [ snapshot_identifier ] ] <TAB> <TAB> raise ClusterSnapshotNotFoundError ( snapshot_identifier ) <TAB> return self . snapshots . values ( ) ","if snapshot . cluster . cluster_identifier == cluster_identifier : 
","if snapshot . cluster_identifier == cluster_identifier :
",59.68,82.19,False
def get_snippet_edit_handler ( model ) : <TAB> if model not in SNIPPET_EDIT_HANDLERS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # use the edit handler specified on the page class <TAB> <TAB> <TAB> edit_handler = model . edit_handler <TAB> <TAB> else : <TAB> <TAB> <TAB> panels = extract_panel_definitions_from_model_class ( model ) <TAB> <TAB> <TAB> edit_handler = ObjectList ( panels ) <TAB> <TAB> SNIPPET_EDIT_HANDLERS [ model ] = edit_handler . bind_to ( model = model ) <TAB> return SNIPPET_EDIT_HANDLERS [ model ] ,"if hasattr ( model , "" edit_handler "" ) : 
","if hasattr ( model , "" edit_handler "" ) :
",100.0,100.0,True
"def start ( ) : <TAB> if os . environ . get ( "" RUN_MAIN "" ) != "" true "" : <TAB> <TAB> try : <TAB> <TAB> <TAB> exit_code = restart_with_reloader ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . kill ( os . getpid ( ) , - exit_code ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sys . exit ( exit_code ) <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> pass ","if exit_code < 0 : 
","if exit_code < 0 :
",100.0,100.0,True
"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB> <TAB> if len ( l ) < 5 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( l [ 2 ] ) <TAB> <TAB> <TAB> int ( l [ 3 ] ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> #<TAB> <TAB>    ret.append(improve(l[0]))<TAB> <TAB> ret . append ( l [ 0 ] ) <TAB> ret . sort ( ) <TAB> for item in objlist : <TAB> <TAB> ret . append ( item ) <TAB> return ret ","if l [ 0 ] == "" Filename "" : 
","if l [ 0 ] == "" # "" :
",85.49,74.19,False
"def ipfs_publish ( self , lib ) : <TAB> with tempfile . NamedTemporaryFile ( ) as tmp : <TAB> <TAB> self . ipfs_added_albums ( lib , tmp . name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cmd = "" ipfs add --nocopy -q  "" . split ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> cmd = "" ipfs add -q  "" . split ( ) <TAB> <TAB> <TAB> cmd . append ( tmp . name ) <TAB> <TAB> <TAB> output = util . command_output ( cmd ) <TAB> <TAB> except ( OSError , subprocess . CalledProcessError ) as err : <TAB> <TAB> <TAB> msg = "" Failed to publish library. Error:  {0} "" . format ( err ) <TAB> <TAB> <TAB> self . _log . error ( msg ) <TAB> <TAB> <TAB> return False <TAB> <TAB> self . _log . info ( "" hash of library:  {0} "" , output ) ","if self . config [ "" nocopy "" ] : 
","if self . _options . cut_if_copy :
",35.93,13.55,False
"def spends ( self ) : <TAB> # Return spends indexed by hashX <TAB> spends = defaultdict ( list ) <TAB> utxos = self . mempool_utxos ( ) <TAB> for tx_hash , tx in self . txs . items ( ) : <TAB> <TAB> for n , input in enumerate ( tx . inputs ) : <TAB> <TAB> <TAB> if input . is_generation ( ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> prevout = ( input . prev_hash , input . prev_idx ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> hashX , value = utxos . pop ( prevout ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> hashX , value = self . db_utxos [ prevout ] <TAB> <TAB> <TAB> spends [ hashX ] . append ( prevout ) <TAB> return spends ","if prevout in utxos : 
","if prevout in utxos :
",100.0,100.0,True
"def terminate ( self ) : <TAB> if self . returncode is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> os . kill ( self . pid , TERM_SIGNAL ) <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> if getattr ( exc , "" errno "" , None ) != errno . ESRCH : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise ","if self . wait ( timeout = 0.1 ) is None : 
","if exc . errno != errno . ESRCH :
",29.72,4.86,False
"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB> <TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self . _value in dynamicStrToScalar : <TAB> <TAB> return dynamicStrToScalar [ self . _value ] <TAB> else : <TAB> <TAB> thisDynamic = self . _value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> thisDynamic = thisDynamic [ 1 : ] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic [ - 1 ] == "" z "" : <TAB> <TAB> <TAB> thisDynamic = thisDynamic [ : - 1 ] <TAB> <TAB> if thisDynamic in dynamicStrToScalar : <TAB> <TAB> <TAB> return dynamicStrToScalar [ thisDynamic ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return dynamicStrToScalar [ None ] ","if "" s "" in thisDynamic : 
","if thisDynamic [ 0 ] == "" s "" :
",38.92,16.59,False
"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB> <TAB> if "" . "" in valname : <TAB> <TAB> <TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB> <TAB> <TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ valname ] = value <TAB> for name in config : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config ","if name in self . values : 
","if name in self . __dict__ :
",82.52,36.72,False
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> if not isinstance ( op_list , list ) : <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list ","if dictionary . path in paths : 
","if dictionary . path in paths :
",100.0,100.0,True
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> if k . lower ( ) == ikey : <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB> <TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key ) ","if isinstance ( key , ( int , long ) ) : 
","if isinstance ( key , str ) :
",43.51,36.06,False
"def _get_items ( self , name , target = 1 ) : <TAB> all_items = self . get_items ( name ) <TAB> items = [ o for o in all_items if not o . disabled ] <TAB> if len ( items ) < target : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ItemNotFoundError ( "" insufficient items with name  %r "" % name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise AttributeError ( "" insufficient non-disabled items with name  %s "" % name ) <TAB> on = [ ] <TAB> off = [ ] <TAB> for o in items : <TAB> <TAB> if o . selected : <TAB> <TAB> <TAB> on . append ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> off . append ( o ) <TAB> return on , off ","if len ( all_items ) < target : 
","if len ( items ) == target :
",59.17,23.34,False
"def get_genome_dir ( gid , galaxy_dir , data ) : <TAB> """"""Return standard location of genome directories."""""" <TAB> if galaxy_dir : <TAB> <TAB> refs = genome . get_refs ( gid , None , galaxy_dir , data ) <TAB> <TAB> seq_file = tz . get_in ( [ "" fasta "" , "" base "" ] , refs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return os . path . dirname ( os . path . dirname ( seq_file ) ) <TAB> else : <TAB> <TAB> gdirs = glob . glob ( os . path . join ( _get_data_dir ( ) , "" genomes "" , "" * "" , gid ) ) <TAB> <TAB> if len ( gdirs ) == 1 and os . path . exists ( gdirs [ 0 ] ) : <TAB> <TAB> <TAB> return gdirs [ 0 ] ","if seq_file and os . path . exists ( seq_file ) : 
","if seq_file :
",26.42,7.83,False
"def _PrintFuncs ( self , names ) : <TAB> # type: (List[str]) -> int <TAB> status = 0 <TAB> for name in names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( name ) <TAB> <TAB> <TAB> # TODO: Could print LST for -f, or render LST.  Bash does this.  'trap' <TAB> <TAB> <TAB> # could use that too. <TAB> <TAB> else : <TAB> <TAB> <TAB> status = 1 <TAB> return status ","if name in self . funcs : 
","if name . endswith ( "" -f "" ) :
",34.62,9.98,False
"def package_files ( self ) : <TAB> seen_package_directories = ( ) <TAB> directories = self . distribution . package_dir or { } <TAB> empty_directory_exists = "" "" in directories <TAB> packages = self . distribution . packages or [ ] <TAB> for package in packages : <TAB> <TAB> if package in directories : <TAB> <TAB> <TAB> package_directory = directories [ package ] <TAB> <TAB> elif empty_directory_exists : <TAB> <TAB> <TAB> package_directory = os . path . join ( directories [ "" "" ] , package ) <TAB> <TAB> else : <TAB> <TAB> <TAB> package_directory = package <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seen_package_directories + = ( package_directory + "" . "" , ) <TAB> <TAB> <TAB> yield package_directory ","if not package_directory . startswith ( seen_package_directories ) : 
","if package_directory not in seen_package_directories :
",26.9,35.76,False
"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB> <TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with open ( conf_file ) as conf_handle : <TAB> <TAB> <TAB> <TAB> value = fn ( conf_handle ) <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> return value <TAB> return None ","if conf_file : 
","if os . path . exists ( conf_file ) :
",29.43,14.32,False
"def on_text ( self , text ) : <TAB> if text != self . chosen_text : <TAB> <TAB> self . fail_test ( ' Expected  "" {} "" , received  "" {} "" ' . format ( self . chosen_text , text ) ) <TAB> else : <TAB> <TAB> self . checks_passed + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . pass_test ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _select_next_text ( ) ","if self . checks_passed > = self . number_of_checks : 
","if self . checks_passed > = self . number_of_checks :
",100.0,100.0,True
"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB> <TAB> if self . _is_ast_node ( name , item ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item ( ) <TAB> <TAB> <TAB> if isinstance ( x , ast . AST ) : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( type ( x . _fields ) , tuple ) ","if name == "" Index "" : 
","if item . __class__ . __name__ == "" Index "" :
",56.75,25.35,False
"def apply ( self , response ) : <TAB> updated_headers = self . update_headers ( response ) <TAB> if updated_headers : <TAB> <TAB> response . headers . update ( updated_headers ) <TAB> <TAB> warning_header_value = self . warning ( response ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response . headers . update ( { "" Warning "" : warning_header_value } ) <TAB> return response ","if warning_header_value is not None : 
","if warning_header_value :
",29.58,54.78,False
"def validate ( self ) : <TAB> self . assertEqual ( len ( self . inputs ) , len ( self . outputs ) ) <TAB> for batch_in , batch_out in zip ( self . inputs , self . outputs ) : <TAB> <TAB> self . assertEqual ( len ( batch_in ) , len ( batch_out ) ) <TAB> <TAB> if self . use_parallel_executor and not self . use_double_buffer : <TAB> <TAB> <TAB> self . validate_unordered_batch ( batch_in , batch_out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for in_data , out_data in zip ( batch_in , batch_out ) : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( in_data . shape , out_data . shape ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( ( in_data == out_data ) . all ( ) ) ","if not self . use_parallel_executor : 
","if self . use_parallel_executor :
",58.31,79.56,False
def finalize ( self ) : <TAB> if self . _started : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _queue . put ( None ) <TAB> <TAB> <TAB> self . _queue . join ( ) <TAB> <TAB> <TAB> self . _consumer . join ( ) <TAB> <TAB> self . _started = False <TAB> self . _finalized = True ,"if not self . _finalized : 
","if self . _queue :
",36.49,29.06,False
"def _get_ilo_version ( self ) : <TAB> try : <TAB> <TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if e . code == 405 : <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e . code == 501 : <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2 ","if hasattr ( e , "" code "" ) : 
","if e . code in ( 502 , 502 , 503 , 504 , 5039 ) :
",27.4,6.26,False
"def _check_data ( self , source , expected_bytes , expected_duration ) : <TAB> received_bytes = 0 <TAB> received_seconds = 0.0 <TAB> bytes_to_read = 1024 <TAB> while True : <TAB> <TAB> data = source . get_audio_data ( bytes_to_read ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> received_bytes + = data . length <TAB> <TAB> received_seconds + = data . duration <TAB> <TAB> self . assertEqual ( data . length , len ( data . data ) ) <TAB> self . assertAlmostEqual ( expected_duration , received_seconds , places = 1 ) <TAB> self . assertAlmostEqual ( expected_bytes , received_bytes , delta = 5 ) ","if data is None : 
","if not data :
",28.67,16.37,False
"def __randomize_interval_task ( self ) : <TAB> for job in self . aps_scheduler . get_jobs ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . aps_scheduler . modify_job ( <TAB> <TAB> <TAB> <TAB> job . id , <TAB> <TAB> <TAB> <TAB> next_run_time = datetime . now ( ) <TAB> <TAB> <TAB> <TAB> + timedelta ( <TAB> <TAB> <TAB> <TAB> <TAB> seconds = randrange ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job . trigger . interval . total_seconds ( ) * 0.75 , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> job . trigger . interval . total_seconds ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> ) ","if isinstance ( job . trigger , IntervalTrigger ) : 
","if job . trigger . interval :
",36.18,18.09,False
"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB> <TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB> <TAB> p , q = i . as_numer_denom ( ) <TAB> <TAB> tol = c / q * * 2 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return i <TAB> <TAB> if tol < machine_epsilon : <TAB> <TAB> <TAB> break <TAB> return x ","if abs ( i - x ) < = tol : 
","if np . abs ( p ) < tol :
",28.68,13.67,False
"def fix_newlines ( lines ) : <TAB> """"""Convert newlines to unix."""""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if line . endswith ( "" \r \n "" ) : <TAB> <TAB> <TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines [ i ] = line [ : - 1 ] + "" \n "" ","elif line . endswith ( "" \r "" ) : 
","elif line . endswith ( "" \r \n "" ) :
",65.75,67.03,False
"def payment_control_render ( self , request : HttpRequest , payment : OrderPayment ) : <TAB> template = get_template ( "" pretixplugins/paypal/control.html "" ) <TAB> sale_id = None <TAB> for trans in payment . info_data . get ( "" transactions "" , [ ] ) : <TAB> <TAB> for res in trans . get ( "" related_resources "" , [ ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sale_id = res [ "" sale "" ] [ "" id "" ] <TAB> ctx = { <TAB> <TAB> "" request "" : request , <TAB> <TAB> "" event "" : self . event , <TAB> <TAB> "" settings "" : self . settings , <TAB> <TAB> "" payment_info "" : payment . info_data , <TAB> <TAB> "" order "" : payment . order , <TAB> <TAB> "" sale_id "" : sale_id , <TAB> } <TAB> return template . render ( ctx ) ","if "" sale "" in res and "" id "" in res [ "" sale "" ] : 
","if "" sale "" in res :
",47.57,17.47,False
"def for_name ( self , name ) : <TAB> try : <TAB> <TAB> name_resources = self . _resources [ name ] <TAB> except KeyError : <TAB> <TAB> raise LookupError ( name ) <TAB> else : <TAB> <TAB> for res in name_resources : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> inst = res . inst ( ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> log . exception ( "" error initializing  %s "" , res ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> log . error ( "" error initializing  %s :  %s "" , res , e ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield inst ","if log . getEffectiveLevel ( ) < = logging . DEBUG : 
","if log . getEffectiveLevel ( ) < = logging . DEBUG :
",100.0,100.0,True
"def describe ( self , done = False ) : <TAB> description = ShellCommand . describe ( self , done ) <TAB> if done : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> description = [ "" compile "" ] <TAB> <TAB> description . append ( "" %d  projects "" % self . getStatistic ( "" projects "" , 0 ) ) <TAB> <TAB> description . append ( "" %d  files "" % self . getStatistic ( "" files "" , 0 ) ) <TAB> <TAB> warnings = self . getStatistic ( "" warnings "" , 0 ) <TAB> <TAB> if warnings > 0 : <TAB> <TAB> <TAB> description . append ( "" %d  warnings "" % warnings ) <TAB> <TAB> errors = self . getStatistic ( "" errors "" , 0 ) <TAB> <TAB> if errors > 0 : <TAB> <TAB> <TAB> description . append ( "" %d  errors "" % errors ) <TAB> return description ","if not description : 
","if description == "" compile "" :
",28.57,7.27,False
"def parse_list ( tl ) : <TAB> ls = [ ] <TAB> nm = [ ] <TAB> while True : <TAB> <TAB> term , nmt , tl = parse_term ( tl ) <TAB> <TAB> ls . append ( term ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nm . append ( nmt ) <TAB> <TAB> if tl [ 0 ] != "" , "" : <TAB> <TAB> <TAB> break <TAB> <TAB> tl = tl [ 1 : ] <TAB> return ls , nm , tl ","if nmt is not None : 
","if nmt :
",29.58,0.0,False
"def infer_dataset_impl ( path ) : <TAB> if IndexedRawTextDataset . exists ( path ) : <TAB> <TAB> return "" raw "" <TAB> elif IndexedDataset . exists ( path ) : <TAB> <TAB> with open ( index_file_path ( path ) , "" rb "" ) as f : <TAB> <TAB> <TAB> magic = f . read ( 8 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return "" cached "" <TAB> <TAB> <TAB> elif magic == MMapIndexedDataset . Index . _HDR_MAGIC [ : 8 ] : <TAB> <TAB> <TAB> <TAB> return "" mmap "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return None <TAB> elif FastaDataset . exists ( path ) : <TAB> <TAB> return "" fasta "" <TAB> else : <TAB> <TAB> return None ","if magic == IndexedDataset . _HDR_MAGIC : 
","if magic == IndexedDataset . _HDR_MAGIC :
",100.0,100.0,True
"def _get ( self ) : <TAB> fut = item = None <TAB> with self . _mutex : <TAB> <TAB> # Critical section never blocks. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fut = Future ( ) <TAB> <TAB> <TAB> fut . add_done_callback ( <TAB> <TAB> <TAB> <TAB> lambda f : self . _get_complete ( ) if not f . cancelled ( ) else None <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _getters . append ( fut ) <TAB> <TAB> else : <TAB> <TAB> <TAB> item = self . _get_item ( ) <TAB> <TAB> <TAB> self . _get_complete ( ) <TAB> return item , fut ","if not self . _queue or self . _getters : 
","if self . _is_async :
",35.87,14.83,False
"def validate ( self ) : <TAB> dates = [ ] <TAB> for d in self . get ( "" leave_block_list_dates "" ) : <TAB> <TAB> # date is not repeated <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . msgprint ( <TAB> <TAB> <TAB> <TAB> _ ( "" Date is repeated "" ) + "" : "" + d . block_date , raise_exception = 1 <TAB> <TAB> <TAB> ) <TAB> <TAB> dates . append ( d . block_date ) ","if d . block_date in dates : 
","if not d . date_repeated and d . block_date not in dates :
",48.0,29.49,False
"def on_choose_watch_dir_clicked ( self ) : <TAB> if self . window ( ) . watchfolder_enabled_checkbox . isChecked ( ) : <TAB> <TAB> previous_watch_dir = self . window ( ) . watchfolder_location_input . text ( ) or "" "" <TAB> <TAB> watch_dir = QFileDialog . getExistingDirectory ( <TAB> <TAB> <TAB> self . window ( ) , <TAB> <TAB> <TAB> "" Please select the watch folder "" , <TAB> <TAB> <TAB> previous_watch_dir , <TAB> <TAB> <TAB> QFileDialog . ShowDirsOnly , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> self . window ( ) . watchfolder_location_input . setText ( watch_dir ) ","if not watch_dir : 
","if not watch_dir :
",100.0,100.0,True
"def log_generator ( self , limit = 6000 , * * kwargs ) : <TAB> # Generator for show_log_panel <TAB> skip = 0 <TAB> while True : <TAB> <TAB> logs = self . log ( limit = limit , skip = skip , * * kwargs ) <TAB> <TAB> if not logs : <TAB> <TAB> <TAB> break <TAB> <TAB> for entry in logs : <TAB> <TAB> <TAB> yield entry <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> skip = skip + limit ","if len ( logs ) < limit : 
","if limit < = 0 :
",27.09,8.22,False
"def _setUpClass ( cls ) : <TAB> global solver <TAB> import pyomo . environ <TAB> from pyomo . solvers . tests . io . writer_test_cases import testCases <TAB> for test_case in testCases : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> solver [ ( test_case . name , test_case . io ) ] = True ","if ( ( test_case . name , test_case . io ) in solver ) and ( test_case . available ) : 
","if test_case . name in environ :
",34.64,6.79,False
"def _get_file_data ( self , normpath , normrev ) : <TAB> data = self . client . cat ( normpath , normrev ) <TAB> if has_expanded_svn_keywords ( data ) : <TAB> <TAB> # Find out if this file has any keyword expansion set. <TAB> <TAB> # If it does, collapse these keywords. This is because SVN <TAB> <TAB> # will return the file expanded to us, which would break patching. <TAB> <TAB> keywords = self . client . propget ( "" svn:keywords "" , normpath , normrev , recurse = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = collapse_svn_keywords ( data , force_bytes ( keywords [ normpath ] ) ) <TAB> return data ","if normpath in keywords : 
","if normpath in keywords :
",100.0,100.0,True
"def add_controller_list ( path ) : <TAB> if not os . path . exists ( os . path . join ( path , "" __init__.py "" ) ) : <TAB> <TAB> bb . fatal ( "" Controllers directory  %s  exists but is missing __init__.py "" % path ) <TAB> files = sorted ( <TAB> <TAB> [ f for f in os . listdir ( path ) if f . endswith ( "" .py "" ) and not f . startswith ( "" _ "" ) ] <TAB> ) <TAB> for f in files : <TAB> <TAB> module = "" oeqa.controllers. "" + f [ : - 3 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> controllerslist . append ( module ) <TAB> <TAB> else : <TAB> <TAB> <TAB> bb . warn ( <TAB> <TAB> <TAB> <TAB> "" Duplicate controller module found for  %s , only one added. Layers should create unique controller module names "" <TAB> <TAB> <TAB> <TAB> % module <TAB> <TAB> <TAB> ) ","if module not in controllerslist : 
","if module not in controllerslist :
",100.0,100.0,True
"def on_session2 ( event ) : <TAB> new_xmpp . get_roster ( ) <TAB> new_xmpp . send_presence ( ) <TAB> logging . info ( roster [ 0 ] ) <TAB> data = roster [ 0 ] [ "" roster "" ] [ "" items "" ] <TAB> logging . info ( data ) <TAB> for jid , item in data . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_xmpp . send_presence ( ptype = "" subscribe "" , pto = jid ) <TAB> <TAB> new_xmpp . update_roster ( jid , name = item [ "" name "" ] , groups = item [ "" groups "" ] ) <TAB> new_xmpp . disconnect ( ) ","if item [ "" subscription "" ] != "" none "" : 
","if item [ "" ptype "" ] == "" subscribe "" :
",64.9,28.92,False
"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> <TAB> elif isinstance ( sym , ast . ClassDef ) : <TAB> <TAB> <TAB> result = _parse_class_simplified ( sym ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB> <TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results ","if isinstance ( sym , ast . FunctionDef ) : 
","if isinstance ( sym , ast . FunctionDef ) :
",100.0,100.0,True
"def check_args ( args ) : <TAB> """"""Checks that the args are coherent."""""" <TAB> check_args_has_attributes ( args ) <TAB> if args . v : <TAB> <TAB> non_version_attrs = [ v for k , v in args . __dict__ . items ( ) if k != "" v "" ] <TAB> <TAB> print ( "" non_version_attrs "" , non_version_attrs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fail ( "" Cannot show the version number with another command. "" ) <TAB> <TAB> return <TAB> if args . i is None : <TAB> <TAB> fail ( "" Cannot draw ER diagram of no database. "" ) <TAB> if args . o is None : <TAB> <TAB> fail ( "" Cannot draw ER diagram with no output file. "" ) ","if len ( [ v for v in non_version_attrs if v is not None ] ) != 0 : 
","if non_version_attrs :
",25.35,5.9,False
"def handle ( self , * args , * * options ) : <TAB> if not settings . ST_BASE_DIR . endswith ( "" spirit "" ) : <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> "" settings.ST_BASE_DIR is not the spirit root folder, are you overriding it? "" <TAB> <TAB> ) <TAB> for root , dirs , files in os . walk ( settings . ST_BASE_DIR ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> with utils . pushd ( root ) : <TAB> <TAB> <TAB> call_command ( <TAB> <TAB> <TAB> <TAB> "" makemessages "" , stdout = self . stdout , stderr = self . stderr , * * options <TAB> <TAB> <TAB> ) <TAB> self . stdout . write ( "" ok "" ) ","if "" locale "" not in dirs : 
","if "" .gitignore "" in dirs :
",54.11,27.05,False
"def scan ( scope ) : <TAB> for s in scope . children : <TAB> <TAB> if s . start_pos < = position < = s . end_pos : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return scan ( s ) or s <TAB> <TAB> <TAB> elif s . type in ( "" suite "" , "" decorated "" ) : <TAB> <TAB> <TAB> <TAB> return scan ( s ) <TAB> return None ","if isinstance ( s , ( tree . Scope , tree . Flow ) ) : 
","if s . type == "" suite "" :
",33.02,3.26,False
def run_sync ( self ) : <TAB> count = 0 <TAB> while count < self . args . num_messages : <TAB> <TAB> batch = self . receiver . fetch_next ( max_batch_size = self . args . num_messages - count ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for msg in batch : <TAB> <TAB> <TAB> <TAB> msg . complete ( ) <TAB> <TAB> count + = len ( batch ) ,"if self . args . peeklock : 
","if len ( batch ) > 0 :
",26.98,6.57,False
"def __getitem__ ( self , item ) : <TAB> if self . _datas is not None : <TAB> <TAB> ret = [ ] <TAB> <TAB> for data in self . _datas : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret . append ( data [ self . _offset ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . append ( data . iloc [ self . _offset ] ) <TAB> <TAB> self . _offset + = 1 <TAB> <TAB> return ret <TAB> else : <TAB> <TAB> return self . _get_data ( item ) ","if isinstance ( data , np . ndarray ) : 
","if isinstance ( data , np . ndarray ) :
",100.0,100.0,True
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB> <TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB> <TAB> except error_perm as error : <TAB> <TAB> <TAB> code , _ = _parse_ftp_error ( error ) <TAB> <TAB> <TAB> if code == "" 550 "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryExpected ( path ) <TAB> <TAB> <TAB> <TAB> if not self . isempty ( path ) : <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryNotEmpty ( path ) <TAB> <TAB> <TAB> raise<TAB> # pragma: no cover ","if self . isfile ( path ) : 
","if self . isempty ( path ) :
",75.15,50.0,False
"def replaces_in_file ( file , replacement_list ) : <TAB> rs = [ ( re . compile ( regexp ) , repl ) for ( regexp , repl ) in replacement_list ] <TAB> file_tmp = file + "" . "" + str ( os . getpid ( ) ) + "" .tmp "" <TAB> with open ( file , "" r "" ) as f : <TAB> <TAB> with open ( file_tmp , "" w "" ) as f_tmp : <TAB> <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <TAB> for r , replace in rs : <TAB> <TAB> <TAB> <TAB> <TAB> match = r . search ( line ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = replace + "" \n "" <TAB> <TAB> <TAB> <TAB> f_tmp . write ( line ) <TAB> shutil . move ( file_tmp , file ) ","if match : 
","if match :
",78.12,0.0,False
"def _get_path_check_mem ( self , i , size ) : <TAB> if size > 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p = self . _get_path ( i , - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p = self . _get_path ( i , size ) <TAB> <TAB> <TAB> if p . startswith ( "" /dev/shm "" ) : <TAB> <TAB> <TAB> <TAB> env . meminfo . add ( size ) <TAB> else : <TAB> <TAB> p = self . _get_path ( i , size ) <TAB> return p ","if env . meminfo . rss + size > env . meminfo . mem_limit_soft : 
","if size == 0 :
",25.75,1.22,False
"def find_widget_by_id ( self , id , parent = None ) : <TAB> """"""Recursively searches for widget with specified ID"""""" <TAB> if parent == None : <TAB> <TAB> if id in self : <TAB> <TAB> <TAB> return self [ id ]<TAB> # Do things fast if possible <TAB> <TAB> parent = self [ "" editor "" ] <TAB> for c in parent . get_children ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if c . get_id ( ) == id : <TAB> <TAB> <TAB> <TAB> return c <TAB> <TAB> if isinstance ( c , Gtk . Container ) : <TAB> <TAB> <TAB> r = self . find_widget_by_id ( id , c ) <TAB> <TAB> <TAB> if not r is None : <TAB> <TAB> <TAB> <TAB> return r <TAB> return None ","if hasattr ( c , "" get_id "" ) : 
","if isinstance ( c , Gtk . Widget ) :
",32.03,16.83,False
"def _deserialize ( cls , io ) : <TAB> flags = VideoFlags ( ) <TAB> flags . byte = U8 . read ( io ) <TAB> if flags . bit . type == VIDEO_FRAME_TYPE_COMMAND_FRAME : <TAB> <TAB> data = VideoCommandFrame . deserialize ( io ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = AVCVideoData . deserialize ( io ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = io . read ( ) <TAB> return cls ( flags . bit . type , flags . bit . codec , data ) ","if flags . bit . codec == VIDEO_CODEC_ID_AVC : 
","if flags . bit . type == AVC_Video_TYPE_DATA :
",74.53,30.13,False
"def asciiLogData ( data , maxlen = 64 , replace = False ) : <TAB> ellipses = ""  ... "" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dd = data [ : maxlen ] + ellipses <TAB> <TAB> else : <TAB> <TAB> <TAB> dd = data <TAB> <TAB> return dd . decode ( "" utf8 "" , errors = "" replace "" if replace else "" strict "" ) <TAB> except : <TAB> <TAB> return "" 0x "" + binLogData ( data , maxlen ) ","if len ( data ) > maxlen - len ( ellipses ) : 
","if len ( data ) > maxlen :
",61.72,46.54,False
"def _check_units ( self , new_unit_system ) : <TAB> # If no unit system has been specified for me yet, adopt the incoming <TAB> # system <TAB> if self . unit_system is None : <TAB> <TAB> self . unit_system = new_unit_system <TAB> else : <TAB> <TAB> # Otherwise, make sure they match <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Unit system mismatch  %d  v.  %d "" % ( self . unit_system , new_unit_system ) <TAB> <TAB> <TAB> ) ","if self . unit_system != new_unit_system : 
","if self . unit_system != new_unit_system :
",100.0,100.0,True
"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB> <TAB> visitor = process_file ( filename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB> <TAB> <TAB> if fix : <TAB> <TAB> <TAB> <TAB> print ( "" Fixing:  %s "" % filename ) <TAB> <TAB> <TAB> <TAB> fix_file ( filename ) ","if visitor . needs_fix ( ) : 
","if visitor :
",28.89,0.0,False
"def assign_attributes_to_variants ( variant_attributes ) : <TAB> for value in variant_attributes : <TAB> <TAB> pk = value [ "" pk "" ] <TAB> <TAB> defaults = value [ "" fields "" ] <TAB> <TAB> defaults [ "" variant_id "" ] = defaults . pop ( "" variant "" ) <TAB> <TAB> defaults [ "" assignment_id "" ] = defaults . pop ( "" assignment "" ) <TAB> <TAB> assigned_values = defaults . pop ( "" values "" ) <TAB> <TAB> assoc , created = AssignedVariantAttribute . objects . update_or_create ( <TAB> <TAB> <TAB> pk = pk , defaults = defaults <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assoc . values . set ( AttributeValue . objects . filter ( pk__in = assigned_values ) ) ","if created : 
","if created :
",78.12,0.0,False
"def _info ( self , userlist ) : <TAB> for strng in userlist : <TAB> <TAB> group_matched = False <TAB> <TAB> for env in self . base . comps . environments_by_pattern ( strng ) : <TAB> <TAB> <TAB> self . output . display_groups_in_environment ( env ) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB> for group in self . base . comps . groups_by_pattern ( strng ) : <TAB> <TAB> <TAB> self . output . display_pkgs_in_groups ( group ) <TAB> <TAB> <TAB> group_matched = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . error ( _ ( "" Warning: Group  %s  does not exist. "" ) , strng ) <TAB> return 0 , [ ] ","if not group_matched : 
","if not group_matched :
",100.0,100.0,True
"def parse_implements_interfaces ( parser ) : <TAB> types = [ ] <TAB> if parser . token . value == "" implements "" : <TAB> <TAB> advance ( parser ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> types . append ( parse_named_type ( parser ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> return types ","if not peek ( parser , TokenKind . NAME ) : 
","if not ( parser . token . value == "" implements "" ) :
",32.42,9.46,False
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> if isinstance ( leaf , Integer ) : <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> if leaf == SymbolTrue : <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector ","elif leaf == SymbolFalse : 
","elif leaf == SymbolFalse :
",100.0,100.0,True
"def update_gstin ( context ) : <TAB> dirty = False <TAB> for key , value in iteritems ( frappe . form_dict ) : <TAB> <TAB> if key != "" party "" : <TAB> <TAB> <TAB> address_name = frappe . get_value ( "" Address "" , key ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> address = frappe . get_doc ( "" Address "" , address_name ) <TAB> <TAB> <TAB> <TAB> address . gstin = value . upper ( ) <TAB> <TAB> <TAB> <TAB> address . save ( ignore_permissions = True ) <TAB> <TAB> <TAB> <TAB> dirty = True <TAB> if dirty : <TAB> <TAB> frappe . db . commit ( ) <TAB> <TAB> context . updated = True ","if address_name : 
","if address_name :
",78.12,100.0,True
"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , _bytes ) : <TAB> <TAB> <TAB> return False <TAB> return True ","if isinstance ( v , dict ) and k != "" headers "" : 
","if isinstance ( v , dict ) :
",53.46,36.24,False
"def check_graph ( graph ) :<TAB> # pragma: no cover <TAB> for c in graph : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot have fuse "" ) <TAB> <TAB> for inp in c . inputs : <TAB> <TAB> <TAB> if isinstance ( inp . op , Fuse ) : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot have fuse "" ) ","if isinstance ( c . op , Fuse ) : 
","if isinstance ( c . op , Fuse ) :
",100.0,100.0,True
"def __getattr__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . __parent . contents [ key ] <TAB> except KeyError : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( value , _ModuleMarker ) : <TAB> <TAB> <TAB> <TAB> return value . mod_ns <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> assert isinstance ( value , _MultipleClassMarker ) <TAB> <TAB> <TAB> <TAB> return value . attempt_get ( self . __parent . path , key ) <TAB> raise AttributeError ( <TAB> <TAB> "" Module  %r  has no mapped classes  "" <TAB> <TAB> "" registered under the name  %r "" % ( self . __parent . name , key ) <TAB> ) ","if value is not None : 
","if value is not None :
",100.0,100.0,True
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> if port . port_no == in_port : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret ","if nw_id_ == nw_id : 
","if nw_id_ == nw_id :
",100.0,100.0,True
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> if not len ( line . strip ( ) ) : <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" option "" , [ head . split ( None ) , tail ] ) ) <TAB> return entries ","if not len ( head ) : 
","if head == "" # "" :
",27.2,7.27,False
"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB> <TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if getattr ( command , "" positional_arg "" , False ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> names . append ( key ) <TAB> return names ","if startswith is not None and not key . startswith ( startswith ) : 
","if startswith and key . startswith ( startswith ) :
",56.58,48.66,False
"def _convert_example ( example , use_bfloat16 ) : <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list ( example . keys ( ) ) : <TAB> <TAB> val = example [ key ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = tf . sparse . to_dense ( val ) <TAB> <TAB> if val . dtype == tf . int64 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . int32 ) <TAB> <TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB> <TAB> example [ key ] = val ","if tf . keras . backend . is_sparse ( val ) : 
","if isinstance ( val , tf . sparse . Sparse ) :
",35.55,10.99,False
"def _get_lang_zone ( self , lang ) : <TAB> if lang not in self . _lang_zone_from_lang : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _lang_zone_from_lang [ lang ] = MultiLangZone ( self . mgr , lang ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _lang_zone_from_lang [ lang ] = LangZone ( self . mgr , lang ) <TAB> return self . _lang_zone_from_lang [ lang ] ","if self . mgr . is_multilang ( lang ) : 
","if self . mgr . lang_zones :
",54.55,35.97,False
"def dispatch ( self , request , * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB> except Http404 as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> request . original_path_info = request . path_info <TAB> <TAB> <TAB> <TAB> request . path_info = settings . FEINCMS_CMS_404_PAGE <TAB> <TAB> <TAB> <TAB> response = super ( Handler , self ) . dispatch ( request , * args , * * kwargs ) <TAB> <TAB> <TAB> <TAB> response . status_code = 404 <TAB> <TAB> <TAB> <TAB> return response <TAB> <TAB> <TAB> except Http404 : <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if settings . FEINCMS_CMS_404_PAGE : 
","if settings . FEINCMS_CMS_404_PAGE is not None :
",60.15,69.31,False
"def _maybe_update_dropout ( self , step ) : <TAB> for i in range ( len ( self . dropout_steps ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . model . update_dropout ( self . dropout [ i ] ) <TAB> <TAB> <TAB> logger . info ( "" Updated dropout to  %f  from step  %d "" % ( self . dropout [ i ] , step ) ) ","if step > 1 and step == self . dropout_steps [ i ] + 1 : 
","if self . dropout_steps [ i ] + self . dropout_offset < = step :
",51.49,46.55,False
"def bulk_move ( * args , * * kwargs ) : <TAB> for arg in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PopupException ( _ ( "" Source path and destination path cannot be same "" ) ) <TAB> <TAB> request . fs . rename ( <TAB> <TAB> <TAB> urllib . unquote ( arg [ "" src_path "" ] ) , urllib . unquote ( arg [ "" dest_path "" ] ) <TAB> <TAB> ) ","if arg [ "" src_path "" ] == arg [ "" dest_path "" ] : 
","if arg [ "" src_path "" ] != arg [ "" dest_path "" ] :
",90.09,85.79,False
"def asisWrite ( self , root ) : <TAB> at , c = self , self . c <TAB> try : <TAB> <TAB> c . endEditing ( ) <TAB> <TAB> c . init_error_dialogs ( ) <TAB> <TAB> fileName = at . initWriteIvars ( root , root . atAsisFileNodeName ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> at . addToOrphanList ( root ) <TAB> <TAB> <TAB> return <TAB> <TAB> at . openOutputStream ( ) <TAB> <TAB> for p in root . self_and_subtree ( copy = False ) : <TAB> <TAB> <TAB> at . writeAsisNode ( p ) <TAB> <TAB> contents = at . closeOutputStream ( ) <TAB> <TAB> at . replaceFile ( contents , at . encoding , fileName , root ) <TAB> except Exception : <TAB> <TAB> at . writeException ( fileName , root ) ","if not at . precheck ( fileName , root ) : 
","if fileName == "" "" :
",26.25,4.88,False
"def next_event ( it ) : <TAB> """"""read an event from an eventstream"""""" <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> line = next ( it ) <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return json . loads ( line . split ( "" : "" , 1 ) [ 1 ] ) ","if line . startswith ( "" data: "" ) : 
","if line :
",27.05,0.0,False
"def process_formdata ( self , valuelist ) : <TAB> if valuelist : <TAB> <TAB> if valuelist [ 0 ] == "" __None "" : <TAB> <TAB> <TAB> self . data = None <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . data = None <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> obj = self . queryset . get ( pk = valuelist [ 0 ] ) <TAB> <TAB> <TAB> <TAB> self . data = obj <TAB> <TAB> <TAB> except DoesNotExist : <TAB> <TAB> <TAB> <TAB> self . data = None ","if self . queryset is None : 
","if valuelist [ 0 ] == "" __None "" :
",26.63,4.07,False
"def _setResultsName ( self , name , listAllMatches = False ) : <TAB> if __diag__ . warn_multiple_tokens_in_named_alternation : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" {} : setting results name  {!r}  on  {}  expression  "" <TAB> <TAB> <TAB> <TAB> "" will return a list of all parsed tokens in an And alternative,  "" <TAB> <TAB> <TAB> <TAB> "" in prior versions only the first token was returned "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" warn_multiple_tokens_in_named_alternation "" , <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> stacklevel = 3 , <TAB> <TAB> <TAB> ) <TAB> return super ( ) . _setResultsName ( name , listAllMatches ) ","if any ( isinstance ( e , And ) for e in self . exprs ) : 
","if name not in self . _getResultsName ( ) :
",31.96,11.06,False
"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB> <TAB> form = BookMarkForm ( request . POST ) <TAB> <TAB> if form . is_valid ( ) : <TAB> <TAB> <TAB> form_type = form . save ( ) <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url = reverse ( "" servers "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url = reverse ( "" metrics "" ) <TAB> <TAB> return redirect ( url ) <TAB> else : <TAB> <TAB> return redirect ( reverse ( "" servers "" ) ) ","if form_type == "" server "" : 
","if form_type == "" metrics "" :
",74.63,70.71,False
"def __init__ ( self , post_id , artist , page , tzInfo = None , dateFormat = None ) : <TAB> self . imageUrls = list ( ) <TAB> self . imageResizedUrls = list ( ) <TAB> self . imageId = int ( post_id ) <TAB> self . _tzInfo = tzInfo <TAB> self . dateFormat = dateFormat <TAB> if page is not None : <TAB> <TAB> post_json = demjson . decode ( page ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> artist_id = post_json [ "" data "" ] [ "" item "" ] [ "" user "" ] [ "" id "" ] <TAB> <TAB> <TAB> self . artist = SketchArtist ( artist_id , page , tzInfo , dateFormat ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . artist = artist <TAB> <TAB> self . parse_post ( post_json [ "" data "" ] [ "" item "" ] ) ","if artist is None : 
","if "" user "" in post_json [ "" data "" ] [ "" item "" ] :
",26.89,2.41,False
"def _create_batch_iterator ( <TAB> self , <TAB> mark_as_delete : Callable [ [ Any ] , None ] , <TAB> to_key : Callable [ [ Any ] , Any ] , <TAB> to_value : Callable [ [ Any ] , Any ] , <TAB> batch : Iterable [ EventT ] , ) - > Iterable [ Tuple [ Any , Any ] ] : <TAB> for event in batch : <TAB> <TAB> key = to_key ( event . key ) <TAB> <TAB> # to delete keys in the table we set the raw value to None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mark_as_delete ( key ) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield key , to_value ( event . value ) ","if event . message . value is None : 
","if mark_as_delete is not None :
",28.28,9.98,False
"def test_lc_numeric_nl_langinfo ( self ) : <TAB> # Test nl_langinfo against known values <TAB> tested = False <TAB> for loc in candidate_locales : <TAB> <TAB> try : <TAB> <TAB> <TAB> setlocale ( LC_NUMERIC , loc ) <TAB> <TAB> <TAB> setlocale ( LC_CTYPE , loc ) <TAB> <TAB> except Error : <TAB> <TAB> <TAB> continue <TAB> <TAB> for li , lc in ( ( RADIXCHAR , "" decimal_point "" ) , ( THOUSEP , "" thousands_sep "" ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tested = True <TAB> if not tested : <TAB> <TAB> self . skipTest ( "" no suitable locales "" ) ","if self . numeric_tester ( "" nl_langinfo "" , nl_langinfo ( li ) , lc , loc ) : 
","if self . nl_langinfo ( li , lc , loc ) :
",46.74,32.43,False
"def _level_up_logging ( self ) : <TAB> for handler in self . log . handlers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if handler . level != logging . DEBUG : <TAB> <TAB> <TAB> <TAB> handler . setLevel ( logging . DEBUG ) <TAB> <TAB> <TAB> <TAB> self . log . debug ( "" Leveled up log file verbosity "" ) ","if issubclass ( handler . __class__ , logging . FileHandler ) : 
","if hasattr ( handler , "" level "" ) :
",27.92,7.21,False
def _show_axes_changed ( self ) : <TAB> marker = self . marker <TAB> if ( self . _vtk_control is not None ) and ( marker is not None ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> marker . interactor = None <TAB> <TAB> <TAB> marker . enabled = False <TAB> <TAB> else : <TAB> <TAB> <TAB> marker . interactor = self . interactor <TAB> <TAB> <TAB> marker . enabled = True <TAB> <TAB> self . render ( ) ,"if not self . show_axes : 
","if self . interactor is None :
",35.8,13.54,False
"def handle_keypress ( self , rawKey , modifiers , key , * args ) : <TAB> if self . recordKeyboard and self . __delayPassed ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . insideKeys = True <TAB> <TAB> <TAB> self . targetParent . start_key_sequence ( ) <TAB> <TAB> modifierCount = len ( modifiers ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> modifierCount > 1 <TAB> <TAB> <TAB> or ( modifierCount == 1 and Key . SHIFT not in modifiers ) <TAB> <TAB> <TAB> or ( Key . SHIFT in modifiers and len ( rawKey ) > 1 ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . targetParent . append_hotkey ( rawKey , modifiers ) <TAB> <TAB> elif key not in MODIFIERS : <TAB> <TAB> <TAB> self . targetParent . append_key ( key ) ","if not self . insideKeys : 
","if key in MODIFIERS :
",27.6,10.4,False
"def transform ( self , data ) : <TAB> with timer ( "" transform  %s "" % self . name , logging . DEBUG ) : <TAB> <TAB> if self . operator in { "" lat "" , "" latitude "" } : <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_latitude ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_longitude ) <TAB> <TAB> elif self . operator in { "" acc "" , "" accuracy "" } : <TAB> <TAB> <TAB> return self . series ( data ) . apply ( GeoIP . get_accuracy ) <TAB> <TAB> raise NameError ( "" Unknown GeoIP operator [lat, lon, acc]:  %s "" % self . operator ) ","elif self . operator in { "" lon "" , "" longitude "" } : 
","elif self . operator in { "" lon "" , "" longitude "" } :
",100.0,100.0,True
"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB> <TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB> <TAB> <TAB> if self . environment_id : <TAB> <TAB> <TAB> <TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected ","if self . service_id : 
","if self . service_id :
",100.0,100.0,True
"def _run_response_middleware ( self , request , response , request_name = None ) : <TAB> named_middleware = self . named_response_middleware . get ( request_name , deque ( ) ) <TAB> applicable_middleware = self . response_middleware + named_middleware <TAB> if applicable_middleware : <TAB> <TAB> for middleware in applicable_middleware : <TAB> <TAB> <TAB> _response = middleware ( request , response ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _response = await _response <TAB> <TAB> <TAB> if _response : <TAB> <TAB> <TAB> <TAB> response = _response <TAB> <TAB> <TAB> <TAB> break <TAB> return response ","if isawaitable ( _response ) : 
","if asyncio . iscoroutine ( _response ) :
",54.08,46.71,False
"def populate_obj ( self , obj , name ) : <TAB> field = getattr ( obj , name , None ) <TAB> if field is not None : <TAB> <TAB> # If field should be deleted, clean it up <TAB> <TAB> if self . _should_delete : <TAB> <TAB> <TAB> field . delete ( ) <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not field . grid_id : <TAB> <TAB> <TAB> <TAB> func = field . put <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> func = field . replace <TAB> <TAB> <TAB> func ( <TAB> <TAB> <TAB> <TAB> self . data . stream , <TAB> <TAB> <TAB> <TAB> filename = self . data . filename , <TAB> <TAB> <TAB> <TAB> content_type = self . data . content_type , <TAB> <TAB> <TAB> ) ","if isinstance ( self . data , FileStorage ) and not is_empty ( self . data . stream ) : 
","if isinstance ( field , Gtk . Field ) :
",32.48,6.43,False
"def _import_hash ( self , operator ) : <TAB> # Import required modules into local namespace so that pipelines <TAB> # may be evaluated directly <TAB> for key in sorted ( operator . import_hash . keys ( ) ) : <TAB> <TAB> module_list = "" ,  "" . join ( sorted ( operator . import_hash [ key ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exec ( "" from  {}  import  {} "" . format ( key [ 4 : ] , module_list ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> exec ( "" from  {}  import  {} "" . format ( key , module_list ) ) <TAB> <TAB> for var in operator . import_hash [ key ] : <TAB> <TAB> <TAB> self . operators_context [ var ] = eval ( var ) ","if key . startswith ( "" tpot. "" ) : 
","if key . startswith ( "" __ "" ) :
",83.03,58.77,False
"def remove_files ( folder , file_extensions ) : <TAB> for f in os . listdir ( folder ) : <TAB> <TAB> f_path = os . path . join ( folder , f ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> extension = os . path . splitext ( f_path ) [ 1 ] <TAB> <TAB> <TAB> if extension in file_extensions : <TAB> <TAB> <TAB> <TAB> os . remove ( f_path ) ","if os . path . isfile ( f_path ) : 
","if os . path . isfile ( f_path ) :
",100.0,100.0,True
"def clearBuffer ( self ) : <TAB> if self . shouldLose == - 1 : <TAB> <TAB> return <TAB> if self . producer : <TAB> <TAB> self . producer . resumeProducing ( ) <TAB> if self . buffer : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . logFile . write ( "" loopback receiving  %s \n "" % repr ( self . buffer ) ) <TAB> <TAB> buffer = self . buffer <TAB> <TAB> self . buffer = b "" "" <TAB> <TAB> self . target . dataReceived ( buffer ) <TAB> if self . shouldLose == 1 : <TAB> <TAB> self . shouldLose = - 1 <TAB> <TAB> self . target . connectionLost ( failure . Failure ( main . CONNECTION_DONE ) ) ","if self . logFile : 
","if self . logFile :
",100.0,100.0,True
"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB> <TAB> if self . _write_line : <TAB> <TAB> <TAB> sys . stderr . write ( fn + "" :  "" ) <TAB> <TAB> if bytes : <TAB> <TAB> <TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sys . stderr . write ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _write_line = True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data ) ","if ( data [ - 1 ] ) == "" \n "" : 
","if not self . _write_line :
",25.95,2.91,False
def stop ( self ) : <TAB> self . queue_com . state_lock . acquire ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . queue_com . state = STOPPED <TAB> <TAB> <TAB> self . remove ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> finally : <TAB> <TAB> self . queue_com . state_lock . release ( ) ,"if self . queue_com . state == RUNNING and self . stop_task ( ) : 
","if self . queue_com . state == STOPPED :
",56.03,42.43,False
"def _handle_special_args ( self , pyobjects ) : <TAB> if len ( pyobjects ) == len ( self . arguments . args ) : <TAB> <TAB> if self . arguments . vararg : <TAB> <TAB> <TAB> pyobjects . append ( rope . base . builtins . get_list ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pyobjects . append ( rope . base . builtins . get_dict ( ) ) ","if self . arguments . kwarg : 
","elif self . arguments . vararg and self . arguments . vararg . startswith ( "" __ "" ) :
",50.38,12.02,False
"def go_to_last_edit_location ( self ) : <TAB> if self . last_edit_cursor_pos is not None : <TAB> <TAB> filename , position = self . last_edit_cursor_pos <TAB> <TAB> if not osp . isfile ( filename ) : <TAB> <TAB> <TAB> self . last_edit_cursor_pos = None <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> self . load ( filename ) <TAB> <TAB> <TAB> editor = self . get_current_editor ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> editor . set_cursor_position ( position ) ","if position < editor . document ( ) . characterCount ( ) : 
","if editor is not None :
",26.01,3.33,False
"def _create_sentence_objects ( self ) : <TAB> """"""Returns a list of Sentence objects from the raw text."""""" <TAB> sentence_objects = [ ] <TAB> sent_tokenizer = SentenceTokenizer ( locale = self . language . code ) <TAB> seq = Sequence ( self . raw ) <TAB> seq = sent_tokenizer . transform ( seq ) <TAB> for start_index , end_index in zip ( seq . idx [ : - 1 ] , seq . idx [ 1 : ] ) : <TAB> <TAB> # Sentences share the same models as their parent blob <TAB> <TAB> sent = seq . text [ start_index : end_index ] . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> s = Sentence ( sent , start_index = start_index , end_index = end_index ) <TAB> <TAB> s . detected_languages = self . detected_languages <TAB> <TAB> sentence_objects . append ( s ) <TAB> return sentence_objects ","if not sent : 
","if not sent :
",100.0,100.0,True
"def to_json_schema ( self , parent = None ) : <TAB> schema = { } <TAB> if not parent : <TAB> <TAB> schema [ "" title "" ] = self . title <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> schema [ "" description "" ] = self . description <TAB> <TAB> if self . has_default : <TAB> <TAB> <TAB> schema [ "" default "" ] = self . default <TAB> <TAB> schema [ "" _required_ "" ] = self . required <TAB> if self . null : <TAB> <TAB> schema [ "" type "" ] = [ "" string "" , "" null "" ] <TAB> else : <TAB> <TAB> schema [ "" type "" ] = "" string "" <TAB> if self . enum is not None : <TAB> <TAB> schema [ "" enum "" ] = self . enum <TAB> return schema ","if self . description : 
","if self . description is not None :
",60.15,36.56,False
def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB> <TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB> <TAB> return<TAB> # do not clear link - we can get out of dir <TAB> for f in os . listdir ( dirname ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os . sep + f <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> rmdir ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . unlink ( path ) <TAB> os . rmdir ( dirname ) ,"if f in ( "" . "" , "" .. "" ) : 
","if f == "" . "" :
",38.17,12.78,False
"def convert_whole_dir ( path = Path ( "" marian_ckpt/ "" ) ) : <TAB> for subdir in tqdm ( list ( path . ls ( ) ) ) : <TAB> <TAB> dest_dir = f "" marian_converted/ { subdir . name } "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> convert ( source_dir , dest_dir ) ","if ( dest_dir / "" pytorch_model.bin "" ) . exists ( ) : 
","if not os . path . exists ( dest_dir ) :
",30.82,20.17,False
"def colorformat ( text ) : <TAB> if text [ 0 : 1 ] == "" # "" : <TAB> <TAB> col = text [ 1 : ] <TAB> <TAB> if len ( col ) == 6 : <TAB> <TAB> <TAB> return col <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return col [ 0 ] * 2 + col [ 1 ] * 2 + col [ 2 ] * 2 <TAB> elif text == "" "" : <TAB> <TAB> return "" "" <TAB> assert False , "" wrong color format  %r "" % text ","elif len ( col ) == 3 : 
","elif len ( col ) == 3 :
",100.0,100.0,True
"def _init_rel_seek ( self ) : <TAB> "" Sets the file object ' s position to the relative location set above. "" <TAB> rs , fo = self . _rel_seek , self . _file_obj <TAB> if rs == 0.0 : <TAB> <TAB> fo . seek ( 0 , os . SEEK_SET ) <TAB> else : <TAB> <TAB> fo . seek ( 0 , os . SEEK_END ) <TAB> <TAB> size = fo . tell ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _cur_pos = size <TAB> <TAB> else : <TAB> <TAB> <TAB> target = int ( size * rs ) <TAB> <TAB> <TAB> fo . seek ( target , os . SEEK_SET ) <TAB> <TAB> <TAB> self . _align_to_newline ( ) <TAB> <TAB> <TAB> self . _cur_pos = fo . tell ( ) ","if rs == 1.0 : 
","if rs == 0 :
",39.48,53.73,False
"def parse_command_line ( self , argv = None ) : <TAB> """"""Parse the command line"""""" <TAB> if self . config : <TAB> <TAB> parser = argparse . ArgumentParser ( add_help = False ) <TAB> <TAB> self . settings [ "" config "" ] . add_argument ( parser ) <TAB> <TAB> opts , _ = parser . parse_known_args ( argv ) <TAB> <TAB> if opts . config is not None : <TAB> <TAB> <TAB> self . set ( "" config "" , opts . config ) <TAB> <TAB> self . params . update ( self . import_from_module ( ) ) <TAB> parser = self . parser ( ) <TAB> opts = parser . parse_args ( argv ) <TAB> for k , v in opts . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . set ( k . lower ( ) , v ) ","if v is None : 
","if k == "" __module__ "" :
",27.53,4.03,False
"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( <TAB> <TAB> "" shield "" , region_name = "" us-east-1 "" <TAB> ) <TAB> protections = get_type_protections ( client , self . manager . get_model ( ) ) <TAB> protected_resources = { p [ "" ResourceArn "" ] for p in protections } <TAB> state = self . data . get ( "" state "" , False ) <TAB> results = [ ] <TAB> for arn , r in zip ( self . manager . get_arns ( resources ) , resources ) : <TAB> <TAB> r [ "" c7n:ShieldProtected "" ] = shielded = arn in protected_resources <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results . append ( r ) <TAB> <TAB> elif not shielded and not state : <TAB> <TAB> <TAB> results . append ( r ) <TAB> return results ","if shielded and state : 
","if arn in self . data :
",27.64,7.81,False
"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self . skip_ws ( aList , i ) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> if i > = len ( aList ) or aList [ i ] == "" \n "" : <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList [ j : i ] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else : <TAB> <TAB> <TAB> i + = 1 ","if self . is_ws ( aList [ i ] ) : 
","if aList [ i ] == "" \n "" :
",42.57,21.59,False
"def predict ( request : Request ) : <TAB> form = await request . form ( ) <TAB> files , entry = convert_input ( form ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return JSONResponse ( ALL_FEATURES_PRESENT_ERROR , status_code = 400 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = model . predict ( data_dict = [ entry ] ) . to_dict ( "" records "" ) [ 0 ] <TAB> <TAB> <TAB> return JSONResponse ( resp ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> logger . error ( "" Error:  {} "" . format ( str ( e ) ) ) <TAB> <TAB> <TAB> return JSONResponse ( COULD_NOT_RUN_INFERENCE_ERROR , status_code = 500 ) <TAB> finally : <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> os . remove ( f . name ) ","if ( entry . keys ( ) & input_features ) != input_features : 
","if entry in ALL_FEATURES_PRESENT_ERROR :
",25.95,2.97,False
"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __conn . close ( ) <TAB> <TAB> <TAB> self . __conn = None <TAB> <TAB> for _ , l in self . _library_cache . items ( ) : <TAB> <TAB> <TAB> if hasattr ( l , "" _reset "" ) and callable ( l . _reset ) : <TAB> <TAB> <TAB> <TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB> <TAB> <TAB> <TAB> l . _reset ( )<TAB> # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth ","if self . __conn is not None : 
","if self . __conn :
",47.74,54.78,False
"def read ( self ) : <TAB> if op . isfile ( self . fileName ) : <TAB> <TAB> with textfile_open ( self . fileName , "" rt "" ) as fid : <TAB> <TAB> <TAB> items = json . load ( fid ) <TAB> <TAB> <TAB> # TODO: catch JSON exception... <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> items = dict ( ) <TAB> else : <TAB> <TAB> items = dict ( ) <TAB> self . _items . clear ( ) <TAB> self . _items . update ( items ) <TAB> self . _haveReadData = True ","if items is None : 
","if items :
",31.27,0.0,False
"def get_django_comment ( text : str , i : int ) - > str : <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end < = len ( text ) : <TAB> <TAB> if text [ end - 2 : end ] == "" #} "" : <TAB> <TAB> <TAB> return text [ i : end ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unclosed_end = end <TAB> <TAB> end + = 1 <TAB> raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] ) ","if not unclosed_end and text [ end ] == "" < "" : 
","if not unclosed_end and text [ end ] == "" # "" :
",89.75,83.71,False
"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self . _eval_late_binding ( value ) <TAB> <TAB> <TAB> schema = self . late_bind_schemas . get ( key ) <TAB> <TAB> <TAB> if schema is not None : <TAB> <TAB> <TAB> <TAB> value_ = schema . validate ( value_ ) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self . _late_binding_returnvalues [ key ] = value_ <TAB> <TAB> return value_ <TAB> else : <TAB> <TAB> return value ","if value_ is KeyError : 
","if value_ is not None :
",37.83,43.47,False
"def connect ( * args , * * ckwargs ) : <TAB> if "" give_content_type "" in kwargs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs [ "" give_content_type "" ] ( args [ 6 ] [ "" content-type "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> kwargs [ "" give_content_type "" ] ( "" "" ) <TAB> if "" give_connect "" in kwargs : <TAB> <TAB> kwargs [ "" give_connect "" ] ( * args , * * ckwargs ) <TAB> status = code_iter . next ( ) <TAB> etag = etag_iter . next ( ) <TAB> timestamp = timestamps_iter . next ( ) <TAB> if status == - 1 : <TAB> <TAB> raise HTTPException ( ) <TAB> return FakeConn ( status , etag , body = kwargs . get ( "" body "" , "" "" ) , timestamp = timestamp ) ","if len ( args ) > = 7 and "" content_type "" in args [ 6 ] : 
","if args [ 6 ] . get ( "" content-type "" ) :
",38.18,14.19,False
"def _reset ( self ) : <TAB> self . _handle_connect ( ) <TAB> if self . rewarder_session : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> env_id = random . choice ( self . _sample_env_ids ) <TAB> <TAB> <TAB> logger . info ( "" Randomly sampled env_id= {} "" . format ( env_id ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> env_id = None <TAB> <TAB> self . rewarder_session . reset ( env_id = env_id ) <TAB> else : <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" No rewarder session exists, so cannot send a reset via the rewarder channel "" <TAB> <TAB> ) <TAB> self . _reset_mask ( ) <TAB> return [ None ] * self . n ","if self . _sample_env_ids : 
","if self . _sample_env_ids :
",100.0,100.0,True
"def _create_architecture_list ( architectures , current_arch ) : <TAB> if not architectures : <TAB> <TAB> return [ _Architecture ( build_on = [ current_arch ] ) ] <TAB> build_architectures : List [ str ] = [ ] <TAB> architecture_list : List [ _Architecture ] = [ ] <TAB> for item in architectures : <TAB> <TAB> if isinstance ( item , str ) : <TAB> <TAB> <TAB> build_architectures . append ( item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> architecture_list . append ( <TAB> <TAB> <TAB> <TAB> _Architecture ( build_on = item . get ( "" build-on "" ) , run_on = item . get ( "" run-on "" ) ) <TAB> <TAB> <TAB> ) <TAB> if build_architectures : <TAB> <TAB> architecture_list . append ( _Architecture ( build_on = build_architectures ) ) <TAB> return architecture_list ","if isinstance ( item , dict ) : 
","elif isinstance ( item , dict ) :
",77.52,84.09,False
"def inspect ( self , pokemon ) : <TAB> # Make sure it was not caught! <TAB> for caught_pokemon in self . cache : <TAB> <TAB> same_latitude = "" {0:.4f} "" . format ( pokemon [ "" latitude "" ] ) == "" {0:.4f} "" . format ( <TAB> <TAB> <TAB> caught_pokemon [ "" latitude "" ] <TAB> <TAB> ) <TAB> <TAB> same_longitude = "" {0:.4f} "" . format ( pokemon [ "" longitude "" ] ) == "" {0:.4f} "" . format ( <TAB> <TAB> <TAB> caught_pokemon [ "" longitude "" ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> if len ( self . cache ) > = 200 : <TAB> <TAB> self . cache . pop ( 0 ) <TAB> self . cache . append ( pokemon ) ","if same_latitude and same_longitude : 
","if same_latitude and same_longitude :
",100.0,100.0,True
"def parley ( self ) : <TAB> for x in [ 0 , 1 ] : <TAB> <TAB> a = self . agents [ x ] . act ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" [DONE] "" in a [ "" text "" ] : <TAB> <TAB> <TAB> <TAB> self . agents [ x - 1 ] . observe ( <TAB> <TAB> <TAB> <TAB> <TAB> { "" id "" : "" World "" , "" text "" : "" The other agent has ended the chat. "" } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self . episodeDone = True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . agents [ x - 1 ] . observe ( a ) ","if a is not None : 
","if a [ "" id "" ] == "" World "" :
",28.13,6.84,False
"def _prepare_subset ( <TAB> full_data : torch . Tensor , <TAB> full_targets : torch . Tensor , <TAB> num_samples : int , <TAB> digits : Sequence , ) : <TAB> classes = { d : 0 for d in digits } <TAB> indexes = [ ] <TAB> for idx , target in enumerate ( full_targets ) : <TAB> <TAB> label = target . item ( ) <TAB> <TAB> if classes . get ( label , float ( "" inf "" ) ) > = num_samples : <TAB> <TAB> <TAB> continue <TAB> <TAB> indexes . append ( idx ) <TAB> <TAB> classes [ label ] + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> data = full_data [ indexes ] <TAB> targets = full_targets [ indexes ] <TAB> return data , targets ","if all ( classes [ k ] > = num_samples for k in classes ) : 
","if classes [ label ] > = num_samples :
",43.46,29.06,False
"def get_work_root ( self , flags ) : <TAB> _flags = flags . copy ( ) <TAB> _flags [ "" is_toplevel "" ] = True <TAB> target = self . _get_target ( _flags ) <TAB> if target : <TAB> <TAB> _flags [ "" target "" ] = target . name <TAB> <TAB> tool = self . get_tool ( _flags ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return target . name + "" - "" + tool <TAB> <TAB> else : <TAB> <TAB> <TAB> raise SyntaxError ( <TAB> <TAB> <TAB> <TAB> "" Failed to determine work root. Could not resolve tool for target  "" <TAB> <TAB> <TAB> <TAB> + target . name <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise SyntaxError ( "" Failed to determine work root. Could not resolve target "" ) ","if tool : 
","if tool :
",78.12,0.0,False
"def run_command ( self , data ) : <TAB> """"""Run editor commands."""""" <TAB> parts = data . split ( "" "" ) <TAB> cmd = parts [ 0 ] . lower ( ) <TAB> if cmd in self . operations . keys ( ) : <TAB> <TAB> return self . run_operation ( cmd ) <TAB> args = "" "" . join ( parts [ 1 : ] ) <TAB> self . logger . debug ( "" Looking for command  ' {0} ' "" . format ( cmd ) ) <TAB> if cmd in self . modules . modules . keys ( ) : <TAB> <TAB> self . logger . debug ( "" Trying to run command  ' {0} ' "" . format ( cmd ) ) <TAB> <TAB> self . get_editor ( ) . store_action_state ( cmd ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> else : <TAB> <TAB> self . set_status ( "" Command  ' {0} '  not found. "" . format ( cmd ) ) <TAB> <TAB> return False <TAB> return True ","if not self . run_module ( cmd , args ) : 
","if cmd not in self . get_editor ( ) . command_names ( args ) :
",35.02,11.27,False
"def get_main_chain_layers ( self ) : <TAB> """"""Return a list of layer IDs in the main chain."""""" <TAB> main_chain = self . get_main_chain ( ) <TAB> ret = [ ] <TAB> for u in main_chain : <TAB> <TAB> for v , layer_id in self . adj_list [ u ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret . append ( layer_id ) <TAB> return ret ","if v in main_chain and u in main_chain : 
","if v == self . main_chain_id :
",27.8,15.86,False
"def hash ( self , context ) : <TAB> with context : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return IECore . MurmurHash ( ) <TAB> <TAB> h = GafferDispatch . TaskNode . hash ( self , context ) <TAB> <TAB> h . append ( self [ "" fileName "" ] . hash ( ) ) <TAB> <TAB> h . append ( self [ "" in "" ] . hash ( ) ) <TAB> <TAB> h . append ( self . __parameterHandler . hash ( ) ) <TAB> <TAB> return h ","if not self [ "" fileName "" ] . getValue ( ) or self [ "" in "" ] . source ( ) == self [ "" in "" ] : 
","if self . __parameterHandler is None :
",25.26,0.52,False
"def consume_buf ( ) : <TAB> ty = state [ "" ty "" ] - 1 <TAB> for i in xrange ( state [ "" buf "" ] . shape [ 1 ] / / N ) : <TAB> <TAB> tx = x / / N + i <TAB> <TAB> src = state [ "" buf "" ] [ : , i * N : ( i + 1 ) * N , : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with self . tile_request ( tx , ty , readonly = False ) as dst : <TAB> <TAB> <TAB> <TAB> mypaintlib . tile_convert_rgba8_to_rgba16 ( src , dst , self . EOTF ) <TAB> if state [ "" progress "" ] : <TAB> <TAB> try : <TAB> <TAB> <TAB> state [ "" progress "" ] . completed ( ty - ty0 ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logger . exception ( "" Progress.completed() failed "" ) <TAB> <TAB> <TAB> state [ "" progress "" ] = None ","if src [ : , : , 3 ] . any ( ) : 
","if self . tile_request :
",25.84,3.18,False
"def check_permissions ( self , obj ) : <TAB> request = self . context . get ( "" request "" ) <TAB> for Perm in permissions : <TAB> <TAB> perm = Perm ( ) <TAB> <TAB> if not perm . has_permission ( request , self ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return True ","if not perm . has_object_permission ( request , self , obj ) : 
","if not perm . has_permission ( obj , self ) :
",43.25,41.57,False
"def _post_order ( op ) : <TAB> if isinstance ( op , tvm . tir . Allocate ) : <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> return op . body <TAB> if isinstance ( op , tvm . tir . AttrStmt ) : <TAB> <TAB> if op . attr_key == "" storage_scope "" : <TAB> <TAB> <TAB> lift_stmt [ - 1 ] . append ( op ) <TAB> <TAB> <TAB> return op . body <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> <TAB> return op <TAB> if isinstance ( op , tvm . tir . For ) : <TAB> <TAB> return _merge_block ( lift_stmt . pop ( ) + [ op ] , op . body ) <TAB> raise RuntimeError ( "" not reached "" ) ","if op . attr_key == "" virtual_thread "" : 
","if op . attr_key == "" storage_scope_elif op . attr_key == "" storage_scope_elif op . attr_key == "" storage_scope_elif "" :
",57.96,20.27,False
"def task_done ( self ) : <TAB> with self . _cond : <TAB> <TAB> if not self . _unfinished_tasks . acquire ( False ) : <TAB> <TAB> <TAB> raise ValueError ( "" task_done() called too many times "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _cond . notify_all ( ) ","if self . _unfinished_tasks . _semlock . _is_zero ( ) : 
","if self . _unfinished_tasks . _semlock . _is_zero ( ) :
",100.0,100.0,True
"def get_json ( self ) : <TAB> if not hasattr ( self , "" _json "" ) : <TAB> <TAB> self . _json = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _json = json . loads ( self . request . body ) <TAB> return self . _json ","if self . request . headers . get ( "" Content-Type "" , "" "" ) . startswith ( "" application/json "" ) : 
","if self . request . method == "" GET "" and self . request . body :
",43.41,15.33,False
"def userfullname ( ) : <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> <MASK> <TAB> <TAB> uid = os . getuid ( ) <TAB> <TAB> entry = pwd_from_uid ( uid ) <TAB> <TAB> if entry : <TAB> <TAB> <TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB> <TAB> if not _userfullname : <TAB> <TAB> <TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname ","if not _userfullname : 
","if not _userfullname :
",100.0,100.0,True
"def test_scatter ( self ) : <TAB> for rank in range ( self . world_size ) : <TAB> <TAB> tensor = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tensor = [ torch . tensor ( i ) for i in range ( self . world_size ) ] <TAB> <TAB> result = comm . get ( ) . scatter ( tensor , rank , size = ( ) ) <TAB> <TAB> self . assertTrue ( torch . is_tensor ( result ) ) <TAB> <TAB> self . assertEqual ( result . item ( ) , self . rank ) ","if self . rank == rank : 
","if rank == self . rank :
",43.26,39.28,False
"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB> <TAB> if pos in decompiler . targets : <TAB> <TAB> <TAB> decompiler . process_target ( pos ) <TAB> <TAB> method = getattr ( decompiler , opname , None ) <TAB> <TAB> if method is None : <TAB> <TAB> <TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB> <TAB> decompiler . pos = pos <TAB> <TAB> decompiler . next_pos = next_pos <TAB> <TAB> x = method ( * arg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> decompiler . stack . append ( x ) ","if x is not None : 
","if x is not None :
",100.0,100.0,True
"def print_scenario_ran ( self , scenario ) : <TAB> if scenario . passed : <TAB> <TAB> self . wrt ( "" OK "" ) <TAB> elif scenario . failed : <TAB> <TAB> reason = self . scenarios_and_its_fails [ scenario ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . wrt ( "" FAILED "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . wrt ( "" ERROR "" ) <TAB> self . wrt ( "" \n "" ) ","if isinstance ( reason . exception , AssertionError ) : 
","if reason . failed :
",32.69,9.35,False
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> if scan_argv ( self . argv , option ) is not None : <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> if option != other_option : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option ","if scan_argv ( self . argv , other_option ) is not None : 
","if other_option not in self . ssl_options ( ) :
",30.87,13.07,False
"def print_po_snippet ( en_loc_old_lists , context ) : <TAB> for m , localized , old in zip ( * en_loc_old_lists ) : <TAB> <TAB> if m == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> localized = old <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" #:  {file} : {line} \n "" <TAB> <TAB> <TAB> ' msgid  "" {context} {en_month} "" \n ' <TAB> <TAB> <TAB> ' msgstr  "" {localized_month} "" \n ' . format ( <TAB> <TAB> <TAB> <TAB> context = context , <TAB> <TAB> <TAB> <TAB> file = filename , <TAB> <TAB> <TAB> <TAB> line = print_po_snippet . line , <TAB> <TAB> <TAB> <TAB> en_month = m , <TAB> <TAB> <TAB> <TAB> localized_month = localized , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> print_po_snippet . line + = 1 ","if m == localized : 
","if m == "" "" and localized == "" "" :
",35.2,21.4,False
"def set_status ( self , dict_new ) : <TAB> for i , value in dict_new . items ( ) : <TAB> <TAB> self . dict_bili [ i ] = value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . dict_bili [ "" pcheaders "" ] [ "" cookie "" ] = value <TAB> <TAB> <TAB> self . dict_bili [ "" appheaders "" ] [ "" cookie "" ] = value ","if i == "" cookie "" : 
","if "" pcheaders "" in self . dict_bili [ "" appheaders "" ] :
",33.0,3.46,False
"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB> <TAB> child = pathobj . child ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pathdict [ key ] = child <TAB> <TAB> <TAB> child . setContent ( value ) <TAB> <TAB> elif isinstance ( value , dict ) : <TAB> <TAB> <TAB> child . createDirectory ( ) <TAB> <TAB> <TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict ","if isinstance ( value , bytes ) : 
","if isinstance ( value , str ) :
",79.9,59.46,False
"def _truncate_to_length ( generator , len_map = None ) : <TAB> for example in generator : <TAB> <TAB> example = list ( example ) <TAB> <TAB> if len_map is not None : <TAB> <TAB> <TAB> for key , max_len in len_map . items ( ) : <TAB> <TAB> <TAB> <TAB> example_len = example [ key ] . shape <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> example [ key ] = np . resize ( example [ key ] , max_len ) <TAB> <TAB> yield tuple ( example ) ","if example_len > max_len : 
","if example_len > = max_len :
",39.71,65.8,False
"def check ( self , * * kw ) : <TAB> if not kw : <TAB> <TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB> <TAB> if "" dir "" in kw : <TAB> <TAB> <TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw ) ","if "" file "" in kw : 
","if "" file "" in kw :
",100.0,100.0,True
"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if parser . is_quoted ( ) : <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) :<TAB> # empty line <TAB> <TAB> <TAB> if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False ","if line . startswith ( ( "" # "" , "" @ "" , "" "" , "" ) "" ) ) : 
","if line . strip ( ) . startswith ( "" function  "" ) :
",41.99,12.51,False
"def askCheckReadFile ( self , localFile , remoteFile ) : <TAB> if not kb . bruteMode : <TAB> <TAB> message = "" do you want confirmation that the remote file  ' %s ' "" % remoteFile <TAB> <TAB> message + = "" has been successfully downloaded from the back-end  "" <TAB> <TAB> message + = "" DBMS file system? [Y/n]  "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _checkFileLength ( localFile , remoteFile , True ) <TAB> return None ","if readInput ( message , default = "" Y "" , boolean = True ) : 
","if self . confirm ( message ) :
",26.83,6.08,False
"def process_tag ( hive_name , company , company_key , tag , default_arch ) : <TAB> with winreg . OpenKeyEx ( company_key , tag ) as tag_key : <TAB> <TAB> version = load_version_data ( hive_name , company , tag , tag_key ) <TAB> <TAB> if version is not None :<TAB> # if failed to get version bail <TAB> <TAB> <TAB> major , minor , _ = version <TAB> <TAB> <TAB> arch = load_arch_data ( hive_name , company , tag , tag_key , default_arch ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> exe_data = load_exe ( hive_name , company , company_key , tag ) <TAB> <TAB> <TAB> <TAB> if exe_data is not None : <TAB> <TAB> <TAB> <TAB> <TAB> exe , args = exe_data <TAB> <TAB> <TAB> <TAB> <TAB> return company , major , minor , arch , exe , args ","if arch is not None : 
","if arch is not None :
",100.0,100.0,True
"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB> <TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB> <TAB> c = s [ pos ] <TAB> <TAB> if c == "" { "" : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> <TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB> <TAB> return pos <TAB> return None ","elif c == "" } "" : 
","elif c == "" } "" :
",100.0,100.0,True
"def pred ( field , value , item ) : <TAB> for suffix , p in _BUILTIN_PREDS . iteritems ( ) : <TAB> <TAB> if field . endswith ( suffix ) : <TAB> <TAB> <TAB> f = field [ : field . index ( suffix ) ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return p ( getattr ( item , f ) , value ) <TAB> if not hasattr ( item , field ) or getattr ( item , field ) is None : <TAB> <TAB> return False <TAB> if isinstance ( value , type ( lambda x : x ) ) : <TAB> <TAB> return value ( getattr ( item , field ) ) <TAB> return getattr ( item , field ) == value ","if not hasattr ( item , f ) or getattr ( item , f ) is None : 
","if f not in item :
",25.63,1.64,False
"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for _ , m in self . multi_deconv_layers . named_modules ( ) : <TAB> <TAB> if isinstance ( m , nn . ConvTranspose2d ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> for m in self . multi_final_layers . modules ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> normal_init ( m , std = 0.001 , bias = 0 ) ","if isinstance ( m , nn . Conv2d ) : 
","if isinstance ( m , nn . Linear ) :
",85.49,70.71,False
"def test_byteswap ( self ) : <TAB> if self . typecode == "" u "" : <TAB> <TAB> example = "" \U00100100 "" <TAB> else : <TAB> <TAB> example = self . example <TAB> a = array . array ( self . typecode , example ) <TAB> self . assertRaises ( TypeError , a . byteswap , 42 ) <TAB> if a . itemsize in ( 1 , 2 , 4 , 8 ) : <TAB> <TAB> b = array . array ( self . typecode , example ) <TAB> <TAB> b . byteswap ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( a , b ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertNotEqual ( a , b ) <TAB> <TAB> b . byteswap ( ) <TAB> <TAB> self . assertEqual ( a , b ) ","if a . itemsize == 1 : 
","if a . itemsize == 1 :
",100.0,100.0,True
"def _remove_blocks_from_variables ( variables ) : <TAB> new_variables = [ ] <TAB> for name , variable in variables : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_variables . extend ( variable . locals ) <TAB> <TAB> <TAB> new_variables . append ( ( name , variable . result ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_variables . append ( ( name , variable ) ) <TAB> return new_variables ","if variable . is_block ( ) : 
","if isinstance ( variable , Block ) :
",29.12,12.26,False
def scope ( self ) : <TAB> <MASK> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . scope_ is None : <TAB> <TAB> <TAB> <TAB> self . scope_ = Scope ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . scope_ ,"if self . scope_ is None : 
","if self . scope_ is None :
",100.0,100.0,True
"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( )<TAB> # Discard attribute list from reader. <TAB> attrs = { } <TAB> d = AttributeList . match . groupdict ( ) <TAB> for k , v in d . items ( ) : <TAB> <TAB> if v is not None : <TAB> <TAB> <TAB> if k == "" attrlist "" : <TAB> <TAB> <TAB> <TAB> v = subs_attrs ( v ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes ( v , attrs ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> AttributeList . attrs [ k ] = v <TAB> AttributeList . subs ( attrs ) <TAB> AttributeList . attrs . update ( attrs ) ","if v : 
","elif isinstance ( v , dict ) :
",28.56,6.57,False
"def parse ( self , response ) : <TAB> try : <TAB> <TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB> <TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB> <TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB> <TAB> return <TAB> for item in content [ "" data "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB> <TAB> elif "" hoverURL "" in item : <TAB> <TAB> <TAB> img_url = item [ "" hoverURL "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict ( file_url = img_url ) ","if "" objURL "" in item : 
","if "" objURL "" in item :
",100.0,100.0,True
"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == "" MOV "" : <TAB> <TAB> if instr . mnemonic . startswith ( "" lsr "" ) : <TAB> <TAB> <TAB> return "" LSR "" <TAB> <TAB> elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB> <TAB> <TAB> return "" LSL "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" ASR "" <TAB> return OP_NAME_MAP . get ( name , name ) ","elif instr . mnemonic . startswith ( "" asr "" ) : 
","elif instr . mnemonic . startswith ( "" asr "" ) :
",100.0,100.0,True
"def _clean_regions ( items , region ) : <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB> <TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( target , six . string_types ) and os . path . isfile ( target ) : <TAB> <TAB> <TAB> <TAB> target = _load_regions ( target ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> target = [ target ] <TAB> <TAB> <TAB> return target ","if target : 
","if target :
",78.12,0.0,False
def reader_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB> <TAB> self . active_readers - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . active_writers + = 1 <TAB> <TAB> <TAB> self . waiting_writers - = 1 <TAB> <TAB> <TAB> self . can_write . release ( ) <TAB> finally : <TAB> <TAB> self . mutex . release ( ) ,"if self . active_readers == 0 and self . waiting_writers != 0 : 
","if self . active_readers == 0 and self . waiting_writers == 0 :
",89.71,84.92,False
"def _bpe_to_words ( sentence , delimiter = "" @@ "" ) : <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [ ] <TAB> word = "" "" <TAB> delimiter_len = len ( delimiter ) <TAB> for subwords in sentence : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> word + = subwords [ : - delimiter_len ] <TAB> <TAB> else : <TAB> <TAB> <TAB> word + = subwords <TAB> <TAB> <TAB> words . append ( word ) <TAB> <TAB> <TAB> word = "" "" <TAB> return words ","if len ( subwords ) > = delimiter_len and subwords [ - delimiter_len : ] == delimiter : 
","if len ( subwords ) > delimiter_len :
",42.54,21.41,False
"def _make_var_names ( exog ) : <TAB> if hasattr ( exog , "" name "" ) : <TAB> <TAB> var_names = exog . name <TAB> elif hasattr ( exog , "" columns "" ) : <TAB> <TAB> var_names = exog . columns <TAB> else : <TAB> <TAB> raise ValueError ( "" exog is not a Series or DataFrame or is unnamed. "" ) <TAB> try : <TAB> <TAB> var_names = "" "" . join ( var_names ) <TAB> except TypeError :<TAB> # cannot have names that are numbers, pandas default <TAB> <TAB> from statsmodels . base . data import _make_exog_names <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> var_names = "" x1 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> var_names = "" "" . join ( _make_exog_names ( exog ) ) <TAB> return var_names ","if exog . ndim == 1 : 
","if isinstance ( exog , ( Series , DataFrame ) ) :
",26.76,4.46,False
"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for extension in self . extensions : <TAB> <TAB> <TAB> <TAB> self [ extension ] = self . type <TAB> <TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB> <TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB> <TAB> pattern = attrs [ "" pattern "" ] <TAB> <TAB> if pattern . startswith ( "" *. "" ) : <TAB> <TAB> <TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) ) ","if self . type : 
","if self . type :
",100.0,100.0,True
"def nodes ( self , id = None , name = None ) : <TAB> for node_dict in self . node_ls ( id = id , name = name ) : <TAB> <TAB> node_id = node_dict [ "" ID "" ] <TAB> <TAB> node = DockerNode ( self , node_id , inspect = node_dict ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield node ","if self . _node_prefix and not node . name . startswith ( self . _node_prefix ) : 
","if node . name != "" docker "" :
",35.52,4.84,False
"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> if e . value is None : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self ","if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : 
","elif type ( e ) is Option and e . argcount == 0 :
",42.11,58.03,False
"def vi_search ( self , rng ) : <TAB> for i in rng : <TAB> <TAB> line_history = self . _history . history [ i ] <TAB> <TAB> pos = line_history . get_line_text ( ) . find ( self . _vi_search_text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _history . history_cursor = i <TAB> <TAB> <TAB> self . l_buffer . line_buffer = list ( line_history . line_buffer ) <TAB> <TAB> <TAB> self . l_buffer . point = pos <TAB> <TAB> <TAB> self . vi_undo_restart ( ) <TAB> <TAB> <TAB> return True <TAB> self . _bell ( ) <TAB> return False ","if pos > = 0 : 
","if pos > - 1 :
",36.11,32.47,False
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if type ( test . value ) in self . _const_types : <TAB> <TAB> <TAB> <TAB> if not test . value : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope ) ","if isinstance ( test , ast . Const ) : 
","if isinstance ( test , ast . If ) :
",85.49,70.71,False
"def collect ( self ) : <TAB> for nickname in self . squid_hosts . keys ( ) : <TAB> <TAB> squid_host = self . squid_hosts [ nickname ] <TAB> <TAB> fulldata = self . _getData ( squid_host [ "" host "" ] , squid_host [ "" port "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fulldata = fulldata . splitlines ( ) <TAB> <TAB> <TAB> for data in fulldata : <TAB> <TAB> <TAB> <TAB> matches = self . stat_pattern . match ( data ) <TAB> <TAB> <TAB> <TAB> if matches : <TAB> <TAB> <TAB> <TAB> <TAB> self . publish_counter ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" %s . %s "" % ( nickname , matches . group ( 1 ) ) , float ( matches . group ( 2 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> ) ","if fulldata is not None : 
","if len ( fulldata ) > 0 :
",27.11,7.27,False
"def convert ( x , base , exponents ) : <TAB> out = [ ] <TAB> for e in exponents : <TAB> <TAB> d = int ( x / ( base * * e ) ) <TAB> <TAB> x - = d * ( base * * e ) <TAB> <TAB> out . append ( digits [ d ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return out ","if x == 0 and e < 0 : 
","if x < 0 :
",42.44,18.39,False
"def print_doc ( manager , options ) : <TAB> plugin_name = options . doc <TAB> plugin = plugins . get ( plugin_name , None ) <TAB> if plugin : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> console ( "" Plugin  %s  does not have documentation "" % plugin_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> console ( "" "" ) <TAB> <TAB> <TAB> console ( trim ( plugin . instance . __doc__ ) ) <TAB> <TAB> <TAB> console ( "" "" ) <TAB> else : <TAB> <TAB> console ( "" Could not find plugin  %s "" % plugin_name ) ","if not plugin . instance . __doc__ : 
","if not plugin . instance . documentation :
",85.66,42.89,False
"def _set_attrs ( self , attrs ) : <TAB> for attr in self . ATTRS : <TAB> <TAB> if attr in attrs : <TAB> <TAB> <TAB> setattr ( self , attr , attrs [ attr ] ) <TAB> <TAB> <TAB> del attrs [ attr ] <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> setattr ( self , attr , NO_DEFAULT ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> setattr ( self , attr , None ) <TAB> if attrs : <TAB> <TAB> attrs = sorted ( attrs . keys ( ) ) <TAB> <TAB> raise OptionError ( "" invalid keyword arguments:  %s "" % "" ,  "" . join ( attrs ) , self ) ","if attr == "" default "" : 
","if attr == "" default "" :
",100.0,100.0,True
"def _get_set_scope ( <TAB> ir_set : irast . Set , scope_tree : irast . ScopeTreeNode ) - > irast . ScopeTreeNode : <TAB> if ir_set . path_scope_id : <TAB> <TAB> new_scope = scope_tree . root . find_by_unique_id ( ir_set . path_scope_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise errors . InternalServerError ( <TAB> <TAB> <TAB> <TAB> f "" dangling scope pointer to node with uid "" <TAB> <TAB> <TAB> <TAB> f "" : { ir_set . path_scope_id }  in  { ir_set !r} "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> new_scope = scope_tree <TAB> return new_scope ","if new_scope is None : 
","if new_scope is None :
",100.0,100.0,True
"def test_leave_one_out ( self ) : <TAB> correct = 0 <TAB> k = 3 <TAB> model = kNN . train ( xs , ys , k ) <TAB> predictions = [ 1 , 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 ] <TAB> for i in range ( len ( predictions ) ) : <TAB> <TAB> model = kNN . train ( xs [ : i ] + xs [ i + 1 : ] , ys [ : i ] + ys [ i + 1 : ] , k ) <TAB> <TAB> prediction = kNN . classify ( model , xs [ i ] ) <TAB> <TAB> self . assertEqual ( prediction , predictions [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> correct + = 1 <TAB> self . assertEqual ( correct , 13 ) ","if prediction == ys [ i ] : 
","if i % 2 == 0 :
",27.07,12.26,False
"def import_files ( self , files ) : <TAB> """"""Import a list of MORE (.csv) files."""""" <TAB> c = self . c <TAB> if files : <TAB> <TAB> changed = False <TAB> <TAB> self . tab_width = c . getTabWidth ( c . p ) <TAB> <TAB> for fileName in files : <TAB> <TAB> <TAB> g . setGlobalOpenDir ( fileName ) <TAB> <TAB> <TAB> p = self . import_file ( fileName ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> p . contract ( ) <TAB> <TAB> <TAB> <TAB> p . setDirty ( ) <TAB> <TAB> <TAB> <TAB> c . setChanged ( True ) <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> if changed : <TAB> <TAB> <TAB> c . redraw ( p ) ","if p : 
","if p :
",78.12,0.0,False
"def getPageTemplate ( payload , place ) : <TAB> retVal = ( kb . originalPage , kb . errorIsNone ) <TAB> if payload and place : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> page , _ , _ = Request . queryPage ( payload , place , content = True , raise404 = False ) <TAB> <TAB> <TAB> kb . pageTemplates [ ( payload , place ) ] = ( page , kb . lastParserStatus is None ) <TAB> <TAB> retVal = kb . pageTemplates [ ( payload , place ) ] <TAB> return retVal ","if ( payload , place ) not in kb . pageTemplates : 
","if ( payload , place ) not in kb . pageTemplates :
",100.0,100.0,True
"def _skip_trivial ( constraint_data ) : <TAB> if skip_trivial_constraints : <TAB> <TAB> if isinstance ( constraint_data , LinearCanonicalRepn ) : <TAB> <TAB> <TAB> if constraint_data . variables is None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if constraint_data . body . polynomial_degree ( ) == 0 : 
","if not _skip_trivial_constraints ( constraint_data ) :
",26.45,11.71,False
"def get_unique_attribute ( self , name : str ) : <TAB> feat = None <TAB> for f in self . features : <TAB> <TAB> if self . _return_feature ( f ) and hasattr ( f , name ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" The attribute was not unique. "" ) <TAB> <TAB> <TAB> feat = f <TAB> if feat is None : <TAB> <TAB> raise RuntimeError ( "" The attribute did not exist "" ) <TAB> return getattr ( feat , name ) ","if feat is not None : 
","if hasattr ( feat , name ) :
",27.11,7.27,False
"def hideEvent ( self , event ) : <TAB> """"""Reimplement Qt method"""""" <TAB> if not self . light : <TAB> <TAB> for plugin in self . widgetlist : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> plugin . visibility_changed ( True ) <TAB> QMainWindow . hideEvent ( self , event ) ","if plugin . isAncestorOf ( self . last_focused_widget ) : 
","if isinstance ( plugin , QGraphicsWidget ) and plugin . isVisible ( ) :
",36.34,8.89,False
"def move_stdout_to_stderr ( self ) : <TAB> to_remove = [ ] <TAB> to_add = [ ] <TAB> for consumer_level , consumer in self . consumers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> to_remove . append ( ( consumer_level , consumer ) ) <TAB> <TAB> <TAB> to_add . append ( ( consumer_level , sys . stderr ) ) <TAB> for item in to_remove : <TAB> <TAB> self . consumers . remove ( item ) <TAB> self . consumers . extend ( to_add ) ","if consumer == sys . stdout : 
","if consumer . is_stdout :
",35.72,17.03,False
"def create ( exported_python_target ) : <TAB> if exported_python_target not in created : <TAB> <TAB> self . context . log . info ( <TAB> <TAB> <TAB> "" Creating setup.py project for  {} "" . format ( exported_python_target ) <TAB> <TAB> ) <TAB> <TAB> subject = self . derived_by_original . get ( <TAB> <TAB> <TAB> exported_python_target , exported_python_target <TAB> <TAB> ) <TAB> <TAB> setup_dir , dependencies = self . create_setup_py ( subject , dist_dir ) <TAB> <TAB> created [ exported_python_target ] = setup_dir <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for dep in dependencies : <TAB> <TAB> <TAB> <TAB> if is_exported_python_target ( dep ) : <TAB> <TAB> <TAB> <TAB> <TAB> create ( dep ) ","if self . _recursive : 
","if dependencies :
",28.55,0.0,False
"def __add__ ( self , other ) : <TAB> other = ArithmeticExpression . try_unpack_const ( other ) <TAB> if not self . symbolic and type ( other ) is int : <TAB> <TAB> return SpOffset ( self . _bits , self . _to_signed ( self . offset + other ) ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return SpOffset ( self . _bits , self . offset + other ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return SpOffset ( <TAB> <TAB> <TAB> <TAB> self . _bits , <TAB> <TAB> <TAB> <TAB> ArithmeticExpression ( <TAB> <TAB> <TAB> <TAB> <TAB> ArithmeticExpression . Add , <TAB> <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . offset , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> other , <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> ) ","if self . symbolic : 
","if self . symbolic :
",100.0,100.0,True
"def check_connection ( conn ) : <TAB> tables = [ <TAB> <TAB> r [ 0 ] <TAB> <TAB> for r in conn . execute ( <TAB> <TAB> <TAB> "" select name from sqlite_master where type= ' table ' "" <TAB> <TAB> ) . fetchall ( ) <TAB> ] <TAB> for table in tables : <TAB> <TAB> try : <TAB> <TAB> <TAB> conn . execute ( <TAB> <TAB> <TAB> <TAB> f "" PRAGMA table_info( { escape_sqlite ( table ) } ); "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> except sqlite3 . OperationalError as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise SpatialiteConnectionProblem ( e ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ConnectionProblem ( e ) ","if e . args [ 0 ] == "" no such module: VirtualSpatialIndex "" : 
","if "" Spatialite "" in str ( e ) :
",30.18,3.12,False
"def _get_github_client ( self ) - > "" Github "" : <TAB> from github import Github <TAB> if self . access_token_secret is not None : <TAB> <TAB> # If access token secret specified, load it <TAB> <TAB> access_token = Secret ( self . access_token_secret ) . get ( ) <TAB> else : <TAB> <TAB> # Otherwise, fallback to loading from local secret or environment variable <TAB> <TAB> access_token = prefect . context . get ( "" secrets "" , { } ) . get ( "" GITHUB_ACCESS_TOKEN "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> access_token = os . getenv ( "" GITHUB_ACCESS_TOKEN "" ) <TAB> return Github ( access_token ) ","if access_token is None : 
","if access_token is None :
",100.0,100.0,True
"def make_tab ( lists ) : <TAB> if hasattr ( lists , "" tolist "" ) : <TAB> <TAB> lists = lists . tolist ( ) <TAB> ut = [ ] <TAB> for rad in lists : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ut . append ( "" \t "" . join ( [ "" %s "" % x for x in rad ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ut . append ( "" %s "" % rad ) <TAB> return "" \n "" . join ( ut ) ","if type ( rad ) in [ list , tuple ] : 
","if isinstance ( rad , ( list , tuple ) ) :
",30.75,17.83,False
"def _ensure_ffi_initialized ( cls ) : <TAB> with cls . _init_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . lib = build_conditional_library ( lib , CONDITIONAL_NAMES ) <TAB> <TAB> <TAB> cls . _lib_loaded = True <TAB> <TAB> <TAB> # initialize the SSL library <TAB> <TAB> <TAB> cls . lib . SSL_library_init ( ) <TAB> <TAB> <TAB> # adds all ciphers/digests for EVP <TAB> <TAB> <TAB> cls . lib . OpenSSL_add_all_algorithms ( ) <TAB> <TAB> <TAB> # loads error strings for libcrypto and libssl functions <TAB> <TAB> <TAB> cls . lib . SSL_load_error_strings ( ) <TAB> <TAB> <TAB> cls . _register_osrandom_engine ( ) ","if not cls . _lib_loaded : 
","if not cls . _lib_loaded :
",100.0,100.0,True
def writer_leaves ( self ) : <TAB> self . mutex . acquire ( ) <TAB> try : <TAB> <TAB> self . active_writers - = 1 <TAB> <TAB> if self . waiting_writers != 0 : <TAB> <TAB> <TAB> self . active_writers + = 1 <TAB> <TAB> <TAB> self . waiting_writers - = 1 <TAB> <TAB> <TAB> self . can_write . release ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> t = self . waiting_readers <TAB> <TAB> <TAB> self . waiting_readers = 0 <TAB> <TAB> <TAB> self . active_readers + = t <TAB> <TAB> <TAB> while t > 0 : <TAB> <TAB> <TAB> <TAB> self . can_read . release ( ) <TAB> <TAB> <TAB> <TAB> t - = 1 <TAB> finally : <TAB> <TAB> self . mutex . release ( ) ,"elif self . waiting_readers != 0 : 
","if self . waiting_readers != 0 :
",75.79,88.01,False
"def _spans ( self , operands ) : <TAB> spans = { } <TAB> k = 0 <TAB> j = 0 <TAB> for mode in ( self . FLOAT , self . MPMATH ) : <TAB> <TAB> for i , operand in enumerate ( operands [ k : ] ) : <TAB> <TAB> <TAB> if operand [ 0 ] > mode : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> j = i + k + 1 <TAB> <TAB> if k == 0 and j == 1 :<TAB> # only init state? then ignore. <TAB> <TAB> <TAB> j = 0 <TAB> <TAB> spans [ mode ] = slice ( k , j ) <TAB> <TAB> k = j <TAB> spans [ self . SYMBOLIC ] = slice ( k , len ( operands ) ) <TAB> return spans ","if k == 0 and j == 1 : 
","if k == 0 and j == 1 :
",100.0,100.0,True
"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> status = location . Status ( response . status_code , response . text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = location . Status ( response . status_code ) <TAB> else : <TAB> <TAB> status = location . Status ( 500 , message ) <TAB> if response is None or not response . ok : <TAB> <TAB> if completion_routine : <TAB> <TAB> <TAB> return completion_routine ( status ) <TAB> <TAB> raise IOError ( response . text ) <TAB> else : <TAB> <TAB> if completion_routine : <TAB> <TAB> <TAB> completion_routine ( status ) <TAB> return location . Status ( 200 , response . content ) ","if not response . ok : 
","if not response . ok :
",100.0,100.0,True
"def readinto ( self , buf ) : <TAB> if self . current_frame : <TAB> <TAB> n = self . current_frame . readinto ( buf ) <TAB> <TAB> if n == 0 and len ( buf ) != 0 : <TAB> <TAB> <TAB> self . current_frame = None <TAB> <TAB> <TAB> n = len ( buf ) <TAB> <TAB> <TAB> buf [ : ] = self . file_read ( n ) <TAB> <TAB> <TAB> return n <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise UnpicklingError ( "" pickle exhausted before end of frame "" ) <TAB> <TAB> return n <TAB> else : <TAB> <TAB> n = len ( buf ) <TAB> <TAB> buf [ : ] = self . file_read ( n ) <TAB> <TAB> return n ","if n < len ( buf ) : 
","elif n < 0 :
",28.19,12.98,False
"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB> <TAB> value = mydict [ name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id ( mydict ) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited . add ( myid ) <TAB> <TAB> mydict = mydict . Parent <TAB> <TAB> if mydict is None : <TAB> <TAB> <TAB> return ","if value is not None : 
","if isinstance ( value , type ) and getattr ( value , "" __class__ "" , None ) is None :
",28.27,3.79,False
"def _handle_Mul ( self , expr ) : <TAB> arg0 , arg1 = expr . args <TAB> expr_0 = self . _expr ( arg0 ) <TAB> if expr_0 is None : <TAB> <TAB> return None <TAB> expr_1 = self . _expr ( arg1 ) <TAB> if expr_1 is None : <TAB> <TAB> return None <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # self.tyenv is not used <TAB> <TAB> <TAB> mask = ( 1 << expr . result_size ( self . tyenv ) ) - 1 <TAB> <TAB> <TAB> return ( expr_0 * expr_1 ) & mask <TAB> <TAB> else : <TAB> <TAB> <TAB> return expr_0 * expr_1 <TAB> except TypeError as e : <TAB> <TAB> self . l . warning ( e ) <TAB> <TAB> return None ","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) : 
","if isinstance ( expr_0 , int ) and isinstance ( expr_1 , int ) :
",100.0,100.0,True
"def end_request ( self , request_id ) : <TAB> """"""Removes the information associated with given request_id."""""" <TAB> with self . _lock : <TAB> <TAB> del self . _request_wsgi_environ [ request_id ] <TAB> <TAB> del self . _request_id_to_server_configuration [ request_id ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _request_id_to_instance [ request_id ] ","if request_id in self . _request_id_to_instance : 
","if request_id in self . _request_id_to_instance :
",100.0,100.0,True
def generate ( ) : <TAB> <MASK> <TAB> <TAB> decoder = zlib . decompressobj ( 16 + zlib . MAX_WBITS ) <TAB> while True : <TAB> <TAB> chunk = self . raw . read ( chunk_size ) <TAB> <TAB> if not chunk : <TAB> <TAB> <TAB> break <TAB> <TAB> if self . _gzipped : <TAB> <TAB> <TAB> chunk = decoder . decompress ( chunk ) <TAB> <TAB> yield chunk ,"if self . _gzipped : 
","if self . _gzipped :
",100.0,100.0,True
"def handle ( self ) : <TAB> from poetry . utils . env import EnvManager <TAB> manager = EnvManager ( self . poetry ) <TAB> current_env = manager . get ( ) <TAB> for venv in manager . list ( ) : <TAB> <TAB> name = venv . path . name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = str ( venv . path ) <TAB> <TAB> if venv == current_env : <TAB> <TAB> <TAB> self . line ( "" <info> {}  (Activated)</info> "" . format ( name ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> self . line ( name ) ","if self . option ( "" full-path "" ) : 
","if name == "" venv "" :
",30.74,6.08,False
"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB> <TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB> <TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB> <TAB> for aggr in aggrs : <TAB> <TAB> <TAB> for c in cols : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators = [ ] <TAB> <TAB> <TAB> <TAB> if aggr and aggr not in c . aggregators : <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators + = [ aggr ] ","if not hasattr ( c , "" aggregators "" ) : 
","if not hasattr ( c , "" aggregators "" ) :
",100.0,100.0,True
"def on_pre_output_coercion ( <TAB> directive_args : Dict [ str , Any ] , <TAB> next_directive : Callable , <TAB> value : Any , <TAB> ctx : Optional [ Any ] , <TAB> info : "" ResolveInfo "" , ) : <TAB> value = await next_directive ( value , ctx , info ) <TAB> if value is None : <TAB> <TAB> return value <TAB> try : <TAB> <TAB> py_enum = _ENUM_MAP [ directive_args [ "" name "" ] ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ None if item is None else py_enum ( item ) . name for item in value ] <TAB> <TAB> return py_enum ( value ) . name <TAB> except Exception : <TAB> <TAB> pass <TAB> return value ","if isinstance ( value , list ) : 
","if isinstance ( value , list ) :
",100.0,100.0,True
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words : <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> <TAB> yield x ,"if re_han . match ( blk ) : 
","if blk in Force_Split_Words :
",26.92,6.03,False
"def refresh_archive_action ( self ) : <TAB> archive_name = self . selected_archive_name ( ) <TAB> if archive_name is not None : <TAB> <TAB> params = BorgInfoArchiveThread . prepare ( self . profile ( ) , archive_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> thread = BorgInfoArchiveThread ( params [ "" cmd "" ] , params , parent = self . app ) <TAB> <TAB> <TAB> thread . updated . connect ( self . _set_status ) <TAB> <TAB> <TAB> thread . result . connect ( self . refresh_archive_result ) <TAB> <TAB> <TAB> self . _toggle_all_buttons ( False ) <TAB> <TAB> <TAB> thread . start ( ) ","if params [ "" ok "" ] : 
","if params :
",28.07,0.0,False
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> if not name [ 0 ] . isupper ( ) : <TAB> <TAB> <TAB> <TAB> if not name . startswith ( "" wait_until "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods ","if is_resource_action ( member ) : 
","if inspect . isclass ( member ) :
",54.08,28.47,False
"def _get_compressor ( compress_type , compresslevel = None ) : <TAB> if compress_type == ZIP_DEFLATED : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return zlib . compressobj ( compresslevel , zlib . DEFLATED , - 15 ) <TAB> <TAB> return zlib . compressobj ( zlib . Z_DEFAULT_COMPRESSION , zlib . DEFLATED , - 15 ) <TAB> elif compress_type == ZIP_BZIP2 : <TAB> <TAB> if compresslevel is not None : <TAB> <TAB> <TAB> return bz2 . BZ2Compressor ( compresslevel ) <TAB> <TAB> return bz2 . BZ2Compressor ( ) <TAB> # compresslevel is ignored for ZIP_LZMA <TAB> elif compress_type == ZIP_LZMA : <TAB> <TAB> return LZMACompressor ( ) <TAB> else : <TAB> <TAB> return None ","if compresslevel is not None : 
","if compresslevel is not None :
",100.0,100.0,True
"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [ ] <TAB> properties = [ ] <TAB> num_points = None <TAB> while b "" end_header "" not in line and line != b "" "" : <TAB> <TAB> line = plyfile . readline ( ) <TAB> <TAB> if b "" element "" in line : <TAB> <TAB> <TAB> line = line . split ( ) <TAB> <TAB> <TAB> num_points = int ( line [ 2 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line = line . split ( ) <TAB> <TAB> <TAB> properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB> return num_points , properties ","elif b "" property "" in line : 
","elif b "" point "" in line :
",75.22,50.0,False
"def download_release_artifacts ( self , version ) : <TAB> try : <TAB> <TAB> os . mkdir ( self . artifacts_dir ) <TAB> except FileExistsError : <TAB> <TAB> pass <TAB> for job_name in self . build_ids : <TAB> <TAB> build_number = self . build_ids . get ( job_name ) <TAB> <TAB> build_status = self . _get_build_status ( job_name , build_number ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _download_job_artifact ( job_name , build_number , version ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Build for  {}  is not fininished "" . format ( job_name ) ) <TAB> <TAB> <TAB> print ( "" \t Run  ' build '  action to check status of  {} "" . format ( job_name ) ) ","if build_status == "" built "" : 
","if build_status :
",28.89,26.01,False
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> if attrvalue == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass ","if attrname . startswith ( "" __ "" ) : 
","if attrname . startswith ( "" _ "" ) :
",83.03,80.45,False
"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB> <TAB> name = heur [ "" name "" ] <TAB> <TAB> if name in excluded : <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur [ "" sql "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB> <TAB> <TAB> print ( sql ) <TAB> <TAB> <TAB> assert sql . find ( name ) != - 1 <TAB> <TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs ) ","if sql . lower ( ) . find ( name . lower ( ) ) == - 1 : 
","if sql is None :
",25.89,1.18,False
def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield child . nodeValue <TAB> <TAB> if child . nodeType == child . ELEMENT_NODE : <TAB> <TAB> <TAB> for item in gettext ( child ) : <TAB> <TAB> <TAB> <TAB> yield item ,"if child . nodeType == child . TEXT_NODE : 
","if child . nodeType == child . TEXT_NODE :
",100.0,100.0,True
"def update ( self ) : <TAB> """"""Update properties over dbus."""""" <TAB> self . _check_dbus ( ) <TAB> _LOGGER . info ( "" Updating service information "" ) <TAB> self . _services . clear ( ) <TAB> try : <TAB> <TAB> systemd_units = await self . sys_dbus . systemd . list_units ( ) <TAB> <TAB> for service_data in systemd_units [ 0 ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _services . add ( ServiceInfo . read_from ( service_data ) ) <TAB> except ( HassioError , IndexError ) : <TAB> <TAB> _LOGGER . warning ( "" Can ' t update host service information! "" ) ","if not service_data [ 0 ] . endswith ( "" .service "" ) or service_data [ 2 ] != "" loaded "" : 
","if service_data . startswith ( "" host "" ) :
",32.5,4.91,False
"def filtercomments ( source ) : <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB> <TAB> elif re . search ( r "" ^ \ s* \ / \ / "" , source ) : <TAB> <TAB> <TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment : <TAB> <TAB> <TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB> <TAB> <TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source ","if re . search ( r "" ^ \ s* \ / \ * "" , source ) : 
","if "" /* "" in source :
",28.77,3.37,False
"def _getSourceStamp_sync ( self , ssid ) : <TAB> if ssid in self . sourcestamps : <TAB> <TAB> ssdict = self . sourcestamps [ ssid ] . copy ( ) <TAB> <TAB> ssdict [ "" ssid "" ] = ssid <TAB> <TAB> patchid = ssdict [ "" patchid "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ssdict . update ( self . patches [ patchid ] ) <TAB> <TAB> <TAB> ssdict [ "" patchid "" ] = patchid <TAB> <TAB> else : <TAB> <TAB> <TAB> ssdict [ "" patch_body "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_level "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_subdir "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_author "" ] = None <TAB> <TAB> <TAB> ssdict [ "" patch_comment "" ] = None <TAB> <TAB> return ssdict <TAB> else : <TAB> <TAB> return None ","if patchid : 
","if patchid in self . patches :
",33.58,14.54,False
"def parseImpl ( self , instring , loc , doActions = True ) : <TAB> try : <TAB> <TAB> loc , tokens = self . expr . _parse ( instring , loc , doActions , callPreParse = False ) <TAB> except ( ParseException , IndexError ) : <TAB> <TAB> if self . defaultValue is not self . __optionalNotMatched : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tokens = ParseResults ( [ self . defaultValue ] ) <TAB> <TAB> <TAB> <TAB> tokens [ self . expr . resultsName ] = self . defaultValue <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tokens = [ self . defaultValue ] <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens = [ ] <TAB> return loc , tokens ","if self . expr . resultsName : 
","if self . expr . resultsName :
",100.0,100.0,True
"def _find_exceptions ( ) : <TAB> for _name , obj in iteritems ( globals ( ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> is_http_exception = issubclass ( obj , HTTPException ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> is_http_exception = False <TAB> <TAB> if not is_http_exception or obj . code is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> __all__ . append ( obj . __name__ ) <TAB> <TAB> old_obj = default_exceptions . get ( obj . code , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> default_exceptions [ obj . code ] = obj ","if old_obj is not None and issubclass ( obj , old_obj ) : 
","if old_obj is not None and issubclass ( obj , old_obj ) :
",100.0,100.0,True
"def generator ( self , data ) : <TAB> for ( proc_as , key_buf_ptr ) in data : <TAB> <TAB> key_buf = proc_as . read ( key_buf_ptr , 24 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> key = "" "" . join ( "" %02X "" % ord ( k ) for k in key_buf ) <TAB> <TAB> yield ( <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> str ( key ) , <TAB> <TAB> <TAB> ] , <TAB> <TAB> ) ","if not key_buf : 
","if not key_buf :
",100.0,100.0,True
"def calculateEnableMargins ( self ) : <TAB> self . cnc . resetEnableMargins ( ) <TAB> for block in self . blocks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> CNC . vars [ "" xmin "" ] = min ( CNC . vars [ "" xmin "" ] , block . xmin ) <TAB> <TAB> <TAB> CNC . vars [ "" ymin "" ] = min ( CNC . vars [ "" ymin "" ] , block . ymin ) <TAB> <TAB> <TAB> CNC . vars [ "" zmin "" ] = min ( CNC . vars [ "" zmin "" ] , block . zmin ) <TAB> <TAB> <TAB> CNC . vars [ "" xmax "" ] = max ( CNC . vars [ "" xmax "" ] , block . xmax ) <TAB> <TAB> <TAB> CNC . vars [ "" ymax "" ] = max ( CNC . vars [ "" ymax "" ] , block . ymax ) <TAB> <TAB> <TAB> CNC . vars [ "" zmax "" ] = max ( CNC . vars [ "" zmax "" ] , block . zmax ) ","if block . enable : 
","if block . xmin is not None :
",44.36,22.09,False
"def __init__ ( self , client , job_id , callback = None ) : <TAB> self . client = client <TAB> self . job_id = job_id <TAB> # If a job event has been received already then we must set an Event <TAB> # to wait for this job to finish. <TAB> # Otherwise we create a new stub for the job with the Event for when <TAB> # the job event arrives to use existing event. <TAB> with client . _jobs_lock : <TAB> <TAB> job = client . _jobs . get ( job_id ) <TAB> <TAB> self . event = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . event = job . get ( "" __ready "" ) <TAB> <TAB> if self . event is None : <TAB> <TAB> <TAB> self . event = job [ "" __ready "" ] = Event ( ) <TAB> <TAB> job [ "" __callback "" ] = callback ","if job : 
","if job is not None :
",34.04,17.97,False
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> if env . cache_static : <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> if path == paths [ - 1 ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag ) ","if not os . path . exists ( fspath + "" .spt "" ) : 
","if env . cache_static :
",28.5,2.39,False
"def set_conf ( ) : <TAB> """"""Collapse all object_trail config into cherrypy.request.config."""""" <TAB> base = cherrypy . config . copy ( ) <TAB> # Note that we merge the config from each node <TAB> # even if that node was None. <TAB> for name , obj , conf , segleft in object_trail : <TAB> <TAB> base . update ( conf ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> base [ "" tools.staticdir.section "" ] = "" / "" + "" / "" . join ( <TAB> <TAB> <TAB> <TAB> fullpath [ 0 : fullpath_len - segleft ] <TAB> <TAB> <TAB> ) <TAB> return base ","if "" tools.staticdir.dir "" in conf : 
","if segleft > 0 :
",27.14,3.83,False
"def __init__ ( self ) : <TAB> self . setLayers ( None , None ) <TAB> self . interface = None <TAB> self . event_callbacks = { } <TAB> self . __stack = None <TAB> self . lock = threading . Lock ( ) <TAB> members = inspect . getmembers ( self , predicate = inspect . ismethod ) <TAB> for m in members : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fname = m [ 0 ] <TAB> <TAB> <TAB> fn = m [ 1 ] <TAB> <TAB> <TAB> self . event_callbacks [ fn . event_callback ] = getattr ( self , fname ) ","if hasattr ( m [ 1 ] , "" event_callback "" ) : 
","if m [ 0 ] . startswith ( "" _ "" ) :
",39.0,14.74,False
def multi_dev_generator ( self ) : <TAB> for data in self . _data_loader ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _tail_data + = data <TAB> <TAB> if len ( self . _tail_data ) == self . _base_number : <TAB> <TAB> <TAB> yield self . _tail_data <TAB> <TAB> <TAB> self . _tail_data = [ ] ,"if len ( self . _tail_data ) < self . _base_number : 
","if data is not None :
",26.07,1.45,False
"def replace_field_to_value ( layout , cb ) : <TAB> for i , lo in enumerate ( layout . fields ) : <TAB> <TAB> if isinstance ( lo , Field ) or issubclass ( lo . __class__ , Field ) : <TAB> <TAB> <TAB> layout . fields [ i ] = ShowField ( <TAB> <TAB> <TAB> <TAB> cb , * lo . fields , attrs = lo . attrs , wrapper_class = lo . wrapper_class <TAB> <TAB> <TAB> ) <TAB> <TAB> elif isinstance ( lo , basestring ) : <TAB> <TAB> <TAB> layout . fields [ i ] = ShowField ( cb , lo ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> replace_field_to_value ( lo , cb ) ","elif hasattr ( lo , "" get_field_names "" ) : 
","elif isinstance ( lo , Field ) :
",32.11,12.78,False
"def function_out ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> return function_in ( * args , * * kwargs ) <TAB> except dbus . exceptions . DBusException as e : <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_UNKNOWN_METHOD : <TAB> <TAB> <TAB> raise ItemNotFoundException ( "" Item does not exist! "" ) <TAB> <TAB> if e . get_dbus_name ( ) == DBUS_NO_SUCH_OBJECT : <TAB> <TAB> <TAB> raise ItemNotFoundException ( e . get_dbus_message ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise SecretServiceNotAvailableException ( e . get_dbus_message ( ) ) <TAB> <TAB> raise ","if e . get_dbus_name ( ) in ( DBUS_NO_REPLY , DBUS_NOT_SUPPORTED ) : 
","if e . get_dbus_name ( ) == DBUS_SECRET_SERVICE_NOT_available_OBJECT :
",55.32,45.45,False
"def results_iter ( self ) : <TAB> if self . connection . ops . oracle : <TAB> <TAB> from django . db . models . fields import DateTimeField <TAB> <TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB> <TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB> <TAB> for row in rows : <TAB> <TAB> <TAB> date = row [ offset ] <TAB> <TAB> <TAB> if self . connection . ops . oracle : <TAB> <TAB> <TAB> <TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp ( str ( date ) ) <TAB> <TAB> <TAB> yield date ","elif needs_string_cast : 
","if needs_string_cast :
",35.87,80.91,False
"def handle_label ( self , path , * * options ) : <TAB> verbosity = int ( options . get ( "" verbosity "" , 1 ) ) <TAB> result = finders . find ( path , all = options [ "" all "" ] ) <TAB> path = smart_unicode ( path ) <TAB> if result : <TAB> <TAB> if not isinstance ( result , ( list , tuple ) ) : <TAB> <TAB> <TAB> result = [ result ] <TAB> <TAB> output = u "" \n<TAB> "" . join ( <TAB> <TAB> <TAB> ( smart_unicode ( os . path . realpath ( path ) ) for path in result ) <TAB> <TAB> ) <TAB> <TAB> self . stdout . write ( smart_str ( u "" Found  ' %s '  here: \n<TAB> %s \n "" % ( path , output ) ) ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . stderr . write ( smart_str ( "" No matching file found for  ' %s ' . \n "" % path ) ) ","if verbosity > = 1 : 
","if verbosity > = 1 :
",100.0,100.0,True
"def name ( self ) : <TAB> """"""Get the enumeration name of this storage class."""""" <TAB> if self . _name_map is None : <TAB> <TAB> self . _name_map = { } <TAB> <TAB> for key , value in list ( StorageClass . __dict__ . items ( ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _name_map [ value ] = key <TAB> return self . _name_map [ self ] ","if isinstance ( value , StorageClass ) : 
","if isinstance ( value , StorageClass ) :
",100.0,100.0,True
"def index ( self , value ) : <TAB> if self . _growing : <TAB> <TAB> if self . _start < = value < self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB> <TAB> <TAB> if r == self . _zero : <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB> <TAB> <TAB> if r == self . _zero : <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) ) ","if self . _start > = value > self . _stop : 
","if self . _start > value :
",50.5,34.54,False
"def extract_cookie ( cookie_header , cookie_name ) : <TAB> inx = cookie_header . find ( cookie_name ) <TAB> if inx > = 0 : <TAB> <TAB> end_inx = cookie_header . find ( "" ; "" , inx ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = cookie_header [ inx : end_inx ] <TAB> <TAB> else : <TAB> <TAB> <TAB> value = cookie_header [ inx : ] <TAB> <TAB> return value <TAB> return "" "" ","if end_inx > 0 : 
","if end_inx > = 0 :
",39.71,59.46,False
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB> <TAB> if isinstance ( elem , str ) : <TAB> <TAB> <TAB> size + = len ( elem ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size + = elem . size * elem . itemsize <TAB> <TAB> elif isinstance ( elem , int ) : <TAB> <TAB> <TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB> <TAB> elif isinstance ( elem , float ) : <TAB> <TAB> <TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( ) <TAB> return size ","elif isinstance ( elem , np . ndarray ) : 
","elif isinstance ( elem , ( RandomState , RandomState ) ) :
",45.74,36.46,False
"def createFields ( self ) : <TAB> size = self . size / 8 <TAB> if size > 2 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield UInt8 ( self , "" cs "" , "" 10ms units, values from 0 to 199 "" ) <TAB> <TAB> yield Bits ( self , "" 2sec "" , 5 , "" seconds/2 "" ) <TAB> <TAB> yield Bits ( self , "" min "" , 6 , "" minutes "" ) <TAB> <TAB> yield Bits ( self , "" hour "" , 5 , "" hours "" ) <TAB> yield Bits ( self , "" day "" , 5 , "" (1-31) "" ) <TAB> yield Bits ( self , "" month "" , 4 , "" (1-12) "" ) <TAB> yield Bits ( self , "" year "" , 7 , "" (0 = 1980, 127 = 2107) "" ) ","if size > 4 : 
","if size == 4 :
",58.14,22.96,False
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" incap_ses|visid_incap "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = re . search ( r "" Incapsula "" , headers . get ( "" X-CDN "" , "" "" ) , re . I ) is not None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return retval ","if retval : 
","if retval :
",78.12,0.0,False
"def _get_order_information ( self , node_id , timeout = 1200 , check_interval = 5 ) : <TAB> mask = { <TAB> <TAB> "" billingItem "" : "" "" , <TAB> <TAB> "" powerState "" : "" "" , <TAB> <TAB> "" operatingSystem "" : { "" passwords "" : "" "" } , <TAB> <TAB> "" provisionDate "" : "" "" , <TAB> } <TAB> for i in range ( 0 , timeout , check_interval ) : <TAB> <TAB> res = self . connection . request ( <TAB> <TAB> <TAB> "" SoftLayer_Virtual_Guest "" , "" getObject "" , id = node_id , object_mask = mask <TAB> <TAB> ) . object <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return res <TAB> <TAB> time . sleep ( check_interval ) <TAB> raise SoftLayerException ( "" Timeout on getting node details "" ) ","if res . get ( "" provisionDate "" , None ) : 
","if res . get ( "" status "" ) == "" available "" :
",54.15,35.83,False
"def _process_param_change ( self , msg ) : <TAB> msg = super ( Select , self ) . _process_param_change ( msg ) <TAB> labels , values = self . labels , self . values <TAB> if "" value "" in msg : <TAB> <TAB> msg [ "" value "" ] = [ <TAB> <TAB> <TAB> labels [ indexOf ( v , values ) ] for v in msg [ "" value "" ] if isIn ( v , values ) <TAB> <TAB> ] <TAB> if "" options "" in msg : <TAB> <TAB> msg [ "" options "" ] = labels <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . value = [ v for v in self . value if isIn ( v , values ) ] <TAB> return msg ","if any ( not isIn ( v , values ) for v in self . value ) : 
","if self . value is not None :
",30.62,7.0,False
"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB> <TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB> <TAB> if not o . name : <TAB> <TAB> <TAB> continue <TAB> <TAB> if o . name . lower ( ) == name . lower ( ) : <TAB> <TAB> <TAB> return o <TAB> if check_symlinks : <TAB> <TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = m [ 0 ] <TAB> <TAB> return self . get_object_from_name ( name , False ) ","if m : 
","if m :
",78.12,0.0,False
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if v [ "" _class "" ] == "" User "" : <TAB> <TAB> <TAB> if v [ "" email "" ] == "" "" : <TAB> <TAB> <TAB> <TAB> v [ "" email "" ] = None <TAB> <TAB> <TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB> <TAB> <TAB> <TAB> v [ "" ip "" ] = None <TAB> return self . objs ","if k . startswith ( "" _ "" ) : 
","if k . startswith ( "" _ "" ) :
",100.0,100.0,True
"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB> <TAB> for ent_id , ent_desc in _md . items ( ) : <TAB> <TAB> <TAB> if descriptor in ent_desc : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ent_id ) <TAB> return res ","if ent_id in res : 
","if ent_id in res :
",100.0,100.0,True
"def test_add_participant ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> share_history_time = datetime . utcnow ( ) <TAB> <TAB> <TAB> share_history_time = share_history_time . replace ( tzinfo = TZ_UTC ) <TAB> <TAB> <TAB> new_participant = ChatThreadParticipant ( <TAB> <TAB> <TAB> <TAB> user = self . new_user , <TAB> <TAB> <TAB> <TAB> display_name = "" name "" , <TAB> <TAB> <TAB> <TAB> share_history_time = share_history_time , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> await self . chat_thread_client . add_participant ( new_participant ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . chat_client . delete_chat_thread ( self . thread_id ) ","if not self . is_playback ( ) : 
","if not self . is_playback ( ) :
",100.0,100.0,True
"def url ( regex , view , kwargs = None , name = None , prefix = "" "" ) : <TAB> if isinstance ( view , ( list , tuple ) ) : <TAB> <TAB> # For include(...) processing. <TAB> <TAB> urlconf_module , app_name , namespace = view <TAB> <TAB> return RegexURLResolver ( <TAB> <TAB> <TAB> regex , urlconf_module , kwargs , app_name = app_name , namespace = namespace <TAB> <TAB> ) <TAB> else : <TAB> <TAB> if isinstance ( view , basestring ) : <TAB> <TAB> <TAB> if not view : <TAB> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Empty URL pattern view name not permitted (for pattern  %r ) "" % regex <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> view = prefix + "" . "" + view <TAB> <TAB> return RegexURLPattern ( regex , view , kwargs , name ) ","if prefix : 
","if prefix :
",78.12,0.0,False
"def tx ( ) : <TAB> # Sync receiver ready to avoid loss of first packets <TAB> while not sub_ready . ready ( ) : <TAB> <TAB> pub . send ( b "" test BEGIN "" ) <TAB> <TAB> eventlet . sleep ( 0.005 ) <TAB> for i in range ( 1 , 101 ) : <TAB> <TAB> msg = "" test  {0} "" . format ( i ) . encode ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pub . send ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pub . send ( b "" test LAST "" ) <TAB> <TAB> <TAB> sub_last . wait ( ) <TAB> <TAB> # XXX: putting a real delay of 1ms here fixes sporadic failures on Travis <TAB> <TAB> # just yield eventlet.sleep(0) doesn't cut it <TAB> <TAB> eventlet . sleep ( 0.001 ) <TAB> pub . send ( b "" done DONE "" ) ","if i != 50 : 
","if sub_last . ready ( ) :
",27.8,5.67,False
"def remove_tmp_snapshot_file ( self , files ) : <TAB> for filepath in files : <TAB> <TAB> path = Path ( filepath ) <TAB> <TAB> if path . is_dir ( ) and path . exists ( ) : <TAB> <TAB> <TAB> shutil . rmtree ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path . unlink ( ) ","elif path . is_file ( ) and path . exists ( ) : 
","elif path . is_file ( ) and path . is_file ( ) :
",88.21,69.65,False
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> if count == 1 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> eol = view . line ( s . b ) . b <TAB> <TAB> <TAB> <TAB> return R ( s . b , eol ) <TAB> <TAB> <TAB> return s <TAB> return s ","if view . line ( s . b ) . size ( ) > 0 : 
","if s . b . isspace ( ) :
",36.68,11.53,False
"def get_ids ( self , * * kwargs ) : <TAB> id = [ ] <TAB> if "" id "" in kwargs : <TAB> <TAB> id = kwargs [ "" id "" ] <TAB> <TAB> # Coerce ids to list <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> id = id . split ( "" , "" ) <TAB> <TAB> # Ensure ids are integers <TAB> <TAB> try : <TAB> <TAB> <TAB> id = list ( map ( int , id ) ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> decorators . error ( "" Invalid id "" ) <TAB> return id ","if not isinstance ( id , list ) : 
","if "" , "" in id :
",26.74,6.98,False
"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return token . stripped_value <TAB> <TAB> if token . token_type == "" quoted-string "" : <TAB> <TAB> <TAB> for token in token : <TAB> <TAB> <TAB> <TAB> if token . token_type == "" bare-quoted-string "" : <TAB> <TAB> <TAB> <TAB> <TAB> for token in token : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if token . token_type == "" value "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token . stripped_value <TAB> return "" "" ","if token . token_type == "" value "" : 
","if token . token_type == "" value "" :
",100.0,100.0,True
"def get_all_start_methods ( self ) : <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> return [ "" spawn "" ] <TAB> else : <TAB> <TAB> methods = [ "" spawn "" , "" fork "" ] if sys . platform == "" darwin "" else [ "" fork "" , "" spawn "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> methods . append ( "" forkserver "" ) <TAB> <TAB> return methods ","if reduction . HAVE_SEND_HANDLE : 
","if self . server :
",53.65,6.32,False
"def _process_watch ( self , watched_event ) : <TAB> logger . debug ( "" process_watch:  %r "" , watched_event ) <TAB> with handle_exception ( self . _tree . _error_listeners ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert self . _parent is None , "" unexpected CREATED on non-root "" <TAB> <TAB> <TAB> self . on_created ( ) <TAB> <TAB> elif watched_event . type == EventType . DELETED : <TAB> <TAB> <TAB> self . on_deleted ( ) <TAB> <TAB> elif watched_event . type == EventType . CHANGED : <TAB> <TAB> <TAB> self . _refresh_data ( ) <TAB> <TAB> elif watched_event . type == EventType . CHILD : <TAB> <TAB> <TAB> self . _refresh_children ( ) ","if watched_event . type == EventType . CREATED : 
","if watched_event . type == EventType . CREATED :
",100.0,100.0,True
"def assert_open ( self , sock , * rest ) : <TAB> if isinstance ( sock , fd_types ) : <TAB> <TAB> self . __assert_fd_open ( sock ) <TAB> else : <TAB> <TAB> fileno = sock . fileno ( ) <TAB> <TAB> assert isinstance ( fileno , fd_types ) , fileno <TAB> <TAB> sockname = sock . getsockname ( ) <TAB> <TAB> assert isinstance ( sockname , tuple ) , sockname <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __assert_fd_open ( fileno ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _assert_sock_open ( sock ) <TAB> if rest : <TAB> <TAB> self . assert_open ( rest [ 0 ] , * rest [ 1 : ] ) ","if not WIN : 
","if fileno :
",29.81,0.0,False
"def detype ( self ) : <TAB> """"""De-types the instance, allowing it to be exported to the environment."""""" <TAB> style = self . style <TAB> if self . _detyped is None : <TAB> <TAB> self . _detyped = "" : "" . join ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> key <TAB> <TAB> <TAB> <TAB> + "" = "" <TAB> <TAB> <TAB> <TAB> + "" ; "" . join ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> LsColors . target_value <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> else ansi_color_name_to_escape_code ( v , cmap = style ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> for v in val <TAB> <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> for key , val in sorted ( self . _d . items ( ) ) <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> return self . _detyped ","if key in self . _targets 
","if key == LsColors . target_value
",54.78,11.34,False
"def gather_metrics ( dry_run = False ) : <TAB> today = datetime . date . today ( ) <TAB> first = today . replace ( day = 1 ) <TAB> last_month = first - datetime . timedelta ( days = 1 ) <TAB> filename = "" form_types_ {} .csv "" . format ( last_month . strftime ( "" % Y- % m "" ) ) <TAB> with connection . cursor ( ) as cursor : <TAB> <TAB> cursor . execute ( REGISTRATION_METRICS_SQL ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for row in cursor . fetchall ( ) : <TAB> <TAB> <TAB> <TAB> logger . info ( encode_row ( row ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> write_raw_data ( cursor = cursor , filename = filename ) ","if dry_run : 
","if dry_run :
",78.12,100.0,True
"def cat ( tensors , dim = 0 ) : <TAB> assert isinstance ( tensors , list ) , "" input to cat must be a list "" <TAB> if len ( tensors ) == 1 : <TAB> <TAB> return tensors [ 0 ] <TAB> from . autograd_cryptensor import AutogradCrypTensor <TAB> if any ( isinstance ( t , AutogradCrypTensor ) for t in tensors ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tensors [ 0 ] = AutogradCrypTensor ( tensors [ 0 ] , requires_grad = False ) <TAB> <TAB> return tensors [ 0 ] . cat ( * tensors [ 1 : ] , dim = dim ) <TAB> else : <TAB> <TAB> return get_default_backend ( ) . cat ( tensors , dim = dim ) ","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) : 
","if not isinstance ( tensors [ 0 ] , AutogradCrypTensor ) :
",100.0,100.0,True
"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB> <TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB> if not installed : <TAB> <TAB> <TAB> status = self . legacy_get_dlc_status ( dlc_title ) <TAB> <TAB> <TAB> installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> installed = True <TAB> return installed ","if self . install_dir and os . path . exists ( self . install_dir ) : 
","if self . is_installed ( ) :
",36.88,7.15,False
"def on_copy ( self ) : <TAB> source_objects = self . __getSelection ( ) <TAB> for source in source_objects : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_obj = model . Phrase ( "" "" , "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_obj = model . Script ( "" "" , "" "" ) <TAB> <TAB> new_obj . copy ( source ) <TAB> <TAB> self . cutCopiedItems . append ( new_obj ) ","if isinstance ( source , model . Phrase ) : 
","if source . endswith ( "" .png "" ) :
",33.0,9.86,False
"def FetchFn ( type_name ) : <TAB> """"""Fetches all hunt results of a given type."""""" <TAB> offset = 0 <TAB> while True : <TAB> <TAB> results = data_store . REL_DB . ReadHuntResults ( <TAB> <TAB> <TAB> hunt_id , offset = offset , count = self . _RESULTS_PAGE_SIZE , with_type = type_name <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> for r in results : <TAB> <TAB> <TAB> msg = r . AsLegacyGrrMessage ( ) <TAB> <TAB> <TAB> msg . source_urn = source_urn <TAB> <TAB> <TAB> yield msg <TAB> <TAB> offset + = self . _RESULTS_PAGE_SIZE ","if not results : 
","if not results :
",100.0,100.0,True
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB "" ","if length < = self . LENGTH_LIMIT_TINYBLOB : 
","if length < = self . LENGTH_LIMIT_TINYBLOB :
",100.0,100.0,True
"def decode ( cls , data ) : <TAB> while data : <TAB> <TAB> ( <TAB> <TAB> <TAB> length , <TAB> <TAB> <TAB> atype , <TAB> <TAB> ) = unpack ( cls . Header . PACK , data [ : cls . Header . LEN ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AttributesError ( "" Buffer underrun  %d  <  %d "" % ( len ( data ) , length ) ) <TAB> <TAB> payload = data [ cls . Header . LEN : length ] <TAB> <TAB> yield atype , payload <TAB> <TAB> data = data [ int ( ( length + 3 ) / 4 ) * 4 : ] ","if len ( data ) < length : 
","if len ( data ) < length :
",100.0,100.0,True
"def test_join_diffs ( db , series_of_diffs , expected ) : <TAB> diffs = [ ] <TAB> for changes in series_of_diffs : <TAB> <TAB> tracker = DBDiffTracker ( ) <TAB> <TAB> for key , val in changes . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del tracker [ key ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tracker [ key ] = val <TAB> <TAB> diffs . append ( tracker . diff ( ) ) <TAB> DBDiff . join ( diffs ) . apply_to ( db ) <TAB> assert db == expected ","if val is None : 
","if key in tracker :
",28.15,12.7,False
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp ","elif col == UNSEEN : 
","elif col == NO :
",64.48,53.73,False
"def _report_error ( self , completion_routine , response = None , message = None ) : <TAB> if response : <TAB> <TAB> # Only include the text in case of error. <TAB> <TAB> if not response . ok : <TAB> <TAB> <TAB> status = location . Status ( response . status_code , response . text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = location . Status ( response . status_code ) <TAB> else : <TAB> <TAB> status = location . Status ( 500 , message ) <TAB> if response is None or not response . ok : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return completion_routine ( status ) <TAB> <TAB> raise IOError ( response . text ) <TAB> else : <TAB> <TAB> if completion_routine : <TAB> <TAB> <TAB> completion_routine ( status ) <TAB> return location . Status ( 200 , response . content ) ","if completion_routine : 
","if completion_routine :
",78.12,100.0,True
"def _generate_examples ( self , src_path = None , tgt_path = None , replace_unk = None ) : <TAB> """"""Yields examples."""""" <TAB> with tf . io . gfile . GFile ( src_path ) as f_d , tf . io . gfile . GFile ( tgt_path ) as f_s : <TAB> <TAB> for i , ( doc_text , sum_text ) in enumerate ( zip ( f_d , f_s ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield i , { <TAB> <TAB> <TAB> <TAB> <TAB> _DOCUMENT : doc_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB> <TAB> <TAB> <TAB> <TAB> _SUMMARY : sum_text . strip ( ) . replace ( "" <unk> "" , "" UNK "" ) , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield i , { _DOCUMENT : doc_text . strip ( ) , _SUMMARY : sum_text . strip ( ) } ","if replace_unk : 
","if replace_unk :
",78.12,100.0,True
"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text ","if newline : 
","if newline :
",78.12,0.0,False
"def _handle_url_click ( self , event ) : <TAB> url = _extract_click_text ( self . info_text , event , "" url "" ) <TAB> if url is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> import webbrowser <TAB> <TAB> <TAB> webbrowser . open ( url ) <TAB> <TAB> elif os . path . sep in url : <TAB> <TAB> <TAB> os . makedirs ( url , exist_ok = True ) <TAB> <TAB> <TAB> open_path_in_system_file_manager ( url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _start_show_package_info ( url ) ","if url . startswith ( "" http: "" ) or url . startswith ( "" https: "" ) : 
","if os . path . isfile ( url ) :
",30.92,3.82,False
"def SConsignFile ( self , name = "" .sconsign "" , dbm_module = None ) : <TAB> if name is not None : <TAB> <TAB> name = self . subst ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = os . path . join ( str ( self . fs . SConstruct_dir ) , name ) <TAB> if name : <TAB> <TAB> name = os . path . normpath ( name ) <TAB> <TAB> sconsign_dir = os . path . dirname ( name ) <TAB> <TAB> if sconsign_dir and not os . path . exists ( sconsign_dir ) : <TAB> <TAB> <TAB> self . Execute ( SCons . Defaults . Mkdir ( sconsign_dir ) ) <TAB> SCons . SConsign . File ( name , dbm_module ) ","if not os . path . isabs ( name ) : 
","if not os . path . exists ( name ) :
",85.27,70.17,False
"def on_train_start ( self , trainer : Trainer , pl_module : LightningModule ) - > None : <TAB> super ( ) . on_train_start ( trainer , pl_module ) <TAB> submodule_dict = dict ( pl_module . named_modules ( ) ) <TAB> self . _hook_handles = [ ] <TAB> for name in self . _get_submodule_names ( pl_module ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rank_zero_warn ( <TAB> <TAB> <TAB> <TAB> f "" { name }  is not a valid identifier for a submodule in  { pl_module . __class__ . __name__ } , "" <TAB> <TAB> <TAB> <TAB> ""  skipping this key. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> handle = self . _register_hook ( name , submodule_dict [ name ] ) <TAB> <TAB> self . _hook_handles . append ( handle ) ","if name not in submodule_dict : 
","if name not in submodule_dict :
",100.0,100.0,True
"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> super ( ) . validate_configuration ( configuration ) <TAB> if configuration is None : <TAB> <TAB> configuration = self . configuration <TAB> try : <TAB> <TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB> <TAB> ) , "" value_set must be a list or a set "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB> <TAB> <TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key. ' <TAB> except AssertionError as e : <TAB> <TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True ","if isinstance ( configuration . kwargs [ "" value_set "" ] , dict ) : 
","if isinstance ( configuration . kwargs [ "" value_set "" ] , dict ) :
",100.0,100.0,True
"def check_refcounts ( expected , timeout = 10 ) : <TAB> start = time . time ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> _check_refcounts ( expected ) <TAB> <TAB> <TAB> break <TAB> <TAB> except AssertionError as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) ","if time . time ( ) - start > timeout : 
","if time . time ( ) - start > timeout :
",100.0,100.0,True
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> if prog . match ( line ) : <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None ","if not line : 
","if not line or not line [ 0 ] . isspace ( ) :
",45.91,11.36,False
def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp . search ( line ) <TAB> <TAB> if r : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> f . close ( ) <TAB> <TAB> return False ,"if line [ 0 ] == "" # "" : 
","if line . startswith ( "" # "" ) :
",37.03,18.6,False
"def link_pantsrefs ( soups , precomputed ) : <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB> <TAB> for a in soup . find_all ( "" a "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a [ "" pantsref "" ] <TAB> <TAB> <TAB> if pantsref not in precomputed . pantsref : <TAB> <TAB> <TAB> <TAB> raise TaskError ( <TAB> <TAB> <TAB> <TAB> <TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] ) ","if not a . has_attr ( "" pantsref "" ) : 
","if "" pantsref "" not in a :
",34.53,13.6,False
"def __init__ ( self , querylist = None ) : <TAB> self . query_id = - 1 <TAB> if querylist is None : <TAB> <TAB> self . querylist = [ ] <TAB> else : <TAB> <TAB> self . querylist = querylist <TAB> <TAB> for query in self . querylist : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . query_id = query . query_id <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if self . query_id != query . query_id : <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" query in list must be same query_id "" ) ","if self . query_id == - 1 : 
","if isinstance ( query , QueryId ) :
",26.81,5.0,False
"def _draw_number ( <TAB> screen , x_offset , y_offset , number , token = Token . Clock , transparent = False ) : <TAB> "" Write number at position. "" <TAB> fg = Char ( "" "" , token ) <TAB> bg = Char ( "" "" , Token ) <TAB> for y , row in enumerate ( _numbers [ number ] ) : <TAB> <TAB> screen_row = screen . data_buffer [ y + y_offset ] <TAB> <TAB> for x , n in enumerate ( row ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> screen_row [ x + x_offset ] = fg <TAB> <TAB> <TAB> elif not transparent : <TAB> <TAB> <TAB> <TAB> screen_row [ x + x_offset ] = bg ","if n == "" # "" : 
","if n == number :
",34.45,38.5,False
"def init ( self ) : <TAB> self . sock . setblocking ( True ) <TAB> if self . parser is None : <TAB> <TAB> # wrap the socket if needed <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . sock = ssl . wrap_socket ( <TAB> <TAB> <TAB> <TAB> self . sock , server_side = True , * * self . cfg . ssl_options <TAB> <TAB> <TAB> ) <TAB> <TAB> # initialize the parser <TAB> <TAB> self . parser = http . RequestParser ( self . cfg , self . sock ) ","if self . cfg . is_ssl : 
","if ssl is not None :
",27.18,6.96,False
"def intersect_face ( pt ) : <TAB> # todo: rewrite! inefficient! <TAB> nonlocal vis_faces2D <TAB> for f , vs in vis_faces2D : <TAB> <TAB> v0 = vs [ 0 ] <TAB> <TAB> for v1 , v2 in iter_pairs ( vs [ 1 : ] , False ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return f <TAB> return None ","if intersect_point_tri_2d ( pt , v0 , v1 , v2 ) : 
","if ( v0 == v1 ) and ( pt < = v2 ) :
",30.57,11.33,False
"def IMPORTFROM ( self , node ) : <TAB> if node . module == "" __future__ "" : <TAB> <TAB> if not self . futuresAllowed : <TAB> <TAB> <TAB> self . report ( messages . LateFutureImport , node , [ n . name for n in node . names ] ) <TAB> else : <TAB> <TAB> self . futuresAllowed = False <TAB> for alias in node . names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . scope . importStarred = True <TAB> <TAB> <TAB> self . report ( messages . ImportStarUsed , node , node . module ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = alias . asname or alias . name <TAB> <TAB> importation = Importation ( name , node ) <TAB> <TAB> if node . module == "" __future__ "" : <TAB> <TAB> <TAB> importation . used = ( self . scope , node ) <TAB> <TAB> self . addBinding ( node , importation ) ","if alias . name == "" * "" : 
","if alias . asname and alias . name in self . scope . importStarred :
",37.13,14.63,False
"def PyObject_Bytes ( obj ) : <TAB> if type ( obj ) == bytes : <TAB> <TAB> return obj <TAB> if hasattr ( obj , "" __bytes__ "" ) : <TAB> <TAB> res = obj . __bytes__ ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" __bytes__ returned non-bytes (type  %s ) "" % type ( res ) . __name__ <TAB> <TAB> <TAB> ) <TAB> return PyBytes_FromObject ( obj ) ","if not isinstance ( res , bytes ) : 
","if not isinstance ( res , bytes ) :
",100.0,100.0,True
"def on_bt_search_clicked ( self , widget ) : <TAB> if self . current_provider is None : <TAB> <TAB> return <TAB> query = self . en_query . get_text ( ) <TAB> @self . obtain_podcasts_with <TAB> def load_data ( ) : <TAB> <TAB> if self . current_provider . kind == directory . Provider . PROVIDER_SEARCH : <TAB> <TAB> <TAB> return self . current_provider . on_search ( query ) <TAB> <TAB> elif self . current_provider . kind == directory . Provider . PROVIDER_URL : <TAB> <TAB> <TAB> return self . current_provider . on_url ( query ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . current_provider . on_file ( query ) ","elif self . current_provider . kind == directory . Provider . PROVIDER_FILE : 
","elif self . current_provider . kind == directory . Provider . PROVIDER_FILE :
",100.0,100.0,True
"def remove ( self , name ) : <TAB> for s in [ self . __storage ( self . __category ) , self . __storage ( None ) ] : <TAB> <TAB> for i , b in enumerate ( s ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del s [ i ] <TAB> <TAB> <TAB> <TAB> if b . persistent : <TAB> <TAB> <TAB> <TAB> <TAB> self . __save ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> raise KeyError ( name ) ","if b . name == name : 
","if name == b . __name__ :
",36.76,17.83,False
"def _wrapper ( data , axis = None , keepdims = False ) : <TAB> if not keepdims : <TAB> <TAB> return func ( data , axis = axis ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> axis = axis if isinstance ( axis , int ) else axis [ 0 ] <TAB> <TAB> <TAB> out_shape = list ( data . shape ) <TAB> <TAB> <TAB> out_shape [ axis ] = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> out_shape = [ 1 for _ in range ( len ( data . shape ) ) ] <TAB> <TAB> return func ( data , axis = axis ) . reshape ( out_shape ) ","if axis is not None : 
","if axis :
",29.58,0.0,False
"def authn_info ( self ) : <TAB> res = [ ] <TAB> for astat in self . assertion . authn_statement : <TAB> <TAB> context = astat . authn_context <TAB> <TAB> try : <TAB> <TAB> <TAB> authn_instant = astat . authn_instant <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> authn_instant = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> aclass = context . authn_context_class_ref . text <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> aclass = "" "" <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> authn_auth = [ a . text for a in context . authenticating_authority ] <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> authn_auth = [ ] <TAB> <TAB> <TAB> res . append ( ( aclass , authn_auth , authn_instant ) ) <TAB> return res ","if context : 
","if context . authn_context_class_ref :
",34.79,8.3,False
"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB> <TAB> if self . posts : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> if self . stories : <TAB> <TAB> <TAB> if self . latest : <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path ) ","if self . latest : 
","if self . latest :
",100.0,100.0,True
"def update_record_image_detail ( input_image_record , updated_image_detail , session = None ) : <TAB> if not session : <TAB> <TAB> session = db . Session <TAB> image_record = { } <TAB> image_record . update ( input_image_record ) <TAB> image_record . pop ( "" created_at "" , None ) <TAB> image_record . pop ( "" last_updated "" , None ) <TAB> if image_record [ "" image_type "" ] == "" docker "" : <TAB> <TAB> for tag_record in updated_image_detail : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> image_record [ "" image_detail "" ] . append ( tag_record ) <TAB> <TAB> <TAB> <TAB> return update_record ( image_record , session = session ) <TAB> return image_record ","if tag_record not in image_record [ "" image_detail "" ] : 
","if tag_record [ "" name "" ] not in image_record [ "" image_detail "" ] :
",72.67,67.51,False
"def backup ( self ) : <TAB> for ds in [ ( "" activedirectory "" , "" AD "" ) , ( "" ldap "" , "" LDAP "" ) , ( "" nis "" , "" NIS "" ) ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ds_cache = self . middleware . call_sync ( "" cache.get "" , f "" { ds [ 1 ] } _cache "" ) <TAB> <TAB> <TAB> <TAB> with open ( f "" /var/db/system/. { ds [ 1 ] } _cache_backup "" , "" wb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> pickle . dump ( ds_cache , f ) <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> self . logger . debug ( "" No cache exists for directory service [ %s ]. "" , ds [ 0 ] ) ","if ( self . middleware . call_sync ( f "" { ds [ 0 ] } .config "" ) ) [ "" enable "" ] : 
","if ds [ 0 ] . endswith ( "" .db "" ) :
",35.27,8.61,False
"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB> <TAB> contents = self . setup_cfg . read_text ( ) <TAB> <TAB> base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> if six . PY2 : <TAB> <TAB> <TAB> <TAB> contents = self . setup_cfg . read_bytes ( ) <TAB> <TAB> <TAB> parsed = parse_setup_cfg ( contents , base_dir ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return { } <TAB> <TAB> return parsed <TAB> return { } ","if not parsed : 
","if parsed is None :
",29.25,14.06,False
"def parts ( ) : <TAB> for l in lists . leaves : <TAB> <TAB> head_name = l . get_head_name ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield l . leaves <TAB> <TAB> elif head_name != "" System`Missing "" : <TAB> <TAB> <TAB> raise MessageException ( "" Catenate "" , "" invrp "" , l ) ","if head_name == "" System`List "" : 
","if head_name == "" List "" :
",74.63,64.32,False
"def _get_callback_and_order ( self , hook ) : <TAB> if callable ( hook ) : <TAB> <TAB> return hook , None <TAB> elif isinstance ( hook , tuple ) and len ( hook ) == 2 : <TAB> <TAB> callback , order = hook <TAB> <TAB> # test that callback is a callable <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Hook callback is not a callable "" ) <TAB> <TAB> # test that number is an int <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( order ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" Hook order is not a number "" ) <TAB> <TAB> return callback , order <TAB> else : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Invalid hook definition, neither a callable nor a 2-tuple (callback, order):  {!r} "" . format ( <TAB> <TAB> <TAB> <TAB> hook <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if not callable ( callback ) : 
","if not callable ( callback ) :
",100.0,100.0,True
"def _resize_masks ( self , results ) : <TAB> """"""Resize masks with ``results['scale']``"""""" <TAB> for key in results . get ( "" mask_fields "" , [ ] ) : <TAB> <TAB> if results [ key ] is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results [ key ] = results [ key ] . rescale ( results [ "" scale "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> results [ key ] = results [ key ] . resize ( results [ "" img_shape "" ] [ : 2 ] ) ","if self . keep_ratio : 
","if isinstance ( results [ key ] , ( Base , Base ) ) :
",27.21,3.13,False
"def getDataMax ( self ) : <TAB> result = - Double . MAX_VALUE <TAB> nCurves = self . chart . getNCurves ( ) <TAB> for i in range ( nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> if not c . isVisible ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nPoints = c . getNPoints ( ) <TAB> <TAB> <TAB> for j in range ( nPoints ) : <TAB> <TAB> <TAB> <TAB> result = self . maxIgnoreNaNAndMaxValue ( result , c . getPoint ( j ) . getY ( ) ) <TAB> if result == - Double . MAX_VALUE : <TAB> <TAB> return Double . NaN <TAB> return result ","if c . getYAxis ( ) == Y_AXIS : 
","if self . chart . isVisible ( c ) :
",30.96,5.38,False
"def _check_token ( self ) : <TAB> if settings . app . sso_client_cache and self . server_auth_token : <TAB> <TAB> doc = self . sso_client_cache_collection . find_one ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" user_id "" : self . user . id , <TAB> <TAB> <TAB> <TAB> "" server_id "" : self . server . id , <TAB> <TAB> <TAB> <TAB> "" device_id "" : self . device_id , <TAB> <TAB> <TAB> <TAB> "" device_name "" : self . device_name , <TAB> <TAB> <TAB> <TAB> "" auth_token "" : self . server_auth_token , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . has_token = True ","if doc : 
","if doc and doc . auth_token :
",33.58,10.55,False
"def parse_header ( plyfile , ext ) : <TAB> # Variables <TAB> line = [ ] <TAB> properties = [ ] <TAB> num_points = None <TAB> while b "" end_header "" not in line and line != b "" "" : <TAB> <TAB> line = plyfile . readline ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line = line . split ( ) <TAB> <TAB> <TAB> num_points = int ( line [ 2 ] ) <TAB> <TAB> elif b "" property "" in line : <TAB> <TAB> <TAB> line = line . split ( ) <TAB> <TAB> <TAB> properties . append ( ( line [ 2 ] . decode ( ) , ext + ply_dtypes [ line [ 1 ] ] ) ) <TAB> return num_points , properties ","if b "" element "" in line : 
","if b "" point "" in line :
",75.22,50.0,False
"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB> <TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB> <TAB> for finfo in self . data : <TAB> <TAB> <TAB> self . __update_editor_margins ( finfo . editor ) <TAB> <TAB> <TAB> finfo . cleanup_analysis_results ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if current_finfo is not finfo : <TAB> <TAB> <TAB> <TAB> <TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 ) ","if ( run_pyflakes or run_pep8 ) and current_finfo is not None : 
","if run_pyflakes or run_pep8 :
",32.74,28.44,False
"def __modules ( self ) : <TAB> raw_output = self . __module_avail_output ( ) . decode ( "" utf-8 "" ) <TAB> for line in StringIO ( raw_output ) : <TAB> <TAB> line = line and line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> line_modules = line . split ( ) <TAB> <TAB> for module in line_modules : <TAB> <TAB> <TAB> if module . endswith ( self . default_indicator ) : <TAB> <TAB> <TAB> <TAB> module = module [ 0 : - len ( self . default_indicator ) ] . strip ( ) <TAB> <TAB> <TAB> module_parts = module . split ( "" / "" ) <TAB> <TAB> <TAB> module_version = None <TAB> <TAB> <TAB> if len ( module_parts ) == 2 : <TAB> <TAB> <TAB> <TAB> module_version = module_parts [ 1 ] <TAB> <TAB> <TAB> module_name = module_parts [ 0 ] <TAB> <TAB> <TAB> yield module_name , module_version ","if not line or line . startswith ( "" - "" ) : 
","if not line :
",31.56,6.73,False
"def _set_trailing_size ( self , size ) : <TAB> if self . is_free ( ) : <TAB> <TAB> next_chunk = self . next_chunk ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . state . memory . store ( next_chunk . base , size , self . state . arch . bytes ) ","if next_chunk is not None : 
","if next_chunk and not next_chunk . is_dirty ( ) :
",28.77,17.61,False
"def _execute_for_all_tables ( self , app , bind , operation , skip_tables = False ) : <TAB> app = self . get_app ( app ) <TAB> if bind == "" __all__ "" : <TAB> <TAB> binds = [ None ] + list ( app . config . get ( "" SQLALCHEMY_BINDS "" ) or ( ) ) <TAB> elif isinstance ( bind , string_types ) or bind is None : <TAB> <TAB> binds = [ bind ] <TAB> else : <TAB> <TAB> binds = bind <TAB> for bind in binds : <TAB> <TAB> extra = { } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tables = self . get_tables_for_bind ( bind ) <TAB> <TAB> <TAB> extra [ "" tables "" ] = tables <TAB> <TAB> op = getattr ( self . Model . metadata , operation ) <TAB> <TAB> op ( bind = self . get_engine ( app , bind ) , * * extra ) ","if not skip_tables : 
","if skip_tables :
",34.18,57.89,False
"def getFileName ( ) : <TAB> extension = "" .json "" <TAB> file = "" %s -stats "" % self . clusterName <TAB> counter = 0 <TAB> while True : <TAB> <TAB> suffix = str ( counter ) . zfill ( 3 ) + extension <TAB> <TAB> fullName = os . path . join ( self . statsPath , file + suffix ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return fullName <TAB> <TAB> counter + = 1 ","if not os . path . exists ( fullName ) : 
","if os . path . exists ( fullName ) :
",78.87,81.76,False
def logic ( ) : <TAB> # direction <TAB> if goRight == ACTIVE : <TAB> <TAB> dir . next = DirType . RIGHT <TAB> <TAB> run . next = True <TAB> elif goLeft == ACTIVE : <TAB> <TAB> dir . next = DirType . LEFT <TAB> <TAB> run . next = True <TAB> # stop <TAB> if stop == ACTIVE : <TAB> <TAB> run . next = False <TAB> # counter action <TAB> if run : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> q . next [ 4 : 1 ] = q [ 3 : ] <TAB> <TAB> <TAB> q . next [ 0 ] = not q [ 3 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> q . next [ 3 : ] = q [ 4 : 1 ] <TAB> <TAB> <TAB> q . next [ 3 ] = not q [ 0 ] ,"if dir == DirType . LEFT : 
","if q [ 0 ] :
",27.18,6.92,False
"def test_broadcast ( self ) : <TAB> """"""Test example broadcast functionality."""""" <TAB> self . create_lang_connection ( "" 1000000000 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000001 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000002 "" , "" en "" ) <TAB> self . create_lang_connection ( "" 1000000003 "" , "" es "" ) <TAB> self . create_lang_connection ( "" 1000000004 "" , "" es "" ) <TAB> app . lang_broadcast ( ) <TAB> self . assertEqual ( 2 , len ( self . outbound ) ) <TAB> for message in self . outbound : <TAB> <TAB> if message . text == "" hello "" : <TAB> <TAB> <TAB> self . assertEqual ( 3 , len ( message . connections ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( 2 , len ( message . connections ) ) ","elif message . text == "" hola "" : 
","elif message . text == "" hello2 "" :
",83.19,70.71,False
"def get_ovf_env ( dirname ) : <TAB> env_names = ( "" ovf-env.xml "" , "" ovf_env.xml "" , "" OVF_ENV.XML "" , "" OVF-ENV.XML "" ) <TAB> for fname in env_names : <TAB> <TAB> full_fn = os . path . join ( dirname , fname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> contents = util . load_file ( full_fn ) <TAB> <TAB> <TAB> <TAB> return ( fname , contents ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> util . logexc ( LOG , "" Failed loading ovf file  %s "" , full_fn ) <TAB> return ( None , False ) ","if os . path . isfile ( full_fn ) : 
","if os . path . isfile ( full_fn ) :
",100.0,100.0,True
"def _calc_offsets_children ( self , offset , is_last ) : <TAB> if self . elems : <TAB> <TAB> elem_last = self . elems [ - 1 ] <TAB> <TAB> for elem in self . elems : <TAB> <TAB> <TAB> offset = elem . _calc_offsets ( offset , ( elem is elem_last ) ) <TAB> <TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> elif not self . props or self . id in _ELEMS_ID_ALWAYS_BLOCK_SENTINEL : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> offset + = _BLOCK_SENTINEL_LENGTH <TAB> return offset ","if not is_last : 
","if not is_last :
",100.0,100.0,True
"def publish_state ( cls , payload , state ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if state == action_constants . LIVEACTION_STATUS_REQUESTED : <TAB> <TAB> <TAB> <TAB> cls . process ( payload ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> worker . get_worker ( ) . process ( payload ) <TAB> except Exception : <TAB> <TAB> traceback . print_exc ( ) <TAB> <TAB> print ( payload ) ","if isinstance ( payload , LiveActionDB ) : 
","if state != action_constants . LIVEACTION_STATUS_NONE :
",26.83,3.38,False
"def log_predictive_density ( self , x_test , y_test , Y_metadata = None ) : <TAB> if isinstance ( x_test , list ) : <TAB> <TAB> x_test , y_test , ind = util . multioutput . build_XY ( x_test , y_test ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> Y_metadata = { "" output_index "" : ind , "" trials "" : np . ones ( ind . shape ) } <TAB> return super ( MultioutputGP , self ) . log_predictive_density ( x_test , y_test , Y_metadata ) ","if Y_metadata is None : 
","if Y_metadata is None :
",100.0,100.0,True
"def minimalBases ( classes ) : <TAB> """"""Reduce a list of base classes to its ordered minimum equivalent"""""" <TAB> if not __python3 :<TAB> # pragma: no cover <TAB> <TAB> classes = [ c for c in classes if c is not ClassType ] <TAB> candidates = [ ] <TAB> for m in classes : <TAB> <TAB> for n in classes : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # m has no subclasses in 'classes' <TAB> <TAB> <TAB> if m in candidates : <TAB> <TAB> <TAB> <TAB> candidates . remove ( m )<TAB> # ensure that we're later in the list <TAB> <TAB> <TAB> candidates . append ( m ) <TAB> return candidates ","if issubclass ( n , m ) and m is not n : 
","if n is not ClassType :
",34.14,6.36,False
"def apply ( self , operations , rotations = None , * * kwargs ) : <TAB> rotations = rotations or [ ] <TAB> # apply the circuit operations <TAB> for i , operation in enumerate ( operations ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise DeviceError ( <TAB> <TAB> <TAB> <TAB> "" Operation  {}  cannot be used after other Operations have already been applied  "" <TAB> <TAB> <TAB> <TAB> "" on a  {}  device. "" . format ( operation . name , self . short_name ) <TAB> <TAB> <TAB> ) <TAB> for operation in operations : <TAB> <TAB> self . _apply_operation ( operation ) <TAB> # store the pre-rotated state <TAB> self . _pre_rotated_state = self . _state <TAB> # apply the circuit rotations <TAB> for operation in rotations : <TAB> <TAB> self . _apply_operation ( operation ) ","if i > 0 and isinstance ( operation , ( QubitStateVector , BasisState ) ) : 
","if i == 0 :
",29.78,3.65,False
"def __str__ ( self ) : <TAB> txt = str ( self . _called ) <TAB> if self . call_gas or self . call_value : <TAB> <TAB> gas = f "" gas:  { self . call_gas } "" if self . call_gas else "" "" <TAB> <TAB> value = f "" value:  { self . call_value } "" if self . call_value else "" "" <TAB> <TAB> salt = f "" salt:  { self . call_salt } "" if self . call_salt else "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> options = [ gas , value , salt ] <TAB> <TAB> <TAB> txt + = "" { "" + "" , "" . join ( [ o for o in options if o != "" "" ] ) + "" } "" <TAB> return txt + "" ( "" + "" , "" . join ( [ str ( a ) for a in self . _arguments ] ) + "" ) "" ","if gas or value or salt : 
","if self . call_salt :
",27.08,14.54,False
"def pop ( self ) : <TAB> """"""Pop a nonterminal.  (Internal)"""""" <TAB> popdfa , popstate , popnode = self . stack . pop ( ) <TAB> newnode = self . convert ( self . grammar , popnode ) <TAB> if newnode is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dfa , state , node = self . stack [ - 1 ] <TAB> <TAB> <TAB> node . children . append ( newnode ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . rootnode = newnode ","if self . stack : 
","if self . stack :
",100.0,100.0,True
"def pollpacket ( self , wait ) : <TAB> self . _stage0 ( ) <TAB> if len ( self . buffer ) < self . bufneed : <TAB> <TAB> r , w , x = select . select ( [ self . sock . fileno ( ) ] , [ ] , [ ] , wait ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> try : <TAB> <TAB> <TAB> s = self . sock . recv ( BUFSIZE ) <TAB> <TAB> except socket . error : <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> if len ( s ) == 0 : <TAB> <TAB> <TAB> raise EOFError <TAB> <TAB> self . buffer + = s <TAB> <TAB> self . _stage0 ( ) <TAB> return self . _stage1 ( ) ","if len ( r ) == 0 : 
","if len ( r ) == 0 :
",100.0,100.0,True
"def increaseToolReach ( self ) : <TAB> if self . draggingFace is not None : <TAB> <TAB> d = ( 1 , - 1 ) [ self . draggingFace & 1 ] <TAB> <TAB> if self . draggingFace >> 1 != 1 :<TAB> # xxxxx y <TAB> <TAB> <TAB> d = - d <TAB> <TAB> self . draggingY + = d <TAB> <TAB> x , y , z = self . editor . mainViewport . cameraPosition <TAB> <TAB> pos = [ x , y , z ] <TAB> <TAB> pos [ self . draggingFace >> 1 ] + = d <TAB> <TAB> self . editor . mainViewport . cameraPosition = tuple ( pos ) <TAB> else : <TAB> <TAB> self . cloneCameraDistance = self . editor . _incrementReach ( self . cloneCameraDistance ) <TAB> return True ","if self . draggingFace >> 1 != 1 : 
","if self . draggingFace >> 1 != 1 :
",100.0,100.0,True
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> if box == self . level . bounds : <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> if boxedChunks . issubset ( selectedChunks ) : <TAB> <TAB> <TAB> remove = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( ) ","if remove and not add : 
","if remove :
",29.69,0.0,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ProjectForm , self ) . __init__ ( * args , * * kwargs ) <TAB> if self . instance . id : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . fields [ "" localfiletype "" ] . widget . attrs [ "" disabled "" ] = True <TAB> <TAB> <TAB> self . fields [ "" localfiletype "" ] . required = False <TAB> <TAB> if ( <TAB> <TAB> <TAB> self . instance . treestyle != "" auto "" <TAB> <TAB> <TAB> and self . instance . translationproject_set . count ( ) <TAB> <TAB> <TAB> and self . instance . treestyle == self . instance . _detect_treestyle ( ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . fields [ "" treestyle "" ] . widget . attrs [ "" disabled "" ] = True <TAB> <TAB> <TAB> self . fields [ "" treestyle "" ] . required = False ","if Store . objects . filter ( translation_project__project = self . instance ) . count ( ) : 
","if self . instance . localfiletype != "" auto "" :
",35.0,6.23,False
"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str<TAB> # tempfile APIs return a str by default. <TAB> return return_type ","if return_type is str : 
","if return_type is bytes :
",64.55,64.35,False
"def deleteDuplicates ( gadgets , callback = None ) : <TAB> toReturn = [ ] <TAB> inst = set ( ) <TAB> count = 0 <TAB> added = False <TAB> len_gadgets = len ( gadgets ) <TAB> for i , gadget in enumerate ( gadgets ) : <TAB> <TAB> inst . add ( gadget . _gadget ) <TAB> <TAB> if len ( inst ) > count : <TAB> <TAB> <TAB> count = len ( inst ) <TAB> <TAB> <TAB> toReturn . append ( gadget ) <TAB> <TAB> <TAB> added = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> callback ( gadget , added , float ( i + 1 ) / ( len_gadgets ) ) <TAB> <TAB> <TAB> added = False <TAB> return toReturn ","if callback : 
","if callback :
",78.12,0.0,False
"def send_all ( self , data : bytes ) : <TAB> with self . _conflict_detector : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise _core . ClosedResourceError ( "" this pipe is already closed "" ) <TAB> <TAB> if not data : <TAB> <TAB> <TAB> await _core . checkpoint ( ) <TAB> <TAB> <TAB> return <TAB> <TAB> try : <TAB> <TAB> <TAB> written = await _core . write_overlapped ( self . _handle_holder . handle , data ) <TAB> <TAB> except BrokenPipeError as ex : <TAB> <TAB> <TAB> raise _core . BrokenResourceError from ex <TAB> <TAB> # By my reading of MSDN, this assert is guaranteed to pass so long <TAB> <TAB> # as the pipe isn't in nonblocking mode, but... let's just <TAB> <TAB> # double-check. <TAB> <TAB> assert written == len ( data ) ","if self . _handle_holder . closed : 
","if self . _closed :
",40.7,31.02,False
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> elif isinstance ( value , float ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value ","if self . use_prop or self . get_prop_name ( ) : 
","if self . sv_count ( ) > 0 :
",45.45,11.06,False
"def collect_active_inst_idx_list ( inst_beams , word_prob , inst_idx_to_position_map ) : <TAB> active_inst_idx_list = [ ] <TAB> for inst_idx , inst_position in inst_idx_to_position_map . items ( ) : <TAB> <TAB> is_inst_complete = inst_beams [ inst_idx ] . advance ( word_prob [ inst_position ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> active_inst_idx_list + = [ inst_idx ] <TAB> return active_inst_idx_list ","if not is_inst_complete : 
","if is_inst_complete :
",34.18,72.9,False
"def compare_member_req_resp_without_key ( self , request , response ) : <TAB> for user_response in resp_json ( response ) [ "" data "" ] : <TAB> <TAB> for user_request in request : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> assert user_request [ "" role "" ] == user_response [ "" role "" ] ","if user_request [ "" user_id "" ] == user_response [ "" user_id "" ] : 
","if user_request [ "" key "" ] == user_response [ "" key "" ] :
",78.98,57.94,False
"def __init__ ( self , dir ) : <TAB> self . module_names = set ( ) <TAB> for name in os . listdir ( dir ) : <TAB> <TAB> if name . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . module_names . add ( name [ : - 3 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . module_names . add ( name ) ","elif "" . "" not in name : 
","elif os . path . isdir ( name ) and not os . path . islink ( name ) :
",26.41,2.86,False
"def _read_filter ( self , data ) : <TAB> if data : <TAB> <TAB> if self . expected_inner_sha256 : <TAB> <TAB> <TAB> self . inner_sha . update ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . inner_md5 . update ( data ) <TAB> return data ","if self . expected_inner_md5sum : 
","if self . expected_inner_md5 :
",64.48,75.06,False
"def _p_basicstr_content ( s , content = _basicstr_re ) : <TAB> res = [ ] <TAB> while True : <TAB> <TAB> res . append ( s . expect_re ( content ) . group ( 0 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> if s . consume_re ( _newline_esc_re ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> elif s . consume_re ( _short_uni_re ) or s . consume_re ( _long_uni_re ) : <TAB> <TAB> <TAB> res . append ( _chr ( int ( s . last ( ) . group ( 1 ) , 16 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> s . expect_re ( _escapes_re ) <TAB> <TAB> <TAB> res . append ( _escapes [ s . last ( ) . group ( 0 ) ] ) <TAB> return "" "" . join ( res ) ","if not s . consume ( "" \\ "" ) : 
","if s . last ( ) . group ( 0 ) == _ENDMARKER :
",30.42,6.44,False
"def process_response ( self , request , response ) : <TAB> if ( <TAB> <TAB> response . status_code == 404 <TAB> <TAB> and request . path_info . endswith ( "" / "" ) <TAB> <TAB> and not is_valid_path ( request . path_info ) <TAB> <TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request . path [ : - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with safe_query_string ( request ) : <TAB> <TAB> <TAB> <TAB> newurl + = "" ? "" + request . META . get ( "" QUERY_STRING "" , "" "" ) <TAB> <TAB> return HttpResponsePermanentRedirect ( newurl ) <TAB> else : <TAB> <TAB> return response ","if request . GET : 
","if request . GET :
",100.0,100.0,True
"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB> <TAB> del obj [ k ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> k = dumps ( k ) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB> if Types . KEYS not in obj : <TAB> <TAB> <TAB> <TAB> obj [ Types . KEYS ] = [ ] <TAB> <TAB> <TAB> obj [ Types . KEYS ] . append ( k ) <TAB> <TAB> obj [ k ] = convertObjects ( v ) <TAB> return obj ","if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) : 
","if isinstance ( k , str ) :
",48.84,21.92,False
"def __repr__ ( self ) : <TAB> if self . _in_repr : <TAB> <TAB> return "" <recursion> "" <TAB> try : <TAB> <TAB> self . _in_repr = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> status = "" computed,  "" <TAB> <TAB> <TAB> if self . error ( ) is None : <TAB> <TAB> <TAB> <TAB> if self . value ( ) is self : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" = self "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> status + = "" =  "" + repr ( self . value ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> status + = "" error =  "" + repr ( self . error ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> status = "" isn ' t computed "" <TAB> <TAB> return "" %s  ( %s ) "" % ( type ( self ) , status ) <TAB> finally : <TAB> <TAB> self . _in_repr = False ","if self . is_computed ( ) : 
","if self . is_computed ( ) :
",100.0,100.0,True
"def allocate_network ( ipv = "" ipv4 "" ) : <TAB> global dtcd_uuid <TAB> global network_pool <TAB> global allocations <TAB> network = None <TAB> try : <TAB> <TAB> cx = httplib . HTTPConnection ( "" localhost:7623 "" ) <TAB> <TAB> cx . request ( "" POST "" , "" /v1/network/ %s / "" % ipv , body = dtcd_uuid ) <TAB> <TAB> resp = cx . getresponse ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> network = netaddr . IPNetwork ( resp . read ( ) . decode ( "" utf-8 "" ) ) <TAB> <TAB> cx . close ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> if network is None : <TAB> <TAB> network = network_pool [ ipv ] . pop ( ) <TAB> <TAB> allocations [ network ] = True <TAB> return network ","if resp . status == 200 : 
","if resp . status_code == 200 and "" network "" in resp . text :
",45.11,20.11,False
"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB> <TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB> <TAB> if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : <TAB> <TAB> <TAB> ind + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if start < ind : <TAB> <TAB> <TAB> <TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines = line . split ( "" : "" ) <TAB> <TAB> <TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d ","if "" : "" in line and len ( line ) > 0 : 
","if "" : "" in line :
",48.41,30.93,False
"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> print ( "" killing  %s "" % member ) <TAB> <TAB> <TAB> proc = hosts [ member ] [ "" proc "" ] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> if sys . platform in ( "" win32 "" , "" cygwin "" ) : <TAB> <TAB> <TAB> <TAB> os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . kill ( proc . pid , sig ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> if ha_tools_debug : <TAB> <TAB> <TAB> <TAB> print ( "" %s  already dead? "" % member ) ","if ha_tools_debug : 
","if ha_tools_debug :
",78.12,100.0,True
"def check ( self ) : <TAB> for path in self . paths : <TAB> <TAB> response = self . http_request ( <TAB> <TAB> <TAB> method = "" GET "" , <TAB> <TAB> <TAB> path = path , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if any ( <TAB> <TAB> <TAB> map ( <TAB> <TAB> <TAB> <TAB> lambda x : x in response . text , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.name "" , <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.sa.pass "" , <TAB> <TAB> <TAB> <TAB> <TAB> "" report.db.server.user.pass "" , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> self . valid = path <TAB> <TAB> <TAB> return True<TAB> # target is vulnerable <TAB> return False<TAB> # target not vulnerable ","if response is None : 
","if response is None :
",100.0,100.0,True
"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB> <TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB> <TAB> if r . ok : <TAB> <TAB> <TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB> <TAB> <TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB> <TAB> <TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB> <TAB> <TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB> <TAB> <TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB> <TAB> <TAB> time . sleep ( 1 )<TAB> # spider rule <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> return result ","if not last_date : 
","if r . status_code == 200 :
",28.37,5.52,False
"def button_press_cb ( self , tdw , event ) : <TAB> self . _update_zone_and_cursors ( tdw , event . x , event . y ) <TAB> if self . _zone in ( _EditZone . CREATE_FRAME , _EditZone . REMOVE_FRAME ) : <TAB> <TAB> button = event . button <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _click_info = ( button , self . _zone ) <TAB> <TAB> <TAB> return False <TAB> return super ( FrameEditMode , self ) . button_press_cb ( tdw , event ) ","if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS : 
","if button is not None :
",26.36,2.06,False
"def first_timestep ( ) : <TAB> assignment = self . has_previous . assign ( <TAB> <TAB> value = tf_util . constant ( value = True , dtype = "" bool "" ) , read_value = False <TAB> ) <TAB> with tf . control_dependencies ( control_inputs = ( assignment , ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> current = x <TAB> <TAB> else : <TAB> <TAB> <TAB> current = tf . expand_dims ( input = x , axis = ( self . axis + 1 ) ) <TAB> <TAB> multiples = tuple ( <TAB> <TAB> <TAB> self . length if dims == self . axis + 1 else 1 <TAB> <TAB> <TAB> for dims in range ( self . output_spec ( ) . rank + 1 ) <TAB> <TAB> ) <TAB> <TAB> return tf . tile ( input = current , multiples = multiples ) ","if self . concatenate : 
","if self . axis == 0 :
",45.06,22.09,False
"def main ( ) - > None : <TAB> onefuzz = Onefuzz ( ) <TAB> jobs = onefuzz . jobs . list ( ) <TAB> for job in jobs : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" job: "" , <TAB> <TAB> <TAB> str ( job . job_id ) [ : 8 ] , <TAB> <TAB> <TAB> "" : "" . join ( [ job . config . project , job . config . name , job . config . build ] ) , <TAB> <TAB> ) <TAB> <TAB> for task in onefuzz . tasks . list ( job_id = job . job_id ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> ""<TAB>  "" , <TAB> <TAB> <TAB> <TAB> str ( task . task_id ) [ : 8 ] , <TAB> <TAB> <TAB> <TAB> task . config . task . type , <TAB> <TAB> <TAB> <TAB> task . config . task . target_exe , <TAB> <TAB> <TAB> ) ","if task . state in [ "" stopped "" , "" stopping "" ] : 
","if task . config . task . type != "" task "" :
",39.66,11.7,False
"def update_stack ( self , full_name , template_url , parameters , tags ) : <TAB> """"""Updates an existing stack in CloudFormation."""""" <TAB> try : <TAB> <TAB> logger . info ( "" Attempting to update stack  %s . "" , full_name ) <TAB> <TAB> self . conn . cloudformation . update_stack ( <TAB> <TAB> <TAB> full_name , <TAB> <TAB> <TAB> template_url = template_url , <TAB> <TAB> <TAB> parameters = parameters , <TAB> <TAB> <TAB> tags = tags , <TAB> <TAB> <TAB> capabilities = [ "" CAPABILITY_IAM "" ] , <TAB> <TAB> ) <TAB> <TAB> return SUBMITTED <TAB> except BotoServerError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . info ( "" Stack  %s  did not change, not updating. "" , full_name ) <TAB> <TAB> <TAB> return SKIPPED <TAB> <TAB> raise ","if "" No updates are to be performed. "" in e . message : 
","if e . response [ "" Error "" ] [ "" Code "" ] == "" InternalError "" :
",36.72,5.04,False
"def header_tag_files ( env , files , legal_header , script_files = False ) : <TAB> """"""Apply the legal_header to the list of files"""""" <TAB> try : <TAB> <TAB> import apply_legal_header <TAB> except : <TAB> <TAB> xbc . cdie ( "" XED ERROR: mfile.py could not find scripts directory "" ) <TAB> for g in files : <TAB> <TAB> print ( "" G:  "" , g ) <TAB> <TAB> for f in mbuild . glob ( g ) : <TAB> <TAB> <TAB> print ( "" F:  "" , f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> apply_legal_header . apply_header_to_data_file ( legal_header , f ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> apply_legal_header . apply_header_to_source_file ( legal_header , f ) ","if script_files : 
","if script_files :
",78.12,100.0,True
"def cleanDataCmd ( cmd ) : <TAB> newcmd = "" AbracadabrA ** <?php  "" <TAB> if cmd [ : 6 ] != "" php:// "" : <TAB> <TAB> if reverseConn not in cmd : <TAB> <TAB> <TAB> cmds = cmd . split ( "" & "" ) <TAB> <TAB> <TAB> for c in cmds : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> newcmd + = "" system( ' %s ' ); "" % c <TAB> <TAB> else : <TAB> <TAB> <TAB> b64cmd = base64 . b64encode ( cmd ) <TAB> <TAB> <TAB> newcmd + = "" system(base64_decode( ' %s ' )); "" % b64cmd <TAB> else : <TAB> <TAB> newcmd + = cmd [ 6 : ] <TAB> newcmd + = "" ?> ** "" <TAB> return newcmd ","if len ( c ) > 0 : 
","if c != "" php:// "" :
",26.96,4.93,False
"def test_form ( self ) : <TAB> n_qubits = 6 <TAB> random_operator = get_fermion_operator ( random_interaction_operator ( n_qubits ) ) <TAB> chemist_operator = chemist_ordered ( random_operator ) <TAB> for term , _ in chemist_operator . terms . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertTrue ( term [ 0 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 2 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertFalse ( term [ 1 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertFalse ( term [ 3 ] [ 1 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 0 ] [ 0 ] > term [ 2 ] [ 0 ] ) <TAB> <TAB> <TAB> self . assertTrue ( term [ 1 ] [ 0 ] > term [ 3 ] [ 0 ] ) ","if len ( term ) == 2 or not len ( term ) : 
","if term [ 0 ] [ 1 ] == 1 :
",26.02,6.63,False
"def do ( server , handler , config , modargs ) : <TAB> data = [ ] <TAB> clients = server . get_clients ( handler . default_filter ) <TAB> if not clients : <TAB> <TAB> return <TAB> for client in clients : <TAB> <TAB> tags = config . tags ( client . node ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tags . remove ( * modargs . remove ) <TAB> <TAB> if modargs . add : <TAB> <TAB> <TAB> tags . add ( * modargs . add ) <TAB> <TAB> data . append ( { "" ID "" : client . node ( ) , "" TAGS "" : tags } ) <TAB> config . save ( project = modargs . write_project , user = modargs . write_user ) <TAB> handler . display ( Table ( data ) ) ","if modargs . remove : 
","if modargs . remove :
",100.0,100.0,True
"def validate ( self ) : <TAB> if self . data . get ( "" state "" ) == "" enabled "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PolicyValidationError ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> "" redshift logging enablement requires `bucket`  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" and `prefix` specification on  %s "" % ( self . manager . data , ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return self ","if "" bucket "" not in self . data : 
","if "" bucket "" not in self . data or "" prefix "" not in self . data :
",78.73,48.25,False
"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB> <TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sx , sy = m . groups ( ) <TAB> <TAB> <TAB> x = colname2num ( sx ) <TAB> <TAB> <TAB> y = int ( sy ) <TAB> <TAB> <TAB> if x1 < = x < = x2 and y1 < = y < = y2 : <TAB> <TAB> <TAB> <TAB> part = cellname ( x + dx , y + dy ) <TAB> <TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment ) ","if m is not None : 
","if m :
",29.58,0.0,False
"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB> <TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB> <TAB> if v is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str ( v ) <TAB> <TAB> if len ( v ) == 0 and not allow_empty : <TAB> <TAB> <TAB> continue <TAB> <TAB> contents [ k ] = v <TAB> <TAB> updated_am + = 1 <TAB> if updated_am : <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str ( contents ) , <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB> <TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 ) ","if not exists : 
","if not exists :
",100.0,100.0,True
"def getElement ( self , aboutUri , namespace , name ) : <TAB> for desc in self . rdfRoot . getElementsByTagNameNS ( RDF_NAMESPACE , "" Description "" ) : <TAB> <TAB> if desc . getAttributeNS ( RDF_NAMESPACE , "" about "" ) == aboutUri : <TAB> <TAB> <TAB> attr = desc . getAttributeNodeNS ( namespace , name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield attr <TAB> <TAB> <TAB> for element in desc . getElementsByTagNameNS ( namespace , name ) : <TAB> <TAB> <TAB> <TAB> yield element ","if attr != None : 
","if attr :
",31.47,0.0,False
"def get_store_name_from_connection_string ( connection_string ) : <TAB> if is_valid_connection_string ( connection_string ) : <TAB> <TAB> segments = dict ( seg . split ( "" = "" , 1 ) for seg in connection_string . split ( "" ; "" ) ) <TAB> <TAB> endpoint = segments . get ( "" Endpoint "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return endpoint . split ( "" // "" ) [ 1 ] . split ( "" . "" ) [ 0 ] <TAB> return None ","if endpoint : 
","if endpoint :
",78.12,0.0,False
"def insertLoopTemplate ( self , layout ) : <TAB> col = layout . column ( align = True ) <TAB> for socket in self . activeNode . outputs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> props = col . operator ( <TAB> <TAB> <TAB> <TAB> "" an.insert_loop_for_iterator "" , <TAB> <TAB> <TAB> <TAB> text = "" Loop through  {} "" . format ( repr ( socket . getDisplayedName ( ) ) ) , <TAB> <TAB> <TAB> <TAB> icon = "" MOD_ARRAY "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> props . nodeIdentifier = self . activeNode . identifier <TAB> <TAB> <TAB> props . socketIndex = socket . getIndex ( ) ","if not socket . hide and isList ( socket . bl_idname ) : 
","if socket . isLoopForIterator ( ) :
",33.65,6.56,False
"def do_task ( self , task ) : <TAB> self . running_task + = 1 <TAB> result = yield gen . Task ( self . fetcher . fetch , task ) <TAB> type , task , response = result . args <TAB> self . processor . on_task ( task , response ) <TAB> # do with message <TAB> while not self . processor . inqueue . empty ( ) : <TAB> <TAB> _task , _response = self . processor . inqueue . get ( ) <TAB> <TAB> self . processor . on_task ( _task , _response ) <TAB> # do with results <TAB> while not self . processor . result_queue . empty ( ) : <TAB> <TAB> _task , _result = self . processor . result_queue . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . result_worker . on_result ( _task , _result ) <TAB> self . running_task - = 1 ","if self . result_worker : 
","if _task is not None :
",28.03,8.64,False
"def _parse_config_result ( data ) : <TAB> command_list = ""  ;  "" . join ( [ x . strip ( ) for x in data [ 0 ] ] ) <TAB> config_result = data [ 1 ] <TAB> if isinstance ( config_result , list ) : <TAB> <TAB> result = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for key in config_result [ 0 ] : <TAB> <TAB> <TAB> <TAB> result + = config_result [ 0 ] [ key ] <TAB> <TAB> <TAB> config_result = result <TAB> <TAB> else : <TAB> <TAB> <TAB> config_result = config_result [ 0 ] <TAB> return [ command_list , config_result ] ","if isinstance ( config_result [ 0 ] , dict ) : 
","if isinstance ( config_result [ 0 ] , dict ) :
",100.0,100.0,True
"def load_api_handler ( self , mod_name ) : <TAB> for name , hdl in API_HANDLERS : <TAB> <TAB> name = name . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> handler = self . mods . get ( name ) <TAB> <TAB> <TAB> if not handler : <TAB> <TAB> <TAB> <TAB> handler = hdl ( self . emu ) <TAB> <TAB> <TAB> <TAB> self . mods . update ( { name : handler } ) <TAB> <TAB> <TAB> return handler <TAB> return None ","if mod_name and name == mod_name . lower ( ) : 
","if name . startswith ( mod_name ) :
",31.28,13.42,False
def heal ( self ) : <TAB> if not self . doctors : <TAB> <TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess . objects . get ( id = proc_id ) <TAB> <TAB> if not proc . is_alive or proc . is_frozen : <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self . doctors : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dr . cure ( proc ) <TAB> <TAB> <TAB> <TAB> break ,"if dr . confirm ( proc ) : 
","if dr . is_alive ( proc ) :
",75.15,37.99,False
"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB> <TAB> if len ( kwargs ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> cls . __name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return super ( ) . __new__ ( cls ) <TAB> <TAB> if isinstance ( args [ 0 ] , cls ) : <TAB> <TAB> <TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs ) ","if not args [ 0 ] : 
","if not args :
",34.82,30.18,False
"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try : <TAB> <TAB> A , B = self [ 0 ] , other [ 0 ] <TAB> <TAB> # uses logical clock value first <TAB> <TAB> if A and B :<TAB> # use logical clock if available <TAB> <TAB> <TAB> if A == B :<TAB> # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self [ 2 ] < other [ 2 ] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self [ 1 ] < other [ 1 ]<TAB> # ... or use timestamp <TAB> except IndexError : <TAB> <TAB> return NotImplemented ","if A and B : 
","if A == B :
",32.78,22.96,False
"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB> <TAB> if str . lower ( key ) == str . lower ( resource_provider ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient ( <TAB> <TAB> <TAB> <TAB> <TAB> key , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" api_version "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" support_list_or_not "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" resource_get_api_version "" ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value ( ) <TAB> raise CLIError ( <TAB> <TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> ) ","if isinstance ( value , dict ) : 
","if value [ "" api_version "" ] > = value [ "" resource_get_api_version "" ] :
",26.43,2.07,False
"def test_progressbar_format_pos ( runner , pos , length ) : <TAB> with _create_progress ( length , length_known = length != 0 , pos = pos ) as progress : <TAB> <TAB> result = progress . format_pos ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert result == f "" { pos } / { length } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> assert result == str ( pos ) ","if progress . length_known : 
","if length != 0 :
",28.41,9.04,False
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> if not Placeholder . check_resolved ( v . size ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed ","if not v . has_attribute ( SplitTarget ) : 
","if height != MAX_TEXTURE_SIZE and width != config . WEBGL_MAX_TEXTURE_SIZE :
",30.62,2.33,False
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> elif col == BARRIER : <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp ","if col == LAND : 
","if col == NONE :
",64.48,53.73,False
"def reset ( self ) : <TAB> logger . debug ( "" Arctic.reset() "" ) <TAB> with self . _lock : <TAB> <TAB> if self . __conn is not None : <TAB> <TAB> <TAB> self . __conn . close ( ) <TAB> <TAB> <TAB> self . __conn = None <TAB> <TAB> for _ , l in self . _library_cache . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> logger . debug ( "" Library reset()  %s "" % l ) <TAB> <TAB> <TAB> <TAB> l . _reset ( )<TAB> # the existence of _reset() is not guaranteed/enforced, it also triggers re-auth ","if hasattr ( l , "" _reset "" ) and callable ( l . _reset ) : 
","if hasattr ( l , "" _reset "" ) :
",57.41,45.38,False
"def add_cand_to_check ( cands ) : <TAB> for cand in cands : <TAB> <TAB> x = cand . creator <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if x not in fan_out : <TAB> <TAB> <TAB> # `len(fan_out)` is in order to avoid comparing `x` <TAB> <TAB> <TAB> heapq . heappush ( cand_funcs , ( - x . rank , len ( fan_out ) , x ) ) <TAB> <TAB> fan_out [ x ] + = 1 ","if x is None : 
","if x is None :
",100.0,100.0,True
"def on_task_modify ( self , task , config ) : <TAB> for entry in task . entries : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size = entry [ "" torrent "" ] . size / 1024 / 1024 <TAB> <TAB> <TAB> log . debug ( "" %s  size:  %s  MB "" % ( entry [ "" title "" ] , size ) ) <TAB> <TAB> <TAB> entry [ "" content_size "" ] = size ","if "" torrent "" in entry : 
","if "" torrent "" in entry and entry [ "" torrent "" ] . size :
",66.35,31.31,False
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> if self . do_corr_and_slope : <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> if self . do_manders : <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ] ","if self . do_costes : 
","if self . do_costes :
",100.0,100.0,True
"def create_root ( cls , site = None , title = "" Root "" , request = None , * * kwargs ) : <TAB> if not site : <TAB> <TAB> site = Site . objects . get_current ( ) <TAB> root_nodes = cls . objects . root_nodes ( ) . filter ( site = site ) <TAB> if not root_nodes : <TAB> <TAB> article = Article ( ) <TAB> <TAB> revision = ArticleRevision ( title = title , * * kwargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> revision . set_from_request ( request ) <TAB> <TAB> article . add_revision ( revision , save = True ) <TAB> <TAB> article . save ( ) <TAB> <TAB> root = cls . objects . create ( site = site , article = article ) <TAB> <TAB> article . add_object_relation ( root ) <TAB> else : <TAB> <TAB> root = root_nodes [ 0 ] <TAB> return root ","if request : 
","if request :
",78.12,0.0,False
"def get ( self , key ) : <TAB> filename = self . _get_filename ( key ) <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> pickle_time = pickle . load ( f ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return pickle . load ( f ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . remove ( filename ) <TAB> <TAB> <TAB> <TAB> return None <TAB> except ( IOError , OSError , pickle . PickleError ) : <TAB> <TAB> return None ","if pickle_time == 0 or pickle_time > = time ( ) : 
","if pickle_time < self . timeout :
",27.03,12.97,False
"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_body ( message , value ) <TAB> <TAB> elif name == "" EMAIL_ATTACHMENT "" : <TAB> <TAB> <TAB> self . add_attachment ( message , value ) <TAB> <TAB> else :<TAB> # From, To, Subject, etc. <TAB> <TAB> <TAB> self . set_option ( message , name , value , target ) <TAB> return message ","if name == "" EMAIL_BODY "" : 
","if name == "" EMAIL_BODY "" :
",100.0,100.0,True
"def updateVar ( name , data , mode = None ) : <TAB> if mode : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . append ( data ) <TAB> <TAB> elif mode == "" add "" : <TAB> <TAB> <TAB> core . config . globalVariables [ name ] . add ( data ) <TAB> else : <TAB> <TAB> core . config . globalVariables [ name ] = data ","if mode == "" append "" : 
","if mode == "" add "" :
",74.63,59.46,False
"def insert_errors ( <TAB> el , <TAB> errors , <TAB> form_id = None , <TAB> form_index = None , <TAB> error_class = "" error "" , <TAB> error_creator = default_error_creator , ) : <TAB> el = _find_form ( el , form_id = form_id , form_index = form_index ) <TAB> for name , error in errors . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for error_el , message in _find_elements_for_name ( el , name , error ) : <TAB> <TAB> <TAB> assert isinstance ( message , ( basestring , type ( None ) , ElementBase ) ) , ( <TAB> <TAB> <TAB> <TAB> "" Bad message:  %r "" % message <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> _insert_error ( error_el , message , error_class , error_creator ) ","if error is None : 
","if not isinstance ( error , ( basestring , type ( None ) , ElementBase ) ) :
",27.22,3.04,False
"def read ( self , item , recursive = False , sort = False ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _store [ item ] <TAB> <TAB> <TAB> raise KeyError ( item ) <TAB> <TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> else : <TAB> <TAB> return self . _read_dir ( item , recursive = recursive , sort = sort ) ","if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) : 
","if not recursive and sort :
",25.52,0.38,False
"def _stash_splitter ( states ) : <TAB> keep , split = [ ] , [ ] <TAB> if state_func is not None : <TAB> <TAB> for s in states : <TAB> <TAB> <TAB> ns = state_func ( s ) <TAB> <TAB> <TAB> if isinstance ( ns , SimState ) : <TAB> <TAB> <TAB> <TAB> split . append ( ns ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> split . extend ( ns ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> split . append ( s ) <TAB> if stash_func is not None : <TAB> <TAB> split = stash_func ( states ) <TAB> if to_stash is not stash : <TAB> <TAB> keep = states <TAB> return keep , split ","elif isinstance ( ns , ( list , tuple , set ) ) : 
","elif isinstance ( ns , list ) :
",40.47,29.04,False
"def run ( self ) : <TAB> while self . runflag : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with self . lock : <TAB> <TAB> <TAB> <TAB> tasks = list ( self . queue ) <TAB> <TAB> <TAB> <TAB> self . queue . clear ( ) <TAB> <TAB> <TAB> while len ( tasks ) > 0 : <TAB> <TAB> <TAB> <TAB> pathname , remotepath = tasks . pop ( 0 ) <TAB> <TAB> <TAB> <TAB> self . bcloud_app . upload_page . add_bg_task ( pathname , remotepath ) <TAB> <TAB> <TAB> self . last = time ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sleep ( 1 ) ","if time ( ) - self . last > 5 and self . qsize ( ) > 0 : 
","if time ( ) - self . last > self . queue_size :
",60.36,46.72,False
"def _append_patch ( self , patch_dir , patch_files ) : <TAB> for patch in patch_files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tmp = patch <TAB> <TAB> <TAB> patch = { } <TAB> <TAB> <TAB> for key in tmp . keys ( ) : <TAB> <TAB> <TAB> <TAB> patch [ os . path . join ( patch_dir , key ) ] = tmp [ key ] <TAB> <TAB> <TAB> self . patches . append ( patch ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . patches . append ( os . path . join ( patch_dir , patch ) ) ","if type ( patch ) is dict : 
","if isinstance ( patch , dict ) :
",28.68,14.54,False
"def __remote_port ( self ) : <TAB> port = 22 <TAB> if self . git_has_remote : <TAB> <TAB> m = re . match ( r "" ^(.*?)?@([^/:]*):?([0-9]+)? "" , self . git_remote . url ) <TAB> <TAB> if m : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> port = m . group ( 3 ) <TAB> return int ( port ) ","if m . group ( 3 ) : 
","if m . group ( 3 ) :
",100.0,100.0,True
"def _create_or_get_helper ( self , infer_mode : Optional [ bool ] = None , * * kwargs ) - > Helper : <TAB> # Prefer creating a new helper when at least one kwarg is specified. <TAB> prefer_new = len ( kwargs ) > 0 <TAB> kwargs . update ( infer_mode = infer_mode ) <TAB> is_training = not infer_mode if infer_mode is not None else self . training <TAB> helper = self . _train_helper if is_training else self . _infer_helper <TAB> if prefer_new or helper is None : <TAB> <TAB> helper = self . create_helper ( * * kwargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _train_helper = helper <TAB> <TAB> elif not is_training and self . _infer_helper is None : <TAB> <TAB> <TAB> self . _infer_helper = helper <TAB> return helper ","if is_training and self . _train_helper is None : 
","if not is_training and self . _train_helper is None :
",76.79,86.66,False
"def flushChangeClassifications ( self , schedulerid , less_than = None ) : <TAB> if less_than is not None : <TAB> <TAB> classifications = self . classifications . setdefault ( schedulerid , { } ) <TAB> <TAB> for changeid in list ( classifications ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del classifications [ changeid ] <TAB> else : <TAB> <TAB> self . classifications [ schedulerid ] = { } <TAB> return defer . succeed ( None ) ","if changeid < less_than : 
","if less_than < changeid :
",54.02,30.21,False
"def pid_from_name ( name ) : <TAB> processes = [ ] <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> pid = int ( pid ) <TAB> <TAB> <TAB> pname , cmdline = SunProcess . _name_args ( pid ) <TAB> <TAB> <TAB> if name in pname : <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return pid <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> raise ProcessException ( "" No process with such name:  %s "" % name ) ","if name in cmdline . split ( "" "" , 1 ) [ 0 ] : 
","if name in cmdline :
",31.6,7.83,False
"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> if part . type == "" body "" : <TAB> <TAB> <TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB> <TAB> <TAB> yield f ( id , msg , write , flush ) <TAB> <TAB> if part is not query [ - 1 ] : <TAB> <TAB> <TAB> space ( ) <TAB> if uid and not seenUID : <TAB> <TAB> space ( ) <TAB> <TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( ) ","if part . type == "" uid "" : 
","if uid :
",26.34,0.0,False
"def rx ( ) : <TAB> while True : <TAB> <TAB> rx_i = rep . recv ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rep . send ( b "" done "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> rep . send ( b "" i "" ) ","if rx_i == b "" 1000 "" : 
","if rx_i == b "" "" :
",80.36,75.17,False
"def test_search_incorrect_base_exception_1 ( self ) : <TAB> self . connection_1c . bind ( ) <TAB> try : <TAB> <TAB> result = self . connection_1c . search ( <TAB> <TAB> <TAB> "" o=nonexistant "" , "" (cn=*) "" , search_scope = SUBTREE , attributes = [ "" cn "" , "" sn "" ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _ , result = self . connection_1c . get_response ( result ) <TAB> <TAB> self . fail ( "" exception not raised "" ) <TAB> except LDAPNoSuchObjectResult : <TAB> <TAB> pass ","if not self . connection_1c . strategy . sync : 
","if not self . connection_1c . strategy . sync :
",100.0,100.0,True
"def value_from_datadict ( self , data , files , prefix ) : <TAB> count = int ( data [ "" %s -count "" % prefix ] ) <TAB> values_with_indexes = [ ] <TAB> for i in range ( 0 , count ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> values_with_indexes . append ( <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> int ( data [ "" %s - %d -order "" % ( prefix , i ) ] ) , <TAB> <TAB> <TAB> <TAB> self . child_block . value_from_datadict ( <TAB> <TAB> <TAB> <TAB> <TAB> data , files , "" %s - %d -value "" % ( prefix , i ) <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> values_with_indexes . sort ( ) <TAB> return [ v for ( i , v ) in values_with_indexes ] ","if data [ "" %s - %d -deleted "" % ( prefix , i ) ] : 
","if i == count - 1 :
",25.74,1.97,False
"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB> <TAB> if not self . _nchannels : <TAB> <TAB> <TAB> raise Error ( "" # channels not specified "" ) <TAB> <TAB> if not self . _sampwidth : <TAB> <TAB> <TAB> raise Error ( "" sample width not specified "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Error ( "" sampling rate not specified "" ) <TAB> <TAB> self . _write_header ( datasize ) ","if not self . _framerate : 
","if not self . _samprate :
",77.23,64.35,False
def wait_til_ready ( cls ) : <TAB> while True : <TAB> <TAB> now = time . time ( ) <TAB> <TAB> next_iteration = now / / 1.0 + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> await cls . _clock . run_til ( next_iteration ) <TAB> <TAB> await asyncio . sleep ( 1.0 ) ,"if cls . connector . ready : 
","if cls . _clock . is_ready ( next_iteration ) :
",45.27,11.63,False
"def lookup_actions ( self , resp ) : <TAB> actions = { } <TAB> for action , conditions in self . actions . items ( ) : <TAB> <TAB> for condition , opts in conditions : <TAB> <TAB> <TAB> for key , val in condition : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if resp . match ( key [ : - 1 ] , val ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> if not resp . match ( key , val ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> actions [ action ] = opts <TAB> return actions ","if key [ - 1 ] == "" ! "" : 
","if key . endswith ( "" _ "" ) :
",31.78,8.64,False
"def close ( self , wait = True , abort = False ) : <TAB> """"""Close the socket connection."""""" <TAB> if not self . closed and not self . closing : <TAB> <TAB> self . closing = True <TAB> <TAB> self . server . _trigger_event ( "" disconnect "" , self . sid , run_async = False ) <TAB> <TAB> if not abort : <TAB> <TAB> <TAB> self . send ( packet . Packet ( packet . CLOSE ) ) <TAB> <TAB> self . closed = True <TAB> <TAB> self . queue . put ( None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . queue . join ( ) ","if wait : 
","if wait :
",78.12,0.0,False
"def model_parse ( self ) : <TAB> for name , submodel in self . model . named_modules ( ) : <TAB> <TAB> for op_type in SUPPORTED_OP_TYPE : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . target_layer [ name ] = submodel <TAB> <TAB> <TAB> <TAB> self . already_pruned [ name ] = 0 ","if isinstance ( submodel , op_type ) : 
","if op_type in self . model . named_modules ( name ) :
",28.06,12.45,False
"def pack_identifier ( self ) : <TAB> """"""Return a combined identifier for the whole pack if this has more than one episode."""""" <TAB> # Currently only supports ep mode <TAB> if self . id_type == "" ep "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" S %02d E %02d -E %02d "" % ( <TAB> <TAB> <TAB> <TAB> self . season , <TAB> <TAB> <TAB> <TAB> self . episode , <TAB> <TAB> <TAB> <TAB> self . episode + self . episodes - 1 , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . identifier <TAB> else : <TAB> <TAB> return self . identifier ","if self . episodes > 1 : 
","if self . episode < self . episodes - 1 :
",42.15,23.46,False
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> if type ( f ) == unicode : <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> elif not args . content_only : <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res ) ","if type ( v ) == unicode : 
","if type ( v ) == unicode :
",100.0,100.0,True
"def _enable_contours_changed ( self , value ) : <TAB> """"""Turns on and off the contours."""""" <TAB> if self . module_manager is None : <TAB> <TAB> return <TAB> if value : <TAB> <TAB> self . actor . inputs = [ self . contour ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . actor . mapper . scalar_mode = "" use_cell_data "" <TAB> else : <TAB> <TAB> self . actor . inputs = [ self . grid_plane ] <TAB> <TAB> self . actor . mapper . scalar_mode = "" default "" <TAB> self . render ( ) ","if self . contour . filled_contours : 
","if self . contour . grid_plane == "" all "" :
",63.0,28.92,False
"def _apply_abs_paths ( data , script_dir ) : <TAB> for flag_data in data . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> default = flag_data . get ( "" default "" ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> not default <TAB> <TAB> <TAB> or not isinstance ( default , six . string_types ) <TAB> <TAB> <TAB> or os . path . sep not in default <TAB> <TAB> ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> abs_path = os . path . join ( script_dir , default ) <TAB> <TAB> if os . path . exists ( abs_path ) : <TAB> <TAB> <TAB> flag_data [ "" default "" ] = abs_path ","if not isinstance ( flag_data , dict ) : 
","if "" default "" not in flag_data :
",26.82,16.81,False
"def button_release ( self , mapper ) : <TAB> self . pressed = False <TAB> if self . waiting_task and self . active is None and not self . action : <TAB> <TAB> # In HoldModifier, button released before timeout <TAB> <TAB> mapper . cancel_task ( self . waiting_task ) <TAB> <TAB> self . waiting_task = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . normalaction . button_press ( mapper ) <TAB> <TAB> <TAB> mapper . schedule ( 0.02 , self . normalaction . button_release ) <TAB> elif self . active : <TAB> <TAB> # Released held button <TAB> <TAB> self . active . button_release ( mapper ) <TAB> <TAB> self . active = None ","if self . normalaction : 
","if self . normalaction :
",100.0,100.0,True
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> if p and p . isMarked ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> elif wrapped : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p )<TAB> # Sets focus. ","elif p : 
","elif p :
",78.12,0.0,False
"def status ( self , name , error = "" No matching script logs found "" ) : <TAB> with self . script_lock : <TAB> <TAB> if self . script_running and self . script_running [ 1 ] == name : <TAB> <TAB> <TAB> return self . script_running [ 1 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . script_last [ 1 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( error ) ","elif self . script_last and self . script_last [ 1 ] == name : 
","elif self . script_last and self . script_last [ 1 ] == name :
",100.0,100.0,True
"def _stderr_supports_color ( ) : <TAB> try : <TAB> <TAB> if hasattr ( sys . stderr , "" isatty "" ) and sys . stderr . isatty ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> curses . setupterm ( ) <TAB> <TAB> <TAB> <TAB> if curses . tigetnum ( "" colors "" ) > 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> elif colorama : <TAB> <TAB> <TAB> <TAB> if sys . stderr is getattr ( <TAB> <TAB> <TAB> <TAB> <TAB> colorama . initialise , "" wrapped_stderr "" , object ( ) <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> except Exception : <TAB> <TAB> # Very broad exception handling because it's always better to <TAB> <TAB> # fall back to non-colored logs than to break at startup. <TAB> <TAB> pass <TAB> return False ","if curses : 
","if curses :
",78.12,0.0,False
"def main ( ) : <TAB> configFilename = "" twitterbot.ini "" <TAB> if sys . argv [ 1 : ] : <TAB> <TAB> configFilename = sys . argv [ 1 ] <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( ) <TAB> <TAB> load_config ( configFilename ) <TAB> except Exception as e : <TAB> <TAB> print ( "" Error while loading ini file  %s "" % ( configFilename ) , file = sys . stderr ) <TAB> <TAB> print ( e , file = sys . stderr ) <TAB> <TAB> print ( __doc__ , file = sys . stderr ) <TAB> <TAB> sys . exit ( 1 ) <TAB> bot = TwitterBot ( configFilename ) <TAB> return bot . run ( ) ","if not os . path . exists ( configFilename ) : 
","if not os . path . exists ( configFilename ) :
",100.0,100.0,True
def safe_to_kill ( request ) : <TAB> if os . path . exists ( DRAIN_FILE ) : <TAB> <TAB> with open ( DRAIN_FILE ) as f : <TAB> <TAB> <TAB> dt = datetime . datetime . fromtimestamp ( float ( f . read ( ) ) ) <TAB> <TAB> <TAB> delta = datetime . datetime . now ( ) - dt <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return Response ( status_int = 200 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return Response ( status_int = 400 ) <TAB> else : <TAB> <TAB> return Response ( status_int = 400 ) ,"if delta . seconds > 2 : 
","if delta < dt :
",29.24,15.85,False
"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> class_name = parent . name <TAB> <TAB> elif isinstance ( parent , pytest . Module ) : <TAB> <TAB> <TAB> module_name = parent . module . __name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "" .tasks. "" not in module_name : <TAB> <TAB> return "" {} . {} "" . format ( module_name , class_name ) <TAB> else : <TAB> <TAB> return module_name ","if isinstance ( parent , pytest . Class ) : 
","if isinstance ( parent , pytest . Class ) :
",100.0,100.0,True
"def getAllFitsLite ( ) : <TAB> fits = eos . db . getFitListLite ( ) <TAB> shipMap = { f . shipID : None for f in fits } <TAB> for shipID in shipMap : <TAB> <TAB> ship = eos . db . getItem ( shipID ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shipMap [ shipID ] = ( ship . name , ship . getShortName ( ) ) <TAB> fitsToPurge = set ( ) <TAB> for fit in fits : <TAB> <TAB> try : <TAB> <TAB> <TAB> fit . shipName , fit . shipNameShort = shipMap [ fit . shipID ] <TAB> <TAB> except ( KeyError , TypeError ) : <TAB> <TAB> <TAB> fitsToPurge . add ( fit ) <TAB> for fit in fitsToPurge : <TAB> <TAB> fits . remove ( fit ) <TAB> return fits ","if ship is not None : 
","if ship :
",29.58,0.0,False
"def _process ( self , event_data ) : <TAB> self . machine . callbacks ( self . machine . prepare_event , event_data ) <TAB> _LOGGER . debug ( <TAB> <TAB> "" %s Executed machine preparation callbacks before conditions. "" , self . machine . name <TAB> ) <TAB> try : <TAB> <TAB> for trans in self . transitions [ event_data . state . name ] : <TAB> <TAB> <TAB> event_data . transition = trans <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> event_data . result = True <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as err : <TAB> <TAB> event_data . error = err <TAB> <TAB> raise <TAB> finally : <TAB> <TAB> self . machine . callbacks ( self . machine . finalize_event , event_data ) <TAB> <TAB> _LOGGER . debug ( "" %s Executed machine finalize callbacks "" , self . machine . name ) <TAB> return event_data . result ","if trans . execute ( event_data ) : 
","if trans . state . name in event_data . state . name :
",36.27,17.1,False
"def fetch_comments ( self , force = False , limit = None ) : <TAB> comments = [ ] <TAB> if ( force is True ) or ( self . badges [ "" comments "" ] > 0 ) : <TAB> <TAB> query_params = { "" filter "" : "" commentCard,copyCommentCard "" } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> query_params [ "" limit "" ] = limit <TAB> <TAB> comments = self . client . fetch_json ( <TAB> <TAB> <TAB> "" /cards/ "" + self . id + "" /actions "" , query_params = query_params <TAB> <TAB> ) <TAB> <TAB> return sorted ( comments , key = lambda comment : comment [ "" date "" ] ) <TAB> return comments ","if limit is not None : 
","if limit is not None :
",100.0,100.0,True
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> if result == self . source : <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> if start < last_end : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( ) ","if not self . _is_expression ( ) : 
","if end == last_end :
",26.79,5.0,False
"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> if builtins . __xonsh__ . env . get ( "" FORCE_POSIX_PATHS "" ) : <TAB> <TAB> <TAB> x = x . replace ( os . sep , os . altsep ) <TAB> <TAB> return x <TAB> else : <TAB> <TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB> <TAB> if x . startswith ( home ) : <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> return x ","if x . startswith ( home ) : 
","if x . startswith ( home ) :
",100.0,100.0,True
"def project_review ( plans ) : <TAB> for plan in plans : <TAB> <TAB> print ( "" Inspecting  {}  plan "" . format ( plan ) ) <TAB> <TAB> branches = get_branches_from_plan ( plan ) <TAB> <TAB> for branch in branches : <TAB> <TAB> <TAB> build_results = get_results_from_branch ( branch ) <TAB> <TAB> <TAB> for build in build_results : <TAB> <TAB> <TAB> <TAB> build_key = build . get ( "" buildResultKey "" ) or None <TAB> <TAB> <TAB> <TAB> print ( "" Inspecting build -  {} "" . format ( build_key ) ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> for status in STATUS_CLEANED_RESULTS : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> remove_build_result ( build_key = build_key , status = status ) ","if build_key : 
","if build_key :
",78.12,100.0,True
"def _check_for_batch_clashes ( xs ) : <TAB> """"""Check that batch names do not overlap with sample names."""""" <TAB> names = set ( [ x [ "" description "" ] for x in xs ] ) <TAB> dups = set ( [ ] ) <TAB> for x in xs : <TAB> <TAB> batches = tz . get_in ( ( "" metadata "" , "" batch "" ) , x ) <TAB> <TAB> if batches : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> batches = [ batches ] <TAB> <TAB> <TAB> for batch in batches : <TAB> <TAB> <TAB> <TAB> if batch in names : <TAB> <TAB> <TAB> <TAB> <TAB> dups . add ( batch ) <TAB> if len ( dups ) > 0 : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Batch names must be unique from sample descriptions. \n "" <TAB> <TAB> <TAB> "" Clashing batch names:  %s "" % sorted ( list ( dups ) ) <TAB> <TAB> ) ","if not isinstance ( batches , ( list , tuple ) ) : 
","if not isinstance ( batches , list ) :
",47.37,43.62,False
"def _check_signal ( self ) : <TAB> """"""Checks if a signal was received and issues a message."""""" <TAB> proc_signal = getattr ( self . proc , "" signal "" , None ) <TAB> if proc_signal is None : <TAB> <TAB> return <TAB> sig , core = proc_signal <TAB> sig_str = SIGNAL_MESSAGES . get ( sig ) <TAB> if sig_str : <TAB> <TAB> if core : <TAB> <TAB> <TAB> sig_str + = ""  (core dumped) "" <TAB> <TAB> print ( sig_str , file = sys . stderr ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . errors + = sig_str + "" \n "" ","if self . errors is not None : 
","if self . errors :
",47.74,38.81,False
"def loadLabelFile ( self , labelpath ) : <TAB> labeldict = { } <TAB> if not os . path . exists ( labelpath ) : <TAB> <TAB> f = open ( labelpath , "" w "" , encoding = "" utf-8 "" ) <TAB> else : <TAB> <TAB> with open ( labelpath , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> data = f . readlines ( ) <TAB> <TAB> <TAB> for each in data : <TAB> <TAB> <TAB> <TAB> file , label = each . split ( "" \t "" ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> label = label . replace ( "" false "" , "" False "" ) <TAB> <TAB> <TAB> <TAB> <TAB> label = label . replace ( "" true "" , "" True "" ) <TAB> <TAB> <TAB> <TAB> <TAB> labeldict [ file ] = eval ( label ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> labeldict [ file ] = [ ] <TAB> return labeldict ","if label : 
","if "" false "" in label :
",33.58,14.54,False
"def exists_col_to_many ( self , select_columns : List [ str ] ) - > bool : <TAB> for column in select_columns : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> root_relation = get_column_root_relation ( column ) <TAB> <TAB> <TAB> if self . is_relation_many_to_many ( <TAB> <TAB> <TAB> <TAB> root_relation <TAB> <TAB> <TAB> ) or self . is_relation_one_to_many ( root_relation ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if is_column_dotted ( column ) : 
","if column . lower ( ) . startswith ( "" relation_ "" ) :
",28.72,6.92,False
"def check_sequence_matches ( seq , template ) : <TAB> i = 0 <TAB> for pattern in template : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pattern = { pattern } <TAB> <TAB> got = set ( seq [ i : i + len ( pattern ) ] ) <TAB> <TAB> assert got == pattern <TAB> <TAB> i + = len ( got ) ","if not isinstance ( pattern , set ) : 
","if isinstance ( pattern , dict ) :
",53.23,37.71,False
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> if module is None or not hasattr ( module , attr ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases : <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( ) ","if hasattr ( module , "" aliases "" ) : 
","if module . aliases ( ) :
",28.03,11.26,False
"def result ( ) : <TAB> # ""global"" does not work here... <TAB> R , V = rays , virtual_rays <TAB> if V is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> V = normalize_rays ( V , lattice ) <TAB> <TAB> if check : <TAB> <TAB> <TAB> R = PointCollection ( V , lattice ) <TAB> <TAB> <TAB> V = PointCollection ( V , lattice ) <TAB> <TAB> <TAB> d = lattice . dimension ( ) <TAB> <TAB> <TAB> if len ( V ) != d - R . dim ( ) or ( R + V ) . dim ( ) != d : <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" virtual rays must be linearly  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" independent and with other rays span the ambient space. "" <TAB> <TAB> <TAB> <TAB> ) <TAB> return RationalPolyhedralFan ( cones , R , lattice , is_complete , V ) ","if normalize : 
","if normalize :
",78.12,0.0,False
"def communicate ( self , _input = None , _timeout = None ) - > Tuple [ bytes , bytes ] : <TAB> if parse_args ( ) . print_commands : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print_stderr ( <TAB> <TAB> <TAB> <TAB> color_line ( "" =>  "" , 14 ) + "" "" . join ( str ( arg ) for arg in self . args ) <TAB> <TAB> <TAB> ) <TAB> stdout , stderr = super ( ) . communicate ( _input , _timeout ) <TAB> self . stdout_text = stdout . decode ( "" utf-8 "" ) if stdout else None <TAB> self . stderr_text = stderr . decode ( "" utf-8 "" ) if stderr else None <TAB> return stdout , stderr ","if self . args != get_sudo_refresh_command ( ) : 
","if self . args :
",45.45,7.83,False
"def convert ( data ) : <TAB> result = [ ] <TAB> for d in data : <TAB> <TAB> # noinspection PyCompatibility <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( ( d [ 0 ] , None , d [ 1 ] ) ) <TAB> <TAB> elif isinstance ( d , basestring ) : <TAB> <TAB> <TAB> result . append ( d ) <TAB> return result ","if isinstance ( d , tuple ) and len ( d ) == 2 : 
","if isinstance ( d , tuple ) :
",50.6,31.98,False
"def validate ( self , value ) : <TAB> try : <TAB> <TAB> value = [ <TAB> <TAB> <TAB> datetime . datetime . strptime ( range , "" % Y- % m- %d % H: % M: % S "" ) <TAB> <TAB> <TAB> for range in value . split ( ""  to  "" ) <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> except ValueError : <TAB> <TAB> return False ","if ( len ( value ) == 2 ) and ( value [ 0 ] < = value [ 1 ] ) : 
","if len ( value ) == 2 :
",39.65,14.6,False
"def rmdir ( dirname ) : <TAB> if dirname [ - 1 ] == os . sep : <TAB> <TAB> dirname = dirname [ : - 1 ] <TAB> if os . path . islink ( dirname ) : <TAB> <TAB> return<TAB> # do not clear link - we can get out of dir <TAB> for f in os . listdir ( dirname ) : <TAB> <TAB> if f in ( "" . "" , "" .. "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = dirname + os . sep + f <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rmdir ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . unlink ( path ) <TAB> os . rmdir ( dirname ) ","if os . path . isdir ( path ) : 
","if os . path . isdir ( path ) :
",100.0,100.0,True
"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB> <TAB> if not l : <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l . split ( "" : "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setSlides ( res ) ","if len ( l ) != 2 : 
","if len ( l ) != 2 :
",100.0,100.0,True
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> if "" init "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if item . nodeid . startswith ( "" tests/infer "" ) : 
","if item . nodeid . startswith ( "" tests/unit "" ) :
",86.85,78.25,False
"def build_message ( self , options , target ) : <TAB> message = multipart . MIMEMultipart ( ) <TAB> for name , value in list ( options . items ( ) ) : <TAB> <TAB> if name == "" EMAIL_BODY "" : <TAB> <TAB> <TAB> self . add_body ( message , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_attachment ( message , value ) <TAB> <TAB> else :<TAB> # From, To, Subject, etc. <TAB> <TAB> <TAB> self . set_option ( message , name , value , target ) <TAB> return message ","elif name == "" EMAIL_ATTACHMENT "" : 
","elif name == "" EMAIL_ATTEMPTS "" :
",74.63,70.71,False
def extend_with_zeroes ( b ) : <TAB> try : <TAB> <TAB> for x in b : <TAB> <TAB> <TAB> x = to_constant ( x ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield ( x ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield ( 0 ) <TAB> <TAB> for _ in range ( 32 ) : <TAB> <TAB> <TAB> yield ( 0 ) <TAB> except Exception as e : <TAB> <TAB> return ,"if isinstance ( x , int ) : 
","if x != 0 :
",26.99,7.65,False
"def _start_cluster ( * , cleanup_atexit = True ) : <TAB> global _default_cluster <TAB> if _default_cluster is None : <TAB> <TAB> cluster_addr = os . environ . get ( "" EDGEDB_TEST_CLUSTER_ADDR "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conn_spec = json . loads ( cluster_addr ) <TAB> <TAB> <TAB> _default_cluster = edgedb_cluster . RunningCluster ( * * conn_spec ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data_dir = os . environ . get ( "" EDGEDB_TEST_DATA_DIR "" ) <TAB> <TAB> <TAB> _default_cluster = _init_cluster ( <TAB> <TAB> <TAB> <TAB> data_dir = data_dir , cleanup_atexit = cleanup_atexit <TAB> <TAB> <TAB> ) <TAB> return _default_cluster ","if cluster_addr : 
","if cluster_addr :
",78.12,100.0,True
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> if line [ 0 ] == "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" ) ","if not line : 
","if not line :
",100.0,100.0,True
"def is_entirely_italic ( line ) : <TAB> style = subs . styles . get ( line . style , SSAStyle . DEFAULT_STYLE ) <TAB> for fragment , sty in parse_tags ( line . text , style , subs . styles ) : <TAB> <TAB> fragment = fragment . replace ( r "" \ h "" , "" "" ) <TAB> <TAB> fragment = fragment . replace ( r "" \ n "" , "" \n "" ) <TAB> <TAB> fragment = fragment . replace ( r "" \ N "" , "" \n "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return True ","if not sty . italic and fragment and not fragment . isspace ( ) : 
","if fragment . startswith ( "" # "" ) or fragment . startswith ( "" # "" ) :
",31.96,6.81,False
def __get_all_nodes ( self ) : <TAB> nodes = [ ] <TAB> next_level = [ self . __tree . get_root ( ) ] <TAB> while len ( next_level ) != 0 : <TAB> <TAB> cur_level = next_level <TAB> <TAB> nodes + = next_level <TAB> <TAB> next_level = [ ] <TAB> <TAB> for cur_node in cur_level : <TAB> <TAB> <TAB> children = cur_node . get_children ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> next_level + = children <TAB> return nodes ,"if children is not None : 
","if children :
",29.58,0.0,False
"def _openvpn_stdout ( self ) : <TAB> while True : <TAB> <TAB> line = self . process . stdout . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> time . sleep ( 0.05 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> yield <TAB> <TAB> try : <TAB> <TAB> <TAB> self . server . output . push_output ( line ) <TAB> <TAB> except : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Failed to push vpn output "" , <TAB> <TAB> <TAB> <TAB> "" server "" , <TAB> <TAB> <TAB> <TAB> server_id = self . server . id , <TAB> <TAB> <TAB> ) <TAB> <TAB> yield ","if self . process . poll ( ) is not None or self . is_interrupted ( ) : 
","if self . process . poll ( ) is not None :
",70.68,47.41,False
"def payment_received_handler ( event ) : <TAB> if isinstance ( event . message . action , types . MessageActionPaymentSentMe ) : <TAB> <TAB> payment : types . MessageActionPaymentSentMe = event . message . action <TAB> <TAB> # do something after payment was received <TAB> <TAB> if payment . payload . decode ( "" UTF-8 "" ) == "" product A "" : <TAB> <TAB> <TAB> await bot . send_message ( <TAB> <TAB> <TAB> <TAB> event . message . from_id , "" Thank you for buying product A! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await bot . send_message ( <TAB> <TAB> <TAB> <TAB> event . message . from_id , "" Thank you for buying product B! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise events . StopPropagation ","elif payment . payload . decode ( "" UTF-8 "" ) == "" product B "" : 
","elif payment . payload . decode ( "" UTF-8 "" ) == "" product B "" :
",100.0,100.0,True
"def spaces_after ( token , prev , next , min = - 1 , max = - 1 , min_desc = None , max_desc = None ) : <TAB> if next is not None and token . end_mark . line == next . start_mark . line : <TAB> <TAB> spaces = next . start_mark . pointer - token . end_mark . pointer <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column , max_desc <TAB> <TAB> <TAB> ) <TAB> <TAB> elif min != - 1 and spaces < min : <TAB> <TAB> <TAB> return LintProblem ( <TAB> <TAB> <TAB> <TAB> token . start_mark . line + 1 , next . start_mark . column + 1 , min_desc <TAB> <TAB> <TAB> ) ","if max != - 1 and spaces > max : 
","if max != - 1 and spaces > max :
",100.0,100.0,True
"def seek_to_block ( self , pos ) : <TAB> baseofs = 0 <TAB> ofs = 0 <TAB> for b in self . blocks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current_block = b <TAB> <TAB> <TAB> break <TAB> <TAB> baseofs + = b . compressed_size <TAB> <TAB> ofs + = b . uncompressed_size <TAB> else : <TAB> <TAB> self . current_block = None <TAB> <TAB> self . current_stream = BytesIO ( b "" "" ) <TAB> <TAB> return <TAB> self . current_block_start = ofs <TAB> self . stream . seek ( self . basepos + baseofs ) <TAB> buf = BytesIO ( self . stream . read ( self . current_block . compressed_size ) ) <TAB> self . current_stream = self . current_block . decompress ( buf ) ","if ofs + b . uncompressed_size > pos : 
","if b . offset == pos :
",33.97,11.35,False
"def rewrite_hunks ( hunks ) : <TAB> # type: (List[Hunk]) -> Iterator[Hunk] <TAB> # Assumes `hunks` are sorted, and from the same file <TAB> deltas = ( hunk . b_length - hunk . a_length for hunk in hunks ) <TAB> offsets = accumulate ( deltas , initial = 0 ) <TAB> for hunk , offset in zip ( hunks , offsets ) : <TAB> <TAB> new_b = hunk . a_start + offset <TAB> <TAB> if hunk_of_additions_only ( hunk ) : <TAB> <TAB> <TAB> new_b + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_b - = 1 <TAB> <TAB> yield hunk . _replace ( b_start = new_b ) ","elif hunk_of_removals_only ( hunk ) : 
","elif hunk_of_removals_only ( hunk ) :
",100.0,100.0,True
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret ","if len ( q ) == 1 : 
","if value :
",26.62,0.0,False
"def get_url ( token , base_url ) : <TAB> """"""Parse an <url> token."""""" <TAB> if token . type == "" url "" : <TAB> <TAB> return _get_url_tuple ( token . value , base_url ) <TAB> elif token . type == "" function "" : <TAB> <TAB> if token . name == "" attr "" : <TAB> <TAB> <TAB> return check_attr_function ( token , "" url "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Ignore url modifiers <TAB> <TAB> <TAB> # See https://drafts.csswg.org/css-values-3/#urls <TAB> <TAB> <TAB> return _get_url_tuple ( token . arguments [ 0 ] . value , base_url ) ","elif token . name == "" url "" and len ( token . arguments ) in ( 1 , 2 ) : 
","elif token . name == "" url_tuple "" :
",43.49,25.93,False
"def read ( self , count ) : <TAB> if self . closed : <TAB> <TAB> return self . upstream . read ( count ) <TAB> try : <TAB> <TAB> while len ( self . upstream ) < count : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> with self . buf_in : <TAB> <TAB> <TAB> <TAB> <TAB> self . transport . downstream_recv ( self . buf_in ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return self . upstream . read ( count ) <TAB> except : <TAB> <TAB> logger . debug ( traceback . format_exc ( ) ) ","if self . buf_in or self . _poll_read ( 10 ) : 
","if self . buf_in :
",42.22,20.15,False
"def get_timestamp_for_block ( <TAB> self , block_hash : HexBytes , max_tries : Optional [ int ] = 10 ) - > int : <TAB> counter = 0 <TAB> block : AttributeDict = None <TAB> if block_hash in self . _block_cache . keys ( ) : <TAB> <TAB> block = self . _block_cache . get ( block_hash ) <TAB> else : <TAB> <TAB> while block is None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValueError ( f "" Block hash  { block_hash . hex ( ) }  does not exist. "" ) <TAB> <TAB> <TAB> counter + = 1 <TAB> <TAB> <TAB> block = self . _block_cache . get ( block_hash ) <TAB> <TAB> <TAB> await asyncio . sleep ( 0.5 ) <TAB> return block . get ( "" timestamp "" ) ","if counter == max_tries : 
","if counter > max_tries :
",58.14,42.38,False
"def reader ( ) : <TAB> batch_out = [ ] <TAB> for video_name in self . video_list : <TAB> <TAB> video_idx = self . video_list . index ( video_name ) <TAB> <TAB> video_feat = self . load_file ( video_name ) <TAB> <TAB> batch_out . append ( ( video_feat , video_idx ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield batch_out <TAB> <TAB> <TAB> batch_out = [ ] ","if len ( batch_out ) == self . batch_size : 
","if len ( batch_out ) == self . batch_size :
",100.0,100.0,True
"def cleanup ( ) : <TAB> gscript . message ( _ ( "" Erasing temporary files... "" ) ) <TAB> for temp_map , maptype in temp_maps : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gscript . run_command ( <TAB> <TAB> <TAB> <TAB> "" g.remove "" , flags = "" f "" , type = maptype , name = temp_map , quiet = True <TAB> <TAB> <TAB> ) ","if gscript . find_file ( temp_map , element = maptype ) [ "" name "" ] : 
","if not gscript . file_exists ( temp_map ) :
",30.02,14.46,False
"def run ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt ( ) : <TAB> <TAB> <TAB> <TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self . _flow_type == BATCH : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> elif self . _flow_type == REALTIME : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = False ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> continue ","if self . _has_stop_signal ( raw_inputs ) : 
","if raw_inputs is None :
",26.99,8.86,False
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB> <TAB> <TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sent . append ( self . handle_word ( child ) ) <TAB> <TAB> elif child . tag not in self . tags_to_ignore : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent ) ","elif child . tag in ( "" w "" , "" c "" ) : 
","elif child . tag == "" w "" :
",47.56,23.83,False
"def bind_subscribers_to_graphql_type ( self , graphql_type ) : <TAB> for field , subscriber in self . _subscribers . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Field  %s  is not defined on type  %s "" % ( field , self . name ) ) <TAB> <TAB> graphql_type . fields [ field ] . subscribe = subscriber ","if field not in graphql_type . fields : 
","if field not in graphql_type . fields :
",100.0,100.0,True
"def _get_from_json ( self , * , name , version ) : <TAB> url = urljoin ( self . url , posixpath . join ( name , str ( version ) , "" json "" ) ) <TAB> async with aiohttp_session ( auth = self . auth ) as session : <TAB> <TAB> async with session . get ( url ) as response : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise PackageNotFoundError ( package = name , url = url ) <TAB> <TAB> <TAB> response . raise_for_status ( ) <TAB> <TAB> <TAB> response = await response . json ( ) <TAB> dist = response [ "" info "" ] [ "" requires_dist "" ] or [ ] <TAB> if dist : <TAB> <TAB> return dist <TAB> # If no requires_dist then package metadata can be broken. <TAB> # Let's check distribution files. <TAB> return await self . _get_from_files ( response [ "" urls "" ] ) ","if response . status == 404 : 
","if response . status == 404 :
",100.0,100.0,True
"def is_active ( self ) : <TAB> if not self . pk : <TAB> <TAB> log_level = get_setting ( "" LOG_MISSING_SWITCHES "" ) <TAB> <TAB> if log_level : <TAB> <TAB> <TAB> logger . log ( log_level , "" Switch  %s  not found "" , self . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> switch , _created = Switch . objects . get_or_create ( <TAB> <TAB> <TAB> <TAB> name = self . name , defaults = { "" active "" : get_setting ( "" SWITCH_DEFAULT "" ) } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cache = get_cache ( ) <TAB> <TAB> <TAB> cache . set ( self . _cache_key ( self . name ) , switch ) <TAB> <TAB> return get_setting ( "" SWITCH_DEFAULT "" ) <TAB> return self . active ","if get_setting ( "" CREATE_MISSING_SWITCHES "" ) : 
","elif get_setting ( "" SWITCH_DEFAULT "" ) :
",51.0,36.96,False
"def add_requirements ( self , requirements ) : <TAB> if self . _legacy : <TAB> <TAB> self . _legacy . add_requirements ( requirements ) <TAB> else : <TAB> <TAB> run_requires = self . _data . setdefault ( "" run_requires "" , [ ] ) <TAB> <TAB> always = None <TAB> <TAB> for entry in run_requires : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> always = entry <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if always is None : <TAB> <TAB> <TAB> always = { "" requires "" : requirements } <TAB> <TAB> <TAB> run_requires . insert ( 0 , always ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rset = set ( always [ "" requires "" ] ) | set ( requirements ) <TAB> <TAB> <TAB> always [ "" requires "" ] = sorted ( rset ) ","if "" environment "" not in entry and "" extra "" not in entry : 
","if entry . get ( "" requires "" ) . issubset ( requirements ) :
",31.5,3.93,False
"def display_failures_for_single_test ( result : TestResult ) - > None : <TAB> """"""Display a failure for a single method / endpoint."""""" <TAB> display_subsection ( result ) <TAB> checks = _get_unique_failures ( result . checks ) <TAB> for idx , check in enumerate ( checks , 1 ) : <TAB> <TAB> message : Optional [ str ] <TAB> <TAB> if check . message : <TAB> <TAB> <TAB> message = f "" { idx } .  { check . message } "" <TAB> <TAB> else : <TAB> <TAB> <TAB> message = None <TAB> <TAB> example = cast ( Case , check . example )<TAB> # filtered in `_get_unique_failures` <TAB> <TAB> display_example ( example , check . name , message , result . seed ) <TAB> <TAB> # Display every time except the last check <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> click . echo ( "" \n "" ) ","if idx != len ( checks ) : 
","if idx == result . seed - 1 :
",28.22,9.98,False
"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code . co_name == "" trace_types "" <TAB> <TAB> or self . should_trace <TAB> <TAB> and not self . should_trace ( code ) <TAB> ) : <TAB> <TAB> return self <TAB> try : <TAB> <TAB> if event == EVENT_CALL : <TAB> <TAB> <TAB> self . handle_call ( frame ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . handle_return ( frame , arg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self ","elif event == EVENT_RETURN : 
","elif event == EVENT_RETURN :
",100.0,100.0,True
"def get_maps ( test ) : <TAB> pages = set ( ) <TAB> for addr in test [ "" pre "" ] [ "" memory "" ] . keys ( ) : <TAB> <TAB> pages . add ( addr >> 12 ) <TAB> for addr in test [ "" pos "" ] [ "" memory "" ] . keys ( ) : <TAB> <TAB> pages . add ( addr >> 12 ) <TAB> maps = [ ] <TAB> for p in sorted ( pages ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> maps [ - 1 ] = ( maps [ - 1 ] [ 0 ] , maps [ - 1 ] [ 1 ] + 0x1000 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> maps . append ( ( p << 12 , 0x1000 ) ) <TAB> return maps ","if len ( maps ) > 0 and maps [ - 1 ] [ 0 ] + maps [ - 1 ] [ 1 ] == p << 12 : 
","if p == 0 :
",25.27,0.28,False
"def process_rotate_aes_key ( self ) : <TAB> if hasattr ( self . options , "" rotate_aes_key "" ) and isinstance ( <TAB> <TAB> self . options . rotate_aes_key , six . string_types <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . options . rotate_aes_key = True <TAB> <TAB> elif self . options . rotate_aes_key . lower ( ) == "" false "" : <TAB> <TAB> <TAB> self . options . rotate_aes_key = False ","if self . options . rotate_aes_key . lower ( ) == "" true "" : 
","if self . options . rotate_aes_key . lower ( ) == "" true "" :
",100.0,100.0,True
"def apply_figure ( self , figure ) : <TAB> super ( legend_text_legend , self ) . apply_figure ( figure ) <TAB> properties = self . properties . copy ( ) <TAB> with suppress ( KeyError ) : <TAB> <TAB> del properties [ "" margin "" ] <TAB> with suppress ( KeyError ) : <TAB> <TAB> texts = figure . _themeable [ "" legend_text_legend "" ] <TAB> <TAB> for text in texts : <TAB> <TAB> <TAB> if not hasattr ( text , "" _x "" ) :<TAB> # textarea <TAB> <TAB> <TAB> <TAB> text = text . _text <TAB> <TAB> <TAB> text . set ( * * properties ) ","if not hasattr ( text , "" _x "" ) : 
","if not hasattr ( text , "" _x "" ) :
",100.0,100.0,True
"def tearDown ( self ) : <TAB> for i in range ( len ( self . tree ) - 1 , - 1 , - 1 ) : <TAB> <TAB> s = os . path . join ( self . root , self . tree [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . rmdir ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . remove ( s ) <TAB> os . rmdir ( self . root ) ","if not "" . "" in s : 
","if os . path . isdir ( s ) :
",26.67,5.93,False
"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> if type != fields [ - 2 ] : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> itype = fields [ - 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id ","if type != itype : 
","if itype != fields [ - 1 ] :
",27.63,10.55,False
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon : <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> if s . siblingAbove is None : <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ","if matchSelf : 
","if s . siblingAbove is None :
",29.58,7.81,False
"def records ( account_id ) : <TAB> """"""Fetch locks data"""""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB> <TAB> if "" LockDate "" in r : <TAB> <TAB> <TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) ) ","if "" RevisionDate "" in r : 
","if "" RevisionDate "" in r :
",100.0,100.0,True
"def _handle_errors ( errors ) : <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors : <TAB> <TAB> return <TAB> log_all = True<TAB> # pylint: disable=unused-variable <TAB> err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB> print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB> for module , err in errors : <TAB> <TAB> err_str = str ( err ) <TAB> <TAB> if log_all : <TAB> <TAB> <TAB> print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" From module  %s "" % module ) <TAB> <TAB> <TAB> raise err ","if not _is_import_err_msg ( err_str , module ) : 
","if err_str != "" no such module "" :
",26.71,9.09,False
"def find_needle ( self , tree , focused = None ) : <TAB> if isinstance ( tree , list ) : <TAB> <TAB> for el in tree : <TAB> <TAB> <TAB> res = self . find_needle ( el , focused ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return res <TAB> elif isinstance ( tree , dict ) : <TAB> <TAB> nodes = tree . get ( "" nodes "" , [ ] ) + tree . get ( "" floating_nodes "" , [ ] ) <TAB> <TAB> if focused : <TAB> <TAB> <TAB> for node in nodes : <TAB> <TAB> <TAB> <TAB> if node [ "" id "" ] == focused [ "" id "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return tree <TAB> <TAB> elif tree [ "" focused "" ] : <TAB> <TAB> <TAB> return tree <TAB> <TAB> return self . find_needle ( nodes , focused ) <TAB> return { } ","if res : 
","if res :
",78.12,0.0,False
"def available_datasets ( self ) : <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB> <TAB> if isinstance ( val , netCDF4 . Variable ) : <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB> <TAB> <TAB> <TAB> "" resolution "" : res , <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ds_info [ "" coordinates "" ] = coordinates <TAB> <TAB> <TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info ","if not self . is_geo : 
","if val . get_coordinates ( ) :
",33.68,6.74,False
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB> <TAB> test_path = k . get_path ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sub = test_path [ len ( parent_path ) : ] <TAB> <TAB> <TAB> if sub . startswith ( "" \\ "" ) : <TAB> <TAB> <TAB> <TAB> sub = sub [ 1 : ] <TAB> <TAB> <TAB> end_slash = sub . find ( "" \\ "" ) <TAB> <TAB> <TAB> if end_slash > = 0 : <TAB> <TAB> <TAB> <TAB> sub = sub [ : end_slash ] <TAB> <TAB> <TAB> if not sub : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys . append ( sub ) <TAB> return subkeys ","if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : 
","if test_path . startswith ( parent_path ) :
",40.79,39.59,False
"def default ( self , o ) : <TAB> try : <TAB> <TAB> if type ( o ) == datetime . datetime : <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr ( o , "" profile "" ) : <TAB> <TAB> <TAB> <TAB> del o . profile <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del o . credentials <TAB> <TAB> <TAB> if hasattr ( o , "" metadata_path "" ) : <TAB> <TAB> <TAB> <TAB> del o . metadata_path <TAB> <TAB> <TAB> if hasattr ( o , "" services_config "" ) : <TAB> <TAB> <TAB> <TAB> del o . services_config <TAB> <TAB> <TAB> return vars ( o ) <TAB> except Exception as e : <TAB> <TAB> return str ( o ) ","if hasattr ( o , "" credentials "" ) : 
","if hasattr ( o , "" credentials "" ) :
",100.0,100.0,True
"def submit ( self , fn , * args , * * kwargs ) : <TAB> with self . _shutdown_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot schedule new futures after shutdown "" ) <TAB> <TAB> f = _base . Future ( ) <TAB> <TAB> w = _WorkItem ( f , fn , args , kwargs ) <TAB> <TAB> self . _work_queue . put ( w ) <TAB> <TAB> self . _adjust_thread_count ( ) <TAB> <TAB> return f ","if self . _shutdown : 
","if self . _shutdown :
",100.0,100.0,True
"def __viewerKeyPress ( viewer , event ) : <TAB> view = viewer . view ( ) <TAB> if not isinstance ( view , GafferSceneUI . SceneView ) : <TAB> <TAB> return False <TAB> if event == __editSourceKeyPress : <TAB> <TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> __editSourceNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB> <TAB> selectedPath = __sceneViewSelectedPath ( view ) <TAB> <TAB> if selectedPath is not None : <TAB> <TAB> <TAB> __editTweaksNode ( view . getContext ( ) , view [ "" in "" ] , selectedPath ) <TAB> <TAB> return True ","if selectedPath is not None : 
","if selectedPath is not None :
",100.0,100.0,True
"def _split_to_option_groups_and_paths ( self , args ) : <TAB> opt_groups = [ ] <TAB> current = [ ] <TAB> for arg in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> opts = self . _arg_parser . parse_args ( current ) [ 0 ] <TAB> <TAB> <TAB> opt_groups . append ( opts ) <TAB> <TAB> <TAB> current = [ ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current . append ( arg ) <TAB> if opt_groups : <TAB> <TAB> return opt_groups , current <TAB> raise ValueError ( "" Nothing to split "" ) ","if arg . replace ( "" - "" , "" "" ) == "" "" and len ( arg ) > = 3 : 
","if arg == "" - "" :
",32.39,4.69,False
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed ","if value : 
","if value :
",78.12,0.0,False
"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB> <TAB> <TAB> if target_pid == pid : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out "" ","if e . args [ 0 ] == errno . ECHILD : 
","if e . args [ 0 ] == errno . ESRCH :
",91.44,84.24,False
"def _get_os_version_lsb_release ( ) : <TAB> try : <TAB> <TAB> output = subprocess . check_output ( "" lsb_release -sri "" , shell = True ) <TAB> <TAB> lines = output . strip ( ) . split ( ) <TAB> <TAB> name , version = lines <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> version = "" "" <TAB> <TAB> return name , version <TAB> except : <TAB> <TAB> return _get_os_version_uname ( ) ","if version . lower ( ) == "" rolling "" : 
","if version == "" "" :
",32.01,17.59,False
"def _check_snapshot_status_healthy ( self , snapshot_uuid ) : <TAB> status = "" "" <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> status , locked = self . _get_snapshot_status ( snapshot_uuid ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> eventlet . sleep ( 2 ) <TAB> except Exception : <TAB> <TAB> with excutils . save_and_reraise_exception ( ) : <TAB> <TAB> <TAB> LOG . exception ( "" Failed to get snapshot status. [ %s ] "" , snapshot_uuid ) <TAB> LOG . debug ( <TAB> <TAB> "" Lun [ %(snapshot)s ], status [ %(status)s ]. "" , <TAB> <TAB> { "" snapshot "" : snapshot_uuid , "" status "" : status } , <TAB> ) <TAB> return status == "" Healthy "" ","if not locked : 
","if not locked :
",100.0,100.0,True
"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMaximizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasPinButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> return n ","if self . HasCloseButton ( ) : 
","if self . HasWindowWindow ( ) :
",63.85,41.11,False
"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB> <TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( key , bytes ) : <TAB> <TAB> <TAB> key = text_type ( key ) . encode ( charset ) <TAB> <TAB> if not isinstance ( value , bytes ) : <TAB> <TAB> <TAB> value = text_type ( value ) . encode ( charset ) <TAB> <TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value ) ","if value is None : 
","if not encode_keys :
",28.41,9.65,False
"def get_response ( self , exc_fmt = None ) : <TAB> self . callback = None <TAB> if __debug__ : <TAB> <TAB> self . parent . _log ( 3 , "" %s : %s .ready.wait "" % ( self . name , self . tag ) ) <TAB> self . ready . wait ( ) <TAB> if self . aborted is not None : <TAB> <TAB> typ , val = self . aborted <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exc_fmt = "" %s  -  %% s "" % typ <TAB> <TAB> raise typ ( exc_fmt % str ( val ) ) <TAB> return self . response ","if exc_fmt is None : 
","if exc_fmt is None :
",100.0,100.0,True
"def extract_items ( self ) : <TAB> responses = self . fetch ( ) <TAB> items = [ ] <TAB> for response in responses : <TAB> <TAB> page_key = response . meta . get ( "" page_key "" ) or response . url <TAB> <TAB> item = { "" key "" : page_key , "" items "" : None , "" templates "" : None } <TAB> <TAB> extracted_items = [ <TAB> <TAB> <TAB> dict ( i ) for i in self . spider . parse ( response ) if not isinstance ( i , Request ) <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> item [ "" items "" ] = extracted_items <TAB> <TAB> <TAB> item [ "" templates "" ] = [ <TAB> <TAB> <TAB> <TAB> i [ "" _template "" ] for i in extracted_items if i . get ( "" _template "" ) <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items ","if extracted_items : 
","if item . get ( "" items "" ) is None :
",29.1,4.46,False
"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB> <TAB> if self . with_centering : <TAB> <TAB> <TAB> self . median [ i ] . update ( xi ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . iqr [ i ] . update ( xi ) <TAB> return self ","if self . with_scaling : 
","if self . with_iqr :
",64.48,64.35,False
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right ","elif not self . word_boundary_char ( text [ left - 1 ] ) : 
","elif self . word_boundary_char ( text [ left ] ) :
",54.59,66.66,False
"def _validate_duplicate_detection_history_time_window ( namespace ) : <TAB> if namespace . duplicate_detection_history_time_window : <TAB> <TAB> if iso8601pattern . match ( namespace . duplicate_detection_history_time_window ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> raise CLIError ( <TAB> <TAB> <TAB> <TAB> "" --duplicate-detection-history-time-window Value Error :  {0}  value is not in ISO 8601 timespan / duration format. e.g. PT10M for duration of 10 min or 00:10:00 for duration of 10 min "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> namespace . duplicate_detection_history_time_window <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","elif timedeltapattern . match ( namespace . duplicate_detection_history_time_window ) : 
","elif durationpattern . match ( namespace . duplicate_detection_history_time_window ) :
",89.36,89.16,False
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB> <TAB> test_path = k . get_path ( ) <TAB> <TAB> if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB> <TAB> <TAB> sub = test_path [ len ( parent_path ) : ] <TAB> <TAB> <TAB> if sub . startswith ( "" \\ "" ) : <TAB> <TAB> <TAB> <TAB> sub = sub [ 1 : ] <TAB> <TAB> <TAB> end_slash = sub . find ( "" \\ "" ) <TAB> <TAB> <TAB> if end_slash > = 0 : <TAB> <TAB> <TAB> <TAB> sub = sub [ : end_slash ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys . append ( sub ) <TAB> return subkeys ","if not sub : 
","if sub == "" \\ "" :
",28.57,6.27,False
"def generator ( self , data ) : <TAB> <MASK> <TAB> <TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB> <TAB> for var , val in task . environment_variables ( ) : <TAB> <TAB> <TAB> if self . _config . SILENT : <TAB> <TAB> <TAB> <TAB> if var in silent_vars : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int ( task . UniqueProcessId ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( task . ImageFileName ) , <TAB> <TAB> <TAB> <TAB> <TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( var ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( val ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) ","if self . _config . SILENT : 
","if self . _config . Silent :
",82.41,70.71,False
"def start_requests ( self ) : <TAB> if self . fail_before_yield : <TAB> <TAB> 1 / 0 <TAB> for s in range ( 100 ) : <TAB> <TAB> qargs = { "" total "" : 10 , "" seed "" : s } <TAB> <TAB> url = self . mockserver . url ( "" /follow? %s "" ) % urlencode ( qargs , doseq = 1 ) <TAB> <TAB> yield Request ( url , meta = { "" seed "" : s } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> 2 / 0 <TAB> assert self . seedsseen , "" All start requests consumed before any download happened "" ","if self . fail_yielding : 
","if self . fail_before_yield :
",64.48,46.71,False
"def populateGridlines ( self ) : <TAB> cTicks = self . getSystemCurve ( self . ticksId ) <TAB> cGridlines = self . getSystemCurve ( self . gridlinesId ) <TAB> cGridlines . clearPoints ( ) <TAB> nTicks = cTicks . getNPoints ( ) <TAB> for iTick in range ( nTicks ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p = cTicks . getPoint ( iTick ) <TAB> <TAB> <TAB> cGridlines . addPoint ( p . getX ( ) , p . getY ( ) ) ","if self . hasGridlines and ( iTick % self . ticksPerGridline ) == 0 : 
","if cTicks . hasPoint ( iTick ) :
",32.99,5.35,False
"def handle_before_events ( request , event_list ) : <TAB> if not event_list : <TAB> <TAB> return "" "" <TAB> if not hasattr ( event_list , "" __iter__ "" ) : <TAB> <TAB> project = event_list . project <TAB> <TAB> event_list = [ event_list ] <TAB> else : <TAB> <TAB> projects = set ( e . project for e in event_list ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> project = projects . pop ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> project = None <TAB> for plugin in plugins . for_project ( project ) : <TAB> <TAB> safe_execute ( plugin . before_events , request , event_list ) <TAB> return "" "" ","if len ( projects ) == 1 : 
","if projects :
",26.73,0.0,False
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> <TAB> if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 : <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args ) ","if self . mutually_exclusive . intersection ( opts ) : 
","if self . multiple and len ( opts [ self . name ] ) > 1 :
",34.94,12.04,False
"def current_word ( cursor_offset , line ) : <TAB> """"""the object.attribute.attribute just before or under the cursor"""""" <TAB> pos = cursor_offset <TAB> start = pos <TAB> end = pos <TAB> word = None <TAB> for m in current_word_re . finditer ( line ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> start = m . start ( 1 ) <TAB> <TAB> <TAB> end = m . end ( 1 ) <TAB> <TAB> <TAB> word = m . group ( 1 ) <TAB> if word is None : <TAB> <TAB> return None <TAB> return LinePart ( start , end , word ) ","if m . start ( 1 ) < pos and m . end ( 1 ) > = pos : 
","if m . start ( 1 ) < start :
",43.28,28.79,False
"def query_to_script_path ( path , query ) : <TAB> if path != "" * "" : <TAB> <TAB> script = os . path . join ( path , query . split ( "" "" ) [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IOError ( "" Script  ' {} '  not found in script directory "" . format ( query ) ) <TAB> <TAB> return os . path . join ( path , query ) . split ( "" "" ) <TAB> return query ","if not os . path . exists ( script ) : 
","if not os . path . exists ( script ) :
",100.0,100.0,True
"def expand ( self , pbegin ) : <TAB> # TODO(b/151921205): we have to do an identity map for unmodified <TAB> # PCollections below because otherwise we get an error from beam. <TAB> identity_map = "" Identity "" >> beam . Map ( lambda x : x ) <TAB> if self . _dataset_key . is_flattened_dataset_key ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _flat_pcollection | identity_map <TAB> <TAB> else : <TAB> <TAB> <TAB> return list ( <TAB> <TAB> <TAB> <TAB> self . _pcollection_dict . values ( ) <TAB> <TAB> <TAB> ) | "" FlattenAnalysisInputs "" >> beam . Flatten ( pipeline = pbegin . pipeline ) <TAB> else : <TAB> <TAB> return self . _pcollection_dict [ self . _dataset_key ] | identity_map ","if self . _flat_pcollection : 
","if self . _flat_pcollection :
",100.0,100.0,True
"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB> <TAB> for _dir , offsets in faceDirections : <TAB> <TAB> <TAB> if _dir == FaceYIncreasing : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx , dy , dz = offsets <TAB> <TAB> <TAB> p = ( x + dx , y + dy , z + dz ) <TAB> <TAB> <TAB> if p not in box : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx , ny , nz = p <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB> <TAB> <TAB> <TAB> newcoords . append ( p ) <TAB> return newcoords ","if level . blockAt ( nx , ny , nz ) == 0 : 
","if nx != ny and nz != None :
",26.1,4.24,False
"def delete_byfilter ( userId , remove = True , session = None , * * dbfilter ) : <TAB> if not session : <TAB> <TAB> session = db . Session <TAB> ret = False <TAB> results = session . query ( ObjectStorageMetadata ) . filter_by ( * * dbfilter ) <TAB> if results : <TAB> <TAB> for result in results : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> session . delete ( result ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" record_state_key "" : "" to_delete "" , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" record_state_val "" : str ( time . time ( ) ) , <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ret = True <TAB> return ret ","if remove : 
","if remove :
",78.12,0.0,False
"def fields ( self , fields ) : <TAB> fields_xml = "" "" <TAB> for field in fields : <TAB> <TAB> field_dict = DEFAULT_FIELD . copy ( ) <TAB> <TAB> field_dict . update ( field ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field_dict [ "" required "" ] = "" true "" <TAB> <TAB> fields_xml + = FIELD_XML_TEMPLATE % field_dict + "" \n "" <TAB> self . xml = force_unicode ( <TAB> <TAB> force_unicode ( self . xml ) . replace ( <TAB> <TAB> <TAB> u "" <!-- REPLACE FIELDS --> "" , force_unicode ( fields_xml ) <TAB> <TAB> ) <TAB> ) ","if self . unique_key_field == field [ "" name "" ] : 
","if field . get ( "" required "" ) :
",34.71,3.26,False
"def get_all_users ( self , access_token , timeout = None ) : <TAB> if timeout is None : <TAB> <TAB> timeout = DEFAULT_TIMEOUT <TAB> headers = self . retrieve_header ( access_token ) <TAB> try : <TAB> <TAB> response = await self . standard_request ( <TAB> <TAB> <TAB> "" get "" , "" /walkoff/api/users "" , timeout = DEFAULT_TIMEOUT , headers = headers <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resp = await response . json ( ) <TAB> <TAB> <TAB> return resp , "" Success "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" Invalid Credentials "" <TAB> except asyncio . CancelledError : <TAB> <TAB> return False , "" TimedOut "" ","if response . status == 200 : 
","if response and response . status == 200 :
",75.48,68.66,False
"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB> <TAB> row = model [ idx ] <TAB> <TAB> if value and row [ 0 ] == value : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB> <TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB> <TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB> <TAB> return None ","if idx == len ( os_widget . get_model ( ) ) - 1 : 
","if idx == len ( model ) - 1 :
",47.49,34.72,False
"def translate_module_name ( module : str , relative : int ) - > Tuple [ str , int ] : <TAB> for pkg in VENDOR_PACKAGES : <TAB> <TAB> for alt in "" six.moves "" , "" six "" : <TAB> <TAB> <TAB> substr = "" {} . {} "" . format ( pkg , alt ) <TAB> <TAB> <TAB> if module . endswith ( "" . "" + substr ) or ( module == substr and relative ) : <TAB> <TAB> <TAB> <TAB> return alt , 0 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return alt + "" . "" + module . partition ( "" . "" + substr + "" . "" ) [ 2 ] , 0 <TAB> return module , relative ","if "" . "" + substr + "" . "" in module : 
","if module . startswith ( "" . "" + substr ) and relative :
",51.56,30.79,False
"def escape ( m ) : <TAB> all , tail = m . group ( 0 , 1 ) <TAB> assert all . startswith ( "" \\ "" ) <TAB> esc = simple_escapes . get ( tail ) <TAB> if esc is not None : <TAB> <TAB> return esc <TAB> if tail . startswith ( "" x "" ) : <TAB> <TAB> hexes = tail [ 1 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB> <TAB> try : <TAB> <TAB> <TAB> i = int ( hexes , 16 ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" invalid hex string escape ( ' \\ %s ' ) "" % tail ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> i = int ( tail , 8 ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( "" invalid octal string escape ( ' \\ %s ' ) "" % tail ) <TAB> return chr ( i ) ","if len ( hexes ) < 2 : 
","if len ( hexes ) != 16 :
",77.42,46.71,False
"def __get_k8s_container_name ( self , job_wrapper ) : <TAB> # These must follow a specific regex for Kubernetes. <TAB> raw_id = job_wrapper . job_destination . id <TAB> if isinstance ( raw_id , str ) : <TAB> <TAB> cleaned_id = re . sub ( "" [^-a-z0-9] "" , "" - "" , raw_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cleaned_id = "" x %s x "" % cleaned_id <TAB> <TAB> return cleaned_id <TAB> return "" job-container "" ","if cleaned_id . startswith ( "" - "" ) or cleaned_id . endswith ( "" - "" ) : 
","if not job_wrapper . is_running :
",30.08,1.71,False
"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB> <TAB> yc / / = 10 <TAB> <TAB> ye + = 1 <TAB> if xc == 1 : <TAB> <TAB> xe * = yc <TAB> <TAB> while xe % 10 == 0 : <TAB> <TAB> <TAB> xe / / = 10 <TAB> <TAB> <TAB> ye + = 1 <TAB> <TAB> if ye < 0 : <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 * * ye <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else : <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5 ","if y and xe : 
","if exponent > 1 :
",28.25,12.7,False
"def lpush ( key , * vals , * * kwargs ) : <TAB> ttl = kwargs . get ( "" ttl "" ) <TAB> cap = kwargs . get ( "" cap "" ) <TAB> if not ttl and not cap : <TAB> <TAB> _client . lpush ( key , * vals ) <TAB> else : <TAB> <TAB> pipe = _client . pipeline ( ) <TAB> <TAB> pipe . lpush ( key , * vals ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pipe . ltrim ( key , 0 , cap ) <TAB> <TAB> if ttl : <TAB> <TAB> <TAB> pipe . expire ( key , ttl ) <TAB> <TAB> pipe . execute ( ) ","if cap : 
","if cap :
",78.12,0.0,False
"def render_headers ( self ) - > bytes : <TAB> if not hasattr ( self , "" _headers "" ) : <TAB> <TAB> parts = [ <TAB> <TAB> <TAB> b "" Content-Disposition: form-data;  "" , <TAB> <TAB> <TAB> format_form_param ( "" name "" , self . name ) , <TAB> <TAB> ] <TAB> <TAB> if self . filename : <TAB> <TAB> <TAB> filename = format_form_param ( "" filename "" , self . filename ) <TAB> <TAB> <TAB> parts . extend ( [ b "" ;  "" , filename ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> content_type = self . content_type . encode ( ) <TAB> <TAB> <TAB> parts . extend ( [ b "" \r \n Content-Type:  "" , content_type ] ) <TAB> <TAB> parts . append ( b "" \r \n \r \n "" ) <TAB> <TAB> self . _headers = b "" "" . join ( parts ) <TAB> return self . _headers ","if self . content_type is not None : 
","if self . content_type :
",47.74,54.78,False
"def validate_custom_field_data ( field_type : int , field_data : ProfileFieldData ) - > None : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Choice type field must have at least have one choice <TAB> <TAB> <TAB> if len ( field_data ) < 1 : <TAB> <TAB> <TAB> <TAB> raise JsonableError ( _ ( "" Field must have at least one choice. "" ) ) <TAB> <TAB> <TAB> validate_choice_field_data ( field_data ) <TAB> <TAB> elif field_type == CustomProfileField . EXTERNAL_ACCOUNT : <TAB> <TAB> <TAB> validate_external_account_field_data ( field_data ) <TAB> except ValidationError as error : <TAB> <TAB> raise JsonableError ( error . message ) ","if field_type == CustomProfileField . CHOICE : 
","if field_type == CustomProfileField . Choice :
",82.41,78.25,False
"def get_data ( self , path ) : <TAB> """"""Gross hack to contort loader to deal w/ load_*()'s bad API."""""" <TAB> if self . file and path == self . path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> file = self . file <TAB> <TAB> else : <TAB> <TAB> <TAB> self . file = file = open ( self . path , "" r "" ) <TAB> <TAB> with file : <TAB> <TAB> <TAB> # Technically should be returning bytes, but <TAB> <TAB> <TAB> # SourceLoader.get_code() just passed what is returned to <TAB> <TAB> <TAB> # compile() which can handle str. And converting to bytes would <TAB> <TAB> <TAB> # require figuring out the encoding to decode to and <TAB> <TAB> <TAB> # tokenize.detect_encoding() only accepts bytes. <TAB> <TAB> <TAB> return file . read ( ) <TAB> else : <TAB> <TAB> return super ( ) . get_data ( path ) ","if not self . file . closed : 
","if isinstance ( self . file , bytes ) :
",36.77,17.75,False
"def handle_read ( self ) : <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try : <TAB> <TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB> <TAB> pass <TAB> except socket . error : <TAB> <TAB> self . handle_error ( ) <TAB> else : <TAB> <TAB> self . tot_bytes_received + = len ( chunk ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . transfer_finished = True <TAB> <TAB> <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> if self . _data_wrapper is not None : <TAB> <TAB> <TAB> chunk = self . _data_wrapper ( chunk ) <TAB> <TAB> try : <TAB> <TAB> <TAB> self . file_obj . write ( chunk ) <TAB> <TAB> except OSError as err : <TAB> <TAB> <TAB> raise _FileReadWriteError ( err ) ","if not chunk : 
","if not chunk :
",100.0,100.0,True
"def _swig_extract_dependency_files ( self , src ) : <TAB> dep = [ ] <TAB> for line in open ( src ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line = line . split ( "" "" ) [ 1 ] . strip ( """""" ' "" \r \n """""" ) <TAB> <TAB> <TAB> if not ( "" < "" in line or line in dep ) : <TAB> <TAB> <TAB> <TAB> dep . append ( line ) <TAB> return [ i for i in dep if os . path . exists ( i ) ] ","if line . startswith ( "" #include "" ) or line . startswith ( "" %i nclude "" ) : 
","if line . startswith ( "" <dependency file "" ) :
",57.23,23.08,False
"def buffer ( self , lines , scroll_end = True , scroll_if_editing = False ) : <TAB> "" Add data to be displayed in the buffer. "" <TAB> self . values . extend ( lines ) <TAB> if scroll_end : <TAB> <TAB> if not self . editing : <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . start_display_at = len ( self . values ) - len ( self . _my_widgets ) ","elif scroll_if_editing : 
","elif scroll_if_editing :
",78.12,100.0,True
"def test_getline ( self ) : <TAB> with tokenize . open ( self . file_name ) as fp : <TAB> <TAB> for index , line in enumerate ( fp ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> line + = "" \n "" <TAB> <TAB> <TAB> cached_line = linecache . getline ( self . file_name , index + 1 ) <TAB> <TAB> <TAB> self . assertEqual ( line , cached_line ) ","if not line . endswith ( "" \n "" ) : 
","if line and not line . endswith ( "" \n "" ) :
",85.47,77.44,False
"def selectRow ( self , rowNumber , highlight = None ) : <TAB> if rowNumber == "" h "" : <TAB> <TAB> rowNumber = 0 <TAB> else : <TAB> <TAB> rowNumber = int ( rowNumber ) + 1 <TAB> if 1 > rowNumber > = len ( self . cells ) + 1 : <TAB> <TAB> raise Exception ( "" Invalid row number. "" ) <TAB> else : <TAB> <TAB> selected = self . cells [ rowNumber ] [ 0 ] . selected <TAB> <TAB> for cell in self . cells [ rowNumber ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if selected : <TAB> <TAB> <TAB> <TAB> <TAB> cell . deselect ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> cell . select ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if highlight : <TAB> <TAB> <TAB> <TAB> <TAB> cell . mouseEnter ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> cell . mouseLeave ( ) ","if highlight is None : 
","if cell . isVisible ( ) :
",27.53,7.81,False
"def put ( self , session ) : <TAB> with sess_lock : <TAB> <TAB> self . parent . put ( session ) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self . skip_paths : <TAB> <TAB> <TAB> if request . path . startswith ( sp ) : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> del self . _cache [ session . sid ] <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . _cache [ session . sid ] = session <TAB> self . _normalize ( ) ","if session . sid in self . _cache : 
","if session . sid in self . _cache :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 18 : 
","if tt == 18 :
",100.0,100.0,True
"def extract ( self , zip ) : <TAB> max_nb = maxNbFile ( self ) <TAB> for index , field in enumerate ( zip . array ( "" file "" ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . warning ( <TAB> <TAB> <TAB> <TAB> "" ZIP archive contains many files, but only first  %s  files are processed "" <TAB> <TAB> <TAB> <TAB> % max_nb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . processFile ( field ) ","if max_nb is not None and max_nb < = index : 
","if index > = max_nb :
",33.44,10.59,False
"def get_norm ( norm , out_channels ) : <TAB> if isinstance ( norm , str ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> norm = { <TAB> <TAB> <TAB> "" BN "" : BatchNorm2d , <TAB> <TAB> <TAB> "" GN "" : lambda channels : nn . GroupNorm ( 32 , channels ) , <TAB> <TAB> <TAB> "" nnSyncBN "" : nn . SyncBatchNorm ,<TAB> # keep for debugging <TAB> <TAB> <TAB> "" "" : lambda x : x , <TAB> <TAB> } [ norm ] <TAB> return norm ( out_channels ) ","if len ( norm ) == 0 : 
","if norm == "" "" :
",27.09,12.41,False
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self . _dicts : <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr ","elif self . _aggregate_rows : 
","elif self . _aggregate :
",64.48,56.98,False
"def emitIpToDomainsData ( self , data , event ) : <TAB> self . emitRawRirData ( data , event ) <TAB> domains = data . get ( "" domains "" ) <TAB> if isinstance ( domains , list ) : <TAB> <TAB> for domain in domains : <TAB> <TAB> <TAB> if self . checkForStop ( ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> domain = domain . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . emitHostname ( domain , event ) ","if domain : 
","if domain and domain != "" / "" :
",33.05,9.29,False
"def delete ( self ) : <TAB> from weblate . trans . models import Change , Suggestion , Vote <TAB> fast_deletes = [ ] <TAB> for item in self . fast_deletes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fast_deletes . append ( Vote . objects . filter ( suggestion__in = item ) ) <TAB> <TAB> <TAB> fast_deletes . append ( Change . objects . filter ( suggestion__in = item ) ) <TAB> <TAB> fast_deletes . append ( item ) <TAB> self . fast_deletes = fast_deletes <TAB> return super ( ) . delete ( ) ","if item . model is Suggestion : 
","if isinstance ( item , Suggestion ) :
",27.13,7.81,False
"def token ( self ) : <TAB> if not self . _token : <TAB> <TAB> try : <TAB> <TAB> <TAB> cookie_token = self . state [ "" request "" ] . headers . cookie [ CSRF_TOKEN ] . value <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> cookie_token = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _token = cookie_token <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _token = get_random_string ( TOKEN_LENGTH ) <TAB> return self . _token ","if len ( cookie_token ) == TOKEN_LENGTH : 
","if cookie_token :
",26.73,9.12,False
"def get_logs ( last_file = None , last_time = None ) : <TAB> try : <TAB> <TAB> response = client . get_logs ( last_file = last_file , last_time = last_time ) <TAB> <TAB> get_logs_streamer ( <TAB> <TAB> <TAB> show_timestamp = not hide_time , <TAB> <TAB> <TAB> all_containers = all_containers , <TAB> <TAB> <TAB> all_info = all_info , <TAB> <TAB> ) ( response ) <TAB> <TAB> return response <TAB> except ( ApiException , HTTPError ) as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> handle_cli_error ( <TAB> <TAB> <TAB> <TAB> e , <TAB> <TAB> <TAB> <TAB> message = "" Could not get logs for run ` {} `. "" . format ( client . run_uuid ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 ) ","if not follow : 
","if client . run_uuid not in [ "" v1.1 "" , "" v1.1 "" ] :
",28.18,2.83,False
"def update ( self , targets ) : <TAB> Section . update ( self , targets ) <TAB> outputNames = set ( ) <TAB> for target in targets : <TAB> <TAB> g = target . globals ( ) <TAB> <TAB> outputNames . update ( [ k for k in g . keys ( ) if k . startswith ( "" output: "" ) ] ) <TAB> rows = [ ] <TAB> outputNames = sorted ( outputNames ) <TAB> for outputName in outputNames : <TAB> <TAB> row = self . __rows . get ( outputName ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> row = _OutputRow ( outputName ) <TAB> <TAB> <TAB> self . __rows [ outputName ] = row <TAB> <TAB> row . update ( targets ) <TAB> <TAB> row . setAlternate ( len ( rows ) % 2 ) <TAB> <TAB> rows . append ( row ) <TAB> self . _mainColumn ( ) [ : ] = rows ","if row is None : 
","if row is None :
",100.0,100.0,True
"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB> <TAB> if git_branch_line . startswith ( "" * "" ) : <TAB> <TAB> <TAB> git_branch_line = git_branch_line [ 1 : ] <TAB> <TAB> git_branch_line = git_branch_line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB> <TAB> <TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned ","if BRANCH_ALIAS_MARKER in git_branch_line : 
","if BRANCH_ALIAS_MARKER in git_branch_line :
",100.0,100.0,True
"def has_bad_headers ( self ) : <TAB> headers = [ self . sender , self . reply_to ] + self . recipients <TAB> for header in headers : <TAB> <TAB> if _has_newline ( header ) : <TAB> <TAB> <TAB> return True <TAB> if self . subject : <TAB> <TAB> if _has_newline ( self . subject ) : <TAB> <TAB> <TAB> for linenum , line in enumerate ( self . subject . split ( "" \r \n "" ) ) : <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if _has_newline ( line ) : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> if len ( line . strip ( ) ) == 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if linenum > 0 and line [ 0 ] not in "" \t "" : 
","if linenum < len ( self . subject ) - 1 :
",26.57,5.37,False
"def resolve_references ( self , note , reflist ) : <TAB> assert len ( note [ "" ids "" ] ) == 1 <TAB> id = note [ "" ids "" ] [ 0 ] <TAB> for ref in reflist : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> ref . delattr ( "" refname "" ) <TAB> <TAB> ref [ "" refid "" ] = id <TAB> <TAB> assert len ( ref [ "" ids "" ] ) == 1 <TAB> <TAB> note . add_backref ( ref [ "" ids "" ] [ 0 ] ) <TAB> <TAB> ref . resolved = 1 <TAB> note . resolved = 1 ","if ref . resolved : 
","if ref . resolved :
",100.0,100.0,True
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist : <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None : <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide ) ","if dist ( currentPos , self . ends [ color ] ) == 1 : 
","if guideDist == minDist :
",25.75,3.65,False
"def __hierarchyViewKeyPress ( hierarchyView , event ) : <TAB> if event == __editSourceKeyPress : <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> __editSourceNode ( <TAB> <TAB> <TAB> <TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True <TAB> elif event == __editTweaksKeyPress : <TAB> <TAB> selectedPath = __hierarchyViewSelectedPath ( hierarchyView ) <TAB> <TAB> if selectedPath is not None : <TAB> <TAB> <TAB> __editTweaksNode ( <TAB> <TAB> <TAB> <TAB> hierarchyView . getContext ( ) , hierarchyView . scene ( ) , selectedPath <TAB> <TAB> <TAB> ) <TAB> <TAB> return True ","if selectedPath is not None : 
","if selectedPath is not None :
",100.0,100.0,True
"def getSubsegments ( self ) : <TAB> for num , localdata in self . lfh . LocalData : <TAB> <TAB> for bucket , seginfo in localdata . SegmentInfo : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield Win32Subsegment ( self . trace , self . heap , seginfo . ActiveSubsegment ) ","if seginfo . ActiveSubsegment == 0 : 
","if seginfo . ActiveSubsegment == 0 :
",100.0,100.0,True
"def test_full_hd_bluray ( self ) : <TAB> cur_test = "" full_hd_bluray "" <TAB> cur_qual = common . Quality . FULLHDBLURAY <TAB> for name , tests in iteritems ( self . test_cases ) : <TAB> <TAB> for test in tests : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( cur_qual , common . Quality . name_quality ( test ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertNotEqual ( cur_qual , common . Quality . name_quality ( test ) ) ","if name == cur_test : 
","if name == cur_test :
",100.0,100.0,True
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res ","elif self . op == "" / "" : 
","elif self . op == "" / "" :
",100.0,100.0,True
"def strip_export_type ( path ) : <TAB> matched = re . search ( r "" #([a-zA-Z0-9 \ -]+ \\ +[a-zA-Z0-9 \ -]+)?$ "" , path . encode ( "" utf-8 "" ) ) <TAB> mime_type = None <TAB> if matched : <TAB> <TAB> fragment = matched . group ( 0 ) <TAB> <TAB> mime_type = matched . group ( 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mime_type = mime_type . replace ( "" + "" , "" / "" ) <TAB> <TAB> path = path [ : - len ( fragment ) ] <TAB> return ( path , mime_type ) ","if mime_type is not None : 
","if mime_type :
",29.58,38.81,False
"def _save_as_module ( file , data , binary = False ) : <TAB> if not data : <TAB> <TAB> return <TAB> with open ( file , "" w "" ) as f : <TAB> <TAB> f . write ( "" DATA= "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f . write ( ' "" ' ) <TAB> <TAB> <TAB> f . write ( base64 . b64encode ( data ) . decode ( "" ascii "" ) ) <TAB> <TAB> <TAB> f . write ( ' "" ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . write ( str ( data ) . replace ( "" \\ \\ "" , "" \\ "" ) ) <TAB> <TAB> f . flush ( ) ","if binary : 
","if binary :
",78.12,0.0,False
"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB> <TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if len ( self . _scopeStrictModes ) > 0 : <TAB> <TAB> <TAB> <TAB> self . _scopeStrictModes . pop ( ) <TAB> <TAB> <TAB> self . _useStrictCurrent = True <TAB> <TAB> <TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent ) ","if text == ' "" use strict "" ' or text == "" ' use strict ' "" : 
","if text and text . strip ( ) == "" ; "" :
",34.07,9.74,False
"def run ( self , ttl = None ) : <TAB> self . zeroconf = zeroconf . Zeroconf ( ) <TAB> zeroconf . ServiceBrowser ( self . zeroconf , self . domain , MDNSHandler ( self ) ) <TAB> if ttl : <TAB> <TAB> gobject . timeout_add ( ttl * 1000 , self . shutdown ) <TAB> self . __running = True <TAB> self . __mainloop = gobject . MainLoop ( ) <TAB> context = self . __mainloop . get_context ( ) <TAB> while self . __running : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> context . iteration ( True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> break <TAB> self . zeroconf . close ( ) <TAB> logger . debug ( "" MDNSListener.run() quit "" ) ","if context . pending ( ) : 
","if context . pending ( ) :
",100.0,100.0,True
"def topology_change_notify ( self , port_state ) : <TAB> notice = False <TAB> if port_state is PORT_STATE_FORWARD : <TAB> <TAB> for port in self . ports . values ( ) : <TAB> <TAB> <TAB> if port . role is DESIGNATED_PORT : <TAB> <TAB> <TAB> <TAB> notice = True <TAB> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> notice = True <TAB> if notice : <TAB> <TAB> self . send_event ( EventTopologyChange ( self . dp ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _transmit_tc_bpdu ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _transmit_tcn_bpdu ( ) ","if self . is_root_bridge : 
","if self . dp . config [ "" topology_change_topology "" ] :
",42.93,10.83,False
def close_open_fds ( keep = None ) :<TAB> # noqa <TAB> keep = [ maybe_fileno ( f ) for f in ( keep or [ ] ) if maybe_fileno ( f ) is not None ] <TAB> for fd in reversed ( range ( get_fdmax ( default = 2048 ) ) ) : <TAB> <TAB> if fd not in keep : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . close ( fd ) <TAB> <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise ,"if exc . errno != errno . EBADF : 
","if exc . errno != errno . ENOTCONN :
",87.71,78.25,False
"def collect_attributes ( options , node , master_list ) : <TAB> """"""Collect all attributes"""""" <TAB> for ii in node . instructions : <TAB> <TAB> if field_check ( ii , "" attributes "" ) : <TAB> <TAB> <TAB> s = getattr ( ii , "" attributes "" ) <TAB> <TAB> <TAB> if isinstance ( s , list ) : <TAB> <TAB> <TAB> <TAB> for x in s : <TAB> <TAB> <TAB> <TAB> <TAB> if x not in master_list : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> master_list . append ( x ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> master_list . append ( s ) <TAB> for nxt in node . next . values ( ) : <TAB> <TAB> collect_attributes ( options , nxt , master_list ) ","elif s != None and s not in master_list : 
","elif isinstance ( s , str ) :
",26.36,3.89,False
"def remove_test_run_directories ( expiry_time : int = 60 * 60 ) - > int : <TAB> removed = 0 <TAB> directories = glob . glob ( os . path . join ( UUID_VAR_DIR , "" test-backend "" , "" run_* "" ) ) <TAB> for test_run in directories : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( test_run ) <TAB> <TAB> <TAB> <TAB> removed + = 1 <TAB> <TAB> <TAB> except FileNotFoundError : <TAB> <TAB> <TAB> <TAB> pass <TAB> return removed ","if round ( time . time ( ) ) - os . path . getmtime ( test_run ) > expiry_time : 
","if os . path . exists ( test_run ) and expiry_time < = time . time ( ) :
",56.67,43.84,False
"def read_work_titles ( fields ) : <TAB> found = [ ] <TAB> if "" 240 "" in fields : <TAB> <TAB> for line in fields [ "" 240 "" ] : <TAB> <TAB> <TAB> title = join_subfield_values ( line , [ "" a "" , "" m "" , "" n "" , "" p "" , "" r "" ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> found . append ( title ) <TAB> if "" 130 "" in fields : <TAB> <TAB> for line in fields [ "" 130 "" ] : <TAB> <TAB> <TAB> title = "" "" . join ( get_lower_subfields ( line ) ) <TAB> <TAB> <TAB> if title not in found : <TAB> <TAB> <TAB> <TAB> found . append ( title ) <TAB> return { "" work_titles "" : found } if found else { } ","if title not in found : 
","if title not in found :
",100.0,100.0,True
"def _process_v1_msg ( prot , msg ) : <TAB> header = None <TAB> body = msg [ 1 ] <TAB> if not isinstance ( body , ( binary_type , mmap , memoryview ) ) : <TAB> <TAB> raise ValidationError ( body , "" Body must be a bytestream. "" ) <TAB> if len ( msg ) > 2 : <TAB> <TAB> header = msg [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( header , "" Header must be a dict. "" ) <TAB> <TAB> for k , v in header . items ( ) : <TAB> <TAB> <TAB> header [ k ] = msgpack . unpackb ( v ) <TAB> ctx = MessagePackMethodContext ( prot , MessagePackMethodContext . SERVER ) <TAB> ctx . in_string = [ body ] <TAB> ctx . transport . in_header = header <TAB> return ctx ","if not isinstance ( header , dict ) : 
","if not isinstance ( header , dict ) :
",100.0,100.0,True
"def find ( self , node ) : <TAB> typename = type ( node ) . __name__ <TAB> method = getattr ( self , "" find_ {} "" . format ( typename ) , None ) <TAB> if method is None : <TAB> <TAB> fields = getattr ( node , "" _fields "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> for field in fields : <TAB> <TAB> <TAB> value = getattr ( node , field ) <TAB> <TAB> <TAB> for result in self . find ( value ) : <TAB> <TAB> <TAB> <TAB> yield result <TAB> else : <TAB> <TAB> for result in method ( node ) : <TAB> <TAB> <TAB> yield result ","if fields is None : 
","if fields is None :
",100.0,100.0,True
"def _str_param_list ( self , name ) : <TAB> out = [ ] <TAB> if self [ name ] : <TAB> <TAB> out + = self . _str_header ( name ) <TAB> <TAB> for param in self [ name ] : <TAB> <TAB> <TAB> parts = [ ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> parts . append ( param . name ) <TAB> <TAB> <TAB> if param . type : <TAB> <TAB> <TAB> <TAB> parts . append ( param . type ) <TAB> <TAB> <TAB> out + = [ ""  :  "" . join ( parts ) ] <TAB> <TAB> <TAB> if param . desc and "" "" . join ( param . desc ) . strip ( ) : <TAB> <TAB> <TAB> <TAB> out + = self . _str_indent ( param . desc ) <TAB> <TAB> out + = [ "" "" ] <TAB> return out ","if param . name : 
","if param . name :
",100.0,100.0,True
"def _get_image ( self , image_list , source ) : <TAB> if source . startswith ( "" wx "" ) : <TAB> <TAB> img = wx . ArtProvider_GetBitmap ( source , wx . ART_OTHER , _SIZE ) <TAB> else : <TAB> <TAB> path = os . path . join ( _BASE , source ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> img = wx . Image ( path , wx . BITMAP_TYPE_GIF ) . ConvertToBitmap ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> img = wx . Image ( path , wx . BITMAP_TYPE_PNG ) . ConvertToBitmap ( ) <TAB> return image_list . Add ( img ) ","if source . endswith ( "" gif "" ) : 
","if os . path . isfile ( path ) :
",32.06,10.55,False
"def change_opacity_function ( self , new_f ) : <TAB> self . opacity_function = new_f <TAB> dr = self . radius / self . num_levels <TAB> sectors = [ ] <TAB> for submob in self . submobjects : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sectors . append ( submob ) <TAB> for ( r , submob ) in zip ( np . arange ( 0 , self . radius , dr ) , sectors ) : <TAB> <TAB> if type ( submob ) != AnnularSector : <TAB> <TAB> <TAB> # it's the shadow, don't dim it <TAB> <TAB> <TAB> continue <TAB> <TAB> alpha = self . opacity_function ( r ) <TAB> <TAB> submob . set_fill ( opacity = alpha ) ","if type ( submob ) == AnnularSector : 
","if submob . is_sector ( ) :
",27.08,7.13,False
"def _sqlite_post_configure_engine ( url , engine , follower_ident ) : <TAB> from sqlalchemy import event <TAB> @event . listens_for ( engine , "" connect "" ) <TAB> def connect ( dbapi_connection , connection_record ) : <TAB> <TAB> # use file DBs in all cases, memory acts kind of strangely <TAB> <TAB> # as an attached <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dbapi_connection . execute ( ' ATTACH DATABASE  "" test_schema.db ""  AS test_schema ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> dbapi_connection . execute ( <TAB> <TAB> <TAB> <TAB> ' ATTACH DATABASE  "" %s _test_schema.db ""  AS test_schema ' % follower_ident <TAB> <TAB> <TAB> ) ","if not follower_ident : 
","if not follower_ident :
",100.0,100.0,True
"def apply_conf_file ( fn , conf_filename ) : <TAB> for env in LSF_CONF_ENV : <TAB> <TAB> conf_file = get_conf_file ( conf_filename , env ) <TAB> <TAB> if conf_file : <TAB> <TAB> <TAB> with open ( conf_file ) as conf_handle : <TAB> <TAB> <TAB> <TAB> value = fn ( conf_handle ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return value <TAB> return None ","if value : 
","if value is not None :
",34.04,17.97,False
"def test_call_extern_c_fn ( self ) : <TAB> global memcmp <TAB> memcmp = cffi_support . ExternCFunction ( <TAB> <TAB> "" memcmp "" , <TAB> <TAB> ( "" int memcmp ( const uint8_t * ptr1,  "" "" const uint8_t * ptr2, size_t num ) "" ) , <TAB> ) <TAB> @udf ( BooleanVal ( FunctionContext , StringVal , StringVal ) ) <TAB> def fn ( context , a , b ) : <TAB> <TAB> if a . is_null != b . is_null : <TAB> <TAB> <TAB> return False <TAB> <TAB> if a is None : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> if a . ptr == b . ptr : <TAB> <TAB> <TAB> return True <TAB> <TAB> return memcmp ( a . ptr , b . ptr , a . len ) == 0 ","if len ( a ) != b . len : 
","if b is None :
",26.44,4.23,False
"def _get_initialized_app ( app ) : <TAB> """"""Returns a reference to an initialized App instance."""""" <TAB> if app is None : <TAB> <TAB> return firebase_admin . get_app ( ) <TAB> if isinstance ( app , firebase_admin . App ) : <TAB> <TAB> initialized_app = firebase_admin . get_app ( app . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Illegal app argument. App instance not  "" <TAB> <TAB> <TAB> <TAB> "" initialized via the firebase module. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return app <TAB> raise ValueError ( <TAB> <TAB> "" Illegal app argument. Argument must be of type  "" <TAB> <TAB> '  firebase_admin.App, but given  "" {0} "" . ' . format ( type ( app ) ) <TAB> ) ","if app is not initialized_app : 
","if initialized_app is not None and not initialized_app . is_valid ( ) :
",35.81,18.95,False
def compiled_query ( self ) : <TAB> <MASK> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . compiled_query_ is None : <TAB> <TAB> <TAB> <TAB> self . compiled_query_ = CompiledQuery ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . compiled_query_ ,"if self . compiled_query_ is None : 
","if self . compiled_query_ is None :
",100.0,100.0,True
"def clean_subevent ( event , subevent ) : <TAB> if event . has_subevents : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" Subevent cannot be null for event series. "" ) ) <TAB> <TAB> if event != subevent . event : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) <TAB> else : <TAB> <TAB> if subevent : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The subevent does not belong to this event. "" ) ) ","if not subevent : 
","if not isinstance ( subevent , Event ) :
",31.56,11.34,False
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_BLOB : <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB "" ","if length < = self . LENGTH_LIMIT_MEDIUMBLOB : 
","if length < = self . LENGTH_LIMIT_MEDIUMBLOB :
",100.0,100.0,True
"def decompress ( self , data ) : <TAB> if not data : <TAB> <TAB> return data <TAB> if not self . _first_try : <TAB> <TAB> return self . _obj . decompress ( data ) <TAB> self . _data + = data <TAB> try : <TAB> <TAB> decompressed = self . _obj . decompress ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _first_try = False <TAB> <TAB> <TAB> self . _data = None <TAB> <TAB> return decompressed <TAB> except zlib . error : <TAB> <TAB> self . _first_try = False <TAB> <TAB> self . _obj = zlib . decompressobj ( - zlib . MAX_WBITS ) <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . decompress ( self . _data ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _data = None ","if decompressed : 
","if decompressed is None :
",34.79,23.64,False
"def _record_event ( self , path , fsevent_handle , filename , events , error ) : <TAB> with self . lock : <TAB> <TAB> self . events [ path ] . append ( events ) <TAB> <TAB> if events | pyuv . fs . UV_RENAME : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . watches . pop ( path ) . close ( ) ","if not os . path . exists ( path ) : 
","if path in self . watches :
",29.92,5.24,False
"def __init__ ( self , duration , batch_shape , event_shape , validate_args = None ) : <TAB> if duration is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Infer duration from event_shape. <TAB> <TAB> <TAB> duration = event_shape [ 0 ] <TAB> elif duration != event_shape [ 0 ] : <TAB> <TAB> if event_shape [ 0 ] != 1 : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" duration, event_shape mismatch:  {}  vs  {} "" . format ( duration , event_shape ) <TAB> <TAB> <TAB> ) <TAB> <TAB> # Infer event_shape from duration. <TAB> <TAB> event_shape = torch . Size ( ( duration , ) + event_shape [ 1 : ] ) <TAB> self . _duration = duration <TAB> super ( ) . __init__ ( batch_shape , event_shape , validate_args ) ","if event_shape [ 0 ] != 1 : 
","if isinstance ( event_shape , tuple ) :
",26.93,16.06,False
"def _CheckPrerequisites ( self ) : <TAB> """"""Exits if any of the prerequisites is not met."""""" <TAB> if not FLAGS . kubectl : <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> "" Please provide path to kubectl tool using --kubectl  "" "" flag. Exiting. "" <TAB> <TAB> ) <TAB> if not FLAGS . kubeconfig : <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> "" Please provide path to kubeconfig using --kubeconfig  "" "" flag. Exiting. "" <TAB> <TAB> ) <TAB> if self . disk_specs and self . disk_specs [ 0 ] . disk_type == disk . STANDARD : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Please provide a list of Ceph Monitors using  "" "" --ceph_monitors flag. "" <TAB> <TAB> <TAB> ) ","if not FLAGS . ceph_monitors : 
","if not FLAGS . ceph_monitors and self . disk_specs [ 0 ] . disk_type == disk . CELL :
",62.34,22.74,False
"def invalidateDependentSlices ( self , iFirstCurve ) : <TAB> # only user defined curve can have slice dependency relationships <TAB> if self . isSystemCurveIndex ( iFirstCurve ) : <TAB> <TAB> return <TAB> nCurves = self . getNCurves ( ) <TAB> for i in range ( iFirstCurve , nCurves ) : <TAB> <TAB> c = self . getSystemCurve ( i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> c . invalidate ( ) <TAB> <TAB> elif i == iFirstCurve : <TAB> <TAB> <TAB> # if first curve isn't a slice, <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # there are no dependent slices ","if isinstance ( c . getSymbol ( ) . getSymbolType ( ) , SymbolType . PieSliceSymbolType ) : 
","if c . isDependent ( ) :
",38.06,4.73,False
"def find_backwards ( self , offset ) : <TAB> try : <TAB> <TAB> for _ , token_type , token_value in reversed ( self . tokens [ self . offset : offset ] ) : <TAB> <TAB> <TAB> if token_type in ( "" comment "" , "" linecomment "" ) : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> prefix , comment = token_value . split ( None , 1 ) <TAB> <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return [ comment . rstrip ( ) ] <TAB> <TAB> return [ ] <TAB> finally : <TAB> <TAB> self . offset = offset ","if prefix in self . comment_tags : 
","if prefix == "" # "" :
",28.91,10.79,False
"def parse_column_definitions ( self , elem ) : <TAB> for column_elem in elem . findall ( "" column "" ) : <TAB> <TAB> name = column_elem . get ( "" name "" , None ) <TAB> <TAB> assert name is not None , "" Required  ' name '  attribute missing from column def "" <TAB> <TAB> index = column_elem . get ( "" index "" , None ) <TAB> <TAB> assert index is not None , "" Required  ' index '  attribute missing from column def "" <TAB> <TAB> index = int ( index ) <TAB> <TAB> self . columns [ name ] = index <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . largest_index = index <TAB> assert "" value "" in self . columns , "" Required  ' value '  column missing from column def "" <TAB> if "" name "" not in self . columns : <TAB> <TAB> self . columns [ "" name "" ] = self . columns [ "" value "" ] ","if index > self . largest_index : 
","if self . largest_index is None :
",40.7,48.55,False
"def __find_smallest ( self ) : <TAB> """"""Find the smallest uncovered value in the matrix."""""" <TAB> minval = sys . maxsize <TAB> for i in range ( self . n ) : <TAB> <TAB> for j in range ( self . n ) : <TAB> <TAB> <TAB> if ( not self . row_covered [ i ] ) and ( not self . col_covered [ j ] ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> minval = self . C [ i ] [ j ] <TAB> return minval ","if minval > self . C [ i ] [ j ] : 
","if self . C [ i ] [ j ] < minval :
",72.4,69.62,False
"def includes_tools_for_display_in_tool_panel ( self ) : <TAB> if self . includes_tools : <TAB> <TAB> tool_dicts = self . metadata [ "" tools "" ] <TAB> <TAB> for tool_dict in tool_dicts : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if tool_dict . get ( "" add_to_tool_panel "" , True ) : 
","if tool_dict [ "" name "" ] == "" includes "" :
",31.45,13.56,False
"def commit ( self , notify = False ) : <TAB> if self . editing : <TAB> <TAB> text = self . _text <TAB> <TAB> if text : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> value = self . type ( text ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> value = self . clamp_value ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = self . empty <TAB> <TAB> <TAB> if value is NotImplemented : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> self . value = value <TAB> <TAB> self . insertion_point = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . change_text ( unicode ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _text = unicode ( value ) <TAB> <TAB> self . editing = False <TAB> else : <TAB> <TAB> self . insertion_point = None ","if notify : 
","if notify :
",78.12,0.0,False
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self . plugin_args . start : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB> <TAB> <TAB> if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB> <TAB> <TAB> <TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ","if start > self . plugin_args . end : 
","if start > = self . plugin_args . end :
",70.14,73.49,False
"def _check_for_duplicate_host_entries ( self , task_entries ) : <TAB> non_host_statuses = ( <TAB> <TAB> models . HostQueueEntry . Status . PARSING , <TAB> <TAB> models . HostQueueEntry . Status . ARCHIVING , <TAB> ) <TAB> for task_entry in task_entries : <TAB> <TAB> using_host = ( <TAB> <TAB> <TAB> task_entry . host is not None and task_entry . status not in non_host_statuses <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _assert_host_has_no_agent ( task_entry ) ","if using_host : 
","if using_host :
",78.12,100.0,True
"def get_biggest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> <TAB> if lowest_wall < j [ "" wall_time "" ] : <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall ","if lowest_wall is None : 
","if lowest_wall is None :
",100.0,100.0,True
"def log_change_report ( self , old_value , new_value , include_details = False ) : <TAB> from octoprint . util import map_boolean <TAB> with self . _check_mutex : <TAB> <TAB> self . _logger . info ( <TAB> <TAB> <TAB> "" Connectivity changed from  {}  to  {} "" . format ( <TAB> <TAB> <TAB> <TAB> map_boolean ( old_value , "" online "" , "" offline "" ) , <TAB> <TAB> <TAB> <TAB> map_boolean ( new_value , "" online "" , "" offline "" ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log_details ( ) ","if include_details : 
","if include_details :
",78.12,100.0,True
"def _include_block ( self , value , context = None ) : <TAB> if hasattr ( value , "" render_as_block "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_context = context . get_all ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_context = { } <TAB> <TAB> return jinja2 . Markup ( value . render_as_block ( context = new_context ) ) <TAB> return jinja2 . Markup ( value ) ","if context : 
","if context :
",78.12,0.0,False
"def __lt__ ( self , other ) : <TAB> # 0: clock 1: timestamp 3: process id <TAB> try : <TAB> <TAB> A , B = self [ 0 ] , other [ 0 ] <TAB> <TAB> # uses logical clock value first <TAB> <TAB> if A and B :<TAB> # use logical clock if available <TAB> <TAB> <TAB> if A == B :<TAB> # equal clocks use lower process id <TAB> <TAB> <TAB> <TAB> return self [ 2 ] < other [ 2 ] <TAB> <TAB> <TAB> return A < B <TAB> <TAB> return self [ 1 ] < other [ 1 ]<TAB> # ... or use timestamp <TAB> except IndexError : <TAB> <TAB> return NotImplemented ","if A == B : 
","if A == B :
",100.0,100.0,True
"def _get_port ( ) : <TAB> while True : <TAB> <TAB> port = 20000 + random . randint ( 1 , 9999 ) <TAB> <TAB> for i in range ( 5 ) : <TAB> <TAB> <TAB> sock = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <TAB> <TAB> <TAB> result = sock . connect_ex ( ( "" 127.0.0.1 "" , port ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> else : <TAB> <TAB> <TAB> return port ","if result == 0 : 
","if result == 0 :
",100.0,100.0,True
"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB> if type ( targets ) != list and type ( targets ) != tuple : <TAB> <TAB> <TAB> targets = tuple ( <TAB> <TAB> <TAB> <TAB> targets , <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> targets = tuple ( targets ) <TAB> for target in targets : <TAB> <TAB> self . _fetch_targets ( api_client , q , target ) ","elif type ( targets ) != tuple : 
","elif type ( targets ) == list :
",77.59,48.55,False
"def migrate_node_facts ( facts ) : <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB> <TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB> <TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for param in params [ role ] : <TAB> <TAB> <TAB> <TAB> if param in facts [ role ] : <TAB> <TAB> <TAB> <TAB> <TAB> facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts ","if role in facts : 
","if role in facts [ "" common "" ] :
",49.62,27.78,False
"def build_dimension_param ( self , dimension , params ) : <TAB> prefix = "" Dimensions.member "" <TAB> i = 0 <TAB> for dim_name in dimension : <TAB> <TAB> dim_value = dimension [ dim_name ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( dim_value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> dim_value = [ dim_value ] <TAB> <TAB> <TAB> for value in dim_value : <TAB> <TAB> <TAB> <TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB> <TAB> <TAB> <TAB> params [ "" %s . %d .Value "" % ( prefix , i + 1 ) ] = value <TAB> <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> params [ "" %s . %d .Name "" % ( prefix , i + 1 ) ] = dim_name <TAB> <TAB> <TAB> i + = 1 ","if dim_value : 
","if dim_value :
",78.12,100.0,True
"def add_if_unique ( self , issuer , use , keys ) : <TAB> if use in self . issuer_keys [ issuer ] and self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> for typ , key in keys : <TAB> <TAB> <TAB> flag = 1 <TAB> <TAB> <TAB> for _typ , _key in self . issuer_keys [ issuer ] [ use ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> flag = 0 <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if flag : <TAB> <TAB> <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] . append ( ( typ , key ) ) <TAB> else : <TAB> <TAB> self . issuer_keys [ issuer ] [ use ] = keys ","if _typ == typ and key is _key : 
","if typ == _key :
",38.1,20.92,False
"def run ( self ) : <TAB> while True : <TAB> <TAB> message = self . in_queue . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . reset ( ) <TAB> <TAB> elif message == EXIT : <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> index , transaction = message <TAB> <TAB> <TAB> self . results_queue . put ( ( index , self . validate ( transaction ) ) ) ","if message == RESET : 
","if message == RESET :
",100.0,100.0,True
"def __run ( self ) : <TAB> threads = self . parameters ( ) [ "" threads "" ] . getTypedValue ( ) <TAB> with IECore . tbb_global_control ( <TAB> <TAB> IECore . tbb_global_control . parameter . max_allowed_parallelism , <TAB> <TAB> IECore . hardwareConcurrency ( ) if threads == 0 else threads , <TAB> ) : <TAB> <TAB> self . _executeStartupFiles ( self . root ( ) . getName ( ) ) <TAB> <TAB> # Append DEBUG message with process information to all messages <TAB> <TAB> defaultMessageHandler = IECore . MessageHandler . getDefaultHandler ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> IECore . MessageHandler . setDefaultHandler ( <TAB> <TAB> <TAB> <TAB> Gaffer . ProcessMessageHandler ( defaultMessageHandler ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return self . _run ( self . parameters ( ) . getValidatedValue ( ) ) ","if not isinstance ( defaultMessageHandler , Gaffer . ProcessMessageHandler ) : 
","if defaultMessageHandler is not None :
",26.39,4.99,False
"def adjust_uri ( self , uri , relativeto ) : <TAB> """"""Adjust the given ``uri`` based on the given relative URI."""""" <TAB> key = ( uri , relativeto ) <TAB> if key in self . _uri_cache : <TAB> <TAB> return self . _uri_cache [ key ] <TAB> if uri [ 0 ] != "" / "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = self . _uri_cache [ key ] = posixpath . join ( <TAB> <TAB> <TAB> <TAB> posixpath . dirname ( relativeto ) , uri <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = self . _uri_cache [ key ] = "" / "" + uri <TAB> else : <TAB> <TAB> v = self . _uri_cache [ key ] = uri <TAB> return v ","if relativeto is not None : 
","if relativeto :
",29.58,0.0,False
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> elif c == "" - "" and decode : <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> elif decode : <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) ) ","if c == "" & "" and not decode : 
","if c == "" & "" and decode :
",68.32,75.17,False
"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if line . startswith ( "" - "" ) : <TAB> <TAB> <TAB> args . extend ( self . _split_option ( line ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . append ( line ) <TAB> return args ","elif line and not line . startswith ( "" # "" ) : 
","elif line . startswith ( "" - "" ) :
",57.55,41.66,False
"def _method_events_callback ( self , values ) : <TAB> try : <TAB> <TAB> previous_echoed = ( <TAB> <TAB> <TAB> values [ "" child_result_list "" ] [ - 1 ] . decode ( ) . split ( "" \n "" ) [ - 2 ] . strip ( ) <TAB> <TAB> ) <TAB> <TAB> if previous_echoed . endswith ( "" foo1 "" ) : <TAB> <TAB> <TAB> return "" echo foo2 \n "" <TAB> <TAB> elif previous_echoed . endswith ( "" foo2 "" ) : <TAB> <TAB> <TAB> return "" echo foo3 \n "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" exit \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected output  {0!r} "" . format ( previous_echoed ) ) <TAB> except IndexError : <TAB> <TAB> return "" echo foo1 \n "" ","elif previous_echoed . endswith ( "" foo3 "" ) : 
","elif previous_echoed . endswith ( "" foo3 "" ) :
",100.0,100.0,True
"def __delete_hook ( self , rpc ) : <TAB> try : <TAB> <TAB> rpc . check_success ( ) <TAB> except apiproxy_errors . Error : <TAB> <TAB> return None <TAB> result = [ ] <TAB> for status in rpc . response . delete_status_list ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( DELETE_SUCCESSFUL ) <TAB> <TAB> elif status == MemcacheDeleteResponse . NOT_FOUND : <TAB> <TAB> <TAB> result . append ( DELETE_ITEM_MISSING ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( DELETE_NETWORK_FAILURE ) <TAB> return result ","if status == MemcacheDeleteResponse . DELETED : 
","if status == MemcacheDeleteResponse . SUCCESS :
",82.41,70.71,False
"def __createRandom ( plug ) : <TAB> node = plug . node ( ) <TAB> parentNode = node . ancestor ( Gaffer . Node ) <TAB> with Gaffer . UndoScope ( node . scriptNode ( ) ) : <TAB> <TAB> randomNode = Gaffer . Random ( ) <TAB> <TAB> parentNode . addChild ( randomNode ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outFloat "" ] ) <TAB> <TAB> elif isinstance ( plug , Gaffer . Color3fPlug ) : <TAB> <TAB> <TAB> plug . setInput ( randomNode [ "" outColor "" ] ) <TAB> GafferUI . NodeEditor . acquire ( randomNode ) ","if isinstance ( plug , ( Gaffer . FloatPlug , Gaffer . IntPlug ) ) : 
","if isinstance ( plug , Gaffer . Float3fPlug ) :
",48.35,30.86,False
"def escapeentities ( self , line ) : <TAB> "" Escape all Unicode characters to HTML entities. "" <TAB> result = "" "" <TAB> pos = TextPosition ( line ) <TAB> while not pos . finished ( ) : <TAB> <TAB> if ord ( pos . current ( ) ) > 128 : <TAB> <TAB> <TAB> codepoint = hex ( ord ( pos . current ( ) ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> codepoint = hex ( ord ( pos . next ( ) ) + 0xF800 ) <TAB> <TAB> <TAB> result + = "" &# "" + codepoint [ 1 : ] + "" ; "" <TAB> <TAB> else : <TAB> <TAB> <TAB> result + = pos . current ( ) <TAB> <TAB> pos . skipcurrent ( ) <TAB> return result ","if codepoint == "" 0xd835 "" : 
","elif ord ( pos . next ( ) ) > 0xF800 :
",26.16,3.39,False
def get_and_set_all_aliases ( self ) : <TAB> all_aliases = [ ] <TAB> for page in self . pages : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> all_aliases . extend ( page . relations . aliases_norm ) <TAB> <TAB> if page . relations . aliases is not None : <TAB> <TAB> <TAB> all_aliases . extend ( page . relations . aliases ) <TAB> return set ( all_aliases ) ,"if page . relations . aliases_norm is not None : 
","if page . relations . aliases_norm is not None :
",100.0,100.0,True
"def _list_cases ( suite ) : <TAB> for test in suite : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _list_cases ( test ) <TAB> <TAB> elif isinstance ( test , unittest . TestCase ) : <TAB> <TAB> <TAB> if support . match_test ( test ) : <TAB> <TAB> <TAB> <TAB> print ( test . id ( ) ) ","if isinstance ( test , unittest . TestSuite ) : 
","if isinstance ( test , unittest . TestSuite ) :
",100.0,100.0,True
"def get_next_requests ( self , max_n_requests , * * kwargs ) : <TAB> next_pages = [ ] <TAB> partitions = set ( kwargs . pop ( "" partitions "" , [ ] ) ) <TAB> for partition_id in range ( 0 , self . queue_partitions ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> results = self . queue . get_next_requests ( max_n_requests , partition_id ) <TAB> <TAB> next_pages . extend ( results ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Got  %d  requests for partition id  %d "" , len ( results ) , partition_id <TAB> <TAB> ) <TAB> return next_pages ","if partition_id not in partitions : 
","if partition_id not in partitions :
",100.0,100.0,True
"def __iter__ ( self ) : <TAB> if ( self . query is not None ) and sqlite . is_read_only_query ( self . query ) : <TAB> <TAB> cur = self . connection . cursor ( ) <TAB> <TAB> results = cur . execute ( self . query ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield [ col [ 0 ] for col in cur . description ] <TAB> <TAB> for i , row in enumerate ( results ) : <TAB> <TAB> <TAB> if i > = self . limit : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> yield [ val for val in row ] <TAB> else : <TAB> <TAB> yield ","if self . headers : 
","if results is not None :
",28.03,9.65,False
"def rollback ( self ) : <TAB> for operation , values in self . current_transaction_state [ : : - 1 ] : <TAB> <TAB> if operation == "" insert "" : <TAB> <TAB> <TAB> values . remove ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> old_value , new_value = values <TAB> <TAB> <TAB> if new_value . full_filename != old_value . full_filename : <TAB> <TAB> <TAB> <TAB> os . unlink ( new_value . full_filename ) <TAB> <TAB> <TAB> old_value . write ( ) <TAB> self . _post_xact_cleanup ( ) ","elif operation == "" update "" : 
","elif operation == "" replace "" :
",74.63,59.46,False
"def index ( self , value ) : <TAB> if self . _growing : <TAB> <TAB> if self . _start < = value < self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( value - self . _start , self . _step ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> else : <TAB> <TAB> if self . _start > = value > self . _stop : <TAB> <TAB> <TAB> q , r = divmod ( self . _start - value , - self . _step ) <TAB> <TAB> <TAB> if r == self . _zero : <TAB> <TAB> <TAB> <TAB> return int ( q ) <TAB> raise ValueError ( "" {}  is not in numeric range "" . format ( value ) ) ","if r == self . _zero : 
","if r == self . _zero :
",100.0,100.0,True
"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB> <TAB> value = body . get ( attribute ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> body [ attribute ] = value . strip ( ) <TAB> <TAB> <TAB> if check_length : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> utils . check_string_length ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception . InvalidInput as error : <TAB> <TAB> <TAB> <TAB> <TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg ) ","if value is not None : 
","if value :
",29.58,0.0,False
"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB> <TAB> if m [ 0 ] == "" "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> output ( "" |} "" ) <TAB> <TAB> <TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else : <TAB> <TAB> <TAB> output ( "" |- "" ) <TAB> <TAB> <TAB> output ( <TAB> <TAB> <TAB> <TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB> <TAB> <TAB> <TAB> + m [ 0 ] <TAB> <TAB> <TAB> <TAB> + "" </tt></span> || ||  "" <TAB> <TAB> <TAB> <TAB> + m [ 1 ] <TAB> <TAB> <TAB> ) <TAB> output ( "" |} "" ) ","if firstHeading : 
","if not firstHeading :
",36.35,35.36,False
"def _get_platforms ( data ) : <TAB> platform_list = [ ] <TAB> for item in data : <TAB> <TAB> if item . startswith ( "" PlatformEdit.html? "" ) : <TAB> <TAB> <TAB> parameter_list = item . split ( "" PlatformEdit.html? "" , 1 ) [ 1 ] . split ( "" & "" ) <TAB> <TAB> <TAB> for parameter in parameter_list : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> platform_list . append ( parameter . split ( "" = "" ) [ 1 ] ) <TAB> return platform_list ","if parameter . startswith ( "" platformName "" ) : 
","if parameter . startswith ( "" Platform "" ) :
",83.03,65.8,False
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> elif name . startswith ( "" SCLEX_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states ) ","if name . startswith ( "" SCE_ "" ) : 
","if name . startswith ( "" SCINTilla_ "" ) :
",83.03,70.17,False
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation : <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition . name and definition . name . value == operation_name : <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation ","if not operation_name : 
","if operation_name is None :
",29.25,27.78,False
"def _insertNewItemAtParent ( self , targetIndex ) : <TAB> if not self . isContainer ( targetIndex ) : <TAB> <TAB> return <TAB> elif not self . isContainerOpen ( targetIndex ) : <TAB> <TAB> uri = self . _rows [ targetIndex ] . uri <TAB> <TAB> modelNode = self . getNodeForURI ( uri ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> modelNode . markForRefreshing ( ) <TAB> <TAB> return <TAB> self . refreshView ( targetIndex ) ","if modelNode : 
","if modelNode :
",78.12,0.0,False
"def _get_trace ( self , model , guide , args , kwargs ) : <TAB> model_trace , guide_trace = super ( ) . _get_trace ( model , guide , args , kwargs ) <TAB> # Mark all sample sites with require_backward to gather enumerated <TAB> # sites and adjust cond_indep_stack of all sample sites. <TAB> for node in model_trace . nodes . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log_prob = node [ "" packed "" ] [ "" unscaled_log_prob "" ] <TAB> <TAB> <TAB> require_backward ( log_prob ) <TAB> self . _saved_state = model , model_trace , guide_trace , args , kwargs <TAB> return model_trace , guide_trace ","if node [ "" type "" ] == "" sample "" and not node [ "" is_observed "" ] : 
","if node [ "" type "" ] == "" sample "" and node [ "" packed "" ] [ "" unscaled_log_prob "" ] > 0 :
",69.53,46.73,False
"def _url_encode_impl ( obj , charset , encode_keys , sort , key ) : <TAB> from . datastructures import iter_multi_items <TAB> iterable = iter_multi_items ( obj ) <TAB> if sort : <TAB> <TAB> iterable = sorted ( iterable , key = key ) <TAB> for key , value in iterable : <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( key , bytes ) : <TAB> <TAB> <TAB> key = text_type ( key ) . encode ( charset ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = text_type ( value ) . encode ( charset ) <TAB> <TAB> yield _fast_url_quote_plus ( key ) + "" = "" + _fast_url_quote_plus ( value ) ","if not isinstance ( value , bytes ) : 
","if not isinstance ( value , bytes ) :
",100.0,100.0,True
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> with augment_usage_errors ( ctx , param = self ) : <TAB> <TAB> value = self . consume_value ( ctx , opts ) <TAB> <TAB> try : <TAB> <TAB> <TAB> value = self . full_process_value ( ctx , value ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> value = None <TAB> <TAB> if self . callback is not None : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> value = invoke_param_callback ( self . callback , ctx , self , value ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> if not ctx . resilient_parsing : <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> if self . expose_value : <TAB> <TAB> ctx . params [ self . name ] = value <TAB> return value , args ","if not ctx . resilient_parsing : 
","if not ctx . resilient_parsing :
",100.0,100.0,True
"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB> <TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB> <TAB> if pattern [ i ] not in dict : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB> <TAB> <TAB> set_value . add ( list_str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if dict [ pattern [ i ] ] != list_str [ i ] : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if list_str [ i ] in set_value : 
","if set_value . issuperset ( list_str [ i ] ) :
",47.36,43.33,False
"def create ( self , path , wipe = False ) : <TAB> # type: (Text, bool) -> bool <TAB> _path = self . validatepath ( path ) <TAB> with ftp_errors ( self , path ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> empty_file = io . BytesIO ( ) <TAB> <TAB> <TAB> self . ftp . storbinary ( <TAB> <TAB> <TAB> <TAB> str ( "" STOR  "" ) + _encode ( _path , self . ftp . encoding ) , empty_file <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> return False ","if wipe or not self . isfile ( path ) : 
","if wipe :
",26.6,0.0,False
"def build_output_for_item ( self , item ) : <TAB> output = [ ] <TAB> for field in self . fields : <TAB> <TAB> values = self . _get_item ( item , field ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values = [ values ] <TAB> <TAB> for value in values : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> output . append ( self . build_output_for_single_value ( value ) ) <TAB> return "" "" . join ( output ) ","if not isinstance ( values , list ) : 
","if not isinstance ( values , list ) :
",100.0,100.0,True
"def get_resource_public_actions ( resource_class ) : <TAB> resource_class_members = inspect . getmembers ( resource_class ) <TAB> resource_methods = { } <TAB> for name , member in resource_class_members : <TAB> <TAB> if not name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> if not name [ 0 ] . isupper ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if is_resource_action ( member ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> resource_methods [ name ] = member <TAB> return resource_methods ","if not name . startswith ( "" wait_until "" ) : 
","if inspect . isclass ( member ) :
",31.11,7.43,False
"def get_command ( cls ) : <TAB> ifconfig_cmd = "" ifconfig "" <TAB> for path in [ "" /sbin "" , "" /usr/sbin "" , "" /bin "" , "" /usr/bin "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ifconfig_cmd = os . path . join ( path , ifconfig_cmd ) <TAB> <TAB> <TAB> break <TAB> ifconfig_cmd = ifconfig_cmd + ""  -a "" <TAB> return ifconfig_cmd ","if os . path . exists ( os . path . join ( path , ifconfig_cmd ) ) : 
","if os . path . exists ( path ) :
",37.02,24.99,False
"def main ( ) : <TAB> base_dir = os . path . join ( os . path . split ( __file__ ) [ 0 ] , "" .. "" , "" .. "" ) <TAB> for path in PATHS : <TAB> <TAB> path = os . path . join ( base_dir , path ) <TAB> <TAB> for root , _ , files in os . walk ( path ) : <TAB> <TAB> <TAB> for file in files : <TAB> <TAB> <TAB> <TAB> extension = os . path . splitext ( file ) [ 1 ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> path = os . path . join ( root , file ) <TAB> <TAB> <TAB> <TAB> <TAB> validate_header ( path ) ","if extension in EXTENSIONS : 
","if extension == "" .py "" :
",29.99,10.55,False
"def auth_login ( request ) : <TAB> form = RegistrationForm ( request . POST or None ) <TAB> if form . is_valid ( ) : <TAB> <TAB> authed_user = authenticate ( <TAB> <TAB> <TAB> username = form . cleaned_data [ "" username "" ] , <TAB> <TAB> <TAB> password = form . cleaned_data [ "" password "" ] , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> login ( request , authed_user ) <TAB> <TAB> <TAB> return HttpResponse ( "" Success "" ) <TAB> raise Http404 ","if authed_user : 
","if authed_user :
",78.12,100.0,True
"def set ( self , _key , _new_login = True ) : <TAB> with self . lock : <TAB> <TAB> user = self . users . get ( current_user . id , None ) <TAB> <TAB> if user is None : <TAB> <TAB> <TAB> self . users [ current_user . id ] = dict ( session_count = 1 , key = _key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> user [ "" session_count "" ] + = 1 <TAB> <TAB> <TAB> user [ "" key "" ] = _key ","if _new_login : 
","if _new_login :
",78.12,100.0,True
"def fetch ( self , fingerprints ) : <TAB> to_fetch = [ f for f in fingerprints if f not in self . _cache ] <TAB> self . _logger . debug ( "" cache size  %s "" % len ( self . _cache ) ) <TAB> self . _logger . debug ( "" to fetch  %d  from  %d "" % ( len ( to_fetch ) , len ( fingerprints ) ) ) <TAB> [ self . _redis_pipeline . hgetall ( key ) for key in to_fetch ] <TAB> responses = self . _redis_pipeline . execute ( ) <TAB> for index , key in enumerate ( to_fetch ) : <TAB> <TAB> response = responses [ index ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _cache [ key ] = response [ FIELD_STATE ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _cache [ key ] = self . NOT_CRAWLED ","if len ( response ) > 0 and FIELD_STATE in response : 
","if FIELD_STATE in response :
",38.91,30.93,False
"def _append_to_io_queue ( self , data , stream_name ) : <TAB> # Make sure ANSI CSI codes and object links are stored as separate events <TAB> # TODO: try to complete previously submitted incomplete code <TAB> parts = re . split ( OUTPUT_SPLIT_REGEX , data ) <TAB> for part in parts : <TAB> <TAB> if part :<TAB> # split may produce empty string in the beginning or start <TAB> <TAB> <TAB> # split the data so that very long lines separated <TAB> <TAB> <TAB> for block in re . split ( <TAB> <TAB> <TAB> <TAB> "" (. { %d ,}) "" % ( self . _get_squeeze_threshold ( ) + 1 ) , part <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . _queued_io_events . append ( ( block , stream_name ) ) ","if block : 
","if block :
",78.12,0.0,False
"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB> <TAB> path = os . path . join ( path , self . index_file ) <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> <TAB> except IsDirectoryError : <TAB> <TAB> <TAB> if os . path . isfile ( os . path . join ( path , self . index_file ) ) : <TAB> <TAB> <TAB> <TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path ) ","if os . path . isfile ( path ) : 
","if url . endswith ( self . index_file ) :
",32.17,8.91,False
"def module_list ( target , fast ) : <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB> <TAB> module_name , ext = os . path . splitext ( name ) <TAB> <TAB> if ext == "" .py "" or ext == "" "" and os . path . isdir ( os . path . join ( basedir , name ) ) : <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> modules . append ( module_name ) <TAB> return set ( modules ) ","if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) : 
","if fast or module_name not in fast :
",35.04,10.95,False
"def housenumber ( self ) : <TAB> if self . address : <TAB> <TAB> expression = r "" \ d+ "" <TAB> <TAB> pattern = re . compile ( expression ) <TAB> <TAB> match = pattern . search ( self . address ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return int ( match . group ( 0 ) ) ","if match : 
","if match :
",78.12,0.0,False
"def get_pip_version ( import_path = BASE_IMPORT_PATH ) : <TAB> try : <TAB> <TAB> pip = importlib . import_module ( import_path ) <TAB> except ImportError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return get_pip_version ( import_path = "" pip "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> import subprocess <TAB> <TAB> <TAB> version = subprocess . check_output ( [ "" pip "" , "" --version "" ] ) <TAB> <TAB> <TAB> if version : <TAB> <TAB> <TAB> <TAB> version = version . decode ( "" utf-8 "" ) . split ( ) [ 1 ] <TAB> <TAB> <TAB> <TAB> return version <TAB> <TAB> <TAB> return "" 0.0.0 "" <TAB> version = getattr ( pip , "" __version__ "" , None ) <TAB> return version ","if import_path != "" pip "" : 
","if import_path == "" __pycache__ "" :
",55.31,24.02,False
"def __animate_progress ( self ) : <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True : <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> with self . __progress_lock : <TAB> <TAB> <TAB> if not self . __progress_status : <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . __progress_status . show_as_ready ( ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time . sleep ( sleep_time ) ","elif self . __show_animation : 
","elif self . __progress_status . is_ready ( ) :
",43.86,26.76,False
"def range_key_names ( self ) : <TAB> keys = [ self . range_key_attr ] <TAB> for index in self . global_indexes : <TAB> <TAB> range_key = None <TAB> <TAB> for key in index . schema : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> range_key = keys . append ( key [ "" AttributeName "" ] ) <TAB> <TAB> keys . append ( range_key ) <TAB> return keys ","if key [ "" KeyType "" ] == "" RANGE "" : 
","if key [ "" KeyType "" ] == "" RangeKey "" :
",88.57,79.11,False
"def run ( self ) : <TAB> dist = self . distribution <TAB> commands = dist . command_options . keys ( ) <TAB> settings = { } <TAB> for cmd in commands : <TAB> <TAB> if cmd == "" saveopts "" : <TAB> <TAB> <TAB> continue<TAB> # don't save our own options! <TAB> <TAB> for opt , ( src , val ) in dist . get_option_dict ( cmd ) . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> settings . setdefault ( cmd , { } ) [ opt ] = val <TAB> edit_config ( self . filename , settings , self . dry_run ) ","if src == "" command line "" : 
","if src == "" --save-settings "" :
",71.15,52.47,False
"def parse_move ( self , node ) : <TAB> old , new = "" "" , "" "" <TAB> for child in node : <TAB> <TAB> tag , text = child . tag , child . text <TAB> <TAB> text = text . strip ( ) if text else None <TAB> <TAB> if tag == "" Old "" and text : <TAB> <TAB> <TAB> old = text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new = text <TAB> return Move ( old , new ) ","elif tag == "" New "" and text : 
","elif tag == "" New "" and text :
",100.0,100.0,True
"def __codeanalysis_settings_changed ( self , current_finfo ) : <TAB> if self . data : <TAB> <TAB> run_pyflakes , run_pep8 = self . pyflakes_enabled , self . pep8_enabled <TAB> <TAB> for finfo in self . data : <TAB> <TAB> <TAB> self . __update_editor_margins ( finfo . editor ) <TAB> <TAB> <TAB> finfo . cleanup_analysis_results ( ) <TAB> <TAB> <TAB> if ( run_pyflakes or run_pep8 ) and current_finfo is not None : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> finfo . run_code_analysis ( run_pyflakes , run_pep8 ) ","if current_finfo is not finfo : 
","if run_pyflakes or run_pep8 :
",27.52,6.27,False
"def tchg ( var , width ) : <TAB> "" Convert time string to given length "" <TAB> ret = "" %2d h %02d "" % ( var / 60 , var % 60 ) <TAB> <MASK> <TAB> <TAB> ret = "" %2d h "" % ( var / 60 ) <TAB> <TAB> if len ( ret ) > width : <TAB> <TAB> <TAB> ret = "" %2d d "" % ( var / 60 / 24 ) <TAB> <TAB> <TAB> if len ( ret ) > width : <TAB> <TAB> <TAB> <TAB> ret = "" %2d w "" % ( var / 60 / 24 / 7 ) <TAB> return ret ","if len ( ret ) > width : 
","if len ( ret ) > width :
",100.0,100.0,True
"def spider_log_activity ( self , messages ) : <TAB> for i in range ( 0 , messages ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . sp_sl_p . send ( <TAB> <TAB> <TAB> <TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , <TAB> <TAB> <TAB> <TAB> b "" http://helloworld.com/way/to/the/sun/ "" + b "" 0 "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . sp_sl_p . send ( <TAB> <TAB> <TAB> <TAB> sha1 ( str ( randint ( 1 , 1000 ) ) ) , b "" http://way.to.the.sun "" + b "" 0 "" <TAB> <TAB> <TAB> ) <TAB> self . sp_sl_p . flush ( ) ","if i % 2 == 0 : 
","if i == 0 :
",35.92,43.3,False
"def decode_serial ( self , offset ) : <TAB> serialnum = ( <TAB> <TAB> ( self . cache [ offset + 3 ] << 24 ) <TAB> <TAB> + ( self . cache [ offset + 2 ] << 16 ) <TAB> <TAB> + ( self . cache [ offset + 1 ] << 8 ) <TAB> <TAB> + self . cache [ offset ] <TAB> ) <TAB> serialstr = "" "" <TAB> is_alnum = True <TAB> for i in range ( 4 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> is_alnum = False <TAB> <TAB> <TAB> break <TAB> <TAB> serialstr + = chr ( self . cache [ offset + 3 - i ] ) <TAB> serial = serialstr if is_alnum else str ( serialnum ) <TAB> self . ann_field ( offset , offset + 3 , "" Serial  "" + serial ) ","if not chr ( self . cache [ offset + 3 - i ] ) . isalnum ( ) : 
","if self . cache [ offset + 3 - i ] == 0 :
",56.66,46.97,False
def gettext ( rv ) : <TAB> for child in rv . childNodes : <TAB> <TAB> if child . nodeType == child . TEXT_NODE : <TAB> <TAB> <TAB> yield child . nodeValue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for item in gettext ( child ) : <TAB> <TAB> <TAB> <TAB> yield item ,"if child . nodeType == child . ELEMENT_NODE : 
","elif child . nodeType == child . ELEMENT_NODE :
",81.27,90.36,False
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints ","elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : 
","if text [ - 2 ] not in "" \n \x85 \u2028 \u2029 "" :
",59.5,54.74,False
"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str<TAB> # tempfile APIs return a str by default. <TAB> return return_type ","if isinstance ( arg , bytes ) : 
","elif isinstance ( arg , ( bytes , bytes ) ) :
",44.84,32.09,False
"def as_iconbitmap ( cls , rkey ) : <TAB> """"""Get image path for use in iconbitmap property"""""" <TAB> img = None <TAB> if rkey in cls . _stock : <TAB> <TAB> data = cls . _stock [ rkey ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fpath = data [ "" filename "" ] <TAB> <TAB> <TAB> fname = os . path . basename ( fpath ) <TAB> <TAB> <TAB> name , file_ext = os . path . splitext ( fname ) <TAB> <TAB> <TAB> file_ext = str ( file_ext ) . lower ( ) <TAB> <TAB> <TAB> if file_ext in TK_BITMAP_FORMATS : <TAB> <TAB> <TAB> <TAB> img = BITMAP_TEMPLATE . format ( fpath ) <TAB> return img ","if data [ "" type "" ] not in ( "" stock "" , "" data "" , "" image "" ) : 
","if "" filename "" in data :
",35.48,1.05,False
"def anonymize_ip ( ip ) : <TAB> if ip : <TAB> <TAB> match = RE_FIRST_THREE_OCTETS_OF_IP . findall ( str ( ip ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" %s %s "" % ( match [ 0 ] [ 0 ] , "" 0 "" ) <TAB> return "" "" ","if match : 
","if match :
",78.12,0.0,False
"def serialize_tail ( self ) : <TAB> msg = bytearray ( ) <TAB> for v in self . info : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = v [ "" value "" ] . encode ( "" utf-8 "" ) <TAB> <TAB> elif v [ "" type "" ] == BMP_TERM_TYPE_REASON : <TAB> <TAB> <TAB> value = struct . pack ( "" !H "" , v [ "" value "" ] ) <TAB> <TAB> v [ "" len "" ] = len ( value ) <TAB> <TAB> msg + = struct . pack ( self . _TLV_PACK_STR , v [ "" type "" ] , v [ "" len "" ] ) <TAB> <TAB> msg + = value <TAB> return msg ","if v [ "" type "" ] == BMP_TERM_TYPE_STRING : 
","if v [ "" type "" ] == BMP_TERM_TYPE_STRING :
",100.0,100.0,True
"def get_django_comment ( text : str , i : int ) - > str : <TAB> end = i + 4 <TAB> unclosed_end = 0 <TAB> while end < = len ( text ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return text [ i : end ] <TAB> <TAB> if not unclosed_end and text [ end ] == "" < "" : <TAB> <TAB> <TAB> unclosed_end = end <TAB> <TAB> end + = 1 <TAB> raise TokenizationException ( "" Unclosed comment "" , text [ i : unclosed_end ] ) ","if text [ end - 2 : end ] == "" #} "" : 
","if text [ end - 4 : end ] == "" > "" :
",78.79,57.11,False
"def ComboBoxDroppedHeightTest ( windows ) : <TAB> "" Check if each combobox height is the same as the reference "" <TAB> bugs = [ ] <TAB> for win in windows : <TAB> <TAB> if not win . ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> if win . Class ( ) != "" ComboBox "" or win . ref . Class ( ) != "" ComboBox "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bugs . append ( <TAB> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> win , <TAB> <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> <TAB> <TAB> { } , <TAB> <TAB> <TAB> <TAB> <TAB> testname , <TAB> <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return bugs ","if win . DroppedRect ( ) . height ( ) != win . ref . DroppedRect ( ) . height ( ) : 
","if win . dropped_height != win . ref . dropped_height ( ) :
",41.26,34.44,False
"def testBadModeArgument ( self ) : <TAB> # verify that we get a sensible error message for bad mode argument <TAB> bad_mode = "" qwerty "" <TAB> try : <TAB> <TAB> f = self . open ( TESTFN , bad_mode ) <TAB> except ValueError as msg : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s = str ( msg ) <TAB> <TAB> <TAB> if TESTFN in s or bad_mode not in s : <TAB> <TAB> <TAB> <TAB> self . fail ( "" bad error message for invalid mode:  %s "" % s ) <TAB> <TAB> # if msg.args[0] == 0, we're probably on Windows where there may be <TAB> <TAB> # no obvious way to discover why open() failed. <TAB> else : <TAB> <TAB> f . close ( ) <TAB> <TAB> self . fail ( "" no error for invalid mode:  %s "" % bad_mode ) ","if msg . args [ 0 ] != 0 : 
","if msg . args [ 0 ] != 0 :
",100.0,100.0,True
"def command_group_expired ( self , command_group_name ) : <TAB> try : <TAB> <TAB> deprecate_info = self . _command_loader . command_group_table [ <TAB> <TAB> <TAB> command_group_name <TAB> <TAB> ] . group_kwargs . get ( "" deprecate_info "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return deprecate_info . expired ( ) <TAB> except AttributeError : <TAB> <TAB> # Items with only token presence in the command table will not have any data. They can't be expired. <TAB> <TAB> pass <TAB> return False ","if deprecate_info : 
","if deprecate_info :
",78.12,100.0,True
"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB> <TAB> if val == 0 : <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert False ","elif val == 1 : 
","elif val == 1 :
",100.0,100.0,True
"def get_labels ( directory ) : <TAB> cache = get_labels . __cache <TAB> if directory not in cache : <TAB> <TAB> l = { } <TAB> <TAB> for t in get_visual_configs ( directory ) [ 0 ] [ LABEL_SECTION ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> Messager . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> "" In configuration, labels for  ' %s '  defined more than once. Only using the last set. "" <TAB> <TAB> <TAB> <TAB> <TAB> % t . storage_form ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> - 1 , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> # first is storage for, rest are labels. <TAB> <TAB> <TAB> l [ t . storage_form ( ) ] = t . terms [ 1 : ] <TAB> <TAB> cache [ directory ] = l <TAB> return cache [ directory ] ","if t . storage_form ( ) in l : 
","if t . terms [ 0 ] . index ( ) > 1 :
",39.44,13.91,False
"def try_split ( self , split_text : List [ str ] ) : <TAB> ret = [ ] <TAB> for i in split_text : <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> val = int ( i , 2 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> ret . append ( val ) <TAB> if len ( ret ) != 0 : <TAB> <TAB> ret = bytes ( ret ) <TAB> <TAB> logger . debug ( f "" binary successful, returning  { ret . __repr__ ( ) } "" ) <TAB> <TAB> return ret ","if val > 255 or val < 0 : 
","if val < 0 or val > 255 :
",62.22,36.56,False
"def setCellValue ( self , row_idx , col , value ) : <TAB> assert col . id == "" repls-marked "" <TAB> with self . _lock : <TAB> <TAB> rgroup = self . events [ row_idx ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> rgroup . _marked = value == "" true "" and True or False <TAB> if self . _tree : <TAB> <TAB> self . _tree . invalidateCell ( row_idx , col ) ","if not isinstance ( rgroup , findlib2 . ReplaceHitGroup ) : 
","if rgroup is None :
",26.2,4.23,False
"def create ( cls , settlement_manager , resource_id ) : <TAB> """"""Create a production chain that can produce the given resource."""""" <TAB> resource_producer = { } <TAB> for abstract_building in AbstractBuilding . buildings . values ( ) : <TAB> <TAB> for resource , production_line in abstract_building . lines . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> resource_producer [ resource ] = [ ] <TAB> <TAB> <TAB> resource_producer [ resource ] . append ( ( production_line , abstract_building ) ) <TAB> return ProductionChain ( settlement_manager , resource_id , resource_producer ) ","if resource not in resource_producer : 
","if resource not in resource_producer :
",100.0,100.0,True
def get_all_partition_sets ( self ) : <TAB> partition_sets = [ ] <TAB> if self . partitions_handle : <TAB> <TAB> partition_sets . extend ( self . partitions_handle . get_partition_sets ( ) ) <TAB> if self . scheduler_handle : <TAB> <TAB> partition_sets . extend ( <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> schedule_def . get_partition_set ( ) <TAB> <TAB> <TAB> <TAB> for schedule_def in self . scheduler_handle . all_schedule_defs ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> return partition_sets ,"if isinstance ( schedule_def , PartitionScheduleDefinition ) 
","if schedule_def . get_partition_set ( )
",27.46,14.99,False
"def _sendDatapointsNow ( self , datapoints ) : <TAB> metrics = { } <TAB> payload_pb = Payload ( ) <TAB> for metric , datapoint in datapoints : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> metric_pb = payload_pb . metrics . add ( ) <TAB> <TAB> <TAB> metric_pb . metric = metric <TAB> <TAB> <TAB> metrics [ metric ] = metric_pb <TAB> <TAB> else : <TAB> <TAB> <TAB> metric_pb = metrics [ metric ] <TAB> <TAB> point_pb = metric_pb . points . add ( ) <TAB> <TAB> point_pb . timestamp = int ( datapoint [ 0 ] ) <TAB> <TAB> point_pb . value = datapoint [ 1 ] <TAB> self . sendString ( payload_pb . SerializeToString ( ) ) ","if metric not in metrics : 
","if metric not in metrics :
",100.0,100.0,True
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> elif self . _naive or not self . _joins or self . verify_naive ( ) : <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self . _aggregate_rows : <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr ","elif self . _dicts : 
","elif self . _dicts :
",100.0,100.0,True
"def get_metrics ( ) : <TAB> classifier , feature_labels = load_classifier ( ) <TAB> available_metrics = ImgageMetrics . get_metric_classes ( ) <TAB> # todo review: DONE IN DOCS <TAB> #  effective_metrics isn't used after filling it with values <TAB> #  in the loops below <TAB> effective_metrics = [ ] <TAB> for metric in available_metrics : <TAB> <TAB> for label in feature_labels : <TAB> <TAB> <TAB> for label_part in metric . get_labels ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> effective_metrics . append ( metric ) <TAB> return ( classifier , feature_labels , available_metrics ) ","if label_part == label and metric not in effective_metrics : 
","if label_part not in effective_metrics :
",53.35,47.65,False
"def test_nic_names ( self ) : <TAB> p = subprocess . Popen ( [ "" ipconfig "" , "" /all "" ] , stdout = subprocess . PIPE ) <TAB> out = p . communicate ( ) [ 0 ] <TAB> if PY3 : <TAB> <TAB> out = str ( out , sys . stdout . encoding ) <TAB> nics = psutil . net_io_counters ( pernic = True ) . keys ( ) <TAB> for nic in nics : <TAB> <TAB> if "" pseudo-interface "" in nic . replace ( "" "" , "" - "" ) . lower ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . fail ( "" %r  nic wasn ' t found in  ' ipconfig /all '  output "" % nic ) ","if nic not in out : 
","if out == nic :
",46.61,11.48,False
"def convert_with_key ( self , key , value , replace = True ) : <TAB> result = self . configurator . convert ( value ) <TAB> # If the converted value is different, save for next time <TAB> if value is not result : <TAB> <TAB> if replace : <TAB> <TAB> <TAB> self [ key ] = result <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . parent = self <TAB> <TAB> <TAB> result . key = key <TAB> return result ","if type ( result ) in ( ConvertingDict , ConvertingList , ConvertingTuple ) : 
","elif result . parent is None :
",25.73,2.87,False
"def _EvaluateFile ( self , test_list , file ) : <TAB> ( name , ext ) = os . path . splitext ( file ) <TAB> if ext == "" .cc "" or ext == "" .cpp "" or ext == "" .c "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . SilentLog ( "" Found native test file  %s "" % file ) <TAB> <TAB> <TAB> test_list . append ( name ) ","if re . search ( "" _test$|_test_$|_unittest$|_unittest_$|^test_|Tests$ "" , name ) : 
","if self . _GetTestFile ( name ) is not None :
",31.62,1.36,False
"def leading_whitespace ( self , inputstring ) : <TAB> """"""Get leading whitespace."""""" <TAB> leading_ws = [ ] <TAB> for i , c in enumerate ( inputstring ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> leading_ws . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> <TAB> if self . indchar is None : <TAB> <TAB> <TAB> self . indchar = c <TAB> <TAB> elif c != self . indchar : <TAB> <TAB> <TAB> self . strict_err_or_warn ( "" found mixing of tabs and spaces "" , inputstring , i ) <TAB> return "" "" . join ( leading_ws ) ","if c in legal_indent_chars : 
","if self . is_whitespace ( c ) :
",27.63,5.93,False
"def ident_values ( self ) : <TAB> value = self . _ident_values <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> #<TAB>   not exposing attrs for now if orig_prefix is set.<TAB> <TAB> <MASK> <TAB> <TAB> <TAB> wrapped = self . wrapped <TAB> <TAB> <TAB> idents = getattr ( wrapped , "" ident_values "" , None ) <TAB> <TAB> <TAB> if idents : <TAB> <TAB> <TAB> <TAB> value = [ self . _wrap_hash ( ident ) for ident in idents ] <TAB> <TAB> <TAB> ##else: <TAB> <TAB> <TAB> ##<TAB> ident = self.ident<TAB> <TAB> <TAB> ##<TAB> if ident is not None:<TAB> <TAB> <TAB> ##<TAB> <TAB> value = [ident]<TAB> <TAB> self . _ident_values = value <TAB> return value ","if not self . orig_prefix : 
","if self . _orig_prefix :
",36.49,42.73,False
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if name not in found_names : <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> if not scoperef : <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ","if name . startswith ( expr ) : 
","if name is not None and expr in name :
",28.2,9.98,False
"def pid_from_name ( name ) : <TAB> # quick and dirty, works with all linux not depending on ps output <TAB> for pid in os . listdir ( "" /proc "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( pid ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> pname = "" "" <TAB> <TAB> with open ( "" /proc/ %s /cmdline "" % pid , "" r "" ) as f : <TAB> <TAB> <TAB> pname = f . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return int ( pid ) <TAB> raise ProcessException ( "" No process with such name:  %s "" % name ) ","if name in pname : 
","if pname == name :
",53.68,11.48,False
"def touch ( self ) : <TAB> if not self . exists ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . parent ( ) . touch ( ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> <TAB> node = self . _fs . touch ( self . pathnames , { } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AssertionError ( "" Not a folder:  %s "" % self . path ) <TAB> <TAB> if self . watcher : <TAB> <TAB> <TAB> self . watcher . emit ( "" created "" , self ) ","if not node . isdir : 
","if not node :
",37.26,38.75,False
"def setUp ( self ) : <TAB> BaseTestCase . setUp ( self ) <TAB> self . rawData = [ ] <TAB> self . dataByKey = { } <TAB> for i in range ( 1 , 11 ) : <TAB> <TAB> stringCol = "" String  %d "" % i <TAB> <TAB> fixedCharCol = ( "" Fixed Char  %d "" % i ) . ljust ( 40 ) <TAB> <TAB> rawCol = "" Raw  %d "" % i <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nullableCol = "" Nullable  %d "" % i <TAB> <TAB> else : <TAB> <TAB> <TAB> nullableCol = None <TAB> <TAB> dataTuple = ( i , stringCol , rawCol , fixedCharCol , nullableCol ) <TAB> <TAB> self . rawData . append ( dataTuple ) <TAB> <TAB> self . dataByKey [ i ] = dataTuple ","if i % 2 : 
","if i % 2 :
",100.0,100.0,True
"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> if vector : <TAB> <TAB> <TAB> if item < vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result ","if level + 1 == len ( hits ) : 
","if level + 1 == len ( hits ) :
",100.0,100.0,True
"def __repr__ ( self ) : <TAB> attrs = [ ] <TAB> for k in self . keydata : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attrs . append ( "" p( %d ) "" % ( self . size ( ) + 1 , ) ) <TAB> <TAB> elif hasattr ( self . key , k ) : <TAB> <TAB> <TAB> attrs . append ( k ) <TAB> if self . has_private ( ) : <TAB> <TAB> attrs . append ( "" private "" ) <TAB> return "" < %s  @0x %x %s > "" % ( self . __class__ . __name__ , id ( self ) , "" , "" . join ( attrs ) ) ","if k == "" p "" : 
","if k == "" p "" :
",100.0,100.0,True
"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if get_osx_theme ( ) == 1 : <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else : <TAB> <TAB> <TAB> theme = self . guess_system_theme ( ) <TAB> <TAB> <TAB> if theme == Dark : <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else :<TAB> # user settings have highest priority <TAB> <TAB> theme = self . _app . config . THEME <TAB> self . load_theme ( theme ) ","if sys . platform == "" darwin "" : 
","if self . _app . config . USE_DARK :
",31.68,4.46,False
"def _get_matching_bracket ( self , s , pos ) : <TAB> if s [ pos ] != "" { "" : <TAB> <TAB> return None <TAB> end = len ( s ) <TAB> depth = 1 <TAB> pos + = 1 <TAB> while pos != end : <TAB> <TAB> c = s [ pos ] <TAB> <TAB> if c == "" { "" : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif c == "" } "" : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> pos + = 1 <TAB> if pos < end and s [ pos ] == "" } "" : <TAB> <TAB> return pos <TAB> return None ","if depth == 0 : 
","elif depth == 0 :
",64.49,75.98,False
"def update_meter ( self , output , target , meters = { "" accuracy "" } ) : <TAB> output = self . __to_tensor ( output ) <TAB> target = self . __to_tensor ( target ) <TAB> for meter in meters : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __addmeter ( meter ) <TAB> <TAB> if meter in [ "" ap "" , "" map "" , "" confusion "" ] : <TAB> <TAB> <TAB> target_th = self . _ver2tensor ( target ) <TAB> <TAB> <TAB> self . meter [ meter ] . add ( output , target_th ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . meter [ meter ] . add ( output , target ) ","if meter not in self . meter . keys ( ) : 
","if meter not in self . meter :
",58.53,52.73,False
"def _reinit_optimizers_with_oss ( self ) : <TAB> optimizers = self . lightning_module . trainer . optimizers <TAB> for x , optimizer in enumerate ( optimizers ) : <TAB> <TAB> if is_lightning_optimizer ( optimizer ) : <TAB> <TAB> <TAB> optimizer = optimizer . _optimizer <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> optim_class = type ( optimizer ) <TAB> <TAB> <TAB> zero_optimizer = OSS ( <TAB> <TAB> <TAB> <TAB> params = optimizer . param_groups , optim = optim_class , * * optimizer . defaults <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> optimizers [ x ] = zero_optimizer <TAB> <TAB> <TAB> del optimizer <TAB> trainer = self . lightning_module . trainer <TAB> trainer . optimizers = optimizers <TAB> trainer . convert_to_lightning_optimizers ( ) ","if not isinstance ( optimizer , OSS ) : 
","if optimizer is not None :
",26.83,6.96,False
"def OnSelChanged ( self , event ) : <TAB> self . item = event . GetItem ( ) <TAB> if self . item : <TAB> <TAB> self . log . write ( "" OnSelChanged:  %s "" % self . GetItemText ( self . item ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . write ( <TAB> <TAB> <TAB> <TAB> "" , BoundingRect:  %s \n "" % self . GetBoundingRect ( self . item , True ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . log . write ( "" \n "" ) <TAB> event . Skip ( ) ","if wx . Platform == "" __WXMSW__ "" : 
","if self . GetBoundingRect :
",31.68,2.32,False
"def parse_batch ( args ) : <TAB> errmsg = "" Invalid batch definition: batch entry has to be defined as RULE=BATCH/BATCHES (with integers BATCH <= BATCHES, BATCH >= 1). "" <TAB> if args . batch is not None : <TAB> <TAB> rule , batchdef = parse_key_value_arg ( args . batch , errmsg = errmsg ) <TAB> <TAB> try : <TAB> <TAB> <TAB> batch , batches = batchdef . split ( "" / "" ) <TAB> <TAB> <TAB> batch = int ( batch ) <TAB> <TAB> <TAB> batches = int ( batches ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise ValueError ( errmsg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( errmsg ) <TAB> <TAB> return Batch ( rule , batch , batches ) <TAB> return None ","if batch > batches or batch < 1 : 
","if len ( batch ) != len ( batches ) :
",26.53,4.79,False
"def get_foreign_key_columns ( self , engine , table_name ) : <TAB> foreign_keys = set ( ) <TAB> table = db_utils . get_table ( engine , table_name ) <TAB> inspector = reflection . Inspector . from_engine ( engine ) <TAB> for column_dict in inspector . get_columns ( table_name ) : <TAB> <TAB> column_name = column_dict [ "" name "" ] <TAB> <TAB> column = getattr ( table . c , column_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> foreign_keys . add ( column_name ) <TAB> return foreign_keys ","if column . foreign_keys : 
","if column . foreign_key :
",64.48,64.35,False
"def update ( self , t ) : <TAB> l = int ( t * self . nr_of_tiles ) <TAB> for i in range ( self . nr_of_tiles ) : <TAB> <TAB> t = self . tiles_order [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . turn_off_tile ( t ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . turn_on_tile ( t ) ","if i < l : 
","if i < l :
",100.0,100.0,True
"def read ( self , amt = None ) : <TAB> # the _rbuf test is only in this first if for speed.  It's not <TAB> # logically necessary <TAB> if self . _rbuf and not amt is None : <TAB> <TAB> L = len ( self . _rbuf ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> amt - = L <TAB> <TAB> else : <TAB> <TAB> <TAB> s = self . _rbuf [ : amt ] <TAB> <TAB> <TAB> self . _rbuf = self . _rbuf [ amt : ] <TAB> <TAB> <TAB> return s <TAB> s = self . _rbuf + self . _raw_read ( amt ) <TAB> self . _rbuf = b "" "" <TAB> return s ","if amt > L : 
","if amt > L :
",100.0,100.0,True
"def draw_menu_button ( self , context , layout , node , text ) : <TAB> if ( <TAB> <TAB> hasattr ( node . id_data , "" sv_show_socket_menus "" ) <TAB> <TAB> and node . id_data . sv_show_socket_menus <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> layout . menu ( "" SV_MT_SocketOptionsMenu "" , text = "" "" , icon = "" TRIA_DOWN "" ) ","if self . is_output or self . is_linked or not self . use_prop : 
","if text :
",25.55,0.0,False
"def __enter__ ( self ) : <TAB> with DB . connection_context ( ) : <TAB> <TAB> session_record = SessionRecord ( ) <TAB> <TAB> session_record . f_session_id = self . _session_id <TAB> <TAB> session_record . f_engine_name = self . _engine_name <TAB> <TAB> session_record . f_engine_type = EngineType . STORAGE <TAB> <TAB> # TODO: engine address <TAB> <TAB> session_record . f_engine_address = { } <TAB> <TAB> session_record . f_create_time = current_timestamp ( ) <TAB> <TAB> rows = session_record . save ( force_insert = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( f "" create session record  { self . _session_id }  failed "" ) <TAB> <TAB> LOGGER . debug ( f "" save session  { self . _session_id }  record "" ) <TAB> self . create ( ) <TAB> return self ","if rows != 1 : 
","if not rows :
",28.94,12.75,False
"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB> <TAB> if self . server : <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self ) ","if self . sl_hdlr : 
","if self . sl_hdlr :
",100.0,100.0,True
"def _dec_device ( self , srcdev , dstdev ) : <TAB> if srcdev : <TAB> <TAB> self . srcdevs [ srcdev ] - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . srcdevs [ srcdev ] <TAB> <TAB> self . _set_limits ( "" read "" , self . srcdevs ) <TAB> if dstdev : <TAB> <TAB> self . dstdevs [ dstdev ] - = 1 <TAB> <TAB> if self . dstdevs [ dstdev ] == 0 : <TAB> <TAB> <TAB> del self . dstdevs [ dstdev ] <TAB> <TAB> self . _set_limits ( "" write "" , self . dstdevs ) ","if self . srcdevs [ srcdev ] == 0 : 
","if self . srcdevs [ srcdev ] == 0 :
",100.0,100.0,True
"def array_for ( self , i ) : <TAB> if 0 < = i < self . _cnt : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _tail <TAB> <TAB> node = self . _root <TAB> <TAB> level = self . _shift <TAB> <TAB> while level > 0 : <TAB> <TAB> <TAB> assert isinstance ( node , Node ) <TAB> <TAB> <TAB> node = node . _array [ ( i >> level ) & 0x01F ] <TAB> <TAB> <TAB> level - = 5 <TAB> <TAB> return node . _array <TAB> affirm ( False , u "" Index out of Range "" ) ","if i > = self . tailoff ( ) : 
","if i > = self . tail_offset :
",59.74,53.73,False
"def convert_tensor ( self , offsets , sizes ) : <TAB> results = [ ] <TAB> for b , batch in enumerate ( offsets ) : <TAB> <TAB> utterances = [ ] <TAB> <TAB> for p , utt in enumerate ( batch ) : <TAB> <TAB> <TAB> size = sizes [ b ] [ p ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> utterances . append ( utt [ 0 : size ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> utterances . append ( torch . tensor ( [ ] , dtype = torch . int ) ) <TAB> <TAB> results . append ( utterances ) <TAB> return results ","if sizes [ b ] [ p ] > 0 : 
","if size > 0 :
",29.91,12.87,False
"def _predict_proba ( self , X , preprocess = True ) : <TAB> if preprocess : <TAB> <TAB> X = self . preprocess ( X ) <TAB> if self . problem_type == REGRESSION : <TAB> <TAB> return self . model . predict ( X ) <TAB> y_pred_proba = self . model . predict_proba ( X ) <TAB> if self . problem_type == BINARY : <TAB> <TAB> if len ( y_pred_proba . shape ) == 1 : <TAB> <TAB> <TAB> return y_pred_proba <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return y_pred_proba [ : , 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return y_pred_proba <TAB> elif y_pred_proba . shape [ 1 ] > 2 : <TAB> <TAB> return y_pred_proba <TAB> else : <TAB> <TAB> return y_pred_proba [ : , 1 ] ","elif y_pred_proba . shape [ 1 ] > 1 : 
","elif len ( y_pred_proba . shape ) == 2 :
",36.13,42.61,False
def timeout ( self ) : <TAB> now = ptime . time ( ) <TAB> dt = now - self . lastPlayTime <TAB> if dt < 0 : <TAB> <TAB> return <TAB> n = int ( self . playRate * dt ) <TAB> if n != 0 : <TAB> <TAB> self . lastPlayTime + = float ( n ) / self . playRate <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . play ( 0 ) <TAB> <TAB> self . jumpFrames ( n ) ,"if self . currentIndex + n > self . image . shape [ self . axes [ "" t "" ] ] : 
","if self . lastPlayTime > = self . playRate :
",25.97,5.82,False
"def __init__ ( self , data , weights = None , ddof = 0 ) : <TAB> self . data = np . asarray ( data ) <TAB> if weights is None : <TAB> <TAB> self . weights = np . ones ( self . data . shape [ 0 ] ) <TAB> else : <TAB> <TAB> self . weights = np . asarray ( weights ) . astype ( float ) <TAB> <TAB> # TODO: why squeeze? <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . weights = self . weights . squeeze ( ) <TAB> self . ddof = ddof ","if len ( self . weights . shape ) > 1 and len ( self . weights ) > 1 : 
","if self . weights . ndim > 1 :
",38.53,11.76,False
"def writerow ( self , row ) : <TAB> unicode_row = [ ] <TAB> for col in row : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unicode_row . append ( col . encode ( "" utf-8 "" ) . strip ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> unicode_row . append ( col ) <TAB> self . writer . writerow ( unicode_row ) <TAB> # Fetch UTF-8 output from the queue ... <TAB> data = self . queue . getvalue ( ) <TAB> data = data . decode ( "" utf-8 "" ) <TAB> # ... and reencode it into the target encoding <TAB> data = self . encoder . encode ( data ) <TAB> # write to the target stream <TAB> self . stream . write ( data ) <TAB> # empty queue <TAB> self . queue . truncate ( 0 ) ","if type ( col ) == str or type ( col ) == unicode : 
","if isinstance ( col , unicode ) :
",26.68,4.72,False
"def __init__ ( self , choices , allow_blank = False , * * kwargs ) : <TAB> self . choiceset = choices <TAB> self . allow_blank = allow_blank <TAB> self . _choices = dict ( ) <TAB> # Unpack grouped choices <TAB> for k , v in choices : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k2 , v2 in v : <TAB> <TAB> <TAB> <TAB> self . _choices [ k2 ] = v2 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _choices [ k ] = v <TAB> super ( ) . __init__ ( * * kwargs ) ","if type ( v ) in [ list , tuple ] : 
","if isinstance ( v , ( list , tuple ) ) :
",30.75,17.83,False
"def simp_ext ( _ , expr ) : <TAB> if expr . op . startswith ( "" zeroExt_ "" ) : <TAB> <TAB> arg = expr . args [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return arg <TAB> <TAB> return ExprCompose ( arg , ExprInt ( 0 , expr . size - arg . size ) ) <TAB> if expr . op . startswith ( "" signExt_ "" ) : <TAB> <TAB> arg = expr . args [ 0 ] <TAB> <TAB> add_size = expr . size - arg . size <TAB> <TAB> new_expr = ExprCompose ( <TAB> <TAB> <TAB> arg , <TAB> <TAB> <TAB> ExprCond ( <TAB> <TAB> <TAB> <TAB> arg . msb ( ) , ExprInt ( size2mask ( add_size ) , add_size ) , ExprInt ( 0 , add_size ) <TAB> <TAB> <TAB> ) , <TAB> <TAB> ) <TAB> <TAB> return new_expr <TAB> return expr ","if expr . size == arg . size : 
","if arg . size == 0 :
",44.62,36.83,False
"def mark_differences ( value : str , compare_against : str ) : <TAB> result = [ ] <TAB> for i , char in enumerate ( value ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result . append ( ' <font color= "" red "" > {} </font> ' . format ( char ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result . append ( char ) <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> result . append ( char ) <TAB> return "" "" . join ( result ) ","if char != compare_against [ i ] : 
","if i == 0 and compare_against == char :
",26.98,14.69,False
"def run_query ( self , query , user ) : <TAB> url = "" %s %s "" % ( self . base_url , "" & "" . join ( query . split ( "" \n "" ) ) ) <TAB> error = None <TAB> data = None <TAB> try : <TAB> <TAB> response = requests . get ( url , auth = self . auth , verify = self . verify ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = _transform_result ( response ) <TAB> <TAB> else : <TAB> <TAB> <TAB> error = "" Failed getting results ( %d ) "" % response . status_code <TAB> except Exception as ex : <TAB> <TAB> data = None <TAB> <TAB> error = str ( ex ) <TAB> return data , error ","if response . status_code == 200 : 
","if response . status_code == 200 :
",100.0,100.0,True
"def on_enter ( self ) : <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB> <TAB> else : <TAB> <TAB> <TAB> if not self . focus_color : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = self . focus_color ","if hasattr ( self , "" theme_cls "" ) and not self . focus_color : 
","if self . focus_color == self . theme_cls . bg_normal :
",32.08,27.55,False
"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . storage_account_name is not None : <TAB> <TAB> <TAB> <TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( ) ","if self . hosted_service_name is not None : 
","if self . hosted_service_name is not None :
",100.0,100.0,True
"def name2cp ( k ) : <TAB> if k == "" apos "" : <TAB> <TAB> return ord ( "" ' "" ) <TAB> if hasattr ( htmlentitydefs , "" name2codepoint "" ) :<TAB> # requires Python 2.3 <TAB> <TAB> return htmlentitydefs . name2codepoint [ k ] <TAB> else : <TAB> <TAB> k = htmlentitydefs . entitydefs [ k ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return int ( k [ 2 : - 1 ] )<TAB> # not in latin-1 <TAB> <TAB> return ord ( codecs . latin_1_decode ( k ) [ 0 ] ) ","if k . startswith ( "" &# "" ) and k . endswith ( "" ; "" ) : 
","if k . startswith ( "" 0x "" ) and k [ : 2 ] == "" 0x "" :
",63.2,36.31,False
"def _para_set ( self , params , part ) : <TAB> if len ( params ) == 0 : <TAB> <TAB> result = suggest ( [ i . get_name ( ) for i in self . _options ] , part ) <TAB> <TAB> return result <TAB> elif len ( params ) == 1 : <TAB> <TAB> paramName = params [ 0 ] <TAB> <TAB> if paramName not in self . _options : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> opt = self . _options [ paramName ] <TAB> <TAB> paramType = opt . get_type ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values = [ opt . get_default_value ( ) == "" True "" and "" False "" or "" True "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> values = self . _memory [ paramName ] <TAB> <TAB> return suggest ( values , part ) <TAB> else : <TAB> <TAB> return [ ] ","if paramType == "" boolean "" : 
","if paramType == "" bool "" :
",74.63,59.46,False
"def hexcmp ( x , y ) : <TAB> try : <TAB> <TAB> a = int ( x , 16 ) <TAB> <TAB> b = int ( y , 16 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> if a > b : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> return cmp ( x , y ) ","if a < b : 
","if a < b :
",100.0,100.0,True
"def execute ( self , statement , arguments = None ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> if arguments : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement , arguments ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor . execute ( statement ) <TAB> <TAB> except sqlite3 . OperationalError as ex : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> if statement . lstrip ( ) . upper ( ) . startswith ( "" SELECT "" ) : <TAB> <TAB> return self . cursor . fetchall ( ) ","if "" locked "" not in getSafeExString ( ex ) : 
","if ex . errno != sqlite3 . ENOENT :
",26.27,5.0,False
"def _test_forever ( self , tests ) : <TAB> while True : <TAB> <TAB> for test_name in tests : <TAB> <TAB> <TAB> yield test_name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if self . ns . fail_env_changed and self . environment_changed : <TAB> <TAB> <TAB> <TAB> return ","if self . bad : 
","if self . test_loop . is_running ( ) :
",43.86,12.36,False
"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> user = self . _users [ username ] <TAB> <TAB> if user . room : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> self . _users . pop ( username ) <TAB> <TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB> <TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB> <TAB> self . _client . lastLeftTime = time . time ( ) <TAB> <TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( ) ","if self . isRoomSame ( user . room ) : 
","if self . _client . lastLeftUser == user . room . name :
",41.39,17.1,False
"def AutoTest ( ) : <TAB> with open ( sys . argv [ 1 ] , "" rb "" ) as f : <TAB> <TAB> for line in f . read ( ) . split ( b "" \n "" ) : <TAB> <TAB> <TAB> line = BYTES2SYSTEMSTR ( line . strip ( ) ) <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> elif line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> <TAB> print ( line ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print ( "" >>>  "" + line ) <TAB> <TAB> <TAB> <TAB> os . system ( line ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( "" \n press enter to continue... "" ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> input ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raw_input ( ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( "" \n "" ) ","if PY3 : 
","if sys . platform == "" win32 "" :
",29.31,4.99,False
"def get_first_field ( layout , clz ) : <TAB> for layout_object in layout . fields : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return layout_object <TAB> <TAB> elif hasattr ( layout_object , "" get_field_names "" ) : <TAB> <TAB> <TAB> gf = get_first_field ( layout_object , clz ) <TAB> <TAB> <TAB> if gf : <TAB> <TAB> <TAB> <TAB> return gf ","if issubclass ( layout_object . __class__ , clz ) : 
","if isinstance ( layout_object , clz ) :
",41.67,29.7,False
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB> <TAB> if key not in valid_keys : <TAB> <TAB> <TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB> <TAB> if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> ) ","if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : 
","if key in kwargs [ "" event_data "" ] :
",47.74,40.28,False
"def visit_productionlist ( self , node ) : <TAB> self . new_state ( ) <TAB> names = [ ] <TAB> for production in node : <TAB> <TAB> names . append ( production [ "" tokenname "" ] ) <TAB> maxlen = max ( len ( name ) for name in names ) <TAB> for production in node : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_text ( production [ "" tokenname "" ] . ljust ( maxlen ) + ""  ::= "" ) <TAB> <TAB> <TAB> lastname = production [ "" tokenname "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> self . add_text ( "" %s<TAB>  "" % ( "" "" * len ( lastname ) ) ) <TAB> <TAB> self . add_text ( production . astext ( ) + self . nl ) <TAB> self . end_state ( wrap = False ) <TAB> raise nodes . SkipNode ","if production [ "" tokenname "" ] : 
","if production [ "" tokenname "" ] :
",100.0,100.0,True
"def uuid ( self ) : <TAB> if not getattr ( self , "" _uuid "" , None ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _uuid = self . repository . _kp_uuid ( <TAB> <TAB> <TAB> <TAB> self . path <TAB> <TAB> <TAB> )<TAB> # Use repository UUID (even if None) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _uuid = str ( uuid . uuid4 ( ) ) <TAB> return self . _uuid ","if self . repository is not None : 
","if self . repository :
",47.74,38.81,False
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> if v == "" ANY "" : <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> elif v in self . _definition : <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ","if isinstance ( self . _definition , dict ) : 
","if self . _definition :
",35.94,24.44,False
"def make ( self ) : <TAB> pygments_dir = join ( self . dir , "" externals "" , "" pygments "" ) <TAB> if exists ( pygments_dir ) : <TAB> <TAB> run_in_dir ( "" hg pull "" , pygments_dir , self . log . info ) <TAB> <TAB> run_in_dir ( "" hg update "" , pygments_dir , self . log . info ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( dirname ( pygments_dir ) ) <TAB> <TAB> run_in_dir ( <TAB> <TAB> <TAB> "" hg clone http://dev.pocoo.org/hg/pygments-main  %s "" <TAB> <TAB> <TAB> % basename ( pygments_dir ) , <TAB> <TAB> <TAB> dirname ( pygments_dir ) , <TAB> <TAB> <TAB> self . log . info , <TAB> <TAB> ) ","if not exists ( dirname ( pygments_dir ) ) : 
","if not exists ( dirname ( pygments_dir ) ) :
",100.0,100.0,True
def set_field ( self ) : <TAB> i = 0 <TAB> for string in self . display_string : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . config [ self . field + str ( i ) ] = self . conversion_fn ( self . str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . config [ self . field + str ( i ) ] = self . str [ i ] <TAB> <TAB> i = i + 1 ,"if self . conversion_fn : 
","if self . conversion_fn :
",100.0,100.0,True
"def cleanup ( self ) : <TAB> with self . lock : <TAB> <TAB> for proc in self . processes : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> proc . join ( ) <TAB> <TAB> <TAB> self . processes . remove ( proc ) <TAB> <TAB> <TAB> log . debug ( "" Subprocess  %s  cleaned up "" , proc . name ) ","if proc . is_alive ( ) : 
","if proc . is_alive ( ) :
",100.0,100.0,True
"def setup ( self , gen ) : <TAB> Node . setup ( self , gen ) <TAB> for c in self . children : <TAB> <TAB> c . setup ( gen ) <TAB> if not self . accepts_epsilon : <TAB> <TAB> # If it's not already accepting epsilon, it might now do so. <TAB> <TAB> for c in self . children : <TAB> <TAB> <TAB> # any non-epsilon means all is non-epsilon <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> self . accepts_epsilon = 1 <TAB> <TAB> <TAB> gen . changed ( ) ","if not c . accepts_epsilon : 
","if c . type == "" epsilon "" :
",35.23,10.55,False
"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack + = 1 <TAB> <TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB> <TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack - = 1 <TAB> <TAB> message . ack ( ) <TAB> <TAB> self . completed_calls + = 1 <TAB> <TAB> if self . completed_calls > = self . _resolve_at_msg_count : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . done_future . set_result ( None ) ","if not self . done_future . done ( ) : 
","if self . done_future :
",34.32,32.74,False
"def build_canned_image_list ( path ) : <TAB> layers_path = get_bitbake_var ( "" BBLAYERS "" ) <TAB> canned_wks_layer_dirs = [ ] <TAB> if layers_path is not None : <TAB> <TAB> for layer_path in layers_path . split ( ) : <TAB> <TAB> <TAB> for wks_path in ( WIC_DIR , SCRIPTS_CANNED_IMAGE_DIR ) : <TAB> <TAB> <TAB> <TAB> cpath = os . path . join ( layer_path , wks_path ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> cpath = os . path . join ( path , CANNED_IMAGE_DIR ) <TAB> canned_wks_layer_dirs . append ( cpath ) <TAB> return canned_wks_layer_dirs ","if os . path . isdir ( cpath ) : 
","if os . path . isdir ( cpath ) :
",100.0,100.0,True
"def _recv_loop ( self ) - > None : <TAB> async with self . _ws as connection : <TAB> <TAB> self . _connected = True <TAB> <TAB> self . connection = connection <TAB> <TAB> while self . _connected : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> resp = await self . connection . recv ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> await self . _on_message ( resp ) <TAB> <TAB> <TAB> except ( websockets . ConnectionClosed , ConnectionResetError ) : <TAB> <TAB> <TAB> <TAB> logger . info ( "" connection closed "" ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> await asyncio . sleep ( 0 ) <TAB> if self . _connected : <TAB> <TAB> self . _loop . create_task ( self . dispose ( ) ) ","if resp : 
","if resp :
",78.12,0.0,False
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> if start in line : <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line : <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ] ","if end and end in line : 
","if end and end in line :
",100.0,100.0,True
"def handle_parse_result ( self , ctx , opts , args ) : <TAB> if self . name in opts : <TAB> <TAB> if self . mutually_exclusive . intersection ( opts ) : <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _raise_exclusive_error ( ) <TAB> return super ( MutuallyExclusiveOption , self ) . handle_parse_result ( ctx , opts , args ) ","if self . multiple and len ( set ( opts [ self . name ] ) ) > 1 : 
","elif self . exclusive_not in opts :
",30.43,3.34,False
"def write ( self , s ) : <TAB> if self . interactive : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . active_mode . write ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> component . get ( "" CmdLine "" ) . add_line ( s , False ) <TAB> <TAB> <TAB> self . events . append ( s ) <TAB> else : <TAB> <TAB> print ( colors . strip_colors ( s ) ) ","if isinstance ( self . active_mode , deluge . ui . console . modes . cmdline . CmdLine ) : 
","if self . active_mode :
",31.87,7.85,False
"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> if name . startswith ( "" . "" ) or name == "" lastsnap.jpg "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os . path . join ( path , name ) <TAB> <TAB> st = os . lstat ( pathname ) <TAB> <TAB> mode = st . st_mode <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> files . extend ( findfiles ( pathname ) ) <TAB> <TAB> elif stat . S_ISREG ( mode ) : <TAB> <TAB> <TAB> files . append ( ( pathname , name , st ) ) <TAB> return files ","if stat . S_ISDIR ( mode ) : 
","if stat . S_ISLNK ( mode ) :
",75.15,65.8,False
"def _get_documented_completions ( self , table , startswith = None ) : <TAB> names = [ ] <TAB> for key , command in table . items ( ) : <TAB> <TAB> if getattr ( command , "" _UNDOCUMENTED "" , False ) : <TAB> <TAB> <TAB> # Don't tab complete undocumented commands/params <TAB> <TAB> <TAB> continue <TAB> <TAB> if startswith is not None and not key . startswith ( startswith ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> names . append ( key ) <TAB> return names ","if getattr ( command , "" positional_arg "" , False ) : 
","if command . _doc_command != self . _documented_command :
",26.17,3.46,False
"def fix_newlines ( lines ) : <TAB> """"""Convert newlines to unix."""""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines [ i ] = line [ : - 2 ] + "" \n "" <TAB> <TAB> elif line . endswith ( "" \r "" ) : <TAB> <TAB> <TAB> lines [ i ] = line [ : - 1 ] + "" \n "" ","if line . endswith ( "" \r \n "" ) : 
","if line . endswith ( "" \n "" ) :
",64.0,75.34,False
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> if end < self . plugin_args . start : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self . plugin_args . end : <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ","if self . plugin_args . start < = vaddr < = self . plugin_args . end : 
","if self . plugin_args . start < = vaddr < = self . plugin_args . end :
",100.0,100.0,True
"def get_shape_at_node ( self , node , assumptions ) : <TAB> for k , v in assumptions . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return v <TAB> if node . inputs : <TAB> <TAB> return node . container . shape ( <TAB> <TAB> <TAB> input_shapes = [ <TAB> <TAB> <TAB> <TAB> self . get_shape_at_node ( input_node , assumptions ) <TAB> <TAB> <TAB> <TAB> for input_node in node . inputs <TAB> <TAB> <TAB> ] <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return node . container . shape ( None ) ","if k in node . names : 
","if k in node . inputs :
",82.52,64.35,False
"def fix_doc ( self , doc ) : <TAB> type = doc . get ( "" type "" , { } ) . get ( "" key "" ) <TAB> if type == "" /type/work "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # some record got empty author records because of an error <TAB> <TAB> <TAB> # temporary hack to fix <TAB> <TAB> <TAB> doc [ "" authors "" ] = [ <TAB> <TAB> <TAB> <TAB> a for a in doc [ "" authors "" ] if "" author "" in a and "" key "" in a [ "" author "" ] <TAB> <TAB> <TAB> ] <TAB> elif type == "" /type/edition "" : <TAB> <TAB> # get rid of title_prefix. <TAB> <TAB> if "" title_prefix "" in doc : <TAB> <TAB> <TAB> title = doc [ "" title_prefix "" ] . strip ( ) + "" "" + doc . get ( "" title "" , "" "" ) <TAB> <TAB> <TAB> doc [ "" title "" ] = title . strip ( ) <TAB> <TAB> <TAB> del doc [ "" title_prefix "" ] <TAB> return doc ","if doc . get ( "" authors "" ) : 
","if "" authors "" in doc :
",35.58,18.94,False
"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB> <TAB> gate = column [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> elif isinstance ( gate , ParityControlCell ) : <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column [ i ] = None <TAB> <TAB> <TAB> self . _basis_change + = gate . _basis_change <TAB> <TAB> <TAB> self . qubits + = gate . qubits <TAB> <TAB> elif gate is not None : <TAB> <TAB> <TAB> column [ i ] = gate . controlled_by ( self . qubits [ 0 ] ) ","if gate is self : 
","if gate is None :
",39.55,42.73,False
"def onSync ( self , auto = False , reload = True ) : <TAB> if not auto or ( <TAB> <TAB> self . pm . profile [ "" syncKey "" ] and self . pm . profile [ "" autoSync "" ] and not self . safeMode <TAB> ) : <TAB> <TAB> from aqt . sync import SyncManager <TAB> <TAB> if not self . unloadCollection ( ) : <TAB> <TAB> <TAB> return <TAB> <TAB> # set a sync state so the refresh timer doesn't fire while deck <TAB> <TAB> # unloaded <TAB> <TAB> self . state = "" sync "" <TAB> <TAB> self . syncer = SyncManager ( self , self . pm ) <TAB> <TAB> self . syncer . sync ( ) <TAB> if reload : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . loadCollection ( ) ","if not self . col : 
","if self . pm . profile [ "" syncKey "" ] and self . safeMode :
",34.49,5.82,False
"def _has_url_match ( self , match , request_url ) : <TAB> url = match [ "" url "" ] <TAB> if _is_string ( url ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _has_strict_url_match ( url , request_url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url_without_qs = request_url . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> return url == url_without_qs <TAB> elif isinstance ( url , re . _pattern_type ) and url . match ( request_url ) : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return False ","if match [ "" match_querystring "" ] : 
","if re . _pattern_type in url :
",26.77,5.52,False
"def pool_image ( self , image ) : <TAB> if self . count < self . pool_size : <TAB> <TAB> self . pool . append ( image ) <TAB> <TAB> self . count + = 1 <TAB> <TAB> return image <TAB> else : <TAB> <TAB> p = random . random ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> random_id = random . randint ( 0 , self . pool_size - 1 ) <TAB> <TAB> <TAB> temp = self . pool [ random_id ] <TAB> <TAB> <TAB> self . pool [ random_id ] = image <TAB> <TAB> <TAB> return temp <TAB> <TAB> else : <TAB> <TAB> <TAB> return image ","if p > 0.5 : 
","if p > 0.5 :
",100.0,100.0,True
"def get_target_dimensions ( self ) : <TAB> width , height = self . engine . size <TAB> for operation in self . operations : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> width = operation [ "" right "" ] - operation [ "" left "" ] <TAB> <TAB> <TAB> height = operation [ "" bottom "" ] - operation [ "" top "" ] <TAB> <TAB> if operation [ "" type "" ] == "" resize "" : <TAB> <TAB> <TAB> width = operation [ "" width "" ] <TAB> <TAB> <TAB> height = operation [ "" height "" ] <TAB> return ( width , height ) ","if operation [ "" type "" ] == "" crop "" : 
","if operation [ "" type "" ] == "" resize "" :
",88.63,79.11,False
"def validate_matrix ( matrix ) : <TAB> if not matrix : <TAB> <TAB> return None <TAB> for key , value in matrix . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> "" ` {} ` defines a non uniform distribution,  "" <TAB> <TAB> <TAB> <TAB> "" and it cannot be used with bayesian optimization. "" . format ( key ) <TAB> <TAB> <TAB> ) <TAB> return matrix ","if value . is_distribution and not value . is_uniform : 
","if not uniform . is_uniform ( value ) :
",36.32,21.24,False
"def scm_to_conandata ( self ) : <TAB> try : <TAB> <TAB> scm_to_conandata = get_env ( "" CONAN_SCM_TO_CONANDATA "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> scm_to_conandata = self . get_item ( "" general.scm_to_conandata "" ) <TAB> <TAB> return scm_to_conandata . lower ( ) in ( "" 1 "" , "" true "" ) <TAB> except ConanException : <TAB> <TAB> return False ","if scm_to_conandata is None : 
","if not scm_to_conandata :
",28.67,49.63,False
"def _link_vrf_table ( self , vrf_table , rt_list ) : <TAB> route_family = vrf_table . route_family <TAB> for rt in rt_list : <TAB> <TAB> rt_rf_id = rt + "" : "" + str ( route_family ) <TAB> <TAB> table_set = self . _tables_for_rt . get ( rt_rf_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> table_set = set ( ) <TAB> <TAB> <TAB> self . _tables_for_rt [ rt_rf_id ] = table_set <TAB> <TAB> table_set . add ( vrf_table ) <TAB> <TAB> LOG . debug ( "" Added VrfTable  %s  to import RT table list:  %s "" , vrf_table , rt ) ","if table_set is None : 
","if table_set is None :
",100.0,100.0,True
"def add_tags ( <TAB> self , cve_results : Dict [ str , Dict [ str , Dict [ str , str ] ] ] , file_object : FileObject ) : <TAB> # results structure: {'component': {'cve_id': {'score2': '6.4', 'score3': 'N/A'}}} <TAB> for component in cve_results : <TAB> <TAB> for cve_id in cve_results [ component ] : <TAB> <TAB> <TAB> entry = cve_results [ component ] [ cve_id ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . add_analysis_tag ( <TAB> <TAB> <TAB> <TAB> <TAB> file_object , "" CVE "" , "" critical CVE "" , TagColor . RED , True <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return ","if self . _entry_has_critical_rating ( entry ) : 
","if entry [ "" score2 "" ] == "" 6.4 "" and entry [ "" score3 "" ] == "" N/A "" :
",26.29,1.96,False
"def _validate ( self ) : <TAB> try : <TAB> <TAB> super ( CustomClassifier , self ) . _validate ( ) <TAB> except UnsupportedDataType : <TAB> <TAB> if self . dtype in FACTOR_DTYPES : <TAB> <TAB> <TAB> raise UnsupportedDataType ( <TAB> <TAB> <TAB> <TAB> typename = type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> dtype = self . dtype , <TAB> <TAB> <TAB> <TAB> hint = "" Did you mean to create a CustomFactor? "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise UnsupportedDataType ( <TAB> <TAB> <TAB> <TAB> typename = type ( self ) . __name__ , <TAB> <TAB> <TAB> <TAB> dtype = self . dtype , <TAB> <TAB> <TAB> <TAB> hint = "" Did you mean to create a CustomFilter? "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> raise ","elif self . dtype in FILTER_DTYPES : 
","elif self . dtype in FILTER_DTYPES :
",100.0,100.0,True
"def formatMessage ( self , record ) : <TAB> recordcopy = copy ( record ) <TAB> levelname = recordcopy . levelname <TAB> seperator = "" "" * ( 8 - len ( recordcopy . levelname ) ) <TAB> if self . use_colors : <TAB> <TAB> levelname = self . color_level_name ( levelname , recordcopy . levelno ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> recordcopy . msg = recordcopy . __dict__ [ "" color_message "" ] <TAB> <TAB> <TAB> recordcopy . __dict__ [ "" message "" ] = recordcopy . getMessage ( ) <TAB> recordcopy . __dict__ [ "" levelprefix "" ] = levelname + "" : "" + seperator <TAB> return super ( ) . formatMessage ( recordcopy ) ","if "" color_message "" in recordcopy . __dict__ : 
","if recordcopy . msg is None :
",33.09,4.98,False
"def dumpregs ( self ) : <TAB> for reg in ( <TAB> <TAB> list ( self . regs . retaddr ) <TAB> <TAB> + list ( self . regs . misc ) <TAB> <TAB> + list ( self . regs . common ) <TAB> <TAB> + list ( self . regs . flags ) <TAB> ) : <TAB> <TAB> enum = self . get_reg_enum ( reg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> debug ( "" # Could not dump register  %r "" % reg ) <TAB> <TAB> <TAB> continue <TAB> <TAB> name = "" U.x86_const.UC_X86_REG_ %s "" % reg . upper ( ) <TAB> <TAB> value = self . uc . reg_read ( enum ) <TAB> <TAB> debug ( "" uc.reg_read( %(name)s ) ==>  %(value)x "" % locals ( ) ) ","if not reg or enum is None : 
","if enum is None :
",48.77,38.81,False
"def filter ( self , lexer , stream ) : <TAB> current_type = None <TAB> current_value = None <TAB> for ttype , value in stream : <TAB> <TAB> if ttype is current_type : <TAB> <TAB> <TAB> current_value + = value <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield current_type , current_value <TAB> <TAB> <TAB> current_type = ttype <TAB> <TAB> <TAB> current_value = value <TAB> if current_type is not None : <TAB> <TAB> yield current_type , current_value ","if current_type is not None : 
","if current_type is not None :
",100.0,100.0,True
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line : <TAB> <TAB> <TAB> return <TAB> <TAB> if should_yield and line : <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ] ","if start in line : 
","if start and start in line :
",64.01,46.71,False
"def parse_git_config ( path ) : <TAB> """"""Parse git config file."""""" <TAB> config = dict ( ) <TAB> section = None <TAB> with open ( os . path . join ( path , "" config "" ) , "" r "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> if line . startswith ( "" [ "" ) : <TAB> <TAB> <TAB> <TAB> section = line [ 1 : - 1 ] . strip ( ) <TAB> <TAB> <TAB> <TAB> config [ section ] = dict ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> key , value = line . replace ( "" "" , "" "" ) . split ( "" = "" ) <TAB> <TAB> <TAB> <TAB> config [ section ] [ key ] = value <TAB> return config ","elif section : 
","elif section :
",78.12,0.0,False
"def test_has_arg ( fn , name , accept_all , expected ) : <TAB> if isinstance ( fn , str ) : <TAB> <TAB> context = dict ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> exec ( "" def  {} : pass "" . format ( fn ) , context ) <TAB> <TAB> except SyntaxError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> pytest . skip ( "" Function is not compatible with Python 2 "" ) <TAB> <TAB> # Sometimes exec adds builtins to the context <TAB> <TAB> context . pop ( "" __builtins__ "" , None ) <TAB> <TAB> ( fn , ) = context . values ( ) <TAB> assert has_arg ( fn , name , accept_all ) is expected ","if sys . version_info > = ( 3 , ) : 
","if sys . version_info [ 0 ] != 2 :
",42.1,40.9,False
"def ObjectExpression ( self , properties , * * kwargs ) : <TAB> data = [ ] <TAB> for prop in properties : <TAB> <TAB> self . emit ( prop [ "" value "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise NotImplementedError ( <TAB> <TAB> <TAB> <TAB> "" ECMA 5.1 does not support computed object properties! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> data . append ( ( to_key ( prop [ "" key "" ] ) , prop [ "" kind "" ] [ 0 ] ) ) <TAB> self . emit ( "" LOAD_OBJECT "" , tuple ( data ) ) ","if prop [ "" computed "" ] : 
","if "" kind "" not in prop :
",33.38,8.26,False
"def run ( self ) : <TAB> for domain , locale , po in self . locales : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = os . path . join ( "" locale "" , locale , "" LC_MESSAGES "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> path = os . path . join ( self . build_dir , locale , "" LC_MESSAGES "" ) <TAB> <TAB> mo = os . path . join ( path , "" %s .mo "" % domain ) <TAB> <TAB> self . mkpath ( path ) <TAB> <TAB> self . spawn ( [ "" msgfmt "" , "" -o "" , mo , po ] ) ","if self . inplace : 
","if domain == "" locale "" :
",27.8,6.57,False
"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB> <TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB> <TAB> if second_byte == None : <TAB> <TAB> <TAB> return "" XED_ILD_MAP1 "" <TAB> <TAB> if second_byte == 0x38 : <TAB> <TAB> <TAB> return "" XED_ILD_MAP2 "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" XED_ILD_MAP3 "" <TAB> <TAB> if second_byte == 0x0F and self . amd_enabled : <TAB> <TAB> <TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) ) ","if second_byte == 0x3A : 
","if second_byte == 0x40 :
",64.48,70.71,False
"def parse_tag ( self ) : <TAB> buf = [ ] <TAB> escaped = False <TAB> for c in self . get_next_chars ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> buf . append ( c ) <TAB> <TAB> elif c == "" \\ "" : <TAB> <TAB> <TAB> escaped = True <TAB> <TAB> elif c == "" > "" : <TAB> <TAB> <TAB> return "" "" . join ( buf ) <TAB> <TAB> else : <TAB> <TAB> <TAB> buf . append ( c ) <TAB> raise Exception ( "" Unclosed tag  "" + "" "" . join ( buf ) ) ","if escaped : 
","if escaped :
",78.12,0.0,False
"def print_pairs ( attrs = None , offset_y = 0 ) : <TAB> fmt = ""  ( {0} : {1} )  "" <TAB> fmt_len = len ( fmt ) <TAB> for bg , fg in get_fg_bg ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> color = curses . color_pair ( pair_number ( fg , bg ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for attr in attrs : <TAB> <TAB> <TAB> <TAB> <TAB> color | = attr <TAB> <TAB> <TAB> screen . addstr ( offset_y + bg , fg * fmt_len , fmt . format ( fg , bg ) , color ) <TAB> <TAB> <TAB> pass <TAB> <TAB> except curses . error : <TAB> <TAB> <TAB> pass ","if not attrs is None : 
","if attrs :
",27.57,0.0,False
"def _impl ( inputs , input_types ) : <TAB> data = inputs [ 0 ] <TAB> axis = None <TAB> keepdims = False <TAB> if len ( inputs ) > 2 :<TAB> # default, torch have only data, axis=None, keepdims=False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> axis = int ( inputs [ 1 ] ) <TAB> <TAB> elif _is_int_seq ( inputs [ 1 ] ) : <TAB> <TAB> <TAB> axis = inputs [ 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> axis = list ( _infer_shape ( inputs [ 1 ] ) ) <TAB> <TAB> keepdims = bool ( inputs [ 2 ] ) <TAB> return get_relay_op ( name ) ( data , axis = axis , keepdims = keepdims ) ","if isinstance ( inputs [ 1 ] , int ) : 
","if _is_int_seq ( inputs [ 1 ] ) :
",51.31,32.56,False
"def run ( self , args , * * kwargs ) : <TAB> # Filtering options <TAB> if args . trace_tag : <TAB> <TAB> kwargs [ "" trace_tag "" ] = args . trace_tag <TAB> if args . trigger_instance : <TAB> <TAB> kwargs [ "" trigger_instance "" ] = args . trigger_instance <TAB> if args . execution : <TAB> <TAB> kwargs [ "" execution "" ] = args . execution <TAB> if args . rule : <TAB> <TAB> kwargs [ "" rule "" ] = args . rule <TAB> if args . sort_order : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs [ "" sort_asc "" ] = True <TAB> <TAB> elif args . sort_order in [ "" desc "" , "" descending "" ] : <TAB> <TAB> <TAB> kwargs [ "" sort_desc "" ] = True <TAB> return self . manager . query_with_count ( limit = args . last , * * kwargs ) ","if args . sort_order in [ "" asc "" , "" ascending "" ] : 
","if args . sort_order in [ "" asc "" , ""asc "" ] :
",86.56,82.82,False
def retaddr ( ) : <TAB> sp = pwndbg . regs . sp <TAB> stack = pwndbg . vmmap . find ( sp ) <TAB> # Enumerate all return addresses <TAB> frame = gdb . newest_frame ( ) <TAB> addresses = [ ] <TAB> while frame : <TAB> <TAB> addresses . append ( frame . pc ( ) ) <TAB> <TAB> frame = frame . older ( ) <TAB> # Find all of them on the stack <TAB> start = stack . vaddr <TAB> stop = start + stack . memsz <TAB> while addresses and start < sp < stop : <TAB> <TAB> value = pwndbg . memory . u ( sp ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> index = addresses . index ( value ) <TAB> <TAB> <TAB> del addresses [ : index ] <TAB> <TAB> <TAB> print ( pwndbg . chain . format ( sp ) ) <TAB> <TAB> sp + = pwndbg . arch . ptrsize ,"if value in addresses : 
","if value in addresses :
",100.0,100.0,True
"def update_from_dictio ( self , dictio_item ) : <TAB> for index , dictio_payload in enumerate ( dictio_item , 1 ) : <TAB> <TAB> fuzz_payload = None <TAB> <TAB> for fuzz_payload in self . payloads [ index ] : <TAB> <TAB> <TAB> fuzz_payload . content = dictio_payload . content <TAB> <TAB> <TAB> fuzz_payload . type = dictio_payload . type <TAB> <TAB> # payload generated not used in seed but in filters <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add ( <TAB> <TAB> <TAB> <TAB> { "" full_marker "" : None , "" word "" : None , "" index "" : index , "" field "" : None } , <TAB> <TAB> <TAB> <TAB> dictio_item [ index - 1 ] , <TAB> <TAB> <TAB> ) ","if fuzz_payload is None : 
","if fuzz_payload is not None :
",64.71,59.46,False
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if isinstance ( result , str ) : 
","if isinstance ( result , str ) :
",100.0,100.0,True
"def execute_sql ( self , sql , params = None , commit = True ) : <TAB> try : <TAB> <TAB> cursor = super ( RetryOperationalError , self ) . execute_sql ( sql , params , commit ) <TAB> except OperationalError : <TAB> <TAB> if not self . is_closed ( ) : <TAB> <TAB> <TAB> self . close ( ) <TAB> <TAB> with __exception_wrapper__ : <TAB> <TAB> <TAB> cursor = self . cursor ( ) <TAB> <TAB> <TAB> cursor . execute ( sql , params or ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . commit ( ) <TAB> return cursor ","if commit and not self . in_transaction ( ) : 
","if commit :
",26.9,0.0,False
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> if isinstance ( definition , ast . OperationDefinition ) : <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition . name and definition . name . value == operation_name : <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation ","if operation : 
","if operation is None :
",34.79,23.64,False
"def removeTrailingWs ( self , aList ) : <TAB> i = 0 <TAB> while i < len ( aList ) : <TAB> <TAB> if self . is_ws ( aList [ i ] ) : <TAB> <TAB> <TAB> j = i <TAB> <TAB> <TAB> i = self . skip_ws ( aList , i ) <TAB> <TAB> <TAB> assert j < i <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # print ""removing trailing ws:"", `i-j` <TAB> <TAB> <TAB> <TAB> del aList [ j : i ] <TAB> <TAB> <TAB> <TAB> i = j <TAB> <TAB> else : <TAB> <TAB> <TAB> i + = 1 ","if i > = len ( aList ) or aList [ i ] == "" \n "" : 
","if aList [ j ] == aList [ i ] :
",23.08,16.76,False
"def _process_filter ( self , query , host_state ) : <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query : <TAB> <TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arg = self . _process_filter ( arg , host_state ) <TAB> <TAB> elif isinstance ( arg , basestring ) : <TAB> <TAB> <TAB> arg = self . _parse_string ( arg , host_state ) <TAB> <TAB> if arg is not None : <TAB> <TAB> <TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result ","if isinstance ( arg , list ) : 
","if isinstance ( arg , list ) :
",100.0,100.0,True
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" mw "" , "" hi "" , "" corr "" , "" trunc "" ) : <TAB> <TAB> <TAB> sent + = [ self . handle_word ( w ) for w in child ] <TAB> <TAB> elif child . tag in ( "" w "" , "" c "" ) : <TAB> <TAB> <TAB> sent . append ( self . handle_word ( child ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return BNCSentence ( elt . attrib [ "" n "" ] , sent ) ","elif child . tag not in self . tags_to_ignore : 
","elif child . tag != "" sent "" :
",47.0,18.62,False
"def get_display_price ( <TAB> base : Union [ TaxedMoney , TaxedMoneyRange ] , display_gross : bool = False ) - > Money : <TAB> """"""Return the price amount that should be displayed based on settings."""""" <TAB> if not display_gross : <TAB> <TAB> display_gross = display_gross_prices ( ) <TAB> if isinstance ( base , TaxedMoneyRange ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> base = MoneyRange ( start = base . start . gross , stop = base . stop . gross ) <TAB> <TAB> else : <TAB> <TAB> <TAB> base = MoneyRange ( start = base . start . net , stop = base . stop . net ) <TAB> if isinstance ( base , TaxedMoney ) : <TAB> <TAB> base = base . gross if display_gross else base . net <TAB> return base ","if display_gross : 
","if display_gross :
",78.12,100.0,True
"def check_classes ( self , node ) : <TAB> if isinstance ( node , nodes . Element ) : <TAB> <TAB> for class_value in node [ "" classes "" ] [ : ] : <TAB> <TAB> <TAB> if class_value in self . strip_classes : <TAB> <TAB> <TAB> <TAB> node [ "" classes "" ] . remove ( class_value ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return 1 ","if class_value in self . strip_elements : 
","if len ( node [ "" classes "" ] ) == 0 :
",26.53,3.38,False
"def validate ( outfile = sys . stdout , silent_success = False ) : <TAB> "" Validates all installed models. "" <TAB> try : <TAB> <TAB> num_errors = get_validation_errors ( outfile ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> outfile . write ( <TAB> <TAB> <TAB> "" %s  error %s  found. \n "" % ( num_errors , num_errors != 1 and "" s "" or "" "" ) <TAB> <TAB> ) <TAB> except ImproperlyConfigured : <TAB> <TAB> outfile . write ( "" Skipping validation because things aren ' t configured properly. "" ) ","if silent_success and num_errors == 0 : 
","if silent_success :
",28.73,17.44,False
"def check_basename_conflicts ( self , targets ) : <TAB> """"""Apps' basenames are used as bundle directory names. Ensure they are all unique."""""" <TAB> basename_seen = { } <TAB> for target in targets : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise self . BasenameConflictError ( <TAB> <TAB> <TAB> <TAB> "" Basename must be unique, found two targets use  "" <TAB> <TAB> <TAB> <TAB> "" the same basename:  {} ' \n \t {}  and  \n \t {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> target . basename , <TAB> <TAB> <TAB> <TAB> <TAB> basename_seen [ target . basename ] . address . spec , <TAB> <TAB> <TAB> <TAB> <TAB> target . address . spec , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> basename_seen [ target . basename ] = target ","if target . basename in basename_seen : 
","if target . basename in basename_seen :
",100.0,100.0,True
"def __init__ ( self , api_version_str ) : <TAB> try : <TAB> <TAB> self . latest = self . preview = False <TAB> <TAB> self . yyyy = self . mm = self . dd = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . latest = True <TAB> <TAB> else : <TAB> <TAB> <TAB> if "" preview "" in api_version_str : <TAB> <TAB> <TAB> <TAB> self . preview = True <TAB> <TAB> <TAB> parts = api_version_str . split ( "" - "" ) <TAB> <TAB> <TAB> self . yyyy = int ( parts [ 0 ] ) <TAB> <TAB> <TAB> self . mm = int ( parts [ 1 ] ) <TAB> <TAB> <TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB> <TAB> ) ","if api_version_str == "" latest "" : 
","if "" latest "" not in api_version_str :
",40.27,44.83,False
"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB> <TAB> y = self . _curve . b <TAB> else : <TAB> <TAB> result = self . sqrtp ( <TAB> <TAB> <TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y = result [ 0 ] <TAB> <TAB> elif len ( result ) == 2 : <TAB> <TAB> <TAB> y1 , y2 = result <TAB> <TAB> <TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return ec . Point ( self . _curve , x , y ) ","if len ( result ) == 1 : 
","if len ( result ) == 1 :
",100.0,100.0,True
"def _visit_import_alike ( self , node : Union [ cst . Import , cst . ImportFrom ] ) - > bool : <TAB> names = node . names <TAB> if isinstance ( names , cst . ImportStar ) : <TAB> <TAB> return False <TAB> # make sure node.names is Sequence[ImportAlias] <TAB> for name in names : <TAB> <TAB> self . provider . set_metadata ( name , self . scope ) <TAB> <TAB> asname = name . asname <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name_values = _gen_dotted_names ( cst . ensure_type ( asname . name , cst . Name ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> name_values = _gen_dotted_names ( name . name ) <TAB> <TAB> for name_value , _ in name_values : <TAB> <TAB> <TAB> self . scope . record_assignment ( name_value , node ) <TAB> return False ","if asname is not None : 
","if asname :
",29.58,0.0,False
"def test_sanity_no_unmatched_parentheses ( CorpusType : Type [ ColumnCorpus ] ) : <TAB> corpus = CorpusType ( ) <TAB> unbalanced_entities = [ ] <TAB> for sentence in corpus . get_all_sentences ( ) : <TAB> <TAB> entities = sentence . get_spans ( "" ner "" ) <TAB> <TAB> for entity in entities : <TAB> <TAB> <TAB> entity_text = "" "" . join ( t . text for t in entity . tokens ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> unbalanced_entities . append ( entity_text ) <TAB> assert unbalanced_entities == [ ] ","if not has_balanced_parantheses ( entity_text ) : 
","if entity_text not in unbalanced_entities :
",27.49,14.3,False
"def _learn_rate_adjust ( self ) : <TAB> if self . learn_rate_decays == 1.0 : <TAB> <TAB> return <TAB> learn_rate_decays = self . _vp ( self . learn_rate_decays ) <TAB> learn_rate_minimums = self . _vp ( self . learn_rate_minimums ) <TAB> for index , decay in enumerate ( learn_rate_decays ) : <TAB> <TAB> new_learn_rate = self . net_ . learnRates [ index ] * decay <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . net_ . learnRates [ index ] = new_learn_rate <TAB> if self . verbose > = 2 : <TAB> <TAB> print ( "" Learn rates:  {} "" . format ( self . net_ . learnRates ) ) ","if new_learn_rate > = learn_rate_minimums [ index ] : 
","if new_learn_rate < learn_rate_minimums :
",28.15,50.36,False
"def set_attr_from_xmp_tag ( self , attr , xmp_tags , tags , cast = None ) : <TAB> v = self . get_xmp_tag ( xmp_tags , tags ) <TAB> if v is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( self , attr , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Handle fractions <TAB> <TAB> <TAB> if ( cast == float or cast == int ) and "" / "" in v : <TAB> <TAB> <TAB> <TAB> v = self . try_parse_fraction ( v ) <TAB> <TAB> <TAB> setattr ( self , attr , cast ( v ) ) ","if cast is None : 
","if cast is None :
",100.0,100.0,True
"def _merge_scientific_float_tokens ( tokens : Iterable [ str ] ) - > List [ str ] : <TAB> tokens = list ( tokens ) <TAB> i = 0 <TAB> while "" e "" in tokens [ i + 1 : ] : <TAB> <TAB> i = tokens . index ( "" e "" , i + 1 ) <TAB> <TAB> s = i - 1 <TAB> <TAB> e = i + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if re . match ( "" [+-] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> if re . match ( "" [0-9] "" , str ( tokens [ e ] ) ) : <TAB> <TAB> <TAB> e + = 1 <TAB> <TAB> <TAB> tokens [ s : e ] = [ "" "" . join ( tokens [ s : e ] ) ] <TAB> <TAB> <TAB> i - = 1 <TAB> return tokens ","if not re . match ( "" [0-9] "" , str ( tokens [ s ] ) ) : 
","if s == 0 :
",25.47,0.68,False
"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> executable = winpymap . get ( name , None ) <TAB> <TAB> <TAB> if executable : <TAB> <TAB> <TAB> <TAB> executable = py . path . local ( executable ) <TAB> <TAB> <TAB> <TAB> if executable . check ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable ","if sys . platform == "" win32 "" : 
","if name in winpymap :
",26.57,4.67,False
"def set_meta ( self , dataset , overwrite = True , * * kwd ) : <TAB> super ( ) . set_meta ( dataset , overwrite = overwrite , * * kwd ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with tarfile . open ( dataset . file_name , "" r "" ) as temptar : <TAB> <TAB> <TAB> <TAB> dataset . metadata . fast5_count = sum ( <TAB> <TAB> <TAB> <TAB> <TAB> 1 for f in temptar if f . name . endswith ( "" .fast5 "" ) <TAB> <TAB> <TAB> <TAB> ) <TAB> except Exception as e : <TAB> <TAB> log . warning ( "" %s , set_meta Exception:  %s "" , self , e ) ","if dataset and tarfile . is_tarfile ( dataset . file_name ) : 
","if not dataset . metadata . fast5_count :
",34.42,6.06,False
"def run ( self ) : <TAB> for k in list ( iterkeys ( self . objs ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> v = self . objs [ k ] <TAB> <TAB> if v [ "" _class "" ] == "" User "" : <TAB> <TAB> <TAB> self . split_user ( k , v ) <TAB> <TAB> elif v [ "" _class "" ] in [ <TAB> <TAB> <TAB> "" Message "" , <TAB> <TAB> <TAB> "" PrintJob "" , <TAB> <TAB> <TAB> "" Question "" , <TAB> <TAB> <TAB> "" Submission "" , <TAB> <TAB> <TAB> "" UserTest "" , <TAB> <TAB> ] : <TAB> <TAB> <TAB> v [ "" participation "" ] = v [ "" user "" ] <TAB> <TAB> <TAB> del v [ "" user "" ] <TAB> return self . objs ","if k . startswith ( "" _ "" ) : 
","if k . startswith ( "" _ "" ) :
",100.0,100.0,True
"def _findInTree ( t , n ) : <TAB> ret = [ ] <TAB> if type ( t ) is dict : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( t ) <TAB> <TAB> for k , v in t . items ( ) : <TAB> <TAB> <TAB> ret + = _findInTree ( v , n ) <TAB> if type ( t ) is list : <TAB> <TAB> for v in t : <TAB> <TAB> <TAB> ret + = _findInTree ( v , n ) <TAB> return ret ","if "" _name "" in t and t [ "" _name "" ] == n : 
","if n in t :
",26.3,1.63,False
"def parseArrayPattern ( self ) : <TAB> node = Node ( ) <TAB> elements = [ ] <TAB> self . expect ( "" [ "" ) <TAB> while not self . match ( "" ] "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . lex ( ) <TAB> <TAB> <TAB> elements . append ( null ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if self . match ( "" ... "" ) : <TAB> <TAB> <TAB> <TAB> restNode = Node ( ) <TAB> <TAB> <TAB> <TAB> self . lex ( ) <TAB> <TAB> <TAB> <TAB> rest = self . parseVariableIdentifier ( ) <TAB> <TAB> <TAB> <TAB> elements . append ( restNode . finishRestElement ( rest ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> elements . append ( self . parsePatternWithDefault ( ) ) <TAB> <TAB> <TAB> if not self . match ( "" ] "" ) : <TAB> <TAB> <TAB> <TAB> self . expect ( "" , "" ) <TAB> self . expect ( "" ] "" ) <TAB> return node . finishArrayPattern ( elements ) ","if self . match ( "" , "" ) : 
","if self . match ( "" null "" ) :
",83.1,65.8,False
"def _set_log_writer ( self ) : <TAB> if self . config [ "" logging "" ] : <TAB> <TAB> config = self . config [ "" log_writer_config "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log_writer = LogWriter ( * * config ) <TAB> <TAB> elif config [ "" writer "" ] == "" tensorboard "" : <TAB> <TAB> <TAB> self . log_writer = TensorBoardWriter ( * * config ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( f "" Unrecognized writer option:  { config [ ' writer ' ] } "" ) <TAB> else : <TAB> <TAB> self . log_writer = None ","if config [ "" writer "" ] == "" json "" : 
","if config [ "" writer "" ] == "" log "" :
",88.57,79.11,False
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> if not len ( head ) : <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB> <TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB> <TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries ","if not len ( line . strip ( ) ) : 
","if not line :
",27.24,6.6,False
"def get_all_values ( self , project ) : <TAB> if isinstance ( project , models . Model ) : <TAB> <TAB> project_id = project . id <TAB> else : <TAB> <TAB> project_id = project <TAB> if project_id not in self . __cache : <TAB> <TAB> cache_key = self . _make_key ( project_id ) <TAB> <TAB> result = cache . get ( cache_key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = self . reload_cache ( project_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __cache [ project_id ] = result <TAB> return self . __cache . get ( project_id , { } ) ","if result is None : 
","if result is None :
",100.0,100.0,True
"def needed_libraries ( self ) : <TAB> for cmd in self . load_commands_of_type ( 0xC ) :<TAB> # LC_LOAD_DYLIB <TAB> <TAB> tname = self . _get_typename ( "" dylib_command "" ) <TAB> <TAB> dylib_command = cmd . cast ( tname ) <TAB> <TAB> name_addr = cmd . obj_offset + dylib_command . name <TAB> <TAB> dylib_name = self . obj_vm . read ( name_addr , 256 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> idx = dylib_name . find ( "" \x00 "" ) <TAB> <TAB> <TAB> if idx != - 1 : <TAB> <TAB> <TAB> <TAB> dylib_name = dylib_name [ : idx ] <TAB> <TAB> <TAB> yield dylib_name ","if dylib_name : 
","if dylib_name :
",78.12,100.0,True
"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_year "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> if data_list [ 0 ] in forms . fields . EMPTY_VALUES : <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_month "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> year = int ( data_list [ 1 ] ) <TAB> <TAB> month = int ( data_list [ 0 ] ) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange ( year , month ) [ 1 ] <TAB> <TAB> return date ( year , month , day ) <TAB> return None ","if data_list [ 1 ] in forms . fields . EMPTY_VALUES : 
","if data_list [ 1 ] in forms . fields . EMPTY_VALUES :
",100.0,100.0,True
"def put ( self , obj , block = True , timeout = None ) : <TAB> assert not self . _closed <TAB> if not self . _sem . acquire ( block , timeout ) : <TAB> <TAB> raise Full <TAB> with self . _notempty : <TAB> <TAB> with self . _cond : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _start_thread ( ) <TAB> <TAB> <TAB> self . _buffer . append ( obj ) <TAB> <TAB> <TAB> self . _unfinished_tasks . release ( ) <TAB> <TAB> <TAB> self . _notempty . notify ( ) ","if self . _thread is None : 
","if self . _thread is None :
",100.0,100.0,True
"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB> <TAB> module_directory = join ( directory , module ) <TAB> <TAB> has_module_directory = isdir ( module_directory ) <TAB> <TAB> if not version : <TAB> <TAB> <TAB> has_module = has_module_directory or exists ( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> )<TAB> # could be a bare modulefile <TAB> <TAB> else : <TAB> <TAB> <TAB> modulefile = join ( module_directory , version ) <TAB> <TAB> <TAB> has_modulefile = exists ( modulefile ) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return has_module ","if has_module : 
","if has_module :
",78.12,100.0,True
"def expanduser ( path ) : <TAB> if path [ : 1 ] == "" ~ "" : <TAB> <TAB> c = path [ 1 : 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return gethome ( ) <TAB> <TAB> if c == os . sep : <TAB> <TAB> <TAB> return asPyString ( File ( gethome ( ) , path [ 2 : ] ) . getPath ( ) ) <TAB> return path ","if not c : 
","if c == "" / "" :
",28.57,7.27,False
"def mock_touch ( self , bearer , version = None , revision = None , * * kwargs ) : <TAB> if version : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . versions [ int ( version ) - 1 ] <TAB> <TAB> <TAB> except ( IndexError , ValueError ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return file_models . FileVersion ( ) ","if self . versions : 
","if version in self . versions :
",61.88,43.47,False
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value ","elif member [ 0 ] == "" wildcards "" : 
","elif member [ 0 ] == "" wildcards "" :
",100.0,100.0,True
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> if isinstance ( expected , str ) : <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if contains : 
","if contains :
",78.12,0.0,False
"def OnKeyUp ( self , event ) : <TAB> if self . _properties . modifiable : <TAB> <TAB> if event . GetKeyCode ( ) == wx . WXK_ESCAPE : <TAB> <TAB> <TAB> self . _cancel_editing ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _update_value ( ) <TAB> <TAB> elif event . GetKeyCode ( ) == wx . WXK_DELETE : <TAB> <TAB> <TAB> self . SetValue ( "" "" ) <TAB> if event . GetKeyCode ( ) != wx . WXK_RETURN : <TAB> <TAB> # Don't send skip event if enter key is pressed <TAB> <TAB> # On some platforms this event is sent too late and causes crash <TAB> <TAB> event . Skip ( ) ","elif event . GetKeyCode ( ) == wx . WXK_RETURN : 
","elif event . GetKeyCode ( ) == wx . WXK_UPDATE :
",90.49,85.55,False
"def load_modules ( <TAB> to_load , load , attr , modules_dict , excluded_aliases , loading_message = None ) : <TAB> if loading_message : <TAB> <TAB> print ( loading_message ) <TAB> for name in to_load : <TAB> <TAB> module = load ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> cls = getattr ( module , attr ) <TAB> <TAB> if hasattr ( cls , "" initialize "" ) and not cls . initialize ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if hasattr ( module , "" aliases "" ) : <TAB> <TAB> <TAB> for alias in module . aliases ( ) : <TAB> <TAB> <TAB> <TAB> if alias not in excluded_aliases : <TAB> <TAB> <TAB> <TAB> <TAB> modules_dict [ alias ] = module <TAB> <TAB> else : <TAB> <TAB> <TAB> modules_dict [ name ] = module <TAB> if loading_message : <TAB> <TAB> print ( ) ","if module is None or not hasattr ( module , attr ) : 
","if not module :
",25.87,2.38,False
def eventIterator ( ) : <TAB> while True : <TAB> <TAB> yield eventmodule . wait ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> event = eventmodule . poll ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield event ,"if event . type == NOEVENT : 
","if event is None :
",29.08,12.98,False
"def _get_state_without_padding ( self , state_with_padding , padding ) : <TAB> lean_state = { } <TAB> for key , value in state_with_padding . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lean_length = value . numel ( ) - padding <TAB> <TAB> <TAB> lean_state [ key ] = value [ : lean_length ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lean_state [ key ] = value <TAB> return lean_state ","if torch . is_tensor ( value ) : 
","if padding :
",26.62,0.0,False
"def _get_validate ( data ) : <TAB> """"""Retrieve items to validate, from single samples or from combined joint calls."""""" <TAB> if data . get ( "" vrn_file "" ) and tz . get_in ( [ "" config "" , "" algorithm "" , "" validate "" ] , data ) : <TAB> <TAB> return utils . deepish_copy ( data ) <TAB> elif "" group_orig "" in data : <TAB> <TAB> for sub in multi . get_orig_items ( data ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sub_val = utils . deepish_copy ( sub ) <TAB> <TAB> <TAB> <TAB> sub_val [ "" vrn_file "" ] = data [ "" vrn_file "" ] <TAB> <TAB> <TAB> <TAB> return sub_val <TAB> return None ","if "" validate "" in sub [ "" config "" ] [ "" algorithm "" ] : 
","if sub . get ( "" group_orig "" ) and tz . get_in ( [ "" config "" , "" algorithm "" , "" validate "" ] , sub ) :
",45.47,13.98,False
"def OnPopup ( self , form , popup_handle ) : <TAB> for num , action_name , menu_name , shortcut in self . actions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ida_kernwin . attach_action_to_popup ( form , popup_handle , None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> handler = command_handler_t ( self , num , 2 ) <TAB> <TAB> <TAB> desc = ida_kernwin . action_desc_t ( action_name , menu_name , handler , shortcut ) <TAB> <TAB> <TAB> ida_kernwin . attach_dynamic_action_to_popup ( form , popup_handle , desc ) ","if menu_name is None : 
","if num == 1 :
",28.15,8.17,False
"def show ( self , indent = 0 ) : <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0 : <TAB> <TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> offset = "" 0x?? "" <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB> <TAB> print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB> <TAB> if isinstance ( field . type , Structure ) : <TAB> <TAB> <TAB> field . type . show ( indent + 1 ) ","if field . offset is None : 
","if field . offset is None :
",100.0,100.0,True
"def get_operation_ast ( document_ast , operation_name = None ) : <TAB> operation = None <TAB> for definition in document_ast . definitions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not operation_name : <TAB> <TAB> <TAB> <TAB> # If no operation name is provided, only return an Operation if it is the only one present in the <TAB> <TAB> <TAB> <TAB> # document. This means that if we've encountered a second operation as we were iterating over the <TAB> <TAB> <TAB> <TAB> # definitions in the document, there are more than one Operation defined, and we should return None. <TAB> <TAB> <TAB> <TAB> if operation : <TAB> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <TAB> operation = definition <TAB> <TAB> <TAB> elif definition . name and definition . name . value == operation_name : <TAB> <TAB> <TAB> <TAB> return definition <TAB> return operation ","if isinstance ( definition , ast . OperationDefinition ) : 
","if isinstance ( definition , Operation ) :
",48.2,46.31,False
"def getSubMenu ( self , callingWindow , context , mainItem , selection , rootMenu , i , pitem ) : <TAB> msw = True if "" wxMSW "" in wx . PlatformInfo else False <TAB> self . context = context <TAB> self . abilityIds = { } <TAB> sub = wx . Menu ( ) <TAB> for ability in self . fighter . abilities : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> menuItem = self . addAbility ( rootMenu if msw else sub , ability ) <TAB> <TAB> sub . Append ( menuItem ) <TAB> <TAB> menuItem . Check ( ability . active ) <TAB> return sub ","if not ability . effect . isImplemented : 
","if ability . disabled :
",33.6,13.94,False
"def consume ( self , event : Dict [ str , Any ] ) - > None : <TAB> with self . lock : <TAB> <TAB> logging . debug ( "" Received missedmessage_emails event:  %s "" , event ) <TAB> <TAB> # When we process an event, just put it into the queue and ensure we have a timer going. <TAB> <TAB> user_profile_id = event [ "" user_profile_id "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . batch_start_by_recipient [ user_profile_id ] = time . time ( ) <TAB> <TAB> self . events_by_recipient [ user_profile_id ] . append ( event ) <TAB> <TAB> self . ensure_timer ( ) ","if user_profile_id not in self . batch_start_by_recipient : 
","if user_profile_id not in self . batch_start_by_recipient :
",100.0,100.0,True
"def __init__ ( self , start_enabled = False , use_hardware = True ) : <TAB> self . _use_hardware = use_hardware <TAB> if use_hardware : <TAB> <TAB> self . _button = Button ( BUTTON_GPIO_PIN ) <TAB> <TAB> self . _enabled = start_enabled <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _button . when_pressed = self . _enable ","if not start_enabled : 
","if self . _enable :
",28.99,10.68,False
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . combine : <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . agg : <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else :<TAB> # pragma: no cover <TAB> <TAB> <TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB> <TAB> pd . reset_option ( "" mode.use_inf_as_na "" ) ","if op . stage == OperandStage . map : 
","if op . stage == OperandStage . map :
",100.0,100.0,True
"def load_package ( name , path ) : <TAB> if os . path . isdir ( path ) : <TAB> <TAB> extensions = machinery . SOURCE_SUFFIXES [ : ] + machinery . BYTECODE_SUFFIXES [ : ] <TAB> <TAB> for extension in extensions : <TAB> <TAB> <TAB> init_path = os . path . join ( path , "" __init__ "" + extension ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> path = init_path <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" {!r}  is not a package "" . format ( path ) ) <TAB> spec = util . spec_from_file_location ( name , path , submodule_search_locations = [ ] ) <TAB> if name in sys . modules : <TAB> <TAB> return _exec ( spec , sys . modules [ name ] ) <TAB> else : <TAB> <TAB> return _load ( spec ) ","if os . path . exists ( init_path ) : 
","if os . path . exists ( init_path ) :
",100.0,100.0,True
def setup ( level = None ) : <TAB> from pipeline . logging import pipeline_logger as logger <TAB> from pipeline . log . handlers import EngineLogHandler <TAB> if level in set ( logging . _levelToName . values ( ) ) : <TAB> <TAB> logger . setLevel ( level ) <TAB> logging . _acquireLock ( ) <TAB> try : <TAB> <TAB> for hdl in logger . handlers : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> hdl = EngineLogHandler ( ) <TAB> <TAB> <TAB> hdl . setLevel ( logger . level ) <TAB> <TAB> <TAB> logger . addHandler ( hdl ) <TAB> finally : <TAB> <TAB> logging . _releaseLock ( ) ,"if isinstance ( hdl , EngineLogHandler ) : 
","if hdl . setLevel ( logging . _levelToName . get ( level ) ) == level :
",26.52,3.03,False
"def find_approximant ( x ) : <TAB> c = 1e-4 <TAB> it = sympy . ntheory . continued_fraction_convergents ( <TAB> <TAB> sympy . ntheory . continued_fraction_iterator ( x ) <TAB> ) <TAB> for i in it : <TAB> <TAB> p , q = i . as_numer_denom ( ) <TAB> <TAB> tol = c / q * * 2 <TAB> <TAB> if abs ( i - x ) < = tol : <TAB> <TAB> <TAB> return i <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return x ","if tol < machine_epsilon : 
","if abs ( i - x ) > = tol :
",27.51,4.93,False
"def resolve ( <TAB> self , debug : bool = False , silent : bool = False , level : Optional [ int ] = None ) - > bool : <TAB> if silent : <TAB> <TAB> spinner = nullcontext ( type ( "" Mock "" , ( ) , { } ) ) <TAB> else : <TAB> <TAB> spinner = yaspin ( text = "" resolving... "" ) <TAB> with spinner as spinner : <TAB> <TAB> while True : <TAB> <TAB> <TAB> resolved = self . _resolve ( <TAB> <TAB> <TAB> <TAB> debug = debug , silent = silent , level = level , spinner = spinner <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . graph . clear ( )<TAB> # remove unused deps from graph <TAB> <TAB> <TAB> return resolved ","if resolved is None : 
","if resolved is False :
",39.07,42.73,False
"def canonicalize_instruction_name ( instr ) : <TAB> name = instr . insn_name ( ) . upper ( ) <TAB> # XXX bypass a capstone bug that incorrectly labels some insns as mov <TAB> if name == "" MOV "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" LSR "" <TAB> <TAB> elif instr . mnemonic . startswith ( "" lsl "" ) : <TAB> <TAB> <TAB> return "" LSL "" <TAB> <TAB> elif instr . mnemonic . startswith ( "" asr "" ) : <TAB> <TAB> <TAB> return "" ASR "" <TAB> return OP_NAME_MAP . get ( name , name ) ","if instr . mnemonic . startswith ( "" lsr "" ) : 
","if instr . mnemonic . startswith ( "" lSR "" ) :
",86.85,73.49,False
"def run_all ( rule_list , defined_variables , defined_actions , stop_on_first_trigger = False ) : <TAB> rule_was_triggered = False <TAB> for rule in rule_list : <TAB> <TAB> result = run ( rule , defined_variables , defined_actions ) <TAB> <TAB> if result : <TAB> <TAB> <TAB> rule_was_triggered = True <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return rule_was_triggered ","if stop_on_first_trigger : 
","if stop_on_first_trigger :
",78.12,100.0,True
"def get_filters ( self , request ) : <TAB> filter_specs = [ ] <TAB> if self . lookup_opts . admin . list_filter and not self . opts . one_to_one_field : <TAB> <TAB> filter_fields = [ <TAB> <TAB> <TAB> self . lookup_opts . get_field ( field_name ) <TAB> <TAB> <TAB> for field_name in self . lookup_opts . admin . list_filter <TAB> <TAB> ] <TAB> <TAB> for f in filter_fields : <TAB> <TAB> <TAB> spec = FilterSpec . create ( f , request , self . params , self . model ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> filter_specs . append ( spec ) <TAB> return filter_specs , bool ( filter_specs ) ","if spec and spec . has_output ( ) : 
","if spec :
",27.38,0.0,False
"def get_type ( type_ref ) : <TAB> kind = type_ref . get ( "" kind "" ) <TAB> if kind == TypeKind . LIST : <TAB> <TAB> item_ref = type_ref . get ( "" ofType "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB> <TAB> return GraphQLList ( get_type ( item_ref ) ) <TAB> elif kind == TypeKind . NON_NULL : <TAB> <TAB> nullable_ref = type_ref . get ( "" ofType "" ) <TAB> <TAB> if not nullable_ref : <TAB> <TAB> <TAB> raise Exception ( "" Decorated type deeper than introspection query. "" ) <TAB> <TAB> return GraphQLNonNull ( get_type ( nullable_ref ) ) <TAB> return get_named_type ( type_ref [ "" name "" ] ) ","if not item_ref : 
","if not item_ref :
",100.0,100.0,True
"def _1_0_cloud_ips_cip_jsjc5_map ( self , method , url , body , headers ) : <TAB> if method == "" POST "" : <TAB> <TAB> body = json . loads ( body ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . test_response ( httplib . ACCEPTED , "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = ' { "" error_name "" : "" bad destination "" ,  "" errors "" : [ "" Bad destination "" ]} ' <TAB> <TAB> <TAB> return self . test_response ( httplib . BAD_REQUEST , data ) ","if "" destination "" in body : 
","if body [ "" status "" ] == "" available "" :
",33.07,4.62,False
"def _get_prefixed_values ( data , prefix ) : <TAB> """"""Collect lines which start with prefix; with trimming"""""" <TAB> matches = [ ] <TAB> for line in data . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> match = line [ len ( prefix ) : ] <TAB> <TAB> <TAB> match = match . strip ( ) <TAB> <TAB> <TAB> matches . append ( match ) <TAB> return matches ","if line . startswith ( prefix ) : 
","if line . startswith ( prefix ) :
",100.0,100.0,True
"def _power_exact ( y , xc , yc , xe ) : <TAB> yc , ye = y . int , y . exp <TAB> while yc % 10 == 0 : <TAB> <TAB> yc / / = 10 <TAB> <TAB> ye + = 1 <TAB> if xc == 1 : <TAB> <TAB> xe * = yc <TAB> <TAB> while xe % 10 == 0 : <TAB> <TAB> <TAB> xe / / = 10 <TAB> <TAB> <TAB> ye + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> exponent = xe * 10 * * ye <TAB> <TAB> if y and xe : <TAB> <TAB> <TAB> xc = exponent <TAB> <TAB> else : <TAB> <TAB> <TAB> xc = 0 <TAB> <TAB> return 5 ","if ye < 0 : 
","if ye == 1 :
",56.5,17.97,False
"def init ( self , view , items = None ) : <TAB> selections = [ ] <TAB> if view . sel ( ) : <TAB> <TAB> for region in view . sel ( ) : <TAB> <TAB> <TAB> selections . append ( view . substr ( region ) ) <TAB> values = [ ] <TAB> for idx , index in enumerate ( map ( int , items ) ) : <TAB> <TAB> if idx > = len ( selections ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i = index - 1 <TAB> <TAB> if i > = 0 and i < len ( selections ) : <TAB> <TAB> <TAB> values . append ( selections [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( None ) <TAB> # fill up <TAB> for idx , value in enumerate ( selections ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values . append ( value ) <TAB> self . stack = values ","if len ( values ) + 1 < idx : 
","if value is not None :
",26.38,4.96,False
"def toggleFactorReload ( self , value = None ) : <TAB> self . serviceFittingOptions [ "" useGlobalForceReload "" ] = ( <TAB> <TAB> value <TAB> <TAB> if value is not None <TAB> <TAB> else not self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> ) <TAB> fitIDs = set ( ) <TAB> for fit in set ( self . _loadedFits ) : <TAB> <TAB> if fit is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fit . factorReload = self . serviceFittingOptions [ "" useGlobalForceReload "" ] <TAB> <TAB> <TAB> fit . clearFactorReloadDependentData ( ) <TAB> <TAB> <TAB> fitIDs . add ( fit . ID ) <TAB> return fitIDs ","if fit . calculated : 
","if fit . serviceFittingOptions [ "" useGlobalForceReload "" ] :
",43.47,16.78,False
"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for m in self . predict_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> <TAB> elif isinstance ( m , nn . Linear ) : <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 ) ","elif isinstance ( m , nn . BatchNorm2d ) : 
","elif isinstance ( m , nn . BatchNorm2d ) :
",100.0,100.0,True
"def _unzip_file ( self , filepath , ext ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> zf = zipfile . ZipFile ( filepath ) <TAB> <TAB> <TAB> zf . extractall ( os . path . dirname ( filepath ) ) <TAB> <TAB> <TAB> zf . close ( ) <TAB> <TAB> elif ext == "" .tar "" : <TAB> <TAB> <TAB> tf = tarfile . open ( filepath ) <TAB> <TAB> <TAB> tf . extractall ( os . path . dirname ( filepath ) ) <TAB> <TAB> <TAB> tf . close ( ) <TAB> except Exception as e : <TAB> <TAB> raise ValueError ( "" Error reading file  %r ! \n %s "" % ( filepath , e ) ) ","if ext == "" .zip "" : 
","if ext == "" .zip "" :
",100.0,100.0,True
"def add_multiple_tasks ( data , parent ) : <TAB> data = json . loads ( data ) <TAB> new_doc = { <TAB> <TAB> "" doctype "" : "" Task "" , <TAB> <TAB> "" parent_task "" : parent if parent != "" All Tasks "" else "" "" , <TAB> } <TAB> new_doc [ "" project "" ] = frappe . db . get_value ( "" Task "" , { "" name "" : parent } , "" project "" ) or "" "" <TAB> for d in data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> new_doc [ "" subject "" ] = d . get ( "" subject "" ) <TAB> <TAB> new_task = frappe . get_doc ( new_doc ) <TAB> <TAB> new_task . insert ( ) ","if not d . get ( "" subject "" ) : 
","if "" subject "" not in d :
",34.53,17.46,False
"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB> <TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict [ key ] = None <TAB> <TAB> if checkContained and keyword in key : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if kwdSndx == soundex ( key . encode ( "" ascii "" , "" ignore "" ) ) : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches ) ","if key in seenDict : 
","if key in seenDict :
",100.0,100.0,True
"def visit_If ( self , node ) : <TAB> self . newline ( ) <TAB> self . write ( "" if  "" ) <TAB> self . visit ( node . test ) <TAB> self . write ( "" : "" ) <TAB> self . body ( node . body ) <TAB> while True : <TAB> <TAB> else_ = node . orelse <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> node = else_ [ 0 ] <TAB> <TAB> <TAB> self . newline ( ) <TAB> <TAB> <TAB> self . write ( "" elif  "" ) <TAB> <TAB> <TAB> self . visit ( node . test ) <TAB> <TAB> <TAB> self . write ( "" : "" ) <TAB> <TAB> <TAB> self . body ( node . body ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . newline ( ) <TAB> <TAB> <TAB> self . write ( "" else: "" ) <TAB> <TAB> <TAB> self . body ( else_ ) <TAB> <TAB> <TAB> break ","if len ( else_ ) == 1 and isinstance ( else_ [ 0 ] , If ) : 
","if len ( else_ ) == 1 :
",48.09,30.08,False
"def _eyeLinkHardwareAndSoftwareVersion ( self ) : <TAB> try : <TAB> <TAB> tracker_software_ver = 0 <TAB> <TAB> eyelink_ver = self . _eyelink . getTrackerVersion ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tvstr = self . _eyelink . getTrackerVersionString ( ) <TAB> <TAB> <TAB> vindex = tvstr . find ( "" EYELINK CL "" ) <TAB> <TAB> <TAB> tracker_software_ver = int ( <TAB> <TAB> <TAB> <TAB> float ( tvstr [ ( vindex + len ( "" EYELINK CL "" ) ) : ] . strip ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return eyelink_ver , tracker_software_ver <TAB> except Exception : <TAB> <TAB> print2err ( "" EYELINK Error during _eyeLinkHardwareAndSoftwareVersion: "" ) <TAB> <TAB> printExceptionDetailsToStdErr ( ) <TAB> <TAB> return EyeTrackerConstants . EYETRACKER_ERROR ","if eyelink_ver == 3 : 
","if eyelink_ver != EyeTrackerConstants . EYETRACKER_ERROR :
",30.29,23.46,False
"def execute ( self , context ) : <TAB> for monad in context . blend_data . node_groups : <TAB> <TAB> if monad . bl_idname == "" SverchGroupTreeType "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> monad . update_cls ( ) <TAB> <TAB> <TAB> <TAB> except Exception as err : <TAB> <TAB> <TAB> <TAB> <TAB> print ( err ) <TAB> <TAB> <TAB> <TAB> <TAB> print ( "" {}  group class could not be created "" . format ( monad . name ) ) <TAB> return { "" FINISHED "" } ","if not getattr ( bpy . types , monad . cls_bl_idname , None ) : 
","if monad . update_cls :
",33.45,3.11,False
"def word_pattern ( pattern , str ) : <TAB> dict = { } <TAB> set_value = set ( ) <TAB> list_str = str . split ( ) <TAB> if len ( list_str ) != len ( pattern ) : <TAB> <TAB> return False <TAB> for i in range ( len ( pattern ) ) : <TAB> <TAB> if pattern [ i ] not in dict : <TAB> <TAB> <TAB> if list_str [ i ] in set_value : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> dict [ pattern [ i ] ] = list_str [ i ] <TAB> <TAB> <TAB> set_value . add ( list_str [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if dict [ pattern [ i ] ] != list_str [ i ] : 
","if list_str [ i ] not in dict :
",43.63,29.62,False
"def decorator_handle ( tokens ) : <TAB> """"""Process decorators."""""" <TAB> defs = [ ] <TAB> decorates = [ ] <TAB> for i , tok in enumerate ( tokens ) : <TAB> <TAB> if "" simple "" in tok and len ( tok ) == 1 : <TAB> <TAB> <TAB> decorates . append ( "" @ "" + tok [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> varname = decorator_var + "" _ "" + str ( i ) <TAB> <TAB> <TAB> defs . append ( varname + ""  =  "" + tok [ 0 ] ) <TAB> <TAB> <TAB> decorates . append ( "" @ "" + varname ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise CoconutInternalException ( "" invalid decorator tokens "" , tok ) <TAB> return "" \n "" . join ( defs + decorates ) + "" \n "" ","elif "" test "" in tok and len ( tok ) == 1 : 
","elif "" varname "" in tok and len ( tok ) == 1 :
",90.63,82.42,False
"def wait_impl ( self , cpid ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> # wait3() shouldn't hang, but some of the buildbots seem to hang <TAB> <TAB> # in the forking tests.  This is an attempt to fix the problem. <TAB> <TAB> spid , status , rusage = os . wait3 ( os . WNOHANG ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( 1.0 ) <TAB> self . assertEqual ( spid , cpid ) <TAB> self . assertEqual ( status , 0 , "" cause =  %d , exit =  %d "" % ( status & 0xFF , status >> 8 ) ) <TAB> self . assertTrue ( rusage ) ","if spid == cpid : 
","if spid == cpid :
",100.0,100.0,True
"def test_non_uniform_probabilities_over_elements ( self ) : <TAB> param = iap . Choice ( [ 0 , 1 ] , p = [ 0.25 , 0.75 ] ) <TAB> samples = param . draw_samples ( ( 10000 , ) ) <TAB> unique , counts = np . unique ( samples , return_counts = True ) <TAB> assert len ( unique ) == 2 <TAB> for val , count in zip ( unique , counts ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert 2500 - 500 < count < 2500 + 500 <TAB> <TAB> elif val == 1 : <TAB> <TAB> <TAB> assert 7500 - 500 < count < 7500 + 500 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert False ","if val == 0 : 
","if val == 0 :
",100.0,100.0,True
"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB> if self . stopframe and frame . f_code . co_flags & CO_GENERATOR : <TAB> <TAB> <TAB> return self . trace_dispatch <TAB> <TAB> try : <TAB> <TAB> <TAB> self . frame_returning = frame <TAB> <TAB> <TAB> self . user_return ( frame , arg ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . frame_returning = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self . stopframe is frame and self . stoplineno != - 1 : <TAB> <TAB> <TAB> self . _set_stopinfo ( None , None ) <TAB> return self . trace_dispatch ","if self . quitting : 
","if self . quitting :
",100.0,100.0,True
"def mouse ( self , button , mods , x , y ) : <TAB> if button == 1 : <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . hit = i <TAB> elif button == - 1 : <TAB> <TAB> self . hit = None <TAB> elif self . hit != None : <TAB> <TAB> self . coords [ self . hit ] = ( x , y ) <TAB> <TAB> self . view . dirty ( ) ","if hypot ( x - self . coords [ i ] [ 0 ] , y - self . coords [ i ] [ 1 ] ) < 4 : 
","if self . coords [ i ] == ( x , y ) :
",41.6,15.72,False
"def __init__ ( self , * commands ) : <TAB> self . all_cmds = list ( <TAB> <TAB> map ( lambda cmd : cmd [ 0 ] if isinstance ( cmd , list ) else cmd , commands ) <TAB> ) <TAB> for command in commands : <TAB> <TAB> self . cmd = command if isinstance ( command , list ) else [ command ] <TAB> <TAB> self . cmd_path = pwndbg . which . which ( self . cmd [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if self . cmd_path : 
","if self . cmd_path is None :
",61.88,61.05,False
"def _recv_obj ( self , suppress_error = False ) : <TAB> """"""Receive a (picklable) object"""""" <TAB> if self . conn . closed : <TAB> <TAB> raise OSError ( "" handle is closed "" ) <TAB> try : <TAB> <TAB> buf = self . conn . recv_bytes ( ) <TAB> except ( ConnectionError , EOFError ) as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> logger . debug ( "" receive has failed "" , exc_info = e ) <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _set_remote_close_cause ( e ) <TAB> <TAB> <TAB> raise PipeShutdownError ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . _close ( ) <TAB> obj = RemoteObjectUnpickler . loads ( buf , self ) <TAB> logger . debug ( "" received  %r "" , obj ) <TAB> return obj ","if suppress_error : 
","if suppress_error :
",78.12,100.0,True
"def act ( self , obs ) : <TAB> with chainer . no_backprop_mode ( ) : <TAB> <TAB> batch_obs = self . batch_states ( [ obs ] , self . xp , self . phi ) <TAB> <TAB> action_distrib = self . model ( batch_obs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return chainer . cuda . to_cpu ( action_distrib . most_probable . array ) [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return chainer . cuda . to_cpu ( action_distrib . sample ( ) . array ) [ 0 ] ","if self . act_deterministically : 
","if self . act_deterministically :
",100.0,100.0,True
"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB> <TAB> for node in level : <TAB> <TAB> <TAB> if node . binary == BINARY_MISSING : <TAB> <TAB> <TAB> <TAB> missing . append ( node ) <TAB> <TAB> <TAB> elif node . binary == BINARY_INVALID : <TAB> <TAB> <TAB> <TAB> invalid . append ( node ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads ","elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) : 
","elif node . binary == BINARY_DOWNLOADING :
",42.4,19.69,False
"def persist ( self , * _ ) : <TAB> for key , obj in self . _objects . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> state = obj . get_state ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> md5 = hashlib . md5 ( state ) . hexdigest ( ) <TAB> <TAB> <TAB> if self . _last_state . get ( key ) == md5 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _persist_provider . store ( key , state ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> system_log . exception ( "" PersistHelper.persist fail "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _last_state [ key ] = md5 ","if not state : 
","if state is None :
",29.25,14.06,False
"def enter ( self , doc , * * kwds ) : <TAB> """"""Enters the mode, arranging for necessary grabs ASAP"""""" <TAB> super ( ColorPickMode , self ) . enter ( doc , * * kwds ) <TAB> if self . _started_from_key_press : <TAB> <TAB> # Pick now using the last recorded event position <TAB> <TAB> doc = self . doc <TAB> <TAB> tdw = self . doc . tdw <TAB> <TAB> t , x , y = doc . get_last_event_info ( tdw ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _pick_color_mode ( tdw , x , y , self . _pickmode ) <TAB> <TAB> # Start the drag when possible <TAB> <TAB> self . _start_drag_on_next_motion_event = True <TAB> <TAB> self . _needs_drag_start = True ","if None not in ( x , y ) : 
","if t == self . _pickmode_t :
",26.29,4.46,False
"def on_profiles_loaded ( self , profiles ) : <TAB> cb = self . builder . get_object ( "" cbProfile "" ) <TAB> model = cb . get_model ( ) <TAB> model . clear ( ) <TAB> for f in profiles : <TAB> <TAB> name = f . get_basename ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if name . endswith ( "" .sccprofile "" ) : <TAB> <TAB> <TAB> name = name [ 0 : - 11 ] <TAB> <TAB> model . append ( ( name , f , None ) ) <TAB> cb . set_active ( 0 ) ","if name . endswith ( "" .mod "" ) : 
","if not name :
",26.38,3.65,False
"def subprocess_post_check ( <TAB> completed_process : subprocess . CompletedProcess , raise_error : bool = True ) - > None : <TAB> if completed_process . returncode : <TAB> <TAB> if completed_process . stdout is not None : <TAB> <TAB> <TAB> print ( completed_process . stdout , file = sys . stdout , end = "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( completed_process . stderr , file = sys . stderr , end = "" "" ) <TAB> <TAB> if raise_error : <TAB> <TAB> <TAB> raise PipxError ( <TAB> <TAB> <TAB> <TAB> f "" { ' ' . join ( [ str ( x ) for x in completed_process . args ] ) !r}  failed "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . info ( f "" { ' ' . join ( completed_process . args ) !r}  failed "" ) ","if completed_process . stderr is not None : 
","if completed_process . stderr is not None :
",100.0,100.0,True
"def test_connect ( <TAB> ipaddr , port , device , partition , method , path , headers = None , query_string = None ) : <TAB> if path == "" /a "" : <TAB> <TAB> for k , v in headers . iteritems ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> test_errors . append ( "" %s :  %s  not in  %s "" % ( test_header , test_value , headers ) ) ","if k . lower ( ) == test_header . lower ( ) and v == test_value : 
","if k . lower ( ) == test_header and v == test_value :
",72.68,73.49,False
"def test_stat_result_pickle ( self ) : <TAB> result = os . stat ( self . fname ) <TAB> for proto in range ( pickle . HIGHEST_PROTOCOL + 1 ) : <TAB> <TAB> p = pickle . dumps ( result , proto ) <TAB> <TAB> self . assertIn ( b "" stat_result "" , p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIn ( b "" cos \n stat_result \n "" , p ) <TAB> <TAB> unpickled = pickle . loads ( p ) <TAB> <TAB> self . assertEqual ( result , unpickled ) ","if proto < 4 : 
","if proto < 2 :
",64.48,42.73,False
"def run_sql ( sql ) : <TAB> table = sql . split ( "" "" ) [ 5 ] <TAB> logger . info ( "" Updating table  {} "" . format ( table ) ) <TAB> with transaction . atomic ( ) : <TAB> <TAB> with connection . cursor ( ) as cursor : <TAB> <TAB> <TAB> cursor . execute ( sql ) <TAB> <TAB> <TAB> rows = cursor . fetchall ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Exception ( "" Sentry notification that  {}  is migrated "" . format ( table ) ) ","if not rows : 
","if rows :
",34.18,0.0,False
"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB> <TAB> if x < self . box [ 0 ] : <TAB> <TAB> <TAB> self . box [ 0 ] = x <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . box [ 2 ] = x <TAB> <TAB> if y < self . box [ 1 ] : <TAB> <TAB> <TAB> self . box [ 1 ] = y <TAB> <TAB> if y > self . box [ 3 ] : <TAB> <TAB> <TAB> self . box [ 3 ] = y ","if x > self . box [ 2 ] : 
","if x > self . box [ 2 ] :
",100.0,100.0,True
"def _packageFocusOutViaKeyPress ( self , row , column , txt ) : <TAB> if txt : <TAB> <TAB> self . _set_current_cell ( row + 1 , column ) <TAB> else : <TAB> <TAB> widget = self . cellWidget ( row + 1 , column ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _delete_cell ( row , column ) <TAB> <TAB> new_request = self . get_request ( ) <TAB> <TAB> self . context_model . set_request ( new_request ) <TAB> <TAB> self . _update_request_column ( column , self . context_model ) ","if widget and isinstance ( widget , PackageSelectWidget ) : 
","if widget is txt :
",27.47,8.7,False
"def parse_bash_set_output ( output ) : <TAB> """"""Parse Bash-like 'set' output"""""" <TAB> if not sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # Replace ""\""-continued lines in *Linux* environment dumps. <TAB> <TAB> # Cannot do this on Windows because a ""\"" at the end of the <TAB> <TAB> # line does not imply a continuation. <TAB> <TAB> output = output . replace ( "" \\ \n "" , "" "" ) <TAB> environ = { } <TAB> for line in output . splitlines ( 0 ) : <TAB> <TAB> line = line . rstrip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue<TAB> # skip black lines <TAB> <TAB> item = _ParseBashEnvStr ( line ) <TAB> <TAB> if item : <TAB> <TAB> <TAB> environ [ item [ 0 ] ] = item [ 1 ] <TAB> return environ ","if not line : 
","if not line :
",100.0,100.0,True
"def _get ( self , domain ) : <TAB> with self . lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> record = self . cache [ domain ] <TAB> <TAB> <TAB> time_now = time . time ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> record = None <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> record = None <TAB> <TAB> if not record : <TAB> <TAB> <TAB> record = { "" r "" : "" unknown "" , "" dns "" : { } , "" g "" : 1 , "" query_count "" : 0 } <TAB> <TAB> # self.cache[domain] = record <TAB> <TAB> return record ","if time_now - record [ "" update "" ] > self . ttl : 
","if time_now > self . cache_max_age :
",33.03,22.96,False
"def test_filehash ( self ) : <TAB> """"""tests the hashes of the files in data/"""""" <TAB> fp = self . get_data_path ( ) <TAB> for fn in os . listdir ( fp ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # file used for something else <TAB> <TAB> <TAB> continue <TAB> <TAB> expected_hash = fn <TAB> <TAB> fullp = os . path . join ( fp , fn ) <TAB> <TAB> output = self . run_command ( "" sha1sum  "" + fullp , exitcode = 0 ) <TAB> <TAB> result = output . split ( "" "" ) [ 0 ] <TAB> <TAB> self . assertEqual ( result , expected_hash ) ","if "" . "" in fn : 
","if not os . path . isfile ( fn ) :
",26.81,5.3,False
"def test_new_vs_reference_code_stream_read_during_iter ( read_idx , read_len , bytecode ) : <TAB> reference = SlowCodeStream ( bytecode ) <TAB> latest = CodeStream ( bytecode ) <TAB> for index , ( actual , expected ) in enumerate ( zip ( latest , reference ) ) : <TAB> <TAB> assert actual == expected <TAB> <TAB> if index == read_idx : <TAB> <TAB> <TAB> readout_actual = latest . read ( read_len ) <TAB> <TAB> <TAB> readout_expected = reference . read ( read_len ) <TAB> <TAB> <TAB> assert readout_expected == readout_actual <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert latest . program_counter > = len ( reference ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert latest . program_counter == reference . program_counter ","if reference . program_counter > = len ( reference ) : 
","if index == read_idx :
",26.16,4.18,False
"def setup_logging ( ) : <TAB> try : <TAB> <TAB> logconfig = config . get ( "" logging_config_file "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . config . fileConfig ( logconfig , disable_existing_loggers = False ) <TAB> <TAB> logger . info ( "" logging initialized "" ) <TAB> <TAB> logger . debug ( "" debug "" ) <TAB> except Exception as e : <TAB> <TAB> print ( "" Unable to set logging configuration: "" , str ( e ) , file = sys . stderr ) <TAB> <TAB> raise ","if logconfig and os . path . exists ( logconfig ) : 
","if logconfig :
",26.42,0.0,False
"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> word = "" "" <TAB> <TAB> <TAB> if c . isalnum ( ) : <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c . lower ( ) <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> if c . isalnum ( ) : <TAB> <TAB> <TAB> <TAB> word + = c . lower ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word ","if start_char == True : 
","if start_char :
",31.47,38.81,False
"def _get_nonce ( self , url , new_nonce_url ) : <TAB> if not self . _nonces : <TAB> <TAB> logger . debug ( "" Requesting fresh nonce "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response = self . head ( url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # request a new nonce from the acme newNonce endpoint <TAB> <TAB> <TAB> response = self . _check_response ( self . head ( new_nonce_url ) , content_type = None ) <TAB> <TAB> self . _add_nonce ( response ) <TAB> return self . _nonces . pop ( ) ","if new_nonce_url is None : 
","if new_nonce_url is None :
",100.0,100.0,True
"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> if line . startswith ( comment ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if is_magic ( line , main_language ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> return i > 0 and _BLANK_LINE . match ( line ) <TAB> return True ","if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) : 
","if i == 0 :
",25.48,1.11,False
"def gvariant_args ( args : List [ Any ] ) - > str : <TAB> """"""Convert args into gvariant."""""" <TAB> gvariant = "" "" <TAB> for arg in args : <TAB> <TAB> if isinstance ( arg , bool ) : <TAB> <TAB> <TAB> gvariant + = "" {} "" . format ( str ( arg ) . lower ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> gvariant + = f "" { arg } "" <TAB> <TAB> elif isinstance ( arg , str ) : <TAB> <TAB> <TAB> gvariant + = f ' "" { arg } "" ' <TAB> <TAB> else : <TAB> <TAB> <TAB> gvariant + = f "" { arg !s} "" <TAB> return gvariant . lstrip ( ) ","elif isinstance ( arg , ( int , float ) ) : 
","elif isinstance ( arg , ( int , float ) ) :
",100.0,100.0,True
"def _SkipGroup ( buffer , pos , end ) : <TAB> """"""Skip sub-group.  Returns the new position."""""" <TAB> while 1 : <TAB> <TAB> ( tag_bytes , pos ) = ReadTag ( buffer , pos ) <TAB> <TAB> new_pos = SkipField ( buffer , pos , end , tag_bytes ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return pos <TAB> <TAB> pos = new_pos ","if new_pos == - 1 : 
","if new_pos == tag_bytes [ 0 ] :
",34.37,39.55,False
"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB> <TAB> if participant is None or participant == self . simulator_config . broadcast_part : <TAB> <TAB> <TAB> continue <TAB> <TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB> <TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB> <TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . participants_dict [ participant ] . refresh ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB> <TAB> self . update_view ( ) ","if participant in self . participants_dict : 
","if participant in self . participants_dict :
",100.0,100.0,True
"def feature_reddit ( layer_data , graph ) : <TAB> feature = { } <TAB> times = { } <TAB> indxs = { } <TAB> for _type in layer_data : <TAB> <TAB> if len ( layer_data [ _type ] ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> idxs = np . array ( list ( layer_data [ _type ] . keys ( ) ) ) <TAB> <TAB> tims = np . array ( list ( layer_data [ _type ] . values ( ) ) ) [ : , 1 ] <TAB> <TAB> feature [ _type ] = np . array ( <TAB> <TAB> <TAB> list ( graph . node_feature [ _type ] . loc [ idxs , "" emb "" ] ) , dtype = np . float <TAB> <TAB> ) <TAB> <TAB> times [ _type ] = tims <TAB> <TAB> indxs [ _type ] = idxs <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attr = feature [ _type ] <TAB> return feature , times , indxs , attr ","if _type == "" def "" : 
","if _type in graph . node_feature :
",28.91,16.78,False
"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> if tag . has_sort : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> if tag . internal : <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts ","if tag . user : 
","if tag . reverse :
",64.48,42.73,False
"def max_radius ( iterator ) : <TAB> radius_result = dict ( ) <TAB> for k , v in iterator : <TAB> <TAB> if v [ 0 ] not in radius_result : <TAB> <TAB> <TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> radius_result [ v [ 0 ] ] = v [ 1 ] <TAB> return radius_result ","elif v [ 1 ] > = radius_result [ v [ 0 ] ] : 
","if v [ 1 ] not in radius_result :
",36.66,20.33,False
"def run ( self ) : <TAB> pwd_found = [ ] <TAB> if constant . user_dpapi and constant . user_dpapi . unlocked : <TAB> <TAB> main_vault_directory = os . path . join ( <TAB> <TAB> <TAB> constant . profile [ "" APPDATA "" ] , u "" .. "" , u "" Local "" , u "" Microsoft "" , u "" Vault "" <TAB> <TAB> ) <TAB> <TAB> if os . path . exists ( main_vault_directory ) : <TAB> <TAB> <TAB> for vault_directory in os . listdir ( main_vault_directory ) : <TAB> <TAB> <TAB> <TAB> cred = constant . user_dpapi . decrypt_vault ( <TAB> <TAB> <TAB> <TAB> <TAB> os . path . join ( main_vault_directory , vault_directory ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> pwd_found . append ( cred ) <TAB> return pwd_found ","if cred : 
","if cred :
",78.12,0.0,False
"def disconnect_sync ( self , connection , close_connection = False ) : <TAB> key = id ( connection ) <TAB> ts = self . in_use . pop ( key ) <TAB> if close_connection : <TAB> <TAB> self . connections_map . pop ( key ) <TAB> <TAB> self . _connection_close_sync ( connection ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . connections_map . pop ( key ) <TAB> <TAB> <TAB> self . _connection_close_sync ( connection ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with self . _lock_sync : <TAB> <TAB> <TAB> <TAB> heapq . heappush ( self . connections_sync , ( ts , key ) ) ","if self . stale_timeout and self . is_stale ( ts ) : 
","if self . _autostart_timeout == ts :
",36.86,12.52,False
"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _populate_number ( element , k , v ) ","elif type ( v ) in [ int , float , long , complex ] : 
","elif isinstance ( v , int ) :
",26.6,5.56,False
"def readframes ( self , nframes ) : <TAB> if self . _ssnd_seek_needed : <TAB> <TAB> self . _ssnd_chunk . seek ( 0 ) <TAB> <TAB> dummy = self . _ssnd_chunk . read ( 8 ) <TAB> <TAB> pos = self . _soundpos * self . _framesize <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _ssnd_chunk . seek ( pos + 8 ) <TAB> <TAB> self . _ssnd_seek_needed = 0 <TAB> if nframes == 0 : <TAB> <TAB> return "" "" <TAB> data = self . _ssnd_chunk . read ( nframes * self . _framesize ) <TAB> if self . _convert and data : <TAB> <TAB> data = self . _convert ( data ) <TAB> self . _soundpos = self . _soundpos + len ( data ) / ( self . _nchannels * self . _sampwidth ) <TAB> return data ","if pos : 
","if pos :
",78.12,0.0,False
"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB> <TAB> <TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB> <TAB> <TAB> if __opts__ . get ( "" ssh_user "" ) : <TAB> <TAB> <TAB> <TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret ","if fnmatch . fnmatch ( tgt , host ) : 
","if __opts__ . get ( "" roster_defaults "" , { } ) :
",32.61,5.33,False
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> if nodeid not in self . _nodes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> if attr not in node . attributes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value ","if attval . value_callback : 
","if attval . value_callback :
",100.0,100.0,True
"def remove_property ( self , key ) :<TAB> # type: (str) -> None <TAB> with self . secure ( ) as config : <TAB> <TAB> keys = key . split ( "" . "" ) <TAB> <TAB> current_config = config <TAB> <TAB> for i , key in enumerate ( keys ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> if i == len ( keys ) - 1 : <TAB> <TAB> <TAB> <TAB> del current_config [ key ] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config [ key ] ","if key not in current_config : 
","if key not in current_config :
",100.0,100.0,True
"def _class_browser ( parent ) :<TAB> # Wrapper for htest <TAB> try : <TAB> <TAB> file = __file__ <TAB> except NameError : <TAB> <TAB> file = sys . argv [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> file = sys . argv [ 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> file = sys . argv [ 0 ] <TAB> dir , file = os . path . split ( file ) <TAB> name = os . path . splitext ( file ) [ 0 ] <TAB> flist = PyShell . PyShellFileList ( parent ) <TAB> global file_open <TAB> file_open = flist . open <TAB> ClassBrowser ( flist , name , [ dir ] , _htest = True ) ","if sys . argv [ 1 : ] : 
","if sys . argv [ 1 : ] :
",100.0,100.0,True
"def get_only_text_part ( self , msg ) : <TAB> count = 0 <TAB> only_text_part = None <TAB> for part in msg . walk ( ) : <TAB> <TAB> if part . is_multipart ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> count + = 1 <TAB> <TAB> mimetype = part . get_content_type ( ) or "" text/plain "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> only_text_part = part <TAB> return only_text_part ","if mimetype != "" text/plain "" or count != 1 : 
","if mimetype != "" text/plain "" and count > = self . max_multipart_size :
",54.71,40.93,False
"def should_keep_alive ( commit_msg ) : <TAB> result = False <TAB> ci = get_current_ci ( ) or "" "" <TAB> for line in commit_msg . splitlines ( ) : <TAB> <TAB> parts = line . strip ( "" #  "" ) . split ( "" : "" , 1 ) <TAB> <TAB> ( key , val ) = parts if len ( parts ) > 1 else ( parts [ 0 ] , "" "" ) <TAB> <TAB> if key == "" CI_KEEP_ALIVE "" : <TAB> <TAB> <TAB> ci_names = val . replace ( "" , "" , "" "" ) . lower ( ) . split ( ) if val else [ ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = True <TAB> return result ","if len ( ci_names ) == 0 or ci . lower ( ) in ci_names : 
","if ci in ci_names :
",27.75,9.05,False
"def _calc_block_io ( self , blkio ) : <TAB> """"""Calculate block IO stats."""""" <TAB> for stats in blkio [ "" io_service_bytes_recursive "" ] : <TAB> <TAB> if stats [ "" op "" ] == "" Read "" : <TAB> <TAB> <TAB> self . _blk_read + = stats [ "" value "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _blk_write + = stats [ "" value "" ] ","elif stats [ "" op "" ] == "" Write "" : 
","if stats [ "" op "" ] == "" Write "" :
",85.28,91.22,False
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB> <TAB> <TAB> ) <TAB> return six . text_type ( value ) ","if settings . USE_TZ : 
","if settings . USE_TZ :
",100.0,100.0,True
"def load_state_dict ( self , state_dict ) : <TAB> for module_name , module_state_dict in state_dict . items ( ) : <TAB> <TAB> if module_name in self . module_pool : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . module_pool [ module_name ] . module . load_state_dict ( module_state_dict ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . module_pool [ module_name ] . load_state_dict ( module_state_dict ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . info ( f "" Missing  { module_name }  in module_pool, skip it.. "" ) ","if self . config [ "" dataparallel "" ] : 
","if isinstance ( self . module_pool [ module_name ] . module , Module ) :
",32.45,5.33,False
"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB> <TAB> if i > = min ( len ( scales ) , len ( vidxs ) / / 2 ) : <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB> <TAB> <TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData ","if not math . isnan ( scale ) : 
","if scale > 0 :
",26.63,6.32,False
"def __init__ ( self , factors , contrast_matrices , num_columns ) : <TAB> self . factors = tuple ( factors ) <TAB> factor_set = frozenset ( factors ) <TAB> if not isinstance ( contrast_matrices , dict ) : <TAB> <TAB> raise ValueError ( "" contrast_matrices must be dict "" ) <TAB> for factor , contrast_matrix in six . iteritems ( contrast_matrices ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected factor in contrast_matrices dict "" ) <TAB> <TAB> if not isinstance ( contrast_matrix , ContrastMatrix ) : <TAB> <TAB> <TAB> raise ValueError ( "" Expected a ContrastMatrix, not  %r "" % ( contrast_matrix , ) ) <TAB> self . contrast_matrices = contrast_matrices <TAB> if not isinstance ( num_columns , six . integer_types ) : <TAB> <TAB> raise ValueError ( "" num_columns must be an integer "" ) <TAB> self . num_columns = num_columns ","if factor not in factor_set : 
","if factor not in factor_set :
",100.0,100.0,True
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB> <TAB> <TAB> break ","if message [ "" type "" ] == "" websocket.connect "" : 
","if message [ "" type "" ] == "" websocket.connect "" :
",100.0,100.0,True
"def value__set ( self , value ) : <TAB> for i , ( option , checked ) in enumerate ( self . options ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . selectedIndex = i <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Option  %r  not found (from  %s ) "" <TAB> <TAB> <TAB> % ( value , "" ,  "" . join ( [ repr ( o ) for o , c in self . options ] ) ) <TAB> <TAB> ) ","if option == str ( value ) : 
","if value == option . value :
",27.16,12.83,False
"def init_links ( self ) : <TAB> links = LinkCallback . find_links ( self ) <TAB> callbacks = [ ] <TAB> for link , src_plot , tgt_plot in links : <TAB> <TAB> cb = Link . _callbacks [ "" bokeh "" ] [ type ( link ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> callbacks . append ( cb ( self . root , link , src_plot , tgt_plot ) ) <TAB> return callbacks ","if src_plot is None or ( link . _requires_target and tgt_plot is None ) : 
","if not cb :
",25.55,0.21,False
"def _validate_scalar_extensions ( self ) - > List [ str ] : <TAB> errors = [ ] <TAB> for extension in [ <TAB> <TAB> x for x in self . extensions if isinstance ( x , GraphQLScalarTypeExtension ) <TAB> ] : <TAB> <TAB> extended = self . type_definitions . get ( extension . name ) <TAB> <TAB> ext_errors = _validate_extension ( <TAB> <TAB> <TAB> extended , extension . name , GraphQLScalarType , "" SCALAR "" <TAB> <TAB> ) <TAB> <TAB> errors . extend ( ext_errors ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errors . extend ( _validate_extension_directives ( extension , extended , "" SCALAR "" ) ) <TAB> return errors ","if not ext_errors : 
","if extension . is_directive :
",28.99,8.64,False
"def copy_tcltk ( src , dest , symlink ) : <TAB> """"""copy tcl/tk libraries on Windows (issue #93)"""""" <TAB> for libversion in "" 8.5 "" , "" 8.6 "" : <TAB> <TAB> for libname in "" tcl "" , "" tk "" : <TAB> <TAB> <TAB> srcdir = join ( src , "" tcl "" , libname + libversion ) <TAB> <TAB> <TAB> destdir = join ( dest , "" tcl "" , libname + libversion ) <TAB> <TAB> <TAB> # Only copy the dirs from the above combinations that exist <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> copyfileordir ( srcdir , destdir , symlink ) ","if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) : 
","if os . path . exists ( srcdir ) and not os . path . exists ( destdir ) :
",100.0,100.0,True
"def parse ( self , response ) : <TAB> try : <TAB> <TAB> content = response . content . decode ( "" utf-8 "" , "" ignore "" ) <TAB> <TAB> content = json . loads ( content , strict = False ) <TAB> except : <TAB> <TAB> self . logger . error ( "" Fail to parse the response in json format "" ) <TAB> <TAB> return <TAB> for item in content [ "" data "" ] : <TAB> <TAB> if "" objURL "" in item : <TAB> <TAB> <TAB> img_url = self . _decode_url ( item [ "" objURL "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> img_url = item [ "" hoverURL "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dict ( file_url = img_url ) ","elif "" hoverURL "" in item : 
","elif "" hoverURL "" in item :
",100.0,100.0,True
"def check_and_reload ( self ) : <TAB> # Check if tables have been modified, if so reload <TAB> for table_name , table_version in self . _table_versions . items ( ) : <TAB> <TAB> table = self . app . tool_data_tables . get ( table_name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . reload_genomes ( ) ","if table is not None and not table . is_current_version ( table_version ) : 
","if table and table . get_modified_date ( ) > = datetime . now ( ) :
",30.29,7.54,False
"def _get_query_defaults ( self , query_defns ) : <TAB> defaults = { } <TAB> for k , v in query_defns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> defaults [ k ] = self . _get_default_obj ( v [ "" schema "" ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> defaults [ k ] = v [ "" schema "" ] [ "" default "" ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> return defaults ","if v [ "" schema "" ] [ "" type "" ] == "" object "" : 
","if isinstance ( v [ "" schema "" ] , dict ) :
",52.62,27.84,False
"def ftp_login ( host , port , username = None , password = None , anonymous = False ) : <TAB> ret = False <TAB> try : <TAB> <TAB> ftp = ftplib . FTP ( ) <TAB> <TAB> ftp . connect ( host , port , timeout = 6 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ftp . login ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ftp . login ( username , password ) <TAB> <TAB> ret = True <TAB> <TAB> ftp . quit ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return ret ","if anonymous : 
","if anonymous :
",78.12,0.0,False
"def _getVolumeScalar ( self ) : <TAB> if self . _volumeScalar is not None : <TAB> <TAB> return self . _volumeScalar <TAB> # use default <TAB> elif self . _value in dynamicStrToScalar : <TAB> <TAB> return dynamicStrToScalar [ self . _value ] <TAB> else : <TAB> <TAB> thisDynamic = self . _value <TAB> <TAB> # ignore leading s like in sf <TAB> <TAB> if "" s "" in thisDynamic : <TAB> <TAB> <TAB> thisDynamic = thisDynamic [ 1 : ] <TAB> <TAB> # ignore closing z like in fz <TAB> <TAB> if thisDynamic [ - 1 ] == "" z "" : <TAB> <TAB> <TAB> thisDynamic = thisDynamic [ : - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return dynamicStrToScalar [ thisDynamic ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return dynamicStrToScalar [ None ] ","if thisDynamic in dynamicStrToScalar : 
","if thisDynamic in dynamicStrToScalar :
",100.0,100.0,True
"def processCoords ( coords ) : <TAB> newcoords = deque ( ) <TAB> for ( x , y , z ) in coords : <TAB> <TAB> for _dir , offsets in faceDirections : <TAB> <TAB> <TAB> if _dir == FaceYIncreasing : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dx , dy , dz = offsets <TAB> <TAB> <TAB> p = ( x + dx , y + dy , z + dz ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> nx , ny , nz = p <TAB> <TAB> <TAB> if level . blockAt ( nx , ny , nz ) == 0 : <TAB> <TAB> <TAB> <TAB> level . setBlockAt ( nx , ny , nz , waterID ) <TAB> <TAB> <TAB> <TAB> newcoords . append ( p ) <TAB> return newcoords ","if p not in box : 
","if len ( p ) < 3 :
",27.18,7.27,False
"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB> <TAB> wstate = str ( target_widget [ "" state "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # change state temporarily <TAB> <TAB> <TAB> target_widget [ "" state "" ] = "" normal "" <TAB> <TAB> target_widget . delete ( "" 0 "" , tk . END ) <TAB> <TAB> target_widget . insert ( "" 0 "" , value ) <TAB> <TAB> target_widget [ "" state "" ] = wstate <TAB> else : <TAB> <TAB> super ( EntryBaseBO , self ) . _set_property ( target_widget , pname , value ) ","if wstate != "" normal "" : 
","if wstate != "" normal "" :
",100.0,100.0,True
"def teardown ( ) : <TAB> try : <TAB> <TAB> time . sleep ( 1 ) <TAB> except KeyboardInterrupt : <TAB> <TAB> return <TAB> while launchers : <TAB> <TAB> p = launchers . pop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> p . stop ( ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> print ( e ) <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> if p . poll ( ) is None : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if p . poll ( ) is None : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> print ( "" cleaning up test process... "" ) <TAB> <TAB> <TAB> <TAB> p . signal ( SIGKILL ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> print ( "" couldn ' t shutdown process:  "" , p ) ","if p . poll ( ) is None : 
","if p is not None :
",29.04,14.72,False
"def checkAndRemoveDuplicate ( self , node ) : <TAB> for bucket in self . buckets : <TAB> <TAB> for n in bucket . getNodes ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . removeContact ( n ) ","if ( n . ip , n . port ) == ( node . ip , node . port ) and n . id != node . id : 
","if n . node == node . node :
",20.56,3.07,False
"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB> <TAB> if this . glob : <TAB> <TAB> <TAB> flags + = u "" g "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flags + = u "" i "" <TAB> <TAB> if this . multiline : <TAB> <TAB> <TAB> flags + = u "" m "" <TAB> except : <TAB> <TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags ","if this . ignore_case : 
","if this . ignore_if :
",64.48,64.35,False
"def import_submodules ( package_name ) : <TAB> package = sys . modules [ package_name ] <TAB> results = { } <TAB> for loader , name , is_pkg in pkgutil . iter_modules ( package . __path__ ) : <TAB> <TAB> full_name = package_name + "" . "" + name <TAB> <TAB> module = importlib . import_module ( full_name ) <TAB> <TAB> setattr ( sys . modules [ __name__ ] , name , module ) <TAB> <TAB> results [ full_name ] = module <TAB> <TAB> if is_pkg : <TAB> <TAB> <TAB> valid_pkg = import_submodules ( full_name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> results . update ( valid_pkg ) <TAB> return results ","if valid_pkg : 
","if valid_pkg :
",78.12,100.0,True
"def _call ( self , cmd ) : <TAB> what = cmd [ "" command "" ] <TAB> if what == "" list "" : <TAB> <TAB> name = cmd [ "" properties "" ] . get ( "" name "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return { "" watchers "" : [ "" one "" , "" two "" , "" three "" ] } <TAB> <TAB> return { "" pids "" : [ 123 , 456 ] } <TAB> elif what == "" dstats "" : <TAB> <TAB> return { "" info "" : { "" pid "" : 789 } } <TAB> elif what == "" listsockets "" : <TAB> <TAB> return { <TAB> <TAB> <TAB> "" status "" : "" ok "" , <TAB> <TAB> <TAB> "" sockets "" : [ { "" path "" : self . _unix , "" fd "" : 5 , "" name "" : "" XXXX "" , "" backlog "" : 2048 } ] , <TAB> <TAB> <TAB> "" time "" : 1369647058.967524 , <TAB> <TAB> } <TAB> raise NotImplementedError ( cmd ) ","if name is None : 
","if name == "" watchdog "" :
",29.79,12.22,False
"def select ( self ) : <TAB> e = xlib . XEvent ( ) <TAB> while xlib . XPending ( self . _display ) : <TAB> <TAB> xlib . XNextEvent ( self . _display , e ) <TAB> <TAB> # Key events are filtered by the xlib window event <TAB> <TAB> # handler so they get a shot at the prefiltered event. <TAB> <TAB> if e . xany . type not in ( xlib . KeyPress , xlib . KeyRelease ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> dispatch = self . _window_map [ e . xany . window ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> continue <TAB> <TAB> dispatch ( e ) ","if xlib . XFilterEvent ( e , e . xany . window ) : 
","if e . xany . window not in self . _window_map :
",51.03,27.67,False
"def translate ( self , line ) : <TAB> parsed = self . RE_LINE_PARSER . match ( line ) <TAB> if parsed : <TAB> <TAB> value = parsed . group ( 3 ) <TAB> <TAB> stage = parsed . group ( 1 ) <TAB> <TAB> if stage == "" send "" :<TAB> # query string is rendered here <TAB> <TAB> <TAB> return "" \n # HTTP Request: \n "" + self . stripslashes ( value ) <TAB> <TAB> elif stage == "" reply "" : <TAB> <TAB> <TAB> return "" \n \n # HTTP Response: \n "" + self . stripslashes ( value ) <TAB> <TAB> elif stage == "" header "" : <TAB> <TAB> <TAB> return value + "" \n "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return value <TAB> return line ","if stage == "" send "" : 
","elif stage == "" send "" :
",75.79,84.09,False
"def toString ( ) : <TAB> flags = u "" "" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flags + = u "" g "" <TAB> <TAB> if this . ignore_case : <TAB> <TAB> <TAB> flags + = u "" i "" <TAB> <TAB> if this . multiline : <TAB> <TAB> <TAB> flags + = u "" m "" <TAB> except : <TAB> <TAB> pass <TAB> v = this . value if this . value else "" (?:) "" <TAB> return u "" / %s / "" % v + flags ","if this . glob : 
","if this . glob :
",100.0,100.0,True
"def __exit__ ( self , * exc_info ) : <TAB> super ( WarningsChecker , self ) . __exit__ ( * exc_info ) <TAB> # only check if we're not currently handling an exception <TAB> if all ( a is None for a in exc_info ) : <TAB> <TAB> if self . expected_warning is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> __tracebackhide__ = True <TAB> <TAB> <TAB> <TAB> pytest . fail ( "" DID NOT WARN "" ) ","if not any ( r . category in self . expected_warning for r in self ) : 
","if not self . expected_warning ( exc_info [ 0 ] ) :
",34.78,24.98,False
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> if k . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if v [ "" email "" ] == "" "" : <TAB> <TAB> <TAB> <TAB> v [ "" email "" ] = None <TAB> <TAB> <TAB> if v [ "" ip "" ] == "" 0.0.0.0 "" : <TAB> <TAB> <TAB> <TAB> v [ "" ip "" ] = None <TAB> return self . objs ","if v [ "" _class "" ] == "" User "" : 
","if v [ "" _class "" ] == "" Event "" :
",88.57,80.91,False
"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB> <TAB> if i < = start_after : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self . count < 4 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i ","if i == 2 and self . count < 1 : 
","if i == 6 and self . count < 3 :
",74.44,54.52,False
"def check ( self ) : <TAB> tcp_client = self . tcp_create ( ) <TAB> if tcp_client . connect ( ) : <TAB> <TAB> tcp_client . send ( b "" ABCDE "" ) <TAB> <TAB> response = tcp_client . recv ( 5 ) <TAB> <TAB> tcp_client . close ( ) <TAB> <TAB> if response : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . endianness = "" > ""<TAB> # BE <TAB> <TAB> <TAB> elif response . startswith ( b "" ScMM "" ) : <TAB> <TAB> <TAB> <TAB> self . endianness = "" < ""<TAB> # LE <TAB> <TAB> <TAB> return True<TAB> # target is vulnerable <TAB> return False<TAB> # target is not vulnerable ","if response . startswith ( b "" MMcS "" ) : 
","if response . startswith ( b "" DFMm "" ) :
",85.2,70.17,False
"def copy_tree ( self , src_dir , dst_dir , skip_variables = False ) : <TAB> for src_root , _ , files in os . walk ( src_dir ) : <TAB> <TAB> if src_root != src_dir : <TAB> <TAB> <TAB> rel_root = os . path . relpath ( src_root , src_dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> rel_root = "" "" <TAB> <TAB> if skip_variables and rel_root . startswith ( "" variables "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> dst_root = os . path . join ( dst_dir , rel_root ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( dst_root ) <TAB> <TAB> for f in files : <TAB> <TAB> <TAB> shutil . copy ( os . path . join ( src_root , f ) , os . path . join ( dst_root , f ) ) ","if not os . path . exists ( dst_root ) : 
","if not os . path . isdir ( dst_root ) :
",85.27,76.12,False
"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB> <TAB> i = host . rfind ( "" : "" ) <TAB> <TAB> j = host . rfind ( "" ] "" )<TAB> # ipv6 addresses have [...] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> port = int ( host [ i + 1 : ] ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB> <TAB> <TAB> host = host [ : i ] <TAB> <TAB> else : <TAB> <TAB> <TAB> port = self . default_port <TAB> <TAB> if host and host [ 0 ] == "" [ "" and host [ - 1 ] == "" ] "" : <TAB> <TAB> <TAB> host = host [ 1 : - 1 ] <TAB> self . host = host <TAB> self . port = port ","if i > j : 
","if i > = 0 and j > 0 :
",35.52,17.75,False
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> if member [ 0 ] == key : <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value ","if key == "" nw_src "" : 
","if key == "" nw_src "" :
",100.0,100.0,True
"def _clear_storage ( ) : <TAB> """"""Clear old files from storage."""""" <TAB> hacs = get_hacs ( ) <TAB> storagefiles = [ "" hacs "" ] <TAB> for s_f in storagefiles : <TAB> <TAB> path = f "" { hacs . core . config_path } /.storage/ { s_f } "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hacs . log . info ( f "" Cleaning up old storage file  { path } "" ) <TAB> <TAB> <TAB> os . remove ( path ) ","if os . path . isfile ( path ) : 
","if os . path . exists ( path ) :
",83.03,65.8,False
"def action_delete ( self , ids ) : <TAB> try : <TAB> <TAB> count = 0 <TAB> <TAB> # TODO: Optimize me <TAB> <TAB> for pk in ids : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> flash ( <TAB> <TAB> <TAB> ngettext ( <TAB> <TAB> <TAB> <TAB> "" Record was successfully deleted. "" , <TAB> <TAB> <TAB> <TAB> "" %(count)s  records were successfully deleted. "" , <TAB> <TAB> <TAB> <TAB> count , <TAB> <TAB> <TAB> <TAB> count = count , <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> "" success "" , <TAB> <TAB> ) <TAB> except Exception as ex : <TAB> <TAB> flash ( gettext ( "" Failed to delete records.  %(error)s "" , error = str ( ex ) ) , "" error "" ) ","if self . delete_model ( self . get_one ( pk ) ) : 
","if self . _model . objects . filter ( pk = pk ) . exists ( ) :
",36.84,14.03,False
"def test_inclusion ( all_values ) : <TAB> for values in [ { "" guid_2 "" , "" guid_1 "" } , { "" guid_5 "" , "" guid_XXX "" } , { "" guid_2 "" } ] : <TAB> <TAB> test_predicate = in_set ( values , "" volume_guid "" ) <TAB> <TAB> included_values = set ( ) <TAB> <TAB> for val in all_values : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> included_values . add ( val ) <TAB> <TAB> assert included_values == all_values . intersection ( values ) ","if test_predicate . do_include ( { "" volume_guid "" : val } ) : 
","if test_predicate . is_included ( val ) :
",32.89,20.47,False
"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB> <TAB> attr_mod , attr_path = ( <TAB> <TAB> <TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB> <TAB> ) <TAB> <TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB> <TAB> op = import_module ( full_mod_path ) <TAB> <TAB> if attr_path : <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path . split ( "" . "" ) : <TAB> <TAB> <TAB> <TAB> op = getattr ( op , part ) <TAB> <TAB> return op <TAB> except ( ImportError , AttributeError ) as ex : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex ","if checked : 
","if checked :
",78.12,0.0,False
"def __exit__ ( self , exc_type , exc_val , exc_tb ) : <TAB> if self . fusefat is not None : <TAB> <TAB> self . fusefat . send_signal ( signal . SIGINT ) <TAB> <TAB> # Allow 1s to return without sending terminate <TAB> <TAB> for count in range ( 10 ) : <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fusefat . terminate ( ) <TAB> <TAB> time . sleep ( self . delay ) <TAB> <TAB> assert not os . path . exists ( self . canary ) <TAB> self . dev_null . close ( ) <TAB> shutil . rmtree ( self . tmpdir ) ","if self . fusefat . poll ( ) is not None : 
","if count == 1 :
",25.93,3.55,False
"def check_context_processors ( output ) : <TAB> with output . section ( "" Context processors "" ) as section : <TAB> <TAB> processors = list ( <TAB> <TAB> <TAB> chain ( <TAB> <TAB> <TAB> <TAB> * [ <TAB> <TAB> <TAB> <TAB> <TAB> template [ "" OPTIONS "" ] . get ( "" context_processors "" , [ ] ) <TAB> <TAB> <TAB> <TAB> <TAB> for template in settings . TEMPLATES <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> required_processors = ( "" cms.context_processors.cms_settings "" , ) <TAB> <TAB> for processor in required_processors : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> section . error ( <TAB> <TAB> <TAB> <TAB> <TAB> "" %s  context processor must be in TEMPLATES option context_processors "" <TAB> <TAB> <TAB> <TAB> <TAB> % processor <TAB> <TAB> <TAB> <TAB> ) ","if processor not in processors : 
","if not processor in processors :
",43.26,35.93,False
"def test_converters ( self ) : <TAB> response = self . _get ( "" datatypes/converters "" ) <TAB> self . _assert_status_code_is ( response , 200 ) <TAB> converters_list = response . json ( ) <TAB> found_fasta_to_tabular = False <TAB> for converter in converters_list : <TAB> <TAB> self . _assert_has_key ( converter , "" source "" , "" target "" , "" tool_id "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> found_fasta_to_tabular = True <TAB> assert found_fasta_to_tabular ","if converter [ "" source "" ] == "" fasta "" and converter [ "" target "" ] == "" tabular "" : 
","if converter [ "" source "" ] . endswith ( "" .fasta "" ) :
",51.97,24.69,False
"def remove_pid ( self , watcher , pid ) : <TAB> if pid in self . _pids [ watcher ] : <TAB> <TAB> logger . debug ( "" Removing  %d  from  %s "" % ( pid , watcher ) ) <TAB> <TAB> self . _pids [ watcher ] . remove ( pid ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( "" Stopping the periodic callback for  {0} "" . format ( watcher ) ) <TAB> <TAB> <TAB> self . _callbacks [ watcher ] . stop ( ) ","if len ( self . _pids [ watcher ] ) == 0 : 
","if not self . _callbacks [ watcher ] . is_running ( ) :
",37.81,17.4,False
"def _fc_layer ( self , sess , bottom , name , trainable = True , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB> <TAB> shape = bottom . get_shape ( ) . as_list ( ) <TAB> <TAB> dim = 1 <TAB> <TAB> for d in shape [ 1 : ] : <TAB> <TAB> <TAB> dim * = d <TAB> <TAB> x = tf . reshape ( bottom , [ - 1 , dim ] ) <TAB> <TAB> weight = self . _get_fc_weight ( sess , name , trainable = trainable ) <TAB> <TAB> bias = self . _get_bias ( sess , name , trainable = trainable ) <TAB> <TAB> fc = tf . nn . bias_add ( tf . matmul ( x , weight ) , bias ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fc = tf . nn . relu ( fc ) <TAB> <TAB> return fc ","if relu : 
","if relu :
",78.12,0.0,False
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> if root_path : <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path : <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive ","if config_root_path and root_path == config_root_path : 
","if config_root_path and config_root_path == root_path :
",60.1,79.38,False
"def rewire_init ( expr ) : <TAB> new_args = [ ] <TAB> if expr [ 0 ] == HySymbol ( "" setv "" ) : <TAB> <TAB> pairs = expr [ 1 : ] <TAB> <TAB> while len ( pairs ) > 0 : <TAB> <TAB> <TAB> k , v = ( pairs . pop ( 0 ) , pairs . pop ( 0 ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> v . append ( HySymbol ( "" None "" ) ) <TAB> <TAB> <TAB> new_args . append ( k ) <TAB> <TAB> <TAB> new_args . append ( v ) <TAB> <TAB> expr = HyExpression ( [ HySymbol ( "" setv "" ) ] + new_args ) . replace ( expr ) <TAB> return expr ","if k == HySymbol ( "" __init__ "" ) : 
","if v is None :
",26.35,1.72,False
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if child . tagName == "" Directory "" : 
","if child . tagName == "" Dir "" :
",83.19,70.71,False
"def _v2_common ( self , cfg ) : <TAB> LOG . debug ( "" v2_common: handling config: \n %s "" , cfg ) <TAB> if "" nameservers "" in cfg : <TAB> <TAB> search = cfg . get ( "" nameservers "" ) . get ( "" search "" , [ ] ) <TAB> <TAB> dns = cfg . get ( "" nameservers "" ) . get ( "" addresses "" , [ ] ) <TAB> <TAB> name_cmd = { "" type "" : "" nameserver "" } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name_cmd . update ( { "" search "" : search } ) <TAB> <TAB> if len ( dns ) > 0 : <TAB> <TAB> <TAB> name_cmd . update ( { "" addresses "" : dns } ) <TAB> <TAB> LOG . debug ( "" v2(nameserver) -> v1(nameserver): \n %s "" , name_cmd ) <TAB> <TAB> self . handle_nameserver ( name_cmd ) ","if len ( search ) > 0 : 
","if len ( search ) > 0 :
",100.0,100.0,True
"def __start_element_handler ( self , name , attrs ) : <TAB> if name == "" mime-type "" : <TAB> <TAB> if self . type : <TAB> <TAB> <TAB> for extension in self . extensions : <TAB> <TAB> <TAB> <TAB> self [ extension ] = self . type <TAB> <TAB> self . type = attrs [ "" type "" ] . lower ( ) <TAB> <TAB> self . extensions = [ ] <TAB> elif name == "" glob "" : <TAB> <TAB> pattern = attrs [ "" pattern "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . extensions . append ( pattern [ 1 : ] . lower ( ) ) ","if pattern . startswith ( "" *. "" ) : 
","if pattern and pattern [ 0 ] . startswith ( "" [ "" ) :
",50.63,26.52,False
"def get_attr_by_data_model ( self , dmodel , exclude_record = False ) : <TAB> if exclude_record : <TAB> <TAB> return list ( <TAB> <TAB> <TAB> filter ( <TAB> <TAB> <TAB> <TAB> lambda x : x . data_model == dmodel and x . value == "" "" <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> else False , <TAB> <TAB> <TAB> <TAB> self . _inferred_intent , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return list ( <TAB> <TAB> <TAB> filter ( <TAB> <TAB> <TAB> <TAB> lambda x : x . data_model == dmodel and x . value == "" "" <TAB> <TAB> <TAB> <TAB> if hasattr ( x , "" data_model "" ) <TAB> <TAB> <TAB> <TAB> else False , <TAB> <TAB> <TAB> <TAB> self . _inferred_intent , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if x . attribute != "" Record "" and hasattr ( x , "" data_model "" ) 
","if hasattr ( x , "" data_model "" )
",55.86,40.36,False
"def general ( metadata , value ) : <TAB> if metadata . get ( "" commands "" ) and value : <TAB> <TAB> if not metadata . get ( "" nargs "" ) : <TAB> <TAB> <TAB> v = quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = value <TAB> <TAB> return u "" {0} {1} "" . format ( metadata [ "" commands "" ] [ 0 ] , v ) <TAB> else : <TAB> <TAB> if not value : <TAB> <TAB> <TAB> return None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return quote ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return value ","elif not metadata . get ( "" nargs "" ) : 
","if metadata . get ( "" nargs "" ) :
",74.55,79.64,False
"def get_images ( self ) : <TAB> images = [ ] <TAB> try : <TAB> <TAB> tag = MP4 ( self [ "" ~filename "" ] ) <TAB> except Exception : <TAB> <TAB> return [ ] <TAB> for cover in tag . get ( "" covr "" , [ ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mime = "" image/jpeg "" <TAB> <TAB> elif cover . imageformat == MP4Cover . FORMAT_PNG : <TAB> <TAB> <TAB> mime = "" image/png "" <TAB> <TAB> else : <TAB> <TAB> <TAB> mime = "" image/ "" <TAB> <TAB> f = get_temp_cover_file ( cover ) <TAB> <TAB> images . append ( EmbeddedImage ( f , mime ) ) <TAB> return images ","if cover . imageformat == MP4Cover . FORMAT_JPEG : 
","if cover . imageformat == MP4Cover . FORMAT_JPEG :
",100.0,100.0,True
"def run_cmd ( self , util , value ) : <TAB> state = util . state <TAB> if not state . argument_supplied : <TAB> <TAB> state . argument_supplied = True <TAB> <TAB> if value == "" by_four "" : <TAB> <TAB> <TAB> state . argument_value = 4 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> state . argument_negative = True <TAB> <TAB> else : <TAB> <TAB> <TAB> state . argument_value = value <TAB> elif value == "" by_four "" : <TAB> <TAB> state . argument_value * = 4 <TAB> elif isinstance ( value , int ) : <TAB> <TAB> state . argument_value * = 10 <TAB> <TAB> state . argument_value + = value <TAB> elif value == "" negative "" : <TAB> <TAB> state . argument_value = - state . argument_value ","elif value == "" negative "" : 
","elif isinstance ( value , int ) :
",27.11,7.27,False
"def finish_character_data ( self ) : <TAB> if self . character_data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line , column = self . character_pos <TAB> <TAB> <TAB> token = XmlToken ( <TAB> <TAB> <TAB> <TAB> XML_CHARACTER_DATA , self . character_data , None , line , column <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . tokens . append ( token ) <TAB> <TAB> self . character_data = "" "" ","if not self . skip_ws or not self . character_data . isspace ( ) : 
","if self . character_pos :
",31.28,8.19,False
"def check_syntax ( filename , raise_error = False ) : <TAB> """"""Return True if syntax is okay."""""" <TAB> with autopep8 . open_with_encoding ( filename ) as input_file : <TAB> <TAB> try : <TAB> <TAB> <TAB> compile ( input_file . read ( ) , "" <string> "" , "" exec "" , dont_inherit = True ) <TAB> <TAB> <TAB> return True <TAB> <TAB> except ( SyntaxError , TypeError , UnicodeDecodeError ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return False ","if raise_error : 
","if raise_error :
",78.12,100.0,True
"def write ( self , file ) : <TAB> if not self . _been_written : <TAB> <TAB> self . _been_written = True <TAB> <TAB> for attribute , value in self . __dict__ . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . write_recursive ( value , file ) <TAB> <TAB> w = file . write <TAB> <TAB> w ( "" \t %s  =  { \n "" % self . _id ) <TAB> <TAB> w ( "" \t \t isa =  %s ; \n "" % self . __class__ . __name__ ) <TAB> <TAB> for attribute , value in self . __dict__ . items ( ) : <TAB> <TAB> <TAB> if attribute [ 0 ] != "" _ "" : <TAB> <TAB> <TAB> <TAB> w ( "" \t \t %s  =  %s ; \n "" % ( attribute , self . tostring ( value ) ) ) <TAB> <TAB> w ( "" \t }; \n \n "" ) ","if attribute [ 0 ] != "" _ "" : 
","if attribute [ 0 ] == "" _ "" :
",83.03,70.17,False
"def update_service_key ( kid , name = None , metadata = None ) : <TAB> try : <TAB> <TAB> with db_transaction ( ) : <TAB> <TAB> <TAB> key = db_for_update ( ServiceKey . select ( ) . where ( ServiceKey . kid == kid ) ) . get ( ) <TAB> <TAB> <TAB> if name is not None : <TAB> <TAB> <TAB> <TAB> key . name = name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> key . metadata . update ( metadata ) <TAB> <TAB> <TAB> key . save ( ) <TAB> except ServiceKey . DoesNotExist : <TAB> <TAB> raise ServiceKeyDoesNotExist ","if metadata is not None : 
","if metadata is not None :
",100.0,100.0,True
"def fill_buf ( self , db , len_ = None ) : <TAB> with open ( "" /dev/urandom "" , "" rb "" ) as rfh : <TAB> <TAB> first = True <TAB> <TAB> for ( id_ , ) in db . query ( "" SELECT id FROM test "" ) : <TAB> <TAB> <TAB> if len_ is None and first : <TAB> <TAB> <TAB> <TAB> val = b "" ""<TAB> # We always want to check this case <TAB> <TAB> <TAB> <TAB> first = False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> val = rfh . read ( random . randint ( 0 , 140 ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> val = rfh . read ( len_ ) <TAB> <TAB> <TAB> db . execute ( "" UPDATE test SET buf=? WHERE id=? "" , ( val , id_ ) ) ","elif len_ is None : 
","elif len_ is None :
",100.0,100.0,True
"def load_category_from_parser ( self , parser ) : <TAB> for cate in parser . keys ( ) : <TAB> <TAB> id = parser . get_id ( cate ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _data [ "" cates "" ] [ id ] = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _data [ "" cates "" ] [ id ] = self . count_unread ( id ) <TAB> self . _is_init = False <TAB> self . save ( ) ","if self . _is_init : 
","if id == "" 0 "" :
",27.8,6.57,False
"def after_insert ( self ) : <TAB> if self . prescription : <TAB> <TAB> frappe . db . set_value ( <TAB> <TAB> <TAB> "" Lab Prescription "" , self . prescription , "" lab_test_created "" , 1 <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . invoiced = True <TAB> if not self . lab_test_name and self . template : <TAB> <TAB> self . load_test_from_template ( ) <TAB> <TAB> self . reload ( ) ","if frappe . db . get_value ( "" Lab Prescription "" , self . prescription , "" invoiced "" ) : 
","if not self . invoiced :
",31.45,1.2,False
"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB> <TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB> <TAB> except UnitNotFound : <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB> if not add : <TAB> <TAB> <TAB> continue <TAB> <TAB> missing . append ( ( source . context , source . source , "" "" ) ) <TAB> if missing : <TAB> <TAB> self . add_units ( None , missing ) ","if "" terminology "" not in source . all_flags : 
","if not isinstance ( source , Unit ) :
",26.57,4.83,False
def refresh ( self ) : <TAB> if self . _obj : <TAB> <TAB> base = self . _db . get_media_from_handle ( self . _obj . get_reference_handle ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _title = base . get_description ( ) <TAB> <TAB> <TAB> self . _value = base . get_path ( ) ,"if base : 
","if base :
",78.12,0.0,False
"def _set_parse_context ( self , tag , tag_attrs ) : <TAB> # special case: script or style parse context <TAB> if not self . _wb_parse_context : <TAB> <TAB> if tag == "" style "" : <TAB> <TAB> <TAB> self . _wb_parse_context = "" style "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . _allow_js_type ( tag_attrs ) : <TAB> <TAB> <TAB> <TAB> self . _wb_parse_context = "" script "" ","elif tag == "" script "" : 
","elif tag == "" script "" :
",100.0,100.0,True
"def can_read ( self ) : <TAB> if hasattr ( self . file , "" __iter__ "" ) : <TAB> <TAB> iterator = iter ( self . file ) <TAB> <TAB> head = next ( iterator , None ) <TAB> <TAB> if head is None : <TAB> <TAB> <TAB> self . repaired = [ ] <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . repaired = itertools . chain ( [ head ] , iterator ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> # We may have mangled a generator at this point, so just abort <TAB> <TAB> <TAB> raise IOSourceError ( <TAB> <TAB> <TAB> <TAB> "" Could not open source:  %r  (mode:  %r ) "" <TAB> <TAB> <TAB> <TAB> % ( self . file , self . options [ "" mode "" ] ) <TAB> <TAB> <TAB> ) <TAB> return False ","if isinstance ( head , str ) : 
","elif isinstance ( head , ( list , tuple ) ) :
",40.59,25.21,False
"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB> <TAB> if kwargs [ "" headers "" ] . get ( "" user-agent "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f "" { user_agent } "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB> else : <TAB> <TAB> kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB> return request_method ( * args , * * kwargs ) ","if user_agent not in kwargs [ "" headers "" ] [ "" user-agent "" ] : 
","if user_agent not in [ "" GIT "" , "" GIT "" , "" GIT "" ] :
",46.85,34.03,False
"def execute ( self ) : <TAB> if self . _dirty or not self . _qr : <TAB> <TAB> model_class = self . model_class <TAB> <TAB> query_meta = self . get_query_meta ( ) <TAB> <TAB> if self . _tuples : <TAB> <TAB> <TAB> ResultWrapper = TuplesQueryResultWrapper <TAB> <TAB> elif self . _dicts : <TAB> <TAB> <TAB> ResultWrapper = DictQueryResultWrapper <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ResultWrapper = NaiveQueryResultWrapper <TAB> <TAB> elif self . _aggregate_rows : <TAB> <TAB> <TAB> ResultWrapper = AggregateQueryResultWrapper <TAB> <TAB> else : <TAB> <TAB> <TAB> ResultWrapper = ModelQueryResultWrapper <TAB> <TAB> self . _qr = ResultWrapper ( model_class , self . _execute ( ) , query_meta ) <TAB> <TAB> self . _dirty = False <TAB> <TAB> return self . _qr <TAB> else : <TAB> <TAB> return self . _qr ","elif self . _naive or not self . _joins or self . verify_naive ( ) : 
","elif self . _naive_rows :
",34.93,12.55,False
"def populate_data ( apps , schema_editor ) : <TAB> Menu = apps . get_model ( "" menu "" , "" Menu "" ) <TAB> for menu in Menu . objects . all ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> json_str = menu . json_content <TAB> <TAB> <TAB> while isinstance ( json_str , str ) : <TAB> <TAB> <TAB> <TAB> json_str = json . loads ( json_str ) <TAB> <TAB> <TAB> menu . json_content_new = json_str <TAB> <TAB> <TAB> menu . save ( ) ","if isinstance ( menu . json_content , str ) : 
","if isinstance ( menu . json_content , str ) :
",100.0,100.0,True
"def virtualenv_exists ( self ) : <TAB> if os . path . exists ( self . virtualenv_location ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> extra = [ "" Scripts "" , "" activate.bat "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> extra = [ "" bin "" , "" activate "" ] <TAB> <TAB> return os . path . isfile ( os . sep . join ( [ self . virtualenv_location ] + extra ) ) <TAB> return False ","if os . name == "" nt "" : 
","if os . name == "" nt "" :
",100.0,100.0,True
"def get_minkowski_function ( name , variable ) : <TAB> fn_name = name + get_postfix ( variable ) <TAB> if hasattr ( MEB , fn_name ) : <TAB> <TAB> return getattr ( MEB , fn_name ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" Function  { fn_name }  not available. Please compile MinkowskiEngine with `torch.cuda.is_available()` is `True`. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( f "" Function  { fn_name }  not available. "" ) ","if variable . is_cuda : 
","if torch . cuda . is_available ( ) :
",36.01,16.59,False
"def build_temp_workspace ( files ) : <TAB> tempdir = tempfile . mkdtemp ( prefix = "" yamllint-tests- "" ) <TAB> for path , content in files . items ( ) : <TAB> <TAB> path = os . path . join ( tempdir , path ) . encode ( "" utf-8 "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( os . path . dirname ( path ) ) <TAB> <TAB> if type ( content ) is list : <TAB> <TAB> <TAB> os . mkdir ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mode = "" wb "" if isinstance ( content , bytes ) else "" w "" <TAB> <TAB> <TAB> with open ( path , mode ) as f : <TAB> <TAB> <TAB> <TAB> f . write ( content ) <TAB> return tempdir ","if not os . path . exists ( os . path . dirname ( path ) ) : 
","if not os . path . exists ( os . path . dirname ( path ) ) :
",100.0,100.0,True
"def clean_form ( self , request , user , form , cleaned_data ) : <TAB> for field in self . get_fields ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> cleaned_data [ field . fieldname ] = field . clean ( <TAB> <TAB> <TAB> <TAB> request , user , cleaned_data [ field . fieldname ] <TAB> <TAB> <TAB> ) <TAB> <TAB> except ValidationError as e : <TAB> <TAB> <TAB> form . add_error ( field . fieldname , e ) <TAB> return cleaned_data ","if field . fieldname not in cleaned_data : 
","if not field . is_editable ( ) :
",33.71,11.04,False
"def setUp ( self ) : <TAB> self . realm = service . InMemoryWordsRealm ( "" realmname "" ) <TAB> self . checker = checkers . InMemoryUsernamePasswordDatabaseDontUse ( ) <TAB> self . portal = portal . Portal ( self . realm , [ self . checker ] ) <TAB> self . factory = service . IRCFactory ( self . realm , self . portal ) <TAB> c = [ ] <TAB> for nick in self . STATIC_USERS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nick = nick . decode ( "" utf-8 "" ) <TAB> <TAB> c . append ( self . realm . createUser ( nick ) ) <TAB> <TAB> self . checker . addUser ( nick , nick + "" _password "" ) <TAB> return DeferredList ( c ) ","if isinstance ( nick , bytes ) : 
","if isinstance ( nick , bytes ) :
",100.0,100.0,True
"def __call__ ( self , message ) : <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack + = 1 <TAB> <TAB> self . max_pending_ack = max ( self . max_pending_ack , self . _pending_ack ) <TAB> <TAB> self . seen_message_ids . append ( int ( message . attributes [ "" seq_num "" ] ) ) <TAB> time . sleep ( self . _processing_time ) <TAB> with self . _lock : <TAB> <TAB> self . _pending_ack - = 1 <TAB> <TAB> message . ack ( ) <TAB> <TAB> self . completed_calls + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not self . done_future . done ( ) : <TAB> <TAB> <TAB> <TAB> self . done_future . set_result ( None ) ","if self . completed_calls > = self . _resolve_at_msg_count : 
","if self . completed_calls == self . max_pending_ack :
",49.94,34.17,False
"def fill_in_standard_formats ( book ) : <TAB> for x in std_format_code_types . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ty = std_format_code_types [ x ] <TAB> <TAB> <TAB> # Note: many standard format codes (mostly CJK date formats) have <TAB> <TAB> <TAB> # format strings that vary by locale; xlrd does not (yet) <TAB> <TAB> <TAB> # handle those; the type (date or numeric) is recorded but the fmt_str will be None. <TAB> <TAB> <TAB> fmt_str = std_format_strings . get ( x ) <TAB> <TAB> <TAB> fmtobj = Format ( x , ty , fmt_str ) <TAB> <TAB> <TAB> book . format_map [ x ] = fmtobj ","if x not in book . format_map : 
","if x in book . format_map :
",74.63,71.89,False
"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i < = 3 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if even_only and i % 2 != 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> result . append ( i ) <TAB> return result ","if less_than_7_only and i > = 7 : 
","if less_than_7_only and i > = 7 :
",100.0,100.0,True
"def next_instruction_is_function_or_class ( lines ) : <TAB> """"""Is the first non-empty, non-commented line of the cell either a function or a class?"""""" <TAB> parser = StringParser ( "" python "" ) <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> <TAB> continue <TAB> <TAB> parser . read_line ( line ) <TAB> <TAB> if not line . strip ( ) :<TAB> # empty line <TAB> <TAB> <TAB> if i > 0 and not lines [ i - 1 ] . strip ( ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> if line . startswith ( "" def  "" ) or line . startswith ( "" class  "" ) : <TAB> <TAB> <TAB> return True <TAB> <TAB> if line . startswith ( ( "" # "" , "" @ "" , "" "" , "" ) "" ) ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> return False <TAB> return False ","if parser . is_quoted ( ) : 
","if not line . strip ( ) :
",48.71,20.61,False
"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB> <TAB> if tag . name not in ( "" input "" , ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError ","if "" name "" in tag . attrs and tag . attrs [ "" name "" ] in ( key , ) : 
","if tag . name == key :
",30.35,2.23,False
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB> <TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if obj . use_scope : <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB> <TAB> <TAB> elif obj . use_scope is None : <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation ","if hasattr ( obj , "" use_scope "" ) : 
","if signature [ 0 ] != "" mock_ "" :
",31.56,5.06,False
"def countbox ( self ) : <TAB> self . box = [ 1000 , 1000 , - 1000 , - 1000 ] <TAB> for x , y in self . body : <TAB> <TAB> if x < self . box [ 0 ] : <TAB> <TAB> <TAB> self . box [ 0 ] = x <TAB> <TAB> if x > self . box [ 2 ] : <TAB> <TAB> <TAB> self . box [ 2 ] = x <TAB> <TAB> if y < self . box [ 1 ] : <TAB> <TAB> <TAB> self . box [ 1 ] = y <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . box [ 3 ] = y ","if y > self . box [ 3 ] : 
","if y > self . box [ 3 ] :
",100.0,100.0,True
"def find_shell ( ) : <TAB> global DEFAULT_SHELL <TAB> if not DEFAULT_SHELL : <TAB> <TAB> for shell in propose_shell ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> DEFAULT_SHELL = shell <TAB> <TAB> <TAB> <TAB> break <TAB> if not DEFAULT_SHELL : <TAB> <TAB> DEFAULT_SHELL = "" /bin/sh "" <TAB> return DEFAULT_SHELL ","if os . path . isfile ( shell ) and os . access ( shell , os . X_OK ) : 
","if os . path . exists ( shell ) :
",49.47,15.33,False
"def addAggregators ( sheet , cols , aggrnames ) : <TAB> "" Add each aggregator in list of *aggrnames* to each of *cols*. "" <TAB> for aggrname in aggrnames : <TAB> <TAB> aggrs = vd . aggregators . get ( aggrname ) <TAB> <TAB> aggrs = aggrs if isinstance ( aggrs , list ) else [ aggrs ] <TAB> <TAB> for aggr in aggrs : <TAB> <TAB> <TAB> for c in cols : <TAB> <TAB> <TAB> <TAB> if not hasattr ( c , "" aggregators "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators = [ ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> c . aggregators + = [ aggr ] ","if aggr and aggr not in c . aggregators : 
","if isinstance ( aggr , list ) :
",26.39,5.66,False
"def run ( self , paths = [ ] ) : <TAB> items = [ ] <TAB> for item in SideBarSelection ( paths ) . getSelectedItems ( ) : <TAB> <TAB> items . append ( item . pathAbsoluteFromProjectEncoded ( ) ) <TAB> if len ( items ) > 0 : <TAB> <TAB> sublime . set_clipboard ( "" \n "" . join ( items ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sublime . status_message ( "" Items copied "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sublime . status_message ( "" Item copied "" ) ","if len ( items ) > 1 : 
","if len ( items ) > 1 :
",100.0,100.0,True
"def social_user ( backend , uid , user = None , * args , * * kwargs ) : <TAB> provider = backend . name <TAB> social = backend . strategy . storage . user . get_social_auth ( provider , uid ) <TAB> if social : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = "" This account is already in use. "" <TAB> <TAB> <TAB> raise AuthAlreadyAssociated ( backend , msg ) <TAB> <TAB> elif not user : <TAB> <TAB> <TAB> user = social . user <TAB> return { <TAB> <TAB> "" social "" : social , <TAB> <TAB> "" user "" : user , <TAB> <TAB> "" is_new "" : user is None , <TAB> <TAB> "" new_association "" : social is None , <TAB> } ","if user and social . user != user : 
","if user is None :
",27.89,8.7,False
"def _text ( bitlist ) : <TAB> out = "" "" <TAB> for typ , text in bitlist : <TAB> <TAB> if not typ : <TAB> <TAB> <TAB> out + = text <TAB> <TAB> elif typ == "" em "" : <TAB> <TAB> <TAB> out + = "" \\ fI %s \\ fR "" % text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out + = "" \\ fB %s \\ fR "" % text <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected tag  %r  inside text "" % ( typ , ) ) <TAB> out = out . strip ( ) <TAB> out = re . sub ( re . compile ( r "" ^ \ s+ "" , re . M ) , "" "" , out ) <TAB> return out ","elif typ in [ "" strong "" , "" code "" ] : 
","elif typ == "" bb "" :
",37.71,7.43,False
"def OnRadioSelect ( self , event ) : <TAB> fitID = self . mainFrame . getActiveFit ( ) <TAB> if fitID is not None : <TAB> <TAB> self . mainFrame . command . Submit ( <TAB> <TAB> <TAB> cmd . GuiChangeImplantLocationCommand ( <TAB> <TAB> <TAB> <TAB> fitID = fitID , <TAB> <TAB> <TAB> <TAB> source = ImplantLocation . FIT <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> else ImplantLocation . CHARACTER , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if self . rbFit . GetValue ( ) 
","if fitID != ImplantLocation . FIT
",31.02,6.77,False
"def hexdump ( data ) : <TAB> """"""yield lines with hexdump of data"""""" <TAB> values = [ ] <TAB> ascii = [ ] <TAB> offset = 0 <TAB> for h , a in sixteen ( data ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( offset , "" "" . join ( [ "" "" . join ( values ) , "" "" . join ( ascii ) ] ) ) <TAB> <TAB> <TAB> del values [ : ] <TAB> <TAB> <TAB> del ascii [ : ] <TAB> <TAB> <TAB> offset + = 0x10 <TAB> <TAB> else : <TAB> <TAB> <TAB> values . append ( h ) <TAB> <TAB> <TAB> ascii . append ( a ) ","if h is None : 
","if h == "" \x00 "" :
",29.79,10.55,False
"def submit ( self ) : <TAB> bot_token = self . config [ "" bot_token "" ] <TAB> chat_ids = self . config [ "" chat_id "" ] <TAB> chat_ids = [ chat_ids ] if isinstance ( chat_ids , str ) else chat_ids <TAB> text = "" \n "" . join ( super ( ) . submit ( ) ) <TAB> if not text : <TAB> <TAB> logger . debug ( "" Not calling telegram API (no changes) "" ) <TAB> <TAB> return <TAB> result = None <TAB> for chunk in chunkstring ( text , self . MAX_LENGTH , numbering = True ) : <TAB> <TAB> for chat_id in chat_ids : <TAB> <TAB> <TAB> res = self . submitToTelegram ( bot_token , chat_id , chunk ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = res <TAB> return result ","if res . status_code != requests . codes . ok or res is None : 
","if res :
",25.92,0.0,False
"def onMessage ( self , payload , isBinary ) : <TAB> if not isBinary : <TAB> <TAB> self . result = "" Expected binary message with payload, but got binary. "" <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . result = ( <TAB> <TAB> <TAB> <TAB> "" Expected binary message with payload of length  %d , but got  %d . "" <TAB> <TAB> <TAB> <TAB> % ( self . DATALEN , len ( payload ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ## FIXME : check actual content <TAB> <TAB> <TAB> ## <TAB> <TAB> <TAB> self . behavior = Case . OK <TAB> <TAB> <TAB> self . result = "" Received binary message of length  %d . "" % len ( payload ) <TAB> self . p . createWirelog = True <TAB> self . p . sendClose ( self . p . CLOSE_STATUS_CODE_NORMAL ) ","if len ( payload ) != self . DATALEN : 
","if len ( payload ) != self . DATALEN :
",100.0,100.0,True
"def verify_output ( actual , expected ) : <TAB> actual = _read_file ( actual , "" Actual "" ) <TAB> expected = _read_file ( join ( CURDIR , expected ) , "" Expected "" ) <TAB> if len ( expected ) != len ( actual ) : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" Lengths differ. Expected  %d  lines but got  %d "" <TAB> <TAB> <TAB> % ( len ( expected ) , len ( actual ) ) <TAB> <TAB> ) <TAB> for exp , act in zip ( expected , actual ) : <TAB> <TAB> tester = fnmatchcase if "" * "" in exp else eq <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" Lines differ. \n Expected:  %s \n Actual:<TAB> %s "" % ( exp , act ) <TAB> <TAB> <TAB> ) ","if not tester ( act . rstrip ( ) , exp . rstrip ( ) ) : 
","if not tester ( act ) :
",36.0,16.95,False
"def _in_out_vector_helper ( self , name1 , name2 , ceil ) : <TAB> vector = [ ] <TAB> stats = self . record <TAB> if ceil is None : <TAB> <TAB> ceil = self . _get_max_rate ( name1 , name2 ) <TAB> maxlen = self . config . get_stats_history_length ( ) <TAB> for n in [ name1 , name2 ] : <TAB> <TAB> for i in range ( maxlen + 1 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> vector . append ( float ( stats [ i ] [ n ] ) / ceil ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> vector . append ( 0.0 ) <TAB> return vector ","if i < len ( stats ) : 
","if stats [ i ] [ n ] > 0.0 :
",26.72,5.3,False
"def _init_param ( param , mode ) : <TAB> if isinstance ( param , str ) : <TAB> <TAB> param = _resolve ( param ) <TAB> elif isinstance ( param , ( list , tuple ) ) : <TAB> <TAB> param = [ _init_param ( p , mode ) for p in param ] <TAB> elif isinstance ( param , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> param = from_params ( param , mode = mode ) <TAB> <TAB> else : <TAB> <TAB> <TAB> param = { k : _init_param ( v , mode ) for k , v in param . items ( ) } <TAB> return param ","if { "" ref "" , "" class_name "" , "" config_path "" } . intersection ( param . keys ( ) ) : 
","if isinstance ( param , ( list , tuple ) ) :
",27.63,4.84,False
"def link_pantsrefs ( soups , precomputed ) : <TAB> """"""Transorm soups: <a pantsref=""foo""> becomes <a href=""../foo_page.html#foo"">"""""" <TAB> for ( page , soup ) in soups . items ( ) : <TAB> <TAB> for a in soup . find_all ( "" a "" ) : <TAB> <TAB> <TAB> if not a . has_attr ( "" pantsref "" ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> pantsref = a [ "" pantsref "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise TaskError ( <TAB> <TAB> <TAB> <TAB> <TAB> f ' Page  { page }  has pantsref  "" { pantsref } ""  and I cannot find pantsmark for it ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> a [ "" href "" ] = rel_href ( page , precomputed . pantsref [ pantsref ] ) ","if pantsref not in precomputed . pantsref : 
","if pantsref not in precomputed . pantsref :
",100.0,100.0,True
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> if not svalue : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return getint ( svalue ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> return value ","elif "" . "" in svalue : 
","elif isinstance ( svalue , float ) :
",27.02,7.27,False
"def default ( self , o ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr ( o , "" profile "" ) : <TAB> <TAB> <TAB> <TAB> del o . profile <TAB> <TAB> <TAB> if hasattr ( o , "" credentials "" ) : <TAB> <TAB> <TAB> <TAB> del o . credentials <TAB> <TAB> <TAB> if hasattr ( o , "" metadata_path "" ) : <TAB> <TAB> <TAB> <TAB> del o . metadata_path <TAB> <TAB> <TAB> if hasattr ( o , "" services_config "" ) : <TAB> <TAB> <TAB> <TAB> del o . services_config <TAB> <TAB> <TAB> return vars ( o ) <TAB> except Exception as e : <TAB> <TAB> return str ( o ) ","if type ( o ) == datetime . datetime : 
","if isinstance ( o , dict ) :
",27.84,9.55,False
"def transform_kwarg ( self , name , value , split_single_char_options ) : <TAB> if len ( name ) == 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ "" - %s "" % name ] <TAB> <TAB> elif value not in ( False , None ) : <TAB> <TAB> <TAB> if split_single_char_options : <TAB> <TAB> <TAB> <TAB> return [ "" - %s "" % name , "" %s "" % value ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return [ "" - %s %s "" % ( name , value ) ] <TAB> else : <TAB> <TAB> if value is True : <TAB> <TAB> <TAB> return [ "" -- %s "" % dashify ( name ) ] <TAB> <TAB> elif value is not False and value is not None : <TAB> <TAB> <TAB> return [ "" -- %s = %s "" % ( dashify ( name ) , value ) ] <TAB> return [ ] ","if value is True : 
","if value in ( True , None ) :
",29.78,11.34,False
"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB> <TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB> <TAB> if context . rounding == ROUND_FLOOR : <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) ","if context . rounding == ROUND_CEILING : 
","if context . rounding == ROUND_FLOOR :
",82.41,78.25,False
"def OnLeftUp ( self , event ) : <TAB> # Stop Drawing <TAB> if self . Drawing : <TAB> <TAB> self . Drawing = False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> world_rect = ( <TAB> <TAB> <TAB> <TAB> self . Canvas . PixelToWorld ( self . RBRect [ 0 ] ) , <TAB> <TAB> <TAB> <TAB> self . Canvas . ScalePixelToWorld ( self . RBRect [ 1 ] ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> wx . CallAfter ( self . CallBack , world_rect ) <TAB> self . RBRect = None ","if self . RBRect : 
","if self . RBRect is not None :
",60.15,36.56,False
"def _map_answers ( answers ) : <TAB> result = [ ] <TAB> for a in answers . split ( "" | "" ) : <TAB> <TAB> user_answers = [ ] <TAB> <TAB> result . append ( dict ( sourcerAnswers = user_answers ) ) <TAB> <TAB> for r in a . split ( "" , "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> user_answers . append ( dict ( noAnswer = True ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> start_ , end_ = map ( int , r . split ( "" : "" ) ) <TAB> <TAB> <TAB> <TAB> user_answers . append ( dict ( s = start_ , e = end_ ) ) <TAB> return result ","if r == "" None "" : 
","if "" : "" not in r :
",35.2,13.89,False
"def parse_edges ( self , pcb ) : <TAB> edges = [ ] <TAB> drawings = list ( pcb . GetDrawings ( ) ) <TAB> bbox = None <TAB> for m in pcb . GetModules ( ) : <TAB> <TAB> for g in m . GraphicalItems ( ) : <TAB> <TAB> <TAB> drawings . append ( g ) <TAB> for d in drawings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parsed_drawing = self . parse_drawing ( d ) <TAB> <TAB> <TAB> if parsed_drawing : <TAB> <TAB> <TAB> <TAB> edges . append ( parsed_drawing ) <TAB> <TAB> <TAB> <TAB> if bbox is None : <TAB> <TAB> <TAB> <TAB> <TAB> bbox = d . GetBoundingBox ( ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> bbox . Merge ( d . GetBoundingBox ( ) ) <TAB> if bbox : <TAB> <TAB> bbox . Normalize ( ) <TAB> return edges , bbox ","if d . GetLayer ( ) == pcbnew . Edge_Cuts : 
","if d . IsOk ( ) :
",45.55,11.84,False
"def get_size ( self ) : <TAB> size = self . start_size <TAB> for operation in self . ran_operations : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size = operation [ 1 ] [ 0 ] <TAB> <TAB> elif operation [ 0 ] == "" crop "" : <TAB> <TAB> <TAB> crop = operation [ 1 ] [ 0 ] <TAB> <TAB> <TAB> size = crop [ 2 ] - crop [ 0 ] , crop [ 3 ] - crop [ 1 ] <TAB> return size ","if operation [ 0 ] == "" resize "" : 
","if operation [ 0 ] == "" crop "" :
",85.49,74.19,False
"def migrate_account_metadata ( account_id ) : <TAB> from inbox . models . session import session_scope <TAB> from inbox . models import Account <TAB> with session_scope ( versioned = False ) as db_session : <TAB> <TAB> account = db_session . query ( Account ) . get ( account_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> create_categories_for_easfoldersyncstatuses ( account , db_session ) <TAB> <TAB> else : <TAB> <TAB> <TAB> create_categories_for_folders ( account , db_session ) <TAB> <TAB> if account . discriminator == "" gmailaccount "" : <TAB> <TAB> <TAB> set_labels_for_imapuids ( account , db_session ) <TAB> <TAB> db_session . commit ( ) ","if account . discriminator == "" easaccount "" : 
","if account . discriminator == "" easfoldersyncstatus "" :
",83.19,70.71,False
"def OnEndDrag ( self , event ) : <TAB> self . StopDragging ( ) <TAB> dropTarget = event . GetItem ( ) <TAB> if not dropTarget : <TAB> <TAB> dropTarget = self . GetRootItem ( ) <TAB> if self . IsValidDropTarget ( dropTarget ) : <TAB> <TAB> self . UnselectAll ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . SelectItem ( dropTarget ) <TAB> <TAB> self . OnDrop ( dropTarget , self . _dragItem ) ","if dropTarget != self . GetRootItem ( ) : 
","if self . _dragItem :
",32.32,9.91,False
"def validate ( self , frame , value ) : <TAB> if self . sep and isinstance ( value , string_types ) : <TAB> <TAB> value = value . split ( self . sep ) <TAB> if isinstance ( value , list ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ self . specs [ 0 ] . validate ( frame , v ) for v in value ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> [ s . validate ( frame , v ) for ( v , s ) in izip ( val , self . specs ) ] <TAB> <TAB> <TAB> <TAB> for val in value <TAB> <TAB> <TAB> ] <TAB> raise ValueError ( "" Invalid MultiSpec data:  %r "" % value ) ","if len ( self . specs ) == 1 : 
","if len ( self . specs ) == 1 :
",100.0,100.0,True
"def __init__ ( self , action_space = None , network = None , network_kwargs = None , hparams = None ) : <TAB> QNetBase . __init__ ( self , hparams = hparams ) <TAB> with tf . variable_scope ( self . variable_scope ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> action_space = Space ( low = 0 , high = self . _hparams . action_space , dtype = np . int32 ) <TAB> <TAB> self . _action_space = action_space <TAB> <TAB> self . _append_output_layer ( ) ","if action_space is None : 
","if action_space is None :
",100.0,100.0,True
"def n_weights ( self ) : <TAB> """"""Return the number of weights (parameters) in this network."""""" <TAB> n_weights = 0 <TAB> for i , w in enumerate ( self . all_weights ) : <TAB> <TAB> n = 1 <TAB> <TAB> # for s in p.eval().shape: <TAB> <TAB> for s in w . get_shape ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> s = int ( s ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> s = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> n = n * s <TAB> <TAB> n_weights = n_weights + n <TAB> # print(""num of weights (parameters) %d"" % n_weights) <TAB> return n_weights ","if s : 
","if s > 0 :
",34.79,23.64,False
"def _arg_desc ( name , ctx ) : <TAB> for param in ctx . command . params : <TAB> <TAB> if param . name == name : <TAB> <TAB> <TAB> desc = param . opts [ - 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> desc = param . human_readable_name <TAB> <TAB> <TAB> return desc <TAB> raise AssertionError ( name ) ","if desc [ 0 ] != "" - "" : 
","if param . human_readable_name :
",26.35,4.54,False
"def walk ( directory , path_so_far ) : <TAB> for name in sorted ( os . listdir ( directory ) ) : <TAB> <TAB> if any ( fnmatch ( name , pattern ) for pattern in basename_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path_so_far + "" / "" + name if path_so_far else name <TAB> <TAB> if any ( fnmatch ( path , pattern ) for pattern in path_ignore ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( directory , name ) <TAB> <TAB> if os . path . isdir ( full_name ) : <TAB> <TAB> <TAB> for file_path in walk ( full_name , path ) : <TAB> <TAB> <TAB> <TAB> yield file_path <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield path ","elif os . path . isfile ( full_name ) : 
","elif os . path . isfile ( path ) :
",85.49,57.89,False
"def cache_dst ( self ) : <TAB> final_dst = None <TAB> final_linenb = None <TAB> for linenb , assignblk in enumerate ( self ) : <TAB> <TAB> for dst , src in viewitems ( assignblk ) : <TAB> <TAB> <TAB> if dst . is_id ( "" IRDst "" ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Multiple destinations! "" ) <TAB> <TAB> <TAB> <TAB> final_dst = src <TAB> <TAB> <TAB> <TAB> final_linenb = linenb <TAB> self . _dst = final_dst <TAB> self . _dst_linenb = final_linenb <TAB> return final_dst ","if final_dst is not None : 
","if len ( src ) > linenb :
",26.98,6.57,False
"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB> <TAB> filters = { } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB> <TAB> if args . policy_type : <TAB> <TAB> <TAB> filters [ "" policy_type "" ] = args . policy_type <TAB> <TAB> filters . update ( * * kwargs ) <TAB> <TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB> <TAB> return self . manager . get_all ( * * kwargs ) ","if args . resource_ref : 
","if args . resource_ref :
",100.0,100.0,True
"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB> <TAB> duplicates = [ ] <TAB> <TAB> for other_folder , other_path in folders . items ( ) : <TAB> <TAB> <TAB> if other_folder == folder : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path : <TAB> <TAB> <TAB> <TAB> duplicates . append ( other_folder ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . duplicates [ folder ] = duplicates ","if len ( duplicates ) : 
","if duplicates :
",27.84,0.0,False
"def limit_clause ( self , select , * * kw ) : <TAB> text = "" "" <TAB> if select . _limit_clause is not None : <TAB> <TAB> text + = "" \n  LIMIT  "" + self . process ( select . _limit_clause , * * kw ) <TAB> if select . _offset_clause is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text + = "" \n  LIMIT  "" + self . process ( sql . literal ( - 1 ) ) <TAB> <TAB> text + = ""  OFFSET  "" + self . process ( select . _offset_clause , * * kw ) <TAB> else : <TAB> <TAB> text + = ""  OFFSET  "" + self . process ( sql . literal ( 0 ) , * * kw ) <TAB> return text ","if select . _limit_clause is None : 
","if select . _offset_clause == "" LIMIT "" :
",38.51,23.9,False
"def _get_activation ( self , act ) : <TAB> """"""Get activation block based on the name."""""" <TAB> if isinstance ( act , str ) : <TAB> <TAB> if act . lower ( ) == "" gelu "" : <TAB> <TAB> <TAB> return GELU ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return GELU ( approximate = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return gluon . nn . Activation ( act ) <TAB> assert isinstance ( act , gluon . Block ) <TAB> return act ","elif act . lower ( ) == "" approx_gelu "" : 
","elif act . lower ( ) == "" gelu "" :
",87.22,70.63,False
"def __eq__ ( self , other ) : <TAB> try : <TAB> <TAB> if self . type != other . type : <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . type == "" ASK "" : <TAB> <TAB> <TAB> return self . askAnswer == other . askAnswer <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . graph == other . graph <TAB> except : <TAB> <TAB> return False ","elif self . type == "" SELECT "" : 
","elif self . type == "" VAR "" :
",83.27,70.71,False
"def _get_text_nodes ( nodes , html_body ) : <TAB> text = [ ] <TAB> open_tags = 0 <TAB> for node in nodes : <TAB> <TAB> if isinstance ( node , HtmlTag ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> open_tags + = 1 <TAB> <TAB> <TAB> elif node . tag_type == CLOSE_TAG : <TAB> <TAB> <TAB> <TAB> open_tags - = 1 <TAB> <TAB> elif ( <TAB> <TAB> <TAB> isinstance ( node , HtmlDataFragment ) <TAB> <TAB> <TAB> and node . is_text_content <TAB> <TAB> <TAB> and open_tags == 0 <TAB> <TAB> ) : <TAB> <TAB> <TAB> text . append ( html_body [ node . start : node . end ] ) <TAB> return text ","if node . tag_type == OPEN_TAG : 
","if node . tag_type == OPEN_TAG :
",100.0,100.0,True
"def test_do_change ( self ) : <TAB> """"""Test if VTK object changes when trait is changed."""""" <TAB> p = Prop ( ) <TAB> p . edge_visibility = not p . edge_visibility <TAB> p . representation = "" p "" <TAB> p . opacity = 0.5 <TAB> p . color = ( 0 , 1 , 0 ) <TAB> p . diffuse_color = ( 1 , 1 , 1 ) <TAB> p . specular_color = ( 1 , 1 , 0 ) <TAB> for t , g in p . _updateable_traits_ : <TAB> <TAB> val = getattr ( p . _vtk_obj , g ) ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( val , getattr ( p , t + "" _ "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( val , getattr ( p , t ) ) ","if t == "" representation "" : 
","if t == "" edge "" :
",74.63,59.46,False
"def update_item ( source_doc , target_doc , source_parent ) : <TAB> target_doc . t_warehouse = "" "" <TAB> if source_doc . material_request_item and source_doc . material_request : <TAB> <TAB> add_to_transit = frappe . db . get_value ( <TAB> <TAB> <TAB> "" Stock Entry "" , source_name , "" add_to_transit "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warehouse = frappe . get_value ( <TAB> <TAB> <TAB> <TAB> "" Material Request Item "" , source_doc . material_request_item , "" warehouse "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> target_doc . t_warehouse = warehouse <TAB> target_doc . s_warehouse = source_doc . t_warehouse <TAB> target_doc . qty = source_doc . qty - source_doc . transferred_qty ","if add_to_transit : 
","if add_to_transit :
",78.12,100.0,True
"def get_drive ( self , root_path = "" "" , volume_guid_path = "" "" ) : <TAB> for drive in self . drives : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> config_root_path = drive . get ( "" root_path "" ) <TAB> <TAB> <TAB> if config_root_path and root_path == config_root_path : <TAB> <TAB> <TAB> <TAB> return drive <TAB> <TAB> elif volume_guid_path : <TAB> <TAB> <TAB> config_volume_guid_path = drive . get ( "" volume_guid_path "" ) <TAB> <TAB> <TAB> if config_volume_guid_path and config_volume_guid_path == volume_guid_path : <TAB> <TAB> <TAB> <TAB> return drive ","if root_path : 
","if root_path :
",78.12,100.0,True
"def f_freeze ( _ ) : <TAB> repos = utils . get_repos ( ) <TAB> for name , path in repos . items ( ) : <TAB> <TAB> url = "" "" <TAB> <TAB> cp = subprocess . run ( [ "" git "" , "" remote "" , "" -v "" ] , cwd = path , capture_output = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url = cp . stdout . decode ( "" utf-8 "" ) . split ( "" \n "" ) [ 0 ] . split ( ) [ 1 ] <TAB> <TAB> print ( f "" { url } , { name } , { path } "" ) ","if cp . returncode == 0 : 
","if cp . returncode :
",54.34,38.81,False
"def conj ( self ) : <TAB> dtype = self . dtype <TAB> if issubclass ( self . dtype . type , np . complexfloating ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" only contiguous arrays may  "" "" be used as arguments to this operation "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if self . flags . f_contiguous : <TAB> <TAB> <TAB> order = "" F "" <TAB> <TAB> else : <TAB> <TAB> <TAB> order = "" C "" <TAB> <TAB> result = self . _new_like_me ( order = order ) <TAB> <TAB> func = elementwise . get_conj_kernel ( dtype ) <TAB> <TAB> func . prepared_async_call ( <TAB> <TAB> <TAB> self . _grid , self . _block , None , self . gpudata , result . gpudata , self . mem_size <TAB> <TAB> ) <TAB> <TAB> return result <TAB> else : <TAB> <TAB> return self ","if not self . flags . forc : 
","if self . flags . f_contiguous :
",54.0,33.03,False
"def detect_reentrancy ( self , contract ) : <TAB> for function in contract . functions_and_modifiers_declared : <TAB> <TAB> if function . is_implemented : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> self . _explore ( function . entry_point , [ ] ) <TAB> <TAB> <TAB> function . context [ self . KEY ] = True ","if self . KEY in function . context : 
","if self . _explore ( function . entry_point , [ ] ) :
",41.31,11.98,False
"def test_default_configuration_no_encoding ( self ) : <TAB> transformations = [ ] <TAB> for i in range ( 2 ) : <TAB> <TAB> transformation , original = _test_preprocessing ( NoEncoding ) <TAB> <TAB> self . assertEqual ( transformation . shape , original . shape ) <TAB> <TAB> self . assertTrue ( ( transformation == original ) . all ( ) ) <TAB> <TAB> transformations . append ( transformation ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertTrue ( ( transformations [ - 1 ] == transformations [ - 2 ] ) . all ( ) ) ","if len ( transformations ) > 1 : 
","if len ( transformations ) > 1 :
",100.0,100.0,True
"def main ( ) : <TAB> """"""main function"""""" <TAB> # todo: lookuo real description <TAB> parser = argparse . ArgumentParser ( description = "" Let a cow speak for you "" ) <TAB> parser . add_argument ( "" text "" , nargs = "" * "" , default = None , help = "" text to say "" ) <TAB> ns = parser . parse_args ( ) <TAB> if ( ns . text is None ) or ( len ( ns . text ) == 0 ) : <TAB> <TAB> text = "" "" <TAB> <TAB> while True : <TAB> <TAB> <TAB> inp = sys . stdin . read ( 4096 ) <TAB> <TAB> <TAB> if inp . endswith ( "" \n "" ) : <TAB> <TAB> <TAB> <TAB> inp = inp [ : - 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text + = inp <TAB> else : <TAB> <TAB> text = "" "" . join ( ns . text ) <TAB> cow = get_cow ( text ) <TAB> print ( cow ) ","if not inp : 
","if inp == "" "" :
",28.83,8.64,False
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> if self . arch == "" i386 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> elif self . arch == "" amd64 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True ) ","if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : 
","if reg :
",25.33,0.0,False
"def get_boarding_status ( project ) : <TAB> status = "" Pending "" <TAB> if project : <TAB> <TAB> doc = frappe . get_doc ( "" Project "" , project ) <TAB> <TAB> if flt ( doc . percent_complete ) > 0.0 and flt ( doc . percent_complete ) < 100.0 : <TAB> <TAB> <TAB> status = "" In Process "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> status = "" Completed "" <TAB> <TAB> return status ","elif flt ( doc . percent_complete ) == 100.0 : 
","elif flt ( doc . percent_complete ) > 0.0 and flt ( doc . percent_complete ) < 100.0 :
",69.2,37.4,False
"def set_weights ( self , new_weights ) : <TAB> weights = self . get_weights ( ) <TAB> if len ( weights ) != len ( new_weights ) : <TAB> <TAB> raise ValueError ( "" len of lists mismatch "" ) <TAB> tuples = [ ] <TAB> for w , new_w in zip ( weights , new_weights ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_w = new_w . reshape ( w . shape ) <TAB> <TAB> tuples . append ( ( w , new_w ) ) <TAB> nn . batch_set_value ( tuples ) ","if len ( w . shape ) != new_w . shape : 
","if isinstance ( new_w , nn . BatchNorm ) :
",33.52,12.55,False
"def reload_json_api_settings ( * args , * * kwargs ) : <TAB> django_setting = kwargs [ "" setting "" ] <TAB> setting = django_setting . replace ( JSON_API_SETTINGS_PREFIX , "" "" ) <TAB> value = kwargs [ "" value "" ] <TAB> if setting in DEFAULTS . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( json_api_settings , setting , value ) <TAB> <TAB> elif hasattr ( json_api_settings , setting ) : <TAB> <TAB> <TAB> delattr ( json_api_settings , setting ) ","if value is not None : 
","if value is not None :
",100.0,100.0,True
"def knamn ( self , sup , cdict ) : <TAB> cname = cdict [ sup ] . class_name <TAB> if not cname : <TAB> <TAB> ( namesp , tag ) = cdict [ sup ] . name . split ( "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctag = self . root . modul [ namesp ] . factory ( tag ) . __class__ . __name__ <TAB> <TAB> <TAB> cname = "" %s . %s "" % ( namesp , ctag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cname = tag + "" _ "" <TAB> return cname ","if namesp : 
","if namesp in self . root . modul :
",33.05,10.55,False
"def setdefault ( self , key , default = None ) : <TAB> try : <TAB> <TAB> o = self . data [ key ] ( ) <TAB> except KeyError : <TAB> <TAB> o = None <TAB> if o is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _commit_removals ( ) <TAB> <TAB> self . data [ key ] = KeyedRef ( default , self . _remove , key ) <TAB> <TAB> return default <TAB> else : <TAB> <TAB> return o ","if self . _pending_removals : 
","if self . _commit_removals :
",64.48,50.0,False
"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB> <TAB> module = self . get_event_module ( event ) <TAB> <TAB> self . __module_view . set_selection ( module . module_num ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . list_ctrl . deactivate_active_item ( ) <TAB> <TAB> <TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB> <TAB> <TAB> <TAB> if self . list_ctrl . IsSelected ( index ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( ) ","if event . EventObject is self . list_ctrl : 
","if self . input_list_ctrl :
",38.05,29.54,False
"def _create_valid_graph ( graph ) : <TAB> nodes = graph . nodes ( ) <TAB> for i in range ( len ( nodes ) ) : <TAB> <TAB> for j in range ( len ( nodes ) ) : <TAB> <TAB> <TAB> if i == j : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> edge = ( nodes [ i ] , nodes [ j ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> graph . del_edge ( edge ) <TAB> <TAB> <TAB> graph . add_edge ( edge , 1 ) ","if graph . has_edge ( edge ) : 
","if graph . has_edge ( edge ) :
",100.0,100.0,True
"def _parse_param_value ( name , datatype , default ) : <TAB> if datatype == "" bool "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> elif default . lower ( ) == "" false "" : <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> _s = "" {} : Invalid default value  ' {} '  for bool parameter  {} "" <TAB> <TAB> <TAB> raise SyntaxError ( _s . format ( self . name , default , p ) ) <TAB> elif datatype == "" int "" : <TAB> <TAB> if type ( default ) == int : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return int ( default , 0 ) <TAB> elif datatype == "" real "" : <TAB> <TAB> if type ( default ) == float : <TAB> <TAB> <TAB> return default <TAB> <TAB> else : <TAB> <TAB> <TAB> return float ( default ) <TAB> else : <TAB> <TAB> return str ( default ) ","if default . lower ( ) == "" true "" : 
","if default . lower ( ) == "" true "" :
",100.0,100.0,True
"def get_size ( self , shape_info ) : <TAB> # The size is the data, that have constant size. <TAB> state = np . random . RandomState ( ) . get_state ( ) <TAB> size = 0 <TAB> for elem in state : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size + = len ( elem ) <TAB> <TAB> elif isinstance ( elem , np . ndarray ) : <TAB> <TAB> <TAB> size + = elem . size * elem . itemsize <TAB> <TAB> elif isinstance ( elem , int ) : <TAB> <TAB> <TAB> size + = np . dtype ( "" int "" ) . itemsize <TAB> <TAB> elif isinstance ( elem , float ) : <TAB> <TAB> <TAB> size + = np . dtype ( "" float "" ) . itemsize <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( ) <TAB> return size ","if isinstance ( elem , str ) : 
","if isinstance ( elem , ( list , tuple ) ) :
",49.15,36.46,False
"def _merge_substs ( self , subst , new_substs ) : <TAB> subst = subst . copy ( ) <TAB> for new_subst in new_substs : <TAB> <TAB> for name , var in new_subst . items ( ) : <TAB> <TAB> <TAB> if name not in subst : <TAB> <TAB> <TAB> <TAB> subst [ name ] = var <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> subst [ name ] . PasteVariable ( var ) <TAB> return subst ","elif subst [ name ] is not var : 
","if isinstance ( subst [ name ] , PasteVariable ) :
",42.59,24.81,False
"def _load_weights_if_possible ( self , model , init_weight_path = None ) : <TAB> """"""Loads model weights when it is provided."""""" <TAB> if init_weight_path : <TAB> <TAB> logging . info ( "" Load weights:  {} "" . format ( init_weight_path ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> checkpoint = tf . train . Checkpoint ( <TAB> <TAB> <TAB> <TAB> model = model , optimizer = self . _create_optimizer ( ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> checkpoint . restore ( init_weight_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> model . load_weights ( init_weight_path ) <TAB> else : <TAB> <TAB> logging . info ( "" Weights not loaded from path: {} "" . format ( init_weight_path ) ) ","if self . use_tpu : 
","if self . _optimizer :
",64.48,29.06,False
"def _cleanup_inactive_receivexlogs ( self , site ) : <TAB> if site in self . receivexlogs : <TAB> <TAB> if not self . receivexlogs [ site ] . running : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . receivexlogs [ site ] . join ( ) <TAB> <TAB> <TAB> del self . receivexlogs [ site ] ","if self . receivexlogs [ site ] . is_alive ( ) : 
","if self . receivexlogs [ site ] . is_alive ( ) :
",100.0,100.0,True
"def get_asset ( self , path ) : <TAB> """"""Loads an asset by path."""""" <TAB> clean_path = cleanup_path ( path ) . strip ( "" / "" ) <TAB> nodes = [ self . asset_root ] + self . theme_asset_roots <TAB> for node in nodes : <TAB> <TAB> for piece in clean_path . split ( "" / "" ) : <TAB> <TAB> <TAB> node = node . get_child ( piece ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if node is not None : <TAB> <TAB> <TAB> return node <TAB> return None ","if node is None : 
","if node is not None :
",64.71,37.99,False
"def palindromic_substrings ( s ) : <TAB> if not s : <TAB> <TAB> return [ [ ] ] <TAB> results = [ ] <TAB> for i in range ( len ( s ) , 0 , - 1 ) : <TAB> <TAB> sub = s [ : i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for rest in palindromic_substrings ( s [ i : ] ) : <TAB> <TAB> <TAB> <TAB> results . append ( [ sub ] + rest ) <TAB> return results ","if sub == sub [ : : - 1 ] : 
","if sub :
",26.72,0.0,False
"def debug_tree ( tree ) : <TAB> l = [ ] <TAB> for elt in tree : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> l . append ( _names . get ( elt , elt ) ) <TAB> <TAB> elif isinstance ( elt , str ) : <TAB> <TAB> <TAB> l . append ( elt ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l . append ( debug_tree ( elt ) ) <TAB> return l ","if isinstance ( elt , ( int , long ) ) : 
","if isinstance ( elt , int ) :
",44.03,37.29,False
"def shared_username ( account ) : <TAB> username = os . environ . get ( "" SHARED_USERNAME "" , "" PKKid "" ) <TAB> for user in account . users ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return username <TAB> <TAB> elif ( <TAB> <TAB> <TAB> user . username <TAB> <TAB> <TAB> and user . email <TAB> <TAB> <TAB> and user . id <TAB> <TAB> <TAB> and username . lower ( ) <TAB> <TAB> <TAB> in ( user . username . lower ( ) , user . email . lower ( ) , str ( user . id ) ) <TAB> <TAB> ) : <TAB> <TAB> <TAB> return username <TAB> pytest . skip ( "" Shared user  %s  wasn`t found in your MyPlex account "" % username ) ","if user . title . lower ( ) == username . lower ( ) : 
","if user . username == username :
",34.02,13.22,False
"def process_schema_element ( self , e ) : <TAB> if e . name is None : <TAB> <TAB> return <TAB> self . debug1 ( "" adding element:  %s "" , e . name ) <TAB> t = self . get_type ( e . type ) <TAB> if t : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . pending_elements [ e . name ] <TAB> <TAB> self . retval [ self . tns ] . elements [ e . name ] = e <TAB> else : <TAB> <TAB> self . pending_elements [ e . name ] = e ","if e . name in self . pending_elements : 
","if e . name in self . pending_elements :
",100.0,100.0,True
"def __setitem__ ( self , key , value ) : <TAB> with self . _lock : <TAB> <TAB> try : <TAB> <TAB> <TAB> link = self . _get_link_and_move_to_front_of_ll ( key ) <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _set_key_and_add_to_front_of_ll ( key , value ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> evicted = self . _set_key_and_evict_last_in_ll ( key , value ) <TAB> <TAB> <TAB> <TAB> super ( LRI , self ) . __delitem__ ( evicted ) <TAB> <TAB> <TAB> super ( LRI , self ) . __setitem__ ( key , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> link [ VALUE ] = value ","if len ( self ) < self . max_size : 
","if self . front_of_key == key :
",31.97,8.52,False
"def __delattr__ ( self , name ) : <TAB> if name == "" __dict__ "" : <TAB> <TAB> raise AttributeError ( <TAB> <TAB> <TAB> "" %r  object attribute  ' __dict__ '  is read-only "" % self . __class__ . __name__ <TAB> <TAB> ) <TAB> if name in self . _local_type_vars : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # A data descriptor, like a property or a slot. <TAB> <TAB> <TAB> type_attr = getattr ( self . _local_type , name , _marker ) <TAB> <TAB> <TAB> type ( type_attr ) . __delete__ ( type_attr , self ) <TAB> <TAB> <TAB> return <TAB> # Otherwise it goes directly in the dict <TAB> # Begin inlined function _get_dict() <TAB> dct = _local_get_dict ( self ) <TAB> try : <TAB> <TAB> del dct [ name ] <TAB> except KeyError : <TAB> <TAB> raise AttributeError ( name ) ","if name in self . _local_type_del_descriptors : 
","if isinstance ( self . _local_type , type ) :
",34.62,37.87,False
"def update_participants ( self , refresh = True ) : <TAB> for participant in list ( self . participants_dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . removeItem ( self . participants_dict [ participant ] ) <TAB> <TAB> self . participant_items . remove ( self . participants_dict [ participant ] ) <TAB> <TAB> del self . participants_dict [ participant ] <TAB> for participant in self . simulator_config . participants : <TAB> <TAB> if participant in self . participants_dict : <TAB> <TAB> <TAB> self . participants_dict [ participant ] . refresh ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . insert_participant ( participant ) <TAB> if refresh : <TAB> <TAB> self . update_view ( ) ","if participant is None or participant == self . simulator_config . broadcast_part : 
","if participant not in self . participants_dict :
",30.91,5.9,False
"def insert_bigger_b_add ( node ) : <TAB> if node . op == theano . tensor . add : <TAB> <TAB> inputs = list ( node . inputs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> inputs [ - 1 ] = theano . tensor . concatenate ( ( inputs [ - 1 ] , inputs [ - 1 ] ) ) <TAB> <TAB> <TAB> return [ node . op ( * inputs ) ] <TAB> return False ","if inputs [ - 1 ] . owner is None : 
","if len ( inputs ) > 1 :
",26.33,5.37,False
"def _activate_cancel_status ( self , cancel_status ) : <TAB> if self . _cancel_status is not None : <TAB> <TAB> self . _cancel_status . _tasks . remove ( self ) <TAB> self . _cancel_status = cancel_status <TAB> if self . _cancel_status is not None : <TAB> <TAB> self . _cancel_status . _tasks . add ( self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _attempt_delivery_of_any_pending_cancel ( ) ","if self . _cancel_status . effectively_cancelled : 
","if self . _cancel_status . _tasks :
",82.41,65.52,False
"def writeLibraryGeometry ( fp , meshes , config , shapes = None ) : <TAB> progress = Progress ( len ( meshes ) , None ) <TAB> fp . write ( "" \n   <library_geometries> \n "" ) <TAB> for mIdx , mesh in enumerate ( meshes ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shape = None <TAB> <TAB> else : <TAB> <TAB> <TAB> shape = shapes [ mIdx ] <TAB> <TAB> writeGeometry ( fp , mesh , config , shape ) <TAB> <TAB> progress . step ( ) <TAB> fp . write ( ""   </library_geometries> \n "" ) ","if shapes is None : 
","if shapes is None :
",100.0,100.0,True
"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB> <TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> if module_json [ "" name "" ] not in config : <TAB> <TAB> <TAB> <TAB> config . add_section ( module_json [ "" name "" ] ) <TAB> <TAB> <TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config ","if config_var not in config [ module_json [ "" name "" ] ] : 
","if config_var . startswith ( config_path ) :
",26.65,14.79,False
"def get_const_defines ( flags , prefix = "" "" ) : <TAB> defs = [ ] <TAB> for k , v in globals ( ) . items ( ) : <TAB> <TAB> if isinstance ( v , int ) : <TAB> <TAB> <TAB> if v & flags : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if k . startswith ( prefix ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> defs . append ( k ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> defs . append ( k ) <TAB> return defs ","if prefix : 
","if prefix :
",78.12,0.0,False
"def __init__ ( self , source , encoding = DEFAULT_ENCODING ) : <TAB> self . data = { } <TAB> with open ( source , encoding = encoding ) as file_ : <TAB> <TAB> for line in file_ : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> k , v = line . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> k = k . strip ( ) <TAB> <TAB> <TAB> v = v . strip ( ) <TAB> <TAB> <TAB> if len ( v ) > = 2 and ( <TAB> <TAB> <TAB> <TAB> ( v [ 0 ] == "" ' "" and v [ - 1 ] == "" ' "" ) or ( v [ 0 ] == ' "" ' and v [ - 1 ] == ' "" ' ) <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> v = v . strip ( "" ' \"" "" ) <TAB> <TAB> <TAB> self . data [ k ] = v ","if not line or line . startswith ( "" # "" ) or "" = "" not in line : 
","if not line or line . startswith ( "" # "" ) :
",58.77,54.31,False
"def __detect_console_logger ( self ) : <TAB> logger = self . log <TAB> while logger : <TAB> <TAB> for handler in logger . handlers [ : ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if handler . stream in ( sys . stdout , sys . stderr ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . logger_handlers . append ( handler ) <TAB> <TAB> if logger . root == logger : <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> logger = logger . root ","if isinstance ( handler , StreamHandler ) : 
","if isinstance ( handler , logging . StreamHandler ) :
",55.42,52.54,False
"def check_heuristic_in_sql ( ) : <TAB> heurs = set ( ) <TAB> excluded = [ "" Equal assembly or pseudo-code "" , "" All or most attributes "" ] <TAB> for heur in HEURISTICS : <TAB> <TAB> name = heur [ "" name "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> sql = heur [ "" sql "" ] <TAB> <TAB> if sql . lower ( ) . find ( name . lower ( ) ) == - 1 : <TAB> <TAB> <TAB> print ( ( "" SQL command not correctly associated to  %s "" % repr ( name ) ) ) <TAB> <TAB> <TAB> print ( sql ) <TAB> <TAB> <TAB> assert sql . find ( name ) != - 1 <TAB> <TAB> heurs . add ( name ) <TAB> print ( "" Heuristics: "" ) <TAB> import pprint <TAB> pprint . pprint ( heurs ) ","if name in excluded : 
","if name in excluded :
",100.0,100.0,True
"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . seek_to_block ( self . cursor ) <TAB> <TAB> part = self . current_stream . read ( size ) <TAB> <TAB> if size > 0 : <TAB> <TAB> <TAB> if len ( part ) == 0 : <TAB> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> <TAB> size - = len ( part ) <TAB> <TAB> self . cursor + = len ( part ) <TAB> <TAB> buf + = part <TAB> return bytes ( buf ) ","if not self . in_current_block ( self . cursor ) : 
","if not self . current_stream . eof ( ) :
",47.51,23.59,False
"def get_project_dir ( env ) : <TAB> project_file = workon_home / env / "" .project "" <TAB> if project_file . exists ( ) : <TAB> <TAB> with project_file . open ( ) as f : <TAB> <TAB> <TAB> project_dir = f . readline ( ) . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return project_dir <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> err ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Corrupted or outdated: "" , <TAB> <TAB> <TAB> <TAB> <TAB> project_file , <TAB> <TAB> <TAB> <TAB> <TAB> "" \n Directory "" , <TAB> <TAB> <TAB> <TAB> <TAB> project_dir , <TAB> <TAB> <TAB> <TAB> <TAB> "" doesn ' t exist. "" , <TAB> <TAB> <TAB> <TAB> ) ","if os . path . exists ( project_dir ) : 
","if os . path . exists ( project_dir ) :
",100.0,100.0,True
"def _cache_mem ( curr_out , prev_mem , mem_len , reuse_len = None ) : <TAB> """"""cache hidden states into memory."""""" <TAB> if mem_len is None or mem_len == 0 : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> curr_out = curr_out [ : reuse_len ] <TAB> <TAB> if prev_mem is None : <TAB> <TAB> <TAB> new_mem = curr_out [ - mem_len : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> new_mem = tf . concat ( [ prev_mem , curr_out ] , 0 ) [ - mem_len : ] <TAB> return tf . keras . backend . stop_gradient ( new_mem ) ","if reuse_len is not None and reuse_len > 0 : 
","if reuse_len is not None :
",54.35,41.07,False
"def cleanup_channel ( self , to_cleanup ) : <TAB> public_key , id_ = to_cleanup <TAB> # TODO: Maybe run it threaded? <TAB> try : <TAB> <TAB> with db_session : <TAB> <TAB> <TAB> channel = self . session . mds . ChannelMetadata . get_for_update ( <TAB> <TAB> <TAB> <TAB> public_key = public_key , id_ = id_ <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> channel . local_version = 0 <TAB> <TAB> <TAB> channel . contents . delete ( bulk = True ) <TAB> except Exception as e : <TAB> <TAB> self . _logger . warning ( "" Exception while cleaning unsubscribed channel:  % "" , str ( e ) ) ","if not channel : 
","if not channel :
",100.0,100.0,True
"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images [ 0 ] <TAB> for img in images : <TAB> <TAB> if img . width == width and img . height == height : <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image ","elif img . width > = width and img . width * img . height > image . width * image . height : 
","if img . width > width and img . height > height :
",34.39,24.89,False
"def add_peer_to_blob ( self , contact : "" KademliaPeer "" , key : bytes ) - > None : <TAB> now = self . loop . time ( ) <TAB> if key in self . _data_store : <TAB> <TAB> current = list ( filter ( lambda x : x [ 0 ] == contact , self . _data_store [ key ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _data_store [ key ] [ self . _data_store [ key ] . index ( current [ 0 ] ) ] = ( <TAB> <TAB> <TAB> <TAB> contact , <TAB> <TAB> <TAB> <TAB> now , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _data_store [ key ] . append ( ( contact , now ) ) <TAB> else : <TAB> <TAB> self . _data_store [ key ] = [ ( contact , now ) ] ","if len ( current ) > 0 : 
","if current :
",26.73,0.0,False
"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB> <TAB> if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) ) ","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) : 
","elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) :
",100.0,100.0,True
"def GeneratePageMetatadata ( self , task ) : <TAB> address_space = self . session . GetParameter ( "" default_address_space "" ) <TAB> for vma in task . mm . mmap . walk_list ( "" vm_next "" ) : <TAB> <TAB> start = vma . vm_start <TAB> <TAB> end = vma . vm_end <TAB> <TAB> # Skip the entire region. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Done. <TAB> <TAB> if start > self . plugin_args . end : <TAB> <TAB> <TAB> break <TAB> <TAB> for vaddr in utils . xrange ( start , end , 0x1000 ) : <TAB> <TAB> <TAB> if self . plugin_args . start < = vaddr < = self . plugin_args . end : <TAB> <TAB> <TAB> <TAB> yield vaddr , self . _CreateMetadata ( address_space . describe_vtop ( vaddr ) ) ","if end < self . plugin_args . start : 
","if start == self . plugin_args . start :
",80.85,63.16,False
"def _available_symbols ( self , scoperef , expr ) : <TAB> cplns = [ ] <TAB> found_names = set ( ) <TAB> while scoperef : <TAB> <TAB> elem = self . _elem_from_scoperef ( scoperef ) <TAB> <TAB> for child in elem : <TAB> <TAB> <TAB> name = child . get ( "" name "" , "" "" ) <TAB> <TAB> <TAB> if name . startswith ( expr ) : <TAB> <TAB> <TAB> <TAB> if name not in found_names : <TAB> <TAB> <TAB> <TAB> <TAB> found_names . add ( name ) <TAB> <TAB> <TAB> <TAB> <TAB> ilk = child . get ( "" ilk "" ) or child . tag <TAB> <TAB> <TAB> <TAB> <TAB> cplns . append ( ( ilk , name ) ) <TAB> <TAB> scoperef = self . parent_scoperef_from_scoperef ( scoperef ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return sorted ( cplns , key = operator . itemgetter ( 1 ) ) ","if not scoperef : 
","if not scoperef :
",100.0,100.0,True
"def get_xenapi_host ( self ) : <TAB> """"""Return the xenapi host on which nova-compute runs on."""""" <TAB> with self . _get_session ( ) as session : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return session . xenapi . host . get_by_uuid ( self . host_uuid ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return session . xenapi . session . get_this_host ( session . handle ) ","if self . host_uuid : 
","if self . host_uuid :
",100.0,100.0,True
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> elif "" status "" in line : <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> elif "" error "" in line : <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError ","if "" stream "" in line and line [ "" stream "" ] . strip ( ) : 
","if "" stream "" in line :
",44.19,17.47,False
"def test_wildcard_import ( ) : <TAB> bonobo = __import__ ( "" bonobo "" ) <TAB> assert bonobo . __version__ <TAB> for name in dir ( bonobo ) : <TAB> <TAB> # ignore attributes starting by underscores <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> attr = getattr ( bonobo , name ) <TAB> <TAB> if inspect . ismodule ( attr ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> assert name in bonobo . __all__ ","if name . startswith ( "" _ "" ) : 
","if name . startswith ( "" _ "" ) :
",100.0,100.0,True
"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB> <TAB> v = b . data <TAB> <TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB> <TAB> <TAB> const = v . pyval is true_val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> elif not compare . compatible_with ( v , False ) : <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else : <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var ","elif not compare . compatible_with ( v , True ) : 
","elif not v . pyval :
",27.5,6.36,False
"def _parse_policies ( self , policies_yaml ) : <TAB> for item in policies_yaml : <TAB> <TAB> id_ = required_key ( item , "" id "" ) <TAB> <TAB> controls_ids = required_key ( item , "" controls "" ) <TAB> <TAB> if not isinstance ( controls_ids , list ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> msg = "" Policy  {id_}  contains invalid controls list  {controls} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> id_ = id_ , controls = str ( controls_ids ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> raise ValueError ( msg ) <TAB> <TAB> self . policies [ id_ ] = controls_ids ","if controls_ids != "" all "" : 
","if not len ( controls_ids ) > 0 :
",26.99,15.85,False
"def pong ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> payload = payload . decode ( "" utf-8 "" ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Sending a pong data frame  "" <TAB> <TAB> <TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PONG ) <TAB> with self . sock_send_lock : <TAB> <TAB> self . sock . send ( data ) ","if isinstance ( payload , bytes ) : 
","if isinstance ( payload , bytes ) :
",100.0,100.0,True
"def _extract_curve_feature_log ( arg ) : <TAB> """"""extract sampled curve feature for log items"""""" <TAB> try : <TAB> <TAB> inp , res = arg <TAB> <TAB> config = inp . config <TAB> <TAB> with inp . target : <TAB> <TAB> <TAB> sch , args = inp . task . instantiate ( config ) <TAB> <TAB> fea = feature . get_buffer_curve_sample_flatten ( sch , args , sample_n = 20 ) <TAB> <TAB> x = np . concatenate ( ( fea , list ( config . get_other_option ( ) . values ( ) ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y = inp . task . flop / np . mean ( res . costs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> y = 0.0 <TAB> <TAB> return x , y <TAB> except Exception :<TAB> # pylint: disable=broad-except <TAB> <TAB> return None ","if res . error_no == 0 : 
","if res . costs :
",40.7,15.72,False
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> if ss [ "" branch "" ] : <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> if ss [ "" patch "" ] is not None : <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text ","if ss [ "" revision "" ] : 
","if ss [ "" revision "" ] is not None :
",73.99,59.0,False
"def find_repository ( ) : <TAB> orig_path = path = os . path . realpath ( "" . "" ) <TAB> drive , path = os . path . splitdrive ( path ) <TAB> while path : <TAB> <TAB> current_path = os . path . join ( drive , path ) <TAB> <TAB> current_repo = LocalRepository ( current_path ) <TAB> <TAB> if current_repo . isValid ( ) : <TAB> <TAB> <TAB> return current_repo <TAB> <TAB> path , path_tail = os . path . split ( current_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CannotFindRepository ( "" Cannot find repository for  %s "" % ( orig_path , ) ) ","if not path_tail : 
","if path_tail != orig_path :
",29.25,17.75,False
"def compute_indices ( text : str , tokens ) : <TAB> indices = [ ] <TAB> for i , token in enumerate ( tokens ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> current_index = indices [ - 1 ] + len ( tokens [ i - 1 ] [ 0 ] ) <TAB> <TAB> <TAB> indices . append ( current_index + text [ current_index : ] . find ( token [ 0 ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> indices . append ( text . find ( token [ 0 ] ) ) <TAB> return indices ","if 1 < = i : 
","if i > 0 :
",27.91,11.51,False
"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self . distribution . has_data_files ( ) : <TAB> <TAB> for item in self . distribution . data_files : <TAB> <TAB> <TAB> if isinstance ( item , str ) : <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path ( item ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . filelist . append ( item ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname , filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames : <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path ( f ) <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( f ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . filelist . append ( f ) ","if os . path . isfile ( item ) : 
","if os . path . isfile ( item ) :
",100.0,100.0,True
"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB> <TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB> <TAB> elif str ( libcxx ) == "" libstdc++11 "" : <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" "" ","if str ( libcxx ) == "" libstdc++ "" : 
","if str ( libcxx ) == "" libstdc++10 "" :
",85.49,80.91,False
"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> elif isinstance ( v , bool ) : <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v ) ","elif isinstance ( v , basestring ) : 
","elif isinstance ( v , str ) :
",79.9,59.46,False
"def test_seek ( self ) : <TAB> <MASK> <TAB> <TAB> print ( "" create large file via seek (may be sparse file) ... "" ) <TAB> with self . open ( TESTFN , "" wb "" ) as f : <TAB> <TAB> f . write ( b "" z "" ) <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> f . seek ( size ) <TAB> <TAB> f . write ( b "" a "" ) <TAB> <TAB> f . flush ( ) <TAB> <TAB> if verbose : <TAB> <TAB> <TAB> print ( "" check file size with os.fstat "" ) <TAB> <TAB> self . assertEqual ( os . fstat ( f . fileno ( ) ) [ stat . ST_SIZE ] , size + 1 ) ","if verbose : 
","if verbose :
",78.12,0.0,False
"def serialize_review_url_field ( self , obj , * * kwargs ) : <TAB> if obj . review_ui : <TAB> <TAB> review_request = obj . get_review_request ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> local_site_name = review_request . local_site . name <TAB> <TAB> else : <TAB> <TAB> <TAB> local_site_name = None <TAB> <TAB> return local_site_reverse ( <TAB> <TAB> <TAB> "" file-attachment "" , <TAB> <TAB> <TAB> local_site_name = local_site_name , <TAB> <TAB> <TAB> kwargs = { <TAB> <TAB> <TAB> <TAB> "" review_request_id "" : review_request . display_id , <TAB> <TAB> <TAB> <TAB> "" file_attachment_id "" : obj . pk , <TAB> <TAB> <TAB> } , <TAB> <TAB> ) <TAB> return "" "" ","if review_request . local_site_id : 
","if review_request . local_site :
",64.48,71.2,False
"def on_item_down_clicked ( self , button ) : <TAB> model = self . treeview . get_model ( ) <TAB> for s in self . _get_selected ( ) : <TAB> <TAB> if s [ 0 ] < len ( model ) - 1 :<TAB> # XXX need model.swap <TAB> <TAB> <TAB> old = model . get_iter ( s [ 0 ] ) <TAB> <TAB> <TAB> iter = model . insert ( s [ 0 ] + 2 ) <TAB> <TAB> <TAB> for i in range ( 3 ) : <TAB> <TAB> <TAB> <TAB> model . set_value ( iter , i , model . get_value ( old , i ) ) <TAB> <TAB> <TAB> model . remove ( old ) <TAB> <TAB> <TAB> self . treeview . get_selection ( ) . select_iter ( iter ) <TAB> self . _update_filter_string ( ) ","if s [ 0 ] < len ( model ) - 1 : 
","if s [ 0 ] < len ( model ) - 1 :
",100.0,100.0,True
"def writer ( self ) : <TAB> """"""loop forever and copy socket->serial"""""" <TAB> while self . alive : <TAB> <TAB> try : <TAB> <TAB> <TAB> data = self . socket . recv ( 1024 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self . serial . write ( b "" "" . join ( self . rfc2217 . filter ( data ) ) ) <TAB> <TAB> except socket . error as msg : <TAB> <TAB> <TAB> self . log . error ( "" {} "" . format ( msg ) ) <TAB> <TAB> <TAB> # probably got disconnected <TAB> <TAB> <TAB> break <TAB> self . stop ( ) ","if not data : 
","if not data :
",100.0,100.0,True
"def __getitem__ ( self , key ) : <TAB> if key == 1 : <TAB> <TAB> return self . get_value ( ) <TAB> elif key == 0 : <TAB> <TAB> return self . cell [ 0 ] <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> s = list ( self . cell . __getitem__ ( key ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s [ s . index ( self . cell [ 1 ] ) ] = self . get_value ( ) <TAB> <TAB> return s <TAB> else : <TAB> <TAB> raise IndexError ( key ) ","if self . cell [ 1 ] in s : 
","if len ( s ) > 0 :
",26.45,5.66,False
"def test_error_stream ( environ , start_response ) : <TAB> writer = start_response ( "" 200 OK "" , [ ] ) <TAB> wsgi_errors = environ [ "" wsgi.errors "" ] <TAB> error_msg = None <TAB> for method in [ <TAB> <TAB> "" flush "" , <TAB> <TAB> "" write "" , <TAB> <TAB> "" writelines "" , <TAB> ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error_msg = "" wsgi.errors has no  ' %s '  attr "" % method <TAB> <TAB> if not error_msg and not callable ( getattr ( wsgi_errors , method ) ) : <TAB> <TAB> <TAB> error_msg = "" wsgi.errors. %s  attr is not callable "" % method <TAB> <TAB> if error_msg : <TAB> <TAB> <TAB> break <TAB> return_msg = error_msg or "" success "" <TAB> writer ( return_msg ) <TAB> return [ ] ","if not hasattr ( wsgi_errors , method ) : 
","if not error_msg :
",28.0,8.39,False
"def job_rule_modules ( app ) : <TAB> rules_module_list = [ ] <TAB> for rules_module_name in __job_rule_module_names ( app ) : <TAB> <TAB> rules_module = sys . modules . get ( rules_module_name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # if using a non-default module, it's not imported until a JobRunnerMapper is instantiated when the first <TAB> <TAB> <TAB> # JobWrapper is created <TAB> <TAB> <TAB> rules_module = importlib . import_module ( rules_module_name ) <TAB> <TAB> rules_module_list . append ( rules_module ) <TAB> return rules_module_list ","if not rules_module : 
","if rules_module is None :
",29.25,27.78,False
"def discover_hdfstore ( f ) : <TAB> d = dict ( ) <TAB> for key in f . keys ( ) : <TAB> <TAB> d2 = d <TAB> <TAB> key2 = key . lstrip ( "" / "" ) <TAB> <TAB> while "" / "" in key2 : <TAB> <TAB> <TAB> group , key2 = key2 . split ( "" / "" , 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> d2 [ group ] = dict ( ) <TAB> <TAB> <TAB> d2 = d2 [ group ] <TAB> <TAB> d2 [ key2 ] = f . get_storer ( key ) <TAB> return discover ( d ) ","if group not in d2 : 
","if group not in d2 :
",100.0,100.0,True
"def test_update_zone ( self ) : <TAB> zone = self . driver . list_zones ( ) [ 0 ] <TAB> updated_zone = self . driver . update_zone ( zone = zone , domain = "" "" , extra = { "" paused "" : True } ) <TAB> self . assertEqual ( zone . id , updated_zone . id ) <TAB> self . assertEqual ( zone . domain , updated_zone . domain ) <TAB> self . assertEqual ( zone . type , updated_zone . type ) <TAB> self . assertEqual ( zone . ttl , updated_zone . ttl ) <TAB> for key in set ( zone . extra ) | set ( updated_zone . extra ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertNotEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( zone . extra [ key ] , updated_zone . extra [ key ] ) ","if key in ( "" paused "" , "" modified_on "" ) : 
","if key in ( "" paused "" , "" zone "" ) :
",88.21,65.26,False
"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dev = devid [ num ] <TAB> <TAB> <TAB> if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =ON "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning On  "" + name ) <TAB> <TAB> <TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =OFF "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning Off  "" + name ) <TAB> <TAB> <TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False ) ","if name . lower ( ) in phrase : 
","if num in devid :
",26.73,6.32,False
"def filter_ports ( self , dpid , in_port , nw_id , allow_nw_id_external = None ) : <TAB> assert nw_id != self . nw_id_unknown <TAB> ret = [ ] <TAB> for port in self . get_ports ( dpid ) : <TAB> <TAB> nw_id_ = port . network_id <TAB> <TAB> if port . port_no == in_port : <TAB> <TAB> <TAB> continue <TAB> <TAB> if nw_id_ == nw_id : <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( port . port_no ) <TAB> return ret ","elif allow_nw_id_external is not None and nw_id_ == allow_nw_id_external : 
","if allow_nw_id_external and port . external_nw_id == allow_nw_id_external :
",30.63,63.3,False
"def tail ( filename ) : <TAB> if os . path . isfile ( filename ) : <TAB> <TAB> file = open ( filename , "" r "" ) <TAB> <TAB> st_results = os . stat ( filename ) <TAB> <TAB> st_size = st_results [ 6 ] <TAB> <TAB> file . seek ( st_size ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> where = file . tell ( ) <TAB> <TAB> <TAB> line = file . readline ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> <TAB> <TAB> file . seek ( where ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> <TAB> line , <TAB> <TAB> <TAB> <TAB> )<TAB> # already has newline <TAB> else : <TAB> <TAB> print_error ( "" File not found, cannot tail. "" ) ","if not line : 
","if not line :
",100.0,100.0,True
"def proc_day_of_week ( d ) : <TAB> if expanded [ 4 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_day_of_week = nearest_diff_method ( d . isoweekday ( ) % 7 , expanded [ 4 ] , 7 ) <TAB> <TAB> if diff_day_of_week is not None and diff_day_of_week != 0 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( days = diff_day_of_week , hour = 23 , minute = 59 , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( days = diff_day_of_week , hour = 0 , minute = 0 , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d ","if is_prev : 
","if expanded [ 4 ] [ 0 ] == "" * "" :
",29.06,3.38,False
"def __call__ ( self ) : <TAB> """"""Run all check_* methods."""""" <TAB> if self . on : <TAB> <TAB> oldformatwarning = warnings . formatwarning <TAB> <TAB> warnings . formatwarning = self . formatwarning <TAB> <TAB> try : <TAB> <TAB> <TAB> for name in dir ( self ) : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" check_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr ( self , name ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> warnings . formatwarning = oldformatwarning ","if method and callable ( method ) : 
","if callable ( method ) :
",62.17,56.98,False
"def get ( self , request , * args , * * kwargs ) : <TAB> if self . revision : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return send_file ( <TAB> <TAB> <TAB> <TAB> <TAB> request , <TAB> <TAB> <TAB> <TAB> <TAB> self . revision . file . path , <TAB> <TAB> <TAB> <TAB> <TAB> self . revision . created , <TAB> <TAB> <TAB> <TAB> <TAB> self . attachment . original_filename , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> return HttpResponseRedirect ( self . revision . file . url ) <TAB> raise Http404 ","if settings . USE_LOCAL_PATH : 
","if self . attachment :
",53.65,6.32,False
"def _close ( self ) : <TAB> super ( Recording , self ) . _close ( ) <TAB> if self . _log_n is not None : <TAB> <TAB> for i in range ( self . n ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _log_n [ i ] . close ( ) <TAB> <TAB> <TAB> <TAB> self . _log_n [ i ] = None ","if self . _log_n [ i ] is not None : 
","if hasattr ( self . _log_n [ i ] , "" close "" ) :
",53.0,47.36,False
"def addTags ( self , rpcObjects = None ) : <TAB> hosts = self . _getOnlyHostObjects ( rpcObjects ) <TAB> if hosts : <TAB> <TAB> title = "" Add Tags "" <TAB> <TAB> body = "" What tags should be added? \n \n Use a comma or space between each "" <TAB> <TAB> ( tags , choice ) = self . getText ( title , body , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tags = str ( tags ) . replace ( "" "" , "" , "" ) . split ( "" , "" ) <TAB> <TAB> <TAB> for host in hosts : <TAB> <TAB> <TAB> <TAB> self . cuebotCall ( <TAB> <TAB> <TAB> <TAB> <TAB> host . addTags , "" Add Tags to  %s  Failed "" % host . data . name , tags <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . _update ( ) ","if choice : 
","if tags :
",56.98,0.0,False
"def available_datasets ( self ) : <TAB> """"""Automatically determine datasets provided by this file"""""" <TAB> res = self . resolution <TAB> coordinates = [ "" pixel_longitude "" , "" pixel_latitude "" ] <TAB> for var_name , val in self . file_content . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ds_info = { <TAB> <TAB> <TAB> <TAB> "" file_type "" : self . filetype_info [ "" file_type "" ] , <TAB> <TAB> <TAB> <TAB> "" resolution "" : res , <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> if not self . is_geo : <TAB> <TAB> <TAB> <TAB> ds_info [ "" coordinates "" ] = coordinates <TAB> <TAB> <TAB> yield DatasetID ( name = var_name , resolution = res ) , ds_info ","if isinstance ( val , netCDF4 . Variable ) : 
","if val and var_name not in coordinates :
",26.5,5.52,False
"def extract_from_file ( fname : PathIsh ) - > Iterator [ Extraction ] : <TAB> path = Path ( fname ) <TAB> fallback_dt = file_mtime ( path ) <TAB> p = Parser ( path ) <TAB> for r in p . walk ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield r <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Visit ( <TAB> <TAB> <TAB> <TAB> url = r . url , <TAB> <TAB> <TAB> <TAB> dt = fallback_dt , <TAB> <TAB> <TAB> <TAB> locator = Loc . file ( fname ) ,<TAB> # TODO line number <TAB> <TAB> <TAB> <TAB> context = r . context , <TAB> <TAB> <TAB> ) ","if isinstance ( r , Exception ) : 
","if r . dt < fallback_dt :
",26.96,6.27,False
"def init_module_config ( module_json , config , config_path = default_config_path ) : <TAB> if "" config "" in module_json [ "" meta "" ] : <TAB> <TAB> if module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> config . add_section ( module_json [ "" name "" ] ) <TAB> <TAB> <TAB> for config_var in module_json [ "" meta "" ] [ "" config "" ] : <TAB> <TAB> <TAB> <TAB> if config_var not in config [ module_json [ "" name "" ] ] : <TAB> <TAB> <TAB> <TAB> <TAB> config . set ( module_json [ "" name "" ] , config_var , "" "" ) <TAB> return config ","if module_json [ "" name "" ] not in config : 
","if module_json [ "" name "" ] not in config :
",100.0,100.0,True
"def _create_entities ( parsed_entities , sidx , eidx ) : <TAB> entities = [ ] <TAB> for k , vs in parsed_entities . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vs = [ vs ] <TAB> <TAB> for value in vs : <TAB> <TAB> <TAB> entities . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" entity "" : k , <TAB> <TAB> <TAB> <TAB> <TAB> "" start "" : sidx , <TAB> <TAB> <TAB> <TAB> <TAB> "" end "" : eidx ,<TAB> # can't be more specific <TAB> <TAB> <TAB> <TAB> <TAB> "" value "" : value , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> return entities ","if not isinstance ( vs , list ) : 
","if not isinstance ( vs , list ) :
",100.0,100.0,True
"def _telegram_upload_stream ( self , stream , * * kwargs ) : <TAB> """"""Perform upload defined in a stream."""""" <TAB> msg = None <TAB> try : <TAB> <TAB> stream . accept ( ) <TAB> <TAB> msg = self . _telegram_special_message ( <TAB> <TAB> <TAB> chat_id = stream . identifier . id , <TAB> <TAB> <TAB> content = stream . raw , <TAB> <TAB> <TAB> msg_type = stream . stream_type , <TAB> <TAB> <TAB> * * kwargs , <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> log . exception ( f "" Upload of  { stream . name }  to  { stream . identifier }  failed. "" ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stream . error ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stream . success ( ) ","if msg is None : 
","if msg is None :
",100.0,100.0,True
"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB> <TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [ ] <TAB> nbr = 0 <TAB> while True : <TAB> <TAB> line = self . readline ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> out . append ( line ) <TAB> <TAB> if size > - 1 : <TAB> <TAB> <TAB> nbr + = len ( line ) <TAB> <TAB> <TAB> if nbr > size : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out ","if not line : 
","if not line :
",100.0,100.0,True
"def clean_permissions ( <TAB> cls , <TAB> requestor : "" User "" , <TAB> group : auth_models . Group , <TAB> errors : Dict [ Optional [ str ] , List [ ValidationError ] ] , <TAB> cleaned_input : dict , ) : <TAB> field = "" add_permissions "" <TAB> permission_items = cleaned_input . get ( field ) <TAB> if permission_items : <TAB> <TAB> cleaned_input [ field ] = get_permissions ( permission_items ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . ensure_can_manage_permissions ( <TAB> <TAB> <TAB> <TAB> requestor , errors , field , permission_items <TAB> <TAB> <TAB> ) ","if not requestor . is_superuser : 
","if group . has_permission ( field ) :
",33.51,5.93,False
"def _bwd ( subj = None , obj = None , seen = None ) : <TAB> seen . add ( obj ) <TAB> for s , o in evalPath ( graph , ( None , self . path , obj ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield s , o <TAB> <TAB> if self . more : <TAB> <TAB> <TAB> if s in seen : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for s2 , o2 in _bwd ( None , s , seen ) : <TAB> <TAB> <TAB> <TAB> yield s2 , o ","if not subj or subj == s : 
","if subj is None or o in seen :
",31.88,6.74,False
"def generate_data ( self , request ) : <TAB> """"""Generate data for the widget."""""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB> <TAB> for hosts , stats in cache_stats : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB> <TAB> <TAB> elif stats [ "" uptime "" ] > 3600 : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime } ","if stats [ "" uptime "" ] > 86400 : 
","if stats [ "" uptime "" ] > 3600 :
",89.28,78.25,False
def refresh ( self ) : <TAB> if self . _handle : <TAB> <TAB> source = self . _db . get_repository_from_handle ( self . _handle ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _title = str ( source . get_type ( ) ) <TAB> <TAB> <TAB> self . _value = source . get_name ( ) ,"if source : 
","if source :
",78.12,0.0,False
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> elif "" . "" in svalue : <TAB> <TAB> <TAB> <TAB> return getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return getint ( svalue ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> return value ","if not svalue : 
","if svalue == "" None "" :
",28.57,7.27,False
"def parseGrants ( self , tree ) : <TAB> for grant in tree . findall ( "" .//Grant "" ) : <TAB> <TAB> grantee = Grantee ( ) <TAB> <TAB> g = grant . find ( "" .//Grantee "" ) <TAB> <TAB> grantee . xsi_type = g . attrib [ "" { http://www.w3.org/2001/XMLSchema-instance}type "" ] <TAB> <TAB> grantee . permission = grant . find ( "" Permission "" ) . text <TAB> <TAB> for el in g : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> grantee . display_name = el . text <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> grantee . tag = el . tag <TAB> <TAB> <TAB> <TAB> grantee . name = el . text <TAB> <TAB> self . grantees . append ( grantee ) ","if el . tag == "" DisplayName "" : 
","if el . tag == "" display_name "" :
",83.19,57.07,False
"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB> <TAB> if order == 0 : <TAB> <TAB> <TAB> name = "" std_dev "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = "" sample_std_dev "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order ","elif order == 1 : 
","elif order == 1 :
",100.0,100.0,True
"def _shouldRollover ( self ) : <TAB> if self . maxBytes > 0 :<TAB> # are we rolling over? <TAB> <TAB> try : <TAB> <TAB> <TAB> self . stream . seek ( 0 , 2 )<TAB> # due to non-posix-compliant Windows feature <TAB> <TAB> except IOError : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _degrade ( False , "" Rotation done or not needed at this time "" ) <TAB> return False ","if self . stream . tell ( ) > = self . maxBytes : 
","if self . _degrade ( False , "" Rotation done "" ) :
",34.92,12.57,False
"def userfullname ( ) : <TAB> """"""Get the user's full name."""""" <TAB> global _userfullname <TAB> if not _userfullname : <TAB> <TAB> uid = os . getuid ( ) <TAB> <TAB> entry = pwd_from_uid ( uid ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _userfullname = entry [ 4 ] . split ( "" , "" ) [ 0 ] or entry [ 0 ] <TAB> <TAB> if not _userfullname : <TAB> <TAB> <TAB> _userfullname = "" user %d "" % uid <TAB> return _userfullname ","if entry : 
","if entry :
",78.12,0.0,False
"def drop ( self ) : <TAB> # mssql <TAB> sql = "" if object_id( ' %s ' ) is not null drop table  %s "" % ( self . tname , self . tname ) <TAB> try : <TAB> <TAB> self . execute ( sql ) <TAB> except Exception as e : <TAB> <TAB> self . conn . rollback ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> # sqlite <TAB> <TAB> sql = "" drop table if exists  %s "" % self . tname <TAB> <TAB> self . execute ( sql ) ","if "" syntax error "" not in str ( e ) : 
","if e . args [ 0 ] != errno . EEXIST :
",26.14,4.07,False
"def _find_delimiter ( f , block_size = 2 * * 16 ) : <TAB> delimiter = b "" \n "" <TAB> if f . tell ( ) == 0 : <TAB> <TAB> return 0 <TAB> while True : <TAB> <TAB> b = f . read ( block_size ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return f . tell ( ) <TAB> <TAB> elif delimiter in b : <TAB> <TAB> <TAB> return f . tell ( ) - len ( b ) + b . index ( delimiter ) + 1 ","if not b : 
","if not b :
",100.0,100.0,True
"def _convert ( container ) : <TAB> if _value_marker in container : <TAB> <TAB> force_list = False <TAB> <TAB> values = container . pop ( _value_marker ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB> <TAB> if not force_list and len ( values ) == 1 : <TAB> <TAB> <TAB> values = values [ 0 ] <TAB> <TAB> if not container : <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert ( container ) <TAB> elif container . pop ( _list_marker , False ) : <TAB> <TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) ) ","if container . pop ( _list_marker , False ) : 
","if container . pop ( _list_marker , True ) :
",64.41,79.11,False
"def fitting ( self , value ) : <TAB> self . _fitting = value <TAB> if self . _fitting is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . makedirs ( dirname ( self . checkpoint_path ( ) ) ) <TAB> <TAB> <TAB> except FileExistsError as ex : <TAB> <TAB> <TAB> <TAB> pass<TAB> # race to create <TAB> <TAB> if not os . path . exists ( dirname ( self . tensorboard_path ( ) ) ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> os . makedirs ( dirname ( self . tensorboard_path ( ) ) ) <TAB> <TAB> <TAB> except FileExistsError as ex : <TAB> <TAB> <TAB> <TAB> pass<TAB> # race to create ","if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) : 
","if not os . path . exists ( dirname ( self . checkpoint_path ( ) ) ) :
",100.0,100.0,True
"def _make_headers ( self ) : <TAB> libraries = self . _df . columns . to_list ( ) <TAB> columns = [ ] <TAB> for library in libraries : <TAB> <TAB> version = self . _package_versions [ library ] <TAB> <TAB> library_description = self . _libraries_description . get ( library ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> library + = "" {} "" . format ( library_description ) <TAB> <TAB> columns . append ( <TAB> <TAB> <TAB> "" {library} <br><small> {version} </small> "" . format ( <TAB> <TAB> <TAB> <TAB> library = library , version = version <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> return [ "" "" ] + columns ","if library_description : 
","if library_description :
",78.12,100.0,True
"def plugin_on_song_ended ( self , song , stopped ) : <TAB> if song is not None : <TAB> <TAB> poll = self . rating_box . poll_vote ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ups = int ( song . get ( "" ~#wins "" ) or 0 ) <TAB> <TAB> <TAB> downs = int ( song . get ( "" ~#losses "" ) or 0 ) <TAB> <TAB> <TAB> ups + = poll [ 0 ] <TAB> <TAB> <TAB> downs + = poll [ 1 ] <TAB> <TAB> <TAB> song [ "" ~#wins "" ] = ups <TAB> <TAB> <TAB> song [ "" ~#losses "" ] = downs <TAB> <TAB> <TAB> song [ "" ~#rating "" ] = ups / max ( ( ups + downs ) , 2 ) <TAB> <TAB> <TAB> # note: ^^^ Look into implementing w/ confidence intervals! <TAB> <TAB> <TAB> song [ "" ~#score "" ] = ups - downs ","if poll [ 0 ] > = 1 or poll [ 1 ] > = 1 : 
","if poll :
",25.82,0.0,False
"def submit ( self , pig_script , params ) : <TAB> workflow = None <TAB> try : <TAB> <TAB> workflow = self . _create_workflow ( pig_script , params ) <TAB> <TAB> mapping = dict ( <TAB> <TAB> <TAB> [ ( param [ "" name "" ] , param [ "" value "" ] ) for param in workflow . get_parameters ( ) ] <TAB> <TAB> ) <TAB> <TAB> oozie_wf = _submit_workflow ( self . user , self . fs , self . jt , workflow , mapping ) <TAB> finally : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> workflow . delete ( skip_trash = True ) <TAB> return oozie_wf ","if workflow : 
","if workflow :
",78.12,0.0,False
"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB> <TAB> try : <TAB> <TAB> <TAB> schema . parse ( example . schema_string ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> if not example . valid : <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB> <TAB> correct , <TAB> <TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg ) ","if example . valid : 
","if example . valid :
",100.0,100.0,True
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> if child . tag in ( "" wf "" , "" punc "" ) : <TAB> <TAB> <TAB> itm = self . handle_word ( child ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sent . extend ( itm ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sent . append ( itm ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent ) ","if self . _unit == "" word "" : 
","if isinstance ( itm , list ) :
",26.58,4.51,False
"def _set_property ( self , target_widget , pname , value ) : <TAB> if pname == "" text "" : <TAB> <TAB> state = target_widget . cget ( "" state "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> target_widget . configure ( state = tk . NORMAL ) <TAB> <TAB> <TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB> <TAB> <TAB> target_widget . configure ( state = tk . DISABLED ) <TAB> <TAB> else : <TAB> <TAB> <TAB> target_widget . insert ( "" 0.0 "" , value ) <TAB> else : <TAB> <TAB> super ( TKText , self ) . _set_property ( target_widget , pname , value ) ","if state == tk . DISABLED : 
","if state == tk . NORMAL :
",82.41,70.71,False
"def get_vrf_tables ( self , vrf_rf = None ) : <TAB> vrf_tables = { } <TAB> for ( scope_id , table_id ) , table in self . _tables . items ( ) : <TAB> <TAB> if scope_id is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> vrf_tables [ ( scope_id , table_id ) ] = table <TAB> return vrf_tables ","if vrf_rf is not None and table_id != vrf_rf : 
","if vrf_rf and table . name != vrf_rf :
",31.72,46.26,False
"def new_f ( self , * args , * * kwargs ) : <TAB> for obj in f ( self , * args , * * kwargs ) : <TAB> <TAB> if self . protected == False : <TAB> <TAB> <TAB> if "" user "" in obj and obj [ "" user "" ] [ "" protected "" ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield obj ","elif "" protected "" in obj and obj [ "" protected "" ] : 
","if "" user_secret "" in obj and obj [ "" user_secret "" ] [ "" protected "" ] :
",70.86,43.43,False
"def draw ( self , context ) : <TAB> col = self . layout . column ( ) <TAB> col . operator ( "" node.sv_show_latest_commits "" ) <TAB> if context . scene . sv_new_version : <TAB> <TAB> col_alert = self . layout . column ( ) <TAB> <TAB> col_alert . alert = True <TAB> <TAB> col_alert . operator ( "" node.sverchok_update_addon "" , text = "" Upgrade Sverchok addon "" ) <TAB> else : <TAB> <TAB> col . operator ( "" node.sverchok_check_for_upgrades_wsha "" , text = "" Check for updates "" ) <TAB> with sv_preferences ( ) as prefs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> col . operator ( "" node.sv_run_pydoc "" ) ","if prefs . developer_mode : 
","if prefs . get ( "" run_pydoc "" , False ) :
",42.93,12.01,False
"def generate_tag_1_data ( ids ) : <TAB> if len ( ids ) != SAMPLE_NUM : <TAB> <TAB> raise ValueError ( "" len ids should equal to sample number "" ) <TAB> counter = 0 <TAB> for sample_i in range ( SAMPLE_NUM ) : <TAB> <TAB> one_data = [ ids [ sample_i ] ] <TAB> <TAB> valid_set = [ x for x in range ( TAG_INTERVAL [ 0 ] , TAG_INTERVAL [ 1 ] ) ] <TAB> <TAB> features = np . random . choice ( valid_set , FEATURE_NUM , replace = False ) <TAB> <TAB> one_data + = [ "" : "" . join ( [ x , "" 1.0 "" ] ) for x in features ] <TAB> <TAB> counter + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" generate data  {} "" . format ( counter ) ) <TAB> <TAB> yield one_data ","if counter % 10000 == 0 : 
","if counter % 10000 == 0 :
",100.0,100.0,True
"def handle_api_languages ( self , http_context ) : <TAB> mgr = PluginManager . get ( aj . context ) <TAB> languages = set ( ) <TAB> for id in mgr : <TAB> <TAB> locale_dir = mgr . get_content_path ( id , "" locale "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for lang in os . listdir ( locale_dir ) : <TAB> <TAB> <TAB> <TAB> if lang != "" app.pot "" : <TAB> <TAB> <TAB> <TAB> <TAB> languages . add ( lang ) <TAB> return sorted ( list ( languages ) ) ","if os . path . isdir ( locale_dir ) : 
","if os . path . isdir ( locale_dir ) :
",100.0,100.0,True
"def update ( self , t ) : <TAB> # direction right - up <TAB> for i in range ( self . grid . x ) : <TAB> <TAB> for j in range ( self . grid . y ) : <TAB> <TAB> <TAB> distance = self . test_func ( i , j , t ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . turn_off_tile ( i , j ) <TAB> <TAB> <TAB> elif distance < 1 : <TAB> <TAB> <TAB> <TAB> self . transform_tile ( i , j , distance ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . turn_on_tile ( i , j ) ","if distance == 0 : 
","if distance > 0 :
",58.14,24.74,False
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : <TAB> <TAB> <TAB> if isinstance ( text , CodeViewText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( ) ","elif isinstance ( text , ShellText ) : 
","elif isinstance ( text , ShellText ) :
",100.0,100.0,True
"def test_create_repository ( repo_name , expected_status , client ) : <TAB> with client_with_identity ( "" devtable "" , client ) as cl : <TAB> <TAB> body = { <TAB> <TAB> <TAB> "" namespace "" : "" devtable "" , <TAB> <TAB> <TAB> "" repository "" : repo_name , <TAB> <TAB> <TAB> "" visibility "" : "" public "" , <TAB> <TAB> <TAB> "" description "" : "" foo "" , <TAB> <TAB> } <TAB> <TAB> result = conduct_api_call ( <TAB> <TAB> <TAB> client , RepositoryList , "" post "" , None , body , expected_code = expected_status <TAB> <TAB> ) . json <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert result [ "" name "" ] == repo_name <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> model . repository . get_repository ( "" devtable "" , repo_name ) . name == repo_name <TAB> <TAB> <TAB> ) ","if expected_status == 201 : 
","if result :
",28.55,0.0,False
"def _apply_filter ( filter_item , filter_list ) : <TAB> for filter_method in filter_list : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> raise MessageException ( <TAB> <TAB> <TAB> <TAB> "" Toolbox filter exception from  ' {} ' :  {} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> filter_method . __name__ , unicodify ( e ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return True ","if not filter_method ( context , filter_item ) : 
","if filter_method ( filter_item ) :
",32.82,50.05,False
"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = fp . read ( bufsize ) <TAB> <TAB> <TAB> if not data : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = data . encode ( fp . encoding ) <TAB> <TAB> <TAB> m . update ( data ) <TAB> except IOError as msg : <TAB> <TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB> <TAB> return 1 <TAB> out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0 ","if isinstance ( data , str ) : 
","if isinstance ( data , str ) :
",100.0,100.0,True
"def get_block_loc_keys ( block ) : <TAB> """"""Extract loc_keys used by @block"""""" <TAB> symbols = set ( ) <TAB> for instr in block . lines : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( instr . raw , list ) : <TAB> <TAB> <TAB> <TAB> for expr in instr . raw : <TAB> <TAB> <TAB> <TAB> <TAB> symbols . update ( get_expr_locs ( expr ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for arg in instr . args : <TAB> <TAB> <TAB> <TAB> symbols . update ( get_expr_locs ( arg ) ) <TAB> return symbols ","if isinstance ( instr , AsmRaw ) : 
","if isinstance ( instr , ast . Expr ) :
",51.33,45.18,False
"def get_operations ( cls , info , operations : List [ ProductAttributeAssignInput ] ) : <TAB> """"""Resolve all passed global ids into integer PKs of the Attribute type."""""" <TAB> product_attrs_pks = [ ] <TAB> variant_attrs_pks = [ ] <TAB> for operation in operations : <TAB> <TAB> pk = from_global_id_strict_type ( <TAB> <TAB> <TAB> operation . id , only_type = Attribute , field = "" operations "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> product_attrs_pks . append ( pk ) <TAB> <TAB> else : <TAB> <TAB> <TAB> variant_attrs_pks . append ( pk ) <TAB> return product_attrs_pks , variant_attrs_pks ","if operation . type == ProductAttributeType . PRODUCT : 
","if operation . product_id == info . id :
",56.95,17.24,False
"def _collect_manual_intervention_nodes ( pipeline_tree ) : <TAB> for act in pipeline_tree [ "" activities "" ] . values ( ) : <TAB> <TAB> if act [ "" type "" ] == "" SubProcess "" : <TAB> <TAB> <TAB> _collect_manual_intervention_nodes ( act [ "" pipeline "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> manual_intervention_nodes . add ( act [ "" id "" ] ) ","elif act [ "" component "" ] [ "" code "" ] in MANUAL_INTERVENTION_COMP_CODES : 
","elif act [ "" type "" ] == "" Intervention "" :
",48.27,13.75,False
"def prompt_authorization ( self , stacks : List [ Stack ] ) : <TAB> auth_required_per_resource = auth_per_resource ( stacks ) <TAB> for resource , authorization_required in auth_required_per_resource : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> auth_confirm = confirm ( <TAB> <TAB> <TAB> <TAB> f "" \t { self . start_bold } { resource }  may not have authorization defined, Is this okay? { self . end_bold } "" , <TAB> <TAB> <TAB> <TAB> default = False , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if not auth_confirm : <TAB> <TAB> <TAB> <TAB> raise GuidedDeployFailedError ( msg = "" Security Constraints Not Satisfied! "" ) ","if not authorization_required : 
","if authorization_required :
",34.18,57.89,False
"def get_cloud_credential ( self ) : <TAB> """"""Return the credential which is directly tied to the inventory source type."""""" <TAB> credential = None <TAB> for cred in self . credentials . all ( ) : <TAB> <TAB> if self . source in CLOUD_PROVIDERS : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> # these need to be returned in the API credential field <TAB> <TAB> <TAB> if cred . credential_type . kind != "" vault "" : <TAB> <TAB> <TAB> <TAB> credential = cred <TAB> <TAB> <TAB> <TAB> break <TAB> return credential ","if cred . kind == self . source . replace ( "" ec2 "" , "" aws "" ) : 
","if cred . credential_type . kind != "" inventory_source "" :
",40.74,9.96,False
"def validate_party_details ( self ) : <TAB> if self . party : <TAB> <TAB> if not frappe . db . exists ( self . party_type , self . party ) : <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid  {0} :  {1} "" ) . format ( self . party_type , self . party ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . validate_account_type ( <TAB> <TAB> <TAB> <TAB> self . party_account , [ erpnext . get_party_account_type ( self . party_type ) ] <TAB> <TAB> <TAB> ) ","if self . party_account and self . party_type in ( "" Customer "" , "" Supplier "" ) : 
","if self . party_account :
",35.06,8.55,False
"def __iter__ ( self ) : <TAB> it = DiskHashMerger . __iter__ ( self ) <TAB> direct_upstreams = self . direct_upstreams <TAB> for k , groups in it : <TAB> <TAB> t = list ( [ [ ] for _ in range ( self . size ) ] ) <TAB> <TAB> for i , g in enumerate ( groups ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if i in direct_upstreams : <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> g . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> <TAB> <TAB> <TAB> g1 = [ ] <TAB> <TAB> <TAB> <TAB> <TAB> for _ , vs in g : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> g1 . extend ( vs ) <TAB> <TAB> <TAB> <TAB> <TAB> t [ i ] = g1 <TAB> <TAB> yield k , tuple ( t ) ","if g : 
","if g :
",78.12,0.0,False
"def _unpack_scales ( scales , vidxs ) : <TAB> scaleData = [ None , None , None ] <TAB> for i in range ( 3 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> scale = scales [ i ] <TAB> <TAB> if not math . isnan ( scale ) : <TAB> <TAB> <TAB> vidx1 , vidx2 = vidxs [ i * 2 ] , vidxs [ i * 2 + 1 ] <TAB> <TAB> <TAB> scaleData [ i ] = ( int ( vidx1 ) , int ( vidx2 ) , float ( scale ) ) <TAB> return scaleData ","if i > = min ( len ( scales ) , len ( vidxs ) / / 2 ) : 
","if i > = len ( scales ) :
",48.92,18.82,False
"def _make_ext_obj ( self , obj ) : <TAB> ext = self . _get_ext_class ( obj . objname ) ( ) <TAB> for name , val in obj . body : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Error val should be a list, this is a python-opcua bug "" , <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> type ( val ) , <TAB> <TAB> <TAB> <TAB> val , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for attname , v in val : <TAB> <TAB> <TAB> <TAB> self . _set_attr ( ext , attname , v ) <TAB> return ext ","if not isinstance ( val , list ) : 
","if not isinstance ( val , ( list , tuple ) ) :
",53.03,44.08,False
"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB> <TAB> if row [ 0 ] == linenum : <TAB> <TAB> <TAB> if row [ refnum + 1 ] is None : <TAB> <TAB> <TAB> <TAB> row [ refnum + 1 ] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> self . rows . insert ( i , self . newRow ( linenum , refnum , line ) ) ","elif row [ 0 ] > linenum : 
","if row [ refnum + 1 ] != line :
",27.9,8.91,False
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if line == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT . match ( line ) <TAB> <TAB> if match : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line ","if "" , "" in line or "" ; "" in line : 
","if line . endswith ( "" - "" ) :
",33.28,4.65,False
"def encodingChanged ( self , idx ) : <TAB> encoding = str ( self . mode_combo . currentText ( ) ) <TAB> validator = None <TAB> if encoding == "" hex "" : <TAB> <TAB> # only clear the box if there are non-hex chars <TAB> <TAB> # before setting the validator. <TAB> <TAB> txt = str ( self . data_edit . text ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . data_edit . setText ( "" "" ) <TAB> <TAB> regex = QtCore . QRegExp ( "" ^[0-9A-Fa-f]+$ "" ) <TAB> <TAB> validator = QtGui . QRegExpValidator ( regex ) <TAB> self . data_edit . setValidator ( validator ) <TAB> self . renderMemory ( ) ","if not all ( c in string . hexdigits for c in txt ) : 
","if len ( txt ) != len ( self . data_edit . text ( ) ) :
",13.42,5.99,False
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> if self . callback : <TAB> <TAB> <TAB> <TAB> self . callback ( ) ","if redo : 
","if compare_id not in compares_done :
",29.81,4.99,False
"def _transform_bin ( self , X : DataFrame ) : <TAB> if self . _bin_map : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> X = X . copy ( deep = True ) <TAB> <TAB> with pd . option_context ( "" mode.chained_assignment "" , None ) : <TAB> <TAB> <TAB> # Pandas complains about SettingWithCopyWarning, but this should be valid. <TAB> <TAB> <TAB> for column in self . _bin_map : <TAB> <TAB> <TAB> <TAB> X [ column ] = binning . bin_column ( <TAB> <TAB> <TAB> <TAB> <TAB> series = X [ column ] , <TAB> <TAB> <TAB> <TAB> <TAB> mapping = self . _bin_map [ column ] , <TAB> <TAB> <TAB> <TAB> <TAB> dtype = self . _astype_map [ column ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> return X ","if not self . inplace : 
","if not self . deep :
",77.23,53.73,False
"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> if "" > "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text ","if "" ' "" in text : 
","if "" ' "" in text :
",100.0,100.0,True
"def read ( self ) : <TAB> """"""Reads the robots.txt URL and feeds it to the parser."""""" <TAB> try : <TAB> <TAB> f = urllib . request . urlopen ( self . url ) <TAB> except urllib . error . HTTPError as err : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . disallow_all = True <TAB> <TAB> elif err . code > = 400 and err . code < 500 : <TAB> <TAB> <TAB> self . allow_all = True <TAB> else : <TAB> <TAB> raw = f . read ( ) <TAB> <TAB> self . parse ( raw . decode ( "" utf-8 "" ) . splitlines ( ) ) ","if err . code in ( 401 , 403 ) : 
","if err . code == 401 and err . code == 401 :
",41.78,18.21,False
"def post_create ( self , user , billing = None ) : <TAB> from weblate . trans . models import Change <TAB> if billing : <TAB> <TAB> billing . projects . add ( self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . access_control = Project . ACCESS_PRIVATE <TAB> <TAB> else : <TAB> <TAB> <TAB> self . access_control = Project . ACCESS_PUBLIC <TAB> <TAB> self . save ( ) <TAB> if not user . is_superuser : <TAB> <TAB> self . add_user ( user , "" @Administration "" ) <TAB> Change . objects . create ( <TAB> <TAB> action = Change . ACTION_CREATE_PROJECT , project = self , user = user , author = user <TAB> ) ","if billing . plan . change_access_control : 
","if user . is_private :
",33.63,5.24,False
"def visitConst ( self , node ) : <TAB> if self . documentable : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . documentable . append ( make_docstring ( node . value , node . lineno ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . documentable = None ","if type ( node . value ) in ( StringType , UnicodeType ) : 
","if node . value :
",31.81,7.47,False
"def requires ( self ) : <TAB> requires = copy . deepcopy ( self . _requires ) <TAB> # Auto add dependencies when parameters reference the Ouptuts of <TAB> # another stack. <TAB> parameters = self . parameters <TAB> for value in parameters . values ( ) : <TAB> <TAB> if isinstance ( value , basestring ) and "" :: "" in value : <TAB> <TAB> <TAB> stack_name , _ = value . split ( "" :: "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> requires . add ( stack_name ) <TAB> return requires ","if stack_name not in requires : 
","if stack_name not in requires :
",100.0,100.0,True
"def __load_protos ( ) : <TAB> g = globals ( ) <TAB> for k , v in g . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = k [ 4 : ] <TAB> <TAB> <TAB> modname = name . lower ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> mod = __import__ ( modname , g , level = 1 ) <TAB> <TAB> <TAB> <TAB> PPP . set_p ( v , getattr ( mod , name ) ) <TAB> <TAB> <TAB> except ( ImportError , AttributeError ) : <TAB> <TAB> <TAB> <TAB> continue ","if k . startswith ( "" PPP_ "" ) : 
","if k . startswith ( "" _ "" ) :
",83.03,71.09,False
"def init_weights ( self ) : <TAB> """"""Initialize model weights."""""" <TAB> for m in self . predict_layers . modules ( ) : <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> elif isinstance ( m , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> normal_init ( m , std = 0.01 ) ","elif isinstance ( m , nn . Linear ) : 
","elif isinstance ( m , nn . Linear ) :
",100.0,100.0,True
"def get_data ( self ) : <TAB> """"""get all data from sockets"""""" <TAB> si = self . inputs <TAB> parameters = [ ] <TAB> for socket in si : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parameters . append ( socket . sv_get ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parameters . append ( socket . sv_get ( default = [ [ ] ] ) ) <TAB> return match_long_repeat ( parameters ) ","if len ( socket . prop_name ) > 0 : 
","if self . inputs . is_linked :
",30.66,4.83,False
"def test_parse_query_params_comparable_field ( self ) : <TAB> query_params = { "" filter[int_field][gt] "" : 42 , "" filter[int_field][lte] "" : 9000 } <TAB> fields = self . view . parse_query_params ( query_params ) <TAB> for key , field_name in fields . items ( ) : <TAB> <TAB> if field_name [ "" int_field "" ] [ "" op "" ] == "" gt "" : <TAB> <TAB> <TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 42 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert_equal ( field_name [ "" int_field "" ] [ "" value "" ] , 9000 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( ) ","elif field_name [ "" int_field "" ] [ "" op "" ] == "" lte "" : 
","elif field_name [ "" int_field "" ] [ "" op "" ] == "" lte "" :
",100.0,100.0,True
"def _create_examples ( self , lines , set_type ) : <TAB> """"""Creates examples for the training and dev sets."""""" <TAB> examples = [ ] <TAB> for ( i , line ) in enumerate ( lines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> guid = "" %s - %s "" % ( set_type , i ) <TAB> <TAB> text = line [ 0 ] <TAB> <TAB> bbox = line [ 1 ] <TAB> <TAB> label = line [ 2 ] <TAB> <TAB> examples . append ( <TAB> <TAB> <TAB> DocExample ( guid = guid , text_a = text , text_b = None , bbox = bbox , label = label ) <TAB> <TAB> ) <TAB> return examples ","if i == 0 : 
","if i == 0 :
",100.0,100.0,True
"def _get_attr ( sdk_path , mod_attr_path , checked = True ) : <TAB> try : <TAB> <TAB> attr_mod , attr_path = ( <TAB> <TAB> <TAB> mod_attr_path . split ( "" # "" ) if "" # "" in mod_attr_path else ( mod_attr_path , "" "" ) <TAB> <TAB> ) <TAB> <TAB> full_mod_path = "" {} . {} "" . format ( sdk_path , attr_mod ) if attr_mod else sdk_path <TAB> <TAB> op = import_module ( full_mod_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Only load attributes if needed <TAB> <TAB> <TAB> for part in attr_path . split ( "" . "" ) : <TAB> <TAB> <TAB> <TAB> op = getattr ( op , part ) <TAB> <TAB> return op <TAB> except ( ImportError , AttributeError ) as ex : <TAB> <TAB> if checked : <TAB> <TAB> <TAB> return None <TAB> <TAB> raise ex ","if attr_path : 
","if op . __name__ == "" sdk "" :
",29.31,3.74,False
"def _load_ui_modules ( self , modules : Any ) - > None : <TAB> if isinstance ( modules , types . ModuleType ) : <TAB> <TAB> self . _load_ui_modules ( dict ( ( n , getattr ( modules , n ) ) for n in dir ( modules ) ) ) <TAB> elif isinstance ( modules , list ) : <TAB> <TAB> for m in modules : <TAB> <TAB> <TAB> self . _load_ui_modules ( m ) <TAB> else : <TAB> <TAB> assert isinstance ( modules , dict ) <TAB> <TAB> for name , cls in modules . items ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . ui_modules [ name ] = cls <TAB> <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> <TAB> pass ","if issubclass ( cls , UIModule ) : 
","if issubclass ( cls , UIModule ) :
",100.0,100.0,True
"def _remove_obsolete_leafs ( input_dict ) : <TAB> if not isinstance ( input_dict , dict ) : <TAB> <TAB> return <TAB> if input_dict [ LEAF_MARKER ] : <TAB> <TAB> bottom_leafs = input_dict [ LEAF_MARKER ] <TAB> <TAB> for leaf in bottom_leafs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> input_dict [ LEAF_MARKER ] . remove ( leaf ) <TAB> for subtree in input_dict . keys ( ) : <TAB> <TAB> _remove_obsolete_leafs ( input_dict [ subtree ] ) ","if leaf in input_dict : 
","if leaf in input_dict [ LEAF_MARKER ] :
",51.82,43.36,False
"def decode ( self , value , force = False ) : <TAB> "" Return a unicode string from the bytes-like representation "" <TAB> if self . decode_responses or force : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value . tobytes ( ) <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> value = value . decode ( self . encoding , self . encoding_errors ) <TAB> return value ","if isinstance ( value , memoryview ) : 
","if isinstance ( value , bytes ) :
",79.9,59.46,False
"def audit ( self , directive ) : <TAB> value = _get_value ( directive ) <TAB> if not value : <TAB> <TAB> return <TAB> server_side = directive . name . startswith ( "" proxy_ "" ) <TAB> for var in compile_script ( value ) : <TAB> <TAB> char = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> char = "" \\ n "" <TAB> <TAB> elif not server_side and var . can_contain ( "" \r "" ) : <TAB> <TAB> <TAB> char = "" \\ r "" <TAB> <TAB> else : <TAB> <TAB> <TAB> continue <TAB> <TAB> reason = ' At least variable  "" $ {var} ""  can contain  "" {char} "" ' . format ( <TAB> <TAB> <TAB> var = var . name , char = char <TAB> <TAB> ) <TAB> <TAB> self . add_issue ( directive = [ directive ] + var . providers , reason = reason ) ","if var . can_contain ( "" \n "" ) : 
","if not server_side and var . can_contain ( "" \n "" ) :
",82.08,64.7,False
"def checkFilename ( filename ) :<TAB> # useful in case of drag and drop <TAB> while True : <TAB> <TAB> if filename [ 0 ] == "" ' "" : <TAB> <TAB> <TAB> filename = filename [ 1 : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = filename [ : - 1 ] <TAB> <TAB> if os . path . exists ( filename ) : <TAB> <TAB> <TAB> return filename <TAB> <TAB> filename = input ( <TAB> <TAB> <TAB> "" [!] Cannot find  ' %s ' . \n [*] Enter a valid name of the file containing the paths to test ->  "" <TAB> <TAB> <TAB> % filename <TAB> <TAB> ) ","if filename [ len ( filename ) - 1 ] == "" ' "" : 
","if filename [ - 1 ] == "" \\ "" :
",43.23,41.81,False
"def findfiles ( self , dir , base , rec ) : <TAB> try : <TAB> <TAB> names = os . listdir ( dir or os . curdir ) <TAB> except os . error as msg : <TAB> <TAB> print ( msg ) <TAB> <TAB> return [ ] <TAB> list = [ ] <TAB> subdirs = [ ] <TAB> for name in names : <TAB> <TAB> fn = os . path . join ( dir , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subdirs . append ( fn ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if fnmatch . fnmatch ( name , base ) : <TAB> <TAB> <TAB> <TAB> list . append ( fn ) <TAB> if rec : <TAB> <TAB> for subdir in subdirs : <TAB> <TAB> <TAB> list . extend ( self . findfiles ( subdir , base , rec ) ) <TAB> return list ","if os . path . isdir ( fn ) : 
","if os . path . isdir ( fn ) :
",100.0,100.0,True
"def loop ( handler , obj ) : <TAB> handler . response . write ( "" <table> "" ) <TAB> for k , v in obj . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> style = "" color: red "" if not v else "" "" <TAB> <TAB> <TAB> handler . response . write ( <TAB> <TAB> <TAB> <TAB> ' <tr style= "" {} "" ><td> {} :</td><td> {} </td></tr> ' . format ( style , k , v ) <TAB> <TAB> <TAB> ) <TAB> handler . response . write ( "" </table> "" ) ","if not k in ( "" data "" , "" gae_user "" , "" credentials "" , "" content "" , "" config "" ) : 
","if isinstance ( v , ( int , float ) ) :
",25.89,2.35,False
"def anypython ( request ) : <TAB> name = request . param <TAB> executable = getexecutable ( name ) <TAB> if executable is None : <TAB> <TAB> if sys . platform == "" win32 "" : <TAB> <TAB> <TAB> executable = winpymap . get ( name , None ) <TAB> <TAB> <TAB> if executable : <TAB> <TAB> <TAB> <TAB> executable = py . path . local ( executable ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return executable <TAB> <TAB> pytest . skip ( "" no suitable  %s  found "" % ( name , ) ) <TAB> return executable ","if executable . check ( ) : 
","if os . path . exists ( executable ) :
",33.8,11.04,False
"def __init__ ( self , socketpath = None ) : <TAB> if socketpath is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> socketpath = "" /var/run/usbmuxd "" <TAB> <TAB> else : <TAB> <TAB> <TAB> socketpath = "" /var/run/usbmuxd "" <TAB> self . socketpath = socketpath <TAB> self . listener = MuxConnection ( socketpath , BinaryProtocol ) <TAB> try : <TAB> <TAB> self . listener . listen ( ) <TAB> <TAB> self . version = 0 <TAB> <TAB> self . protoclass = BinaryProtocol <TAB> except MuxVersionError : <TAB> <TAB> self . listener = MuxConnection ( socketpath , PlistProtocol ) <TAB> <TAB> self . listener . listen ( ) <TAB> <TAB> self . protoclass = PlistProtocol <TAB> <TAB> self . version = 1 <TAB> self . devices = self . listener . devices ","if sys . platform == "" darwin "" : 
","if sys . platform == "" win32 "" :
",83.19,70.71,False
"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> elif isinstance ( results [ i ] , list ) : <TAB> <TAB> <TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0 ","if isinstance ( results [ i ] , dict ) : 
","if isinstance ( results [ i ] , dict ) :
",100.0,100.0,True
"def getRootId ( self , id ) : <TAB> with self . connect ( ) as cu : <TAB> <TAB> while True : <TAB> <TAB> <TAB> stmt = "" select parent_path_id from hierarchy where path_id = ? "" <TAB> <TAB> <TAB> cu . execute ( stmt , ( id , ) ) <TAB> <TAB> <TAB> parent_id = cu . fetchone ( ) [ 0 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return id <TAB> <TAB> <TAB> id = parent_id ","if parent_id is None or parent_id == id : 
","if parent_id == id :
",46.14,47.24,False
"def add ( self , path ) : <TAB> with self . get_lock ( path ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . entries [ path ] = { } <TAB> <TAB> <TAB> self . entries [ path ] [ "" lock "" ] = self . new_locks [ path ] <TAB> <TAB> <TAB> del self . new_locks [ path ] <TAB> <TAB> <TAB> self . lru . append ( path ) ","if not path in self . entries : 
","if path not in self . entries :
",64.07,58.14,False
"def _get_coordinates_for_dataset_key ( self , dsid ) : <TAB> """"""Get the coordinate dataset keys for *dsid*."""""" <TAB> ds_info = self . ids [ dsid ] <TAB> cids = [ ] <TAB> for cinfo in ds_info . get ( "" coordinates "" , [ ] ) : <TAB> <TAB> if not isinstance ( cinfo , dict ) : <TAB> <TAB> <TAB> cinfo = { "" name "" : cinfo } <TAB> <TAB> cinfo [ "" resolution "" ] = ds_info [ "" resolution "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cinfo [ "" polarization "" ] = ds_info [ "" polarization "" ] <TAB> <TAB> cid = DatasetID ( * * cinfo ) <TAB> <TAB> cids . append ( self . get_dataset_key ( cid ) ) <TAB> return cids ","if "" polarization "" in ds_info : 
","if "" polarization "" in ds_info :
",100.0,100.0,True
"def build_from_gdobj ( cls , gdobj , steal = False ) : <TAB> # Avoid calling cls.__init__ by first instanciating a placeholder, then <TAB> # overloading it __class__ to turn it into an instance of the right class <TAB> ret = BuiltinInitPlaceholder ( ) <TAB> if steal : <TAB> <TAB> assert ffi . typeof ( gdobj ) . kind == "" pointer "" <TAB> <TAB> ret . _gd_ptr = gdobj <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . _gd_ptr = cls . _copy_gdobj ( gdobj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret . _gd_ptr = cls . _copy_gdobj ( ffi . addressof ( gdobj ) ) <TAB> ret . __class__ = cls <TAB> return ret ","if ffi . typeof ( gdobj ) . kind == "" pointer "" : 
","if gdobj . __class__ . __name__ == "" gdobject "" :
",33.85,10.38,False
"def _listen_output ( self ) : <TAB> "" NB! works in background thread "" <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> chars = self . _proc . read ( 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> as_bytes = chars . encode ( self . encoding ) <TAB> <TAB> <TAB> <TAB> self . _make_output_available ( as_bytes ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _error = "" EOF "" <TAB> <TAB> <TAB> <TAB> break <TAB> except Exception as e : <TAB> <TAB> self . _error = str ( e ) ","if len ( chars ) > 0 : 
","if chars :
",26.73,0.0,False
"def result ( <TAB> metrics : Dict [ metric_types . MetricKey , Any ] ) - > Dict [ metric_types . AttributionsKey , Dict [ Text , Union [ float , np . ndarray ] ] ] : <TAB> """"""Returns mean attributions."""""" <TAB> total_attributions = metrics [ total_attributions_key ] <TAB> weighted_count = metrics [ weighted_example_count_key ] <TAB> attributions = { } <TAB> for k , v in total_attributions . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attributions [ k ] = float ( "" nan "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> attributions [ k ] = v / weighted_count <TAB> return { key : attributions } ","if np . isclose ( weighted_count , 0.0 ) : 
","if v is None :
",26.35,3.13,False
"def write_if_changed ( path , data ) : <TAB> if isinstance ( data , str ) : <TAB> <TAB> data = data . encode ( ) <TAB> changed = False <TAB> with open ( os . open ( path , os . O_CREAT | os . O_RDWR ) , "" wb+ "" ) as f : <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> current = f . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> f . seek ( 0 ) <TAB> <TAB> <TAB> f . write ( data ) <TAB> <TAB> <TAB> f . truncate ( ) <TAB> <TAB> os . fsync ( f ) <TAB> return changed ","if current != data : 
","if current != data :
",100.0,100.0,True
"def detect_ssl_option ( self ) : <TAB> for option in self . ssl_options ( ) : <TAB> <TAB> if scan_argv ( self . argv , option ) is not None : <TAB> <TAB> <TAB> for other_option in self . ssl_options ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if scan_argv ( self . argv , other_option ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ConfigurationError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Cannot give both  %s  and  %s "" % ( option , other_option ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return option ","if option != other_option : 
","if option != other_option :
",100.0,100.0,True
"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> if return_type is bytes : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str<TAB> # tempfile APIs return a str by default. <TAB> return return_type ","if arg is None : 
","if arg is None :
",100.0,100.0,True
"def _get_app ( self , body = None ) : <TAB> app = self . _app <TAB> if app is None : <TAB> <TAB> try : <TAB> <TAB> <TAB> tasks = self . tasks . tasks<TAB> # is a group <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> tasks = self . tasks <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> app = tasks [ 0 ] . _app <TAB> <TAB> if app is None and body is not None : <TAB> <TAB> <TAB> app = body . _app <TAB> return app if app is not None else current_app ","if len ( tasks ) : 
","if tasks :
",27.84,0.0,False
"def add_field ( self , field ) : <TAB> self . remove_field ( field . name ) <TAB> self . fields [ field . name ] = field <TAB> self . columns [ field . db_column ] = field <TAB> self . _sorted_field_list . insert ( field ) <TAB> self . _update_field_lists ( ) <TAB> if field . default is not None : <TAB> <TAB> self . defaults [ field ] = field . default <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _default_callables [ field ] = field . default <TAB> <TAB> <TAB> self . _default_callable_list . append ( ( field . name , field . default ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _default_dict [ field ] = field . default <TAB> <TAB> <TAB> self . _default_by_name [ field . name ] = field . default ","if callable ( field . default ) : 
","if isinstance ( field . default , callable ) :
",49.44,33.57,False
"def _get_families ( self ) : <TAB> families = [ ] <TAB> for name , ext in self . _get_family_dirs ( ) : <TAB> <TAB> if ext is None :<TAB> # is a directory <TAB> <TAB> <TAB> family = self . get_resource ( <TAB> <TAB> <TAB> <TAB> FileSystemPackageFamilyResource . key , location = self . location , name = name <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> family = self . get_resource ( <TAB> <TAB> <TAB> <TAB> FileSystemCombinedPackageFamilyResource . key , <TAB> <TAB> <TAB> <TAB> location = self . location , <TAB> <TAB> <TAB> <TAB> name = name , <TAB> <TAB> <TAB> <TAB> ext = ext , <TAB> <TAB> <TAB> ) <TAB> <TAB> families . append ( family ) <TAB> return families ","if ext is None : 
","if ext is None :
",100.0,100.0,True
"def test ( model , data_loader , device = None ) : <TAB> device = device or torch . device ( "" cpu "" ) <TAB> model . eval ( ) <TAB> correct = 0 <TAB> total = 0 <TAB> with torch . no_grad ( ) : <TAB> <TAB> for batch_idx , ( data , target ) in enumerate ( data_loader ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> data , target = data . to ( device ) , target . to ( device ) <TAB> <TAB> <TAB> outputs = model ( data ) <TAB> <TAB> <TAB> _ , predicted = torch . max ( outputs . data , 1 ) <TAB> <TAB> <TAB> total + = target . size ( 0 ) <TAB> <TAB> <TAB> correct + = ( predicted == target ) . sum ( ) . item ( ) <TAB> return correct / total ","if batch_idx * len ( data ) > TEST_SIZE : 
","if batch_idx * len ( data ) > = 100 :
",74.69,69.81,False
"def __animate_progress ( self ) : <TAB> """"""Change the status message, mostly used to animate progress."""""" <TAB> while True : <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> with self . __progress_lock : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> <TAB> elif self . __show_animation : <TAB> <TAB> <TAB> <TAB> self . __progress_status . update_progress ( self . __current_operation_name ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_UPDATE_DELAY <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . __progress_status . show_as_ready ( ) <TAB> <TAB> <TAB> <TAB> sleep_time = ThreadPool . PROGRESS_IDLE_DELAY <TAB> <TAB> # Allow some time for progress status to be updated. <TAB> <TAB> time . sleep ( sleep_time ) ","if not self . __progress_status : 
","if self . __progress_status . is_ready ( ) :
",40.0,42.61,False
"def _parse_subtitles ( self , video_data , url_key ) : <TAB> subtitles = { } <TAB> for translation in video_data . get ( "" translations "" , [ ] ) : <TAB> <TAB> vtt_path = translation . get ( url_key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> lang = translation . get ( "" language_w3c "" ) or ISO639Utils . long2short ( <TAB> <TAB> <TAB> translation [ "" language_medium "" ] <TAB> <TAB> ) <TAB> <TAB> subtitles . setdefault ( lang , [ ] ) . append ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" ext "" : "" vtt "" , <TAB> <TAB> <TAB> <TAB> "" url "" : vtt_path , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return subtitles ","if not vtt_path : 
","if not vtt_path :
",100.0,100.0,True
"def postprocess_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" and msg [ "" value "" ] is not None : <TAB> <TAB> fn , value = msg [ "" fn "" ] , msg [ "" value "" ] <TAB> <TAB> value_batch_ndims = jnp . ndim ( value ) - fn . event_dim <TAB> <TAB> fn_batch_ndim = len ( fn . batch_shape ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> prepend_shapes = ( 1 , ) * ( value_batch_ndims - fn_batch_ndim ) <TAB> <TAB> <TAB> msg [ "" fn "" ] = tree_map ( <TAB> <TAB> <TAB> <TAB> lambda x : jnp . reshape ( x , prepend_shapes + jnp . shape ( x ) ) , fn <TAB> <TAB> <TAB> ) ","if fn_batch_ndim < value_batch_ndims : 
","if fn_batch_ndim < value_batch_ndims :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_filename ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def createError ( self , line , pos , description ) : <TAB> global ENABLE_PYIMPORT <TAB> msg = "" Line  "" + unicode ( line ) + "" :  "" + unicode ( description ) <TAB> if ENABLE_JS2PY_ERRORS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> import js2py . base <TAB> <TAB> <TAB> return js2py . base . MakeError ( "" SyntaxError "" , msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ENABLE_JS2PY_ERRORS ( msg ) <TAB> else : <TAB> <TAB> return JsSyntaxError ( msg ) ","if isinstance ( ENABLE_JS2PY_ERRORS , bool ) : 
","if self . source_code == "" py "" :
",26.69,4.46,False
"def extract ( self , page , start_index = 0 , end_index = None ) : <TAB> items = [ ] <TAB> for extractor in self . extractors : <TAB> <TAB> extracted = extractor . extract ( <TAB> <TAB> <TAB> page , start_index , end_index , self . template . ignored_regions <TAB> <TAB> ) <TAB> <TAB> for item in arg_to_iter ( extracted ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if isinstance ( item , ( ItemProcessor , dict ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> item [ u "" _template "" ] = self . template . id <TAB> <TAB> <TAB> <TAB> items . append ( item ) <TAB> return items ","if item : 
","if item is not None :
",34.04,17.97,False
"def create_volume ( self , volume ) : <TAB> """"""Create a volume."""""" <TAB> try : <TAB> <TAB> cmd = [ "" volume "" , "" create "" , volume [ "" name "" ] , "" %s G "" % ( volume [ "" size "" ] ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cmd . append ( "" pool "" ) <TAB> <TAB> <TAB> cmd . append ( self . configuration . eqlx_pool ) <TAB> <TAB> if self . configuration . san_thin_provision : <TAB> <TAB> <TAB> cmd . append ( "" thin-provision "" ) <TAB> <TAB> out = self . _eql_execute ( * cmd ) <TAB> <TAB> self . add_multihost_access ( volume ) <TAB> <TAB> return self . _get_volume_data ( out ) <TAB> except Exception : <TAB> <TAB> with excutils . save_and_reraise_exception ( ) : <TAB> <TAB> <TAB> LOG . error ( ' Failed to create volume  "" %s "" . ' , volume [ "" name "" ] ) ","if self . configuration . eqlx_pool != "" default "" : 
","if self . configuration . eqlx_pool :
",57.64,51.01,False
"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self . code : <TAB> <TAB> self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB> if not self . site : <TAB> <TAB> placeholders = StaticPlaceholder . objects . filter ( <TAB> <TAB> <TAB> code = self . code , site__isnull = True <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> placeholders = placeholders . exclude ( pk = self . pk ) <TAB> <TAB> if placeholders . exists ( ) : <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> _ ( "" A static placeholder with the same site and code already exists "" ) <TAB> <TAB> <TAB> ) ","if self . pk : 
","if self . pk :
",100.0,100.0,True
"def spawnMenu ( self , event ) : <TAB> clickedPos = self . getRowByAbs ( event . Position ) <TAB> self . ensureSelection ( clickedPos ) <TAB> selection = self . getSelectedBoosters ( ) <TAB> mainBooster = None <TAB> if clickedPos != - 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> booster = self . boosters [ clickedPos ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> mainBooster = booster <TAB> itemContext = None if mainBooster is None else _t ( "" Booster "" ) <TAB> menu = ContextMenu . getMenu ( <TAB> <TAB> self , <TAB> <TAB> mainBooster , <TAB> <TAB> selection , <TAB> <TAB> ( "" boosterItem "" , itemContext ) , <TAB> <TAB> ( "" boosterItemMisc "" , itemContext ) , <TAB> ) <TAB> if menu : <TAB> <TAB> self . PopupMenu ( menu ) ","if booster in self . original : 
","if booster :
",28.73,0.0,False
"def init_errorhandler ( ) : <TAB> # http error handling <TAB> for ex in default_exceptions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> app . register_error_handler ( ex , error_http ) <TAB> <TAB> elif ex == 500 : <TAB> <TAB> <TAB> app . register_error_handler ( ex , internal_error ) <TAB> if services . ldap : <TAB> <TAB> # Only way of catching the LDAPException upon logging in with LDAP server down <TAB> <TAB> @app . errorhandler ( services . ldap . LDAPException ) <TAB> <TAB> def handle_exception ( e ) : <TAB> <TAB> <TAB> log . debug ( "" LDAP server not accessible while trying to login to opds feed "" ) <TAB> <TAB> <TAB> return error_http ( FailedDependency ( ) ) ","if ex < 500 : 
","if ex == 400 :
",56.5,17.97,False
"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif "" M "" in fmt : <TAB> <TAB> <TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif "" i "" in fmt : <TAB> <TAB> <TAB> t = int <TAB> <TAB> elif "" f "" in fmt : <TAB> <TAB> <TAB> t = float <TAB> <TAB> else : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self . addColumn ( ColumnItem ( name , i , type = t ) ) ","if shape : 
","if "" F "" in fmt :
",29.58,7.81,False
"def Proc2 ( IntParIO ) : <TAB> IntLoc = IntParIO + 10 <TAB> while True : <TAB> <TAB> if Char1Glob == "" A "" : <TAB> <TAB> <TAB> IntLoc = IntLoc - 1 <TAB> <TAB> <TAB> IntParIO = IntLoc - IntGlob <TAB> <TAB> <TAB> EnumLoc = Ident1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return IntParIO ","if EnumLoc == Ident1 : 
","if EnumLoc == Ident1 :
",100.0,100.0,True
"def opengroup ( self , name = None ) : <TAB> gid = self . groups <TAB> self . groupwidths . append ( None ) <TAB> if self . groups > MAXGROUPS : <TAB> <TAB> raise error ( "" too many groups "" ) <TAB> if name is not None : <TAB> <TAB> ogid = self . groupdict . get ( name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise error ( <TAB> <TAB> <TAB> <TAB> "" redefinition of group name  %r  as group  %d ;  "" <TAB> <TAB> <TAB> <TAB> "" was group  %d "" % ( name , gid , ogid ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . groupdict [ name ] = gid <TAB> return gid ","if ogid is not None : 
","if ogid is not None :
",100.0,100.0,True
"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB> <TAB> if name in self : <TAB> <TAB> <TAB> old_val = self [ name ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Computed attributed  ' {} '  already exists  "" <TAB> <TAB> <TAB> <TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self [ name ] = val <TAB> else : <TAB> <TAB> super ( ) . __setattr__ ( name , val ) ","if old_val == val : 
","if old_val == val :
",100.0,100.0,True
"def get_all_function_symbols ( self , module = "" kernel "" ) : <TAB> """"""Gets all the function tuples for the given module"""""" <TAB> ret = [ ] <TAB> symtable = self . type_map <TAB> if module in symtable : <TAB> <TAB> mod = symtable [ module ] <TAB> <TAB> for ( addr , ( name , _sym_types ) ) in mod . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> addr = addr + self . shift_address <TAB> <TAB> <TAB> ret . append ( [ name , addr ] ) <TAB> else : <TAB> <TAB> debug . info ( "" All symbols requested for non-existent module  %s "" % module ) <TAB> return ret ","if self . shift_address and addr : 
","if self . shift_address in symtable :
",52.52,61.05,False
"def __call__ ( self , frame : FrameType , event : str , arg : Any ) - > "" CallTracer "" : <TAB> code = frame . f_code <TAB> if ( <TAB> <TAB> event not in SUPPORTED_EVENTS <TAB> <TAB> or code . co_name == "" trace_types "" <TAB> <TAB> or self . should_trace <TAB> <TAB> and not self . should_trace ( code ) <TAB> ) : <TAB> <TAB> return self <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . handle_call ( frame ) <TAB> <TAB> elif event == EVENT_RETURN : <TAB> <TAB> <TAB> self . handle_return ( frame , arg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . error ( "" Cannot handle event  %s "" , event ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Failed collecting trace "" ) <TAB> return self ","if event == EVENT_CALL : 
","if event == EVENT_CALL :
",100.0,100.0,True
"def test_update_topic ( self ) : <TAB> async with self . chat_client : <TAB> <TAB> await self . _create_thread ( ) <TAB> <TAB> topic = "" update topic "" <TAB> <TAB> async with self . chat_thread_client : <TAB> <TAB> <TAB> await self . chat_thread_client . update_topic ( topic = topic ) <TAB> <TAB> # delete chat threads <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . chat_client . delete_chat_thread ( self . thread_id ) ","if not self . is_playback ( ) : 
","if self . is_playback ( ) :
",72.37,79.56,False
"def render_observation ( self ) : <TAB> x = self . read_head_position <TAB> label = "" Observation Grid<TAB> : "" <TAB> x_str = "" "" <TAB> for j in range ( - 1 , self . rows + 1 ) : <TAB> <TAB> if j != - 1 : <TAB> <TAB> <TAB> x_str + = "" "" * len ( label ) <TAB> <TAB> for i in range ( - 2 , self . input_width + 2 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> x_str + = colorize ( self . _get_str_obs ( ( i , j ) ) , "" green "" , highlight = True ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> x_str + = self . _get_str_obs ( ( i , j ) ) <TAB> <TAB> x_str + = "" \n "" <TAB> x_str = label + x_str <TAB> return x_str ","if i == x [ 0 ] and j == x [ 1 ] : 
","if i != j :
",26.35,3.26,False
"def build ( opt ) : <TAB> dpath = os . path . join ( opt [ "" datapath "" ] , "" QA-ZRE "" ) <TAB> version = None <TAB> if not build_data . built ( dpath , version_string = version ) : <TAB> <TAB> print ( "" [building data:  "" + dpath + "" ] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # An older version exists, so remove these outdated files. <TAB> <TAB> <TAB> build_data . remove_dir ( dpath ) <TAB> <TAB> build_data . make_dir ( dpath ) <TAB> <TAB> # Download the data. <TAB> <TAB> for downloadable_file in RESOURCES : <TAB> <TAB> <TAB> downloadable_file . download_file ( dpath ) <TAB> <TAB> # Mark the data as built. <TAB> <TAB> build_data . mark_done ( dpath , version_string = version ) ","if build_data . built ( dpath ) : 
","if build_data . built ( dpath ) :
",100.0,100.0,True
"def git_pull ( args ) : <TAB> if len ( args ) < = 1 : <TAB> <TAB> repo = _get_repo ( ) <TAB> <TAB> _confirm_dangerous ( ) <TAB> <TAB> url = args [ 0 ] if len ( args ) == 1 else repo . remotes . get ( "" origin "" , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> origin = url <TAB> <TAB> <TAB> url = repo . remotes . get ( origin ) <TAB> <TAB> if url : <TAB> <TAB> <TAB> repo . pull ( origin_uri = url ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" No pull URL. "" ) <TAB> else : <TAB> <TAB> print ( command_help [ "" git pull "" ] ) ","if url in repo . remotes : 
","if not origin :
",27.2,8.97,False
"def FindAndDelete ( script , sig ) : <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b "" "" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r + = script [ last_sop_idx : sop_idx ] <TAB> <TAB> last_sop_idx = sop_idx <TAB> <TAB> if script [ sop_idx : sop_idx + len ( sig ) ] == sig : <TAB> <TAB> <TAB> skip = True <TAB> <TAB> else : <TAB> <TAB> <TAB> skip = False <TAB> if not skip : <TAB> <TAB> r + = script [ last_sop_idx : ] <TAB> return CScript ( r ) ","if not skip : 
","if opcode == opcode :
",28.99,9.65,False
"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if ip . venture is not None : <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> if ip . device is not None : <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result ","if ip . device . venture is not None : 
","if ip . device . venture is not None :
",100.0,100.0,True
"def restore ( self , state ) : <TAB> """"""Restore the state of a mesh previously saved using save()"""""" <TAB> import pickle <TAB> state = pickle . loads ( state ) <TAB> for k in state : <TAB> <TAB> if isinstance ( state [ k ] , list ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> state [ k ] = [ [ v . x ( ) , v . y ( ) , v . z ( ) ] for v in state [ k ] ] <TAB> <TAB> <TAB> state [ k ] = np . array ( state [ k ] ) <TAB> <TAB> setattr ( self , k , state [ k ] ) ","if isinstance ( state [ k ] [ 0 ] , QtGui . QVector3D ) : 
","if len ( state [ k ] ) == 2 :
",41.57,25.55,False
"def get_extra_lines ( tup ) : <TAB> ext_name , pyopencl_ver = tup <TAB> if ext_name is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # capital letters -> CL version, not extension <TAB> <TAB> <TAB> yield "" "" <TAB> <TAB> <TAB> yield ""<TAB>  Available with OpenCL %s . "" % ( ext_name [ 3 : ] ) <TAB> <TAB> <TAB> yield "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> yield "" "" <TAB> <TAB> <TAB> yield ""<TAB>  Available with the ``%s `` extension. "" % ext_name <TAB> <TAB> <TAB> yield "" "" <TAB> if pyopencl_ver is not None : <TAB> <TAB> yield "" "" <TAB> <TAB> yield ""<TAB>  .. versionadded:: %s "" % pyopencl_ver <TAB> <TAB> yield "" "" ","if ext_name . startswith ( "" CL_ "" ) : 
","if ext_name . startswith ( "" cl_ "" ) :
",83.03,76.12,False
"def _gen_remote_uri ( <TAB> fileobj : IO [ bytes ] , <TAB> remote_uri : Optional [ ParseResult ] , <TAB> remote_path_prefix : Optional [ str ] , <TAB> remote_path_suffix : Optional [ str ] , <TAB> sha256sum : Optional [ str ] , ) - > ParseResult : <TAB> if remote_uri is None : <TAB> <TAB> assert remote_path_prefix is not None and remote_path_suffix is not None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sha256sum = _hash_fileobj ( fileobj ) <TAB> <TAB> return urlparse ( <TAB> <TAB> <TAB> os . path . join ( remote_path_prefix , f "" { sha256sum } { remote_path_suffix } "" ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return remote_uri ","if sha256sum is None : 
","if sha256sum is None :
",100.0,100.0,True
"def queries ( self ) : <TAB> if DEV : <TAB> <TAB> cmd = ShellCommand ( "" docker "" , "" ps "" , "" -qf "" , "" name= %s "" % self . path . k8s ) <TAB> <TAB> if not cmd . check ( f "" docker check for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> log_cmd = ShellCommand ( <TAB> <TAB> <TAB> <TAB> <TAB> "" docker "" , "" logs "" , self . path . k8s , stderr = subprocess . STDOUT <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if log_cmd . check ( f "" docker logs for  { self . path . k8s } "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> print ( cmd . stdout ) <TAB> <TAB> <TAB> <TAB> pytest . exit ( f "" container failed to start for  { self . path . k8s } "" ) <TAB> return ( ) ","if not cmd . stdout . strip ( ) : 
","if self . path . k8s not in [ "" docker "" , "" logs "" ] :
",33.41,3.21,False
"def get_range ( self ) : <TAB> present = self . xml . find ( "" { %s }range "" % self . namespace ) <TAB> if present is not None : <TAB> <TAB> attributes = present . attrib <TAB> <TAB> return_value = dict ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return_value [ "" minimum "" ] = attributes [ "" min "" ] <TAB> <TAB> if "" max "" in attributes : <TAB> <TAB> <TAB> return_value [ "" maximum "" ] = attributes [ "" max "" ] <TAB> <TAB> return return_value <TAB> return False ","if "" min "" in attributes : 
","if "" min "" in attributes :
",100.0,100.0,True
"def _configuredOn ( self , workerid , builderid = None , masterid = None ) : <TAB> cfg = [ ] <TAB> for cs in itervalues ( self . configured ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> bid , mid = self . db . builders . builder_masters [ cs [ "" buildermasterid "" ] ] <TAB> <TAB> if builderid is not None and bid != builderid : <TAB> <TAB> <TAB> continue <TAB> <TAB> if masterid is not None and mid != masterid : <TAB> <TAB> <TAB> continue <TAB> <TAB> cfg . append ( { "" builderid "" : bid , "" masterid "" : mid } ) <TAB> return cfg ","if cs [ "" workerid "" ] != workerid : 
","if cs [ "" workerid "" ] != workerid :
",100.0,100.0,True
"def __exit__ ( self , type , value , traceback ) : <TAB> try : <TAB> <TAB> if type is not None : <TAB> <TAB> <TAB> return self . exception_handler ( type , value , traceback ) <TAB> finally : <TAB> <TAB> final_contexts = _state . contexts <TAB> <TAB> _state . contexts = self . old_contexts <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise StackContextInconsistentError ( <TAB> <TAB> <TAB> <TAB> "" stack_context inconsistency (may be caused by yield  "" <TAB> <TAB> <TAB> <TAB> ' within a  "" with StackContext ""  block) ' <TAB> <TAB> <TAB> ) <TAB> <TAB> # Break up a reference to itself to allow for faster GC on CPython. <TAB> <TAB> self . new_contexts = None ","if final_contexts is not self . new_contexts : 
","if _state . contexts != final_contexts :
",31.94,21.42,False
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self . _keys [ hash_ ] == key : <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self . _keys [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _values [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _len - = 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self . _rehash ( hash_ ) <TAB> <TAB> if initial_hash == hash_ : <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None ","if self . _keys [ hash_ ] is self . _empty : 
","if self . _keys [ hash_ ] is None :
",69.81,64.37,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def data_generator ( ) : <TAB> i = 0 <TAB> max_batch_index = len ( X_train ) / / batch_size <TAB> tot = 0 <TAB> while 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> np . ones ( [ batch_size , input_dim ] ) * np . nan , <TAB> <TAB> <TAB> <TAB> np . ones ( [ batch_size , num_classes ] ) * np . nan , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> X_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB> <TAB> <TAB> <TAB> y_train [ i * batch_size : ( i + 1 ) * batch_size ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> i + = 1 <TAB> <TAB> tot + = 1 <TAB> <TAB> i = i % max_batch_index ","if tot > 3 * len ( X_train ) : 
","if i == max_batch_index :
",26.35,4.52,False
"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> width = self . statwidth ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB> <TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> width = self . colwidth ( ) <TAB> <TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if op . color : <TAB> <TAB> <TAB> <TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" space "" ] <TAB> return ret ","if i + 1 != len ( self . vars ) : 
","if i == 0 :
",26.92,6.01,False
"def get_container_from_dport ( dport , docker_client ) : <TAB> for container in docker_client . containers ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> ports = container [ "" Ports "" ] <TAB> <TAB> <TAB> for port in ports : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if port [ "" PublicPort "" ] == int ( dport ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return container <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> print ( ports ) <TAB> <TAB> <TAB> pass ","if "" PublicPort "" in port : 
","if port [ "" PublicPort "" ] != int ( dport ) :
",38.1,12.57,False
"def _get_parents_data ( self , data ) : <TAB> parents = 0 <TAB> if data [ COLUMN_PARENT ] : <TAB> <TAB> family = self . db . get_family_from_handle ( data [ COLUMN_PARENT ] [ 0 ] ) <TAB> <TAB> if family . get_father_handle ( ) : <TAB> <TAB> <TAB> parents + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parents + = 1 <TAB> return parents ","if family . get_mother_handle ( ) : 
","elif family . get_father_handle ( ) == data [ COLUMN_PARENT ] [ 1 ] :
",43.38,22.27,False
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> if filename in cache : <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> if old_mtime == mtime : <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache [ filename ] = old_mtime , result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB> <TAB> cache [ filename ] = mtime , result<TAB> # at the end <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cache . popitem ( last = False ) <TAB> return result ","if len ( cache ) > max_size : 
","if len ( cache ) > = cache_size :
",68.15,58.77,False
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> if op . stage == OperandStage . map : <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . combine : <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else :<TAB> # pragma: no cover <TAB> <TAB> <TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB> <TAB> pd . reset_option ( "" mode.use_inf_as_na "" ) ","elif op . stage == OperandStage . agg : 
","elif op . stage == OperandStage . aggregate :
",87.71,78.25,False
"def FindAndDelete ( script , sig ) : <TAB> """"""Consensus critical, see FindAndDelete() in Satoshi codebase"""""" <TAB> r = b "" "" <TAB> last_sop_idx = sop_idx = 0 <TAB> skip = True <TAB> for ( opcode , data , sop_idx ) in script . raw_iter ( ) : <TAB> <TAB> if not skip : <TAB> <TAB> <TAB> r + = script [ last_sop_idx : sop_idx ] <TAB> <TAB> last_sop_idx = sop_idx <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> skip = True <TAB> <TAB> else : <TAB> <TAB> <TAB> skip = False <TAB> if not skip : <TAB> <TAB> r + = script [ last_sop_idx : ] <TAB> return CScript ( r ) ","if script [ sop_idx : sop_idx + len ( sig ) ] == sig : 
","if opcode == sig :
",27.94,5.21,False
"def extractall ( zip : typing . Any , path : str ) - > NoneType : <TAB> for name in zip . namelist ( ) : <TAB> <TAB> member = zip . getinfo ( name ) <TAB> <TAB> extracted_path = zip . _extract_member ( member , path , None ) <TAB> <TAB> attr = member . external_attr >> 16 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . chmod ( extracted_path , attr ) ","if attr != 0 : 
","if extracted_path is not None :
",28.03,6.57,False
"def find_all_gyptest_files ( directory ) : <TAB> result = [ ] <TAB> for root , dirs , files in os . walk ( directory ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dirs . remove ( "" .svn "" ) <TAB> <TAB> result . extend ( [ os . path . join ( root , f ) for f in files if is_test_name ( f ) ] ) <TAB> result . sort ( ) <TAB> return result ","if "" .svn "" in dirs : 
","if "" .svn "" in dirs :
",100.0,100.0,True
"def load ( cls , storefile , template_store ) : <TAB> # Did we get file or filename? <TAB> if not hasattr ( storefile , "" read "" ) : <TAB> <TAB> storefile = open ( storefile , "" rb "" ) <TAB> # Adjust store to have translations <TAB> store = cls . convertfile ( storefile , template_store ) <TAB> for unit in store . units : <TAB> <TAB> if unit . isheader ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> # HTML does this properly on loading, others need it <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unit . target = unit . source <TAB> <TAB> <TAB> unit . rich_target = unit . rich_source <TAB> return store ","if cls . needs_target_sync : 
","if unit . ishtml ( ) :
",36.31,6.5,False
"def postOptions ( self ) : <TAB> _BasicOptions . postOptions ( self ) <TAB> if self [ "" jobs "" ] : <TAB> <TAB> conflicts = [ "" debug "" , "" profile "" , "" debug-stacktraces "" , "" exitfirst "" ] <TAB> <TAB> for option in conflicts : <TAB> <TAB> <TAB> if self [ option ] : <TAB> <TAB> <TAB> <TAB> raise usage . UsageError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" You can ' t specify -- %s  when using --jobs "" % option <TAB> <TAB> <TAB> <TAB> ) <TAB> if self [ "" nopm "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise usage . UsageError ( "" You must specify --debug when using  "" "" --nopm  "" ) <TAB> <TAB> failure . DO_POST_MORTEM = False ","if not self [ "" debug "" ] : 
","if self [ "" debug "" ] :
",71.9,76.73,False
"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB> <TAB> if not ( i < len ( extra . tokens ) ) : <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra . tokens [ i ] <TAB> <TAB> token = jsdict ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" type "" : entry . type , <TAB> <TAB> <TAB> <TAB> "" value "" : entry . value , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra . range : <TAB> <TAB> <TAB> token . range = entry . range <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> token . loc = entry . loc <TAB> <TAB> tokens . append ( token ) <TAB> <TAB> i + = 1 <TAB> extra . tokens = tokens ","if extra . loc : 
","if extra . loc :
",100.0,100.0,True
"def on_rebalance_end ( self ) - > None : <TAB> """"""Call when rebalancing is done."""""" <TAB> self . rebalancing = False <TAB> if self . _rebalancing_span : <TAB> <TAB> self . _rebalancing_span . finish ( ) <TAB> self . _rebalancing_span = None <TAB> sensor_state = self . _rebalancing_sensor_state <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . warning ( <TAB> <TAB> <TAB> <TAB> "" Missing sensor state for rebalance # %s "" , self . rebalancing_count <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . sensors . on_rebalance_end ( self , sensor_state ) <TAB> finally : <TAB> <TAB> self . _rebalancing_sensor_state = None ","if not sensor_state : 
","if sensor_state is None :
",29.25,27.78,False
"def decorator ( request , * args , * * kwargs ) : <TAB> if CALENDAR_VIEW_PERM : <TAB> <TAB> user = request . user <TAB> <TAB> if not user : <TAB> <TAB> <TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB> <TAB> occurrence , event , calendar = get_objects ( request , * * kwargs ) <TAB> <TAB> if calendar : <TAB> <TAB> <TAB> allowed = CHECK_CALENDAR_PERM_FUNC ( calendar , user ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return HttpResponseRedirect ( settings . LOGIN_URL ) <TAB> <TAB> <TAB> # all checks passed <TAB> <TAB> <TAB> return function ( request , * args , * * kwargs ) <TAB> <TAB> return HttpResponseNotFound ( "" <h1>Page not found</h1> "" ) <TAB> return function ( request , * args , * * kwargs ) ","if not allowed : 
","if not allowed :
",100.0,100.0,True
"def reduce_arguments ( self , args ) : <TAB> assert isinstance ( args , nodes . Arguments ) <TAB> if args . incorrect_order ( ) : <TAB> <TAB> raise InvalidArguments ( <TAB> <TAB> <TAB> "" All keyword arguments must be after positional arguments. "" <TAB> <TAB> ) <TAB> reduced_pos = [ self . reduce_single ( arg ) for arg in args . arguments ] <TAB> reduced_kw = { } <TAB> for key in args . kwargs . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidArguments ( "" Keyword argument name is not a string. "" ) <TAB> <TAB> a = args . kwargs [ key ] <TAB> <TAB> reduced_kw [ key ] = self . reduce_single ( a ) <TAB> return ( reduced_pos , reduced_kw ) ","if not isinstance ( key , str ) : 
","if not isinstance ( key , str ) :
",100.0,100.0,True
"def _encode ( n , nbytes , little_endian = False ) : <TAB> retval = [ ] <TAB> n = long ( n ) <TAB> for i in range ( nbytes ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> retval . append ( chr ( n & 0xFF ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval . insert ( 0 , chr ( n & 0xFF ) ) <TAB> <TAB> n >> = 8 <TAB> return "" "" . join ( retval ) ","if little_endian : 
","if little_endian :
",78.12,100.0,True
"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( )<TAB> # create a new group <TAB> new_i . id = self . id<TAB> # with the same id <TAB> cls . id = old_id<TAB> # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls . properties : <TAB> <TAB> if prop is not "" members "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> val = getattr ( self , prop ) <TAB> <TAB> <TAB> <TAB> setattr ( new_i , prop , val ) <TAB> # but no members <TAB> new_i . members = [ ] <TAB> return new_i ","if self . has ( prop ) : 
","if hasattr ( self , prop ) :
",33.28,24.45,False
"def dataspec ( config ) : <TAB> master = yield fakemaster . make_master ( ) <TAB> data = connector . DataConnector ( ) <TAB> data . setServiceParent ( master ) <TAB> if config [ "" out "" ] != "" -- "" : <TAB> <TAB> dirs = os . path . dirname ( config [ "" out "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( dirs ) <TAB> <TAB> f = open ( config [ "" out "" ] , "" w "" ) <TAB> else : <TAB> <TAB> f = sys . stdout <TAB> if config [ "" global "" ] is not None : <TAB> <TAB> f . write ( "" window. "" + config [ "" global "" ] + "" = "" ) <TAB> f . write ( json . dumps ( data . allEndpoints ( ) , indent = 2 ) ) <TAB> f . close ( ) <TAB> defer . returnValue ( 0 ) ","if dirs and not os . path . exists ( dirs ) : 
","if not os . path . exists ( dirs ) :
",78.04,76.26,False
"def _parseSCDOCDC ( self , src ) : <TAB> """"""[S|CDO|CDC]*"""""" <TAB> while 1 : <TAB> <TAB> src = src . lstrip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> src = src [ 4 : ] <TAB> <TAB> elif src . startswith ( "" --> "" ) : <TAB> <TAB> <TAB> src = src [ 3 : ] <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return src ","if src . startswith ( "" <!-- "" ) : 
","if src . startswith ( "" --S "" ) :
",83.03,53.88,False
"def command ( filenames , dirnames , fix ) : <TAB> for filename in gather_files ( dirnames , filenames ) : <TAB> <TAB> visitor = process_file ( filename ) <TAB> <TAB> if visitor . needs_fix ( ) : <TAB> <TAB> <TAB> print ( "" %s :  %s "" % ( filename , visitor . get_stats ( ) ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> print ( "" Fixing:  %s "" % filename ) <TAB> <TAB> <TAB> <TAB> fix_file ( filename ) ","if fix : 
","if fix :
",78.12,0.0,False
"def shutdown ( self ) : <TAB> """"""Shutdown host system."""""" <TAB> self . _check_dbus ( MANAGER ) <TAB> use_logind = self . sys_dbus . logind . is_connected <TAB> _LOGGER . info ( "" Initialize host power off  %s "" , "" logind "" if use_logind else "" systemd "" ) <TAB> try : <TAB> <TAB> await self . sys_core . shutdown ( ) <TAB> finally : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await self . sys_dbus . logind . power_off ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await self . sys_dbus . systemd . power_off ( ) ","if use_logind : 
","if use_logind :
",78.12,100.0,True
"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split : <TAB> <TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB> <TAB> char = chars [ i ] <TAB> <TAB> if _is_punctuation ( char ) : <TAB> <TAB> <TAB> output . append ( [ char ] ) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> output . append ( [ ] ) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output [ - 1 ] . append ( char ) <TAB> <TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ] ","if start_new_word : 
","if start_new_word :
",78.12,100.0,True
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> if tp == "" write "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" write_flush "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass ","elif tp == "" flush "" : 
","elif tp == "" flush "" :
",100.0,100.0,True
"def checkClassDeclation ( file ) : <TAB> localResult = [ ] <TAB> with open ( file , "" rb "" ) as f : <TAB> <TAB> lineNumber = 0 <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> m = re . search ( "" class \ s+[^ \ (]*: "" , line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> localResult . append ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Old class definition found on  {0} "" . format ( m . group ( ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return localResult ","if m : 
","if m :
",78.12,0.0,False
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> if isinstance ( in_arrays , tuple ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> if self . _progress_hook : <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results ","elif isinstance ( in_arrays , dict ) : 
","elif isinstance ( in_arrays , dict ) :
",100.0,100.0,True
"def check_billing_view ( user , permission , obj ) : <TAB> if hasattr ( obj , "" all_projects "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> # This is a billing object <TAB> <TAB> return any ( check_permission ( user , permission , prj ) for prj in obj . all_projects ) <TAB> return check_permission ( user , permission , obj ) ","if user . is_superuser or obj . owners . filter ( pk = user . pk ) . exists ( ) : 
","if obj . all_projects == [ ] :
",31.67,3.03,False
"def ensure_output_spaces_contain_the_same_data ( self , y , y_ensured ) : <TAB> stride = y . shape [ 1 ] <TAB> self . assertEqual ( y . shape [ 0 ] * y . shape [ 1 ] , y_ensured . shape [ 0 ] ) <TAB> self . assertEqual ( len ( y_ensured . shape ) , 1 ) <TAB> for row in range ( y . shape [ 0 ] ) : <TAB> <TAB> for column in range ( y . shape [ 1 ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( y [ row , column ] , y_ensured [ row * stride + column ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertEqual ( y [ row ] [ column ] , y_ensured [ row * stride + column ] ) ","if sp . issparse ( y ) : 
","if row > = 0 :
",26.85,6.92,False
"def train ( <TAB> self , <TAB> training_data : TrainingData , <TAB> config : Optional [ RasaNLUModelConfig ] = None , <TAB> * * kwargs : Any , ) - > None : <TAB> """"""Tokenize all training data."""""" <TAB> for example in training_data . training_examples : <TAB> <TAB> for attribute in MESSAGE_ATTRIBUTES : <TAB> <TAB> <TAB> if example . get ( attribute ) is not None and not example . get ( attribute ) == "" "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self . _split_name ( example , attribute ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> tokens = self . tokenize ( example , attribute ) <TAB> <TAB> <TAB> <TAB> example . set ( TOKENS_NAMES [ attribute ] , tokens ) ","if attribute in [ INTENT , ACTION_NAME , INTENT_RESPONSE_KEY ] : 
","if attribute in TOKENS_NAMES :
",30.03,6.66,False
"def refresh_token ( self , strategy , * args , * * kwargs ) : <TAB> token = self . extra_data . get ( "" refresh_token "" ) or self . extra_data . get ( "" access_token "" ) <TAB> backend = self . get_backend ( strategy ) <TAB> if token and backend and hasattr ( backend , "" refresh_token "" ) : <TAB> <TAB> backend = backend ( strategy = strategy ) <TAB> <TAB> response = backend . refresh_token ( token , * args , * * kwargs ) <TAB> <TAB> extra_data = backend . extra_data ( self , self . uid , response , self . extra_data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . save ( ) ","if self . set_extra_data ( extra_data ) : 
","if "" access_token "" in extra_data and "" access_token "" in extra_data :
",26.53,12.58,False
"def _verify_environ ( _collected_environ ) : <TAB> try : <TAB> <TAB> yield <TAB> finally : <TAB> <TAB> new_environ = dict ( os . environ ) <TAB> <TAB> current_test = new_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB> <TAB> old_environ = dict ( _collected_environ ) <TAB> <TAB> old_environ . pop ( "" PYTEST_CURRENT_TEST "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise DirtyTest ( <TAB> <TAB> <TAB> <TAB> "" Left over environment variables "" , <TAB> <TAB> <TAB> <TAB> current_test , <TAB> <TAB> <TAB> <TAB> _compare_eq_dict ( new_environ , old_environ , verbose = 2 ) , <TAB> <TAB> <TAB> ) ","if new_environ != old_environ : 
","if current_test != old_environ :
",64.48,55.55,False
"def clean_len ( self , line ) : <TAB> """"""Calculate wisible length of string"""""" <TAB> if isinstance ( line , basestring ) : <TAB> <TAB> return len ( self . screen . markup . clean_markup ( line ) ) <TAB> elif isinstance ( line , tuple ) or isinstance ( line , list ) : <TAB> <TAB> markups = self . screen . markup . get_markup_vars ( ) <TAB> <TAB> length = 0 <TAB> <TAB> for i in line : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> length + = len ( i ) <TAB> <TAB> return length ","if i not in markups : 
","if markups and markups [ i ] . strip ( ) :
",26.91,4.79,False
"def _build_merged_dataset_args ( datasets ) : <TAB> merged_dataset_args = [ ] <TAB> for dataset in datasets : <TAB> <TAB> dataset_code_column = _parse_dataset_code ( dataset ) <TAB> <TAB> arg = dataset_code_column [ "" code "" ] <TAB> <TAB> column_index = dataset_code_column [ "" column_index "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arg = ( dataset_code_column [ "" code "" ] , { "" column_index "" : [ column_index ] } ) <TAB> <TAB> merged_dataset_args . append ( arg ) <TAB> return merged_dataset_args ","if column_index is not None : 
","if column_index is not None :
",100.0,100.0,True
"def update_watch_data_table_paths ( self ) : <TAB> if hasattr ( self . tool_data_watcher , "" monitored_dirs "" ) : <TAB> <TAB> for tool_data_table_path in self . tool_data_paths : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . tool_data_watcher . watch_directory ( tool_data_table_path ) ","if tool_data_table_path not in self . tool_data_watcher . monitored_dirs : 
","if tool_data_table_path not in self . monitored_dirs :
",66.2,64.71,False
"def getsource ( obj ) : <TAB> """"""Wrapper around inspect.getsource"""""" <TAB> try : <TAB> <TAB> try : <TAB> <TAB> <TAB> src = encoding . to_unicode ( inspect . getsource ( obj ) ) <TAB> <TAB> except TypeError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> src = encoding . to_unicode ( inspect . getsource ( obj . __class__ ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # Bindings like VTK or ITK require this case <TAB> <TAB> <TAB> <TAB> src = getdoc ( obj ) <TAB> <TAB> return src <TAB> except ( TypeError , IOError ) : <TAB> <TAB> return ","if hasattr ( obj , "" __class__ "" ) : 
","if inspect . isfunction ( obj ) :
",28.49,7.8,False
"def __iter__ ( self ) : <TAB> for model in self . app_config . get_models ( ) : <TAB> <TAB> admin_model = AdminModel ( model , * * self . options ) <TAB> <TAB> for model_re in self . model_res : <TAB> <TAB> <TAB> if model_re . search ( admin_model . name ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield admin_model ","if self . model_res : 
","if admin_model . name not in self . _excluded_models :
",38.13,6.92,False
"def run ( self ) : <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> with DelayedKeyboardInterrupt ( ) : <TAB> <TAB> <TAB> <TAB> raw_inputs = self . _parent_task_queue . get ( ) <TAB> <TAB> <TAB> <TAB> if self . _has_stop_signal ( raw_inputs ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> if self . _flow_type == BATCH : <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = True ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _rq . put ( raw_inputs , block = False ) <TAB> <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> except KeyboardInterrupt : <TAB> <TAB> <TAB> continue ","elif self . _flow_type == REALTIME : 
","elif self . _flow_type == REVERT :
",82.41,80.71,False
"def dump ( self ) : <TAB> self . ql . log . info ( "" [*] Dumping object:  %s "" % ( self . sf_name ) ) <TAB> for field in self . _fields_ : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . ql . log . info ( "" %s : 0x %x "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . value ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , int ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %d "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) ) ) <TAB> <TAB> elif isinstance ( getattr ( self , field [ 0 ] ) , bytes ) : <TAB> <TAB> <TAB> self . ql . log . info ( "" %s :  %s "" % ( field [ 0 ] , getattr ( self , field [ 0 ] ) . decode ( ) ) ) ","if isinstance ( getattr ( self , field [ 0 ] ) , POINTER64 ) : 
","if isinstance ( getattr ( self , field [ 0 ] ) , torch . Tensor ) :
",75.09,73.51,False
"def validate_configuration ( self , configuration : Optional [ ExpectationConfiguration ] ) : <TAB> """"""Validating that user has inputted a value set and that configuration has been initialized"""""" <TAB> super ( ) . validate_configuration ( configuration ) <TAB> try : <TAB> <TAB> assert "" value_set "" in configuration . kwargs , "" value_set is required "" <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> configuration . kwargs [ "" value_set "" ] , ( list , set , dict ) <TAB> <TAB> ) , "" value_set must be a list or a set "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert ( <TAB> <TAB> <TAB> <TAB> "" $PARAMETER "" in configuration . kwargs [ "" value_set "" ] <TAB> <TAB> <TAB> ) , ' Evaluation Parameter dict for value_set kwarg must have  "" $PARAMETER ""  key ' <TAB> except AssertionError as e : <TAB> <TAB> raise InvalidExpectationConfigurationError ( str ( e ) ) <TAB> return True ","if isinstance ( configuration . kwargs [ "" value_set "" ] , dict ) : 
","if isinstance ( configuration . kwargs [ "" value_set "" ] , dict ) :
",100.0,100.0,True
def test_one_dead_branch ( ) : <TAB> with deterministic_PRNG ( ) : <TAB> <TAB> seen = set ( ) <TAB> <TAB> @run_to_buffer <TAB> <TAB> def x ( data ) : <TAB> <TAB> <TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB> <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> <TAB> data . mark_invalid ( ) <TAB> <TAB> <TAB> i = data . draw_bytes ( 1 ) [ 0 ] <TAB> <TAB> <TAB> if len ( seen ) < 255 : <TAB> <TAB> <TAB> <TAB> seen . add ( i ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data . mark_interesting ( ) ,"elif i not in seen : 
","if i in seen :
",35.75,34.98,False
"def __on_item_activated ( self , event ) : <TAB> if self . __module_view : <TAB> <TAB> module = self . get_event_module ( event ) <TAB> <TAB> self . __module_view . set_selection ( module . module_num ) <TAB> <TAB> if event . EventObject is self . list_ctrl : <TAB> <TAB> <TAB> self . input_list_ctrl . deactivate_active_item ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . list_ctrl . deactivate_active_item ( ) <TAB> <TAB> <TAB> for index in range ( self . list_ctrl . GetItemCount ( ) ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . list_ctrl . Select ( index , False ) <TAB> self . __controller . enable_module_controls_panel_buttons ( ) ","if self . list_ctrl . IsSelected ( index ) : 
","if self . list_ctrl . GetItem ( index ) == self . __selected_item :
",64.45,34.82,False
"def prime ( self , callback ) : <TAB> <MASK> <TAB> <TAB> # import pdb <TAB> <TAB> # pdb.set_trace() <TAB> <TAB> self . cbhdl = simulator . register_rwsynch_callback ( callback , self ) <TAB> <TAB> if self . cbhdl is None : <TAB> <TAB> <TAB> raise_error ( self , "" Unable set up  %s  Trigger "" % ( str ( self ) ) ) <TAB> Trigger . prime ( self ) ","if self . cbhdl is None : 
","if self . cbhdl is None :
",100.0,100.0,True
"def fstab_configuration ( middleware ) : <TAB> for command in ( <TAB> <TAB> [ <TAB> <TAB> <TAB> [ "" systemctl "" , "" daemon-reload "" ] , <TAB> <TAB> <TAB> [ "" systemctl "" , "" restart "" , "" local-fs.target "" ] , <TAB> <TAB> ] <TAB> <TAB> if osc . IS_LINUX <TAB> <TAB> else [ [ "" mount "" , "" -uw "" , "" / "" ] ] <TAB> ) : <TAB> <TAB> ret = subprocess . run ( command , capture_output = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> middleware . logger . debug ( <TAB> <TAB> <TAB> <TAB> f ' Failed to execute  "" { "" "" . join ( command ) } "" :  { ret . stderr . decode ( ) } ' <TAB> <TAB> <TAB> ) ","if ret . returncode : 
","if ret . stderr :
",64.48,42.73,False
"def _generate_table ( self , fromdesc , todesc , diffs ) : <TAB> if fromdesc or todesc : <TAB> <TAB> yield ( <TAB> <TAB> <TAB> simple_colorize ( fromdesc , "" description "" ) , <TAB> <TAB> <TAB> simple_colorize ( todesc , "" description "" ) , <TAB> <TAB> ) <TAB> for i , line in enumerate ( diffs ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # mdiff yields None on separator lines; skip the bogus ones <TAB> <TAB> <TAB> # generated for the first line <TAB> <TAB> <TAB> if i > 0 : <TAB> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB> <TAB> <TAB> <TAB> <TAB> simple_colorize ( "" --- "" , "" separator "" ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield line ","if line is None : 
","if line . strip ( ) :
",29.79,14.54,False
"def update_completion ( self ) : <TAB> """"""Update completion model with exist tags"""""" <TAB> orig_text = self . widget . text ( ) <TAB> text = "" ,  "" . join ( orig_text . replace ( "" ,  "" , "" , "" ) . split ( "" , "" ) [ : - 1 ] ) <TAB> tags = [ ] <TAB> for tag in self . tags_list : <TAB> <TAB> if "" , "" in orig_text : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tags . append ( "" %s , %s "" % ( text , tag ) ) <TAB> <TAB> <TAB> tags . append ( "" %s ,  %s "" % ( text , tag ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags . append ( tag ) <TAB> if tags != self . completer_model . stringList ( ) : <TAB> <TAB> self . completer_model . setStringList ( tags ) ","if orig_text [ - 1 ] not in ( "" , "" , "" "" ) : 
","if tag not in tags :
",29.08,2.21,False
"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB> <TAB> return False <TAB> for digit in reversed ( number ) : <TAB> <TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> digit * = 2 <TAB> <TAB> <TAB> if digit > = 10 : <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit / / 10 <TAB> <TAB> digits . append ( digit ) <TAB> <TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False ","if even : 
","if even :
",78.12,0.0,False
"def __get_param_string__ ( params ) : <TAB> params_string = [ ] <TAB> for key in sorted ( params . keys ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> value = params [ key ] <TAB> <TAB> params_string . append ( "" "" if value == "" null "" else str ( value ) ) <TAB> return "" | "" . join ( params_string ) ","if "" REFUND "" in params [ key ] or "" | "" in params [ key ] : 
","if key == "" null "" :
",31.16,2.09,False
"def _map_handlers ( self , session , event_class , mapfn ) : <TAB> for event in DOC_EVENTS : <TAB> <TAB> event_handler_name = event . replace ( "" - "" , "" _ "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> event_handler = getattr ( self , event_handler_name ) <TAB> <TAB> <TAB> format_string = DOC_EVENTS [ event ] <TAB> <TAB> <TAB> num_args = len ( format_string . split ( "" . "" ) ) - 2 <TAB> <TAB> <TAB> format_args = ( event_class , ) + ( "" * "" , ) * num_args <TAB> <TAB> <TAB> event_string = event + format_string % format_args <TAB> <TAB> <TAB> unique_id = event_class + event_handler_name <TAB> <TAB> <TAB> mapfn ( event_string , event_handler , unique_id ) ","if hasattr ( self , event_handler_name ) : 
","if event_handler_name in session . _event_handlers :
",26.96,28.92,False
"def _create_param_lr ( self , param_and_grad ) : <TAB> # create learning rate variable for every parameter <TAB> param = param_and_grad [ 0 ] <TAB> param_lr = param . optimize_attr [ "" learning_rate "" ] <TAB> if type ( param_lr ) == Variable : <TAB> <TAB> return param_lr <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _global_learning_rate ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with default_main_program ( ) . _lr_schedule_guard ( <TAB> <TAB> <TAB> <TAB> is_with_opt = True <TAB> <TAB> <TAB> ) , framework . name_scope ( "" scale_with_param_lr "" ) : <TAB> <TAB> <TAB> <TAB> return self . _global_learning_rate ( ) * param_lr ","if param_lr == 1.0 : 
","if param_lr == 0 :
",39.48,70.71,False
"def __getitem__ ( self , key ) : <TAB> try : <TAB> <TAB> return self . _clsmap [ key ] <TAB> except KeyError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _mutex . acquire ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> if not self . initialized : <TAB> <TAB> <TAB> <TAB> <TAB> self . _init ( ) <TAB> <TAB> <TAB> <TAB> <TAB> self . initialized = True <TAB> <TAB> <TAB> <TAB> return self . _clsmap [ key ] <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . _mutex . release ( ) <TAB> <TAB> raise e ","if not self . initialized : 
","if not self . initialized :
",100.0,100.0,True
"def save ( self , force = False ) : <TAB> if not force : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if time . time ( ) - self . last_save_time < 10 : <TAB> <TAB> <TAB> return <TAB> with self . lock : <TAB> <TAB> with open ( self . file_path , "" w "" ) as fd : <TAB> <TAB> <TAB> for ip in self . cache : <TAB> <TAB> <TAB> <TAB> record = self . cache [ ip ] <TAB> <TAB> <TAB> <TAB> rule = record [ "" r "" ] <TAB> <TAB> <TAB> <TAB> connect_time = record [ "" c "" ] <TAB> <TAB> <TAB> <TAB> update_time = record [ "" update "" ] <TAB> <TAB> <TAB> <TAB> fd . write ( "" %s %s %d %d \n "" % ( ip , rule , connect_time , update_time ) ) <TAB> self . last_save_time = time . time ( ) <TAB> self . need_save = False ","if not self . need_save : 
","if self . need_save :
",58.31,72.9,False
"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield x <TAB> <TAB> elif not x . is_atom ( ) and not s . is_atom ( ) : <TAB> <TAB> <TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation ) ","if match ( s ) : 
","if x . is_atom ( ) and s . is_atom ( ) :
",28.58,5.75,False
"def isValidFloat ( config_param_name , value , constraints ) : <TAB> if isinstance ( value , float ) : <TAB> <TAB> constraints . setdefault ( "" min "" , MIN_VALID_FLOAT_VALUE ) <TAB> <TAB> constraints . setdefault ( "" max "" , MAX_VALID_FLOAT_VALUE ) <TAB> <TAB> minv = float ( constraints . get ( "" min "" ) ) <TAB> <TAB> maxv = float ( constraints . get ( "" max "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value < = maxv : <TAB> <TAB> <TAB> <TAB> return value <TAB> raise FloatValueError ( config_param_name , value , constraints ) ","if value > = minv : 
","if value > = minv :
",100.0,100.0,True
"def get_files ( d ) : <TAB> f = [ ] <TAB> for root , dirs , files in os . walk ( d ) : <TAB> <TAB> for name in files : <TAB> <TAB> <TAB> if "" meta-environment "" in root or "" cross-canadian "" in root : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if "" do_build "" not in name and "" do_populate_sdk "" not in name : <TAB> <TAB> <TAB> <TAB> f . append ( os . path . join ( root , name ) ) <TAB> return f ","if "" qemux86copy- "" in root or "" qemux86- "" in root : 
","if "" do_build "" in root and "" do_populate_sdk "" in root :
",65.97,20.97,False
"def __get_photo ( self , person_or_marriage ) : <TAB> """"""returns the first photo in the media list or None"""""" <TAB> media_list = person_or_marriage . get_media_list ( ) <TAB> for media_ref in media_list : <TAB> <TAB> media_handle = media_ref . get_reference_handle ( ) <TAB> <TAB> media = self . database . get_media_from_handle ( media_handle ) <TAB> <TAB> mime_type = media . get_mime_type ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return media <TAB> return None ","if mime_type and mime_type . startswith ( "" image "" ) : 
","if mime_type == "" photo "" :
",30.8,16.58,False
"def filter ( this , args ) : <TAB> array = to_object ( this , args . space ) <TAB> callbackfn = get_arg ( args , 0 ) <TAB> arr_len = js_arr_length ( array ) <TAB> if not is_callable ( callbackfn ) : <TAB> <TAB> raise MakeError ( "" TypeError "" , "" callbackfn must be a function "" ) <TAB> _this = get_arg ( args , 1 ) <TAB> k = 0 <TAB> res = [ ] <TAB> while k < arr_len : <TAB> <TAB> if array . has_property ( unicode ( k ) ) : <TAB> <TAB> <TAB> kValue = array . get ( unicode ( k ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> res . append ( kValue ) <TAB> <TAB> k + = 1 <TAB> return args . space . ConstructArray ( res ) ","if to_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) : 
","if is_boolean ( callbackfn . call ( _this , ( kValue , float ( k ) , array ) ) ) :
",95.7,92.45,False
"def optimize ( self , graph : Graph ) : <TAB> for v in graph . inputs : <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> DumpGraph ( ) . optimize ( graph ) <TAB> <TAB> raise NotImplementedError ( <TAB> <TAB> <TAB> f "" Input Variable  { v }  is too large to handle in WebGL backend "" <TAB> <TAB> ) <TAB> return graph , False ","if flags . DEBUG : 
","if v . has_attribute ( DumpTarget ) :
",36.13,5.52,False
"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self . list_nodes ( ) : <TAB> <TAB> if type ( node . image ) is not list : <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node . image : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk . extra [ "" disk_id "" ] <TAB> <TAB> <TAB> <TAB> return self . _do_detach_volume ( node . id , disk_id ) <TAB> return False ","if disk . id == volume . id : 
","if disk . extra [ "" volume "" ] == volume :
",41.82,20.1,False
"def Yield ( value , level = 1 ) : <TAB> g = greenlet . getcurrent ( ) <TAB> while level != 0 : <TAB> <TAB> if not isinstance ( g , genlet ) : <TAB> <TAB> <TAB> raise RuntimeError ( "" yield outside a genlet "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . parent . set_child ( g ) <TAB> <TAB> g = g . parent <TAB> <TAB> level - = 1 <TAB> g . switch ( value ) ","if level > 1 : 
","if g . parent :
",28.41,12.7,False
"def get_all_pipeline_nodes ( <TAB> pipeline : pipeline_pb2 . Pipeline , ) - > List [ pipeline_pb2 . PipelineNode ] : <TAB> """"""Returns all pipeline nodes in the given pipeline."""""" <TAB> result = [ ] <TAB> for pipeline_or_node in pipeline . nodes : <TAB> <TAB> which = pipeline_or_node . WhichOneof ( "" node "" ) <TAB> <TAB> # TODO(goutham): Handle sub-pipelines. <TAB> <TAB> # TODO(goutham): Handle system nodes. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( pipeline_or_node . pipeline_node ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( "" Only pipeline nodes supported. "" ) <TAB> return result ","if which == "" pipeline_node "" : 
","if which in [ "" pipeline "" , "" pipeline_node "" ] :
",39.24,29.26,False
"def __init__ ( self , * * settings ) : <TAB> default_settings = self . get_default_settings ( ) <TAB> for name , value in default_settings . items ( ) : <TAB> <TAB> if not hasattr ( self , name ) : <TAB> <TAB> <TAB> setattr ( self , name , value ) <TAB> for name , value in settings . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Invalid setting  ' {} '  for  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name , <TAB> <TAB> <TAB> <TAB> <TAB> self . __class__ . __name__ , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> setattr ( self , name , value ) ","if name not in default_settings : 
","if not hasattr ( self , name ) :
",27.29,6.74,False
"def _check_choice ( self ) : <TAB> if self . type == "" choice "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise OptionError ( "" must supply a list of choices for type  ' choice ' "" , self ) <TAB> <TAB> elif type ( self . choices ) not in ( types . TupleType , types . ListType ) : <TAB> <TAB> <TAB> raise OptionError ( <TAB> <TAB> <TAB> <TAB> "" choices must be a list of strings ( ' %s '  supplied) "" <TAB> <TAB> <TAB> <TAB> % str ( type ( self . choices ) ) . split ( "" ' "" ) [ 1 ] , <TAB> <TAB> <TAB> <TAB> self , <TAB> <TAB> <TAB> ) <TAB> elif self . choices is not None : <TAB> <TAB> raise OptionError ( "" must not supply choices for type  %r "" % self . type , self ) ","if self . choices is None : 
","if self . choices is None :
",100.0,100.0,True
"def prepare ( self , size = None ) : <TAB> if _is_seekable ( self . file ) : <TAB> <TAB> start_pos = self . file . tell ( ) <TAB> <TAB> self . file . seek ( 0 , 2 ) <TAB> <TAB> end_pos = self . file . tell ( ) <TAB> <TAB> self . file . seek ( start_pos ) <TAB> <TAB> fsize = end_pos - start_pos <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . remain = fsize <TAB> <TAB> else : <TAB> <TAB> <TAB> self . remain = min ( fsize , size ) <TAB> return self . remain ","if size is None : 
","if size is None :
",100.0,100.0,True
"def _setSitemapTargets ( ) : <TAB> if not conf . sitemapUrl : <TAB> <TAB> return <TAB> infoMsg = "" parsing sitemap  ' %s ' "" % conf . sitemapUrl <TAB> logger . info ( infoMsg ) <TAB> found = False <TAB> for item in parseSitemap ( conf . sitemapUrl ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> kb . targets . add ( ( item . strip ( ) , None , None , None , None ) ) <TAB> if not found and not conf . forms and not conf . crawlDepth : <TAB> <TAB> warnMsg = "" no usable links found (with GET parameters) "" <TAB> <TAB> logger . warn ( warnMsg ) ","if re . match ( r "" [^ ]+ \ ?(.+) "" , item , re . I ) : 
","if item . strip ( ) :
",31.61,1.15,False
"def test_CY_decomposition ( self , tol ) : <TAB> """"""Tests that the decomposition of the CY gate is correct"""""" <TAB> op = qml . CY ( wires = [ 0 , 1 ] ) <TAB> res = op . decomposition ( op . wires ) <TAB> mats = [ ] <TAB> for i in reversed ( res ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mats . append ( np . kron ( i . matrix , np . eye ( 2 ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mats . append ( i . matrix ) <TAB> decomposed_matrix = np . linalg . multi_dot ( mats ) <TAB> assert np . allclose ( decomposed_matrix , op . matrix , atol = tol , rtol = 0 ) ","if len ( i . wires ) == 1 : 
","if i . ndim == 1 :
",36.26,29.37,False
"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> if not start : <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start : <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs ","if stmt == lines [ lidx ] : 
","if stmt != "" , "" :
",28.49,11.59,False
"def init_params ( net ) : <TAB> """"""Init layer parameters."""""" <TAB> for module in net . modules ( ) : <TAB> <TAB> if isinstance ( module , nn . Conv2d ) : <TAB> <TAB> <TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . BatchNorm2d ) : <TAB> <TAB> <TAB> init . constant ( module . weight , 1 ) <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . Linear ) : <TAB> <TAB> <TAB> init . normal ( module . weight , std = 1e-3 ) <TAB> <TAB> <TAB> if module . bias : <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) ","if module . bias : 
","if module . bias :
",100.0,100.0,True
"def _get_directory_size_in_bytes ( directory ) : <TAB> total = 0 <TAB> try : <TAB> <TAB> for entry in os . scandir ( directory ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # if it's a file, use stat() function <TAB> <TAB> <TAB> <TAB> total + = entry . stat ( ) . st_size <TAB> <TAB> <TAB> elif entry . is_dir ( ) : <TAB> <TAB> <TAB> <TAB> # if it's a directory, recursively call this function <TAB> <TAB> <TAB> <TAB> total + = _get_directory_size_in_bytes ( entry . path ) <TAB> except NotADirectoryError : <TAB> <TAB> # if `directory` isn't a directory, get the file size then <TAB> <TAB> return os . path . getsize ( directory ) <TAB> except PermissionError : <TAB> <TAB> # if for whatever reason we can't open the folder, return 0 <TAB> <TAB> return 0 <TAB> return total ","if entry . is_file ( ) : 
","if entry . is_file ( ) :
",100.0,100.0,True
"def run_cmd ( self , util , to , always_push_mark = False ) : <TAB> if to == "" bof "" : <TAB> <TAB> util . push_mark_and_goto_position ( 0 ) <TAB> elif to == "" eof "" : <TAB> <TAB> util . push_mark_and_goto_position ( self . view . size ( ) ) <TAB> elif to in ( "" eow "" , "" bow "" ) : <TAB> <TAB> visible = self . view . visible_region ( ) <TAB> <TAB> pos = visible . a if to == "" bow "" else visible . b <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> util . push_mark_and_goto_position ( pos ) <TAB> <TAB> else : <TAB> <TAB> <TAB> util . set_cursors ( [ sublime . Region ( pos ) ] ) ","if always_push_mark : 
","if always_push_mark :
",78.12,100.0,True
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> if "" results.train_y_misclass "" in dd : <TAB> <TAB> <TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) ) ","if "" hyper_parameters "" in key : 
","if value != numpy . inf :
",27.05,5.8,False
"def clean_vc_position ( self ) : <TAB> vc_position = self . cleaned_data [ "" vc_position "" ] <TAB> if self . validate_vc_position : <TAB> <TAB> conflicting_members = Device . objects . filter ( <TAB> <TAB> <TAB> virtual_chassis = self . instance . virtual_chassis , vc_position = vc_position <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise forms . ValidationError ( <TAB> <TAB> <TAB> <TAB> "" A virtual chassis member already exists in position  {} . "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> vc_position <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return vc_position ","if conflicting_members . exists ( ) : 
","if conflicting_members . exists ( ) :
",100.0,100.0,True
"def cal_pads ( auto_pad , pad_shape ) : <TAB> spatial_size = len ( pad_shape ) <TAB> pads = [ 0 ] * spatial_size * 2 <TAB> for i in range ( spatial_size ) : <TAB> <TAB> if auto_pad == "" SAME_LOWER "" : <TAB> <TAB> <TAB> pads [ i + spatial_size ] = pad_shape [ i ] / / 2 <TAB> <TAB> <TAB> pads [ i ] = pad_shape [ i ] - pads [ i + spatial_size ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pads [ i ] = pad_shape [ i ] / / 2 <TAB> <TAB> <TAB> pads [ i + spatial_size ] = pad_shape [ i ] - pads [ i ] <TAB> return pads ","elif auto_pad == "" SAME_UPPER "" : 
","elif auto_pad == "" SAME_UPPER "" :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def test_cwl_rnaseq ( self , install_test_files ) : <TAB> with install_cwl_test_files ( ) as work_dir : <TAB> <TAB> with utils . chdir ( os . path . join ( work_dir , "" rnaseq "" ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( "" cromwell_work "" ) <TAB> <TAB> <TAB> subprocess . check_call ( <TAB> <TAB> <TAB> <TAB> [ "" bcbio_vm.py "" , "" cwlrun "" , "" cromwell "" , "" rnaseq-workflow "" ] <TAB> <TAB> <TAB> ) ","if os . path . exists ( "" cromwell_work "" ) : 
","if os . path . exists ( "" cromwell_work "" ) :
",100.0,100.0,True
"def files_per_version ( self ) : <TAB> xpath = "" ./files/file "" <TAB> files = self . root . findall ( xpath ) <TAB> versions = { } <TAB> for file in files : <TAB> <TAB> vfile = file . findall ( "" version "" ) <TAB> <TAB> for version in vfile : <TAB> <TAB> <TAB> nb = version . attrib [ "" nb "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> versions [ nb ] = [ ] <TAB> <TAB> <TAB> versions [ nb ] . append ( file . attrib [ "" url "" ] ) <TAB> return versions ","if not nb in versions : 
","if nb not in versions :
",43.26,35.93,False
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # SQLite doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" SQLite backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB> <TAB> <TAB> ) <TAB> return six . text_type ( value ) ","if settings . USE_TZ : 
","if settings . USE_TZ :
",100.0,100.0,True
"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB> <TAB> t = threading . current_thread ( ) <TAB> <TAB> t . name = func . __name__ <TAB> <TAB> try : <TAB> <TAB> <TAB> t . status = func ( * args , * * kwargs ) <TAB> <TAB> except EscapeException as e :<TAB> # user aborted <TAB> <TAB> <TAB> t . status = "" aborted by user "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> t . exception = e <TAB> <TAB> <TAB> t . status = "" exception "" <TAB> <TAB> <TAB> vd . exceptionCaught ( e ) <TAB> <TAB> if t . sheet : <TAB> <TAB> <TAB> t . sheet . currentThreads . remove ( t ) ","if status : 
","if status :
",78.12,0.0,False
"def ESP ( phrase ) : <TAB> for num , name in enumerate ( devname ) : <TAB> <TAB> if name . lower ( ) in phrase : <TAB> <TAB> <TAB> dev = devid [ num ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ctrl = "" =ON "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning On  "" + name ) <TAB> <TAB> <TAB> elif custom_action_keyword [ "" Dict "" ] [ "" Off "" ] in phrase : <TAB> <TAB> <TAB> <TAB> ctrl = "" =OFF "" <TAB> <TAB> <TAB> <TAB> say ( "" Turning Off  "" + name ) <TAB> <TAB> <TAB> rq = requests . head ( "" https:// "" + ip + dev + ctrl , verify = False ) ","if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase : 
","if custom_action_keyword [ "" Dict "" ] [ "" On "" ] in phrase :
",100.0,100.0,True
"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = { } <TAB> for _ , name , data_type , not_null , _ , primary_key in rows : <TAB> <TAB> parts = [ data_type ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts . append ( "" PRIMARY KEY "" ) <TAB> <TAB> if not_null : <TAB> <TAB> <TAB> parts . append ( "" NOT NULL "" ) <TAB> <TAB> result [ name ] = "" "" . join ( parts ) <TAB> return result ","if primary_key : 
","if primary_key :
",78.12,100.0,True
"def _validate_forward_input ( x , n_in ) : <TAB> if n_in != 1 : <TAB> <TAB> if not isinstance ( x , ( tuple , list ) ) : <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> f "" Expected input to be a tuple or list; instead got  { type ( x ) } . "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" Input tuple length ( { len ( x ) } ) does not equal required  "" <TAB> <TAB> <TAB> <TAB> f "" number of inputs ( { n_in } ). "" <TAB> <TAB> <TAB> ) ","if len ( x ) != n_in : 
","if len ( x ) != n_in :
",100.0,100.0,True
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> if isinstance ( val , compat . string_types ) : <TAB> <TAB> <TAB> return ""<TAB> %s "" % val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ""<TAB> %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> elif val < 1024 * * 3 : <TAB> <TAB> <TAB> return ""<TAB> %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ""<TAB> %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return ""<TAB> %s "" % val ","elif val < 1024 * * 2 : 
","elif val < 1024 * * 1 :
",85.56,70.71,False
"def get_path_name ( self ) : <TAB> if self . is_root ( ) : <TAB> <TAB> return "" @ "" + self . name <TAB> else : <TAB> <TAB> parent_name = self . parent . get_path_name ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" / "" . join ( [ parent_name , "" @ "" + self . name ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" @ "" + self . name ","if parent_name : 
","if parent_name :
",78.12,100.0,True
"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB> <TAB> elif k == "" created_at "" : <TAB> <TAB> <TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( lst , k , v ) <TAB> return lst ","if k == "" user "" : 
","if k == "" user "" :
",100.0,100.0,True
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> if not py_file . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" c "" ) <TAB> <TAB> if self . optimize > 0 : <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files ","if self . compile : 
","if self . compile > 0 :
",61.88,43.47,False
"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB> <TAB> if isinstance ( self . subheader , RenderedContent ) : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader <TAB> return d ","if isinstance ( self . header , RenderedContent ) : 
","if isinstance ( self . header , RenderedContent ) :
",100.0,100.0,True
"def makeSomeFiles ( pathobj , dirdict ) : <TAB> pathdict = { } <TAB> for ( key , value ) in dirdict . items ( ) : <TAB> <TAB> child = pathobj . child ( key ) <TAB> <TAB> if isinstance ( value , bytes ) : <TAB> <TAB> <TAB> pathdict [ key ] = child <TAB> <TAB> <TAB> child . setContent ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> child . createDirectory ( ) <TAB> <TAB> <TAB> pathdict [ key ] = makeSomeFiles ( child , value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" only strings and dicts allowed as values "" ) <TAB> return pathdict ","elif isinstance ( value , dict ) : 
","elif isinstance ( value , dict ) :
",100.0,100.0,True
"def Restore ( self ) : <TAB> picker , obj = self . _window , self . _pObject <TAB> value = obj . RestoreValue ( PERSIST_FILEDIRPICKER_PATH ) <TAB> if value is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if type ( value ) == list : <TAB> <TAB> <TAB> <TAB> value = value [ - 1 ] <TAB> <TAB> picker . SetPath ( value ) <TAB> <TAB> return True <TAB> return False ","if issubclass ( picker . __class__ , wx . FileDialog ) : 
","if value != "" "" :
",26.07,2.16,False
"def recv ( self , buffer_size ) : <TAB> try : <TAB> <TAB> return super ( SSLConnection , self ) . recv ( buffer_size ) <TAB> except ssl . SSLError as err : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> if err . args [ 0 ] in ( ssl . SSL_ERROR_EOF , ssl . SSL_ERROR_ZERO_RETURN ) : <TAB> <TAB> <TAB> self . handle_close ( ) <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> raise ","if err . args [ 0 ] in ( ssl . SSL_ERROR_WANT_READ , ssl . SSL_ERROR_WANT_WRITE ) : 
","if err . args [ 0 ] == ssl . SSL_ERROR_EOF :
",55.6,29.88,False
"def IncrementErrorCount ( self , category ) : <TAB> """"""Bumps the module's error statistic."""""" <TAB> self . error_count + = 1 <TAB> if self . counting in ( "" toplevel "" , "" detailed "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> category = category . split ( "" / "" ) [ 0 ] <TAB> <TAB> if category not in self . errors_by_category : <TAB> <TAB> <TAB> self . errors_by_category [ category ] = 0 <TAB> <TAB> self . errors_by_category [ category ] + = 1 ","if self . counting != "" detailed "" : 
","if "" / "" in category :
",31.8,6.05,False
"def _get_y ( self , data_inst ) : <TAB> if self . stratified : <TAB> <TAB> y = [ v for i , v in data_inst . mapValues ( lambda v : v . label ) . collect ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y = self . transform_regression_label ( data_inst ) <TAB> else : <TAB> <TAB> # make dummy y <TAB> <TAB> y = [ 0 ] * ( data_inst . count ( ) ) <TAB> return y ","if self . need_transform : 
","if self . transform_regression_label :
",64.48,21.11,False
"def test_all_project_files ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB> <TAB> # XXX something with newlines goes wrong on Windows. <TAB> <TAB> return <TAB> for filepath in support . all_project_files ( ) : <TAB> <TAB> with open ( filepath , "" rb "" ) as fp : <TAB> <TAB> <TAB> encoding = tokenize . detect_encoding ( fp . readline ) [ 0 ] <TAB> <TAB> self . assertIsNotNone ( encoding , "" can ' t detect encoding for  %s "" % filepath ) <TAB> <TAB> with open ( filepath , "" r "" ) as fp : <TAB> <TAB> <TAB> source = fp . read ( ) <TAB> <TAB> <TAB> source = source . decode ( encoding ) <TAB> <TAB> tree = driver . parse_string ( source ) <TAB> <TAB> new = unicode ( tree ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . fail ( "" Idempotency failed:  %s "" % filepath ) ","if diff ( filepath , new , encoding ) : 
","if not driver . save_file ( filepath , new ) :
",40.6,23.9,False
"def test_resource_arn_override_generator ( self ) : <TAB> overrides = set ( ) <TAB> for k , v in manager . resources . items ( ) : <TAB> <TAB> arn_gen = bool ( v . __dict__ . get ( "" get_arns "" ) or v . __dict__ . get ( "" generate_arn "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> overrides . add ( k ) <TAB> overrides = overrides . difference ( <TAB> <TAB> { <TAB> <TAB> <TAB> "" account "" , <TAB> <TAB> <TAB> "" s3 "" , <TAB> <TAB> <TAB> "" hostedzone "" , <TAB> <TAB> <TAB> "" log-group "" , <TAB> <TAB> <TAB> "" rest-api "" , <TAB> <TAB> <TAB> "" redshift-snapshot "" , <TAB> <TAB> <TAB> "" rest-stage "" , <TAB> <TAB> } <TAB> ) <TAB> if overrides : <TAB> <TAB> raise ValueError ( "" unknown arn overrides in  %s "" % ( "" ,  "" . join ( overrides ) ) ) ","if arn_gen : 
","if arn_gen :
",78.12,100.0,True
"def _check_dsl_runner ( self ) - > None : <TAB> """"""Checks if runner in dsl is Kubeflow V2 runner."""""" <TAB> with open ( self . flags_dict [ labels . PIPELINE_DSL_PATH ] , "" r "" ) as f : <TAB> <TAB> dsl_contents = f . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" KubeflowV2DagRunner not found in dsl. "" ) ","if "" KubeflowV2DagRunner "" not in dsl_contents : 
","if "" KubeflowV2DagRunner "" in dsl_contents :
",69.91,66.9,False
"def create_warehouse ( warehouse_name , properties = None , company = None ) : <TAB> if not company : <TAB> <TAB> company = "" _Test Company "" <TAB> warehouse_id = erpnext . encode_company_abbr ( warehouse_name , company ) <TAB> if not frappe . db . exists ( "" Warehouse "" , warehouse_id ) : <TAB> <TAB> warehouse = frappe . new_doc ( "" Warehouse "" ) <TAB> <TAB> warehouse . warehouse_name = warehouse_name <TAB> <TAB> warehouse . parent_warehouse = "" All Warehouses - _TCUV "" <TAB> <TAB> warehouse . company = company <TAB> <TAB> warehouse . account = get_warehouse_account ( warehouse_name , company ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warehouse . update ( properties ) <TAB> <TAB> warehouse . save ( ) <TAB> <TAB> return warehouse . name <TAB> else : <TAB> <TAB> return warehouse_id ","if properties : 
","if properties :
",78.12,0.0,False
"def _parse ( self , contents ) : <TAB> entries = [ ] <TAB> hostnames_found = set ( ) <TAB> for line in contents . splitlines ( ) : <TAB> <TAB> if not len ( line . strip ( ) ) : <TAB> <TAB> <TAB> entries . append ( ( "" blank "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> ( head , tail ) = chop_comment ( line . strip ( ) , "" # "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> entries . append ( ( "" all_comment "" , [ line ] ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> entries . append ( ( "" hostname "" , [ head , tail ] ) ) <TAB> <TAB> hostnames_found . add ( head ) <TAB> if len ( hostnames_found ) > 1 : <TAB> <TAB> raise IOError ( "" Multiple hostnames ( %s ) found! "" % ( hostnames_found ) ) <TAB> return entries ","if not len ( head ) : 
","if head == "" # "" :
",27.2,7.27,False
"def _get_omega ( self ) : <TAB> if self . _omega is None : <TAB> <TAB> n = self . get_drift_dim ( ) / / 2 <TAB> <TAB> omg = sympl . calc_omega ( n ) <TAB> <TAB> if self . oper_dtype == Qobj : <TAB> <TAB> <TAB> self . _omega = Qobj ( omg , dims = self . dyn_dims ) <TAB> <TAB> <TAB> self . _omega_qobj = self . _omega <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _omega = sp . csr_matrix ( omg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _omega = omg <TAB> return self . _omega ","elif self . oper_dtype == sp . csr_matrix : 
","elif self . oper_dtype == csr_matrix :
",61.39,70.63,False
"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB> <TAB> for k , v in data . items ( ) : <TAB> <TAB> <TAB> if k == key : <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> out = get_in_inputs ( key , v ) <TAB> <TAB> <TAB> <TAB> if out : <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB> <TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB> <TAB> out = [ x for x in out if x ] <TAB> <TAB> if out : <TAB> <TAB> <TAB> return out [ 0 ] ","elif isinstance ( v , ( list , tuple , dict ) ) : 
","if isinstance ( v , ( dict , list ) ) :
",43.76,38.87,False
def visit_binary ( binary ) : <TAB> if binary . operator == operators . eq : <TAB> <TAB> cols = util . column_set ( chain ( * [ c . proxy_set for c in columns . difference ( omit ) ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for c in reversed ( columns ) : <TAB> <TAB> <TAB> <TAB> if c . shares_lineage ( binary . right ) and ( <TAB> <TAB> <TAB> <TAB> <TAB> not only_synonyms or c . name == binary . left . name <TAB> <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> <TAB> omit . add ( c ) <TAB> <TAB> <TAB> <TAB> <TAB> break ,"if binary . left in cols and binary . right in cols : 
","if not only_synonyms :
",25.75,3.01,False
"def wait_tasks_or_abort ( futures , timeout = 60 , kill_switch_ev = None ) : <TAB> try : <TAB> <TAB> LazySingletonTasksCoordinator . wait_tasks ( <TAB> <TAB> <TAB> futures , return_when = FIRST_EXCEPTION , raise_exceptions = True <TAB> <TAB> ) <TAB> except Exception as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Used when we want to keep both raise the exception and wait for all tasks to finish <TAB> <TAB> <TAB> kill_switch_ev . set ( ) <TAB> <TAB> <TAB> LazySingletonTasksCoordinator . wait_tasks ( <TAB> <TAB> <TAB> <TAB> futures , <TAB> <TAB> <TAB> <TAB> return_when = ALL_COMPLETED , <TAB> <TAB> <TAB> <TAB> raise_exceptions = False , <TAB> <TAB> <TAB> <TAB> timeout = timeout , <TAB> <TAB> <TAB> ) <TAB> <TAB> raise e ","if kill_switch_ev is not None : 
","if kill_switch_ev is not None :
",100.0,100.0,True
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , np . ndarray ) and s . size == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if s is None : 
","if s is None :
",100.0,100.0,True
"def setVaName ( self , va , parent = None ) : <TAB> if parent is None : <TAB> <TAB> parent = self <TAB> curname = self . vw . getName ( va ) <TAB> if curname is None : <TAB> <TAB> curname = "" "" <TAB> name , ok = QInputDialog . getText ( parent , "" Enter... "" , "" Name "" , text = curname ) <TAB> if ok : <TAB> <TAB> name = str ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Duplicate Name:  %s "" % name ) <TAB> <TAB> self . vw . makeName ( va , name ) ","if self . vw . vaByName ( name ) : 
","if name in self . vw . names :
",48.79,30.72,False
"def generic_tag_compiler ( params , defaults , name , node_class , parser , token ) : <TAB> "" Returns a template.Node subclass. "" <TAB> bits = token . split_contents ( ) [ 1 : ] <TAB> bmax = len ( params ) <TAB> def_len = defaults and len ( defaults ) or 0 <TAB> bmin = bmax - def_len <TAB> if len ( bits ) < bmin or len ( bits ) > bmax : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message = "" %s  takes  %s  arguments "" % ( name , bmin ) <TAB> <TAB> else : <TAB> <TAB> <TAB> message = "" %s  takes between  %s  and  %s  arguments "" % ( name , bmin , bmax ) <TAB> <TAB> raise TemplateSyntaxError ( message ) <TAB> return node_class ( bits ) ","if bmin == bmax : 
","if bits == def_len :
",53.65,13.13,False
"def extract_segmentation_mask ( annotation ) : <TAB> poly_specs = annotation [ DensePoseDataRelative . S_KEY ] <TAB> if isinstance ( poly_specs , torch . Tensor ) : <TAB> <TAB> # data is already given as mask tensors, no need to decode <TAB> <TAB> return poly_specs <TAB> import pycocotools . mask as mask_utils <TAB> segm = torch . zeros ( ( DensePoseDataRelative . MASK_SIZE , ) * 2 , dtype = torch . float32 ) <TAB> for i in range ( DensePoseDataRelative . N_BODY_PARTS ) : <TAB> <TAB> poly_i = poly_specs [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mask_i = mask_utils . decode ( poly_i ) <TAB> <TAB> <TAB> segm [ mask_i > 0 ] = i + 1 <TAB> return segm ","if poly_i : 
","if poly_i > 0 :
",34.79,43.47,False
"def module_list ( target , fast ) : <TAB> """"""Find the list of modules to be compiled"""""" <TAB> modules = [ ] <TAB> native = native_modules ( target ) <TAB> basedir = os . path . join ( ouroboros_repo_folder ( ) , "" ouroboros "" ) <TAB> for name in os . listdir ( basedir ) : <TAB> <TAB> module_name , ext = os . path . splitext ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if module_name not in IGNORE_MODULES and module_name not in native : <TAB> <TAB> <TAB> <TAB> if not ( fast and module_name in KNOWN_PROBLEM_MODULES ) : <TAB> <TAB> <TAB> <TAB> <TAB> modules . append ( module_name ) <TAB> return set ( modules ) ","if ext == "" .py "" or ext == "" "" and os . path . isdir ( os . path . join ( basedir , name ) ) : 
","if ext == "" .py "" :
",36.13,6.18,False
"def filelist_from_patterns ( pats , rootdir = None ) : <TAB> if rootdir is None : <TAB> <TAB> rootdir = "" . "" <TAB> # filelist = [] <TAB> fileset = set ( [ ] ) <TAB> lines = [ line . strip ( ) for line in pats ] <TAB> for line in lines : <TAB> <TAB> pat = line [ 2 : ] <TAB> <TAB> newfiles = glob ( osp . join ( rootdir , pat ) ) <TAB> <TAB> if line . startswith ( "" + "" ) : <TAB> <TAB> <TAB> fileset . update ( newfiles ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fileset . difference_update ( newfiles ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" line must start with + or - "" ) <TAB> filelist = list ( fileset ) <TAB> return filelist ","elif line . startswith ( "" - "" ) : 
","elif line . startswith ( "" - "" ) :
",100.0,100.0,True
"def get_upstream_statuses_events ( self , upstream : Set ) - > Dict [ str , V1Statuses ] : <TAB> statuses_by_refs = { u : [ ] for u in upstream } <TAB> events = self . events or [ ]<TAB> # type: List[V1EventTrigger] <TAB> for e in events : <TAB> <TAB> entity_ref = contexts_refs . get_entity_ref ( e . ref ) <TAB> <TAB> if not entity_ref : <TAB> <TAB> <TAB> continue <TAB> <TAB> if entity_ref not in statuses_by_refs : <TAB> <TAB> <TAB> continue <TAB> <TAB> for kind in e . kinds : <TAB> <TAB> <TAB> status = V1EventKind . events_statuses_mapping . get ( kind ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> statuses_by_refs [ entity_ref ] . append ( status ) <TAB> return statuses_by_refs ","if status : 
","if status :
",78.12,0.0,False
"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> info , reference = value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB> <TAB> <TAB> self . _infos . append ( info ) <TAB> <TAB> if reference not in self . _reverse_references : <TAB> <TAB> <TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB> <TAB> <TAB> self . _references . append ( reference ) <TAB> <TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB> <TAB> <TAB> self . _reverse_infos [ info ] , <TAB> <TAB> <TAB> self . _reverse_references [ reference ] , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) ) ","if info not in self . _reverse_infos : 
","if info not in self . _reverse_infos :
",100.0,100.0,True
"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if combo . GetLabel ( ) == "" TR_VIRTUAL "" : <TAB> <TAB> <TAB> <TAB> style = style | HTL . TR_VIRTUAL <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB> <TAB> self . SetAGWWindowStyleFlag ( style ) ","if combo . GetValue ( ) == 1 : 
","if combo . HasLabel ( ) :
",45.59,20.96,False
"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB> <TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB> <TAB> <TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB> <TAB> <TAB> <TAB> <TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self . _CSRFtoken != None : <TAB> <TAB> <TAB> <TAB> break ","if c . strip ( ) . startswith ( "" CSRF-Token- "" ) : 
","if c . startswith ( "" Set-Cookie-Value: "" ) :
",49.49,32.15,False
"def test_page_size_matching_max_returned_rows ( <TAB> app_client_returned_rows_matches_page_size , ) : <TAB> fetched = [ ] <TAB> path = "" /fixtures/no_primary_key.json "" <TAB> while path : <TAB> <TAB> response = app_client_returned_rows_matches_page_size . get ( path ) <TAB> <TAB> fetched . extend ( response . json [ "" rows "" ] ) <TAB> <TAB> assert len ( response . json [ "" rows "" ] ) in ( 1 , 50 ) <TAB> <TAB> path = response . json [ "" next_url "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = path . replace ( "" http://localhost "" , "" "" ) <TAB> assert 201 == len ( fetched ) ","if path : 
","if path :
",78.12,0.0,False
"def get_mapping_exception_message ( mappings : List [ Tuple [ Text , Text ] ] ) : <TAB> """"""Return a message given a list of duplicates."""""" <TAB> message = "" "" <TAB> for name , action_name in mappings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> message + = "" \n "" <TAB> <TAB> message + = ( <TAB> <TAB> <TAB> "" Intent  ' {} '  is set to trigger action  ' {} ' , which is  "" <TAB> <TAB> <TAB> "" not defined in the domain. "" . format ( name , action_name ) <TAB> <TAB> ) <TAB> return message ","if message : 
","if message :
",78.12,0.0,False
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> if re_han . match ( blk ) : <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> if word not in Force_Split_Words : <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> yield x ,"if x : 
","if x not in Force_Split_Words :
",34.04,9.29,False
"def chop ( expr , delta = 10.0 * * ( - 10.0 ) ) : <TAB> if isinstance ( expr , Real ) : <TAB> <TAB> if - delta < expr . get_float_value ( ) < delta : <TAB> <TAB> <TAB> return Integer ( 0 ) <TAB> elif isinstance ( expr , Complex ) and expr . is_inexact ( ) : <TAB> <TAB> real , imag = expr . real , expr . imag <TAB> <TAB> if - delta < real . get_float_value ( ) < delta : <TAB> <TAB> <TAB> real = Integer ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> imag = Integer ( 0 ) <TAB> <TAB> return Complex ( real , imag ) <TAB> elif isinstance ( expr , Expression ) : <TAB> <TAB> return Expression ( chop ( expr . head ) , * [ chop ( leaf ) for leaf in expr . leaves ] ) <TAB> return expr ","if - delta < imag . get_float_value ( ) < delta : 
","if - delta < imag . get_float_value ( ) < delta :
",100.0,100.0,True
"def make_row ( self ) : <TAB> res = [ ] <TAB> for i in range ( self . num_cols ) : <TAB> <TAB> t = sqlite3_column_type ( self . stmnt , i ) <TAB> <TAB> # print(""type"", t) <TAB> <TAB> if t == SQLITE_INTEGER : <TAB> <TAB> <TAB> res . append ( sqlite3_column_int ( self . stmnt , i ) ) <TAB> <TAB> elif t == SQLITE_FLOAT : <TAB> <TAB> <TAB> res . append ( sqlite3_column_double ( self . stmnt , i ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res . append ( sqlite3_column_text ( self . stmnt , i ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError <TAB> return tuple ( res ) ","elif t == SQLITE_TEXT : 
","elif t == SQLITE_TEXT :
",100.0,100.0,True
"def try_convert ( self , string ) : <TAB> string = string . strip ( ) <TAB> try : <TAB> <TAB> return int ( string ) <TAB> except : <TAB> <TAB> try : <TAB> <TAB> <TAB> return float ( string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> if string == "" True "" : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> return string ","if string == "" False "" : 
","if string == "" False "" :
",100.0,100.0,True
"def configure_create_table_epilogue ( store ) : <TAB> for val in [ "" "" , ""  ENGINE=InnoDB "" ] : <TAB> <TAB> store . config [ "" create_table_epilogue "" ] = val <TAB> <TAB> store . _set_sql_flavour ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> store . log . info ( "" create_table_epilogue= ' %s ' "" , val ) <TAB> <TAB> <TAB> return <TAB> raise Exception ( "" Can not create a transactional table. "" ) ","if store . _test_transaction ( ) : 
","if store . _transactional_enable ( ) :
",63.85,39.28,False
"def _check_rule ( self , match , target_dict , cred_dict ) : <TAB> """"""Recursively checks credentials based on the brains rules."""""" <TAB> try : <TAB> <TAB> new_match_list = self . rules [ match ] <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_match_list = ( "" rule: %s "" % self . default_rule , ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return self . check ( new_match_list , target_dict , cred_dict ) ","if self . default_rule and match != self . default_rule : 
","if self . default_rule :
",49.31,27.65,False
"def get_civil_names ( self ) : <TAB> congresspeople_ids = self . get_all_congresspeople_ids ( ) <TAB> for i , congress_id in enumerate ( congresspeople_ids ) : <TAB> <TAB> if not np . math . isnan ( float ( congress_id ) ) : <TAB> <TAB> <TAB> percentage = i / self . total * 100 <TAB> <TAB> <TAB> msg = "" Processed  {}  out of  {}  ( {:.2f} % ) "" <TAB> <TAB> <TAB> print ( msg . format ( i , self . total , percentage ) , end = "" \r "" ) <TAB> <TAB> <TAB> data = self . fetch_data_repository ( congress_id ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield dict ( data ) ","if data is not None : 
","if data :
",29.58,0.0,False
"def parse_network_whitelist ( self , network_whitelist_location ) : <TAB> networks = [ ] <TAB> with open ( network_whitelist_location , "" r "" ) as text_file : <TAB> <TAB> for line in text_file : <TAB> <TAB> <TAB> line = line . strip ( ) . strip ( "" ' "" ) . strip ( ' "" ' ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> networks . append ( line ) <TAB> return networks ","if isIPv4 ( line ) or isIPv6 ( line ) : 
","if line and not line . startswith ( "" # "" ) :
",27.38,8.13,False
"def _pick ( self , cum ) : <TAB> if self . _isleaf ( ) : <TAB> <TAB> return self . bd [ 0 ] , self . s <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . left . _pick ( cum ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . right . _pick ( cum - self . left . s ) ","if cum < self . left . s : 
","if cum < self . left . s :
",100.0,100.0,True
"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> if len ( value ) not in ( 2 , 3 ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" When setting content_range to a list/tuple, it must  "" <TAB> <TAB> <TAB> <TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> begin , end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else : <TAB> <TAB> <TAB> begin , end , length = value <TAB> <TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB> <TAB> return None <TAB> return value ","if len ( value ) == 2 : 
","if len ( value ) == 2 :
",100.0,100.0,True
"def make_index_fields ( rec ) : <TAB> fields = { } <TAB> for k , v in rec . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fields [ k ] = v <TAB> <TAB> <TAB> continue <TAB> <TAB> if k == "" full_title "" : <TAB> <TAB> <TAB> fields [ "" title "" ] = [ read_short_title ( v ) ] <TAB> return fields ","if k in ( "" lccn "" , "" oclc "" , "" isbn "" ) : 
","if k . startswith ( "" _ "" ) :
",39.75,11.4,False
"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB> <TAB> trans_len = len ( translation ) <TAB> <TAB> ind = np . random . randint ( trans_len ) <TAB> <TAB> action = np . random . choice ( actions ) <TAB> <TAB> if action == "" deletion "" : <TAB> <TAB> <TAB> del translation [ ind ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ind_rep = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation [ ind ] = translation [ ind_rep ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ind_insert = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation ","elif action == "" replacement "" : 
","elif action == "" repaint "" :
",74.63,59.46,False
"def __call__ ( self , text : str ) - > str : <TAB> for t in self . cleaner_types : <TAB> <TAB> if t == "" tacotron "" : <TAB> <TAB> <TAB> text = tacotron_cleaner . cleaners . custom_english_cleaners ( text ) <TAB> <TAB> elif t == "" jaconv "" : <TAB> <TAB> <TAB> text = jaconv . normalize ( text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if vietnamese_cleaners is None : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" Please install underthesea "" ) <TAB> <TAB> <TAB> text = vietnamese_cleaners . vietnamese_cleaner ( text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( f "" Not supported: type= { t } "" ) <TAB> return text ","elif t == "" vietnamese "" : 
","elif t == "" vietnamese "" :
",100.0,100.0,True
"def hook_GetVariable ( ql , address , params ) : <TAB> if params [ "" VariableName "" ] in ql . env : <TAB> <TAB> var = ql . env [ params [ "" VariableName "" ] ] <TAB> <TAB> read_len = read_int64 ( ql , params [ "" DataSize "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> write_int64 ( ql , params [ "" Attributes "" ] , 0 ) <TAB> <TAB> write_int64 ( ql , params [ "" DataSize "" ] , len ( var ) ) <TAB> <TAB> if read_len < len ( var ) : <TAB> <TAB> <TAB> return EFI_BUFFER_TOO_SMALL <TAB> <TAB> if params [ "" Data "" ] != 0 : <TAB> <TAB> <TAB> ql . mem . write ( params [ "" Data "" ] , var ) <TAB> <TAB> return EFI_SUCCESS <TAB> return EFI_NOT_FOUND ","if params [ "" Attributes "" ] != 0 : 
","if read_len == 0 :
",27.56,15.18,False
"def test_setupapp ( self , overrideRootMenu ) : <TAB> "" Call setupApp with each possible graphics type. "" <TAB> root = self . root <TAB> flist = FileList ( root ) <TAB> for tktype in alltypes : <TAB> <TAB> with self . subTest ( tktype = tktype ) : <TAB> <TAB> <TAB> macosx . _tk_type = tktype <TAB> <TAB> <TAB> macosx . setupApp ( root , flist ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( overrideRootMenu . called ) <TAB> <TAB> <TAB> overrideRootMenu . reset_mock ( ) ","if tktype in ( "" carbon "" , "" cocoa "" ) : 
","if overrideRootMenu :
",25.66,0.0,False
"def names ( self , persistent = None ) : <TAB> u = set ( ) <TAB> result = [ ] <TAB> for s in [ <TAB> <TAB> self . __storage ( None ) , <TAB> <TAB> self . __storage ( self . __category ) , <TAB> ] : <TAB> <TAB> for b in s : <TAB> <TAB> <TAB> if persistent is not None and b . persistent != persistent : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if b . name not in u : <TAB> <TAB> <TAB> <TAB> result . append ( b . name ) <TAB> <TAB> <TAB> <TAB> u . add ( b . name ) <TAB> return result ","if b . name . startswith ( "" __ "" ) : 
","if b . name in ( "" * "" , "" ** "" ) :
",47.49,24.68,False
"def _check_extra_specs ( key , value = None ) : <TAB> extra_specs = diff . get ( "" extra_specs "" ) <TAB> specific_type = extra_specs . get ( key ) if extra_specs else None <TAB> old_type = None <TAB> new_type = None <TAB> if specific_type : <TAB> <TAB> old_type , new_type = specific_type <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> old_type = True if old_type and old_type . upper ( ) == value else False <TAB> <TAB> <TAB> new_type = True if new_type and new_type . upper ( ) == value else False <TAB> return old_type , new_type ","if value : 
","if value :
",78.12,0.0,False
"def _write_lock_file ( self , repo , force = True ) :<TAB> # type: (Repository, bool) -> None <TAB> if force or ( self . _update and self . _write_lock ) : <TAB> <TAB> updated_lock = self . _locker . set_lock_data ( self . _package , repo . packages ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _io . write_line ( "" "" ) <TAB> <TAB> <TAB> self . _io . write_line ( "" <info>Writing lock file</> "" ) ","if updated_lock : 
","if updated_lock is None :
",34.79,43.47,False
"def process_message ( self , msg ) : <TAB> if msg [ "" type "" ] == "" sample "" : <TAB> <TAB> batch_shape = msg [ "" fn "" ] . batch_shape <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> batch_shape = [ 1 ] * ( - self . dim - len ( batch_shape ) ) + list ( batch_shape ) <TAB> <TAB> <TAB> batch_shape [ self . dim ] = self . size <TAB> <TAB> <TAB> msg [ "" fn "" ] = msg [ "" fn "" ] . expand ( torch . Size ( batch_shape ) ) ","if len ( batch_shape ) < - self . dim or batch_shape [ self . dim ] != self . size : 
","if self . dim > 0 :
",33.1,1.6,False
"def _test_reducibility ( self ) : <TAB> # make a copy of the graph <TAB> graph = networkx . DiGraph ( self . _graph ) <TAB> # preprocess: make it a super graph <TAB> self . _make_supergraph ( graph ) <TAB> while True : <TAB> <TAB> changed = False <TAB> <TAB> # find a node with a back-edge, remove the edge (deleting the loop), and replace it with a MultiNode <TAB> <TAB> changed | = self . _remove_self_loop ( graph ) <TAB> <TAB> # find a node that has only one predecessor, and merge it with its predecessor (replace them with a <TAB> <TAB> # MultiNode) <TAB> <TAB> changed | = self . _merge_single_entry_node ( graph ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # a fixed-point is reached <TAB> <TAB> <TAB> break ","if not changed : 
","if changed :
",34.18,0.0,False
"def __init__ ( self , roberta , num_classes = 2 , dropout = 0.0 , prefix = None , params = None ) : <TAB> super ( RoBERTaClassifier , self ) . __init__ ( prefix = prefix , params = params ) <TAB> self . roberta = roberta <TAB> self . _units = roberta . _units <TAB> with self . name_scope ( ) : <TAB> <TAB> self . classifier = nn . HybridSequential ( prefix = prefix ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB> <TAB> self . classifier . add ( nn . Dense ( units = self . _units , activation = "" tanh "" ) ) <TAB> <TAB> if dropout : <TAB> <TAB> <TAB> self . classifier . add ( nn . Dropout ( rate = dropout ) ) <TAB> <TAB> self . classifier . add ( nn . Dense ( units = num_classes ) ) ","if dropout : 
","if dropout :
",78.12,0.0,False
"def get_object_from_name ( self , name , check_symlinks = True ) : <TAB> if not name : <TAB> <TAB> return None <TAB> name = name . rstrip ( "" \\ "" ) <TAB> for a , o in self . objects . items ( ) : <TAB> <TAB> if not o . name : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return o <TAB> if check_symlinks : <TAB> <TAB> m = [ sl [ 1 ] for sl in self . symlinks if name . lower ( ) == sl [ 0 ] . lower ( ) ] <TAB> <TAB> if m : <TAB> <TAB> <TAB> name = m [ 0 ] <TAB> <TAB> return self . get_object_from_name ( name , False ) ","if o . name . lower ( ) == name . lower ( ) : 
","if o . name == name :
",26.92,19.02,False
"def __call__ ( self ) : <TAB> """"""Run all check_* methods."""""" <TAB> if self . on : <TAB> <TAB> oldformatwarning = warnings . formatwarning <TAB> <TAB> warnings . formatwarning = self . formatwarning <TAB> <TAB> try : <TAB> <TAB> <TAB> for name in dir ( self ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> method = getattr ( self , name ) <TAB> <TAB> <TAB> <TAB> <TAB> if method and callable ( method ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> method ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> warnings . formatwarning = oldformatwarning ","if name . startswith ( "" check_ "" ) : 
","if name . startswith ( "" check_ "" ) :
",100.0,100.0,True
"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB> <TAB> print_func = str <TAB> else : <TAB> <TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB> <TAB> value = getattr ( self , k ) <TAB> <TAB> if not defaults and value == default_values [ k ] : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print_func = repr<TAB> # keep quotes around strings <TAB> <TAB> pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB> if pieces or self . __base__ : <TAB> <TAB> return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB> else : <TAB> <TAB> return "" "" ","if isinstance ( value , basestring ) : 
","if print_func is str :
",26.86,6.77,False
"def apply ( self , * * kwargs : Any ) - > None : <TAB> for node in self . document . traverse ( nodes . target ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> "" ismod "" in node <TAB> <TAB> <TAB> and node . parent . __class__ is nodes . section <TAB> <TAB> <TAB> and <TAB> <TAB> <TAB> # index 0 is the section title node <TAB> <TAB> <TAB> node . parent . index ( node ) == 1 <TAB> <TAB> ) : <TAB> <TAB> <TAB> node . parent [ "" ids "" ] [ 0 : 0 ] = node [ "" ids "" ] <TAB> <TAB> <TAB> node . parent . remove ( node ) ","if not node [ "" ids "" ] : 
","if node [ "" id "" ] == "" id "" :
",41.76,15.73,False
"def add_special_token_2d ( <TAB> values : List [ List [ int ] ] , special_token : int = 0 , use_first_value : bool = False ) - > List [ List [ int ] ] : <TAB> results = torch . jit . annotate ( List [ List [ int ] ] , [ ] ) <TAB> for value in values : <TAB> <TAB> result = torch . jit . annotate ( List [ int ] , [ ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> special_token = value [ 0 ] <TAB> <TAB> result . append ( special_token ) <TAB> <TAB> result . extend ( value ) <TAB> <TAB> result . append ( special_token ) <TAB> <TAB> results . append ( result ) <TAB> return results ","if use_first_value and len ( value ) > 0 : 
","if use_first_value :
",26.96,30.93,False
"def test_import ( self ) : <TAB> TIMEOUT = 5 <TAB> # Test for a deadlock when importing a module that runs the <TAB> # ThreadedResolver at import-time. See resolve_test.py for <TAB> # full explanation. <TAB> command = [ sys . executable , "" -c "" , "" import tornado.test.resolve_test_helper "" ] <TAB> start = time . time ( ) <TAB> popen = Popen ( command , preexec_fn = lambda : signal . alarm ( TIMEOUT ) ) <TAB> while time . time ( ) - start < TIMEOUT : <TAB> <TAB> return_code = popen . poll ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( 0 , return_code ) <TAB> <TAB> <TAB> return<TAB> # Success. <TAB> <TAB> time . sleep ( 0.05 ) <TAB> self . fail ( "" import timed out "" ) ","if return_code is not None : 
","if return_code != 0 :
",29.71,36.56,False
"def find_item_for_key ( self , e ) : <TAB> for item in self . _items : <TAB> <TAB> if item . keycode == e . key and item . shift == e . shift and item . alt == e . alt : <TAB> <TAB> <TAB> focus = get_focus ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . _items . index ( item ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return - 1 <TAB> return - 1 ","if self . command_is_enabled ( item , focus ) : 
","if focus is not None :
",26.48,3.03,False
"def check_app_config_brackets ( self ) : <TAB> for sn , app in cherrypy . tree . apps . items ( ) : <TAB> <TAB> if not isinstance ( app , cherrypy . Application ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for key in app . config . keys ( ) : <TAB> <TAB> <TAB> if key . startswith ( "" [ "" ) or key . endswith ( "" ] "" ) : <TAB> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> <TAB> "" The application mounted at  %r  has config  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" section names with extraneous brackets:  %r .  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" Config *files* need brackets; config *dicts*  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" (e.g. passed to tree.mount) do not. "" % ( sn , key ) <TAB> <TAB> <TAB> <TAB> ) ","if not app . config : 
","if not app . config :
",100.0,100.0,True
"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr ( a , "" modules "" , [ ] ) : <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m . strip ( ) <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self . modules : <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> if getattr ( mod , "" module_name "" , "" "" ) . strip ( ) == m : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if getattr ( mod , "" module_type "" , "" "" ) . strip ( ) == mod_type . strip ( ) : 
","if mod . type == mod_type :
",27.79,7.72,False
"def write_config_to_file ( self , folder , filename , config ) : <TAB> do_not_write = [ "" hyperparameter_search_space_updates "" ] <TAB> with open ( os . path . join ( folder , filename ) , "" w "" ) as f : <TAB> <TAB> f . write ( <TAB> <TAB> <TAB> "" \n "" . join ( <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> ( key + "" = "" + str ( value ) ) <TAB> <TAB> <TAB> <TAB> <TAB> for ( key , value ) in sorted ( config . items ( ) , key = lambda x : x [ 0 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if not key in do_not_write 
","if key not in do_not_write
",38.39,65.01,False
"def parsing ( self , parsing ) :<TAB> # type: (bool) -> None <TAB> self . _parsed = parsing <TAB> for k , v in self . _body : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v . value . parsing ( parsing ) <TAB> <TAB> elif isinstance ( v , AoT ) : <TAB> <TAB> <TAB> for t in v . body : <TAB> <TAB> <TAB> <TAB> t . value . parsing ( parsing ) ","if isinstance ( v , Table ) : 
","if isinstance ( v , AoT ) :
",79.9,59.46,False
"def test_crashers_crash ( self ) : <TAB> for fname in glob . glob ( CRASHER_FILES ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Some ""crashers"" only trigger an exception rather than a <TAB> <TAB> # segfault. Consider that an acceptable outcome. <TAB> <TAB> if test . support . verbose : <TAB> <TAB> <TAB> print ( "" Checking crasher: "" , fname ) <TAB> <TAB> assert_python_failure ( fname ) ","if os . path . basename ( fname ) in infinite_loops : 
","if not os . path . isfile ( fname ) :
",55.41,27.51,False
"def __getitem__ ( self , k ) - > "" SimMemView "" : <TAB> if isinstance ( k , slice ) : <TAB> <TAB> if k . step is not None : <TAB> <TAB> <TAB> raise ValueError ( "" Slices with strides are not supported "" ) <TAB> <TAB> elif k . start is None : <TAB> <TAB> <TAB> raise ValueError ( "" Must specify start index "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Slices with stop index are not supported "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> addr = k . start <TAB> elif self . _type is not None and self . _type . _can_refine_int : <TAB> <TAB> return self . _type . _refine ( self , k ) <TAB> else : <TAB> <TAB> addr = k <TAB> return self . _deeper ( addr = addr ) ","elif k . stop is not None : 
","elif k . stop is None :
",75.66,61.3,False
"def get_lowest_wall_time ( jsons ) : <TAB> lowest_wall = None <TAB> for j in jsons : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> <TAB> if lowest_wall > j [ "" wall_time "" ] : <TAB> <TAB> <TAB> lowest_wall = j [ "" wall_time "" ] <TAB> return lowest_wall ","if lowest_wall is None : 
","if lowest_wall is None :
",100.0,100.0,True
"def extract_wav_headers ( data ) : <TAB> # def search_subchunk(data, subchunk_id): <TAB> pos = 12<TAB> # The size of the RIFF chunk descriptor <TAB> subchunks = [ ] <TAB> while pos + 8 < = len ( data ) and len ( subchunks ) < 10 : <TAB> <TAB> subchunk_id = data [ pos : pos + 4 ] <TAB> <TAB> subchunk_size = struct . unpack_from ( "" <I "" , data [ pos + 4 : pos + 8 ] ) [ 0 ] <TAB> <TAB> subchunks . append ( WavSubChunk ( subchunk_id , pos , subchunk_size ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # 'data' is the last subchunk <TAB> <TAB> <TAB> break <TAB> <TAB> pos + = subchunk_size + 8 <TAB> return subchunks ","if subchunk_id == b "" data "" : 
","if subchunk_size == 0 :
",26.99,18.59,False
"def _any_targets_have_native_sources ( self , targets ) : <TAB> # TODO(#5949): convert this to checking if the closure of python requirements has any <TAB> # platform-specific packages (maybe find the platforms there too?). <TAB> for tgt in targets : <TAB> <TAB> for type_constraint , target_predicate in self . _native_target_matchers . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if type_constraint . satisfied_by ( tgt ) and target_predicate ( tgt ) : 
","if tgt . has_target_predicate ( type_constraint , target_predicate ) :
",30.43,22.47,False
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> if v is None :<TAB> # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB> <TAB> if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB> <TAB> <TAB> raise serializers . ValidationError ( <TAB> <TAB> <TAB> <TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB> <TAB> <TAB> ) <TAB> return value ","if not re . match ( PROCTYPE_MATCH , k ) : 
","if not isinstance ( v , types . ProcessType ) :
",32.42,10.17,False
"def cart_number_checksum_validation ( cls , number ) : <TAB> digits = [ ] <TAB> even = False <TAB> if not number . isdigit ( ) : <TAB> <TAB> return False <TAB> for digit in reversed ( number ) : <TAB> <TAB> digit = ord ( digit ) - ord ( "" 0 "" ) <TAB> <TAB> if even : <TAB> <TAB> <TAB> digit * = 2 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> digit = digit % 10 + digit / / 10 <TAB> <TAB> digits . append ( digit ) <TAB> <TAB> even = not even <TAB> return sum ( digits ) % 10 == 0 if digits else False ","if digit > = 10 : 
","if digit % 10 != 0 :
",29.76,13.89,False
"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB> <TAB> ctype , line , col , char = cmd <TAB> <TAB> if ctype == "" D "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB> <TAB> <TAB> <TAB> del buf [ line + 1 ] <TAB> <TAB> elif ctype == "" I "" : <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB> <TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf ) ","if char != "" \n "" : 
","if col + len ( char ) > len ( buf [ line ] ) :
",26.6,3.22,False
"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { }<TAB> # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self . edges : <TAB> <TAB> if edge . is_dangling ( ) : <TAB> <TAB> <TAB> raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB> <TAB> if self . _is_my_trace ( edge ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node , shared_axis = self . _get_partner ( edge ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> partners [ partner_node ] = set ( ) <TAB> <TAB> partners [ partner_node ] . add ( shared_axis ) <TAB> return partners ","if partner_node not in partners : 
","if partner_node not in partners :
",100.0,100.0,True
"def _bind_interactive_rez ( self ) : <TAB> if config . set_prompt and self . settings . prompt : <TAB> <TAB> stored_prompt = os . getenv ( "" REZ_STORED_PROMPT_CMD "" ) <TAB> <TAB> curr_prompt = stored_prompt or os . getenv ( "" PROMPT "" , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . setenv ( "" REZ_STORED_PROMPT_CMD "" , curr_prompt ) <TAB> <TAB> new_prompt = "" %% REZ_ENV_PROMPT %% "" <TAB> <TAB> new_prompt = ( <TAB> <TAB> <TAB> ( new_prompt + "" %s "" ) if config . prefix_prompt else ( "" %s "" + new_prompt ) <TAB> <TAB> ) <TAB> <TAB> new_prompt = new_prompt % curr_prompt <TAB> <TAB> self . _addline ( "" set PROMPT= %s "" % new_prompt ) ","if not stored_prompt : 
","if curr_prompt :
",29.81,34.98,False
"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB> <TAB> definition = column ( name ) <TAB> <TAB> if not definition : <TAB> <TAB> <TAB> IECore . msg ( <TAB> <TAB> <TAB> <TAB> IECore . Msg . Level . Error , <TAB> <TAB> <TAB> <TAB> "" GafferImageUI.CatalogueUI "" , <TAB> <TAB> <TAB> <TAB> "" No column registered with name  ' %s ' "" % name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB> <TAB> columns . append ( c ) <TAB> return columns ","if isinstance ( definition , IconColumn ) : 
","if definition . icon :
",26.99,7.72,False
"def _check_invalid_keys ( self , section_name , section ) : <TAB> for key in section : <TAB> <TAB> key_name = str ( key ) <TAB> <TAB> valid_key_names = [ s [ 0 ] for s in self . keys ] <TAB> <TAB> is_valid_key = key_name in valid_key_names <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> err_msg = ( <TAB> <TAB> <TAB> <TAB> "" ' {0} '  is not a valid key name for  ' {1} ' . Must  "" "" be one of these:  {2} "" <TAB> <TAB> <TAB> ) . format ( key_name , section_name , "" ,  "" . join ( valid_key_names ) ) <TAB> <TAB> <TAB> raise InvalidConfig ( err_msg ) ","if not is_valid_key : 
","if not is_valid_key :
",100.0,100.0,True
"def _get_startup_packages ( lib_path : Path , packages ) - > Set [ str ] : <TAB> names = set ( ) <TAB> for path in lib_path . iterdir ( ) : <TAB> <TAB> name = path . name <TAB> <TAB> if name == "" __pycache__ "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if name . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> names . add ( name . split ( "" . "" ) [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> names . add ( name ) <TAB> if packages : <TAB> <TAB> packages = { package . lower ( ) . replace ( "" - "" , "" _ "" ) for package in packages } <TAB> <TAB> if len ( names & packages ) == len ( packages ) : <TAB> <TAB> <TAB> return packages <TAB> return names ","elif path . is_dir ( ) and "" . "" not in name : 
","elif name . startswith ( "" __ "" ) :
",31.7,4.12,False
"def sortkeypicker ( keynames ) : <TAB> negate = set ( ) <TAB> for i , k in enumerate ( keynames ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> keynames [ i ] = k [ 1 : ] <TAB> <TAB> <TAB> negate . add ( k [ 1 : ] ) <TAB> def getit ( adict ) : <TAB> <TAB> composite = [ adict [ k ] for k in keynames ] <TAB> <TAB> for i , ( k , v ) in enumerate ( zip ( keynames , composite ) ) : <TAB> <TAB> <TAB> if k in negate : <TAB> <TAB> <TAB> <TAB> composite [ i ] = - v <TAB> <TAB> return composite <TAB> return getit ","if k [ : 1 ] == "" - "" : 
","if k [ 0 ] == "" - "" :
",58.96,64.07,False
"def iter_symbols ( code ) : <TAB> """"""Yield names and strings used by `code` and its nested code objects"""""" <TAB> for name in code . co_names : <TAB> <TAB> yield name <TAB> for const in code . co_consts : <TAB> <TAB> if isinstance ( const , six . string_types ) : <TAB> <TAB> <TAB> yield const <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for name in iter_symbols ( const ) : <TAB> <TAB> <TAB> <TAB> yield name ","elif isinstance ( const , CodeType ) : 
","elif isinstance ( const , ( list , tuple ) ) :
",49.15,36.46,False
"def set_study_directions ( <TAB> self , study_id : int , directions : Sequence [ StudyDirection ] ) - > None : <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> current_directions = self . _studies [ study_id ] . directions <TAB> <TAB> <TAB> if directions == current_directions : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif ( <TAB> <TAB> <TAB> <TAB> len ( current_directions ) == 1 <TAB> <TAB> <TAB> <TAB> and current_directions [ 0 ] == StudyDirection . NOT_SET <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> self . _studies [ study_id ] . directions = list ( directions ) <TAB> <TAB> <TAB> <TAB> self . _backend . set_study_directions ( study_id , directions ) <TAB> <TAB> <TAB> <TAB> return <TAB> self . _backend . set_study_directions ( study_id , directions ) ","if study_id in self . _studies : 
","if study_id in self . _studies :
",100.0,100.0,True
"def PreprocessConditionalStatement ( self , IfList , ReplacedLine ) : <TAB> while self : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = 1 <TAB> <TAB> elif not IfList : <TAB> <TAB> <TAB> if self < = 2 : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionSizeGuid = 3 <TAB> <TAB> <TAB> if not RegionSizeGuid : <TAB> <TAB> <TAB> <TAB> RegionLayoutLine = 5 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> RegionLayoutLine = self . CurrentLineNumber <TAB> return 1 ","if self . __Token : 
","if self . IsConditional ( IfList , ReplacedLine ) :
",43.47,16.78,False
"def _check_blocking ( self , current_time ) : <TAB> if self . _switch_flag is False : <TAB> <TAB> active_greenlet = self . _active_greenlet <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _notify_greenlet_blocked ( active_greenlet , current_time ) <TAB> self . _switch_flag = False ","if active_greenlet is not None and active_greenlet != self . _hub : 
","if active_greenlet is not None and active_greenlet != current_time :
",64.71,72.35,False
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( r "" BlockDos \ .net "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return retval ","if retval : 
","if retval :
",78.12,0.0,False
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> elif in_section : <TAB> <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >>END "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out ","if line . startswith ( "" >> %s "" % section_name ) : 
","if section_name in line :
",25.99,6.97,False
"def shortcut ( self , input , ch_out , stride , is_first , name ) : <TAB> ch_in = input . shape [ 1 ] <TAB> if ch_in != ch_out or stride != 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . conv_bn_layer_new ( input , ch_out , 1 , stride , name = name ) <TAB> elif is_first : <TAB> <TAB> return self . conv_bn_layer ( input , ch_out , 1 , stride , name = name ) <TAB> else : <TAB> <TAB> return input ","if is_first or stride == 1 : 
","if is_first :
",28.73,26.01,False
"def get_value_from_string ( self , string_value ) : <TAB> """"""Return internal representation starting from CFN/user-input value."""""" <TAB> param_value = self . get_default_value ( ) <TAB> try : <TAB> <TAB> if string_value is not None : <TAB> <TAB> <TAB> string_value = str ( string_value ) . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> param_value = int ( string_value ) <TAB> except ValueError : <TAB> <TAB> self . pcluster_config . warn ( <TAB> <TAB> <TAB> "" Unable to convert the value  ' {0} '  to an Integer.  "" <TAB> <TAB> <TAB> "" Using default value for parameter  ' {1} ' "" . format ( string_value , self . key ) <TAB> <TAB> ) <TAB> return param_value ","if string_value != "" NONE "" : 
","if not param_value . isdigit ( ) :
",26.98,9.98,False
"def get_running ( workers ) : <TAB> running = [ ] <TAB> for worker in workers : <TAB> <TAB> current_test_name = worker . current_test_name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = time . monotonic ( ) - worker . start_time <TAB> <TAB> if dt > = PROGRESS_MIN_TIME : <TAB> <TAB> <TAB> text = "" %s  ( %s ) "" % ( current_test_name , format_duration ( dt ) ) <TAB> <TAB> <TAB> running . append ( text ) <TAB> return running ","if not current_test_name : 
","if not current_test_name :
",100.0,100.0,True
"def generate_data ( self , request ) : <TAB> """"""Generate data for the widget."""""" <TAB> uptime = { } <TAB> cache_stats = get_cache_stats ( ) <TAB> if cache_stats : <TAB> <TAB> for hosts , stats in cache_stats : <TAB> <TAB> <TAB> if stats [ "" uptime "" ] > 86400 : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 / 24 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" days "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" hours "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> uptime [ "" value "" ] = stats [ "" uptime "" ] / 60 <TAB> <TAB> <TAB> <TAB> uptime [ "" unit "" ] = _ ( "" minutes "" ) <TAB> return { "" cache_stats "" : cache_stats , "" uptime "" : uptime } ","elif stats [ "" uptime "" ] > 3600 : 
","elif stats [ "" uptime "" ] > 3600 :
",100.0,100.0,True
"def add_actors ( self ) : <TAB> """"""Adds `self.actors` to the scene."""""" <TAB> if not self . _actors_added : <TAB> <TAB> self . reader . render_window = self . scene . render_window <TAB> <TAB> self . _update_reader ( ) <TAB> <TAB> self . _actors_added = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _visible_changed ( self . visible ) <TAB> <TAB> self . scene . render ( ) ","if not self . visible : 
","if self . visible :
",58.31,57.89,False
"def _add_uniqu_suffix ( self , titles ) : <TAB> counters = dict ( ) <TAB> titles_with_suffix = [ ] <TAB> for title in titles : <TAB> <TAB> counters [ title ] = counters [ title ] + 1 if title in counters else 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> title = f "" { title }  ( { counters [ title ] } ) "" <TAB> <TAB> titles_with_suffix . append ( title ) <TAB> return titles_with_suffix ","if counters [ title ] > 1 : 
","if counter [ title ] > 1 :
",85.56,70.71,False
"def _verify_udf_resources ( self , job , config ) : <TAB> udf_resources = config . get ( "" userDefinedFunctionResources "" , ( ) ) <TAB> self . assertEqual ( len ( job . udf_resources ) , len ( udf_resources ) ) <TAB> for found , expected in zip ( job . udf_resources , udf_resources ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( found . udf_type , "" resourceUri "" ) <TAB> <TAB> <TAB> self . assertEqual ( found . value , expected [ "" resourceUri "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( found . udf_type , "" inlineCode "" ) <TAB> <TAB> <TAB> self . assertEqual ( found . value , expected [ "" inlineCode "" ] ) ","if "" resourceUri "" in expected : 
","if isinstance ( found . udf_type , dict ) :
",26.7,4.03,False
"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """"""Constructor."""""" <TAB> self . layout = layout <TAB> if value is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB> <TAB> self . value = np . array ( value ) <TAB> <TAB> if self . value . shape != ( self . layout . gaDims , ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB> <TAB> <TAB> ) ","if string is None : 
","if string is None :
",100.0,100.0,True
"def read_file ( filename , print_error = True ) : <TAB> """"""Returns the contents of a file."""""" <TAB> try : <TAB> <TAB> for encoding in [ "" utf-8 "" , "" latin1 "" ] : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> with io . open ( filename , encoding = encoding ) as fp : <TAB> <TAB> <TAB> <TAB> <TAB> return fp . read ( ) <TAB> <TAB> <TAB> except UnicodeDecodeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> except IOError as exception : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( exception , file = sys . stderr ) <TAB> <TAB> return None ","if print_error : 
","if print_error :
",78.12,100.0,True
"def get_albums_for_iter ( self , iter_ ) : <TAB> obj = self . get_value ( iter_ ) <TAB> if isinstance ( obj , AlbumNode ) : <TAB> <TAB> return { obj . album } <TAB> albums = set ( ) <TAB> for child_iter , value in self . iterrows ( iter_ ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> albums . add ( value . album ) <TAB> <TAB> else : <TAB> <TAB> <TAB> albums . update ( self . get_albums_for_iter ( child_iter ) ) <TAB> return albums ","if isinstance ( value , AlbumNode ) : 
","if isinstance ( value , AlbumNode ) :
",100.0,100.0,True
"def wait_til_ready ( cls , connector = None ) : <TAB> if connector is None : <TAB> <TAB> connector = cls . connector <TAB> while True : <TAB> <TAB> now = time . time ( ) <TAB> <TAB> next_iteration = now / / 1.0 + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> await cls . _clock . run_til ( next_iteration ) <TAB> <TAB> await asyncio . sleep ( 1.0 ) ","if connector . ready : 
","if connector . is_connected ( next_iteration ) :
",44.36,13.55,False
"def remove_property ( self , key ) :<TAB> # type: (str) -> None <TAB> with self . secure ( ) as config : <TAB> <TAB> keys = key . split ( "" . "" ) <TAB> <TAB> current_config = config <TAB> <TAB> for i , key in enumerate ( keys ) : <TAB> <TAB> <TAB> if key not in current_config : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del current_config [ key ] <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> current_config = current_config [ key ] ","if i == len ( keys ) - 1 : 
","if current_config [ key ] == "" "" :
",26.5,8.05,False
"def get ( self , hash160 , default = None ) : <TAB> v = self . p2s_for_hash ( hash160 ) <TAB> <MASK> <TAB> <TAB> return v <TAB> if hash160 not in self . _secret_exponent_cache : <TAB> <TAB> v = self . path_for_hash160 ( hash160 ) <TAB> <TAB> if v : <TAB> <TAB> <TAB> fingerprint , path = v <TAB> <TAB> <TAB> for key in self . _secrets . get ( fingerprint , [ ] ) : <TAB> <TAB> <TAB> <TAB> subkey = key . subkey_for_path ( path ) <TAB> <TAB> <TAB> <TAB> self . _add_key_to_cache ( subkey ) <TAB> return self . _secret_exponent_cache . get ( hash160 , default ) ","if v : 
","if v :
",78.12,0.0,False
"def fetch_all ( self , api_client , fetchstatuslogger , q , targets ) : <TAB> self . fetchstatuslogger = fetchstatuslogger <TAB> if targets != None : <TAB> <TAB> # Ensure targets is a tuple <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> targets = tuple ( <TAB> <TAB> <TAB> <TAB> targets , <TAB> <TAB> <TAB> ) <TAB> <TAB> elif type ( targets ) != tuple : <TAB> <TAB> <TAB> targets = tuple ( targets ) <TAB> for target in targets : <TAB> <TAB> self . _fetch_targets ( api_client , q , target ) ","if type ( targets ) != list and type ( targets ) != tuple : 
","if type ( targets ) == list :
",54.28,22.47,False
"def dgl_mp_batchify_fn ( data ) : <TAB> if isinstance ( data [ 0 ] , tuple ) : <TAB> <TAB> data = zip ( * data ) <TAB> <TAB> return [ dgl_mp_batchify_fn ( i ) for i in data ] <TAB> for dt in data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( dt , dgl . DGLGraph ) : <TAB> <TAB> <TAB> <TAB> return [ d for d in data if isinstance ( d , dgl . DGLGraph ) ] <TAB> <TAB> <TAB> elif isinstance ( dt , nd . NDArray ) : <TAB> <TAB> <TAB> <TAB> pad = Pad ( axis = ( 1 , 2 ) , num_shards = 1 , ret_length = False ) <TAB> <TAB> <TAB> <TAB> data_list = [ dt for dt in data if dt is not None ] <TAB> <TAB> <TAB> <TAB> return pad ( data_list ) ","if dt is not None : 
","if isinstance ( dt , ( dgl . DGLBatchify , dgl . DGLBatchify ) ) :
",26.6,3.22,False
"def capture_server ( evt , buf , serv ) : <TAB> try : <TAB> <TAB> serv . listen ( 5 ) <TAB> <TAB> conn , addr = serv . accept ( ) <TAB> except socket . timeout : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> n = 200 <TAB> <TAB> while n > 0 : <TAB> <TAB> <TAB> r , w , e = select . select ( [ conn ] , [ ] , [ ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = conn . recv ( 10 ) <TAB> <TAB> <TAB> <TAB> # keep everything except for the newline terminator <TAB> <TAB> <TAB> <TAB> buf . write ( data . replace ( "" \n "" , "" "" ) ) <TAB> <TAB> <TAB> <TAB> if "" \n "" in data : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> <TAB> time . sleep ( 0.01 ) <TAB> <TAB> conn . close ( ) <TAB> finally : <TAB> <TAB> serv . close ( ) <TAB> <TAB> evt . set ( ) ","if r : 
","if w :
",56.98,0.0,False
"def elem ( ) : <TAB> if ints_only : <TAB> <TAB> return random . randint ( 0 , 10000000000 ) <TAB> else : <TAB> <TAB> t = random . randint ( 0 , 2 ) <TAB> <TAB> if t == 0 : <TAB> <TAB> <TAB> return random . randint ( 0 , 10000000000 ) <TAB> <TAB> elif t == 1 : <TAB> <TAB> <TAB> return float ( random . randint ( 0 , 10000000000 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return strings [ random . randint ( 0 , len ( strings ) - 1 ) ] <TAB> <TAB> return random_string ( random . randint ( 100 , 1000 ) ) ","elif strings is not None : 
","elif t == 2 :
",27.46,9.65,False
"def has_changed ( self , initial , data ) : <TAB> if self . disabled : <TAB> <TAB> return False <TAB> if initial is None : <TAB> <TAB> initial = [ "" "" for x in range ( 0 , len ( data ) ) ] <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> initial = self . widget . decompress ( initial ) <TAB> for field , initial , data in zip ( self . fields , initial , data ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> initial = field . to_python ( initial ) <TAB> <TAB> except ValidationError : <TAB> <TAB> <TAB> return True <TAB> <TAB> if field . has_changed ( initial , data ) : <TAB> <TAB> <TAB> return True <TAB> return False ","if not isinstance ( initial , list ) : 
","if self . widget :
",26.52,5.71,False
"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB> <TAB> package = _normalize_module ( package , 3 ) <TAB> <TAB> filename = _module_relative_path ( package , filename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if hasattr ( package . __loader__ , "" get_data "" ) : <TAB> <TAB> <TAB> <TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB> return open ( filename ) . read ( ) , filename ","if hasattr ( package , "" __loader__ "" ) : 
","if hasattr ( package , "" __loader__ "" ) :
",100.0,100.0,True
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> if self . owner != tid : <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> if self . count == 0 : <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( ) ","if self . waiters : 
","if self . waiters > 0 :
",61.88,43.47,False
"def stage ( <TAB> self , x , num_modules , num_blocks , channels , multi_scale_output = True , name = None ) : <TAB> out = x <TAB> for i in range ( num_modules ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out = self . high_resolution_module ( <TAB> <TAB> <TAB> <TAB> out , <TAB> <TAB> <TAB> <TAB> num_blocks , <TAB> <TAB> <TAB> <TAB> channels , <TAB> <TAB> <TAB> <TAB> multi_scale_output = False , <TAB> <TAB> <TAB> <TAB> name = name + "" _ "" + str ( i + 1 ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out = self . high_resolution_module ( <TAB> <TAB> <TAB> <TAB> out , num_blocks , channels , name = name + "" _ "" + str ( i + 1 ) <TAB> <TAB> <TAB> ) <TAB> return out ","if i == num_modules - 1 and multi_scale_output == False : 
","if i == num_modules - 1 :
",56.38,36.74,False
"def changeFrontAlteration ( intV , alter ) : <TAB> # fati = front alteration transpose interval <TAB> fati = self . frontAlterationTransposeInterval <TAB> if fati : <TAB> <TAB> newFati = interval . add ( [ fati , intV ] ) <TAB> <TAB> self . frontAlterationTransposeInterval = newFati <TAB> <TAB> self . frontAlterationAccidental . alter = ( <TAB> <TAB> <TAB> self . frontAlterationAccidental . alter + alter <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . frontAlterationTransposeInterval = None <TAB> <TAB> <TAB> self . frontAlterationAccidental = None <TAB> else : <TAB> <TAB> self . frontAlterationTransposeInterval = intV <TAB> <TAB> self . frontAlterationAccidental = pitch . Accidental ( alter ) ","if self . frontAlterationAccidental . alter == 0 : 
","if self . frontAlterationTransposeInterval == intV :
",37.05,21.07,False
"def set_to_train ( self ) : <TAB> for T in self . trainable_attributes ( ) : <TAB> <TAB> for k , v in T . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> c_f . set_requires_grad ( v , requires_grad = False ) <TAB> <TAB> <TAB> <TAB> v . eval ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> v . train ( ) <TAB> self . maybe_freeze_trunk_batchnorm ( ) ","if k in self . freeze_these : 
","if k == "" requires_grad "" :
",28.91,9.98,False
"def _migrate ( self , sig = None , compact = True ) : <TAB> with self . lock : <TAB> <TAB> sig = sig or self . sig <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if sig in self . WORDS and len ( self . WORDS [ sig ] ) > 0 : <TAB> <TAB> <TAB> PostingList . Append ( <TAB> <TAB> <TAB> <TAB> self . session , sig , self . WORDS [ sig ] , sig = sig , compact = compact <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self . WORDS [ sig ] ","if sig in GPL_NEVER_MIGRATE : 
","if sig is None :
",31.2,10.62,False
"def on_prediction_step ( self , args , state , control , eval_dataloader = None , * * kwargs ) : <TAB> if self . prediction_bar is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . prediction_bar = self . training_tracker . add_child ( len ( eval_dataloader ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . prediction_bar = NotebookProgressBar ( len ( eval_dataloader ) ) <TAB> <TAB> self . prediction_bar . update ( 1 ) <TAB> else : <TAB> <TAB> self . prediction_bar . update ( self . prediction_bar . value + 1 ) ","if self . training_tracker is not None : 
","if self . training_tracker is not None :
",100.0,100.0,True
"def show ( self , indent = 0 ) : <TAB> """"""Pretty print this structure."""""" <TAB> if indent == 0 : <TAB> <TAB> print ( "" struct  {} "" . format ( self . name ) ) <TAB> for field in self . fields : <TAB> <TAB> if field . offset is None : <TAB> <TAB> <TAB> offset = "" 0x?? "" <TAB> <TAB> else : <TAB> <TAB> <TAB> offset = "" 0x {:02x} "" . format ( field . offset ) <TAB> <TAB> print ( "" {} + {} {} {} "" . format ( "" "" * indent , offset , field . name , field . type ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field . type . show ( indent + 1 ) ","if isinstance ( field . type , Structure ) : 
","if isinstance ( field . type , Field ) :
",85.57,70.71,False
"def __exit__ ( self , exc , value , tb ) : <TAB> for key in self . overrides . keys ( ) : <TAB> <TAB> old_value = self . old [ key ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> delattr ( self . instance , key ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( self . instance , key , old_value ) <TAB> self . instance . save ( ) ","if old_value is NULL : 
","if old_value is None :
",39.55,64.35,False
"def complete ( self , block ) : <TAB> with self . _condition : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . _complete ( ) : <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> if block : <TAB> <TAB> <TAB> self . _condition . wait_for ( self . _complete ) <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False ","if not self . _final : 
","if self . _condition . is_set ( ) :
",35.23,14.32,False
"def parseArguments ( self ) : <TAB> args = [ ] <TAB> self . expect ( "" ( "" ) <TAB> if not self . match ( "" ) "" ) : <TAB> <TAB> while self . startIndex < self . length : <TAB> <TAB> <TAB> args . append ( self . isolateCoverGrammar ( self . parseAssignmentExpression ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> self . expectCommaSeparator ( ) <TAB> self . expect ( "" ) "" ) <TAB> return args ","if self . match ( "" ) "" ) : 
","if self . startIndex == self . length - 1 :
",34.55,13.55,False
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> if value == "" DD-MM-YYYY "" : <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( month ) < 1 or int ( month ) > 12 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) ","if int ( day ) < 1 or int ( day ) > 31 : 
","if not valid_value :
",25.62,2.15,False
"def build_tree ( path ) : <TAB> tree = Tree ( ) <TAB> for basename , entry in trees [ path ] . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mode = stat . S_IFDIR <TAB> <TAB> <TAB> sha = build_tree ( pathjoin ( path , basename ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ( mode , sha ) = entry <TAB> <TAB> tree . add ( basename , mode , sha ) <TAB> object_store . add_object ( tree ) <TAB> return tree . id ","if isinstance ( entry , dict ) : 
","if entry is None :
",26.99,7.72,False
"def get_quarantine_count ( self ) : <TAB> """"""get obj/container/account quarantine counts"""""" <TAB> qcounts = { "" objects "" : 0 , "" containers "" : 0 , "" accounts "" : 0 } <TAB> qdir = "" quarantined "" <TAB> for device in os . listdir ( self . devices ) : <TAB> <TAB> for qtype in qcounts : <TAB> <TAB> <TAB> qtgt = os . path . join ( self . devices , device , qdir , qtype ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> linkcount = os . lstat ( qtgt ) . st_nlink <TAB> <TAB> <TAB> <TAB> if linkcount > 2 : <TAB> <TAB> <TAB> <TAB> <TAB> qcounts [ qtype ] + = linkcount - 2 <TAB> return qcounts ","if os . path . exists ( qtgt ) : 
","if os . path . exists ( qtgt ) :
",100.0,100.0,True
"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB> <TAB> return False <TAB> for dim_value in shape : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> if dim_value < 0 : <TAB> <TAB> <TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True ","if not isinstance ( dim_value , int ) : 
","if dim_value == 0 :
",26.63,16.05,False
"def BraceDetectAll ( words ) : <TAB> # type: (List[compound_word]) -> List[word_t] <TAB> """"""Return a new list of words, possibly with BracedTree instances."""""" <TAB> out = [ ]<TAB> # type: List[word_t] <TAB> for w in words : <TAB> <TAB> # The shortest possible brace expansion is {,}.  This heuristic prevents <TAB> <TAB> # a lot of garbage from being created, since otherwise nearly every word <TAB> <TAB> # would be checked.  We could be even more precise but this is cheap. <TAB> <TAB> if len ( w . parts ) > = 3 : <TAB> <TAB> <TAB> brace_tree = _BraceDetect ( w ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> out . append ( brace_tree ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> out . append ( w ) <TAB> return out ","if brace_tree : 
","if brace_tree :
",78.12,100.0,True
"def __init__ ( original , self , * args , * * kwargs ) : <TAB> data = args [ 0 ] if len ( args ) > 0 else kwargs . get ( "" data "" ) <TAB> if data is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> <TAB> "" cannot gather example input when dataset is loaded from a file. "" <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo ( <TAB> <TAB> <TAB> <TAB> input_example = deepcopy ( data [ : INPUT_EXAMPLE_SAMPLE_ROWS ] ) <TAB> <TAB> <TAB> ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> input_example_info = _InputExampleInfo ( error_msg = str ( e ) ) <TAB> <TAB> setattr ( self , "" input_example_info "" , input_example_info ) <TAB> original ( self , * args , * * kwargs ) ","if isinstance ( data , str ) : 
","if len ( data ) < INPUT_EXAMPLE_SAMPLE_ROWS :
",28.78,7.14,False
"def setRow ( self , row , vals ) : <TAB> if row > self . rowCount ( ) - 1 : <TAB> <TAB> self . setRowCount ( row + 1 ) <TAB> for col in range ( len ( vals ) ) : <TAB> <TAB> val = vals [ col ] <TAB> <TAB> item = self . itemClass ( val , row ) <TAB> <TAB> item . setEditable ( self . editable ) <TAB> <TAB> sortMode = self . sortModes . get ( col , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> item . setSortMode ( sortMode ) <TAB> <TAB> format = self . _formats . get ( col , self . _formats [ None ] ) <TAB> <TAB> item . setFormat ( format ) <TAB> <TAB> self . items . append ( item ) <TAB> <TAB> self . setItem ( row , col , item ) <TAB> <TAB> item . setValue ( val )<TAB> # Required--the text-change callback is invoked ","if sortMode is not None : 
","if sortMode is not None :
",100.0,100.0,True
"def wakeUp ( self ) : <TAB> """"""Write one byte to the pipe, and flush it."""""" <TAB> # We don't use fdesc.writeToFD since we need to distinguish <TAB> # between EINTR (try again) and EAGAIN (do nothing). <TAB> if self . o is not None : <TAB> <TAB> try : <TAB> <TAB> <TAB> util . untilConcludes ( os . write , self . o , b "" x "" ) <TAB> <TAB> except OSError as e : <TAB> <TAB> <TAB> # XXX There is no unit test for raising the exception <TAB> <TAB> <TAB> # for other errnos. See #4285. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ","if e . errno != errno . EAGAIN : 
","if e . errno != errno . EAGAIN :
",100.0,100.0,True
"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model references. <TAB> resolved_classes = [ ] <TAB> for m in self . model_classes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if m == owner_model . __name__ : <TAB> <TAB> <TAB> <TAB> resolved_classes . append ( owner_model ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> <TAB> "" PolyModelType: Unable to resolve model  ' {} ' . "" . format ( m ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> resolved_classes . append ( m ) <TAB> self . model_classes = tuple ( resolved_classes ) <TAB> super ( PolyModelType , self ) . _setup ( field_name , owner_model ) ","if isinstance ( m , string_type ) : 
","if isinstance ( owner_model , model . BaseModel ) :
",33.08,17.24,False
"def _wrap_forwarded ( self , key , value ) : <TAB> if isinstance ( value , SourceCode ) and value . late_binding : <TAB> <TAB> # get cached return value if present <TAB> <TAB> value_ = self . _late_binding_returnvalues . get ( key , KeyError ) <TAB> <TAB> if value_ is KeyError : <TAB> <TAB> <TAB> # evaluate the late-bound function <TAB> <TAB> <TAB> value_ = self . _eval_late_binding ( value ) <TAB> <TAB> <TAB> schema = self . late_bind_schemas . get ( key ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value_ = schema . validate ( value_ ) <TAB> <TAB> <TAB> # cache result of late bound func <TAB> <TAB> <TAB> self . _late_binding_returnvalues [ key ] = value_ <TAB> <TAB> return value_ <TAB> else : <TAB> <TAB> return value ","if schema is not None : 
","if schema :
",29.58,0.0,False
"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB> <TAB> arg = arg [ 1 : ] <TAB> try : <TAB> <TAB> value = int ( arg , base = 16 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB> <TAB> arg = arg . replace ( "" "" , "" _ "" ) <TAB> <TAB> method = getattr ( discord . Colour , arg , None ) <TAB> <TAB> if arg . startswith ( "" from_ "" ) or method is None or not inspect . ismethod ( method ) : <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return method ( ) ","if not ( 0 < = value < = 0xFFFFFF ) : 
","if value < 0 or value > 65535 :
",27.3,8.59,False
"def get_versions ( * , all = False , quiet = None ) : <TAB> import bonobo <TAB> from bonobo . util . pkgs import bonobo_packages <TAB> yield _format_version ( bonobo , quiet = quiet ) <TAB> if all : <TAB> <TAB> for name in sorted ( bonobo_packages ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> mod = __import__ ( name . replace ( "" - "" , "" _ "" ) ) <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield _format_version ( mod , name = name , quiet = quiet ) <TAB> <TAB> <TAB> <TAB> <TAB> except Exception as exc : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield "" {}  ( {} ) "" . format ( name , exc ) <TAB> <TAB> <TAB> <TAB> except ImportError as exc : <TAB> <TAB> <TAB> <TAB> <TAB> yield "" {}  is not importable ( {} ). "" . format ( name , exc ) ","if name != "" bonobo "" : 
","if name . startswith ( "" __ "" ) :
",34.92,9.43,False
"def assertOperationsInjected ( self , plan , * * kwargs ) : <TAB> for migration , _backward in plan : <TAB> <TAB> operations = iter ( migration . operations ) <TAB> <TAB> for operation in operations : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> next_operation = next ( operations ) <TAB> <TAB> <TAB> <TAB> self . assertIsInstance ( <TAB> <TAB> <TAB> <TAB> <TAB> next_operation , contenttypes_management . RenameContentType <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . app_label , migration . app_label ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . old_model , operation . old_name_lower ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( next_operation . new_model , operation . new_name_lower ) ","if isinstance ( operation , migrations . RenameModel ) : 
","if operation . is_backward :
",31.51,6.05,False
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if line == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT . match ( line ) <TAB> <TAB> if match : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" , "" in line or "" ; "" in line : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line ","if strip_delimiters : 
","if strip_delimiters :
",78.12,100.0,True
"def read_lccn ( line , is_marc8 = False ) : <TAB> found = [ ] <TAB> for k , v in get_raw_subfields ( line , [ "" a "" ] ) : <TAB> <TAB> lccn = v . strip ( ) <TAB> <TAB> if re_question . match ( lccn ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> m = re_lccn . search ( lccn ) <TAB> <TAB> if not m : <TAB> <TAB> <TAB> continue <TAB> <TAB> # remove letters and bad chars <TAB> <TAB> lccn = re_letters_and_bad . sub ( "" "" , m . group ( 1 ) ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> found . append ( lccn ) <TAB> return found ","if lccn : 
","if is_marc8 and lccn not in found :
",29.65,5.52,False
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> if name == "" likelihood.noise_covar.raw_noise "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> elif name == "" mean_module.constant "" : <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","elif name == "" covar_module.base_kernel.raw_lengthscale "" : 
","elif name == "" covar_module.raw_inputscale "" :
",74.63,54.94,False
"def _cleanupSocket ( self ) : <TAB> """"""Close the Connection's socket."""""" <TAB> try : <TAB> <TAB> self . _sock . shutdown ( socket . SHUT_WR ) <TAB> except : <TAB> <TAB> return <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r , w , e = select . select ( [ self . _sock ] , [ ] , [ ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> except : <TAB> <TAB> pass <TAB> self . _sock . close ( ) ","if not r or not self . _sock . recv ( 1024 ) : 
","if not w :
",29.12,2.26,False
"def fadeIn ( self , acts = None , t = None , duration = None ) : <TAB> """"""Gradually switch on the input list of meshes by increasing opacity."""""" <TAB> if self . bookingMode : <TAB> <TAB> acts , t , duration , rng = self . _parse ( acts , t , duration ) <TAB> <TAB> for tt in rng : <TAB> <TAB> <TAB> alpha = linInterpolate ( tt , [ t , t + duration ] , [ 0 , 1 ] ) <TAB> <TAB> <TAB> self . events . append ( ( tt , self . fadeIn , acts , alpha ) ) <TAB> else : <TAB> <TAB> for a in self . _performers : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> a . alpha ( self . _inputvalues ) <TAB> return self ","if a . alpha ( ) > = self . _inputvalues : 
","if not a . _inputvalues :
",36.44,20.75,False
"def get_config_updates_recursive ( self ) : <TAB> config_updates = self . config_updates . copy ( ) <TAB> for sr_path , subrunner in self . subrunners . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> update = subrunner . get_config_updates_recursive ( ) <TAB> <TAB> if update : <TAB> <TAB> <TAB> config_updates [ rel_path ( self . path , sr_path ) ] = update <TAB> return config_updates ","if not is_prefix ( self . path , sr_path ) : 
","if not isinstance ( subrunner , Subrunner ) :
",28.27,7.66,False
"def setArgs ( self , * * kwargs ) : <TAB> """"""See GridSearchCostGamma"""""" <TAB> for key , value in list ( kwargs . items ( ) ) : <TAB> <TAB> if key in ( "" folds "" , "" nfolds "" ) : <TAB> <TAB> <TAB> self . _n_folds = int ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _validator_kwargs [ "" max_epochs "" ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> GridSearchDOE . setArgs ( self , * * { key : value } ) ","elif key in ( "" max_epochs "" ) : 
","elif key == "" max_epochs "" :
",41.16,42.27,False
"def _parse_composite_axis ( composite_axis_name : str ) : <TAB> axes_names = [ axis for axis in composite_axis_name . split ( "" "" ) if len ( axis ) > 0 ] <TAB> for axis in axes_names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> assert "" a "" < = axis [ 0 ] < = "" z "" <TAB> <TAB> for letter in axis : <TAB> <TAB> <TAB> assert str . isdigit ( letter ) or "" a "" < = letter < = "" z "" <TAB> return axes_names ","if axis == "" _ "" : 
","if not len ( axis ) == 2 :
",27.09,10.55,False
"def visit_For ( self , node , for_branch = "" body "" , * * kwargs ) : <TAB> if for_branch == "" body "" : <TAB> <TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB> <TAB> branch = node . body <TAB> elif for_branch == "" else "" : <TAB> <TAB> branch = node . else_ <TAB> elif for_branch == "" test "" : <TAB> <TAB> self . sym_visitor . visit ( node . target , store_as_param = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . sym_visitor . visit ( node . test ) <TAB> <TAB> return <TAB> else : <TAB> <TAB> raise RuntimeError ( "" Unknown for branch "" ) <TAB> for item in branch or ( ) : <TAB> <TAB> self . sym_visitor . visit ( item ) ","if node . test is not None : 
","elif for_branch == "" test_expr "" :
",26.24,4.03,False
def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ,"if not any ( [ not is_text ( s ) for s in node . contents ] ) : 
","if node . contents :
",29.12,1.84,False
"def dir_tag_click ( event ) : <TAB> mouse_index = self . path_bar . index ( "" @ %d , %d "" % ( event . x , event . y ) ) <TAB> lineno = int ( float ( mouse_index ) ) <TAB> if lineno == 1 : <TAB> <TAB> self . request_focus_into ( "" "" ) <TAB> else : <TAB> <TAB> assert lineno == 2 <TAB> <TAB> dir_range = get_dir_range ( event ) <TAB> <TAB> if dir_range : <TAB> <TAB> <TAB> _ , end_index = dir_range <TAB> <TAB> <TAB> path = self . path_bar . get ( "" 2.0 "" , end_index ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> path + = "" \\ "" <TAB> <TAB> <TAB> self . request_focus_into ( path ) ","if path . endswith ( "" : "" ) : 
","if path and path [ - 1 ] != "" \\ "" :
",28.01,7.86,False
"def validate_employee_id ( self ) : <TAB> if self . employee : <TAB> <TAB> sales_person = frappe . db . get_value ( "" Sales Person "" , { "" employee "" : self . employee } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Another Sales Person  {0}  exists with the same Employee id "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> sales_person <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","if sales_person and sales_person != self . name : 
","if sales_person . employee == self . employee :
",33.77,26.84,False
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/infer "" ) : <TAB> <TAB> <TAB> if "" stage "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if "" init "" not in item . keywords : 
","if "" init "" not in item . keywords :
",100.0,100.0,True
"def poll ( self , timeout ) : <TAB> if timeout < 0 : <TAB> <TAB> timeout = None<TAB> # kqueue behaviour <TAB> events = self . _kqueue . control ( None , KqueueLoop . MAX_EVENTS , timeout ) <TAB> results = defaultdict ( lambda : POLL_NULL ) <TAB> for e in events : <TAB> <TAB> fd = e . ident <TAB> <TAB> if e . filter == select . KQ_FILTER_READ : <TAB> <TAB> <TAB> results [ fd ] | = POLL_IN <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results [ fd ] | = POLL_OUT <TAB> return results . items ( ) ","elif e . filter == select . KQ_FILTER_WRITE : 
","if e . filter == select . KQ_FILTER_WRITE :
",70.44,91.93,False
"def _read_dimensions ( self , * dimnames , * * kwargs ) : <TAB> path = kwargs . get ( "" path "" , "" / "" ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ self . rootgrp . dimensions [ dname ] for dname in dimnames ] <TAB> <TAB> group = self . path2group [ path ] <TAB> <TAB> return [ group . dimensions [ dname ] for dname in dimnames ] <TAB> except KeyError : <TAB> <TAB> raise self . Error ( <TAB> <TAB> <TAB> "" In file  %s : \n Error while reading dimensions: ` %s ` with kwargs: ` %s ` "" <TAB> <TAB> <TAB> % ( self . path , dimnames , kwargs ) <TAB> <TAB> ) ","if path == "" / "" : 
","if path == "" / "" :
",100.0,100.0,True
"def spam_to_me ( address ) : <TAB> sock = eventlet . connect ( address ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> sock . sendall ( b "" hello world "" ) <TAB> <TAB> <TAB> # Arbitrary delay to not use all available CPU, keeps the test <TAB> <TAB> <TAB> # running quickly and reliably under a second <TAB> <TAB> <TAB> time . sleep ( 0.001 ) <TAB> <TAB> except socket . error as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise ","if get_errno ( e ) == errno . EPIPE : 
","if e . errno == errno . EAGAIN :
",35.57,23.14,False
"def has_hash_of ( self , destpath , code , package_level ) : <TAB> """"""Determine if a file has the hash of the code."""""" <TAB> if destpath is not None and os . path . isfile ( destpath ) : <TAB> <TAB> with univ_open ( destpath , "" r "" ) as opened : <TAB> <TAB> <TAB> compiled = readfile ( opened ) <TAB> <TAB> hashash = gethash ( compiled ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if hashash is not None and hashash == self . comp . genhash ( code , package_level ) : 
","if hashash != code [ 0 ] :
",26.08,2.83,False
"def insert ( self , index , item ) : <TAB> if len ( self . lists ) == 1 : <TAB> <TAB> self . lists [ 0 ] . insert ( index , item ) <TAB> <TAB> self . _balance_list ( 0 ) <TAB> else : <TAB> <TAB> list_idx , rel_idx = self . _translate_index ( index ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IndexError ( ) <TAB> <TAB> self . lists [ list_idx ] . insert ( rel_idx , item ) <TAB> <TAB> self . _balance_list ( list_idx ) <TAB> return ","if list_idx is None : 
","if rel_idx not in self . lists :
",27.37,9.98,False
"def _parse_class_simplified ( symbol ) : <TAB> results = { } <TAB> name = symbol . name + "" ( "" <TAB> name + = "" ,  "" . join ( [ analyzer . expand_attribute ( base ) for base in symbol . bases ] ) <TAB> name + = "" ) "" <TAB> for sym in symbol . body : <TAB> <TAB> if isinstance ( sym , ast . FunctionDef ) : <TAB> <TAB> <TAB> result = _parse_function_simplified ( sym , symbol . name ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = _parse_class_simplified ( sym ) <TAB> <TAB> <TAB> results . update ( result ) <TAB> lineno = symbol . lineno <TAB> for decorator in symbol . decorator_list : <TAB> <TAB> lineno + = 1 <TAB> results [ lineno ] = ( name , "" c "" ) <TAB> return results ","elif isinstance ( sym , ast . ClassDef ) : 
","elif isinstance ( sym , ast . ClassDef ) :
",100.0,100.0,True
"def append_vars ( pairs , result ) : <TAB> for name , value in sorted ( pairs . items ( ) ) : <TAB> <TAB> if isinstance ( value , list ) : <TAB> <TAB> <TAB> value = "" [ %s ] "" % "" , "" . join ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( "" %s : %s = %s "" % ( package , name , value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( "" %s = %s "" % ( name , value ) ) ","if package : 
","if package :
",78.12,0.0,False
"def nextEditable ( self ) : <TAB> """"""Moves focus of the cursor to the next editable window"""""" <TAB> if self . currentEditable is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ 0 ] <TAB> else : <TAB> <TAB> for ref in weakref . getweakrefs ( self . currentEditable ) : <TAB> <TAB> <TAB> if ref in self . _editableChildren : <TAB> <TAB> <TAB> <TAB> cei = self . _editableChildren . index ( ref ) <TAB> <TAB> <TAB> <TAB> nei = cei + 1 <TAB> <TAB> <TAB> <TAB> if nei > = len ( self . _editableChildren ) : <TAB> <TAB> <TAB> <TAB> <TAB> nei = 0 <TAB> <TAB> <TAB> <TAB> self . _currentEditableRef = self . _editableChildren [ nei ] <TAB> return self . currentEditable ","if len ( self . _editableChildren ) : 
","if len ( self . _editableChildren ) == 1 :
",78.25,63.16,False
"def everythingIsUnicode ( d ) : <TAB> """"""Takes a dictionary, recursively verifies that every value is unicode"""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) and k != "" headers "" : <TAB> <TAB> <TAB> if not everythingIsUnicode ( v ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in v : <TAB> <TAB> <TAB> <TAB> if isinstance ( i , dict ) and not everythingIsUnicode ( i ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <TAB> elif isinstance ( i , _bytes ) : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return True ","elif isinstance ( v , _bytes ) : 
","elif not isinstance ( i , unicode ) :
",41.84,14.92,False
"def is_valid ( sample ) : <TAB> if sample is None : <TAB> <TAB> return False <TAB> if isinstance ( sample , tuple ) : <TAB> <TAB> for s in sample : <TAB> <TAB> <TAB> if s is None : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif isinstance ( s , collections . abc . Sequence ) and len ( s ) == 0 : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","elif isinstance ( s , np . ndarray ) and s . size == 0 : 
","elif isinstance ( s , str ) and s . strip ( ) != "" "" :
",50.76,35.41,False
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> if "" attributes "" in conf [ "" properties "" ] : <TAB> <TAB> <TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED ","if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : 
","if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] :
",100.0,100.0,True
"def encode ( self ) : <TAB> if self . expr in gpregs . expr : <TAB> <TAB> self . value = gpregs . expr . index ( self . expr ) <TAB> <TAB> self . parent . rot2 . value = 0 <TAB> elif isinstance ( self . expr , ExprOp ) and self . expr . op == allshifts [ 3 ] : <TAB> <TAB> reg , value = self . expr . args <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> self . value = gpregs . expr . index ( reg ) <TAB> <TAB> if not isinstance ( value , ExprInt ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> value = int ( value ) <TAB> <TAB> if not value in [ 8 , 16 , 24 ] : <TAB> <TAB> <TAB> return False <TAB> <TAB> self . parent . rot2 . value = value / / 8 <TAB> return True ","if reg not in gpregs . expr : 
","if reg not in gpregs . expr :
",100.0,100.0,True
"def validate_transaction_reference ( self ) : <TAB> bank_account = self . paid_to if self . payment_type == "" Receive "" else self . paid_from <TAB> bank_account_type = frappe . db . get_value ( "" Account "" , bank_account , "" account_type "" ) <TAB> if bank_account_type == "" Bank "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( <TAB> <TAB> <TAB> <TAB> _ ( "" Reference No and Reference Date is mandatory for Bank transaction "" ) <TAB> <TAB> <TAB> ) ","if not self . reference_no or not self . reference_date : 
","if not self . paid_to or not self . paid_from :
",74.54,35.63,False
"def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB> <TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB> <TAB> if hasattr ( monad , "" cls_bl_idname "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None ","if monad . cls_bl_idname == self . cls_bl_idname : 
","if monad . cls_bl_idname == self . cls_bl_idname :
",100.0,100.0,True
"def _create_mask ( self , plen ) : <TAB> mask = [ ] <TAB> for i in range ( 16 ) : <TAB> <TAB> if plen > = 8 : <TAB> <TAB> <TAB> mask . append ( 0xFF ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mask . append ( 0xFF >> ( 8 - plen ) << ( 8 - plen ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask . append ( 0x00 ) <TAB> <TAB> plen - = 8 <TAB> return mask ","elif plen > 0 : 
","elif plen < = 0x20 :
",30.74,17.97,False
"def dataset_to_stream ( dataset , input_name ) : <TAB> """"""Takes a tf.Dataset and creates a numpy stream of ready batches."""""" <TAB> # All input-pipeline processing should be on CPU. <TAB> for example in fastmath . dataset_as_numpy ( dataset ) : <TAB> <TAB> features = example [ 0 ] <TAB> <TAB> inp , out = features [ input_name ] , example [ 1 ] <TAB> <TAB> mask = features [ "" mask "" ] if "" mask "" in features else None <TAB> <TAB> # Some accelerators don't handle uint8 well, cast to int. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> inp = inp . astype ( np . int32 ) <TAB> <TAB> if isinstance ( out , np . uint8 ) : <TAB> <TAB> <TAB> out = out . astype ( np . int32 ) <TAB> <TAB> yield ( inp , out ) if mask is None else ( inp , out , mask ) ","if isinstance ( inp , np . uint8 ) : 
","if isinstance ( inp , np . uint8 ) :
",100.0,100.0,True
"def _idle_redraw_cb ( self ) : <TAB> assert self . _idle_redraw_src_id is not None <TAB> queue = self . _idle_redraw_queue <TAB> if len ( queue ) > 0 : <TAB> <TAB> bbox = queue . pop ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> super ( CanvasRenderer , self ) . queue_draw ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> super ( CanvasRenderer , self ) . queue_draw_area ( * bbox ) <TAB> if len ( queue ) == 0 : <TAB> <TAB> self . _idle_redraw_src_id = None <TAB> <TAB> return False <TAB> return True ","if bbox is None : 
","if bbox is None :
",100.0,100.0,True
"def mutated ( self , indiv ) : <TAB> """"""mutate some genes of the given individual"""""" <TAB> res = indiv . copy ( ) <TAB> # to avoid having a child identical to one of the currentpopulation''' <TAB> for i in range ( self . numParameters ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . xBound is None : <TAB> <TAB> <TAB> <TAB> res [ i ] = indiv [ i ] + gauss ( 0 , self . mutationStdDev ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> res [ i ] = max ( <TAB> <TAB> <TAB> <TAB> <TAB> min ( indiv [ i ] + gauss ( 0 , self . mutationStdDev ) , self . maxs [ i ] ) , <TAB> <TAB> <TAB> <TAB> <TAB> self . mins [ i ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> return res ","if random ( ) < self . mutationProb : 
","if res [ i ] != 0 :
",26.58,5.67,False
"def _justifyDrawParaLine ( tx , offset , extraspace , words , last = 0 ) : <TAB> setXPos ( tx , offset ) <TAB> text = b "" "" . join ( words ) <TAB> if last : <TAB> <TAB> # last one, left align <TAB> <TAB> tx . _textOut ( text , 1 ) <TAB> else : <TAB> <TAB> nSpaces = len ( words ) - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tx . setWordSpace ( extraspace / float ( nSpaces ) ) <TAB> <TAB> <TAB> tx . _textOut ( text , 1 ) <TAB> <TAB> <TAB> tx . setWordSpace ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tx . _textOut ( text , 1 ) <TAB> setXPos ( tx , - offset ) <TAB> return offset ","if nSpaces : 
","if nSpaces > 0 :
",34.79,23.64,False
"def _read_0 ( self , stream ) : <TAB> r = b "" "" <TAB> while True : <TAB> <TAB> c = stream . read ( 2 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> if c == b "" \x00 \x00 "" : <TAB> <TAB> <TAB> break <TAB> <TAB> r + = c <TAB> return r . decode ( self . encoding ) ","if len ( c ) != 2 : 
","if c == b "" "" :
",26.96,6.89,False
"def run ( self , app , editor , args ) : <TAB> line_nums = [ ] <TAB> for cursor in editor . cursors : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line_nums . append ( cursor . y ) <TAB> <TAB> <TAB> data = editor . lines [ cursor . y ] . get_data ( ) . upper ( ) <TAB> <TAB> <TAB> editor . lines [ cursor . y ] . set_data ( data ) ","if cursor . y not in line_nums : 
","if cursor . y not in line_nums :
",100.0,100.0,True
"def create_default_energy_point_rules ( ) : <TAB> for rule in get_default_energy_point_rules ( ) : <TAB> <TAB> # check if any rule for ref. doctype exists <TAB> <TAB> rule_exists = frappe . db . exists ( <TAB> <TAB> <TAB> "" Energy Point Rule "" , { "" reference_doctype "" : rule . get ( "" reference_doctype "" ) } <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = frappe . get_doc ( rule ) <TAB> <TAB> doc . insert ( ignore_permissions = True ) ","if rule_exists : 
","if not rule_exists :
",36.35,53.73,False
"def __new__ ( cls , * nodes ) : <TAB> if not nodes : <TAB> <TAB> raise TypeError ( "" DisjunctionNode() requires at least one node "" ) <TAB> elif len ( nodes ) == 1 : <TAB> <TAB> return nodes [ 0 ] <TAB> self = super ( DisjunctionNode , cls ) . __new__ ( cls ) <TAB> self . __nodes = [ ] <TAB> # TODO: Remove duplicates? <TAB> for node in nodes : <TAB> <TAB> if not isinstance ( node , Node ) : <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" DisjunctionNode() expects Node instances as arguments; "" <TAB> <TAB> <TAB> <TAB> ""  received a non-Node instance  %r "" % node <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __nodes . extend ( node . __nodes ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __nodes . append ( node ) <TAB> return self ","if isinstance ( node , DisjunctionNode ) : 
","if hasattr ( node , "" __nodes "" ) :
",33.08,16.59,False
def dfs ( v : str ) - > Iterator [ Set [ str ] ] : <TAB> index [ v ] = len ( stack ) <TAB> stack . append ( v ) <TAB> boundaries . append ( index [ v ] ) <TAB> for w in edges [ v ] : <TAB> <TAB> if w not in index : <TAB> <TAB> <TAB> yield from dfs ( w ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> while index [ w ] < boundaries [ - 1 ] : <TAB> <TAB> <TAB> <TAB> boundaries . pop ( ) <TAB> if boundaries [ - 1 ] == index [ v ] : <TAB> <TAB> boundaries . pop ( ) <TAB> <TAB> scc = set ( stack [ index [ v ] : ] ) <TAB> <TAB> del stack [ index [ v ] : ] <TAB> <TAB> identified . update ( scc ) <TAB> <TAB> yield scc ,"elif w not in identified : 
","if boundaries [ - 1 ] < index [ v ] :
",26.2,3.39,False
"def unpack_item_obj ( map_uuid_global_id , misp_obj ) : <TAB> obj_meta = get_object_metadata ( misp_obj ) <TAB> obj_id = None <TAB> io_content = None <TAB> for attribute in misp_obj . attributes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> obj_id = attribute . value<TAB> # # TODO: sanitize <TAB> <TAB> <TAB> io_content = attribute . data<TAB> # # TODO: check if type == io <TAB> if obj_id and io_content : <TAB> <TAB> res = Item . create_item ( obj_id , obj_meta , io_content ) <TAB> <TAB> map_uuid_global_id [ misp_obj . uuid ] = get_global_id ( "" item "" , obj_id ) ","if attribute . object_relation == "" raw-data "" : 
","if attribute . name == "" id "" :
",58.81,24.44,False
"def parse ( self , response ) : <TAB> soup = BeautifulSoup ( response . content . decode ( "" utf-8 "" , "" ignore "" ) , "" lxml "" ) <TAB> image_divs = soup . find_all ( "" div "" , class_ = "" imgpt "" ) <TAB> pattern = re . compile ( r "" murl \"" : \"" (.*?) \ .jpg "" ) <TAB> for div in image_divs : <TAB> <TAB> href_str = html_parser . HTMLParser ( ) . unescape ( div . a [ "" m "" ] ) <TAB> <TAB> match = pattern . search ( href_str ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = match . group ( 1 ) if six . PY3 else match . group ( 1 ) . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> img_url = "" {} .jpg "" . format ( name ) <TAB> <TAB> <TAB> yield dict ( file_url = img_url ) ","if match : 
","if match :
",78.12,0.0,False
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors ","if fn is not None : 
","if fn :
",29.58,0.0,False
"def decompileFormat1 ( self , reader , otFont ) : <TAB> self . classDefs = classDefs = [ ] <TAB> startGlyphID = reader . readUShort ( ) <TAB> glyphCount = reader . readUShort ( ) <TAB> for i in range ( glyphCount ) : <TAB> <TAB> glyphName = otFont . getglyphName ( startGlyphID + i ) <TAB> <TAB> classValue = reader . readUShort ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> classDefs . append ( ( glyphName , classValue ) ) ","if classValue : 
","if classValue :
",78.12,0.0,False
"def compress ( self , data_list ) : <TAB> if len ( data_list ) == 2 : <TAB> <TAB> value , lookup_expr = data_list <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if lookup_expr not in EMPTY_VALUES : <TAB> <TAB> <TAB> <TAB> return Lookup ( value = value , lookup_expr = lookup_expr ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise forms . ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> self . error_messages [ "" lookup_required "" ] , code = "" lookup_required "" <TAB> <TAB> <TAB> <TAB> ) <TAB> return None ","if value not in EMPTY_VALUES : 
","if value is not None :
",30.13,13.83,False
"def open_compat ( path , mode = "" r "" ) : <TAB> if mode in [ "" r "" , "" rb "" ] and not os . path . exists ( path ) : <TAB> <TAB> raise FileNotFoundError ( u ' The file  "" %s ""  could not be found ' % path ) <TAB> if sys . version_info > = ( 3 , ) : <TAB> <TAB> encoding = "" utf-8 "" <TAB> <TAB> errors = "" replace "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> encoding = None <TAB> <TAB> <TAB> errors = None <TAB> <TAB> return open ( path , mode , encoding = encoding , errors = errors ) <TAB> else : <TAB> <TAB> return open ( path , mode ) ","if mode in [ "" rb "" , "" wb "" , "" ab "" ] : 
","if encoding == "" utf-8 "" :
",36.43,2.54,False
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> if fn is not None : <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors ","if _path [ - 1 ] != current_path [ - 1 ] : 
","if _path and _path [ - 1 ] != "" . "" :
",61.06,50.95,False
"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB> <TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB> <TAB> lookup = "" "" <TAB> <TAB> if "" "" in level_per_module : <TAB> <TAB> <TAB> level = level_per_module [ "" "" ] <TAB> <TAB> for n in name . split ( "" . "" ) : <TAB> <TAB> <TAB> lookup + = n <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> level = level_per_module [ lookup ] <TAB> <TAB> <TAB> lookup + = "" . "" <TAB> if level is False : <TAB> <TAB> return False <TAB> return record [ "" level "" ] . no > = level ","if lookup in level_per_module : 
","if lookup in level_per_module :
",100.0,100.0,True
"def CountButtons ( self ) : <TAB> """"""Returns the number of visible buttons in the docked pane."""""" <TAB> n = 0 <TAB> if self . HasCaption ( ) or self . HasCaptionLeft ( ) : <TAB> <TAB> if isinstance ( wx . GetTopLevelParent ( self . window ) , AuiFloatingFrame ) : <TAB> <TAB> <TAB> return 1 <TAB> <TAB> if self . HasCloseButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasMinimizeButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> if self . HasPinButton ( ) : <TAB> <TAB> <TAB> n + = 1 <TAB> return n ","if self . HasMaximizeButton ( ) : 
","if self . HasWindowWindow ( ) :
",63.85,41.11,False
"def search ( a , b , desired ) : <TAB> if a == b : <TAB> <TAB> return a <TAB> if abs ( b - a ) < 0.005 : <TAB> <TAB> ca = count ( a ) <TAB> <TAB> cb = count ( b ) <TAB> <TAB> dista = abs ( desired - ca ) <TAB> <TAB> distb = abs ( desired - cb ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return a <TAB> <TAB> else : <TAB> <TAB> <TAB> return b <TAB> m = ( a + b ) / 2.0 <TAB> cm = count ( m ) <TAB> if desired < cm : <TAB> <TAB> return search ( m , b , desired ) <TAB> else : <TAB> <TAB> return search ( a , m , desired ) ","if dista < distb : 
","if dista < distb :
",100.0,100.0,True
"def force_ipv4 ( self , * args ) : <TAB> """"""only ipv4 localhost in /etc/hosts"""""" <TAB> logg . debug ( "" checking /etc/hosts for  ' ::1 localhost ' "" ) <TAB> lines = [ ] <TAB> for line in open ( self . etc_hosts ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newline = re . sub ( "" \\ slocalhost \\ s "" , "" "" , line ) <TAB> <TAB> <TAB> if line != newline : <TAB> <TAB> <TAB> <TAB> logg . info ( "" /etc/hosts:  ' %s '  =>  ' %s ' "" , line . rstrip ( ) , newline . rstrip ( ) ) <TAB> <TAB> <TAB> <TAB> line = newline <TAB> <TAB> lines . append ( line ) <TAB> f = open ( self . etc_hosts ( ) , "" w "" ) <TAB> for line in lines : <TAB> <TAB> f . write ( line ) <TAB> f . close ( ) ","if "" ::1 "" in line : 
","if line . startswith ( "" localhost "" ) :
",33.22,6.27,False
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not isinstance ( data , dict ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> if not isinstance ( inner , dict ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id ","if not fpath . exists ( ) : 
","if not os . path . exists ( fpath . name ) :
",37.78,18.48,False
"def _get_dbutils ( ) : <TAB> try : <TAB> <TAB> import IPython <TAB> <TAB> ip_shell = IPython . get_ipython ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise _NoDbutilsError <TAB> <TAB> return ip_shell . ns_table [ "" user_global "" ] [ "" dbutils "" ] <TAB> except ImportError : <TAB> <TAB> raise _NoDbutilsError <TAB> except KeyError : <TAB> <TAB> raise _NoDbutilsError ","if ip_shell is None : 
","if not ip_shell . ns_table :
",27.95,17.75,False
"def _bytecode_filenames ( self , py_filenames ) : <TAB> bytecode_files = [ ] <TAB> for py_file in py_filenames : <TAB> <TAB> # Since build_py handles package data installation, the <TAB> <TAB> # list of outputs can contain more than just .py files. <TAB> <TAB> # Make sure we only report bytecode for the .py files. <TAB> <TAB> ext = os . path . splitext ( os . path . normcase ( py_file ) ) [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if self . compile : <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" c "" ) <TAB> <TAB> if self . optimize > 0 : <TAB> <TAB> <TAB> bytecode_files . append ( py_file + "" o "" ) <TAB> return bytecode_files ","if ext != PYTHON_SOURCE_EXTENSION : 
","if ext not in self . _ext :
",29.98,10.15,False
"def compute_distances_mu ( line , pts , result , gates , tolerance ) : <TAB> """"""calculate all distances with mathuutils"""""" <TAB> line_origin = V ( line [ 0 ] ) <TAB> line_end = V ( line [ - 1 ] ) <TAB> local_result = [ [ ] , [ ] , [ ] , [ ] , [ ] ] <TAB> for point in pts : <TAB> <TAB> data = compute_distance ( V ( point ) , line_origin , line_end , tolerance ) <TAB> <TAB> for i , res in enumerate ( local_result ) : <TAB> <TAB> <TAB> res . append ( data [ i ] ) <TAB> for i , res in enumerate ( result ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res . append ( local_result [ i ] ) ","if gates [ i ] : 
","if i < len ( result ) - 1 :
",27.16,5.52,False
"def _get_next_segment ( self , segment_path , page_size , segment_cursor = None ) : <TAB> if segment_path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> return Segment ( self . client , segment_path , page_size , segment_cursor ) <TAB> return None ","if self . end_time and self . _is_later_than_end_time ( segment_path ) : 
","if not self . _has_segment ( self . client , segment_path ) :
",38.33,21.39,False
"def _check_number_of_sessions ( ) : <TAB> nb_desktop_sessions = sessions . get_number_of_desktop_sessions ( ignore_gdm = True ) <TAB> if nb_desktop_sessions > 1 : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" WARNING : There are  %d  other desktop sessions open. The GPU switch will not become effective until you have manually "" <TAB> <TAB> <TAB> ""  logged out from ALL desktop sessions. \n "" <TAB> <TAB> <TAB> "" Continue ? (y/N) "" % ( nb_desktop_sessions - 1 ) <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sys . exit ( 0 ) ","if not confirmation : 
","if not confirmation :
",100.0,100.0,True
"def delete_compute_environment ( self , compute_environment_name ) : <TAB> if compute_environment_name is None : <TAB> <TAB> raise InvalidParameterValueException ( "" Missing computeEnvironment parameter "" ) <TAB> compute_env = self . get_compute_environment ( compute_environment_name ) <TAB> if compute_env is not None : <TAB> <TAB> # Pop ComputeEnvironment <TAB> <TAB> self . _compute_environments . pop ( compute_env . arn ) <TAB> <TAB> # Delete ECS cluster <TAB> <TAB> self . ecs_backend . delete_cluster ( compute_env . ecs_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Delete compute environment <TAB> <TAB> <TAB> instance_ids = [ instance . id for instance in compute_env . instances ] <TAB> <TAB> <TAB> self . ec2_backend . terminate_instances ( instance_ids ) ","if compute_env . env_type == "" MANAGED "" : 
","if compute_env . instances :
",36.67,23.67,False
"def run ( self ) : <TAB> results = { } <TAB> for func_name in [ <TAB> <TAB> # Execute every function starting with check_* <TAB> <TAB> fn <TAB> <TAB> for fn in self . check_functions <TAB> <TAB> # if the user does not specify any name <TAB> <TAB> if not self . args . get ( "" check "" ) <TAB> <TAB> # of if specify the current function name <TAB> <TAB> or self . args . get ( "" check "" ) == fn <TAB> ] : <TAB> <TAB> function = getattr ( self , func_name ) <TAB> <TAB> log . warn ( function . __doc__ ) <TAB> <TAB> result = function ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" \n "" . join ( result ) ) <TAB> <TAB> <TAB> results . update ( { func_name : result } ) <TAB> return results ","if result : 
","if result :
",78.12,0.0,False
"def invalidate ( self , layers = None ) : <TAB> if layers is None : <TAB> <TAB> layers = Layer . AllLayers <TAB> if layers : <TAB> <TAB> layers = set ( layers ) <TAB> <TAB> self . invalidLayers . update ( layers ) <TAB> <TAB> blockRenderers = [ <TAB> <TAB> <TAB> br <TAB> <TAB> <TAB> for br in self . blockRenderers <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> <TAB> if len ( blockRenderers ) < len ( self . blockRenderers ) : <TAB> <TAB> <TAB> self . forgetDisplayLists ( ) <TAB> <TAB> self . blockRenderers = blockRenderers <TAB> <TAB> if self . renderer . showRedraw and Layer . Blocks in layers : <TAB> <TAB> <TAB> self . needsRedisplay = True ","if br . layer is Layer . Blocks or br . layer not in layers 
","if br . layerName in layers
",39.64,8.48,False
"def get_library_dirs ( platform , arch = None ) : <TAB> if platform == "" win32 "" : <TAB> <TAB> jre_home = get_jre_home ( platform ) <TAB> <TAB> jdk_home = JAVA_HOME <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> jre_home = jre_home . decode ( "" utf-8 "" ) <TAB> <TAB> return [ join ( jdk_home , "" lib "" ) , join ( jdk_home , "" bin "" , "" server "" ) ] <TAB> elif platform == "" android "" : <TAB> <TAB> return [ "" libs/ {} "" . format ( arch ) ] <TAB> return [ ] ","if isinstance ( jre_home , bytes ) : 
","if isinstance ( jre_home , bytes ) :
",100.0,100.0,True
"def save_plugin_options ( self ) : <TAB> for name , option_widgets in self . _plugin_option_widgets . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . config [ "" plugins "" ] [ name ] = { } <TAB> <TAB> plugin_config = self . config [ "" plugins "" ] [ <TAB> <TAB> <TAB> name <TAB> <TAB> ]<TAB> # use or instead of get incase the value is actually None <TAB> <TAB> for option_name , option_widget in option_widgets . items ( ) : <TAB> <TAB> <TAB> plugin_config [ option_name ] = option_widget . option . get_widget_value ( <TAB> <TAB> <TAB> <TAB> option_widget . widget <TAB> <TAB> <TAB> ) ","if name not in self . config [ "" plugins "" ] : 
","if name not in self . config [ "" plugins "" ] :
",100.0,100.0,True
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> if str_in [ pos ] == start_tag : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> elif str_in [ pos ] == end_tag : <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel ","if depth == 0 : 
","if depth == 0 :
",100.0,100.0,True
"def _coerce_to_bool ( self , node , var , true_val = True ) : <TAB> """"""Coerce the values in a variable to bools."""""" <TAB> bool_var = self . program . NewVariable ( ) <TAB> for b in var . bindings : <TAB> <TAB> v = b . data <TAB> <TAB> if isinstance ( v , mixin . PythonConstant ) and isinstance ( v . pyval , bool ) : <TAB> <TAB> <TAB> const = v . pyval is true_val <TAB> <TAB> elif not compare . compatible_with ( v , True ) : <TAB> <TAB> <TAB> const = not true_val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> const = true_val <TAB> <TAB> else : <TAB> <TAB> <TAB> const = None <TAB> <TAB> bool_var . AddBinding ( self . convert . bool_values [ const ] , { b } , node ) <TAB> return bool_var ","elif not compare . compatible_with ( v , False ) : 
","elif compare . compatible_with ( v , False ) :
",75.59,84.96,False
def multiline_indentation ( self ) : <TAB> if self . _multiline_indentation is None : <TAB> <TAB> offset = 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> offset = 2 <TAB> <TAB> indentation = make_indentation ( 3 * self . indent_size + offset ) <TAB> <TAB> self . _multiline_indentation = indentation <TAB> if self . current_rule : <TAB> <TAB> indent_extra = make_indentation ( self . indent_size ) <TAB> <TAB> return self . _multiline_indentation + indent_extra <TAB> return self . _multiline_indentation ,"if self . show_aligned_keywords : 
","if self . current_rule :
",64.48,20.87,False
"def __call__ ( self , event , data = None ) : <TAB> datatype , delta = event <TAB> self . midi_ctrl . delta + = delta <TAB> if TIMING_CLOCK in datatype and not self . played : <TAB> <TAB> self . midi_ctrl . pulse + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> t_master = 60.0 <TAB> <TAB> <TAB> self . midi_ctrl . bpm = round ( 60.0 / self . midi_ctrl . delta , 0 ) <TAB> <TAB> <TAB> self . midi_ctrl . pulse = 0 <TAB> <TAB> <TAB> self . midi_ctrl . delta = 0.0 ","if self . midi_ctrl . pulse == self . midi_ctrl . ppqn : 
","if self . pulse > = self . midi_ctrl . pulse :
",59.54,47.33,False
"def handle_sent ( self , elt ) : <TAB> sent = [ ] <TAB> for child in elt : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> itm = self . handle_word ( child ) <TAB> <TAB> <TAB> if self . _unit == "" word "" : <TAB> <TAB> <TAB> <TAB> sent . extend ( itm ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sent . append ( itm ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unexpected element  %s "" % child . tag ) <TAB> return SemcorSentence ( elt . attrib [ "" snum "" ] , sent ) ","if child . tag in ( "" wf "" , "" punc "" ) : 
","if child . tag . startswith ( "" sent "" ) :
",48.9,26.61,False
"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef . error : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( testdef . exception , Exception ) : <TAB> <TAB> <TAB> <TAB> raise testdef . exception <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise Exception ( testdef . exception ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Test parse failure "" ) ","if testdef . exception : 
","if testdef . exception :
",100.0,100.0,True
"def _authorized_sid ( self , jid , sid , ifrom , iq ) : <TAB> with self . _preauthed_sids_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _preauthed_sids [ ( jid , sid , ifrom ) ] <TAB> <TAB> <TAB> return True <TAB> <TAB> return False ","if ( jid , sid , ifrom ) in self . _preauthed_sids : 
","if ( jid , sid , ifrom ) in self . _preauthed_sids :
",100.0,100.0,True
"def wait ( self , timeout = None ) : <TAB> if self . returncode is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msecs = _subprocess . INFINITE <TAB> <TAB> else : <TAB> <TAB> <TAB> msecs = max ( 0 , int ( timeout * 1000 + 0.5 ) ) <TAB> <TAB> res = _subprocess . WaitForSingleObject ( int ( self . _handle ) , msecs ) <TAB> <TAB> if res == _subprocess . WAIT_OBJECT_0 : <TAB> <TAB> <TAB> code = _subprocess . GetExitCodeProcess ( self . _handle ) <TAB> <TAB> <TAB> if code == TERMINATE : <TAB> <TAB> <TAB> <TAB> code = - signal . SIGTERM <TAB> <TAB> <TAB> self . returncode = code <TAB> return self . returncode ","if timeout is None : 
","if timeout is None :
",100.0,100.0,True
"def _gen_legal_y_s_t ( self ) : <TAB> while True : <TAB> <TAB> y = self . _gen_random_scalar ( ) <TAB> <TAB> s = self . tec_arithmetic . mul ( <TAB> <TAB> <TAB> scalar = y , a = self . tec_arithmetic . get_generator ( ) <TAB> <TAB> )<TAB> # S = yG <TAB> <TAB> t = self . _hash_tec_element ( s ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Both S and T are legal <TAB> <TAB> <TAB> LOGGER . info ( "" randomly generated y, S, T "" ) <TAB> <TAB> <TAB> return y , s , t ","if self . tec_arithmetic . is_in_group ( s ) and type ( t ) != int : 
","if t != 0 :
",25.6,1.02,False
"def write_out ( ) : <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> data_str = self . instrument_queue . get ( ) <TAB> <TAB> data_str = data_str . splitlines ( ) <TAB> <TAB> tb . write ( "" "" )<TAB> # position cursor to end <TAB> <TAB> for line in data_str : <TAB> <TAB> <TAB> tb . write ( line ) <TAB> <TAB> tb . write ( "" \n "" ) ","if self . instrument_queue . empty ( ) : 
","if self . instrument_queue . empty ( ) :
",100.0,100.0,True
"def _parse_preamble ( self ) : <TAB> """"""Parse metadata about query (PRIVATE)."""""" <TAB> meta = { } <TAB> while self . line : <TAB> <TAB> regx = re . search ( _RE_QUERY , self . line ) <TAB> <TAB> if regx : <TAB> <TAB> <TAB> self . query_id = regx . group ( 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . seq_len = int ( self . line . strip ( ) . split ( ) [ 1 ] ) <TAB> <TAB> self . line = self . handle . readline ( ) . strip ( ) <TAB> return meta ","if self . line . startswith ( "" Match_columns "" ) : 
","if self . query_id == "" seq_len "" :
",37.32,13.07,False
"def init_sequence ( self , coll_name , seq_config ) : <TAB> if not isinstance ( seq_config , list ) : <TAB> <TAB> raise Exception ( ' "" sequence ""  config must be a list ' ) <TAB> handlers = [ ] <TAB> for entry in seq_config : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( ' "" sequence ""  entry must be a dict ' ) <TAB> <TAB> name = entry . get ( "" name "" , "" "" ) <TAB> <TAB> handler = self . load_coll ( name , entry ) <TAB> <TAB> handlers . append ( handler ) <TAB> return HandlerSeq ( handlers ) ","if not isinstance ( entry , dict ) : 
","if not isinstance ( entry , dict ) :
",100.0,100.0,True
"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB> <TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB> <TAB> if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : <TAB> <TAB> <TAB> ind + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB> <TAB> if "" : "" in line and len ( line ) > 0 : <TAB> <TAB> <TAB> lines = line . split ( "" : "" ) <TAB> <TAB> <TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d ","if start < ind : 
","if start :
",31.77,0.0,False
"def wait ( self ) : <TAB> while True : <TAB> <TAB> return_code = self . _process . poll ( ) <TAB> <TAB> if return_code is not None : <TAB> <TAB> <TAB> line = self . _process . stdout . readline ( ) . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> log . debug ( line . strip ( "" \n "" ) ) <TAB> return True ","if line == "" "" : 
","if return_code == 0 :
",27.91,13.13,False
"def __getattr__ ( self , key ) : <TAB> for tag in self . tag . children : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if "" name "" in tag . attrs and tag . attrs [ "" name "" ] in ( key , ) : <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> return DOMImplementation . createHTMLElement ( self . doc , tag ) <TAB> raise AttributeError ","if tag . name not in ( "" input "" , ) : 
","if tag . tag != "" input "" :
",38.66,20.23,False
"def compare_hash ( hash_of_gold , path_to_file ) : <TAB> with open ( path_to_file , "" rb "" ) as f : <TAB> <TAB> hash_of_file = hashlib . sha256 ( f . read ( ) ) . hexdigest ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" ########## Hash sum of "" , <TAB> <TAB> <TAB> <TAB> path_to_file , <TAB> <TAB> <TAB> <TAB> "" differs from the target, the topology will be deleted !!! ########## "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> shutil . rmtree ( os . path . dirname ( path_to_file ) ) ","if hash_of_file != hash_of_gold : 
","if hash_of_gold != hash_of_file :
",54.02,79.72,False
def on_completed2 ( ) : <TAB> doner [ 0 ] = True <TAB> if not qr : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> observer . on_next ( False ) <TAB> <TAB> <TAB> observer . on_completed ( ) <TAB> <TAB> elif donel [ 0 ] : <TAB> <TAB> <TAB> observer . on_next ( True ) <TAB> <TAB> <TAB> observer . on_completed ( ) ,"if len ( ql ) > 0 : 
","if qr :
",26.62,0.0,False
"def get_other ( self , data , items ) : <TAB> is_tuple = False <TAB> if type ( data ) == tuple : <TAB> <TAB> data = list ( data ) <TAB> <TAB> is_tuple = True <TAB> if type ( data ) == list : <TAB> <TAB> m_items = items . copy ( ) <TAB> <TAB> for idx , item in enumerate ( items ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> m_items [ idx ] = len ( data ) - abs ( item ) <TAB> <TAB> for i in sorted ( set ( m_items ) , reverse = True ) : <TAB> <TAB> <TAB> if i < len ( data ) and i > - 1 : <TAB> <TAB> <TAB> <TAB> del data [ i ] <TAB> <TAB> if is_tuple : <TAB> <TAB> <TAB> return tuple ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return data <TAB> else : <TAB> <TAB> return None ","if item < 0 : 
","if abs ( item ) > 0.5 :
",27.8,7.27,False
"def _open_url ( cls , url ) : <TAB> if config . browser : <TAB> <TAB> cmd = [ config . browser , url ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" running command:  %s "" % "" "" . join ( cmd ) ) <TAB> <TAB> p = Popen ( cmd ) <TAB> <TAB> p . communicate ( ) <TAB> else : <TAB> <TAB> if not config . quiet : <TAB> <TAB> <TAB> print ( "" opening URL in browser:  %s "" % url ) <TAB> <TAB> webbrowser . open_new ( url ) ","if not config . quiet : 
","if not config . quiet :
",100.0,100.0,True
"def setLabel ( self , s , protect = False ) : <TAB> """"""Set the label of the minibuffer."""""" <TAB> c , k , w = self . c , self , self . w <TAB> if w : <TAB> <TAB> # Support for the curses gui. <TAB> <TAB> if hasattr ( g . app . gui , "" set_minibuffer_label "" ) : <TAB> <TAB> <TAB> g . app . gui . set_minibuffer_label ( c , s ) <TAB> <TAB> w . setAllText ( s ) <TAB> <TAB> n = len ( s ) <TAB> <TAB> w . setSelectionRange ( n , n , insert = n ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> k . mb_prefix = s ","if protect : 
","if protect and s . endswith ( "" .mb-prefix "" ) :
",32.64,6.84,False
"def __init__ ( self , path ) : <TAB> self . symcaches = [ ] <TAB> for path in path . split ( "" ; "" ) : <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> self . symcaches . append ( SymbolCache ( dirname = path ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> import cobra <TAB> <TAB> <TAB> self . symcaches . append ( cobra . CobraProxy ( path ) ) <TAB> <TAB> <TAB> continue ","if path . startswith ( "" cobra:// "" ) or path . startswith ( "" cobrassl:// "" ) : 
","if os . path . isfile ( path ) :
",18.73,3.15,False
"def init_params ( net ) : <TAB> """"""Init layer parameters."""""" <TAB> for module in net . modules ( ) : <TAB> <TAB> if isinstance ( module , nn . Conv2d ) : <TAB> <TAB> <TAB> init . kaiming_normal ( module . weight , mode = "" fan_out "" ) <TAB> <TAB> <TAB> if module . bias : <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> init . constant ( module . weight , 1 ) <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) <TAB> <TAB> elif isinstance ( module , nn . Linear ) : <TAB> <TAB> <TAB> init . normal ( module . weight , std = 1e-3 ) <TAB> <TAB> <TAB> if module . bias : <TAB> <TAB> <TAB> <TAB> init . constant ( module . bias , 0 ) ","elif isinstance ( module , nn . BatchNorm2d ) : 
","elif isinstance ( module , nn . BatchNorm2d ) :
",100.0,100.0,True
"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> elif old [ key ] != new [ key ] : <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> <TAB> added . append ( key ) <TAB> for key , value in new . items ( ) : <TAB> <TAB> if key not in old : <TAB> <TAB> <TAB> added . append ( key ) <TAB> if removed : <TAB> <TAB> diff [ "" removed "" ] = sorted ( removed ) <TAB> if added : <TAB> <TAB> diff [ "" added "" ] = sorted ( added ) <TAB> return diff ","if key not in new : 
","if key not in new :
",100.0,100.0,True
"def __init__ ( self , * args , * * kwargs ) : <TAB> _kwargs = { <TAB> <TAB> "" max_length "" : 20 , <TAB> <TAB> "" widget "" : forms . TextInput ( attrs = { "" autocomplete "" : "" off "" } ) , <TAB> <TAB> "" label "" : _ ( "" Card number "" ) , <TAB> } <TAB> if "" types "" in kwargs : <TAB> <TAB> self . accepted_cards = set ( kwargs . pop ( "" types "" ) ) <TAB> <TAB> difference = self . accepted_cards - VALID_CARDS <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" The following accepted_cards are  "" "" unknown:  %s "" % difference <TAB> <TAB> <TAB> ) <TAB> _kwargs . update ( kwargs ) <TAB> super ( ) . __init__ ( * args , * * _kwargs ) ","if difference : 
","if difference :
",78.12,0.0,False
"def dumps ( self ) : <TAB> sections = [ ] <TAB> for name , env_info in self . _dependencies_ . items ( ) : <TAB> <TAB> sections . append ( "" [ENV_ %s ] "" % name ) <TAB> <TAB> for var , values in sorted ( env_info . vars . items ( ) ) : <TAB> <TAB> <TAB> tmp = "" %s = "" % var <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp + = "" [ %s ] "" % "" , "" . join ( [ ' "" %s "" ' % val for val in values ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tmp + = "" %s "" % values <TAB> <TAB> <TAB> sections . append ( tmp ) <TAB> return "" \n "" . join ( sections ) ","if isinstance ( values , list ) : 
","if isinstance ( values , list ) :
",100.0,100.0,True
"def air_quality ( self ) : <TAB> aqi_data = self . _get_aqi_data ( ) <TAB> if aqi_data : <TAB> <TAB> if aqi_data . get ( "" status "" ) == "" ok "" : <TAB> <TAB> <TAB> aqi_data = self . _organize ( aqi_data ) <TAB> <TAB> <TAB> aqi_data = self . _manipulate ( aqi_data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . py3 . error ( aqi_data . get ( "" data "" ) ) <TAB> return { <TAB> <TAB> "" cached_until "" : self . py3 . time_in ( self . cache_timeout ) , <TAB> <TAB> "" full_text "" : self . py3 . safe_format ( self . format , aqi_data ) , <TAB> } ","elif aqi_data . get ( "" status "" ) == "" error "" : 
","if not aqi_data . get ( "" status "" ) == "" error "" :
",86.6,87.82,False
"def _blend ( x , y ) :<TAB> # pylint: disable=invalid-name <TAB> """"""Implements the ""blend"" strategy for `deep_merge`."""""" <TAB> if isinstance ( x , ( dict , OrderedDict ) ) : <TAB> <TAB> if not isinstance ( y , ( dict , OrderedDict ) ) : <TAB> <TAB> <TAB> return y <TAB> <TAB> return _merge ( x , y , recursion_func = _blend ) <TAB> if isinstance ( x , ( list , tuple ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return y <TAB> <TAB> result = [ _blend ( * i ) for i in zip ( x , y ) ] <TAB> <TAB> if len ( x ) > len ( y ) : <TAB> <TAB> <TAB> result + = x [ len ( y ) : ] <TAB> <TAB> elif len ( x ) < len ( y ) : <TAB> <TAB> <TAB> result + = y [ len ( x ) : ] <TAB> <TAB> return result <TAB> return y ","if not isinstance ( y , ( list , tuple ) ) : 
","if len ( x ) == len ( y ) :
",27.68,10.14,False
"def _rate ( cls , sample1 , sample2 ) : <TAB> "" Simple rate "" <TAB> try : <TAB> <TAB> interval = sample2 [ 0 ] - sample1 [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Infinity ( ) <TAB> <TAB> delta = sample2 [ 1 ] - sample1 [ 1 ] <TAB> <TAB> if delta < 0 : <TAB> <TAB> <TAB> raise UnknownValue ( ) <TAB> <TAB> return ( sample2 [ 0 ] , delta / interval , sample2 [ 2 ] , sample2 [ 3 ] ) <TAB> except Infinity : <TAB> <TAB> raise <TAB> except UnknownValue : <TAB> <TAB> raise <TAB> except Exception as e : <TAB> <TAB> raise NaN ( e ) ","if interval == 0 : 
","if interval < 0 :
",58.14,24.74,False
"def wrapped_request_method ( * args , * * kwargs ) : <TAB> """"""Modifies HTTP headers to include a specified user-agent."""""" <TAB> if kwargs . get ( "" headers "" ) is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if user_agent not in kwargs [ "" headers "" ] [ "" user-agent "" ] : <TAB> <TAB> <TAB> <TAB> # Save the existing user-agent header and tack on our own. <TAB> <TAB> <TAB> <TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = ( <TAB> <TAB> <TAB> <TAB> <TAB> f "" { user_agent } "" f ' { kwargs [ "" headers "" ] [ "" user-agent "" ] } ' <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> kwargs [ "" headers "" ] [ "" user-agent "" ] = user_agent <TAB> else : <TAB> <TAB> kwargs [ "" headers "" ] = { "" user-agent "" : user_agent } <TAB> return request_method ( * args , * * kwargs ) ","if kwargs [ "" headers "" ] . get ( "" user-agent "" ) : 
","if "" user-agent "" in kwargs [ "" headers "" ] :
",56.28,43.49,False
"def remove_addons ( auth , resource_object_list ) : <TAB> for config in AbstractNode . ADDONS_AVAILABLE : <TAB> <TAB> try : <TAB> <TAB> <TAB> settings_model = config . node_settings <TAB> <TAB> except LookupError : <TAB> <TAB> <TAB> settings_model = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> addon_list = settings_model . objects . filter ( <TAB> <TAB> <TAB> <TAB> owner__in = resource_object_list , is_deleted = False <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> for addon in addon_list : <TAB> <TAB> <TAB> <TAB> addon . after_delete ( auth . user ) ","if settings_model : 
","if settings_model :
",78.12,100.0,True
"def Decorator ( * args , * * kwargs ) : <TAB> delay = 0.2 <TAB> num_attempts = 15 <TAB> cur_attempt = 0 <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return f ( * args , * * kwargs ) <TAB> <TAB> except exceptions . WebDriverException as e : <TAB> <TAB> <TAB> logging . warning ( "" Selenium raised  %s "" , utils . SmartUnicode ( e ) ) <TAB> <TAB> <TAB> cur_attempt + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> time . sleep ( delay ) ","if cur_attempt == num_attempts : 
","if cur_attempt > num_attempts :
",58.14,53.42,False
"def _cleanup_parts_dir ( parts_dir , local_plugins_dir , parts ) : <TAB> if os . path . exists ( parts_dir ) : <TAB> <TAB> logger . info ( "" Cleaning up parts directory "" ) <TAB> <TAB> for subdirectory in os . listdir ( parts_dir ) : <TAB> <TAB> <TAB> path = os . path . join ( parts_dir , subdirectory ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( path ) <TAB> <TAB> <TAB> <TAB> except NotADirectoryError : <TAB> <TAB> <TAB> <TAB> <TAB> os . remove ( path ) <TAB> for part in parts : <TAB> <TAB> part . mark_cleaned ( steps . BUILD ) <TAB> <TAB> part . mark_cleaned ( steps . PULL ) ","if path != local_plugins_dir : 
","if os . path . isdir ( path ) :
",27.58,5.52,False
"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB> <TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB> <TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB> <TAB> # reach leaf <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB> <TAB> <TAB> tree , sample , cur_node_idx <TAB> <TAB> ) <TAB> <TAB> if reach_leaf : <TAB> <TAB> <TAB> node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB> <TAB> node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB> return node_pos ","if cur_node_idx == - 1 : 
","if cur_node_idx == 0 :
",36.53,70.81,False
"def get_measurements ( self , pipeline , object_name , category ) : <TAB> if self . get_categories ( pipeline , object_name ) == [ category ] : <TAB> <TAB> results = [ ] <TAB> <TAB> if self . do_corr_and_slope : <TAB> <TAB> <TAB> if object_name == "" Image "" : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" , "" Slope "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results + = [ "" Correlation "" ] <TAB> <TAB> if self . do_overlap : <TAB> <TAB> <TAB> results + = [ "" Overlap "" , "" K "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results + = [ "" Manders "" ] <TAB> <TAB> if self . do_rwc : <TAB> <TAB> <TAB> results + = [ "" RWC "" ] <TAB> <TAB> if self . do_costes : <TAB> <TAB> <TAB> results + = [ "" Costes "" ] <TAB> <TAB> return results <TAB> return [ ] ","if self . do_manders : 
","if self . do_manders :
",100.0,100.0,True
"def create_connection ( self , infos , f2 , laddr_infos , protocol ) : <TAB> for family in infos : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for laddr in laddr_infos : <TAB> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> protocol = "" foo "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> protocol = "" bar "" <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise <TAB> return protocol ","if f2 : 
","if family == f2 :
",34.79,17.97,False
"def app_middleware ( next , root , info , * * kwargs ) : <TAB> app_auth_header = "" HTTP_AUTHORIZATION "" <TAB> prefix = "" bearer "" <TAB> request = info . context <TAB> if request . path == API_PATH : <TAB> <TAB> if not hasattr ( request , "" app "" ) : <TAB> <TAB> <TAB> request . app = None <TAB> <TAB> <TAB> auth = request . META . get ( app_auth_header , "" "" ) . split ( ) <TAB> <TAB> <TAB> if len ( auth ) == 2 : <TAB> <TAB> <TAB> <TAB> auth_prefix , auth_token = auth <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> request . app = SimpleLazyObject ( lambda : get_app ( auth_token ) ) <TAB> return next ( root , info , * * kwargs ) ","if auth_prefix . lower ( ) == prefix : 
","if auth_token . startswith ( prefix ) :
",31.1,16.34,False
"def when ( self , matches , context ) : <TAB> ret = [ ] <TAB> for episode in matches . named ( "" episode "" , lambda match : len ( match . initiator ) == 1 ) : <TAB> <TAB> group = matches . markers . at_match ( <TAB> <TAB> <TAB> episode , lambda marker : marker . name == "" group "" , index = 0 <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not matches . range ( <TAB> <TAB> <TAB> <TAB> * group . span , predicate = lambda match : match . name == "" title "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> ret . append ( episode ) <TAB> return ret ","if group : 
","if group :
",78.12,0.0,False
def locate_via_pep514 ( spec ) : <TAB> with _PY_LOCK : <TAB> <TAB> if not _PY_AVAILABLE : <TAB> <TAB> <TAB> from . import pep514 <TAB> <TAB> <TAB> _PY_AVAILABLE . extend ( pep514 . discover_pythons ( ) ) <TAB> <TAB> <TAB> _PY_AVAILABLE . append ( CURRENT ) <TAB> for cur_spec in _PY_AVAILABLE : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return cur_spec . path ,"if cur_spec . satisfies ( spec ) : 
","if cur_spec . path == spec . path :
",37.46,34.48,False
"def setCorkImageDefault ( self ) : <TAB> if settings . corkBackground [ "" image "" ] != "" "" : <TAB> <TAB> i = self . cmbCorkImage . findData ( settings . corkBackground [ "" image "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . cmbCorkImage . setCurrentIndex ( i ) ","if i != - 1 : 
","if i != - 1 :
",100.0,100.0,True
"def _split_key ( key ) : <TAB> if isinstance ( key , util . string_types ) : <TAB> <TAB> # coerce fooload('*') into ""default loader strategy"" <TAB> <TAB> if key == _WILDCARD_TOKEN : <TAB> <TAB> <TAB> return ( _DEFAULT_TOKEN , ) <TAB> <TAB> # coerce fooload("".*"") into ""wildcard on default entity"" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = key [ 1 : ] <TAB> <TAB> return key . split ( "" . "" ) <TAB> else : <TAB> <TAB> return ( key , ) ","elif key . startswith ( "" . "" + _WILDCARD_TOKEN ) : 
","if key . startswith ( "" * "" ) :
",46.46,28.33,False
"def detach_volume ( self , volume ) : <TAB> # We need to find the node using this volume <TAB> for node in self . list_nodes ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # This node has only one associated image. It is not the one we <TAB> <TAB> <TAB> # are after. <TAB> <TAB> <TAB> continue <TAB> <TAB> for disk in node . image : <TAB> <TAB> <TAB> if disk . id == volume . id : <TAB> <TAB> <TAB> <TAB> # Node found. We can now detach the volume <TAB> <TAB> <TAB> <TAB> disk_id = disk . extra [ "" disk_id "" ] <TAB> <TAB> <TAB> <TAB> return self . _do_detach_volume ( node . id , disk_id ) <TAB> return False ","if type ( node . image ) is not list : 
","if node . image is None :
",34.05,16.42,False
"def create ( self , private = False ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( <TAB> <TAB> <TAB> <TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> if e . error == "" user_is_bot "" : <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e ) ","if private : 
","if private :
",78.12,0.0,False
"def test_dataset_has_valid_etag ( self , dataset_name ) : <TAB> py_script_path = list ( filter ( lambda x : x , dataset_name . split ( "" / "" ) ) ) [ - 1 ] + "" .py "" <TAB> dataset_url = hf_bucket_url ( dataset_name , filename = py_script_path , dataset = True ) <TAB> etag = None <TAB> try : <TAB> <TAB> response = requests . head ( <TAB> <TAB> <TAB> dataset_url , allow_redirects = True , proxies = None , timeout = 10 <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> etag = response . headers . get ( "" Etag "" ) <TAB> except ( EnvironmentError , requests . exceptions . Timeout ) : <TAB> <TAB> pass <TAB> self . assertIsNotNone ( etag ) ","if response . status_code == 200 : 
","if response . status_code == 200 and "" Etag "" in response . headers :
",66.93,46.25,False
"def set_dir_modes ( self , dirname , mode ) : <TAB> if not self . is_chmod_supported ( ) : <TAB> <TAB> return <TAB> for dirpath , dirnames , fnames in os . walk ( dirname ) : <TAB> <TAB> if os . path . islink ( dirpath ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> log . info ( "" changing mode of  %s  to  %o "" , dirpath , mode ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . chmod ( dirpath , mode ) ","if not self . dry_run : 
","if not self . is_symlink_supported ( dirpath ) :
",52.94,21.4,False
"def _clean ( self ) : <TAB> logger . info ( "" Cleaning up... "" ) <TAB> if self . _process is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for _ in range ( 3 ) : <TAB> <TAB> <TAB> <TAB> self . _process . terminate ( ) <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.5 ) <TAB> <TAB> <TAB> <TAB> if self . _process . poll ( ) is not None : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _process . kill ( ) <TAB> <TAB> <TAB> <TAB> self . _process . wait ( ) <TAB> <TAB> <TAB> <TAB> logger . error ( "" KILLED "" ) <TAB> if os . path . exists ( self . _tmp_dir ) : <TAB> <TAB> shutil . rmtree ( self . _tmp_dir ) <TAB> self . _process = None <TAB> self . _ws = None <TAB> logger . info ( "" Cleanup complete "" ) ","if self . _process . poll ( ) is None : 
","if self . _process . poll ( ) is not None :
",90.51,79.11,False
"def iter_chars_to_words ( self , chars ) : <TAB> current_word = [ ] <TAB> for char in chars : <TAB> <TAB> if not self . keep_blank_chars and char [ "" text "" ] . isspace ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> <TAB> current_word = [ ] <TAB> <TAB> elif current_word and self . char_begins_new_word ( current_word , char ) : <TAB> <TAB> <TAB> yield current_word <TAB> <TAB> <TAB> current_word = [ char ] <TAB> <TAB> else : <TAB> <TAB> <TAB> current_word . append ( char ) <TAB> if current_word : <TAB> <TAB> yield current_word ","if current_word : 
","if current_word and self . char_begins_new_word ( current_word , char ) :
",32.64,11.43,False
"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB> <TAB> for spec in specs [ i ] . __sro__ : <TAB> <TAB> <TAB> comps = components . get ( spec ) <TAB> <TAB> <TAB> if comps : <TAB> <TAB> <TAB> <TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else : <TAB> <TAB> for iface in provided : <TAB> <TAB> <TAB> comps = components . get ( iface ) <TAB> <TAB> <TAB> if comps : <TAB> <TAB> <TAB> <TAB> r = comps . get ( name ) <TAB> <TAB> <TAB> <TAB> if r is not None : <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None ","if r is not None : 
","if r is not None :
",100.0,100.0,True
"def run ( cmd , task = None ) : <TAB> process = subprocess . Popen ( <TAB> <TAB> cmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , close_fds = True <TAB> ) <TAB> output_lines = [ ] <TAB> while True : <TAB> <TAB> line = process . stdout . readline ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> line = line . decode ( "" utf-8 "" ) <TAB> <TAB> output_lines + = [ line ] <TAB> <TAB> logger . info ( line . rstrip ( "" \n "" ) ) <TAB> process . stdout . close ( ) <TAB> exit_code = process . wait ( ) <TAB> if exit_code : <TAB> <TAB> output = "" "" . join ( output_lines ) <TAB> <TAB> raise subprocess . CalledProcessError ( exit_code , cmd , output = output ) ","if not line : 
","if not line :
",100.0,100.0,True
"def process_response ( self , request , response ) : <TAB> if ( <TAB> <TAB> response . status_code == 404 <TAB> <TAB> and request . path_info . endswith ( "" / "" ) <TAB> <TAB> and not is_valid_path ( request . path_info ) <TAB> <TAB> and is_valid_path ( request . path_info [ : - 1 ] ) <TAB> ) : <TAB> <TAB> # Use request.path because we munged app/locale in path_info. <TAB> <TAB> newurl = request . path [ : - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with safe_query_string ( request ) : <TAB> <TAB> <TAB> <TAB> newurl + = "" ? "" + request . META [ "" QUERY_STRING "" ] <TAB> <TAB> return HttpResponsePermanentRedirect ( newurl ) <TAB> return response ","if request . GET : 
","if request . META [ "" QUERY_STRING "" ] :
",43.47,13.55,False
"def dependencies ( self ) : <TAB> deps = [ ] <TAB> midx = None <TAB> if self . ref is not None : <TAB> <TAB> query = TypeQuery ( self . ref ) <TAB> <TAB> super = query . execute ( self . schema ) <TAB> <TAB> if super is None : <TAB> <TAB> <TAB> log . debug ( self . schema ) <TAB> <TAB> <TAB> raise TypeNotFound ( self . ref ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> deps . append ( super ) <TAB> <TAB> <TAB> midx = 0 <TAB> return ( midx , deps ) ","if not super . builtin ( ) : 
","if super . is_dependency ( ) :
",46.48,23.36,False
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> elif hasattr ( self . object , "" read "" ) : <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs ","if isfile ( self . object ) : 
","if sys . version_info > ( 3 , 0 ) :
",33.19,7.77,False
"def _save ( self ) : <TAB> fd , tempname = tempfile . mkstemp ( ) <TAB> fd = os . fdopen ( fd , "" w "" ) <TAB> json . dump ( self . _cache , fd , indent = 2 , separators = ( "" , "" , "" :  "" ) ) <TAB> fd . close ( ) <TAB> # Silently ignore errors <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( os . path . dirname ( self . filename ) ) <TAB> <TAB> shutil . move ( tempname , self . filename ) <TAB> except ( IOError , OSError ) : <TAB> <TAB> os . remove ( tempname ) ","if not os . path . exists ( os . path . dirname ( self . filename ) ) : 
","if not os . path . exists ( os . path . dirname ( self . filename ) ) :
",100.0,100.0,True
"def refiner_configs ( self ) : <TAB> rv = { } <TAB> for refiner in refiner_manager : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rv [ refiner . name ] = { k : v for k , v in self . config . items ( refiner . name ) } <TAB> return rv ","if self . config . has_section ( refiner . name ) : 
","if refiner . name in self . config :
",39.91,18.4,False
"def com_slice ( self , primary , node , assigning ) : <TAB> # short_slice:  [lower_bound] "":"" [upper_bound] <TAB> lower = upper = None <TAB> if len ( node . children ) == 2 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> upper = self . com_node ( node . children [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lower = self . com_node ( node . children [ 0 ] ) <TAB> elif len ( node . children ) == 3 : <TAB> <TAB> lower = self . com_node ( node . children [ 0 ] ) <TAB> <TAB> upper = self . com_node ( node . children [ 2 ] ) <TAB> return Slice ( primary , assigning , lower , upper , lineno = extractLineNo ( node ) ) ","if node . children [ 0 ] . type == token . COLON : 
","if node . children [ 1 ] . type == "" bound "" :
",62.54,50.39,False
"def close ( self , * args , * * kwargs ) : <TAB> super ( mytqdm , self ) . close ( * args , * * kwargs ) <TAB> # If it was not run in a notebook, sp is not assigned, check for it <TAB> if hasattr ( self , "" sp "" ) : <TAB> <TAB> # Try to detect if there was an error or KeyboardInterrupt <TAB> <TAB> # in manual mode: if n < total, things probably got wrong <TAB> <TAB> if self . total and self . n < self . total : <TAB> <TAB> <TAB> self . sp ( bar_style = "" danger "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . sp ( bar_style = "" success "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . sp ( close = True ) ","if self . leave : 
","if self . n < self . n :
",43.86,19.07,False
"def test_alloc ( self ) : <TAB> b = bytearray ( ) <TAB> alloc = b . __alloc__ ( ) <TAB> self . assertTrue ( alloc > = 0 ) <TAB> seq = [ alloc ] <TAB> for i in range ( 100 ) : <TAB> <TAB> b + = b "" x "" <TAB> <TAB> alloc = b . __alloc__ ( ) <TAB> <TAB> self . assertTrue ( alloc > = len ( b ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seq . append ( alloc ) ","if alloc not in seq : 
","if not ( alloc == b "" "" ) and ( alloc != b "" "" ) :
",26.83,2.71,False
"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> <MASK> <TAB> <TAB> f . compress = zlib . compressobj ( <TAB> <TAB> <TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB> <TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB> <TAB> if self . compress : <TAB> <TAB> <TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB> <TAB> <TAB> if open_files > self . MAX_OPEN_FILES : <TAB> <TAB> <TAB> <TAB> f . fileobj . close ( ) <TAB> <TAB> <TAB> <TAB> f . fileobj = None <TAB> <TAB> else : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> self . files . pop ( key ) ","if self . compress : 
","if self . compress :
",100.0,100.0,True
"def _run ( self ) : <TAB> # Low-level run method to do the actual scheduling loop. <TAB> self . running = True <TAB> while self . running : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . sched . run ( ) <TAB> <TAB> except Exception as x : <TAB> <TAB> <TAB> logging . error ( <TAB> <TAB> <TAB> <TAB> "" Error during scheduler execution:  %s "" % str ( x ) , exc_info = True <TAB> <TAB> <TAB> ) <TAB> <TAB> # queue is empty; sleep a short while before checking again <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> time . sleep ( 5 ) ","if self . running : 
","if self . queue . empty ( ) :
",43.86,19.07,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_app_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_max_rows ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 16 : 
","if tt == 16 :
",100.0,100.0,True
"def check ( dbdef ) : <TAB> "" drop script must clear the database "" <TAB> for version in dbdef : <TAB> <TAB> connector = MemConnector ( ) . bound ( None ) <TAB> <TAB> create ( dbdef , version , connector ) <TAB> <TAB> drop ( dbdef , version , connector ) <TAB> <TAB> remaining = connector . execute ( <TAB> <TAB> <TAB> "" SELECT * FROM sqlite_master WHERE name NOT LIKE  ' sqlite_ % ' "" <TAB> <TAB> ) . fetchall ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield "" {0} :drop.sql "" . format ( version ) , remaining ","if remaining : 
","if remaining :
",78.12,0.0,False
"def test_open_overwrite_offset_size ( self , sftp ) : <TAB> """"""Test writing data at a specific offset"""""" <TAB> f = None <TAB> try : <TAB> <TAB> self . _create_file ( "" file "" , "" xxxxyyyy "" ) <TAB> <TAB> f = yield from sftp . open ( "" file "" , "" r+ "" ) <TAB> <TAB> yield from f . write ( "" zz "" , 3 ) <TAB> <TAB> yield from f . close ( ) <TAB> <TAB> with open ( "" file "" ) as localf : <TAB> <TAB> <TAB> self . assertEqual ( localf . read ( ) , "" xxxzzyyy "" ) <TAB> finally : <TAB> <TAB> if f :<TAB> # pragma: no branch <TAB> <TAB> <TAB> yield from f . close ( ) <TAB> <TAB> remove ( "" file "" ) ","if f : 
","if f :
",78.12,0.0,False
"def pump ( ) : <TAB> import sys as _sys <TAB> while self . countdown_active ( ) : <TAB> <TAB> if not ( self . connected ( "" send "" ) and other . connected ( "" recv "" ) ) : <TAB> <TAB> <TAB> break <TAB> <TAB> try : <TAB> <TAB> <TAB> data = other . recv ( timeout = 0.05 ) <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if not data : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> self . send ( data ) <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> break <TAB> <TAB> if not _sys : <TAB> <TAB> <TAB> return <TAB> self . shutdown ( "" send "" ) <TAB> other . shutdown ( "" recv "" ) ","if not _sys : 
","if not data :
",59.64,27.53,False
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> if "" results.train_y_misclass "" in dd : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> if "" hyper_parameters "" in key : <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) ) ","if dd [ "" results.train_y_misclass "" ] < optimal_measure : 
","if optimal_measure is None :
",26.44,5.77,False
"def valid ( self ) : <TAB> valid = True <TAB> <MASK> <TAB> <TAB> return valid <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> with io . open ( self . pathfile , "" w "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> <TAB> <TAB> f . close ( )<TAB> # do nothing <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> valid = False <TAB> <TAB> if os . path . exists ( self . pathfile ) : <TAB> <TAB> <TAB> os . remove ( self . pathfile ) <TAB> <TAB> return valid ","if os . path . exists ( self . pathfile ) : 
","if os . path . exists ( self . pathfile ) :
",100.0,100.0,True
"def __getitem__ ( self , key ) : <TAB> try : <TAB> <TAB> value = self . cache [ key ] <TAB> except KeyError : <TAB> <TAB> f = BytesIO ( self . dict [ key . encode ( self . keyencoding ) ] ) <TAB> <TAB> value = Unpickler ( f ) . load ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . cache [ key ] = value <TAB> return value ","if self . writeback : 
","if value is not None :
",28.03,9.65,False
"def hasMenu ( cls , callingWindow , mainItem , selection , * fullContexts ) : <TAB> for i , fullContext in enumerate ( fullContexts ) : <TAB> <TAB> srcContext = fullContext [ 0 ] <TAB> <TAB> for menuHandler in cls . menus : <TAB> <TAB> <TAB> m = menuHandler ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False ","if m . _baseDisplay ( callingWindow , srcContext , mainItem , selection ) : 
","if m . itemTouched == srcContext :
",33.89,9.74,False
"def lr_read_tables ( module = tab_module , optimize = 0 ) : <TAB> global _lr_action , _lr_goto , _lr_productions , _lr_method <TAB> try : <TAB> <TAB> exec ( "" import  %s  as parsetab "" % module ) <TAB> <TAB> global parsetab<TAB> # declare the name of the imported module <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _lr_action = parsetab . _lr_action <TAB> <TAB> <TAB> _lr_goto = parsetab . _lr_goto <TAB> <TAB> <TAB> _lr_productions = parsetab . _lr_productions <TAB> <TAB> <TAB> _lr_method = parsetab . _lr_method <TAB> <TAB> <TAB> return 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return 0 <TAB> except ( ImportError , AttributeError ) : <TAB> <TAB> return 0 ","if ( optimize ) or ( Signature . digest ( ) == parsetab . _lr_signature ) : 
","if optimize :
",25.46,0.0,False
"def _Determine_Do ( self ) : <TAB> if sys . platform . startswith ( "" win "" ) : <TAB> <TAB> self . applicable = 1 <TAB> <TAB> for opt , optarg in self . chosenOptions : <TAB> <TAB> <TAB> if opt == "" --moz-tools "" : <TAB> <TAB> <TAB> <TAB> self . value = os . path . abspath ( os . path . normpath ( optarg ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . value = os . environ [ self . name ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . value = None <TAB> else : <TAB> <TAB> self . applicable = 0 <TAB> self . determined = 1 ","if os . environ . has_key ( self . name ) : 
","if self . name in os . environ :
",39.91,18.4,False
"def parse_chunked ( self , unreader ) : <TAB> ( size , rest ) = self . parse_chunk_size ( unreader ) <TAB> while size > 0 : <TAB> <TAB> while size > len ( rest ) : <TAB> <TAB> <TAB> size - = len ( rest ) <TAB> <TAB> <TAB> yield rest <TAB> <TAB> <TAB> rest = unreader . read ( ) <TAB> <TAB> <TAB> if not rest : <TAB> <TAB> <TAB> <TAB> raise NoMoreData ( ) <TAB> <TAB> yield rest [ : size ] <TAB> <TAB> # Remove \r\n after chunk <TAB> <TAB> rest = rest [ size : ] <TAB> <TAB> while len ( rest ) < 2 : <TAB> <TAB> <TAB> rest + = unreader . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ChunkMissingTerminator ( rest [ : 2 ] ) <TAB> <TAB> ( size , rest ) = self . parse_chunk_size ( unreader , data = rest [ 2 : ] ) ","if rest [ : 2 ] != b "" \r \n "" : 
","if not rest [ : 2 ] == "" \r \n "" :
",67.27,62.63,False
"def _scroll_down ( self , cli ) : <TAB> "" Scroll window down. "" <TAB> info = self . render_info <TAB> if self . vertical_scroll < info . content_height - info . window_height : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . content . move_cursor_down ( cli ) <TAB> <TAB> self . vertical_scroll + = 1 ","if info . cursor_position . y < = info . configured_scroll_offsets . top : 
","if self . content . is_visible ( cli ) :
",38.56,2.6,False
"def _add_defaults_data_files ( self ) : <TAB> # getting distribution.data_files <TAB> if self . distribution . has_data_files ( ) : <TAB> <TAB> for item in self . distribution . data_files : <TAB> <TAB> <TAB> if isinstance ( item , str ) : <TAB> <TAB> <TAB> <TAB> # plain file <TAB> <TAB> <TAB> <TAB> item = convert_path ( item ) <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( item ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . filelist . append ( item ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # a (dirname, filenames) tuple <TAB> <TAB> <TAB> <TAB> dirname , filenames = item <TAB> <TAB> <TAB> <TAB> for f in filenames : <TAB> <TAB> <TAB> <TAB> <TAB> f = convert_path ( f ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . filelist . append ( f ) ","if os . path . isfile ( f ) : 
","if os . path . isdir ( f ) :
",83.03,65.8,False
"def list_stuff ( self , upto = 10 , start_after = - 1 ) : <TAB> for i in range ( upto ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if i == 2 and self . count < 1 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> if i == 7 and self . count < 4 : <TAB> <TAB> <TAB> self . count + = 1 <TAB> <TAB> <TAB> raise TemporaryProblem <TAB> <TAB> yield i ","if i < = start_after : 
","if i == start_after and self . count == 0 :
",28.87,20.33,False
"def is_open ( self ) : <TAB> if self . signup_code : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . messages . get ( "" invalid_signup_code "" ) : <TAB> <TAB> <TAB> <TAB> messages . add_message ( <TAB> <TAB> <TAB> <TAB> <TAB> self . request , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> * * { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" code "" : self . get_code ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP ","if self . signup_code_present : 
","if settings . ACCOUNT_OPEN_SIGNUP is None :
",36.31,5.6,False
"def on_delete_from_disk ( self , widget , data = None ) : <TAB> model , iter = self . get_selection ( ) . get_selected ( ) <TAB> if iter : <TAB> <TAB> path = model . get_value ( iter , COLUMN_PATH ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ErrorDialog ( _ ( "" Can ' t delete system item from disk. "" ) ) . launch ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . remove ( path ) <TAB> self . update_items ( ) ","if self . is_defaultitem ( path ) : 
","if not os . path . exists ( path ) :
",51.31,25.97,False
"def get_detections_for_batch ( self , images ) : <TAB> images = images [ . . . , : : - 1 ] <TAB> detected_faces = self . face_detector . detect_from_batch ( images . copy ( ) ) <TAB> results = [ ] <TAB> for i , d in enumerate ( detected_faces ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> results . append ( None ) <TAB> <TAB> <TAB> continue <TAB> <TAB> d = d [ 0 ] <TAB> <TAB> d = np . clip ( d , 0 , None ) <TAB> <TAB> x1 , y1 , x2 , y2 = map ( int , d [ : - 1 ] ) <TAB> <TAB> results . append ( ( x1 , y1 , x2 , y2 ) ) <TAB> return results ","if len ( d ) == 0 : 
","if i == len ( detected_faces ) - 1 :
",38.45,10.05,False
def on_update ( self ) : <TAB> # <TAB> # Calculate maximum # of planes per well <TAB> # <TAB> self . max_per_well = 0 <TAB> for pd in list ( self . plate_well_site . values ( ) ) : <TAB> <TAB> for wd in list ( pd . values ( ) ) : <TAB> <TAB> <TAB> nplanes = sum ( [ len ( x ) for x in list ( wd . values ( ) ) ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . max_per_well = nplanes <TAB> for registrant in self . registrants : <TAB> <TAB> registrant ( ) ,"if nplanes > self . max_per_well : 
","if nplanes > self . max_per_well :
",100.0,100.0,True
"def is_writable ( self , path ) : <TAB> result = False <TAB> while not result : <TAB> <TAB> if os . path . exists ( path ) : <TAB> <TAB> <TAB> result = os . access ( path , os . W_OK ) <TAB> <TAB> <TAB> break <TAB> <TAB> parent = os . path . dirname ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> path = parent <TAB> return result ","if parent == path : 
","if parent == self . root :
",36.73,36.56,False
"def _check_seed ( self , seed ) : <TAB> if seed is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _raise_error ( <TAB> <TAB> <TAB> <TAB> "" The random number generator seed value, seed, should be integer type or None. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if seed < 0 : <TAB> <TAB> <TAB> self . _raise_error ( <TAB> <TAB> <TAB> <TAB> "" The random number generator seed value, seed, should be non-negative integer or None. "" <TAB> <TAB> <TAB> ) ","if type ( seed ) != int : 
","if not isinstance ( seed , ( int , long ) ) :
",27.93,8.13,False
"def write ( self , x ) : <TAB> # try to use backslash and surrogate escape strategies before failing <TAB> self . _errors = "" backslashescape "" if self . encoding != "" mbcs "" else "" surrogateescape "" <TAB> try : <TAB> <TAB> return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) ) <TAB> except UnicodeDecodeError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _errors = "" surrogateescape "" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _errors = "" replace "" <TAB> <TAB> return io . TextIOWrapper . write ( self , to_text ( x , errors = self . _errors ) ) ","if self . _errors != "" surrogateescape "" : 
","if self . encoding == "" mbcs "" :
",57.95,20.77,False
"def post ( self , request , * args , * * kwargs ) : <TAB> validated_session = [ ] <TAB> for session_id in request . data : <TAB> <TAB> session = get_object_or_none ( Session , id = session_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> validated_session . append ( session_id ) <TAB> <TAB> <TAB> self . model . objects . create ( <TAB> <TAB> <TAB> <TAB> name = "" kill_session "" , <TAB> <TAB> <TAB> <TAB> args = session . id , <TAB> <TAB> <TAB> <TAB> terminal = session . terminal , <TAB> <TAB> <TAB> ) <TAB> return Response ( { "" ok "" : validated_session } ) ","if session and not session . is_finished : 
","if session :
",27.85,0.0,False
"def _has_list_or_dict_var_value_before ( self , arg_index ) : <TAB> for idx , value in enumerate ( self . args ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> if variablematcher . is_list_variable ( <TAB> <TAB> <TAB> value <TAB> <TAB> ) and not variablematcher . is_list_variable_subitem ( value ) : <TAB> <TAB> <TAB> return True <TAB> <TAB> if robotapi . is_dict_var ( value ) and not variablematcher . is_dict_var_access ( <TAB> <TAB> <TAB> value <TAB> <TAB> ) : <TAB> <TAB> <TAB> return True <TAB> return False ","if idx > arg_index : 
","if idx == arg_index :
",58.14,41.11,False
"def test_return_correct_type ( self ) : <TAB> for proto in protocols : <TAB> <TAB> # Protocol 0 supports only ASCII strings. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _check_return_correct_type ( "" abc "" , 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for obj in [ b "" abc \n "" , "" abc \n "" , - 1 , - 1.1 * 0.1 , str ] : <TAB> <TAB> <TAB> <TAB> self . _check_return_correct_type ( obj , proto ) ","if proto == 0 : 
","if proto == 0 :
",100.0,100.0,True
"def backward_impl ( self , inputs , outputs , prop_down , accum ) : <TAB> # inputs: [inputs_fwd_graph] + [inputs_bwd_graph] or <TAB> # [inputs_fwd_graph] + [outputs_fwd_graph] + [inputs_bwd_graph] <TAB> # Args <TAB> axis = self . forward_func . info . args [ "" axis "" ] <TAB> # Compute <TAB> ## w.r.t. dy <TAB> if prop_down [ - 1 ] : <TAB> <TAB> g_dy = inputs [ - 1 ] . grad <TAB> <TAB> g_dy_ = F . stack ( * [ o . grad for o in outputs ] , axis = axis ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g_dy + = g_dy_ <TAB> <TAB> else : <TAB> <TAB> <TAB> g_dy . copy_from ( g_dy_ ) ","if accum [ - 1 ] : 
","if accum [ - 1 ] :
",100.0,100.0,True
"def remove ( self , url ) : <TAB> try : <TAB> <TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> was_selected = i in self . selectedindices ( ) <TAB> <TAB> self . list . delete ( i ) <TAB> <TAB> del self . items [ i ] <TAB> <TAB> if not self . items : <TAB> <TAB> <TAB> self . mp . hidepanel ( self . name ) <TAB> <TAB> elif was_selected : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> self . list . select_set ( i ) ","if i > = len ( self . items ) : 
","if self . list . get_selected ( ) == i :
",31.35,8.03,False
"def prepend ( self , value ) : <TAB> """"""prepend value to nodes"""""" <TAB> root , root_text = self . _get_root ( value ) <TAB> for i , tag in enumerate ( self ) : <TAB> <TAB> if not tag . text : <TAB> <TAB> <TAB> tag . text = "" "" <TAB> <TAB> if len ( root ) > 0 : <TAB> <TAB> <TAB> root [ - 1 ] . tail = tag . text <TAB> <TAB> <TAB> tag . text = root_text <TAB> <TAB> else : <TAB> <TAB> <TAB> tag . text = root_text + tag . text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> root = deepcopy ( list ( root ) ) <TAB> <TAB> tag [ : 0 ] = root <TAB> <TAB> root = tag [ : len ( root ) ] <TAB> return self ","if i > 0 : 
","if i == len ( root ) :
",29.98,10.55,False
"def _get_tracks_compositors_list ( ) : <TAB> tracks_list = [ ] <TAB> tracks = current_sequence ( ) . tracks <TAB> compositors = current_sequence ( ) . compositors <TAB> for track_index in range ( 1 , len ( tracks ) - 1 ) : <TAB> <TAB> track_compositors = [ ] <TAB> <TAB> for j in range ( 0 , len ( compositors ) ) : <TAB> <TAB> <TAB> comp = compositors [ j ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> track_compositors . append ( comp ) <TAB> <TAB> tracks_list . append ( track_compositors ) <TAB> return tracks_list ","if comp . transition . b_track == track_index : 
","if comp . track_index == track_index :
",40.34,47.27,False
"def __getattr__ ( self , name ) : <TAB> if name in self . _sections : <TAB> <TAB> return "" \n "" . join ( self . _sections [ name ] ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ConanException ( "" ConfigParser: Unrecognized field  ' %s ' "" % name ) ","if self . _allowed_fields and name in self . _allowed_fields : 
","if name == "" default "" :
",26.25,2.36,False
"def get_first_param_index ( self , group_id , param_group , partition_id ) : <TAB> for index , param in enumerate ( param_group ) : <TAB> <TAB> param_id = self . get_param_id ( param ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return index <TAB> return None ","if partition_id in self . param_to_partition_ids [ group_id ] [ param_id ] : 
","if group_id == param_id and partition_id == param_id :
",26.17,14.27,False
"def handle_uv_sockets ( self , context ) : <TAB> u_socket = self . inputs [ "" U "" ] <TAB> v_socket = self . inputs [ "" V "" ] <TAB> if self . cast_mode == "" Sphere "" : <TAB> <TAB> u_socket . hide_safe = True <TAB> <TAB> v_socket . hide_safe = True <TAB> elif self . cast_mode in [ "" Cylinder "" , "" Prism "" ] : <TAB> <TAB> v_socket . hide_safe = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> u_socket . hide_safe = False <TAB> else : <TAB> <TAB> if u_socket . hide_safe : <TAB> <TAB> <TAB> u_socket . hide_safe = False <TAB> <TAB> if v_socket . hide_safe : <TAB> <TAB> <TAB> v_socket . hide_safe = False ","if u_socket . hide_safe : 
","if u_socket . hide_safe :
",100.0,100.0,True
"def _scrub_generated_timestamps ( self , target_workdir ) : <TAB> """"""Remove the first line of comment from each file if it contains a timestamp."""""" <TAB> for root , _ , filenames in safe_walk ( target_workdir ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> source = os . path . join ( root , filename ) <TAB> <TAB> <TAB> with open ( source , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> lines = f . readlines ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> with open ( source , "" w "" ) as f : <TAB> <TAB> <TAB> <TAB> if not self . _COMMENT_WITH_TIMESTAMP_RE . match ( lines [ 0 ] ) : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( lines [ 0 ] ) <TAB> <TAB> <TAB> <TAB> for line in lines [ 1 : ] : <TAB> <TAB> <TAB> <TAB> <TAB> f . write ( line ) ","if len ( lines ) < 1 : 
","if not lines :
",26.99,7.73,False
"def inner ( request , * args , * * kwargs ) : <TAB> page = request . current_page <TAB> if page : <TAB> <TAB> if page . login_required and not request . user . is_authenticated : <TAB> <TAB> <TAB> return redirect_to_login ( <TAB> <TAB> <TAB> <TAB> urlquote ( request . get_full_path ( ) ) , settings . LOGIN_URL <TAB> <TAB> <TAB> ) <TAB> <TAB> site = get_current_site ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return _handle_no_page ( request ) <TAB> return func ( request , * args , * * kwargs ) ","if not user_can_view_page ( request . user , page , site ) : 
","if not site . is_active :
",31.18,3.68,False
"def flush ( self , * args , * * kwargs ) : <TAB> with self . _lock : <TAB> <TAB> self . _last_updated = time . time ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> mailbox . mbox . flush ( self , * args , * * kwargs ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> if "" _create_temporary "" in traceback . format_exc ( ) : <TAB> <TAB> <TAB> <TAB> self . _locked_flush_without_tempfile ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . _last_updated = time . time ( ) ","if kwargs . get ( "" in_place "" , False ) : 
","if self . _create_temporary :
",30.21,3.69,False
"def sanitize_event_keys ( kwargs , valid_keys ) : <TAB> # Sanity check: Don't honor keys that we don't recognize. <TAB> for key in list ( kwargs . keys ( ) ) : <TAB> <TAB> if key not in valid_keys : <TAB> <TAB> <TAB> kwargs . pop ( key ) <TAB> # Truncate certain values over 1k <TAB> for key in [ "" play "" , "" role "" , "" task "" , "" playbook "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if len ( kwargs [ "" event_data "" ] [ key ] ) > 1024 : <TAB> <TAB> <TAB> <TAB> kwargs [ "" event_data "" ] [ key ] = Truncator ( kwargs [ "" event_data "" ] [ key ] ) . chars ( <TAB> <TAB> <TAB> <TAB> <TAB> 1024 <TAB> <TAB> <TAB> <TAB> ) ","if isinstance ( kwargs . get ( "" event_data "" , { } ) . get ( key ) , str ) : 
","if key in kwargs [ "" event_data "" ] :
",29.33,12.43,False
"def parse_auth ( val ) : <TAB> if val is not None : <TAB> <TAB> authtype , params = val . split ( "" "" , 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if authtype == "" Basic "" and ' "" ' not in params : <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> params = parse_auth_params ( params ) <TAB> <TAB> return authtype , params <TAB> return val ","if authtype in known_auth_schemes : 
","if params :
",28.39,0.0,False
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> if self . _call_count > self . ctl or age > self . ttl : <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self . ctl : <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args ) ","if value : 
","if not isinstance ( value , type ( None ) ) :
",29.3,4.46,False
"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color<TAB> # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t . theme_style == "" Dark "" : <TAB> <TAB> if self . md_bg_color == t . primary_color : <TAB> <TAB> <TAB> c = t . primary_dark <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> c = t . accent_dark <TAB> return c ","elif self . md_bg_color == t . accent_color : 
","elif self . md_bg_color == t . accent_color :
",100.0,100.0,True
def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >> = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> part_l | = 1 << 31 <TAB> <TAB> <TAB> part_h >> = 1 <TAB> <TAB> <TAB> if rflag : <TAB> <TAB> <TAB> <TAB> part_h ^ = 0xD8000000 <TAB> <TAB> _table_h . append ( part_h ) <TAB> return _table_h ,"if part_h & 1 : 
","if j & 1 :
",64.48,28.64,False
"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB> <TAB> if not old_obj . summary : <TAB> <TAB> <TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB> <TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB> <TAB> self . session_new . add ( new_obj ) ","if key not in old_obj . __table__ . columns : 
","if key in [ "" summary "" , "" summary_index "" ] :
",27.41,6.18,False
"def get_in_turn_repetition ( pred , is_cn = False ) : <TAB> """"""Get in-turn repetition."""""" <TAB> if len ( pred ) == 0 : <TAB> <TAB> return 1.0 <TAB> if isinstance ( pred [ 0 ] , str ) : <TAB> <TAB> pred = [ tok . lower ( ) for tok in pred ] <TAB> <TAB> if is_cn : <TAB> <TAB> <TAB> pred = "" "" . join ( pred ) <TAB> tri_grams = set ( ) <TAB> for i in range ( len ( pred ) - 2 ) : <TAB> <TAB> tri_gram = tuple ( pred [ i : i + 3 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 1.0 <TAB> <TAB> tri_grams . add ( tri_gram ) <TAB> return 0.0 ","if tri_gram in tri_grams : 
","if tri_gram in tri_grams :
",100.0,100.0,True
"def translate ( ) : <TAB> assert Lex . next ( ) is AttributeList <TAB> reader . read ( )<TAB> # Discard attribute list from reader. <TAB> attrs = { } <TAB> d = AttributeList . match . groupdict ( ) <TAB> for k , v in d . items ( ) : <TAB> <TAB> if v is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> v = subs_attrs ( v ) <TAB> <TAB> <TAB> <TAB> if v : <TAB> <TAB> <TAB> <TAB> <TAB> parse_attributes ( v , attrs ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> AttributeList . attrs [ k ] = v <TAB> AttributeList . subs ( attrs ) <TAB> AttributeList . attrs . update ( attrs ) ","if k == "" attrlist "" : 
","if isinstance ( v , str ) :
",26.98,6.57,False
"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> if "" axis "" in self . args : <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if not isinstance ( self . axis , int ) : 
","if not isinstance ( self . axis , ( int , float ) ) :
",61.48,53.28,False
"def __getattr__ ( self , attrname ) : <TAB> if attrname in ( "" visamp "" , "" visamperr "" , "" visphi "" , "" visphierr "" ) : <TAB> <TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB> elif attrname in ( "" cflux "" , "" cfluxerr "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ma . masked_array ( self . __dict__ [ "" _ "" + attrname ] , mask = self . flag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> raise AttributeError ( attrname ) ","if self . __dict__ [ "" _ "" + attrname ] != None : 
","if self . mask_array :
",31.77,5.0,False
"def draw ( self , context ) : <TAB> layout = self . layout <TAB> presets . draw_presets_ops ( layout , context = context ) <TAB> for category in presets . get_category_names ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if category in preset_category_menus : <TAB> <TAB> <TAB> <TAB> class_name = preset_category_menus [ category ] . __name__ <TAB> <TAB> <TAB> <TAB> layout . menu ( class_name ) ","if category in preset_category_menus : 
","if category in preset_category_menus :
",100.0,100.0,True
"def __setitem__ ( self , key , value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> info , reference = value <TAB> <TAB> if info not in self . _reverse_infos : <TAB> <TAB> <TAB> self . _reverse_infos [ info ] = len ( self . _infos ) <TAB> <TAB> <TAB> self . _infos . append ( info ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _reverse_references [ reference ] = len ( self . _references ) <TAB> <TAB> <TAB> self . _references . append ( reference ) <TAB> <TAB> self . _trails [ key ] = "" %d , %d "" % ( <TAB> <TAB> <TAB> self . _reverse_infos [ info ] , <TAB> <TAB> <TAB> self . _reverse_references [ reference ] , <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" unsupported type  ' %s ' "" % type ( value ) ) ","if reference not in self . _reverse_references : 
","if reference not in self . _reverse_references :
",100.0,100.0,True
"def format_bpe_text ( symbols , delimiter = b "" @@ "" ) : <TAB> """"""Convert a sequence of bpe words into sentence."""""" <TAB> words = [ ] <TAB> word = b "" "" <TAB> if isinstance ( symbols , str ) : <TAB> <TAB> symbols = symbols . encode ( ) <TAB> delimiter_len = len ( delimiter ) <TAB> for symbol in symbols : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> word + = symbol [ : - delimiter_len ] <TAB> <TAB> else :<TAB> # end of a word <TAB> <TAB> <TAB> word + = symbol <TAB> <TAB> <TAB> words . append ( word ) <TAB> <TAB> <TAB> word = b "" "" <TAB> return b "" "" . join ( words ) ","if len ( symbol ) > = delimiter_len and symbol [ - delimiter_len : ] == delimiter : 
","if symbol . endswith ( delimiter ) :
",28.02,1.33,False
"def output_type ( data , request , response ) : <TAB> accept = request . accept <TAB> if accept in ( "" "" , "" * "" , "" / "" ) : <TAB> <TAB> handler = default or handlers and next ( iter ( handlers . values ( ) ) ) <TAB> else : <TAB> <TAB> handler = default <TAB> <TAB> accepted = [ accept_quality ( accept_type ) for accept_type in accept . split ( "" , "" ) ] <TAB> <TAB> accepted . sort ( key = itemgetter ( 0 ) ) <TAB> <TAB> for _quality , accepted_content_type in reversed ( accepted ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> handler = handlers [ accepted_content_type ] <TAB> <TAB> <TAB> <TAB> break <TAB> if not handler : <TAB> <TAB> raise falcon . HTTPNotAcceptable ( error ) <TAB> response . content_type = handler . content_type <TAB> return handler ( data , request = request , response = response ) ","if accepted_content_type in handlers : 
","if accepted_content_type in handlers :
",100.0,100.0,True
"def _render_raw_list ( bytes_items ) : <TAB> flatten_items = [ ] <TAB> for item in bytes_items : <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> flatten_items . append ( b "" "" ) <TAB> <TAB> elif isinstance ( item , bytes ) : <TAB> <TAB> <TAB> flatten_items . append ( item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flatten_items . append ( str ( item ) . encode ( ) ) <TAB> <TAB> elif isinstance ( item , list ) : <TAB> <TAB> <TAB> flatten_items . append ( _render_raw_list ( item ) ) <TAB> return b "" \n "" . join ( flatten_items ) ","elif isinstance ( item , int ) : 
","elif isinstance ( item , str ) :
",79.9,59.46,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_mime_type ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 16 : <TAB> <TAB> <TAB> self . set_quality ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 8 : 
","if tt == 8 :
",100.0,100.0,True
"def delete ( self , waiters ) : <TAB> # Delete flow. <TAB> msgs = self . ofctl . get_all_flow ( waiters ) <TAB> for msg in msgs : <TAB> <TAB> for stats in msg . body : <TAB> <TAB> <TAB> vlan_id = VlanRouter . _cookie_to_id ( REST_VLANID , stats . cookie ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . ofctl . delete_flow ( stats ) <TAB> assert len ( self . packet_buffer ) == 0 ","if vlan_id == self . vlan_id : 
","if vlan_id == self . ofctl . get_vlan_id ( ) :
",56.75,47.63,False
def missing_push_allowance ( push_allowances : List [ PushAllowance ] ) - > bool : <TAB> for push_allowance in push_allowances : <TAB> <TAB> # a null databaseId indicates this is not a GitHub App. <TAB> <TAB> if push_allowance . actor . databaseId is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return True ,"if str ( push_allowance . actor . databaseId ) == str ( app_config . GITHUB_APP_ID ) : 
","if push_allowance . actor . databaseId != push_allowance . actor . databaseId :
",44.8,23.99,False
"def _cluster_page ( self , htmlpage ) : <TAB> template_cluster , preferred = _CLUSTER_NA , None <TAB> if self . clustering : <TAB> <TAB> self . clustering . add_page ( htmlpage ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> clt = self . clustering . classify ( htmlpage ) <TAB> <TAB> <TAB> if clt != - 1 : <TAB> <TAB> <TAB> <TAB> template_cluster = preferred = self . template_names [ clt ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> template_cluster = _CLUSTER_OUTLIER <TAB> return template_cluster , preferred ","if self . clustering . is_fit : 
","if self . template_names :
",40.7,20.87,False
"def readlines ( self , size = - 1 ) : <TAB> if self . _nbr == self . _size : <TAB> <TAB> return [ ] <TAB> # leave all additional logic to our readline method, we just check the size <TAB> out = [ ] <TAB> nbr = 0 <TAB> while True : <TAB> <TAB> line = self . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> out . append ( line ) <TAB> <TAB> if size > - 1 : <TAB> <TAB> <TAB> nbr + = len ( line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> # END handle size constraint <TAB> # END readline loop <TAB> return out ","if nbr > size : 
","if nbr > self . _size :
",36.73,25.85,False
"def post_mortem ( t = None ) : <TAB> # handling the default <TAB> <MASK> <TAB> <TAB> # sys.exc_info() returns (type, value, traceback) if an exception is <TAB> <TAB> # being handled, otherwise it returns None <TAB> <TAB> t = sys . exc_info ( ) [ 2 ] <TAB> <TAB> if t is None : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" A valid traceback must be passed if no exception is being handled. "" <TAB> <TAB> <TAB> ) <TAB> p = BPdb ( ) <TAB> p . reset ( ) <TAB> p . interaction ( None , t ) ","if t is None : 
","if t is None :
",100.0,100.0,True
"def fixup ( m ) : <TAB> txt = m . group ( 0 ) <TAB> if txt [ : 2 ] == "" &# "" : <TAB> <TAB> # character reference <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return unichr ( int ( txt [ 3 : - 1 ] , 16 ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return unichr ( int ( txt [ 2 : - 1 ] ) ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> pass <TAB> else : <TAB> <TAB> # named entity <TAB> <TAB> try : <TAB> <TAB> <TAB> txt = unichr ( htmlentitydefs . name2codepoint [ txt [ 1 : - 1 ] ] ) <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> pass <TAB> return txt<TAB> # leave as is ","if txt [ : 3 ] == "" &#x "" : 
","if txt [ : 3 ] == "" &#x "" :
",100.0,100.0,True
"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB> <TAB> value = item . group ( "" stringval "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = item . group ( "" value "" ) <TAB> <TAB> value = _pythonize ( value ) <TAB> <TAB> if not item . group ( "" name "" ) : <TAB> <TAB> <TAB> args . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> name = item . group ( "" name "" ) <TAB> <TAB> <TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs ","if value is None : 
","if value is not None :
",64.71,37.99,False
"def IT ( cpu ) : <TAB> cc = cpu . instruction . cc <TAB> true_case = cpu . _evaluate_conditional ( cc ) <TAB> # this is incredibly hacky--how else does capstone expose this? <TAB> # TODO: find a better way than string parsing the mnemonic -GR, 2017-07-13 <TAB> for c in cpu . instruction . mnemonic [ 1 : ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cpu . _it_conditional . append ( true_case ) <TAB> <TAB> elif c == "" e "" : <TAB> <TAB> <TAB> cpu . _it_conditional . append ( not true_case ) ","if c == "" t "" : 
","if c == "" g "" :
",74.63,59.46,False
"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [ ] <TAB> channel = await self . messageable . _get_channel ( ) <TAB> self . channel = channel <TAB> while self . _get_retrieve ( ) : <TAB> <TAB> data = await self . _retrieve_messages ( self . retrieve ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . limit = 0<TAB> # terminate the infinite loop <TAB> <TAB> if self . reverse : <TAB> <TAB> <TAB> data = reversed ( data ) <TAB> <TAB> if self . _filter : <TAB> <TAB> <TAB> data = filter ( self . _filter , data ) <TAB> <TAB> for element in data : <TAB> <TAB> <TAB> result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB> return result ","if len ( data ) < 100 : 
","if len ( data ) > self . limit :
",59.17,41.11,False
"def _get_beta_accumulators ( self ) : <TAB> with tf . init_scope ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> graph = None <TAB> <TAB> else : <TAB> <TAB> <TAB> graph = tf . get_default_graph ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> self . _get_non_slot_variable ( "" beta1_power "" , graph = graph ) , <TAB> <TAB> <TAB> self . _get_non_slot_variable ( "" beta2_power "" , graph = graph ) , <TAB> <TAB> ) ","if tf . executing_eagerly ( ) : 
","if self . _get_beta_accumulators_graph ( ) is not None :
",43.67,6.02,False
"def prefixed ( self , prefix : _StrType ) - > typing . Iterator [ "" Env "" ] : <TAB> """"""Context manager for parsing envvars with a common prefix."""""" <TAB> try : <TAB> <TAB> old_prefix = self . _prefix <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _prefix = prefix <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _prefix = f "" { old_prefix } { prefix } "" <TAB> <TAB> yield self <TAB> finally : <TAB> <TAB> # explicitly reset the stored prefix on completion and exceptions <TAB> <TAB> self . _prefix = None <TAB> self . _prefix = old_prefix ","if old_prefix is None : 
","if prefix == _StrType . all ( ) :
",27.26,5.3,False
"def decode_content ( self ) : <TAB> """"""Return the best possible representation of the response body."""""" <TAB> ct = self . headers . get ( "" content-type "" ) <TAB> if ct : <TAB> <TAB> ct , options = parse_options_header ( ct ) <TAB> <TAB> charset = options . get ( "" charset "" ) <TAB> <TAB> if ct in JSON_CONTENT_TYPES : <TAB> <TAB> <TAB> return self . json ( charset ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . text ( charset ) <TAB> <TAB> elif ct == FORM_URL_ENCODED : <TAB> <TAB> <TAB> return parse_qsl ( self . content . decode ( charset ) , keep_blank_values = True ) <TAB> return self . content ","elif ct . startswith ( "" text/ "" ) : 
","elif ct in TEXT_CONTENT_TYPES :
",31.13,8.45,False
"def test_incrementaldecoder ( self ) : <TAB> UTF8Writer = codecs . getwriter ( "" utf-8 "" ) <TAB> for sizehint in [ None , - 1 ] + list ( range ( 1 , 33 ) ) + [ 64 , 128 , 256 , 512 , 1024 ] : <TAB> <TAB> istream = BytesIO ( self . tstring [ 0 ] ) <TAB> <TAB> ostream = UTF8Writer ( BytesIO ( ) ) <TAB> <TAB> decoder = self . incrementaldecoder ( ) <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = istream . read ( sizehint ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> u = decoder . decode ( data ) <TAB> <TAB> <TAB> <TAB> ostream . write ( u ) <TAB> <TAB> self . assertEqual ( ostream . getvalue ( ) , self . tstring [ 1 ] ) ","if not data : 
","if not data :
",100.0,100.0,True
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .png "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .md "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path ) ","if os . path . isdir ( fn ) : 
","if fn . endswith ( "" .png "" ) :
",32.17,10.25,False
"def _delete_reason ( self ) : <TAB> for i in range ( _lib . X509_REVOKED_get_ext_count ( self . _revoked ) ) : <TAB> <TAB> ext = _lib . X509_REVOKED_get_ext ( self . _revoked , i ) <TAB> <TAB> obj = _lib . X509_EXTENSION_get_object ( ext ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _lib . X509_EXTENSION_free ( ext ) <TAB> <TAB> <TAB> _lib . X509_REVOKED_delete_ext ( self . _revoked , i ) <TAB> <TAB> <TAB> break ","if _lib . OBJ_obj2nid ( obj ) == _lib . NID_crl_reason : 
","if obj . obj_type == _lib . OBJ_obj_reason :
",37.48,36.81,False
"def hexcmp ( x , y ) : <TAB> try : <TAB> <TAB> a = int ( x , 16 ) <TAB> <TAB> b = int ( y , 16 ) <TAB> <TAB> if a < b : <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> return cmp ( x , y ) ","if a > b : 
","if a > b :
",100.0,100.0,True
"def get_indentation_count ( view , start ) : <TAB> indent_count = 0 <TAB> i = start - 1 <TAB> while i > 0 : <TAB> <TAB> ch = view . substr ( i ) <TAB> <TAB> scope = view . scope_name ( i ) <TAB> <TAB> # Skip preprocessors, strings, characaters and comments <TAB> <TAB> if "" string.quoted "" in scope or "" comment "" in scope or "" preprocessor "" in scope : <TAB> <TAB> <TAB> extent = view . extract_scope ( i ) <TAB> <TAB> <TAB> i = extent . a - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> else : <TAB> <TAB> <TAB> i - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> indent_count - = 1 <TAB> <TAB> elif ch == "" { "" : <TAB> <TAB> <TAB> indent_count + = 1 <TAB> return indent_count ","if ch == "" } "" : 
","if ch == "" } "" :
",100.0,100.0,True
"def set ( self , name , value , ex = None , px = None , nx = False , xx = False ) : <TAB> if ( <TAB> <TAB> ( not nx and not xx ) <TAB> <TAB> or ( nx and self . _db . get ( name , None ) is None ) <TAB> <TAB> or ( xx and not self . _db . get ( name , None ) is None ) <TAB> ) : <TAB> <TAB> if ex > 0 : <TAB> <TAB> <TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( seconds = ex ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _db . expire ( name , datetime . now ( ) + timedelta ( milliseconds = px ) ) <TAB> <TAB> self . _db [ name ] = str ( value ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return None ","elif px > 0 : 
","if px > 0 :
",56.15,66.87,False
"def _get_between ( content , start , end = None ) : <TAB> should_yield = False <TAB> for line in content . split ( "" \n "" ) : <TAB> <TAB> if start in line : <TAB> <TAB> <TAB> should_yield = True <TAB> <TAB> <TAB> continue <TAB> <TAB> if end and end in line : <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield line . strip ( ) . split ( "" "" ) [ 0 ] ","if should_yield and line : 
","if should_yield :
",31.47,47.4,False
"def iter_event_handlers ( <TAB> self , <TAB> resource : resources_ . Resource , <TAB> event : bodies . RawEvent , ) - > Iterator [ handlers . ResourceWatchingHandler ] : <TAB> warnings . warn ( <TAB> <TAB> "" SimpleRegistry.iter_event_handlers() is deprecated; use  "" <TAB> <TAB> "" ResourceWatchingRegistry.iter_handlers(). "" , <TAB> <TAB> DeprecationWarning , <TAB> ) <TAB> cause = _create_watching_cause ( resource , event ) <TAB> for handler in self . _handlers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif registries . match ( handler = handler , cause = cause , ignore_fields = True ) : <TAB> <TAB> <TAB> yield handler ","if not isinstance ( handler , handlers . ResourceWatchingHandler ) : 
","if isinstance ( handler , handlers . ResourceWatchingHandler ) :
",77.08,81.76,False
"def __enter__ ( self ) : <TAB> if log_timer : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . logger . debug ( "" %s  starting "" % self . name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( ( "" [ %s  starting]... "" % self . name ) ) <TAB> <TAB> self . tstart = time . time ( ) ","if self . logger : 
","if self . logger :
",100.0,100.0,True
"def _handle_errors ( errors ) : <TAB> """"""Log out and possibly reraise errors during import."""""" <TAB> if not errors : <TAB> <TAB> return <TAB> log_all = True<TAB> # pylint: disable=unused-variable <TAB> err_msg = "" T2T: skipped importing  {num_missing}  data_generators modules. "" <TAB> print ( err_msg . format ( num_missing = len ( errors ) ) ) <TAB> for module , err in errors : <TAB> <TAB> err_str = str ( err ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Did not import module:  %s ; Cause:  %s "" % ( module , err_str ) ) <TAB> <TAB> if not _is_import_err_msg ( err_str , module ) : <TAB> <TAB> <TAB> print ( "" From module  %s "" % module ) <TAB> <TAB> <TAB> raise err ","if log_all : 
","if not log_all :
",36.35,53.73,False
"def _ungroup ( sequence , groups = None ) : <TAB> for v in sequence : <TAB> <TAB> if isinstance ( v , ( list , tuple ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> groups . append ( list ( _ungroup ( v , groups = None ) ) ) <TAB> <TAB> <TAB> for v in _ungroup ( v , groups ) : <TAB> <TAB> <TAB> <TAB> yield v <TAB> <TAB> else : <TAB> <TAB> <TAB> yield v ","if groups is not None : 
","if groups is not None :
",100.0,100.0,True
def run ( self ) : <TAB> while not self . completed : <TAB> <TAB> if self . block : <TAB> <TAB> <TAB> time . sleep ( self . period ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _completed . wait ( self . period ) <TAB> <TAB> self . counter + = 1 <TAB> <TAB> try : <TAB> <TAB> <TAB> self . callback ( self . counter ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . timeout is not None : <TAB> <TAB> <TAB> dt = time . time ( ) - self . _start_time <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . stop ( ) <TAB> <TAB> if self . counter == self . count : <TAB> <TAB> <TAB> self . stop ( ) ,"if dt > self . timeout : 
","if dt > self . timeout :
",100.0,100.0,True
"def dont_let_stderr_buffer ( ) : <TAB> while True : <TAB> <TAB> line = context . daemon . stderr . readline ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> if DEAD_DEPLOYD_WORKER_MESSAGE . encode ( "" utf-8 "" ) in line : <TAB> <TAB> <TAB> context . num_workers_crashed + = 1 <TAB> <TAB> print ( f "" deployd stderr:  { line } "" ) ","if not line : 
","if not line :
",100.0,100.0,True
"def mergeHiLo ( self , x_stats ) : <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats . firsttime is not None : <TAB> <TAB> if self . firsttime is None or x_stats . firsttime < self . firsttime : <TAB> <TAB> <TAB> self . firsttime = x_stats . firsttime <TAB> <TAB> <TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . lasttime = x_stats . lasttime <TAB> <TAB> <TAB> self . last = x_stats . last ","if self . lasttime is None or x_stats . lasttime > = self . lasttime : 
","if self . lasttime is None or x_stats . lasttime > self . lasttime :
",77.15,84.28,False
"def test_rlimit_get ( self ) : <TAB> import resource <TAB> p = psutil . Process ( os . getpid ( ) ) <TAB> names = [ x for x in dir ( psutil ) if x . startswith ( "" RLIMIT "" ) ] <TAB> assert names <TAB> for name in names : <TAB> <TAB> value = getattr ( psutil , name ) <TAB> <TAB> self . assertGreaterEqual ( value , 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( value , getattr ( resource , name ) ) <TAB> <TAB> <TAB> self . assertEqual ( p . rlimit ( value ) , resource . getrlimit ( value ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret = p . rlimit ( value ) <TAB> <TAB> <TAB> self . assertEqual ( len ( ret ) , 2 ) <TAB> <TAB> <TAB> self . assertGreaterEqual ( ret [ 0 ] , - 1 ) <TAB> <TAB> <TAB> self . assertGreaterEqual ( ret [ 1 ] , - 1 ) ","if name in dir ( resource ) : 
","if hasattr ( resource , name ) :
",29.49,17.29,False
"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB> <TAB> if not prop_name in entity . unindexed_properties ( ) : <TAB> <TAB> <TAB> prop_vals = entity [ prop_name ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> num_prop_vals = len ( prop_vals ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes + = 2 * num_prop_vals <TAB> return writes ","if isinstance ( prop_vals , ( list ) ) : 
","if isinstance ( prop_vals , list ) :
",49.96,61.46,False
"def check_value_check ( self , x_data , t_data , use_cudnn ) : <TAB> x = chainer . Variable ( x_data ) <TAB> t = chainer . Variable ( t_data ) <TAB> with chainer . using_config ( "" use_cudnn "" , use_cudnn ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Check if it throws nothing <TAB> <TAB> <TAB> functions . softmax_cross_entropy ( <TAB> <TAB> <TAB> <TAB> x , t , enable_double_backprop = self . enable_double_backprop <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> with self . assertRaises ( ValueError ) : <TAB> <TAB> <TAB> <TAB> functions . softmax_cross_entropy ( <TAB> <TAB> <TAB> <TAB> <TAB> x , t , enable_double_backprop = self . enable_double_backprop <TAB> <TAB> <TAB> <TAB> ) ","if self . valid : 
","if self . use_cudnn :
",64.48,26.27,False
"def get_note_title_file ( note ) : <TAB> mo = note_title_re . match ( note . get ( "" content "" , "" "" ) ) <TAB> if mo : <TAB> <TAB> fn = mo . groups ( ) [ 0 ] <TAB> <TAB> fn = fn . replace ( "" "" , "" _ "" ) <TAB> <TAB> fn = fn . replace ( "" / "" , "" _ "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> if isinstance ( fn , str ) : <TAB> <TAB> <TAB> fn = unicode ( fn , "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn = unicode ( fn ) <TAB> <TAB> if note_markdown ( note ) : <TAB> <TAB> <TAB> fn + = "" .mkdn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> fn + = "" .txt "" <TAB> <TAB> return fn <TAB> else : <TAB> <TAB> return "" "" ","if not fn : 
","if fn . startswith ( "" . "" ) :
",28.18,5.52,False
"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB> <TAB> s = s [ 1 : ] <TAB> <TAB> end = s . find ( "" ; "" ) <TAB> <TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB> <TAB> <TAB> end = s . find ( "" ; "" , end + 1 ) <TAB> <TAB> if end < 0 : <TAB> <TAB> <TAB> end = len ( s ) <TAB> <TAB> f = s [ : end ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> i = f . index ( "" = "" ) <TAB> <TAB> <TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB> <TAB> plist . append ( f . strip ( ) ) <TAB> <TAB> s = s [ end : ] <TAB> return plist ","if "" = "" in f : 
","if "" = "" in f :
",100.0,100.0,True
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> if not isinstance ( child , minidom . Element ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if grandchild . tagName != "" File "" : 
","if grandchild . getAttribute ( "" Source "" ) is None :
",41.16,14.99,False
"def date_to_format ( value , target_format ) : <TAB> """"""Convert date to specified format"""""" <TAB> if target_format == str : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . datetime ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" %d / % m/ % y "" ) <TAB> <TAB> elif isinstance ( value , datetime . time ) : <TAB> <TAB> <TAB> ret = value . strftime ( "" % H: % M: % S "" ) <TAB> else : <TAB> <TAB> ret = value <TAB> return ret ","if isinstance ( value , datetime . date ) : 
","if isinstance ( value , datetime . date ) :
",100.0,100.0,True
"def __listingColumns ( self ) : <TAB> columns = [ ] <TAB> for name in self . __getColumns ( ) : <TAB> <TAB> definition = column ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> IECore . msg ( <TAB> <TAB> <TAB> <TAB> IECore . Msg . Level . Error , <TAB> <TAB> <TAB> <TAB> "" GafferImageUI.CatalogueUI "" , <TAB> <TAB> <TAB> <TAB> "" No column registered with name  ' %s ' "" % name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( definition , IconColumn ) : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . IconColumn ( definition . title ( ) , "" "" , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> c = GafferUI . PathListingWidget . StandardColumn ( definition . title ( ) , name ) <TAB> <TAB> columns . append ( c ) <TAB> return columns ","if not definition : 
","if not definition :
",100.0,100.0,True
"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = v . item ( ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . metrics_to_scalars ( v ) <TAB> <TAB> new_metrics [ k ] = v <TAB> return new_metrics ","if isinstance ( v , torch . Tensor ) : 
","if isinstance ( v , dict ) :
",48.2,46.31,False
"def start ( self , connection ) : <TAB> try : <TAB> <TAB> if self . client_name : <TAB> <TAB> <TAB> creds = gssapi . Credentials ( name = gssapi . Name ( self . client_name ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> creds = None <TAB> <TAB> hostname = self . get_hostname ( connection ) <TAB> <TAB> name = gssapi . Name ( <TAB> <TAB> <TAB> b "" @ "" . join ( [ self . service , hostname ] ) , gssapi . NameType . hostbased_service <TAB> <TAB> ) <TAB> <TAB> context = gssapi . SecurityContext ( name = name , creds = creds ) <TAB> <TAB> return context . step ( None ) <TAB> except gssapi . raw . misc . GSSError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return NotImplemented <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if self . fail_soft : 
","if self . strict :
",64.48,28.64,False
"def nanmax ( self , axis = None , dtype = None , keepdims = None ) : <TAB> ret = self . _reduction ( <TAB> <TAB> "" nanmax "" , axis = axis , dtype = dtype , keepdims = keepdims , todense = True <TAB> ) <TAB> if not issparse ( ret ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ret <TAB> <TAB> xps = get_sparse_module ( self . spmatrix ) <TAB> <TAB> ret = SparseNDArray ( xps . csr_matrix ( ret ) ) <TAB> <TAB> return ret <TAB> return ret ","if get_array_module ( ret ) . isscalar ( ret ) : 
","if not self . spmatrix :
",26.29,2.38,False
"def utterance_to_sample ( query_data , tagging_scheme , language ) : <TAB> tokens , tags = [ ] , [ ] <TAB> current_length = 0 <TAB> for chunk in query_data : <TAB> <TAB> chunk_tokens = tokenize ( chunk [ TEXT ] , language ) <TAB> <TAB> tokens + = [ <TAB> <TAB> <TAB> Token ( t . value , current_length + t . start , current_length + t . end ) <TAB> <TAB> <TAB> for t in chunk_tokens <TAB> <TAB> ] <TAB> <TAB> current_length + = len ( chunk [ TEXT ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tags + = negative_tagging ( len ( chunk_tokens ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tags + = positive_tagging ( <TAB> <TAB> <TAB> <TAB> tagging_scheme , chunk [ SLOT_NAME ] , len ( chunk_tokens ) <TAB> <TAB> <TAB> ) <TAB> return { TOKENS : tokens , TAGS : tags } ","if SLOT_NAME not in chunk : 
","if SLOT_NAME not in chunk :
",100.0,100.0,True
"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB> <TAB> if isinstance ( t , Index ) : <TAB> <TAB> <TAB> self . _use_indexes . append ( t ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _use_indexes . append ( Index ( t ) ) ","elif isinstance ( t , str ) : 
","elif not isinstance ( t , str ) :
",78.0,75.06,False
"def reconfigServiceWithBuildbotConfig ( self , new_config ) : <TAB> if new_config . manhole != self . manhole : <TAB> <TAB> if self . manhole : <TAB> <TAB> <TAB> yield self . manhole . disownServiceParent ( ) <TAB> <TAB> <TAB> self . manhole = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . manhole = new_config . manhole <TAB> <TAB> <TAB> yield self . manhole . setServiceParent ( self ) <TAB> # chain up <TAB> yield service . ReconfigurableServiceMixin . reconfigServiceWithBuildbotConfig ( <TAB> <TAB> self , new_config <TAB> ) ","if new_config . manhole : 
","if self . manhole is None :
",38.88,15.62,False
"def cleanup_folder ( target_folder ) : <TAB> for file in os . listdir ( target_folder ) : <TAB> <TAB> file_path = os . path . join ( target_folder , file ) <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . remove ( file_path ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> logging . error ( e ) ","if os . path . isfile ( file_path ) : 
","if os . path . isfile ( file_path ) :
",100.0,100.0,True
"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> elif isinstance ( k , bool ) : <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k ) ","if isinstance ( k , float ) : 
","if isinstance ( k , float ) :
",100.0,100.0,True
"def decompile ( decompiler ) : <TAB> for pos , next_pos , opname , arg in decompiler . instructions : <TAB> <TAB> if pos in decompiler . targets : <TAB> <TAB> <TAB> decompiler . process_target ( pos ) <TAB> <TAB> method = getattr ( decompiler , opname , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> throw ( DecompileError ( "" Unsupported operation:  %s "" % opname ) ) <TAB> <TAB> decompiler . pos = pos <TAB> <TAB> decompiler . next_pos = next_pos <TAB> <TAB> x = method ( * arg ) <TAB> <TAB> if x is not None : <TAB> <TAB> <TAB> decompiler . stack . append ( x ) ","if method is None : 
","if method is None :
",100.0,100.0,True
"def shutdown ( self , timeout , callback = None ) : <TAB> logger . debug ( "" background worker got shutdown request "" ) <TAB> with self . _lock : <TAB> <TAB> if self . is_alive : <TAB> <TAB> <TAB> self . _queue . put_nowait ( _TERMINATOR ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _wait_shutdown ( timeout , callback ) <TAB> <TAB> self . _thread = None <TAB> <TAB> self . _thread_for_pid = None <TAB> logger . debug ( "" background worker shut down "" ) ","if timeout > 0.0 : 
","if timeout is not None :
",30.74,17.97,False
"def getDOMImplementation ( features = None ) : <TAB> if features : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> features = domreg . _parse_feature_string ( features ) <TAB> <TAB> for f , v in features : <TAB> <TAB> <TAB> if not Document . implementation . hasFeature ( f , v ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> return Document . implementation ","if isinstance ( features , str ) : 
","if isinstance ( features , str ) :
",100.0,100.0,True
"def validate_subevent ( self , subevent ) : <TAB> if self . context [ "" event "" ] . has_subevents : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( "" You need to set a subevent. "" ) <TAB> <TAB> if subevent . event != self . context [ "" event "" ] : <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> "" The specified subevent does not belong to this event. "" <TAB> <TAB> <TAB> ) <TAB> elif subevent : <TAB> <TAB> raise ValidationError ( "" You cannot set a subevent for this event. "" ) <TAB> return subevent ","if not subevent : 
","if not subevent :
",100.0,100.0,True
"def einsum ( job_id , idx , einsum_expr , data_list ) : <TAB> _ , all_parties = session_init ( job_id , idx ) <TAB> with SPDZ ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = FixedPointTensor . from_source ( "" x "" , data_list [ 0 ] ) <TAB> <TAB> <TAB> y = FixedPointTensor . from_source ( "" y "" , all_parties [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> x = FixedPointTensor . from_source ( "" x "" , all_parties [ 0 ] ) <TAB> <TAB> <TAB> y = FixedPointTensor . from_source ( "" y "" , data_list [ 1 ] ) <TAB> <TAB> return x . einsum ( y , einsum_expr ) . get ( ) ","if idx == 0 : 
","if idx == 0 :
",100.0,100.0,True
"def slowSorted ( qq ) : <TAB> "" Reference sort peformed by insertion using only < "" <TAB> rr = list ( ) <TAB> for q in qq : <TAB> <TAB> i = 0 <TAB> <TAB> for i in range ( len ( rr ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> rr . insert ( i , q ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> rr . append ( q ) <TAB> return rr ","if q < rr [ i ] : 
","if q < rr [ i ] :
",100.0,100.0,True
"def _format_entry ( entry , src ) : <TAB> if entry : <TAB> <TAB> result = [ ] <TAB> <TAB> for x in entry . split ( "" , "" ) : <TAB> <TAB> <TAB> x = x . strip ( ) <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( src , x ) ) : <TAB> <TAB> <TAB> <TAB> result . append ( relpath ( os . path . join ( src , x ) , src ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result . append ( relpath ( os . path . abspath ( x ) , src ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise RuntimeError ( "" No entry script  %s  found "" % x ) <TAB> <TAB> return "" , "" . join ( result ) ","elif os . path . exists ( x ) : 
","elif os . path . isabs ( x ) :
",83.03,65.8,False
"def reloadCols ( self ) : <TAB> self . columns = [ ] <TAB> for i , ( name , fmt , * shape ) in enumerate ( self . npy . dtype . descr ) : <TAB> <TAB> if shape : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> elif "" M "" in fmt : <TAB> <TAB> <TAB> self . addColumn ( Column ( name , type = date , getter = lambda c , r , i = i : str ( r [ i ] ) ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> elif "" i "" in fmt : <TAB> <TAB> <TAB> t = int <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> t = float <TAB> <TAB> else : <TAB> <TAB> <TAB> t = anytype <TAB> <TAB> self . addColumn ( ColumnItem ( name , i , type = t ) ) ","elif "" f "" in fmt : 
","elif "" f "" in fmt :
",100.0,100.0,True
"def tool_lineages ( self , trans ) : <TAB> rval = [ ] <TAB> for id , tool in self . app . toolbox . tools ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lineage_dict = tool . lineage . to_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lineage_dict = None <TAB> <TAB> entry = dict ( id = id , lineage = lineage_dict ) <TAB> <TAB> rval . append ( entry ) <TAB> return rval ","if hasattr ( tool , "" lineage "" ) : 
","if tool . lineage :
",26.51,5.56,False
"def item ( self , tensor ) : <TAB> numel = 0 <TAB> if len ( tensor . shape ) > 0 : <TAB> <TAB> numel = fct . reduce ( op . mul , tensor . shape ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> f "" expected tensor with one element,  "" f "" got  { tensor . shape } "" <TAB> <TAB> <TAB> ) <TAB> if numel == 1 : <TAB> <TAB> return tensor [ 0 ] <TAB> return tensor ","if numel != 1 : 
","if numel != 1 :
",100.0,100.0,True
"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB> <TAB> <TAB> ) . json ( ) <TAB> <TAB> <TAB> if "" Version "" in resp : <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta ","if match is not None and len ( match . groups ( ) ) == 1 : 
","if match :
",25.79,0.0,False
"def generate ( ) : <TAB> for leaf in u . leaves : <TAB> <TAB> if isinstance ( leaf , Integer ) : <TAB> <TAB> <TAB> val = leaf . get_int_value ( ) <TAB> <TAB> <TAB> if val in ( 0 , 1 ) : <TAB> <TAB> <TAB> <TAB> yield val <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> elif isinstance ( leaf , Symbol ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield 1 <TAB> <TAB> <TAB> elif leaf == SymbolFalse : <TAB> <TAB> <TAB> <TAB> yield 0 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise _NoBoolVector <TAB> <TAB> else : <TAB> <TAB> <TAB> raise _NoBoolVector ","if leaf == SymbolTrue : 
","if leaf == SymbolTrue :
",100.0,100.0,True
"def _test_set_metadata ( self , metadata , mask = None ) : <TAB> header = ofproto . OXM_OF_METADATA <TAB> match = OFPMatch ( ) <TAB> if mask is None : <TAB> <TAB> match . set_metadata ( metadata ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> header = ofproto . OXM_OF_METADATA_W <TAB> <TAB> match . set_metadata_masked ( metadata , mask ) <TAB> <TAB> metadata & = mask <TAB> self . _test_serialize_and_parser ( match , header , metadata , mask ) ","if ( mask + 1 ) >> 64 != 1 : 
","if mask . size ( ) > 0 :
",26.47,8.05,False
"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB> <TAB> icon = "" class "" <TAB> else : <TAB> <TAB> if tok . visibility == "" private "" : <TAB> <TAB> <TAB> icon = "" method_priv "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> icon = "" method_prot "" <TAB> <TAB> else : <TAB> <TAB> <TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] ) ","elif tok . visibility == "" protected "" : 
","elif tok . visibility == "" proteins "" :
",83.19,70.71,False
"def path_sum2 ( root , s ) : <TAB> if root is None : <TAB> <TAB> return [ ] <TAB> res = [ ] <TAB> stack = [ ( root , [ root . val ] ) ] <TAB> while stack : <TAB> <TAB> node , ls = stack . pop ( ) <TAB> <TAB> if node . left is None and node . right is None and sum ( ls ) == s : <TAB> <TAB> <TAB> res . append ( ls ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stack . append ( ( node . left , ls + [ node . left . val ] ) ) <TAB> <TAB> if node . right is not None : <TAB> <TAB> <TAB> stack . append ( ( node . right , ls + [ node . right . val ] ) ) <TAB> return res ","if node . left is not None : 
","if node . left is not None :
",100.0,100.0,True
"def clear_slot ( self , slot_id , trigger_changed ) : <TAB> if self . slots [ slot_id ] is not None : <TAB> <TAB> old_resource_id = self . slots [ slot_id ] . resource_id <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . sell_list [ old_resource_id ] <TAB> <TAB> else : <TAB> <TAB> <TAB> del self . buy_list [ old_resource_id ] <TAB> self . slots [ slot_id ] = None <TAB> if trigger_changed : <TAB> <TAB> self . _changed ( ) ","if self . slots [ slot_id ] . selling : 
","if old_resource_id in self . sell_list :
",32.8,9.67,False
"def OnRightUp ( self , event ) : <TAB> self . HandleMouseEvent ( event ) <TAB> self . Unbind ( wx . EVT_RIGHT_UP , handler = self . OnRightUp ) <TAB> self . Unbind ( wx . EVT_MOUSE_CAPTURE_LOST , handler = self . OnRightUp ) <TAB> self . _right = False <TAB> if not self . _left : <TAB> <TAB> self . Unbind ( wx . EVT_MOTION , handler = self . OnMotion ) <TAB> <TAB> self . SendChangeEvent ( ) <TAB> <TAB> self . SetToolTip ( wx . ToolTip ( self . _tooltip ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . ReleaseMouse ( ) ","if self . HasCapture ( ) : 
","if self . _left :
",39.45,27.48,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> for arg in args : <TAB> <TAB> for k , v in arg . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> arg [ k ] = AttrDict ( v ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arg [ k ] = v <TAB> super ( AttrDict , self ) . __init__ ( * args , * * kwargs ) ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def _toplevelTryFunc ( func , * args , status = status , * * kwargs ) : <TAB> with ThreadProfiler ( threading . current_thread ( ) ) as prof : <TAB> <TAB> t = threading . current_thread ( ) <TAB> <TAB> t . name = func . __name__ <TAB> <TAB> try : <TAB> <TAB> <TAB> t . status = func ( * args , * * kwargs ) <TAB> <TAB> except EscapeException as e :<TAB> # user aborted <TAB> <TAB> <TAB> t . status = "" aborted by user "" <TAB> <TAB> <TAB> if status : <TAB> <TAB> <TAB> <TAB> status ( "" %s  aborted "" % t . name , priority = 2 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> t . exception = e <TAB> <TAB> <TAB> t . status = "" exception "" <TAB> <TAB> <TAB> vd . exceptionCaught ( e ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> t . sheet . currentThreads . remove ( t ) ","if t . sheet : 
","if t in t . sheet . currentThreads :
",45.42,22.32,False
"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB> <TAB> if text == "" "" : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) ","elif text != self . labelList . item ( i ) . text ( ) : 
","elif text == "" "" :
",26.29,3.74,False
"def __attempt_add_to_linked_match ( <TAB> self , input_name , hdca , collection_type_description , subcollection_type ) : <TAB> structure = get_structure ( <TAB> <TAB> hdca , collection_type_description , leaf_subcollection_type = subcollection_type <TAB> ) <TAB> if not self . linked_structure : <TAB> <TAB> self . linked_structure = structure <TAB> <TAB> self . collections [ input_name ] = hdca <TAB> <TAB> self . subcollection_types [ input_name ] = subcollection_type <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise exceptions . MessageException ( CANNOT_MATCH_ERROR_MESSAGE ) <TAB> <TAB> self . collections [ input_name ] = hdca <TAB> <TAB> self . subcollection_types [ input_name ] = subcollection_type ","if not self . linked_structure . can_match ( structure ) : 
","if self . type_hint != "" match "" :
",31.01,6.94,False
"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB> <TAB> time . sleep ( 2 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> if not online and not self . _is_testbot_online ( ) : <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB> <TAB> ) ","if online and self . _is_testbot_online ( ) : 
","if self . _is_testbot_offline ( ) :
",45.33,54.97,False
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> if self . match_function ( file ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file ) ","if self . match_function ( path ) : 
","if self . match_function ( path ) :
",100.0,100.0,True
"def optimize ( self , graph : Graph ) : <TAB> MAX_TEXTURE_SIZE = config . WEBGL_MAX_TEXTURE_SIZE <TAB> flag_changed = False <TAB> for v in traverse . listup_variables ( graph ) : <TAB> <TAB> if not Placeholder . check_resolved ( v . size ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> height , width = TextureShape . get ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v . has_attribute ( SplitTarget ) : <TAB> <TAB> <TAB> flag_changed = True <TAB> <TAB> <TAB> v . attributes . add ( SplitTarget ( ) ) <TAB> return graph , flag_changed ","if height < = MAX_TEXTURE_SIZE and width < = MAX_TEXTURE_SIZE : 
","if height > MAX_TEXTURE_SIZE :
",27.67,21.75,False
"def brightness_func ( args ) : <TAB> device = _get_device_from_filter ( args ) <TAB> if args . set is None : <TAB> <TAB> # Get brightness <TAB> <TAB> if args . raw : <TAB> <TAB> <TAB> print ( str ( device . brightness ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" Brightness:  {0} % "" . format ( device . brightness ) ) <TAB> else : <TAB> <TAB> brightness_value = float ( _clamp_u8 ( args . set ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Setting brightness to  {0} % "" . format ( brightness_value ) ) <TAB> <TAB> device . brightness = brightness_value ","if not args . raw : 
","if brightness_value > device . brightness :
",33.68,6.27,False
"def _setup ( self , field_name , owner_model ) : <TAB> # Resolve possible name-based model reference. <TAB> if not self . model_class : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . model_class = owner_model <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" ModelType: Unable to resolve model  ' {} ' . "" . format ( self . model_name ) <TAB> <TAB> <TAB> ) <TAB> super ( ModelType , self ) . _setup ( field_name , owner_model ) ","if self . model_name == owner_model . __name__ : 
","if owner_model :
",26.4,3.36,False
"def build_json_schema_object ( cls , parent_builder = None ) : <TAB> builder = builders . ObjectBuilder ( cls , parent_builder ) <TAB> if builder . count_type ( builder . type ) > 1 : <TAB> <TAB> return builder <TAB> for _ , name , field in cls . iterate_with_name ( ) : <TAB> <TAB> if isinstance ( field , fields . EmbeddedField ) : <TAB> <TAB> <TAB> builder . add_field ( name , field , _parse_embedded ( field , builder ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> builder . add_field ( name , field , _parse_list ( field , builder ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> builder . add_field ( name , field , _create_primitive_field_schema ( field ) ) <TAB> return builder ","elif isinstance ( field , fields . ListField ) : 
","elif isinstance ( field , fields . ListField ) :
",100.0,100.0,True
"def filter_module ( mod , type_req = None , subclass_req = None ) : <TAB> for name in dir ( mod ) : <TAB> <TAB> val = getattr ( mod , name ) <TAB> <TAB> if type_req is not None and not isinstance ( val , type_req ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield name , val ","if subclass_req is not None and not issubclass ( val , subclass_req ) : 
","if subclass_req is not None and not issubclass ( val , subclass_req ) :
",100.0,100.0,True
"def get_icon ( self ) : <TAB> if self . icon is not None : <TAB> <TAB> # Load it from an absolute filename <TAB> <TAB> if os . path . exists ( self . icon ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return GdkPixbuf . Pixbuf . new_from_file_at_size ( self . icon , 24 , 24 ) <TAB> <TAB> <TAB> except GObject . GError as ge : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> # Load it from the current icon theme <TAB> <TAB> ( icon_name , extension ) = os . path . splitext ( os . path . basename ( self . icon ) ) <TAB> <TAB> theme = Gtk . IconTheme ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return theme . load_icon ( icon_name , 24 , 0 ) ","if theme . has_icon ( icon_name ) : 
","if extension == "" .png "" :
",26.83,4.5,False
"def sysctlTestAndSet ( name , limit ) : <TAB> "" Helper function to set sysctl limits "" <TAB> # convert non-directory names into directory names <TAB> if "" / "" not in name : <TAB> <TAB> name = "" /proc/sys/ "" + name . replace ( "" . "" , "" / "" ) <TAB> # read limit <TAB> with open ( name , "" r "" ) as readFile : <TAB> <TAB> oldLimit = readFile . readline ( ) <TAB> <TAB> if isinstance ( limit , int ) : <TAB> <TAB> <TAB> # compare integer limits before overriding <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> with open ( name , "" w "" ) as writeFile : <TAB> <TAB> <TAB> <TAB> <TAB> writeFile . write ( "" %d "" % limit ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # overwrite non-integer limits <TAB> <TAB> <TAB> with open ( name , "" w "" ) as writeFile : <TAB> <TAB> <TAB> <TAB> writeFile . write ( limit ) ","if int ( oldLimit ) < limit : 
","if limit != oldLimit :
",27.1,8.22,False
"def _wait_for_bot_presense ( self , online ) : <TAB> for _ in range ( 10 ) : <TAB> <TAB> time . sleep ( 2 ) <TAB> <TAB> if online and self . _is_testbot_online ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> "" test bot is still  {} "" . format ( "" offline "" if online else "" online "" ) <TAB> <TAB> ) ","if not online and not self . _is_testbot_online ( ) : 
","elif not online and self . _is_testbot_offline ( ) :
",43.12,54.01,False
"def handle ( self , context , sign , * args ) : <TAB> if context . rounding in ( ROUND_HALF_UP , ROUND_HALF_EVEN , ROUND_HALF_DOWN , ROUND_UP ) : <TAB> <TAB> return Infsign [ sign ] <TAB> if sign == 0 : <TAB> <TAB> if context . rounding == ROUND_CEILING : <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) <TAB> if sign == 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return Infsign [ sign ] <TAB> <TAB> return Decimal ( ( sign , ( 9 , ) * context . prec , context . Emax - context . prec + 1 ) ) ","if context . rounding == ROUND_FLOOR : 
","if context . rounding == ROUND_NEEDED :
",82.41,78.25,False
"def _get_item_columns_panel ( items , rows ) : <TAB> hbox = Gtk . HBox ( False , 4 ) <TAB> n_item = 0 <TAB> col_items = 0 <TAB> vbox = Gtk . VBox ( ) <TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB> while n_item < len ( items ) : <TAB> <TAB> item = items [ n_item ] <TAB> <TAB> vbox . pack_start ( item , False , False , 0 ) <TAB> <TAB> n_item + = 1 <TAB> <TAB> col_items + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vbox = Gtk . VBox ( ) <TAB> <TAB> <TAB> hbox . pack_start ( vbox , False , False , 0 ) <TAB> <TAB> <TAB> col_items = 0 <TAB> return hbox ","if col_items > rows : 
","if col_items == rows :
",58.14,41.11,False
"def _changed ( self ) : <TAB> if self . gtk_range . get_sensitive ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . timer . cancel ( ) <TAB> <TAB> self . timer = _Timer ( 0.5 , lambda : GLib . idle_add ( self . _write ) ) <TAB> <TAB> self . timer . start ( ) ","if self . timer : 
","if self . timer :
",100.0,100.0,True
"def unlock_graph ( result , callback , interval = 1 , propagate = False , max_retries = None ) : <TAB> if result . ready ( ) : <TAB> <TAB> second_level_res = result . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with allow_join_result ( ) : <TAB> <TAB> <TAB> <TAB> signature ( callback ) . delay ( <TAB> <TAB> <TAB> <TAB> <TAB> list ( joinall ( second_level_res , propagate = propagate ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> unlock_graph . retry ( countdown = interval , max_retries = max_retries ) ","if second_level_res . ready ( ) : 
","if second_level_res :
",28.89,47.49,False
"def update ( self , other = None , / , * * kwargs ) : <TAB> if self . _pending_removals : <TAB> <TAB> self . _commit_removals ( ) <TAB> d = self . data <TAB> if other is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> other = dict ( other ) <TAB> <TAB> for key , o in other . items ( ) : <TAB> <TAB> <TAB> d [ key ] = KeyedRef ( o , self . _remove , key ) <TAB> for key , o in kwargs . items ( ) : <TAB> <TAB> d [ key ] = KeyedRef ( o , self . _remove , key ) ","if not hasattr ( other , "" items "" ) : 
","if isinstance ( other , dict ) :
",31.15,18.59,False
"def default ( self , o ) : <TAB> try : <TAB> <TAB> if type ( o ) == datetime . datetime : <TAB> <TAB> <TAB> return str ( o ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # remove unwanted attributes from the provider object during conversion to json <TAB> <TAB> <TAB> if hasattr ( o , "" profile "" ) : <TAB> <TAB> <TAB> <TAB> del o . profile <TAB> <TAB> <TAB> if hasattr ( o , "" credentials "" ) : <TAB> <TAB> <TAB> <TAB> del o . credentials <TAB> <TAB> <TAB> if hasattr ( o , "" metadata_path "" ) : <TAB> <TAB> <TAB> <TAB> del o . metadata_path <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del o . services_config <TAB> <TAB> <TAB> return vars ( o ) <TAB> except Exception as e : <TAB> <TAB> return str ( o ) ","if hasattr ( o , "" services_config "" ) : 
","if hasattr ( o , "" services_config "" ) :
",100.0,100.0,True
"def read ( self , count = True , timeout = None , ignore_non_errors = True , ignore_timeouts = True ) : <TAB> try : <TAB> <TAB> return self . _read ( count , timeout ) <TAB> except usb . USBError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( <TAB> <TAB> <TAB> <TAB> "" read: e.errno= %s  e.strerror= %s  e.message= %s  repr= %s "" <TAB> <TAB> <TAB> <TAB> % ( e . errno , e . strerror , e . message , repr ( e ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if ignore_timeouts and is_timeout ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> if ignore_non_errors and is_noerr ( e ) : <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> raise ","if DEBUG_COMM : 
","if log . getEffectiveLevel ( ) < = logging . DEBUG :
",29.1,4.46,False
def heal ( self ) : <TAB> if not self . doctors : <TAB> <TAB> return <TAB> proc_ids = self . _get_process_ids ( ) <TAB> for proc_id in proc_ids : <TAB> <TAB> # get proc every time for latest state <TAB> <TAB> proc = PipelineProcess . objects . get ( id = proc_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for dr in self . doctors : <TAB> <TAB> <TAB> if dr . confirm ( proc ) : <TAB> <TAB> <TAB> <TAB> dr . cure ( proc ) <TAB> <TAB> <TAB> <TAB> break ,"if not proc . is_alive or proc . is_frozen : 
","if not proc :
",30.42,5.24,False
"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> #<TAB>   taiga.projects.history.models.HistoryEntry.values_diff()<TAB> ret = { } <TAB> for key , val in value . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret [ key ] = val <TAB> <TAB> elif key == "" points "" : <TAB> <TAB> <TAB> ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB> <TAB> else : <TAB> <TAB> <TAB> ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB> return ret ","if key in [ "" attachments "" , "" custom_attributes "" , "" description_diff "" ] : 
","if key == "" points "" :
",37.04,2.73,False
"def default_generator ( <TAB> self , dataset , epochs = 1 , mode = "" fit "" , deterministic = True , pad_batches = True ) : <TAB> for epoch in range ( epochs ) : <TAB> <TAB> for ( X_b , y_b , w_b , ids_b ) in dataset . iterbatches ( <TAB> <TAB> <TAB> batch_size = self . batch_size , <TAB> <TAB> <TAB> deterministic = deterministic , <TAB> <TAB> <TAB> pad_batches = pad_batches , <TAB> <TAB> ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dropout = np . array ( 0.0 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> dropout = np . array ( 1.0 ) <TAB> <TAB> <TAB> yield ( [ X_b , dropout ] , [ y_b ] , [ w_b ] ) ","if mode == "" predict "" : 
","if mode == "" fit "" :
",74.63,59.46,False
"def _cygwin_hack_find_addresses ( target ) : <TAB> addresses = [ ] <TAB> for h in [ <TAB> <TAB> target , <TAB> <TAB> "" localhost "" , <TAB> <TAB> "" 127.0.0.1 "" , <TAB> ] : <TAB> <TAB> try : <TAB> <TAB> <TAB> addr = get_local_ip_for ( h ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> addresses . append ( addr ) <TAB> <TAB> except socket . gaierror : <TAB> <TAB> <TAB> pass <TAB> return defer . succeed ( addresses ) ","if addr not in addresses : 
","if addr :
",29.69,0.0,False
"def _get_notify ( self , action_node ) : <TAB> if action_node . name not in self . _skip_notify_tasks : <TAB> <TAB> if action_node . notify : <TAB> <TAB> <TAB> task_notify = NotificationsHelper . to_model ( action_node . notify ) <TAB> <TAB> <TAB> return task_notify <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _chain_notify <TAB> return None ","elif self . _chain_notify : 
","elif self . _chain_notify :
",100.0,100.0,True
"def filterTokenLocation ( ) : <TAB> i = None <TAB> entry = None <TAB> token = None <TAB> tokens = [ ] <TAB> i = 0 <TAB> while 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> entry = extra . tokens [ i ] <TAB> <TAB> token = jsdict ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" type "" : entry . type , <TAB> <TAB> <TAB> <TAB> "" value "" : entry . value , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> <TAB> if extra . range : <TAB> <TAB> <TAB> token . range = entry . range <TAB> <TAB> if extra . loc : <TAB> <TAB> <TAB> token . loc = entry . loc <TAB> <TAB> tokens . append ( token ) <TAB> <TAB> i + = 1 <TAB> extra . tokens = tokens ","if not ( i < len ( extra . tokens ) ) : 
","if i is None :
",25.92,2.84,False
"def read ( self , size = - 1 ) : <TAB> buf = bytearray ( ) <TAB> while size != 0 and self . cursor < self . maxpos : <TAB> <TAB> if not self . in_current_block ( self . cursor ) : <TAB> <TAB> <TAB> self . seek_to_block ( self . cursor ) <TAB> <TAB> part = self . current_stream . read ( size ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if len ( part ) == 0 : <TAB> <TAB> <TAB> <TAB> raise EOFError ( ) <TAB> <TAB> <TAB> size - = len ( part ) <TAB> <TAB> self . cursor + = len ( part ) <TAB> <TAB> buf + = part <TAB> return bytes ( buf ) ","if size > 0 : 
","if not size or len ( part ) < size :
",27.51,4.93,False
"def get_properties_from_model ( model_class ) : <TAB> """"""Show properties from a model"""""" <TAB> properties = [ ] <TAB> attr_names = [ name for ( name , value ) in inspect . getmembers ( model_class , isprop ) ] <TAB> for attr_name in attr_names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attr_names . remove ( attr_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> properties . append ( <TAB> <TAB> <TAB> <TAB> dict ( label = attr_name , name = attr_name . strip ( "" _ "" ) . replace ( "" _ "" , "" "" ) ) <TAB> <TAB> <TAB> ) <TAB> return sorted ( properties , key = lambda k : k [ "" label "" ] ) ","if attr_name . endswith ( "" pk "" ) : 
","if attr_name in model_class . __dict__ :
",31.97,18.21,False
"def __getitem__ ( self , name , set = set , getattr = getattr , id = id ) : <TAB> visited = set ( ) <TAB> mydict = self . basedict <TAB> while 1 : <TAB> <TAB> value = mydict [ name ] <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> return value <TAB> <TAB> myid = id ( mydict ) <TAB> <TAB> assert myid not in visited <TAB> <TAB> visited . add ( myid ) <TAB> <TAB> mydict = mydict . Parent <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ","if mydict is None : 
","if mydict is None :
",100.0,100.0,True
"def multicolumn ( self , list , format , cols = 4 ) : <TAB> """"""Format a list of items into a multi-column list."""""" <TAB> result = "" "" <TAB> rows = ( len ( list ) + cols - 1 ) / / cols <TAB> for col in range ( cols ) : <TAB> <TAB> result = result + ' <td width= "" %d %% ""  valign=top> ' % ( 100 / / cols ) <TAB> <TAB> for i in range ( rows * col , rows * col + rows ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = result + format ( list [ i ] ) + "" <br> \n "" <TAB> <TAB> result = result + "" </td> "" <TAB> return ' <table width= "" 100 %% ""  summary= "" list "" ><tr> %s </tr></table> ' % result ","if i < len ( list ) : 
","if format :
",26.62,0.0,False
"def format_exc ( exc = None ) : <TAB> """"""Return exc (or sys.exc_info if None), formatted."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exc = _exc_info ( ) <TAB> <TAB> if exc == ( None , None , None ) : <TAB> <TAB> <TAB> return "" "" <TAB> <TAB> import traceback <TAB> <TAB> return "" "" . join ( traceback . format_exception ( * exc ) ) <TAB> finally : <TAB> <TAB> del exc ","if exc is None : 
","if exc is None :
",100.0,100.0,True
"def assert_counts ( res , lang , files , blank , comment , code ) : <TAB> for line in res : <TAB> <TAB> fields = line . split ( ) <TAB> <TAB> if len ( fields ) > = 5 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( files , int ( fields [ 1 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( blank , int ( fields [ 2 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( comment , int ( fields [ 3 ] ) ) <TAB> <TAB> <TAB> <TAB> self . assertEqual ( code , int ( fields [ 4 ] ) ) <TAB> <TAB> <TAB> <TAB> return <TAB> self . fail ( "" Found no output line for  {} "" . format ( lang ) ) ","if fields [ 0 ] == lang : 
","if fields [ 0 ] == lang :
",100.0,100.0,True
"def __iter__ ( self ) : <TAB> for name , value in self . __class__ . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( value , flag_value ) : <TAB> <TAB> <TAB> yield ( name , self . _has_flag ( value . flag ) ) ","if isinstance ( value , alias_flag_value ) : 
","if name . startswith ( "" _ "" ) :
",28.2,8.64,False
"def optimize_models ( args , use_cuda , models ) : <TAB> """"""Optimize ensemble for generation"""""" <TAB> for model in models : <TAB> <TAB> model . make_generation_fast_ ( <TAB> <TAB> <TAB> beamable_mm_beam_size = None if args . no_beamable_mm else args . beam , <TAB> <TAB> <TAB> need_attn = args . print_alignment , <TAB> <TAB> ) <TAB> <TAB> if args . fp16 : <TAB> <TAB> <TAB> model . half ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> model . cuda ( ) ","if use_cuda : 
","if use_cuda :
",78.12,100.0,True
"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB> <TAB> target_str = mydict [ source_str ] <TAB> <TAB> if target_str == source_str : <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u "" "" <TAB> <TAB> pounit = self . convertunit ( source_str , target_str ) <TAB> <TAB> self . mypofile . addunit ( pounit ) <TAB> return self . mypofile ","elif target_str . startswith ( u "" ***  "" ) : 
","elif target_str . endswith ( u "" .py "" ) :
",60.71,40.73,False
"def __sparse_values_set ( instances , static_col_indexes : list ) : <TAB> tmp_result = { idx : set ( ) for idx in static_col_indexes } <TAB> for _ , instance in instances : <TAB> <TAB> data_generator = instance . features . get_all_data ( ) <TAB> <TAB> for idx , value in data_generator : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> tmp_result [ idx ] . add ( value ) <TAB> result = [ tmp_result [ x ] for x in static_col_indexes ] <TAB> return result ","if idx not in tmp_result : 
","if value is None :
",27.52,6.97,False
def puts ( self ) : <TAB> <MASK> <TAB> <TAB> self . lazy_init_lock_ . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . puts_ is None : <TAB> <TAB> <TAB> <TAB> self . puts_ = PutRequest ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . lazy_init_lock_ . release ( ) <TAB> return self . puts_ ,"if self . puts_ is None : 
","if self . puts_ is None :
",100.0,100.0,True
"def run ( self , args , * * kwargs ) : <TAB> if args . resource_ref or args . policy_type : <TAB> <TAB> filters = { } <TAB> <TAB> if args . resource_ref : <TAB> <TAB> <TAB> filters [ "" resource_ref "" ] = args . resource_ref <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filters [ "" policy_type "" ] = args . policy_type <TAB> <TAB> filters . update ( * * kwargs ) <TAB> <TAB> return self . manager . query ( * * filters ) <TAB> else : <TAB> <TAB> return self . manager . get_all ( * * kwargs ) ","if args . policy_type : 
","if args . policy_type :
",100.0,100.0,True
"def Get_Gene ( self , id ) : <TAB> """"""Retreive the gene name (GN)."""""" <TAB> entry = self . Get ( id ) <TAB> if not entry : <TAB> <TAB> return None <TAB> GN = "" "" <TAB> for line in string . split ( entry , "" \n "" ) : <TAB> <TAB> if line [ 0 : 5 ] == "" GN<TAB> "" : <TAB> <TAB> <TAB> GN = string . strip ( line [ 5 : ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> GN = GN [ 0 : - 1 ] <TAB> <TAB> <TAB> return GN <TAB> <TAB> if line [ 0 : 2 ] == "" // "" : <TAB> <TAB> <TAB> break <TAB> return GN ","if GN [ - 1 ] == "" . "" : 
","if GN [ - 1 ] == "" . "" :
",100.0,100.0,True
"def processMovie ( self , atom ) : <TAB> for field in atom : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . processTrack ( field [ "" track "" ] ) <TAB> <TAB> if "" movie_hdr "" in field : <TAB> <TAB> <TAB> self . processMovieHeader ( field [ "" movie_hdr "" ] ) ","if "" track "" in field : 
","if "" track "" in field :
",100.0,100.0,True
"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB> <TAB> return <TAB> while True : <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self . _get_video_packet ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _decode_video_packet ( video_packet ) <TAB> <TAB> if video_packet . image is not None or not skip_empty_frame : <TAB> <TAB> <TAB> break <TAB> if _debug : <TAB> <TAB> print ( "" Returning "" , video_packet ) <TAB> return video_packet . image ","if video_packet . image == 0 : 
","if video_packet . image is not None :
",51.63,53.73,False
"def get_devices ( display = None ) : <TAB> base = "" /dev/input "" <TAB> for filename in os . listdir ( base ) : <TAB> <TAB> if filename . startswith ( "" event "" ) : <TAB> <TAB> <TAB> path = os . path . join ( base , filename ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> _devices [ path ] = EvdevDevice ( display , path ) <TAB> <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> <TAB> pass <TAB> return list ( _devices . values ( ) ) ","if path in _devices : 
","if not os . path . exists ( path ) :
",27.34,4.93,False
"def _ensure_header_written ( self , datasize ) : <TAB> if not self . _headerwritten : <TAB> <TAB> if not self . _nchannels : <TAB> <TAB> <TAB> raise Error ( "" # channels not specified "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Error ( "" sample width not specified "" ) <TAB> <TAB> if not self . _framerate : <TAB> <TAB> <TAB> raise Error ( "" sampling rate not specified "" ) <TAB> <TAB> self . _write_header ( datasize ) ","if not self . _sampwidth : 
","if not self . _sampwidth :
",100.0,100.0,True
"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB> <TAB> record = line . split ( "" / "" ) <TAB> <TAB> if len ( record ) == 6 and record [ 1 ] : <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) ) ","if record [ 0 ] == "" D "" : 
","if record [ 0 ] == "" /CVS/Entries "" :
",85.49,56.22,False
"def tearDown ( self ) : <TAB> """"""Shutdown the UDP server."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . server . stop ( 2.0 ) <TAB> <TAB> if self . sock_hdlr : <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sock_hdlr ) <TAB> <TAB> <TAB> self . sock_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self ) ","if self . server : 
","if self . server :
",100.0,100.0,True
"def get_backend ( find_library = None ) : <TAB> try : <TAB> <TAB> global _lib , _ctx <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _lib = _load_library ( find_library ) <TAB> <TAB> <TAB> _setup_prototypes ( _lib ) <TAB> <TAB> <TAB> _ctx = _Context ( ) <TAB> <TAB> _logger . warning ( <TAB> <TAB> <TAB> "" OpenUSB backend deprecated (https://github.com/pyusb/pyusb/issues/284) "" <TAB> <TAB> ) <TAB> <TAB> return _OpenUSB ( ) <TAB> except usb . libloader . LibraryException : <TAB> <TAB> # exception already logged (if any) <TAB> <TAB> _logger . error ( "" Error loading OpenUSB backend "" , exc_info = False ) <TAB> <TAB> return None <TAB> except Exception : <TAB> <TAB> _logger . error ( "" Error loading OpenUSB backend "" , exc_info = True ) <TAB> <TAB> return None ","if _lib is None : 
","if _lib is None :
",100.0,100.0,True
"def __init__ ( self , event , event_info , fields = [ ] ) : <TAB> _wmi_object . __init__ ( self , event , fields = fields ) <TAB> _set ( self , "" event_type "" , None ) <TAB> _set ( self , "" timestamp "" , None ) <TAB> _set ( self , "" previous "" , None ) <TAB> if event_info : <TAB> <TAB> event_type = self . event_type_re . match ( event_info . Path_ . Class ) . group ( 1 ) . lower ( ) <TAB> <TAB> _set ( self , "" event_type "" , event_type ) <TAB> <TAB> if hasattr ( event_info , "" TIME_CREATED "" ) : <TAB> <TAB> <TAB> _set ( self , "" timestamp "" , from_1601 ( event_info . TIME_CREATED ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _set ( self , "" previous "" , event_info . PreviousInstance ) ","if hasattr ( event_info , "" PreviousInstance "" ) : 
","if event_info . PreviousInstance :
",26.51,14.23,False
"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) : <TAB> <TAB> <TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB> <TAB> <TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" ) ","if pkg in Scheduler . listOfPackagesCurrentlyBuilding : 
","if pkg in constants . INIT_LIST :
",59.52,20.16,False
"def process_all ( self , lines , times = 1 ) : <TAB> gap = False <TAB> for _ in range ( times ) : <TAB> <TAB> for line in lines : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> <TAB> self . process ( line ) <TAB> <TAB> <TAB> if not is_command ( line ) : <TAB> <TAB> <TAB> <TAB> gap = True <TAB> return 0 ","if gap : 
","if gap :
",78.12,0.0,False
"def diff ( old , new , display = True ) : <TAB> """"""Nice colored diff implementation"""""" <TAB> if not isinstance ( old , list ) : <TAB> <TAB> old = decolorize ( str ( old ) ) . splitlines ( ) <TAB> if not isinstance ( new , list ) : <TAB> <TAB> new = decolorize ( str ( new ) ) . splitlines ( ) <TAB> line_types = { "" "" : "" % Reset "" , "" - "" : "" % Red "" , "" + "" : "" %G reen "" , "" ? "" : "" % Pink "" } <TAB> if display : <TAB> <TAB> for line in difflib . Differ ( ) . compare ( old , new ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> print ( colorize ( line_types [ line [ 0 ] ] , line ) ) <TAB> return old != new ","if line . startswith ( "" ? "" ) : 
","if line [ 0 ] not in line_types :
",27.66,8.3,False
"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB> <TAB> try : <TAB> <TAB> <TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB> <TAB> <TAB> if limit < 0 : <TAB> <TAB> <TAB> <TAB> raise ValueError ( ) <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB> if settings . MAX_PAGE_SIZE : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return settings . MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> return min ( limit , settings . MAX_PAGE_SIZE ) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except ( KeyError , ValueError ) : <TAB> <TAB> <TAB> pass <TAB> return self . default_limit ","if limit == 0 : 
","if limit < 0 :
",58.14,24.74,False
"def slice_fill ( self , slice_ ) : <TAB> "" Fills the slice with zeroes for the dimensions that have single elements and squeeze_dims true "" <TAB> if isinstance ( self . indexes , int ) : <TAB> <TAB> new_slice_ = [ 0 ] <TAB> <TAB> offset = 0 <TAB> else : <TAB> <TAB> new_slice_ = [ slice_ [ 0 ] ] <TAB> <TAB> offset = 1 <TAB> for i in range ( 1 , len ( self . nums ) ) : <TAB> <TAB> if self . squeeze_dims [ i ] : <TAB> <TAB> <TAB> new_slice_ . append ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_slice_ . append ( slice_ [ offset ] ) <TAB> <TAB> <TAB> offset + = 1 <TAB> new_slice_ + = slice_ [ offset : ] <TAB> return new_slice_ ","elif offset < len ( slice_ ) : 
","elif self . indexes [ i ] == 0 :
",26.61,4.46,False
"def wrapper ( * args , * * kw ) : <TAB> instance = args [ 0 ] <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret_dict = instance . _create_ret_object ( <TAB> <TAB> <TAB> <TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> instance . logger . error ( instance . MUST_JSON ) <TAB> <TAB> <TAB> return jsonify ( ret_dict ) , 400 <TAB> except BadRequest : <TAB> <TAB> ret_dict = instance . _create_ret_object ( <TAB> <TAB> <TAB> instance . FAILURE , None , True , instance . MUST_JSON <TAB> <TAB> ) <TAB> <TAB> instance . logger . error ( instance . MUST_JSON ) <TAB> <TAB> return jsonify ( ret_dict ) , 400 <TAB> instance . logger . debug ( "" JSON is valid "" ) <TAB> return f ( * args , * * kw ) ","if request . get_json ( ) is None : 
","if not instance . is_valid ( ) :
",40.62,10.39,False
"def add_css ( self , data ) : <TAB> if data : <TAB> <TAB> for medium , paths in data . items ( ) : <TAB> <TAB> <TAB> for path in paths : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . _css . setdefault ( medium , [ ] ) . append ( path ) ","if not self . _css . get ( medium ) or path not in self . _css [ medium ] : 
","if path not in self . _css . get ( medium , [ ] ) :
",56.86,47.09,False
"def mangle_template ( template : str , template_vars : Set [ str ] ) - > str : <TAB> if TEMPLATE_PREFIX in template or TEMPLATE_SUFFIX in template : <TAB> <TAB> raise Exception ( "" Cannot parse a template containing reserved strings "" ) <TAB> for var in template_vars : <TAB> <TAB> original = f "" {{ { var } }} "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> f ' Template string is missing a reference to  "" { var } ""  referred to in kwargs ' <TAB> <TAB> <TAB> ) <TAB> <TAB> template = template . replace ( original , mangled_name ( var ) ) <TAB> return template ","if original not in template : 
","if not original :
",28.17,13.7,False
"def filterSimilarKeywords ( keyword , kwdsIterator ) : <TAB> """"""Return a sorted list of keywords similar to the one given."""""" <TAB> seenDict = { } <TAB> kwdSndx = soundex ( keyword . encode ( "" ascii "" , "" ignore "" ) ) <TAB> matches = [ ] <TAB> matchesappend = matches . append <TAB> checkContained = False <TAB> if len ( keyword ) > 4 : <TAB> <TAB> checkContained = True <TAB> for movieID , key in kwdsIterator : <TAB> <TAB> if key in seenDict : <TAB> <TAB> <TAB> continue <TAB> <TAB> seenDict [ key ] = None <TAB> <TAB> if checkContained and keyword in key : <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> matchesappend ( key ) <TAB> return _sortKeywords ( keyword , matches ) ","if kwdSndx == soundex ( key . encode ( "" ascii "" , "" ignore "" ) ) : 
","if kwdSndx in key :
",25.93,1.26,False
"def GetInfo ( self ) : <TAB> for k , v in sorted ( self . memory_parameters . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not v : <TAB> <TAB> <TAB> continue <TAB> <TAB> print ( "" %s :  \t %#08x  ( %s ) "" % ( k , v , v ) ) <TAB> print ( "" Memory ranges: "" ) <TAB> print ( "" Start \t \t End \t \t Length "" ) <TAB> for start , length in self . runs : <TAB> <TAB> print ( "" 0x %X \t \t 0x %X \t \t 0x %X "" % ( start , start + length , length ) ) ","if k . startswith ( "" Pad "" ) : 
","if k . startswith ( "" _ "" ) :
",83.03,65.8,False
"def Children ( self ) : <TAB> """"""Returns a list of all of this object's owned (strong) children."""""" <TAB> children = [ ] <TAB> for property , attributes in self . _schema . iteritems ( ) : <TAB> <TAB> ( is_list , property_type , is_strong ) = attributes [ 0 : 3 ] <TAB> <TAB> if is_strong and property in self . _properties : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> children . append ( self . _properties [ property ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> children . extend ( self . _properties [ property ] ) <TAB> return children ","if not is_list : 
","if is_list :
",34.18,57.89,False
"def normalize_res_identifier ( self , emu , cw , val ) : <TAB> mask = ( 16 * * ( emu . get_ptr_size ( ) / / 2 ) - 1 ) << 16 <TAB> if val & mask :<TAB> # not an INTRESOURCE <TAB> <TAB> name = emu . read_mem_string ( val , cw ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> name = int ( name [ 1 : ] ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> return 0 <TAB> else : <TAB> <TAB> name = val <TAB> return name ","if name [ 0 ] == "" # "" : 
","if name . startswith ( "" 0x "" ) :
",32.9,9.55,False
"def _optimize ( self , solutions ) : <TAB> best_a = None <TAB> best_silhouette = None <TAB> best_k = None <TAB> for a , silhouette , k in solutions ( ) : <TAB> <TAB> if best_silhouette is None : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> best_silhouette = silhouette <TAB> <TAB> best_a = a <TAB> <TAB> best_k = k <TAB> return best_a , best_silhouette , best_k ","elif silhouette < = best_silhouette : 
","elif silhouette > best_k :
",30.17,17.03,False
"def find_commit_type ( sha ) : <TAB> try : <TAB> <TAB> o = obj_store [ sha ] <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> else : <TAB> <TAB> if isinstance ( o , Commit ) : <TAB> <TAB> <TAB> commits . add ( sha ) <TAB> <TAB> elif isinstance ( o , Tag ) : <TAB> <TAB> <TAB> tags . add ( sha ) <TAB> <TAB> <TAB> commits . add ( o . object [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise KeyError ( "" Not a commit or a tag:  %s "" % sha ) ","if not ignore_unknown : 
","if not all ( [ isinstance ( o , Commit ) for o in commits ] ) :
",30.57,4.75,False
"def on_search_entry_keypress ( self , widget , event ) : <TAB> key = Gdk . keyval_name ( event . keyval ) <TAB> if key == "" Escape "" : <TAB> <TAB> self . hide_search_box ( ) <TAB> elif key == "" Return "" : <TAB> <TAB> # Combine with Shift? <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . search_prev = False <TAB> <TAB> <TAB> self . do_search ( None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . search_prev = True ","if event . state & Gdk . ModifierType . SHIFT_MASK : 
","if self . search_prev :
",34.58,3.94,False
"def process_webhook_prop ( namespace ) : <TAB> if not isinstance ( namespace . webhook_properties , list ) : <TAB> <TAB> return <TAB> result = { } <TAB> for each in namespace . webhook_properties : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" = "" in each : <TAB> <TAB> <TAB> <TAB> key , value = each . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> key , value = each , "" "" <TAB> <TAB> <TAB> result [ key ] = value <TAB> namespace . webhook_properties = result ","if each : 
","if isinstance ( each , str ) :
",29.65,7.27,False
"def run ( self ) : <TAB> global WAITING_BEFORE_START <TAB> time . sleep ( WAITING_BEFORE_START ) <TAB> while self . keep_alive : <TAB> <TAB> path_id , module , resolve = self . queue_receive . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . lock . acquire ( ) <TAB> <TAB> self . modules [ path_id ] = module <TAB> <TAB> self . lock . release ( ) <TAB> <TAB> if resolve : <TAB> <TAB> <TAB> resolution = self . _resolve_with_other_modules ( resolve ) <TAB> <TAB> <TAB> self . _relations [ path_id ] = [ ] <TAB> <TAB> <TAB> for package in resolution : <TAB> <TAB> <TAB> <TAB> self . _relations [ path_id ] . append ( resolution [ package ] ) <TAB> <TAB> <TAB> self . queue_send . put ( ( path_id , module , False , resolution ) ) ","if path_id is None : 
","if module is None :
",64.58,28.64,False
"def _get_download_link ( self , url , download_type = "" torrent "" ) : <TAB> links = { <TAB> <TAB> "" torrent "" : "" "" , <TAB> <TAB> "" magnet "" : "" "" , <TAB> } <TAB> try : <TAB> <TAB> data = self . session . get ( url ) . text <TAB> <TAB> with bs4_parser ( data ) as html : <TAB> <TAB> <TAB> downloads = html . find ( "" div "" , { "" class "" : "" download "" } ) <TAB> <TAB> <TAB> if downloads : <TAB> <TAB> <TAB> <TAB> for download in downloads . findAll ( "" a "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> link = download [ "" href "" ] <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" magnet "" ] = link <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> links [ "" torrent "" ] = urljoin ( self . urls [ "" base_url "" ] , link ) <TAB> except Exception : <TAB> <TAB> pass <TAB> return links [ download_type ] ","if link . startswith ( "" magnet "" ) : 
","if link . startswith ( "" magnet: "" ) :
",83.03,70.17,False
"def _parse_fields ( cls , read ) : <TAB> read = unicode_to_str ( read ) <TAB> if type ( read ) is not str : <TAB> <TAB> _wrong_type_for_arg ( read , "" str "" , "" read "" ) <TAB> fields = { } <TAB> while read and read [ 0 ] != "" ; "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> DeserializeError ( read , "" does not separate fields with commas "" ) <TAB> <TAB> read = read [ 1 : ] <TAB> <TAB> key , _type , value , read = cls . _parse_field ( read ) <TAB> <TAB> fields [ key ] = ( _type , value ) <TAB> if read : <TAB> <TAB> # read[0] == ';' <TAB> <TAB> read = read [ 1 : ] <TAB> return fields , read ","if read and read [ 0 ] != "" , "" : 
","if not read [ 0 ] . isspace ( ) :
",40.96,21.65,False
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> elif isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> if isinstance ( k , bytes ) : <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r ","if isinstance ( v , bytes ) : 
","if isinstance ( v , bytes ) :
",100.0,100.0,True
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> if filename in cache : <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache [ filename ] = old_mtime , result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB> <TAB> cache [ filename ] = mtime , result<TAB> # at the end <TAB> <TAB> if len ( cache ) > max_size : <TAB> <TAB> <TAB> cache . popitem ( last = False ) <TAB> return result ","if old_mtime == mtime : 
","if mtime > old_mtime :
",53.85,27.89,False
def isFinished ( self ) : <TAB> # returns true if episode timesteps has reached episode length and resets the task <TAB> if self . count > self . epiLen : <TAB> <TAB> self . res ( ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . pertGlasPos ( 0 ) <TAB> <TAB> if self . count == self . epiLen / 2 + 1 : <TAB> <TAB> <TAB> self . env . reset ( ) <TAB> <TAB> <TAB> self . pertGlasPos ( 1 ) <TAB> <TAB> self . count + = 1 <TAB> <TAB> return False ,"if self . count == 1 : 
","if self . count == 0 :
",82.41,70.71,False
"def _check_vulnerabilities ( self , processed_analysis ) : <TAB> matched_vulnerabilities = list ( ) <TAB> for vulnerability in self . _rule_base_vulnerabilities : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vulnerability_data = vulnerability . get_dict ( ) <TAB> <TAB> <TAB> name = vulnerability_data . pop ( "" short_name "" ) <TAB> <TAB> <TAB> matched_vulnerabilities . append ( ( name , vulnerability_data ) ) <TAB> return matched_vulnerabilities ","if evaluate ( processed_analysis , vulnerability . rule ) : 
","if vulnerability . get_analysis ( ) == processed_analysis :
",33.12,15.4,False
"def _table_reprfunc ( self , row , col , val ) : <TAB> if self . _table . column_names [ col ] . endswith ( "" Size "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ""<TAB> %s "" % val <TAB> <TAB> elif val < 1024 * * 2 : <TAB> <TAB> <TAB> return ""<TAB> %.1f  KB "" % ( val / 1024.0 * * 1 ) <TAB> <TAB> elif val < 1024 * * 3 : <TAB> <TAB> <TAB> return ""<TAB> %.1f  MB "" % ( val / 1024.0 * * 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return ""<TAB> %.1f  GB "" % ( val / 1024.0 * * 3 ) <TAB> if col in ( 0 , "" "" ) : <TAB> <TAB> return str ( val ) <TAB> else : <TAB> <TAB> return ""<TAB> %s "" % val ","if isinstance ( val , compat . string_types ) : 
","if val < 1024 * * 1 :
",26.5,4.41,False
"def serve_until_stopped ( self ) - > None : <TAB> while True : <TAB> <TAB> rd , wr , ex = select . select ( [ self . socket . fileno ( ) ] , [ ] , [ ] , self . timeout ) <TAB> <TAB> if rd : <TAB> <TAB> <TAB> self . handle_request ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if self . event is not None and self . event . is_set ( ) : 
","if not rd :
",25.59,0.63,False
"def resize ( self , * e ) : <TAB> bold = ( "" helvetica "" , - self . _size . get ( ) , "" bold "" ) <TAB> helv = ( "" helvetica "" , - self . _size . get ( ) ) <TAB> xspace = self . _size . get ( ) <TAB> yspace = self . _size . get ( ) <TAB> for widget in self . _widgets : <TAB> <TAB> widget [ "" node_font "" ] = bold <TAB> <TAB> widget [ "" leaf_font "" ] = helv <TAB> <TAB> widget [ "" xspace "" ] = xspace <TAB> <TAB> widget [ "" yspace "" ] = yspace <TAB> <TAB> if self . _size . get ( ) < 20 : <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 2 <TAB> <TAB> else : <TAB> <TAB> <TAB> widget [ "" line_width "" ] = 3 <TAB> self . _layout ( ) ","elif self . _size . get ( ) < 30 : 
","elif self . _size . get ( ) < 24 :
",90.49,82.65,False
"def __assertTilesChangedInRegion ( self , t1 , t2 , region ) : <TAB> for tileOriginTuple in t1 . keys ( ) : <TAB> <TAB> tileOrigin = imath . V2i ( * tileOriginTuple ) <TAB> <TAB> tileRegion = imath . Box2i ( <TAB> <TAB> <TAB> tileOrigin , tileOrigin + imath . V2i ( GafferImage . ImagePlug . tileSize ( ) ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertNotEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( t1 [ tileOriginTuple ] , t2 [ tileOriginTuple ] ) ","if GafferImage . BufferAlgo . intersects ( tileRegion , region ) : 
","if region == tileRegion :
",26.13,4.22,False
"def grouped_by_prefix ( args , prefixes ) : <TAB> """"""Group behave args by (directory) scope into multiple test-runs."""""" <TAB> group_args = [ ] <TAB> current_scope = None <TAB> for arg in args . strip ( ) . split ( ) : <TAB> <TAB> assert not arg . startswith ( "" - "" ) , "" REQUIRE: arg, not options "" <TAB> <TAB> scope = select_prefix_for ( arg , prefixes ) <TAB> <TAB> if scope != current_scope : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # -- DETECTED GROUP-END: <TAB> <TAB> <TAB> <TAB> yield "" "" . join ( group_args ) <TAB> <TAB> <TAB> <TAB> group_args = [ ] <TAB> <TAB> <TAB> current_scope = scope <TAB> <TAB> group_args . append ( arg ) <TAB> if group_args : <TAB> <TAB> yield "" "" . join ( group_args ) ","if group_args : 
","if group_args :
",78.12,100.0,True
"def __print__ ( self , defaults = False ) : <TAB> if defaults : <TAB> <TAB> print_func = str <TAB> else : <TAB> <TAB> print_func = repr <TAB> pieces = [ ] <TAB> default_values = self . __defaults__ <TAB> for k in self . __fields__ : <TAB> <TAB> value = getattr ( self , k ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( value , basestring ) : <TAB> <TAB> <TAB> print_func = repr<TAB> # keep quotes around strings <TAB> <TAB> pieces . append ( "" %s = %s "" % ( k , print_func ( value ) ) ) <TAB> if pieces or self . __base__ : <TAB> <TAB> return "" %s ( %s ) "" % ( self . __class__ . __name__ , "" ,  "" . join ( pieces ) ) <TAB> else : <TAB> <TAB> return "" "" ","if not defaults and value == default_values [ k ] : 
","if k in default_values :
",26.23,10.69,False
"def setInnerHTML ( self , html ) : <TAB> log . HTMLClassifier . classify ( <TAB> <TAB> log . ThugLogging . url if log . ThugOpts . local else log . last_url , html <TAB> ) <TAB> self . tag . clear ( ) <TAB> for node in bs4 . BeautifulSoup ( html , "" html.parser "" ) . contents : <TAB> <TAB> self . tag . append ( node ) <TAB> <TAB> name = getattr ( node , "" name "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> handler = getattr ( log . DFT , "" handle_ %s "" % ( name , ) , None ) <TAB> <TAB> if handler : <TAB> <TAB> <TAB> handler ( node ) ","if name is None : 
","if name is None :
",100.0,100.0,True
"def createFields ( self ) : <TAB> yield Enum ( Bits ( self , "" class "" , 2 ) , self . CLASS_DESC ) <TAB> yield Enum ( Bit ( self , "" form "" ) , self . FORM_DESC ) <TAB> if self [ "" class "" ] . value == 0 : <TAB> <TAB> yield Enum ( Bits ( self , "" type "" , 5 ) , self . TYPE_DESC ) <TAB> else : <TAB> <TAB> yield Bits ( self , "" type "" , 5 ) <TAB> yield ASNInteger ( self , "" size "" , "" Size in bytes "" ) <TAB> size = self [ "" size "" ] . value <TAB> if size : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for field in self . _handler ( self , size ) : <TAB> <TAB> <TAB> <TAB> yield field <TAB> <TAB> else : <TAB> <TAB> <TAB> yield RawBytes ( self , "" raw "" , size ) ","if self . _handler : 
","if self . _handler :
",100.0,100.0,True
"def _process_service_request ( self , pkttype , pktid , packet ) : <TAB> """"""Process a service request"""""" <TAB> # pylint: disable=unused-argument <TAB> service = packet . get_string ( ) <TAB> packet . check_end ( ) <TAB> if service == self . _next_service : <TAB> <TAB> self . logger . debug2 ( "" Accepting request for service  %s "" , service ) <TAB> <TAB> self . _next_service = None <TAB> <TAB> self . send_packet ( MSG_SERVICE_ACCEPT , String ( service ) ) <TAB> <TAB> if self . is_server ( ) and service == _USERAUTH_SERVICE :<TAB> # pragma: no branch <TAB> <TAB> <TAB> self . _auth_in_progress = True <TAB> <TAB> <TAB> self . _send_deferred_packets ( ) <TAB> else : <TAB> <TAB> raise DisconnectError ( <TAB> <TAB> <TAB> DISC_SERVICE_NOT_AVAILABLE , "" Unexpected service request received "" <TAB> <TAB> ) ","if self . is_server ( ) and service == _USERAUTH_SERVICE : 
","if self . is_server ( ) and service == _USERAUTH_SERVICE :
",100.0,100.0,True
"def _read_fixed_body ( <TAB> self , content_length : int , delegate : httputil . HTTPMessageDelegate ) - > None : <TAB> while content_length > 0 : <TAB> <TAB> body = await self . stream . read_bytes ( <TAB> <TAB> <TAB> min ( self . params . chunk_size , content_length ) , partial = True <TAB> <TAB> ) <TAB> <TAB> content_length - = len ( body ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with _ExceptionLoggingContext ( app_log ) : <TAB> <TAB> <TAB> <TAB> ret = delegate . data_received ( body ) <TAB> <TAB> <TAB> <TAB> if ret is not None : <TAB> <TAB> <TAB> <TAB> <TAB> await ret ","if not self . _write_finished or self . is_client : 
","if app_log . isEnabledFor ( logging . DEBUG ) :
",34.81,3.94,False
"def wait_for_child ( pid , timeout = 1.0 ) : <TAB> deadline = mitogen . core . now ( ) + timeout <TAB> while timeout < mitogen . core . now ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> target_pid , status = os . waitpid ( pid , os . WNOHANG ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> if e . args [ 0 ] == errno . ECHILD : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> time . sleep ( 0.05 ) <TAB> assert False , "" wait_for_child() timed out "" ","if target_pid == pid : 
","if target_pid == pid :
",100.0,100.0,True
"def execute ( cls , ctx , op : "" DataFrameGroupByAgg "" ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> if op . stage == OperandStage . map : <TAB> <TAB> <TAB> cls . _execute_map ( ctx , op ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _execute_combine ( ctx , op ) <TAB> <TAB> elif op . stage == OperandStage . agg : <TAB> <TAB> <TAB> cls . _execute_agg ( ctx , op ) <TAB> <TAB> else :<TAB> # pragma: no cover <TAB> <TAB> <TAB> raise ValueError ( "" Aggregation operand not executable "" ) <TAB> finally : <TAB> <TAB> pd . reset_option ( "" mode.use_inf_as_na "" ) ","elif op . stage == OperandStage . combine : 
","elif op . stage == OperandStage . combine :
",100.0,100.0,True
def cut ( sentence ) : <TAB> sentence = strdecode ( sentence ) <TAB> blocks = re_han . split ( sentence ) <TAB> for blk in blocks : <TAB> <TAB> if re_han . match ( blk ) : <TAB> <TAB> <TAB> for word in __cut ( blk ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> yield word <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> for c in word : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield c <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp = re_skip . split ( blk ) <TAB> <TAB> <TAB> for x in tmp : <TAB> <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> <TAB> yield x ,"if word not in Force_Split_Words : 
","if word :
",29.69,0.0,False
"def _iter_tags ( self , type = None ) : <TAB> """"""Yield all raw tags (limit to |type| if specified)"""""" <TAB> for n in itertools . count ( ) : <TAB> <TAB> tag = self . _get_tag ( n ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield tag <TAB> <TAB> if tag [ "" d_tag "" ] == "" DT_NULL "" : <TAB> <TAB> <TAB> break ","if type is None or tag [ "" d_tag "" ] == type : 
","if type and tag [ "" d_tag "" ] == type :
",67.1,72.14,False
"def reverse_search_history ( self , searchfor , startpos = None ) : <TAB> if startpos is None : <TAB> <TAB> startpos = self . history_cursor <TAB> if _ignore_leading_spaces : <TAB> <TAB> res = [ <TAB> <TAB> <TAB> ( idx , line . lstrip ( ) ) <TAB> <TAB> <TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB> <TAB> <TAB> if line . lstrip ( ) . startswith ( searchfor . lstrip ( ) ) <TAB> <TAB> ] <TAB> else : <TAB> <TAB> res = [ <TAB> <TAB> <TAB> ( idx , line ) <TAB> <TAB> <TAB> for idx , line in enumerate ( self . history [ startpos : 0 : - 1 ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> if res : <TAB> <TAB> self . history_cursor - = res [ 0 ] [ 0 ] <TAB> <TAB> return res [ 0 ] [ 1 ] . get_line_text ( ) <TAB> return "" "" ","if line . startswith ( searchfor ) 
","if line . startswith ( searchfor )
",100.0,100.0,True
"def value_to_db_datetime ( self , value ) : <TAB> if value is None : <TAB> <TAB> return None <TAB> # Oracle doesn't support tz-aware datetimes <TAB> if timezone . is_aware ( value ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value . astimezone ( timezone . utc ) . replace ( tzinfo = None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Oracle backend does not support timezone-aware datetimes when USE_TZ is False. "" <TAB> <TAB> <TAB> ) <TAB> return unicode ( value ) ","if settings . USE_TZ : 
","if settings . USE_TZ :
",100.0,100.0,True
"def _sniff ( filename , oxlitype ) : <TAB> try : <TAB> <TAB> with open ( filename , "" rb "" ) as fileobj : <TAB> <TAB> <TAB> header = fileobj . read ( 4 ) <TAB> <TAB> <TAB> if header == b "" OXLI "" : <TAB> <TAB> <TAB> <TAB> fileobj . read ( 1 )<TAB> # skip the version number <TAB> <TAB> <TAB> <TAB> ftype = fileobj . read ( 1 ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False <TAB> except OSError : <TAB> <TAB> return False ","if binascii . hexlify ( ftype ) == oxlitype : 
","if ftype == b "" SNIF "" and oxlitype == ftype :
",26.48,7.47,False
"def unget ( self , char ) : <TAB> # Only one character is allowed to be ungotten at once - it must <TAB> # be consumed again before any further call to unget <TAB> if char is not EOF : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # unget is called quite rarely, so it's a good idea to do <TAB> <TAB> <TAB> # more work here if it saves a bit of work in the frequently <TAB> <TAB> <TAB> # called char and charsUntil. <TAB> <TAB> <TAB> # So, just prepend the ungotten character onto the current <TAB> <TAB> <TAB> # chunk: <TAB> <TAB> <TAB> self . chunk = char + self . chunk <TAB> <TAB> <TAB> self . chunkSize + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . chunkOffset - = 1 <TAB> <TAB> <TAB> assert self . chunk [ self . chunkOffset ] == char ","if self . chunkOffset == 0 : 
","if self . chunkOffset == 0 :
",100.0,100.0,True
"def scan ( rule , extensions , paths , ignore_paths = None ) : <TAB> """"""The libsast scan."""""" <TAB> try : <TAB> <TAB> options = { <TAB> <TAB> <TAB> "" match_rules "" : rule , <TAB> <TAB> <TAB> "" match_extensions "" : extensions , <TAB> <TAB> <TAB> "" ignore_paths "" : ignore_paths , <TAB> <TAB> <TAB> "" show_progress "" : False , <TAB> <TAB> } <TAB> <TAB> scanner = Scanner ( options , paths ) <TAB> <TAB> res = scanner . scan ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return format_findings ( res [ "" pattern_matcher "" ] , paths [ 0 ] ) <TAB> except Exception : <TAB> <TAB> logger . exception ( "" libsast scan "" ) <TAB> return { } ","if res : 
","if res :
",78.12,0.0,False
"def _getPatternTemplate ( pattern , key = None ) : <TAB> if key is None : <TAB> <TAB> key = pattern <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = pattern . upper ( ) <TAB> template = DD_patternCache . get ( key ) <TAB> if not template : <TAB> <TAB> if key in ( "" EPOCH "" , "" { ^LN-BEG}EPOCH "" , "" ^EPOCH "" ) : <TAB> <TAB> <TAB> template = DateEpoch ( lineBeginOnly = ( key != "" EPOCH "" ) ) <TAB> <TAB> elif key in ( "" TAI64N "" , "" { ^LN-BEG}TAI64N "" , "" ^TAI64N "" ) : <TAB> <TAB> <TAB> template = DateTai64n ( wordBegin = ( "" start "" if key != "" TAI64N "" else False ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template = DatePatternRegex ( pattern ) <TAB> DD_patternCache . set ( key , template ) <TAB> return template ","if "" % "" not in pattern : 
","if isinstance ( pattern , str ) :
",26.81,7.27,False
"def _forward_response ( self , src , dst ) : <TAB> """"""Forward an SCP response between two remote SCP servers"""""" <TAB> # pylint: disable=no-self-use <TAB> try : <TAB> <TAB> exc = yield from src . await_response ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dst . send_error ( exc ) <TAB> <TAB> <TAB> return exc <TAB> <TAB> else : <TAB> <TAB> <TAB> dst . send_ok ( ) <TAB> <TAB> <TAB> return None <TAB> except OSError as exc : <TAB> <TAB> return exc ","if exc : 
","if exc :
",78.12,0.0,False
"def _maybe_signal_recovery_end ( ) - > None : <TAB> if self . in_recovery and not self . active_remaining_total ( ) : <TAB> <TAB> # apply anything stuck in the buffers <TAB> <TAB> self . flush_buffers ( ) <TAB> <TAB> self . _set_recovery_ended ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _actives_span . set_tag ( "" Actives-Ready "" , True ) <TAB> <TAB> self . signal_recovery_end . set ( ) ","if self . _actives_span is not None : 
","if self . _actives_span :
",47.74,59.76,False
"def main ( ) : <TAB> tmpdir = None <TAB> try : <TAB> <TAB> # Create a temporary working directory <TAB> <TAB> tmpdir = tempfile . mkdtemp ( ) <TAB> <TAB> # Unpack the zipfile into the temporary directory <TAB> <TAB> pip_zip = os . path . join ( tmpdir , "" pip.zip "" ) <TAB> <TAB> with open ( pip_zip , "" wb "" ) as fp : <TAB> <TAB> <TAB> fp . write ( b85decode ( DATA . replace ( b "" \n "" , b "" "" ) ) ) <TAB> <TAB> # Add the zipfile to sys.path so that we can import it <TAB> <TAB> sys . path . insert ( 0 , pip_zip ) <TAB> <TAB> # Run the bootstrap <TAB> <TAB> bootstrap ( tmpdir = tmpdir ) <TAB> finally : <TAB> <TAB> # Clean up our temporary working directory <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutil . rmtree ( tmpdir , ignore_errors = True ) ","if tmpdir : 
","if tmpdir is not None :
",34.04,17.97,False
"def __init__ ( self , api_version_str ) : <TAB> try : <TAB> <TAB> self . latest = self . preview = False <TAB> <TAB> self . yyyy = self . mm = self . dd = None <TAB> <TAB> if api_version_str == "" latest "" : <TAB> <TAB> <TAB> self . latest = True <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . preview = True <TAB> <TAB> <TAB> parts = api_version_str . split ( "" - "" ) <TAB> <TAB> <TAB> self . yyyy = int ( parts [ 0 ] ) <TAB> <TAB> <TAB> self . mm = int ( parts [ 1 ] ) <TAB> <TAB> <TAB> self . dd = int ( parts [ 2 ] ) <TAB> except ( ValueError , TypeError ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The API version  {}  is not in a  "" "" supported format "" . format ( api_version_str ) <TAB> <TAB> ) ","if "" preview "" in api_version_str : 
","if api_version_str . endswith ( "" preview "" ) :
",38.92,37.6,False
"def _merge ( self , items , map_id , dep_id , use_disk , meminfo , mem_limit ) : <TAB> combined = self . combined <TAB> merge_combiner = self . aggregator . mergeCombiners <TAB> for k , v in items : <TAB> <TAB> o = combined . get ( k ) <TAB> <TAB> combined [ k ] = merge_combiner ( o , v ) if o is not None else v <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mem_limit = self . _rotate ( ) ","if use_disk and meminfo . rss > mem_limit : 
","if meminfo . size > mem_limit :
",42.83,34.03,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_value ( d . getVarInt32 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 8 : 
","if tt == 8 :
",100.0,100.0,True
"def nice ( deltat ) : <TAB> # singular,plural <TAB> times = _ ( <TAB> <TAB> "" second,seconds:minute,minutes:hour,hours:day,days:week,weeks:month,months:year,years "" <TAB> ) . split ( "" : "" ) <TAB> d = abs ( int ( deltat ) ) <TAB> for div , time in zip ( ( 60 , 60 , 24 , 7 , 4 , 12 , 100 ) , times ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" %s %i %s "" % ( deltat < 0 and "" - "" or "" "" , d , time . split ( "" , "" ) [ d != 1 ] ) <TAB> <TAB> d / = div ","if d < div * 5 : 
","if div == 0 :
",27.38,9.04,False
"def after_get_object ( self , event , view_kwargs ) : <TAB> if event and event . state == "" draft "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ObjectNotFound ( { "" parameter "" : "" {id} "" } , "" Event: not found "" ) ","if not is_logged_in ( ) or not has_access ( "" is_coorganizer "" , event_id = event . id ) : 
","if not self . _get_object ( event ) :
",28.56,2.62,False
def daemonize_if_required ( self ) : <TAB> if self . options . daemon : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Stop the logging queue listener for the current process <TAB> <TAB> <TAB> # We'll restart it once forked <TAB> <TAB> <TAB> log . shutdown_multiprocessing_logging_listener ( daemonizing = True ) <TAB> <TAB> # Late import so logging works correctly <TAB> <TAB> salt . utils . process . daemonize ( ) <TAB> # Setup the multiprocessing log queue listener if enabled <TAB> self . _setup_mp_logging_listener ( ) ,"if self . _setup_mp_logging_listener_ is True : 
","if self . options . forked :
",39.71,8.38,False
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> if not clients : <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None : <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module ","if module . is_compatible_with ( client ) : 
","if client . module_name == module_name :
",32.07,5.51,False
"def _incremental_avg_dp ( self , avg , new_el , idx ) : <TAB> for attr in [ "" coarse_segm "" , "" fine_segm "" , "" u "" , "" v "" ] : <TAB> <TAB> setattr ( <TAB> <TAB> <TAB> avg , attr , ( getattr ( avg , attr ) * idx + getattr ( new_el , attr ) ) / ( idx + 1 ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Deletion of the > 0 index intermediary values to prevent GPU OOM <TAB> <TAB> <TAB> setattr ( new_el , attr , None ) <TAB> return avg ","if idx : 
","if getattr ( avg , attr ) == 0 :
",29.22,4.46,False
"def run ( self , paths = [ ] ) : <TAB> collapsed = False <TAB> for item in SideBarSelection ( paths ) . getSelectedDirectories ( ) : <TAB> <TAB> for view in item . views ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> Window ( ) . focus_view ( view ) <TAB> <TAB> <TAB> <TAB> self . collapse_sidebar_folder ( ) <TAB> <TAB> <TAB> <TAB> collapsed = True <TAB> <TAB> <TAB> view . close ( ) ","if not collapsed : 
","if collapsed :
",34.18,0.0,False
"def test_reductions ( expr , rdd ) : <TAB> result = compute ( expr , rdd ) <TAB> expected = compute ( expr , data ) <TAB> if not result == expected : <TAB> <TAB> print ( result ) <TAB> <TAB> print ( expected ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert abs ( result - expected ) < 0.001 <TAB> <TAB> else : <TAB> <TAB> <TAB> assert result == expected ","if isinstance ( result , float ) : 
","if math . abs ( result - expected ) < 0.001 :
",28.06,8.52,False
"def deltask ( task , d ) : <TAB> if task [ : 3 ] != "" do_ "" : <TAB> <TAB> task = "" do_ "" + task <TAB> bbtasks = d . getVar ( "" __BBTASKS "" , False ) or [ ] <TAB> if task in bbtasks : <TAB> <TAB> bbtasks . remove ( task ) <TAB> <TAB> d . delVarFlag ( task , "" task "" ) <TAB> <TAB> d . setVar ( "" __BBTASKS "" , bbtasks ) <TAB> d . delVarFlag ( task , "" deps "" ) <TAB> for bbtask in d . getVar ( "" __BBTASKS "" , False ) or [ ] : <TAB> <TAB> deps = d . getVarFlag ( bbtask , "" deps "" , False ) or [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> deps . remove ( task ) <TAB> <TAB> <TAB> d . setVarFlag ( bbtask , "" deps "" , deps ) ","if task in deps : 
","if task in deps :
",100.0,100.0,True
"def _apply_weightnorm ( self , list_layers ) : <TAB> """"""Try apply weightnorm for all layer in list_layers."""""" <TAB> for i in range ( len ( list_layers ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> layer_name = list_layers [ i ] . name . lower ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> list_layers [ i ] = WeightNormalization ( list_layers [ i ] ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass ","if "" conv1d "" in layer_name or "" dense "" in layer_name : 
","if layer_name == "" weightnorm "" :
",33.22,9.59,False
"def __init__ ( self , execution_context , aggregate_operators ) : <TAB> super ( _QueryExecutionAggregateEndpointComponent , self ) . __init__ ( execution_context ) <TAB> self . _local_aggregators = [ ] <TAB> self . _results = None <TAB> self . _result_index = 0 <TAB> for operator in aggregate_operators : <TAB> <TAB> if operator == "" Average "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _AverageAggregator ( ) ) <TAB> <TAB> elif operator == "" Count "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _CountAggregator ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MaxAggregator ( ) ) <TAB> <TAB> elif operator == "" Min "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _MinAggregator ( ) ) <TAB> <TAB> elif operator == "" Sum "" : <TAB> <TAB> <TAB> self . _local_aggregators . append ( _SumAggregator ( ) ) ","elif operator == "" Max "" : 
","elif operator == "" Max "" :
",100.0,100.0,True
"def _conv_layer ( self , sess , bottom , name , trainable = True , padding = "" SAME "" , relu = True ) : <TAB> with tf . variable_scope ( name ) as scope : <TAB> <TAB> filt = self . _get_conv_filter ( sess , name , trainable = trainable ) <TAB> <TAB> conv_biases = self . _get_bias ( sess , name , trainable = trainable ) <TAB> <TAB> conv = tf . nn . conv2d ( bottom , filt , [ 1 , 1 , 1 , 1 ] , padding = padding ) <TAB> <TAB> bias = tf . nn . bias_add ( conv , conv_biases ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bias = tf . nn . relu ( bias ) <TAB> <TAB> return bias ","if relu : 
","if relu :
",78.12,0.0,False
"def get_partners ( self ) - > Dict [ AbstractNode , Set [ int ] ] : <TAB> partners = { }<TAB> # type: Dict[AbstractNode, Set[int]] <TAB> for edge in self . edges : <TAB> <TAB> if edge . is_dangling ( ) : <TAB> <TAB> <TAB> raise ValueError ( "" Cannot contract copy tensor with dangling edges "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> partner_node , shared_axis = self . _get_partner ( edge ) <TAB> <TAB> if partner_node not in partners : <TAB> <TAB> <TAB> partners [ partner_node ] = set ( ) <TAB> <TAB> partners [ partner_node ] . add ( shared_axis ) <TAB> return partners ","if self . _is_my_trace ( edge ) : 
","if edge . axis != self . axis :
",33.53,7.82,False
"def close ( self ) : <TAB> with self . _lock : <TAB> <TAB> """"""Close this _MultiFileWatcher object forever."""""" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _folder_handlers = { } <TAB> <TAB> <TAB> LOGGER . debug ( <TAB> <TAB> <TAB> <TAB> "" Stopping observer thread even though there is a non-zero  "" <TAB> <TAB> <TAB> <TAB> "" number of event observers! "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> LOGGER . debug ( "" Stopping observer thread "" ) <TAB> <TAB> self . _observer . stop ( ) <TAB> <TAB> self . _observer . join ( timeout = 5 ) ","if len ( self . _folder_handlers ) != 0 : 
","if len ( self . _folder_handlers ) == 0 :
",85.49,78.25,False
"def comboSelectionChanged ( self , index ) : <TAB> text = self . comboBox . cb . itemText ( index ) <TAB> for i in range ( self . labelList . count ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) <TAB> <TAB> elif text != self . labelList . item ( i ) . text ( ) : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . labelList . item ( i ) . setCheckState ( 2 ) ","if text == "" "" : 
","if text == self . labelList . item ( i ) . text ( ) :
",32.32,15.14,False
"def _get_messages ( self ) : <TAB> r = [ ] <TAB> try : <TAB> <TAB> self . _connect ( ) <TAB> <TAB> self . _login ( ) <TAB> <TAB> for message in self . _fetch ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> r . append ( message ) <TAB> <TAB> self . _connection . expunge ( ) <TAB> <TAB> self . _connection . close ( ) <TAB> <TAB> self . _connection . logout ( ) <TAB> except MailFetcherError as e : <TAB> <TAB> self . log ( "" error "" , str ( e ) ) <TAB> return r ","if message : 
","if message . get ( "" type "" ) == "" message "" :
",32.48,5.82,False
"def get_current_user ( self ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return config . get ( "" json_authentication_override "" ) <TAB> <TAB> tkn_header = self . request . headers [ "" authorization "" ] <TAB> except KeyError : <TAB> <TAB> raise WebAuthNError ( reason = "" Missing Authorization Header "" ) <TAB> else : <TAB> <TAB> tkn_str = tkn_header . split ( "" "" ) [ - 1 ] <TAB> try : <TAB> <TAB> tkn = self . jwt_validator ( tkn_str ) <TAB> except AuthenticationError as e : <TAB> <TAB> raise WebAuthNError ( reason = e . message ) <TAB> else : <TAB> <TAB> return tkn ","if config . get ( "" development "" ) and config . get ( "" json_authentication_override "" ) : 
","if config . get ( "" json_authentication_override "" ) :
",65.36,52.58,False
def _get_data ( self ) : <TAB> formdata = self . _formdata <TAB> if formdata : <TAB> <TAB> data = [ ] <TAB> <TAB> # TODO: Optimize? <TAB> <TAB> for item in formdata : <TAB> <TAB> <TAB> model = self . loader . get_one ( item ) if item else None <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data . append ( model ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _invalid_formdata = True <TAB> <TAB> self . _set_data ( data ) <TAB> return self . _data ,"if model : 
","if model :
",78.12,0.0,False
"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set ( ) <TAB> end = va + size <TAB> for offs in range ( va , end , 1 ) : <TAB> <TAB> loc = self . getLocation ( offs , range = True ) <TAB> <TAB> if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va : <TAB> <TAB> <TAB> subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB> return list ( subs ) ","if loc [ L_TINFO ] : 
","if ltyp == LC_SUBSTRING and loc [ L_TINFO ] :
",63.49,41.37,False
def monad ( self ) : <TAB> if not self . cls_bl_idname : <TAB> <TAB> return None <TAB> for monad in bpy . data . node_groups : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if monad . cls_bl_idname == self . cls_bl_idname : <TAB> <TAB> <TAB> <TAB> return monad <TAB> return None ,"if hasattr ( monad , "" cls_bl_idname "" ) : 
","if monad . node_type == bpy . node_type . BLENDER :
",26.41,3.66,False
"def _set_peer_statuses ( self ) : <TAB> """"""Set peer statuses."""""" <TAB> cutoff = time . time ( ) - STALE_SECS <TAB> for peer in self . peers : <TAB> <TAB> if peer . bad : <TAB> <TAB> <TAB> peer . status = PEER_BAD <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> peer . status = PEER_GOOD <TAB> <TAB> elif peer . last_good : <TAB> <TAB> <TAB> peer . status = PEER_STALE <TAB> <TAB> else : <TAB> <TAB> <TAB> peer . status = PEER_NEVER ","elif peer . last_good > cutoff : 
","elif cutoff < = time . time ( ) :
",33.24,5.93,False
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> if i == index : <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> if composite_file . optional : <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None ","if composite_file . description : 
","if composite_file . description :
",100.0,100.0,True
"def testUiViewServerDump_windowIntM1 ( self ) : <TAB> device = None <TAB> try : <TAB> <TAB> device = MockDevice ( version = 15 , startviewserver = True ) <TAB> <TAB> vc = ViewClient ( device , device . serialno , adb = TRUE , autodump = False ) <TAB> <TAB> vc . dump ( window = - 1 ) <TAB> <TAB> vc . findViewByIdOrRaise ( "" id/home "" ) <TAB> finally : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> device . shutdownMockViewServer ( ) ","if device : 
","if device :
",78.12,0.0,False
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , bytes ) : <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> if isinstance ( k , bytes ) : <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r ","elif isinstance ( v , dict ) : 
","elif isinstance ( v , dict ) :
",100.0,100.0,True
"def _testSendmsgTimeout ( self ) : <TAB> try : <TAB> <TAB> self . cli_sock . settimeout ( 0.03 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> self . sendmsgToServer ( [ b "" a "" * 512 ] ) <TAB> <TAB> except socket . timeout : <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> # bpo-33937 the test randomly fails on Travis CI with <TAB> <TAB> <TAB> # ""OSError: [Errno 12] Cannot allocate memory"" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" socket.timeout not raised "" ) <TAB> finally : <TAB> <TAB> self . misc_event . set ( ) ","if exc . errno != errno . ENOMEM : 
","if exc . errno != errno . EAGAIN :
",87.71,78.25,False
"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB> <TAB> if self . showAll : <TAB> <TAB> <TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . stream . write ( "" s "" ) <TAB> <TAB> <TAB> self . stream . flush ( ) <TAB> <TAB> return <TAB> _org_AddError ( self , test , err ) ","elif self . dots : 
","if self . verbose > 1 :
",37.98,14.54,False
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> if self . scrolling : <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event ) ","elif self . scroll_down_rect ( ) . collidepoint ( p ) : 
","if self . scroll_down_rect ( ) . collidepoint ( p ) :
",87.36,93.06,False
"def find_file_copyright_notices ( fname ) : <TAB> ret = set ( ) <TAB> f = open ( fname ) <TAB> lines = f . readlines ( ) <TAB> for l in lines [ : 80 ] :<TAB> # hmmm, assume copyright to be in first 80 lines <TAB> <TAB> idx = l . lower ( ) . find ( "" copyright "" ) <TAB> <TAB> if idx < 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = l [ idx + 9 : ] . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> copyright = sanitise ( copyright ) <TAB> <TAB> # hmm, do a quick check to see if there's a year, <TAB> <TAB> # if not, skip it <TAB> <TAB> if not copyright . find ( "" 200 "" ) > = 0 and not copyright . find ( "" 199 "" ) > = 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> ret . add ( copyright ) <TAB> return ret ","if not copyright : 
","if not copyright :
",100.0,100.0,True
"def get_selectable_values ( self , request ) : <TAB> shop = lfs . core . utils . get_default_shop ( request ) <TAB> countries = [ ] <TAB> for country in shop . shipping_countries . all ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selected = True <TAB> <TAB> else : <TAB> <TAB> <TAB> selected = False <TAB> <TAB> countries . append ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" id "" : country . id , <TAB> <TAB> <TAB> <TAB> "" name "" : country . name , <TAB> <TAB> <TAB> <TAB> "" selected "" : selected , <TAB> <TAB> <TAB> } <TAB> <TAB> ) <TAB> return countries ","if country in self . value . all ( ) : 
","if country . is_shipping_country ( request ) :
",31.7,10.6,False
"def _addItemToLayout ( self , sample , label ) : <TAB> col = self . layout . columnCount ( ) <TAB> row = self . layout . rowCount ( ) <TAB> if row : <TAB> <TAB> row - = 1 <TAB> nCol = self . columnCount * 2 <TAB> # FIRST ROW FULL <TAB> if col == nCol : <TAB> <TAB> for col in range ( 0 , nCol , 2 ) : <TAB> <TAB> <TAB> # FIND RIGHT COLUMN <TAB> <TAB> <TAB> if not self . layout . itemAt ( row , col ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # MAKE NEW ROW <TAB> <TAB> <TAB> col = 0 <TAB> <TAB> <TAB> row + = 1 <TAB> self . layout . addItem ( sample , row , col ) <TAB> self . layout . addItem ( label , row , col + 1 ) ","if col + 2 == nCol : 
","if self . layout . itemAt ( row , col ) :
",26.76,4.46,False
def contains_only_whitespace ( node ) : <TAB> if is_tag ( node ) : <TAB> <TAB> if not any ( [ not is_text ( s ) for s in node . contents ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ,"if not any ( [ unicode ( s ) . strip ( ) for s in node . contents ] ) : 
","if node . contents [ 0 ] . isspace ( ) and not node . contents [ 1 ] . isspace ( ) :
",26.09,10.05,False
"def tokenize_generator ( cw ) : <TAB> ret = [ ] <TAB> done = { } <TAB> for op in ops : <TAB> <TAB> ch = op . symbol [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> sops = start_symbols [ ch ] <TAB> <TAB> cw . write ( "" case  ' %s ' : "" % ch ) <TAB> <TAB> for t in gen_tests ( sops , 1 ) : <TAB> <TAB> <TAB> cw . write ( t ) <TAB> <TAB> done [ ch ] = True <TAB> return ret ","if ch in done : 
","if ch in done :
",100.0,100.0,True
"def _convertNbCharsInNbBits ( self , nbChars ) : <TAB> nbMinBit = None <TAB> nbMaxBit = None <TAB> if nbChars is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> nbMinBit = nbChars * 8 <TAB> <TAB> <TAB> nbMaxBit = nbMinBit <TAB> <TAB> else : <TAB> <TAB> <TAB> if nbChars [ 0 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMinBit = nbChars [ 0 ] * 8 <TAB> <TAB> <TAB> if nbChars [ 1 ] is not None : <TAB> <TAB> <TAB> <TAB> nbMaxBit = nbChars [ 1 ] * 8 <TAB> return ( nbMinBit , nbMaxBit ) ","if isinstance ( nbChars , int ) : 
","if nbChars [ 0 ] == 1 :
",26.93,6.27,False
"def init ( self , * args , * * kwargs ) : <TAB> if "" _state "" not in kwargs : <TAB> <TAB> state = { } <TAB> <TAB> # Older versions have the _state entries as individual kwargs <TAB> <TAB> for arg in ( "" children "" , "" windowState "" , "" detachedPanels "" ) : <TAB> <TAB> <TAB> if arg in kwargs : <TAB> <TAB> <TAB> <TAB> state [ arg ] = kwargs [ arg ] <TAB> <TAB> <TAB> <TAB> del kwargs [ arg ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs [ "" _state "" ] = state <TAB> originalInit ( self , * args , * * kwargs ) ","if state : 
","elif state :
",35.87,0.0,False
"def spm_decode ( tokens : List [ str ] ) - > List [ str ] : <TAB> words = [ ] <TAB> pieces : List [ str ] = [ ] <TAB> for t in tokens : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if len ( pieces ) > 0 : <TAB> <TAB> <TAB> <TAB> words . append ( "" "" . join ( pieces ) ) <TAB> <TAB> <TAB> pieces = [ t [ 1 : ] ] <TAB> <TAB> else : <TAB> <TAB> <TAB> pieces . append ( t ) <TAB> if len ( pieces ) > 0 : <TAB> <TAB> words . append ( "" "" . join ( pieces ) ) <TAB> return words ","if t [ 0 ] == DecodeMixin . spm_bos_token : 
","if t . startswith ( "" @ "" ) :
",32.78,6.05,False
"def _compare_dirs ( self , dir1 : str , dir2 : str ) - > List [ str ] : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [ ]<TAB> # type: List[str] <TAB> for root , dirs , files in os . walk ( dir1 ) : <TAB> <TAB> for file_ in files : <TAB> <TAB> <TAB> path = os . path . join ( root , file_ ) <TAB> <TAB> <TAB> target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> diff . append ( file_ ) <TAB> return diff ","if not os . path . exists ( target_path ) : 
","if self . _compare_path ( path , target_path ) :
",34.31,28.5,False
"def credentials ( self ) : <TAB> """"""The session credentials as a dict"""""" <TAB> creds = { } <TAB> if self . _creds : <TAB> <TAB> if self . _creds . access_key :<TAB> # pragma: no branch <TAB> <TAB> <TAB> creds [ "" aws_access_key_id "" ] = self . _creds . access_key <TAB> <TAB> if self . _creds . secret_key :<TAB> # pragma: no branch <TAB> <TAB> <TAB> creds [ "" aws_secret_access_key "" ] = self . _creds . secret_key <TAB> <TAB> if self . _creds . token : <TAB> <TAB> <TAB> creds [ "" aws_session_token "" ] = self . _creds . token <TAB> if self . _session . region_name : <TAB> <TAB> creds [ "" aws_region "" ] = self . _session . region_name <TAB> if self . requester_pays : <TAB> <TAB> creds [ "" aws_request_payer "" ] = "" requester "" <TAB> return creds ","if self . _creds . access_key : 
","if self . _creds . access_key :
",100.0,100.0,True
"def got_arbiter_module_type_defined ( self , mod_type ) : <TAB> for a in self . arbiters : <TAB> <TAB> # Do like the linkify will do after.... <TAB> <TAB> for m in getattr ( a , "" modules "" , [ ] ) : <TAB> <TAB> <TAB> # So look at what the arbiter try to call as module <TAB> <TAB> <TAB> m = m . strip ( ) <TAB> <TAB> <TAB> # Ok, now look in modules... <TAB> <TAB> <TAB> for mod in self . modules : <TAB> <TAB> <TAB> <TAB> # try to see if this module is the good type <TAB> <TAB> <TAB> <TAB> if getattr ( mod , "" module_type "" , "" "" ) . strip ( ) == mod_type . strip ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> # if so, the good name? <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if getattr ( mod , "" module_name "" , "" "" ) . strip ( ) == m : 
","if m == m :
",26.97,3.73,False
"def find_file_at_path_with_indexes ( self , path , url ) : <TAB> if url . endswith ( "" / "" ) : <TAB> <TAB> path = os . path . join ( path , self . index_file ) <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> elif url . endswith ( "" / "" + self . index_file ) : <TAB> <TAB> if os . path . isfile ( path ) : <TAB> <TAB> <TAB> return self . redirect ( url , url [ : - len ( self . index_file ) ] ) <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_static_file ( path , url ) <TAB> <TAB> except IsDirectoryError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . redirect ( url , url + "" / "" ) <TAB> raise MissingFileError ( path ) ","if os . path . isfile ( os . path . join ( path , self . index_file ) ) : 
","if path . endswith ( "" / "" ) :
",33.22,3.58,False
def _use_full_params ( self ) - > None : <TAB> for p in self . params : <TAB> <TAB> if not p . _is_sharded : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> assert p . _fp16_shard . storage ( ) . size ( ) != 0 <TAB> <TAB> <TAB> <TAB> p . data = p . _fp16_shard <TAB> <TAB> else : <TAB> <TAB> <TAB> assert p . _full_param_padded . storage ( ) . size ( ) != 0 <TAB> <TAB> <TAB> p . data = p . _full_param_padded [ : p . _orig_size . numel ( ) ] . view ( p . _orig_size ) ,"if self . mixed_precision : 
","if p . _fp16_shard is not None :
",36.13,5.3,False
"def _attrdata ( self , cont , name , * val ) : <TAB> if not name : <TAB> <TAB> return None , False <TAB> if isinstance ( name , Mapping ) : <TAB> <TAB> if val : <TAB> <TAB> <TAB> raise TypeError ( "" Cannot set a value to  %s "" % name ) <TAB> <TAB> return name , True <TAB> else : <TAB> <TAB> if val : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return { name : val [ 0 ] } , True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Too may arguments "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cont = self . _extra . get ( cont ) <TAB> <TAB> <TAB> return cont . get ( name ) if cont else None , False ","if len ( val ) == 1 : 
","if len ( val ) == 1 :
",100.0,100.0,True
"def evaluate ( env , net , device = "" cpu "" ) : <TAB> obs = env . reset ( ) <TAB> reward = 0.0 <TAB> steps = 0 <TAB> while True : <TAB> <TAB> obs_v = ptan . agent . default_states_preprocessor ( [ obs ] ) . to ( device ) <TAB> <TAB> action_v = net ( obs_v ) <TAB> <TAB> action = action_v . data . cpu ( ) . numpy ( ) [ 0 ] <TAB> <TAB> obs , r , done , _ = env . step ( action ) <TAB> <TAB> reward + = r <TAB> <TAB> steps + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return reward , steps ","if done : 
","if done :
",78.12,0.0,False
"def convert_html_js_files ( app : Sphinx , config : Config ) - > None : <TAB> """"""This converts string styled html_js_files to tuple styled one."""""" <TAB> html_js_files = [ ]<TAB> # type: List[Tuple[str, Dict]] <TAB> for entry in config . html_js_files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> html_js_files . append ( ( entry , { } ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> filename , attrs = entry <TAB> <TAB> <TAB> <TAB> html_js_files . append ( ( filename , attrs ) ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> logger . warning ( __ ( "" invalid js_file:  %r , ignored "" ) , entry ) <TAB> <TAB> <TAB> <TAB> continue <TAB> config . html_js_files = html_js_files<TAB> # type: ignore ","if isinstance ( entry , str ) : 
","if isinstance ( entry , str ) :
",100.0,100.0,True
"def _check_duplications ( self , regs ) : <TAB> """"""n^2 loop which verifies that each reg exists only once."""""" <TAB> for reg in regs : <TAB> <TAB> count = 0 <TAB> <TAB> for r in regs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> if count > 1 : <TAB> <TAB> <TAB> genutil . die ( "" reg  %s  defined more than once "" % reg ) ","if reg == r : 
","if r == reg :
",54.02,21.36,False
"def PyJsHoisted_vault_ ( key , forget , this , arguments , var = var ) : <TAB> var = Scope ( <TAB> <TAB> { u "" this "" : this , u "" forget "" : forget , u "" key "" : key , u "" arguments "" : arguments } , var <TAB> ) <TAB> var . registers ( [ u "" forget "" , u "" key "" ] ) <TAB> if PyJsStrictEq ( var . get ( u "" key "" ) , var . get ( u "" passkey "" ) ) : <TAB> <TAB> return ( <TAB> <TAB> <TAB> var . put ( u "" secret "" , var . get ( u "" null "" ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else ( <TAB> <TAB> <TAB> <TAB> var . get ( u "" secret "" ) <TAB> <TAB> <TAB> <TAB> or var . put ( u "" secret "" , var . get ( u "" secretCreatorFn "" ) ( var . get ( u "" object "" ) ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if var . get ( u "" forget "" ) 
","if PyJsStrictEq ( var . get ( u "" secret "" ) , var . get ( u "" null "" ) )
",63.82,23.5,False
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( v [ i ] , dict ) : <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d ","if isinstance ( v , dict ) : 
","elif isinstance ( v , dict ) :
",77.52,84.09,False
"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB> <TAB> if data [ t ] == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data [ t ] <TAB> <TAB> for b in range ( 8 ) : <TAB> <TAB> <TAB> if value & 0x80 : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( "" (unknown) "" ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB> <TAB> <TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) ) ","if len ( TRANSCEIVER [ t ] ) < b + 1 : 
","if b not in TRANSCEIVER [ t ] :
",39.9,22.01,False
"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB> <TAB> if char != self . int_to_char [ self . blank_index ] : <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> elif char == self . labels [ self . space_index ] : <TAB> <TAB> <TAB> <TAB> string + = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string ","if remove_repetitions and i != 0 and char == sequence [ i - 1 ] : 
","if remove_repetitions and i == 0 :
",39.15,23.51,False
"def clean ( self ) : <TAB> username = self . cleaned_data . get ( "" username "" ) <TAB> password = self . cleaned_data . get ( "" password "" ) <TAB> if username and password : <TAB> <TAB> self . user_cache = authenticate ( username = username , password = password ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_login "" ] ) <TAB> <TAB> elif not self . user_cache . is_active : <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" inactive "" ] ) <TAB> self . check_for_test_cookie ( ) <TAB> return self . cleaned_data ","if self . user_cache is None : 
","if self . user_cache is None :
",100.0,100.0,True
"def is_listening_for_message ( conversation_id : Text , endpoint : EndpointConfig ) - > bool : <TAB> """"""Check if the conversation is in need for a user message."""""" <TAB> tracker = await retrieve_tracker ( endpoint , conversation_id , EventVerbosity . APPLIED ) <TAB> for i , e in enumerate ( reversed ( tracker . get ( "" events "" , [ ] ) ) ) : <TAB> <TAB> if e . get ( "" event "" ) == UserUttered . type_name : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return e . get ( "" name "" ) == ACTION_LISTEN_NAME <TAB> return False ","elif e . get ( "" event "" ) == ActionExecuted . type_name : 
","if e . get ( "" event "" ) == ActionExecuted . type_name :
",77.9,93.51,False
"def getReferences ( view , name = "" "" ) : <TAB> """"""Find all reference definitions."""""" <TAB> # returns {name -> Region} <TAB> refs = [ ] <TAB> name = re . escape ( name ) <TAB> if name == "" "" : <TAB> <TAB> refs . extend ( view . find_all ( r "" (?<=^ \ [)([^ \ ]]+)(?= \ ]:) "" , 0 ) ) <TAB> else : <TAB> <TAB> refs . extend ( view . find_all ( r "" (?<=^ \ [)( %s )(?= \ ]:) "" % name , 0 ) ) <TAB> regions = refs <TAB> ids = { } <TAB> for reg in regions : <TAB> <TAB> name = view . substr ( reg ) . strip ( ) <TAB> <TAB> key = name . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ids [ key ] . regions . append ( reg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ids [ key ] = Obj ( regions = [ reg ] , label = name ) <TAB> return ids ","if key in ids : 
","if key in ids :
",100.0,100.0,True
"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . revs_enabled : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB> <TAB> <TAB> return headers . get ( header_name ) ","if header_name in headers : 
","if url . endswith ( "" /download "" ) :
",27.28,4.46,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_shuffle_name ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def make_release_tree ( self , base_dir , files ) : <TAB> """"""Make the release tree."""""" <TAB> self . mkpath ( base_dir ) <TAB> create_tree ( base_dir , files , dry_run = self . dry_run ) <TAB> if not files : <TAB> <TAB> self . log . warning ( "" no files to distribute -- empty manifest? "" ) <TAB> else : <TAB> <TAB> self . log . info ( "" copying files to  %s ... "" , base_dir ) <TAB> for filename in files : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . warning ( "" ' %s '  not a regular file -- skipping "" , filename ) <TAB> <TAB> else : <TAB> <TAB> <TAB> dest = os . path . join ( base_dir , filename ) <TAB> <TAB> <TAB> self . copy_file ( filename , dest ) <TAB> self . distribution . metadata . write_pkg_info ( base_dir ) ","if not os . path . isfile ( filename ) : 
","if fnmatch . fnmatch ( filename , self . pattern ) :
",31.62,11.02,False
"def _parse_names_set ( feature_names ) : <TAB> """"""Helping function of `_parse_feature_names` that parses a set of feature names."""""" <TAB> feature_collection = OrderedDict ( ) <TAB> for feature_name in feature_names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> feature_collection [ feature_name ] = . . . <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Failed to parse  {} , expected string "" . format ( feature_name ) ) <TAB> return feature_collection ","if isinstance ( feature_name , str ) : 
","if isinstance ( feature_name , str ) :
",100.0,100.0,True
"def get_connection ( self , url , proxies = None ) : <TAB> with self . pools . lock : <TAB> <TAB> pool = self . pools . get ( url ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return pool <TAB> <TAB> pool = NpipeHTTPConnectionPool ( <TAB> <TAB> <TAB> self . npipe_path , self . timeout , maxsize = self . max_pool_size <TAB> <TAB> ) <TAB> <TAB> self . pools [ url ] = pool <TAB> return pool ","if pool : 
","if pool is not None :
",34.04,17.97,False
"def _parse_dimensions ( dimensions ) : <TAB> arrays = [ ] <TAB> names = [ ] <TAB> for key in dimensions : <TAB> <TAB> values = [ v [ "" name "" ] for v in key [ "" values "" ] ] <TAB> <TAB> role = key . get ( "" role "" , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values = [ _fix_quarter_values ( v ) for v in values ] <TAB> <TAB> <TAB> values = pd . DatetimeIndex ( values ) <TAB> <TAB> arrays . append ( values ) <TAB> <TAB> names . append ( key [ "" name "" ] ) <TAB> midx = pd . MultiIndex . from_product ( arrays , names = names ) <TAB> if len ( arrays ) == 1 and isinstance ( midx , pd . MultiIndex ) : <TAB> <TAB> # Fix for pandas >= 0.21 <TAB> <TAB> midx = midx . levels [ 0 ] <TAB> return midx ","if role in ( "" time "" , "" TIME_PERIOD "" ) : 
","if role == "" Quarter "" :
",35.33,5.79,False
"def _add_trials ( self , name , spec ) : <TAB> """"""Add trial by invoking TrialRunner."""""" <TAB> resource = { } <TAB> resource [ "" trials "" ] = [ ] <TAB> trial_generator = BasicVariantGenerator ( ) <TAB> trial_generator . add_configurations ( { name : spec } ) <TAB> while not trial_generator . is_finished ( ) : <TAB> <TAB> trial = trial_generator . next_trial ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> runner . add_trial ( trial ) <TAB> <TAB> resource [ "" trials "" ] . append ( self . _trial_info ( trial ) ) <TAB> return resource ","if not trial : 
","if trial is None :
",29.25,14.06,False
"def _retrieve_key ( self ) : <TAB> url = "" http://www.canadapost.ca/cpo/mc/personal/postalcode/fpc.jsf "" <TAB> text = "" "" <TAB> try : <TAB> <TAB> r = requests . get ( url , timeout = self . timeout , proxies = self . proxies ) <TAB> <TAB> text = r . text <TAB> except : <TAB> <TAB> self . error = "" ERROR - URL Connection "" <TAB> if text : <TAB> <TAB> expression = r "" ' (....-....-....-....) ' ; "" <TAB> <TAB> pattern = re . compile ( expression ) <TAB> <TAB> match = pattern . search ( text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . key = match . group ( 1 ) <TAB> <TAB> <TAB> return self . key <TAB> <TAB> else : <TAB> <TAB> <TAB> self . error = "" ERROR - No API Key "" ","if match : 
","if match :
",78.12,0.0,False
"def test_net ( net , env , count = 10 , device = "" cpu "" ) : <TAB> rewards = 0.0 <TAB> steps = 0 <TAB> for _ in range ( count ) : <TAB> <TAB> obs = env . reset ( ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> obs_v = ptan . agent . float32_preprocessor ( [ obs ] ) . to ( device ) <TAB> <TAB> <TAB> mu_v = net ( obs_v ) [ 0 ] <TAB> <TAB> <TAB> action = mu_v . squeeze ( dim = 0 ) . data . cpu ( ) . numpy ( ) <TAB> <TAB> <TAB> action = np . clip ( action , - 1 , 1 ) <TAB> <TAB> <TAB> obs , reward , done , _ = env . step ( action ) <TAB> <TAB> <TAB> rewards + = reward <TAB> <TAB> <TAB> steps + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> return rewards / count , steps / count ","if done : 
","if done :
",78.12,0.0,False
"def compile ( self , filename , obfuscate = False , raw = False , magic = "" \x00 "" * 8 ) : <TAB> body = marshal . dumps ( compile ( self . visit ( self . _source_ast ) , filename , "" exec "" ) ) <TAB> if obfuscate : <TAB> <TAB> body_len = len ( body ) <TAB> <TAB> offset = 0 if raw else 8 <TAB> <TAB> output = bytearray ( body_len + 8 ) <TAB> <TAB> for i , x in enumerate ( body ) : <TAB> <TAB> <TAB> output [ i + offset ] = ord ( x ) ^ ( ( 2 * * ( ( 65535 - i ) % 65535 ) ) % 251 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for i in xrange ( 8 ) : <TAB> <TAB> <TAB> <TAB> output [ i ] = 0 <TAB> <TAB> return output <TAB> elif raw : <TAB> <TAB> return body <TAB> else : <TAB> <TAB> return magic + body ","if raw : 
","if i + offset < body_len :
",29.58,5.67,False
"def _map_saslprep ( s ) : <TAB> """"""Map stringprep table B.1 to nothing and C.1.2 to ASCII space"""""" <TAB> r = [ ] <TAB> for c in s : <TAB> <TAB> if stringprep . in_table_c12 ( c ) : <TAB> <TAB> <TAB> r . append ( "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r . append ( c ) <TAB> return "" "" . join ( r ) ","elif not stringprep . in_table_b1 ( c ) : 
","if c . isalnum ( ) and c . isalnum ( ) and c in "" 0x0A "" :
",29.72,3.17,False
"def ensemble ( self , pairs , other_preds ) : <TAB> """"""Ensemble the dict with statistical model predictions."""""" <TAB> lemmas = [ ] <TAB> assert len ( pairs ) == len ( other_preds ) <TAB> for p , pred in zip ( pairs , other_preds ) : <TAB> <TAB> w , pos = p <TAB> <TAB> if ( w , pos ) in self . composite_dict : <TAB> <TAB> <TAB> lemma = self . composite_dict [ ( w , pos ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lemma = self . word_dict [ w ] <TAB> <TAB> else : <TAB> <TAB> <TAB> lemma = pred <TAB> <TAB> if lemma is None : <TAB> <TAB> <TAB> lemma = w <TAB> <TAB> lemmas . append ( lemma ) <TAB> return lemmas ","elif w in self . word_dict : 
","elif w in self . word_dict :
",100.0,100.0,True
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> if any ( item is None for item in value ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> return value ","if value . has_form ( "" List "" , None ) : 
","if isinstance ( value , Leaf ) :
",27.36,6.87,False
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> if not dest . parent . is_dir ( ) : <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> if src . exists ( ) : <TAB> <TAB> <TAB> shutil . copy ( src , dest ) ","if dest . exists ( ) : 
","if dest . exists ( ) :
",100.0,100.0,True
"def assert_readback ( vehicle , values ) : <TAB> i = 10 <TAB> while i > 0 : <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> i - = 0.1 <TAB> <TAB> for k , v in values . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> break <TAB> if i < = 0 : <TAB> <TAB> raise Exception ( "" Did not match in channels readback  %s "" % values ) ","if vehicle . channels [ k ] != v : 
","if k in vehicle . channels :
",36.41,16.42,False
"def _get_linode_client ( self ) : <TAB> api_key = self . credentials . conf ( "" key "" ) <TAB> api_version = self . credentials . conf ( "" version "" ) <TAB> if api_version == "" "" : <TAB> <TAB> api_version = None <TAB> if not api_version : <TAB> <TAB> api_version = 3 <TAB> <TAB> # Match for v4 api key <TAB> <TAB> regex_v4 = re . compile ( "" ^[0-9a-f] {64} $ "" ) <TAB> <TAB> regex_match = regex_v4 . match ( api_key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> api_version = 4 <TAB> else : <TAB> <TAB> api_version = int ( api_version ) <TAB> return _LinodeLexiconClient ( api_key , api_version ) ","if regex_match : 
","if regex_match :
",78.12,100.0,True
"def mergeHiLo ( self , x_stats ) : <TAB> """"""Merge the highs and lows of another accumulator into myself."""""" <TAB> if x_stats . firsttime is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . firsttime = x_stats . firsttime <TAB> <TAB> <TAB> self . first = x_stats . first <TAB> if x_stats . lasttime is not None : <TAB> <TAB> if self . lasttime is None or x_stats . lasttime > = self . lasttime : <TAB> <TAB> <TAB> self . lasttime = x_stats . lasttime <TAB> <TAB> <TAB> self . last = x_stats . last ","if self . firsttime is None or x_stats . firsttime < self . firsttime : 
","if self . firsttime is None or x_stats . firsttime < = self . first :
",69.49,74.71,False
"def _check_good_input ( self , X , y = None ) : <TAB> if isinstance ( X , dict ) : <TAB> <TAB> lengths = [ len ( X1 ) for X1 in X . values ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Not all values of X are of equal length. "" ) <TAB> <TAB> x_len = lengths [ 0 ] <TAB> else : <TAB> <TAB> x_len = len ( X ) <TAB> if y is not None : <TAB> <TAB> if len ( y ) != x_len : <TAB> <TAB> <TAB> raise ValueError ( "" X and y are not of equal length. "" ) <TAB> if self . regression and y is not None and y . ndim == 1 : <TAB> <TAB> y = y . reshape ( - 1 , 1 ) <TAB> return X , y ","if len ( set ( lengths ) ) > 1 : 
","if len ( lengths ) != 1 :
",40.97,26.26,False
"def set ( self , obj , * * kwargs ) : <TAB> """"""Check for missing event functions and substitute these with"""""" <TAB> """"""the ignore method"""""" <TAB> ignore = getattr ( self , "" ignore "" ) <TAB> for k , v in kwargs . iteritems ( ) : <TAB> <TAB> setattr ( self , k , getattr ( obj , v ) ) <TAB> <TAB> if k in self . combinations : <TAB> <TAB> <TAB> for k1 in self . combinations [ k ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> setattr ( self , k1 , ignore ) ","if not hasattr ( self , k1 ) : 
","if getattr ( self , k1 ) not in ignore :
",57.59,39.46,False
"def _parse_list ( self , tokens ) : <TAB> # Process left to right, allow descending in sub lists <TAB> assert tokens [ 0 ] in ( "" [ "" , "" ( "" ) <TAB> delim = "" ] "" if tokens . pop ( 0 ) == "" [ "" else "" ) "" <TAB> expr = ExpressionList ( ) <TAB> while tokens and tokens [ 0 ] != delim : <TAB> <TAB> item = self . _parse ( tokens ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if tokens . pop ( 0 ) != "" , "" : <TAB> <TAB> <TAB> <TAB> raise ExpressionSyntaxError ( ' Expected:  "" , "" ' ) <TAB> <TAB> expr . append ( item ) <TAB> if not tokens or tokens [ 0 ] != delim : <TAB> <TAB> raise ExpressionSyntaxError ( ' Missing:  "" %s "" ' % delim ) <TAB> else : <TAB> <TAB> tokens . pop ( 0 ) <TAB> return expr ","if tokens and tokens [ 0 ] != delim : 
","if item is not None :
",26.34,4.19,False
"def param_value ( self ) : <TAB> # This is part of the ""handle quoted extended parameters"" hack. <TAB> for token in self : <TAB> <TAB> if token . token_type == "" value "" : <TAB> <TAB> <TAB> return token . stripped_value <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for token in token : <TAB> <TAB> <TAB> <TAB> if token . token_type == "" bare-quoted-string "" : <TAB> <TAB> <TAB> <TAB> <TAB> for token in token : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if token . token_type == "" value "" : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return token . stripped_value <TAB> return "" "" ","if token . token_type == "" quoted-string "" : 
","if token . token_type == "" string "" :
",83.19,76.92,False
"def paragraph_is_fully_commented ( lines , comment , main_language ) : <TAB> """"""Is the paragraph fully commented?"""""" <TAB> for i , line in enumerate ( lines ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if line [ len ( comment ) : ] . lstrip ( ) . startswith ( comment ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if is_magic ( line , main_language ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> continue <TAB> <TAB> return i > 0 and _BLANK_LINE . match ( line ) <TAB> return True ","if line . startswith ( comment ) : 
","if comment :
",26.73,0.0,False
"def lots_connected_to_existing_roads ( model ) : <TAB> set = [ ] <TAB> for h in model . HarvestCells : <TAB> <TAB> for ( i , j ) in model . ExistingRoads : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if h not in set : <TAB> <TAB> <TAB> <TAB> <TAB> set . append ( h ) <TAB> return set ","if ( i in model . COriginNodeForCell [ h ] ) or ( j in model . COriginNodeForCell [ h ] ) : 
","if i == j :
",25.36,0.68,False
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" \ Abarra_counter_session= "" , <TAB> <TAB> <TAB> <TAB> headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , <TAB> <TAB> <TAB> <TAB> re . I , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = ( <TAB> <TAB> <TAB> re . search ( <TAB> <TAB> <TAB> <TAB> r "" ( \ A| \ b)barracuda_ "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return retval ","if retval : 
","if retval :
",78.12,0.0,False
"def test_files ( self ) : <TAB> # get names of files to test <TAB> dist_dir = os . path . join ( os . path . dirname ( __file__ ) , os . pardir , os . pardir ) <TAB> names = [ ] <TAB> for d in self . test_directories : <TAB> <TAB> test_dir = os . path . join ( dist_dir , d ) <TAB> <TAB> for n in os . listdir ( test_dir ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> names . append ( os . path . join ( test_dir , n ) ) <TAB> for filename in names : <TAB> <TAB> if test_support . verbose : <TAB> <TAB> <TAB> print ( "" Testing  %s "" % filename ) <TAB> <TAB> source = read_pyfile ( filename ) <TAB> <TAB> self . check_roundtrip ( source ) ","if n . endswith ( "" .py "" ) and not n . startswith ( "" bad "" ) : 
","if n . endswith ( "" .py "" ) :
",61.13,38.97,False
"def test_calibrate_target ( create_target ) : <TAB> mod , params = testing . synthetic . get_workload ( ) <TAB> dataset = get_calibration_dataset ( mod , "" data "" ) <TAB> with relay . quantize . qconfig ( calibrate_mode = "" kl_divergence "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with tvm . target . Target ( "" llvm "" ) : <TAB> <TAB> <TAB> <TAB> relay . quantize . quantize ( mod , params , dataset ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # current_target = None <TAB> <TAB> <TAB> relay . quantize . quantize ( mod , params , dataset ) ","if create_target : 
","if create_target :
",78.12,100.0,True
"def _cleanSubmodule ( self , _ = None ) : <TAB> rc = RC_SUCCESS <TAB> if self . submodules : <TAB> <TAB> command = [ <TAB> <TAB> <TAB> "" submodule "" , <TAB> <TAB> <TAB> "" foreach "" , <TAB> <TAB> <TAB> "" --recursive "" , <TAB> <TAB> <TAB> "" git "" , <TAB> <TAB> <TAB> "" clean "" , <TAB> <TAB> <TAB> "" -f "" , <TAB> <TAB> <TAB> "" -f "" , <TAB> <TAB> <TAB> "" -d "" , <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> command . append ( "" -x "" ) <TAB> <TAB> rc = yield self . _dovccmd ( command ) <TAB> defer . returnValue ( rc ) ","if self . mode == "" full "" and self . method == "" fresh "" : 
","if self . verbose :
",32.86,2.6,False
"def screen_length_to_bytes_count ( string , screen_length_limit , encoding ) : <TAB> bytes_count = 0 <TAB> screen_length = 0 <TAB> for unicode_char in string : <TAB> <TAB> screen_length + = screen_len ( unicode_char ) <TAB> <TAB> char_bytes_count = len ( unicode_char . encode ( encoding ) ) <TAB> <TAB> bytes_count + = char_bytes_count <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bytes_count - = char_bytes_count <TAB> <TAB> <TAB> break <TAB> return bytes_count ","if screen_length > screen_length_limit : 
","if screen_length > screen_length_limit :
",100.0,100.0,True
"def tamper ( payload , * * kwargs ) : <TAB> junk_chars = "" !#$ % &()*~+-_.,:;?@[/| \ ]^` "" <TAB> retval = "" "" <TAB> for i , char in enumerate ( payload , start = 1 ) : <TAB> <TAB> amount = random . randint ( 10 , 15 ) <TAB> <TAB> if char == "" > "" : <TAB> <TAB> <TAB> retval + = "" > "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> retval + = "" < "" <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> elif char == "" "" : <TAB> <TAB> <TAB> for _ in range ( amount ) : <TAB> <TAB> <TAB> <TAB> retval + = random . choice ( junk_chars ) <TAB> <TAB> else : <TAB> <TAB> <TAB> retval + = char <TAB> return retval ","elif char == "" < "" : 
","elif char == "" < "" :
",100.0,100.0,True
"def test_parse ( self ) : <TAB> correct = 0 <TAB> for example in EXAMPLES : <TAB> <TAB> try : <TAB> <TAB> <TAB> schema . parse ( example . schema_string ) <TAB> <TAB> <TAB> if example . valid : <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Invalid schema was parsed:  "" + example . schema_string ) <TAB> <TAB> except : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> correct + = 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . fail ( "" Valid schema failed to parse:  "" + example . schema_string ) <TAB> fail_msg = "" Parse behavior correct on  %d  out of  %d  schemas. "" % ( <TAB> <TAB> correct , <TAB> <TAB> len ( EXAMPLES ) , <TAB> ) <TAB> self . assertEqual ( correct , len ( EXAMPLES ) , fail_msg ) ","if not example . valid : 
","if example . valid :
",58.31,57.89,False
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed ","if isinstance ( value , bool ) : 
","if isinstance ( value , str ) :
",79.9,59.46,False
"def normalize ( d : Dict [ Any , Any ] ) - > Dict [ str , Any ] : <TAB> first_exception = None <TAB> for normalizer in normalizers : <TAB> <TAB> try : <TAB> <TAB> <TAB> normalized = normalizer ( d ) <TAB> <TAB> except KeyError as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> first_exception = e <TAB> <TAB> else : <TAB> <TAB> <TAB> return normalized <TAB> assert first_exception is not None <TAB> raise first_exception ","if not first_exception : 
","if first_exception is None :
",29.25,27.78,False
"def gather_callback_args ( self , obj , callbacks ) : <TAB> session = sa . orm . object_session ( obj ) <TAB> for callback in callbacks : <TAB> <TAB> backref = callback . backref <TAB> <TAB> root_objs = getdotattr ( obj , backref ) if backref else obj <TAB> <TAB> if root_objs : <TAB> <TAB> <TAB> if not isinstance ( root_objs , Iterable ) : <TAB> <TAB> <TAB> <TAB> root_objs = [ root_objs ] <TAB> <TAB> <TAB> with session . no_autoflush : <TAB> <TAB> <TAB> <TAB> for root_obj in root_objs : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> args = self . get_callback_args ( root_obj , callback ) <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if args : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> yield args ","if root_obj : 
","if hasattr ( root_obj , "" backref "" ) :
",29.43,14.32,False
"def test_opdm_to_oqdm ( self ) : <TAB> for file in filter ( lambda x : x . endswith ( "" .hdf5 "" ) , os . listdir ( DATA_DIRECTORY ) ) : <TAB> <TAB> molecule = MolecularData ( filename = os . path . join ( DATA_DIRECTORY , file ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> test_oqdm = map_one_pdm_to_one_hole_dm ( molecule . fci_one_rdm ) <TAB> <TAB> <TAB> true_oqdm = numpy . eye ( molecule . n_qubits ) - molecule . fci_one_rdm <TAB> <TAB> <TAB> assert numpy . allclose ( test_oqdm , true_oqdm ) ","if molecule . fci_one_rdm is not None : 
","if molecule . fci_one_rdm is not None :
",100.0,100.0,True
"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB> <TAB> if self . checkForStop ( ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . emitHostname ( subDomain , event ) ","if subDomain : 
","if subDomain and subDomain != self . _getDomain ( ) :
",32.75,6.84,False
"def download_cve ( <TAB> download_path : str , years : Optional [ List [ int ] ] = None , update : bool = False ) : <TAB> if update : <TAB> <TAB> process_url ( CVE_URL . format ( "" modified "" ) , download_path ) <TAB> else : <TAB> <TAB> all_cve_urls = get_cve_links ( CVE_URL , years ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CveLookupException ( "" Error: No CVE links found "" ) <TAB> <TAB> for url in all_cve_urls : <TAB> <TAB> <TAB> process_url ( url , download_path ) ","if not all_cve_urls : 
","if not all_cve_urls :
",100.0,100.0,True
"def is_special ( s , i , directive ) : <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive [ 0 ] == "" @ "" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB> while i < len ( s ) : <TAB> <TAB> if match_word ( s , i , directive ) : <TAB> <TAB> <TAB> return True , i <TAB> <TAB> else : <TAB> <TAB> <TAB> i = skip_line ( s , i ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> i = skip_ws ( s , i ) <TAB> return False , - 1 ","if skip_flag : 
","if skip_flag :
",78.12,100.0,True
"def run_async ( self , nuke_cursors ) : <TAB> # type: (bool) -> None <TAB> interface_type = self . view . settings ( ) . get ( "" git_savvy.interface "" ) <TAB> for cls in subclasses : <TAB> <TAB> if cls . interface_type == interface_type : <TAB> <TAB> <TAB> vid = self . view . id ( ) <TAB> <TAB> <TAB> interface = interfaces . get ( vid , None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> interface = interfaces [ vid ] = cls ( view = self . view ) <TAB> <TAB> <TAB> interface . render ( nuke_cursors = nuke_cursors )<TAB> # type: ignore[union-attr] <TAB> <TAB> <TAB> break ","if not interface : 
","if not interface :
",100.0,100.0,True
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if str ( conf [ "" properties "" ] [ "" sslEnforcement "" ] ) . lower ( ) == "" enabled "" : <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED ","if "" sslEnforcement "" in conf [ "" properties "" ] : 
","if "" sslEnforcement "" in conf [ "" properties "" ] :
",100.0,100.0,True
"def do_shorts ( <TAB> opts : List [ Tuple [ str , str ] ] , optstring : str , shortopts : str , args : List [ str ] ) - > Tuple [ List [ Tuple [ str , str ] ] , List [ str ] ] : <TAB> while optstring != "" "" : <TAB> <TAB> opt , optstring = optstring [ 0 ] , optstring [ 1 : ] <TAB> <TAB> if short_has_arg ( opt , shortopts ) : <TAB> <TAB> <TAB> if optstring == "" "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> raise GetoptError ( "" option - %s  requires argument "" % opt , opt ) <TAB> <TAB> <TAB> <TAB> optstring , args = args [ 0 ] , args [ 1 : ] <TAB> <TAB> <TAB> optarg , optstring = optstring , "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> optarg = "" "" <TAB> <TAB> opts . append ( ( "" - "" + opt , optarg ) ) <TAB> return opts , args ","if not args : 
","if not args :
",100.0,100.0,True
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> if self . count == 0 : <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> if self . waiters : <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( ) ","if self . owner != tid : 
","if tid is self . owner :
",41.04,25.2,False
"def _summarize_kraken ( fn ) : <TAB> """"""get the value at species level"""""" <TAB> kraken = { } <TAB> list_sp , list_value = [ ] , [ ] <TAB> with open ( fn ) as handle : <TAB> <TAB> for line in handle : <TAB> <TAB> <TAB> cols = line . strip ( ) . split ( "" \t "" ) <TAB> <TAB> <TAB> sp = cols [ 5 ] . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> list_sp . append ( sp ) <TAB> <TAB> <TAB> <TAB> list_value . append ( cols [ 0 ] ) <TAB> kraken = { "" kraken_sp "" : list_sp , "" kraken_value "" : list_value } <TAB> return kraken ","if len ( sp . split ( "" "" ) ) > 1 and not sp . startswith ( "" cellular "" ) : 
","if sp :
",25.29,0.0,False
"def _sync_remote_run ( remote_run ) : <TAB> assert remote_run . remote <TAB> remote_name = remote_run . remote . name <TAB> pull_args = click_util . Args ( remote = remote_name , delete = False ) <TAB> try : <TAB> <TAB> remote_impl_support . pull_runs ( [ remote_run ] , pull_args ) <TAB> except Exception as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . exception ( "" pull  %s  from  %s "" , remote_run . id , remote_name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . error ( "" error pulling  %s  from  %s :  %s "" , remote_run . id , remote_name , e ) ","if log . getEffectiveLevel ( ) < = logging . DEBUG : 
","if log . getEffectiveLevel ( ) < = logging . DEBUG :
",100.0,100.0,True
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if ki != 0 : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if sign * ki < - slop : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq ","if sign is None : 
","if sign is None :
",100.0,100.0,True
"def import_til ( self ) : <TAB> log ( "" Importing type libraries... "" ) <TAB> cur = self . db_cursor ( ) <TAB> sql = "" select name from diff.program_data where type =  ' til ' "" <TAB> cur . execute ( sql ) <TAB> for row in cur . fetchall ( ) : <TAB> <TAB> til = row [ "" name "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> til = til . decode ( "" utf-8 "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> add_default_til ( til ) <TAB> <TAB> except : <TAB> <TAB> <TAB> log ( "" Error loading til  %s :  %s "" % ( row [ "" name "" ] , str ( sys . exc_info ( ) [ 1 ] ) ) ) <TAB> cur . close ( ) <TAB> auto_wait ( ) ","if type ( til ) is bytes : 
","if isinstance ( til , bytes ) :
",28.68,14.54,False
"def getBranches ( self ) : <TAB> returned = [ ] <TAB> for git_branch_line in self . _executeGitCommandAssertSuccess ( "" branch "" ) . stdout : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> git_branch_line = git_branch_line [ 1 : ] <TAB> <TAB> git_branch_line = git_branch_line . strip ( ) <TAB> <TAB> if BRANCH_ALIAS_MARKER in git_branch_line : <TAB> <TAB> <TAB> alias_name , aliased = git_branch_line . split ( BRANCH_ALIAS_MARKER ) <TAB> <TAB> <TAB> returned . append ( branch . LocalBranchAlias ( self , alias_name , aliased ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> returned . append ( branch . LocalBranch ( self , git_branch_line ) ) <TAB> return returned ","if git_branch_line . startswith ( "" * "" ) : 
","if git_branch_line . startswith ( "" # "" ) :
",83.03,78.25,False
"def add_include_dirs ( self , args ) : <TAB> ids = [ ] <TAB> for a in args : <TAB> <TAB> # FIXME same hack, forcibly unpack from holder. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> a = a . includedirs <TAB> <TAB> if not isinstance ( a , IncludeDirs ) : <TAB> <TAB> <TAB> raise InvalidArguments ( <TAB> <TAB> <TAB> <TAB> "" Include directory to be added is not an include directory object. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> ids . append ( a ) <TAB> self . include_dirs + = ids ","if hasattr ( a , "" includedirs "" ) : 
","if isinstance ( a , IncludeDirs ) :
",32.11,21.07,False
"def _serialize_feature ( self , feature ) : <TAB> name = feature . unique_name ( ) <TAB> <MASK> <TAB> <TAB> self . _features_dict [ feature . unique_name ( ) ] = feature . to_dictionary ( ) <TAB> <TAB> for dependency in feature . get_dependencies ( deep = True ) : <TAB> <TAB> <TAB> name = dependency . unique_name ( ) <TAB> <TAB> <TAB> if name not in self . _features_dict : <TAB> <TAB> <TAB> <TAB> self . _features_dict [ name ] = dependency . to_dictionary ( ) ","if name not in self . _features_dict : 
","if name not in self . _features_dict :
",100.0,100.0,True
"def generate_io ( chart_type , race_configs , environment ) : <TAB> # output JSON structures <TAB> structures = [ ] <TAB> for race_config in race_configs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> title = chart_type . format_title ( <TAB> <TAB> <TAB> <TAB> environment , <TAB> <TAB> <TAB> <TAB> race_config . track , <TAB> <TAB> <TAB> <TAB> es_license = race_config . es_license , <TAB> <TAB> <TAB> <TAB> suffix = "" %s -io "" % race_config . label , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> structures . append ( chart_type . io ( title , environment , race_config ) ) <TAB> return structures ","if "" io "" in race_config . charts : 
","if "" io "" in race_config . charts :
",100.0,100.0,True
"def format_partition ( partition , partition_schema ) : <TAB> tokens = [ ] <TAB> if isinstance ( partition , dict ) : <TAB> <TAB> for name in partition_schema : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tok = _format_partition_kv ( <TAB> <TAB> <TAB> <TAB> <TAB> name , partition [ name ] , partition_schema [ name ] <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # dynamic partitioning <TAB> <TAB> <TAB> <TAB> tok = name <TAB> <TAB> <TAB> tokens . append ( tok ) <TAB> else : <TAB> <TAB> for name , value in zip ( partition_schema , partition ) : <TAB> <TAB> <TAB> tok = _format_partition_kv ( name , value , partition_schema [ name ] ) <TAB> <TAB> <TAB> tokens . append ( tok ) <TAB> return "" PARTITION ( {} ) "" . format ( "" ,  "" . join ( tokens ) ) ","if name in partition : 
","if name in partition :
",100.0,100.0,True
"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self<TAB> # don't copy unless we need to <TAB> if condition is not Undefined : <TAB> <TAB> if isinstance ( condition , core . SchemaBase ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB> <TAB> <TAB> copy = self . copy ( deep = [ "" condition "" ] ) <TAB> <TAB> <TAB> copy . condition . update ( kwds ) <TAB> return super ( ValueChannelMixin , copy ) . to_dict ( <TAB> <TAB> validate = validate , ignore = ignore , context = context <TAB> ) ","elif "" field "" in condition and "" type "" not in condition : 
","elif isinstance ( condition , dict ) :
",25.88,3.43,False
"def _checkForCommand ( self ) : <TAB> prompt = b "" cftp>  "" <TAB> if self . _expectingCommand and self . _lineBuffer == prompt : <TAB> <TAB> buf = b "" \n "" . join ( self . _linesReceived ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> buf = buf [ len ( prompt ) : ] <TAB> <TAB> self . clearBuffer ( ) <TAB> <TAB> d , self . _expectingCommand = self . _expectingCommand , None <TAB> <TAB> d . callback ( buf ) ","if buf . startswith ( prompt ) : 
","if buf . startswith ( prompt ) :
",100.0,100.0,True
"def schedule_logger ( job_id = None , delete = False ) : <TAB> if not job_id : <TAB> <TAB> return getLogger ( "" fate_flow_schedule "" ) <TAB> else : <TAB> <TAB> if delete : <TAB> <TAB> <TAB> with LoggerFactory . lock : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> for key in LoggerFactory . schedule_logger_dict . keys ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> if job_id in key : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> del LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> return True <TAB> <TAB> key = job_id + "" schedule "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return LoggerFactory . schedule_logger_dict [ key ] <TAB> <TAB> return LoggerFactory . get_schedule_logger ( job_id ) ","if key in LoggerFactory . schedule_logger_dict : 
","if key in LoggerFactory . schedule_logger_dict :
",100.0,100.0,True
"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB> <TAB> <TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB> <TAB> <TAB> <TAB> if "" %s %s "" % ( wrong , nr ) in nzb_name . lower ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - 30 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0 ","if wrong_found == 1 : 
","if wrong_found == 0 :
",64.48,70.71,False
"def parse_converter_args ( argstr : str ) - > t . Tuple [ t . Tuple , t . Dict [ str , t . Any ] ] : <TAB> argstr + = "" , "" <TAB> args = [ ] <TAB> kwargs = { } <TAB> for item in _converter_args_re . finditer ( argstr ) : <TAB> <TAB> value = item . group ( "" stringval "" ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> value = item . group ( "" value "" ) <TAB> <TAB> value = _pythonize ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . append ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> name = item . group ( "" name "" ) <TAB> <TAB> <TAB> kwargs [ name ] = value <TAB> return tuple ( args ) , kwargs ","if not item . group ( "" name "" ) : 
","if item . group ( "" args "" ) :
",63.08,48.96,False
"def leaves ( self , unique = True ) : <TAB> """"""Get the leaves of the tree starting at this root."""""" <TAB> if not self . children : <TAB> <TAB> return [ self ] <TAB> else : <TAB> <TAB> res = list ( ) <TAB> <TAB> for child in self . children : <TAB> <TAB> <TAB> for sub_child in child . leaves ( unique = unique ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( sub_child ) <TAB> <TAB> return res ","if not unique or sub_child not in res : 
","if sub_child not in res :
",56.86,59.76,False
"def to_tree ( self , tagname = None , idx = None , namespace = None ) : <TAB> axIds = set ( ( ax . axId for ax in self . _axes ) ) <TAB> for chart in self . _charts : <TAB> <TAB> for id , axis in chart . _axes . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> setattr ( self , axis . tagname , axis ) <TAB> <TAB> <TAB> <TAB> axIds . add ( id ) <TAB> return super ( PlotArea , self ) . to_tree ( tagname ) ","if id not in axIds : 
","if id not in axIds :
",100.0,100.0,True
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> if k == neighbors . MULTI_EXIT_DISC : <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . ENABLED : <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets ) ","if k == neighbors . CONNECT_MODE : 
","if k == neighbors . CONNECT_MODE :
",100.0,100.0,True
"def close_all_connections ( ) : <TAB> global _managers , _lock , _in_use , _timer <TAB> _lock . acquire ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _timer . cancel ( ) <TAB> <TAB> <TAB> _timer = None <TAB> <TAB> for domain , managers in _managers . items ( ) : <TAB> <TAB> <TAB> for manager in managers : <TAB> <TAB> <TAB> <TAB> manager . close ( ) <TAB> <TAB> _managers = { } <TAB> finally : <TAB> <TAB> _lock . release ( ) ","if _timer : 
","if _timer is not None :
",34.04,26.27,False
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) :<TAB> # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance ( value , tf . keras . layers . Layer ) : <TAB> <TAB> <TAB> new_layer = self . _instrument ( value ) <TAB> <TAB> <TAB> if new_layer is not value : <TAB> <TAB> <TAB> <TAB> setattr ( model , key , new_layer ) <TAB> <TAB> elif isinstance ( value , list ) : <TAB> <TAB> <TAB> for i , item in enumerate ( value ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> value [ i ] = self . _instrument ( item ) <TAB> return model ","if isinstance ( item , tf . keras . layers . Layer ) : 
","if isinstance ( item , tf . keras . layers . Layer ) :
",100.0,100.0,True
"def target_glob ( tgt , hosts ) : <TAB> ret = { } <TAB> for host in hosts : <TAB> <TAB> if fnmatch . fnmatch ( tgt , host ) : <TAB> <TAB> <TAB> ret [ host ] = copy . deepcopy ( __opts__ . get ( "" roster_defaults "" , { } ) ) <TAB> <TAB> <TAB> ret [ host ] . update ( { "" host "" : host } ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret [ host ] . update ( { "" user "" : __opts__ [ "" ssh_user "" ] } ) <TAB> return ret ","if __opts__ . get ( "" ssh_user "" ) : 
","elif __opts__ . get ( "" ssh_user "" ) :
",83.9,93.06,False
"def write ( self , data ) : <TAB> if mock_target . _mirror_on_stderr : <TAB> <TAB> if self . _write_line : <TAB> <TAB> <TAB> sys . stderr . write ( fn + "" :  "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sys . stderr . write ( data . decode ( "" utf8 "" ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sys . stderr . write ( data ) <TAB> <TAB> if ( data [ - 1 ] ) == "" \n "" : <TAB> <TAB> <TAB> self . _write_line = True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _write_line = False <TAB> super ( Buffer , self ) . write ( data ) ","if bytes : 
","if isinstance ( data , bytes ) :
",29.65,7.27,False
"def task_thread ( ) : <TAB> while not task_queue . empty ( ) : <TAB> <TAB> host , port , username , password = task_queue . get ( ) <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" try burst  {} : {}  use username: {}  password: {} "" . format ( <TAB> <TAB> <TAB> <TAB> host , port , username , password <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with task_queue . mutex : <TAB> <TAB> <TAB> <TAB> task_queue . queue . clear ( ) <TAB> <TAB> <TAB> result_queue . put ( ( username , password ) ) ","if telnet_login ( host , port , username , password ) : 
","if host or port :
",26.13,2.5,False
"def _format_results ( name , ppl , scores , metrics ) : <TAB> """"""Format results."""""" <TAB> result_str = "" "" <TAB> if ppl : <TAB> <TAB> result_str = "" %s  ppl  %.2f "" % ( name , ppl ) <TAB> if scores : <TAB> <TAB> for metric in metrics : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result_str + = "" ,  %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result_str = "" %s %s %.1f "" % ( name , metric , scores [ metric ] ) <TAB> return result_str ","if result_str : 
","if metric in result_str :
",34.79,43.47,False
"def info_query ( self , query ) : <TAB> """"""Send a query which only returns 1 row"""""" <TAB> self . _cmysql . query ( query ) <TAB> first_row = ( ) <TAB> if self . _cmysql . have_result_set : <TAB> <TAB> first_row = self . _cmysql . fetch_row ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _cmysql . free_result ( ) <TAB> <TAB> <TAB> raise errors . InterfaceError ( "" Query should not return more than 1 row "" ) <TAB> self . _cmysql . free_result ( ) <TAB> return first_row ","if self . _cmysql . fetch_row ( ) : 
","if first_row > 1 :
",26.57,7.65,False
"def reset_class ( self ) : <TAB> for f in self . fields_order : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f . value = int ( f . strbits , 2 ) <TAB> <TAB> elif "" default_val "" in f . kargs : <TAB> <TAB> <TAB> f . value = int ( f . kargs [ "" default_val "" ] , 2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . value = None <TAB> <TAB> if f . fname : <TAB> <TAB> <TAB> setattr ( self , f . fname , f ) ","if f . strbits and isbin ( f . strbits ) : 
","if f . strbits :
",42.22,17.44,False
"def _walk_map_list ( self , access_func ) : <TAB> seen = [ ] <TAB> cur = self <TAB> while cur : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> yield cur <TAB> <TAB> seen . append ( cur . obj_offset ) <TAB> <TAB> # check for signs of infinite looping <TAB> <TAB> if len ( seen ) > 1024 : <TAB> <TAB> <TAB> break <TAB> <TAB> cur = access_func ( cur ) ","if cur . obj_offset in seen : 
","if cur . obj_offset in seen :
",100.0,100.0,True
def bgdel ( ) : <TAB> q = bgdelq <TAB> while True : <TAB> <TAB> name = q . get ( ) <TAB> <TAB> while os . path . exists ( name ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> os . remove ( name ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> shutil . rmtree ( name ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if os . path . exists ( name ) : <TAB> <TAB> <TAB> <TAB> time . sleep ( 0.1 ) ,"if os . path . isfile ( name ) : 
","if os . path . isfile ( name ) :
",100.0,100.0,True
"def _find_all_variables ( transfer_variable ) : <TAB> d = { } <TAB> for _k , _v in transfer_variable . __dict__ . items ( ) : <TAB> <TAB> if isinstance ( _v , Variable ) : <TAB> <TAB> <TAB> d [ _v . _name ] = _v <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d . update ( _find_all_variables ( _v ) ) <TAB> return d ","elif isinstance ( _v , BaseTransferVariables ) : 
","elif isinstance ( _v , ( list , tuple ) ) :
",49.15,42.8,False
"def set_val ( ) : <TAB> idx = 0 <TAB> for idx in range ( 0 , len ( model ) ) : <TAB> <TAB> row = model [ idx ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> if idx == len ( os_widget . get_model ( ) ) - 1 : <TAB> <TAB> <TAB> idx = - 1 <TAB> os_widget . set_active ( idx ) <TAB> if idx == - 1 : <TAB> <TAB> os_widget . set_active ( 0 ) <TAB> if idx > = 0 : <TAB> <TAB> return row [ 1 ] <TAB> if self . show_all_os : <TAB> <TAB> return None ","if value and row [ 0 ] == value : 
","if row [ 0 ] == self . active_row :
",51.01,40.9,False
"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB> <TAB> if methods == ALL : <TAB> <TAB> <TAB> methods = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB> <TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) ","elif isinstance ( methods , ( list , tuple ) ) : 
","elif methods :
",25.83,0.0,False
"def findfiles ( path ) : <TAB> files = [ ] <TAB> for name in os . listdir ( path ) : <TAB> <TAB> # ignore hidden files/dirs and other unwanted files <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> pathname = os . path . join ( path , name ) <TAB> <TAB> st = os . lstat ( pathname ) <TAB> <TAB> mode = st . st_mode <TAB> <TAB> if stat . S_ISDIR ( mode ) : <TAB> <TAB> <TAB> files . extend ( findfiles ( pathname ) ) <TAB> <TAB> elif stat . S_ISREG ( mode ) : <TAB> <TAB> <TAB> files . append ( ( pathname , name , st ) ) <TAB> return files ","if name . startswith ( "" . "" ) or name == "" lastsnap.jpg "" : 
","if name . startswith ( "" . "" ) or name . startswith ( "" . "" ) :
",70.76,58.37,False
"def __getitem__ ( self , key ) : <TAB> if isinstance ( key , str_types ) : <TAB> <TAB> keys = self . get_keys ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise KeyError ( ' "" {0} ""  is an invalid key ' . format ( key ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self [ keys . index ( key ) ] <TAB> else : <TAB> <TAB> return list . __getitem__ ( self , key ) ","if key not in keys : 
","if key not in keys :
",100.0,100.0,True
"def test_assert_set_equal ( estimate : tp . Iterable [ int ] , message : str ) - > None : <TAB> reference = { 1 , 2 , 3 } <TAB> try : <TAB> <TAB> testing . assert_set_equal ( estimate , reference ) <TAB> except AssertionError as error : <TAB> <TAB> if not message : <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" An error has been raised while it should not. "" <TAB> <TAB> <TAB> ) from error <TAB> <TAB> np . testing . assert_equal ( error . args [ 0 ] . split ( "" \n "" ) [ 1 : ] , message ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AssertionError ( "" An error should have been raised. "" ) ","if message : 
","if len ( estimate ) != 4 :
",29.42,5.67,False
"def get_directory_info ( prefix , pth , recursive ) : <TAB> res = [ ] <TAB> directory = os . listdir ( pth ) <TAB> directory . sort ( ) <TAB> for p in directory : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subp = os . path . join ( pth , p ) <TAB> <TAB> <TAB> p = os . path . join ( prefix , p ) <TAB> <TAB> <TAB> if recursive and os . path . isdir ( subp ) : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , get_directory_info ( prefix , subp , 1 ) ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> res . append ( [ p , None ] ) <TAB> return res ","if p [ 0 ] != "" . "" : 
","if not os . path . islink ( p ) :
",26.48,5.3,False
"def check ( self , runner , script , info ) : <TAB> if isinstance ( info , ast . FunctionDef ) : <TAB> <TAB> for arg in info . args . args : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if arg . id in script . modelVars : <TAB> <TAB> <TAB> <TAB> <TAB> self . problem ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Function  {0}  may shadow model variable  {1} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> info . name , arg . id <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> lineno = info . lineno , <TAB> <TAB> <TAB> <TAB> <TAB> ) ","if isinstance ( arg , ast . Name ) : 
","if isinstance ( arg , ast . Name ) :
",100.0,100.0,True
"def db_lookup ( field , key , publish_year = None ) : <TAB> sql = "" select sum(ebook_count) as num from subjects where field=$field and key=$key "" <TAB> if publish_year : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sql + = ""  and publish_year between $y1 and $y2 "" <TAB> <TAB> <TAB> ( y1 , y2 ) = publish_year <TAB> <TAB> else : <TAB> <TAB> <TAB> sql + = ""  and publish_year=$publish_year "" <TAB> return list ( ebook_count_db . query ( sql , vars = locals ( ) ) ) [ 0 ] . num ","if isinstance ( publish_year , ( tuple , list ) ) : 
","if field . endswith ( "" .y "" ) :
",27.27,6.79,False
"def put ( self , session ) : <TAB> with sess_lock : <TAB> <TAB> self . parent . put ( session ) <TAB> <TAB> # Do not store the session if skip paths <TAB> <TAB> for sp in self . skip_paths : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> if session . sid in self . _cache : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> del self . _cache [ session . sid ] <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> self . _cache [ session . sid ] = session <TAB> self . _normalize ( ) ","if request . path . startswith ( sp ) : 
","if session . sid in sp :
",30.74,6.05,False
"def summarize ( self ) : <TAB> if self . bad_commit and self . good_commit : <TAB> <TAB> for subresult in self . subresults . values ( ) : <TAB> <TAB> <TAB> sub = subresult . summarize ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return sub <TAB> <TAB> return "" Detected bad commit in  {}  repository: \n {} {} "" . format ( <TAB> <TAB> <TAB> self . repo_name , self . bad_commit , get_message ( self . suite , self . bad_commit ) <TAB> <TAB> ) <TAB> return "" "" ","if sub : 
","if sub :
",78.12,0.0,False
def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB> <TAB> for p in self . grammar . Productions [ 1 : ] : <TAB> <TAB> <TAB> if p . len == 0 : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p . prod : <TAB> <TAB> <TAB> <TAB> if not t in nullable : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len ( nullable ) <TAB> return nullable ,"if len ( nullable ) == num_nullable : 
","if num_nullable != len ( nullable ) :
",55.0,37.1,False
"def _cast_float64_to_float32 ( self , feeds ) : <TAB> for input_name , input_type in self . inputs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> feed = feeds . get ( input_name ) <TAB> <TAB> <TAB> if feed is not None and feed . dtype == np . float64 : <TAB> <TAB> <TAB> <TAB> feeds [ input_name ] = feed . astype ( np . float32 ) <TAB> return feeds ","if input_type == "" tensor(float) "" : 
","if input_type == "" feed "" :
",74.63,52.38,False
"def proc_minute ( d ) : <TAB> if expanded [ 0 ] [ 0 ] != "" * "" : <TAB> <TAB> diff_min = nearest_diff_method ( d . minute , expanded [ 0 ] , 60 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if is_prev : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 59 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> d + = relativedelta ( minutes = diff_min , second = 0 ) <TAB> <TAB> <TAB> return True , d <TAB> return False , d ","if diff_min is not None and diff_min != 0 : 
","if diff_min is not None and diff_min > 0 :
",85.67,75.33,False
"def detype ( self ) : <TAB> if self . _detyped is not None : <TAB> <TAB> return self . _detyped <TAB> ctx = { } <TAB> for key , val in self . _d . items ( ) : <TAB> <TAB> if not isinstance ( key , str ) : <TAB> <TAB> <TAB> key = str ( key ) <TAB> <TAB> detyper = self . get_detyper ( key ) <TAB> <TAB> if detyper is None : <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> deval = detyper ( val ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # cannot be detyped <TAB> <TAB> <TAB> continue <TAB> <TAB> ctx [ key ] = deval <TAB> self . _detyped = ctx <TAB> return ctx ","if deval is None : 
","if deval is None :
",100.0,100.0,True
"def get_or_create_user ( request , user_data ) : <TAB> try : <TAB> <TAB> user = User . objects . get ( sso_id = user_data [ "" id "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> update_user ( user , user_data ) <TAB> <TAB> return user <TAB> except User . DoesNotExist : <TAB> <TAB> user = User . objects . create_user ( <TAB> <TAB> <TAB> user_data [ "" username "" ] , <TAB> <TAB> <TAB> user_data [ "" email "" ] , <TAB> <TAB> <TAB> is_active = user_data . get ( "" is_active "" , True ) , <TAB> <TAB> <TAB> sso_id = user_data [ "" id "" ] , <TAB> <TAB> ) <TAB> <TAB> user . update_acl_key ( ) <TAB> <TAB> setup_new_user ( request . settings , user ) <TAB> <TAB> return user ","if user_needs_updating ( user , user_data ) : 
","if user . is_active :
",26.99,5.75,False
"def _populate_tree ( self , element , d ) : <TAB> """"""Populates an etree with attributes & elements, given a dict."""""" <TAB> for k , v in d . iteritems ( ) : <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> self . _populate_dict ( element , k , v ) <TAB> <TAB> elif isinstance ( v , list ) : <TAB> <TAB> <TAB> self . _populate_list ( element , k , v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _populate_bool ( element , k , v ) <TAB> <TAB> elif isinstance ( v , basestring ) : <TAB> <TAB> <TAB> self . _populate_str ( element , k , v ) <TAB> <TAB> elif type ( v ) in [ int , float , long , complex ] : <TAB> <TAB> <TAB> self . _populate_number ( element , k , v ) ","elif isinstance ( v , bool ) : 
","elif isinstance ( v , bool ) :
",100.0,100.0,True
"def load ( cls ) : <TAB> if not cls . _loaded : <TAB> <TAB> cls . log . debug ( "" Loading action_sets... "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _find_action_sets ( PATHS . ACTION_SETS_DIRECTORY ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cls . action_sets = JsonDecoder . load ( PATHS . ACTION_SETS_JSON_FILE ) <TAB> <TAB> cls . log . debug ( "" Done! "" ) <TAB> <TAB> cls . _loaded = True ","if not horizons . globals . fife . use_atlases : 
","if PATHS . ACTION_SETS_DIRECTORY in PATHS . ACTION_SETS :
",30.69,3.93,False
"def Resolve ( self , updater = None ) : <TAB> if len ( self . Conflicts ) : <TAB> <TAB> for setting , edge in self . Conflicts : <TAB> <TAB> <TAB> answer = self . AskUser ( self . Setting , setting ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = setting . Value . split ( "" | "" ) <TAB> <TAB> <TAB> <TAB> value . remove ( edge ) <TAB> <TAB> <TAB> <TAB> setting . Value = "" | "" . join ( value ) <TAB> <TAB> <TAB> <TAB> if updater : <TAB> <TAB> <TAB> <TAB> <TAB> updater . UpdateSetting ( setting ) <TAB> <TAB> <TAB> if answer == Gtk . ResponseType . NO : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if answer == Gtk . ResponseType . YES : 
","if answer == Gtk . ResponseType . YES :
",100.0,100.0,True
"def read_tsv ( input_file , quotechar = None ) : <TAB> """"""Reads a tab separated value file."""""" <TAB> with open ( input_file , "" r "" , encoding = "" utf-8-sig "" ) as f : <TAB> <TAB> reader = csv . reader ( f , delimiter = "" \t "" , quotechar = quotechar ) <TAB> <TAB> lines = [ ] <TAB> <TAB> for line in reader : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> line = list ( str ( cell , "" utf-8 "" ) for cell in line )<TAB> # noqa: F821 <TAB> <TAB> <TAB> lines . append ( line ) <TAB> <TAB> return lines ","if sys . version_info [ 0 ] == 2 : 
","if not isinstance ( line , list ) :
",26.4,3.64,False
"def devd_devfs_hook ( middleware , data ) : <TAB> if data . get ( "" subsystem "" ) != "" CDEV "" : <TAB> <TAB> return <TAB> if data [ "" type "" ] == "" CREATE "" : <TAB> <TAB> disks = await middleware . run_in_thread ( <TAB> <TAB> <TAB> lambda : sysctl . filter ( "" kern.disks "" ) [ 0 ] . value . split ( ) <TAB> <TAB> ) <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> if data [ "" cdev "" ] not in disks : <TAB> <TAB> <TAB> return <TAB> <TAB> await added_disk ( middleware , data [ "" cdev "" ] ) <TAB> elif data [ "" type "" ] == "" DESTROY "" : <TAB> <TAB> # Device notified about is not a disk <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> await remove_disk ( middleware , data [ "" cdev "" ] ) ","if not RE_ISDISK . match ( data [ "" cdev "" ] ) : 
","if data [ "" cdev "" ] not in disks :
",50.7,32.43,False
"def on_edit_button_clicked ( self , event = None , a = None , col = None ) : <TAB> tree , tree_id = self . treeView . get_selection ( ) . get_selected ( ) <TAB> watchdir_id = str ( self . store . get_value ( tree_id , 0 ) ) <TAB> if watchdir_id : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . watchdirs [ watchdir_id ] [ "" enabled "" ] : <TAB> <TAB> <TAB> <TAB> client . autoadd . disable_watchdir ( watchdir_id ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . autoadd . enable_watchdir ( watchdir_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . opts_dialog . show ( self . watchdirs [ watchdir_id ] , watchdir_id ) ","if col and col . get_title ( ) == _ ( "" Active "" ) : 
","if self . opts_dialog . hide ( ) :
",31.89,5.67,False
"def _execute ( self , options , args ) : <TAB> if len ( args ) < 1 : <TAB> <TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> paths = args <TAB> songs = [ self . load_song ( p ) for p in paths ] <TAB> for song in songs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CommandError ( <TAB> <TAB> <TAB> <TAB> _ ( "" Image editing not supported for  %(file_name)s "" "" ( %(file_format)s ) "" ) <TAB> <TAB> <TAB> <TAB> % { "" file_name "" : song ( "" ~filename "" ) , "" file_format "" : song ( "" ~format "" ) } <TAB> <TAB> <TAB> ) <TAB> for song in songs : <TAB> <TAB> try : <TAB> <TAB> <TAB> song . clear_images ( ) <TAB> <TAB> except AudioFileError as e : <TAB> <TAB> <TAB> raise CommandError ( e ) ","if not song . can_change_images : 
","if song . is_image ( ) :
",35.8,10.73,False
"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB> <TAB> for pricing_rule in pricing_rules : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules ","if pricing_rule . condition : 
","if pricing_rule . condition :
",100.0,100.0,True
"def ProcessStringLiteral ( self ) : <TAB> if self . _lastToken == None or self . _lastToken . type == self . OpenBrace : <TAB> <TAB> text = super ( JavaScriptBaseLexer , self ) . text <TAB> <TAB> if text == ' "" use strict "" ' or text == "" ' use strict ' "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _scopeStrictModes . pop ( ) <TAB> <TAB> <TAB> self . _useStrictCurrent = True <TAB> <TAB> <TAB> self . _scopeStrictModes . append ( self . _useStrictCurrent ) ","if len ( self . _scopeStrictModes ) > 0 : 
","if self . _useStrictCurrent and self . _useStrictCurrent in self . _scopeStrictModes :
",34.51,16.94,False
"def _find_remote_inputs ( metadata ) : <TAB> out = [ ] <TAB> for fr_key in metadata . keys ( ) : <TAB> <TAB> if isinstance ( fr_key , ( list , tuple ) ) : <TAB> <TAB> <TAB> frs = fr_key <TAB> <TAB> else : <TAB> <TAB> <TAB> frs = [ fr_key ] <TAB> <TAB> for fr in frs : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> out . append ( fr ) <TAB> return out ","if objectstore . is_remote ( fr ) : 
","if metadata [ fr ] [ "" name "" ] == "" remote "" :
",26.46,3.46,False
"def sub_paragraph ( self , li ) : <TAB> """"""Search for checkbox in sub-paragraph."""""" <TAB> found = False <TAB> if len ( li ) : <TAB> <TAB> first = list ( li ) [ 0 ] <TAB> <TAB> if first . tag == "" p "" and first . text is not None : <TAB> <TAB> <TAB> m = RE_CHECKBOX . match ( first . text ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> first . text = self . markdown . htmlStash . store ( <TAB> <TAB> <TAB> <TAB> <TAB> get_checkbox ( m . group ( "" state "" ) ) , safe = True <TAB> <TAB> <TAB> <TAB> ) + m . group ( "" line "" ) <TAB> <TAB> <TAB> <TAB> found = True <TAB> return found ","if m is not None : 
","if m :
",29.58,0.0,False
"def list_files ( basedir ) : <TAB> """"""List files in the directory rooted at |basedir|."""""" <TAB> if not os . path . isdir ( basedir ) : <TAB> <TAB> raise NoSuchDirectory ( basedir ) <TAB> directories = [ "" "" ] <TAB> while directories : <TAB> <TAB> d = directories . pop ( ) <TAB> <TAB> for basename in os . listdir ( os . path . join ( basedir , d ) ) : <TAB> <TAB> <TAB> filename = os . path . join ( d , basename ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> directories . append ( filename ) <TAB> <TAB> <TAB> elif os . path . exists ( os . path . join ( basedir , filename ) ) : <TAB> <TAB> <TAB> <TAB> yield filename ","if os . path . isdir ( os . path . join ( basedir , filename ) ) : 
","if os . path . isdir ( filename ) :
",52.02,30.52,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def _dump ( self , fd ) : <TAB> with self . no_unpicklable_properties ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d = pickle . dumps ( self ) <TAB> <TAB> <TAB> module_name = os . path . basename ( sys . argv [ 0 ] ) . rsplit ( "" . "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> d = d . replace ( b "" c__main__ "" , b "" c "" + module_name . encode ( "" ascii "" ) ) <TAB> <TAB> <TAB> fd . write ( d ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pickle . dump ( self , fd ) ","if self . __module__ == "" __main__ "" : 
","if self . dumps :
",36.67,3.17,False
"def assert_session_stack ( classes ) : <TAB> assert len ( _SklearnTrainingSession . _session_stack ) == len ( classes ) <TAB> for idx , ( sess , ( parent_clazz , clazz ) ) in enumerate ( <TAB> <TAB> zip ( _SklearnTrainingSession . _session_stack , classes ) <TAB> ) : <TAB> <TAB> assert sess . clazz == clazz <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert sess . _parent is None <TAB> <TAB> else : <TAB> <TAB> <TAB> assert sess . _parent . clazz == parent_clazz ","if idx == 0 : 
","if idx == 0 :
",100.0,100.0,True
"def native_color ( c ) : <TAB> try : <TAB> <TAB> color = CACHE [ c ] <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> c = NAMED_COLOR [ c ] <TAB> <TAB> color = Color . FromArgb ( <TAB> <TAB> <TAB> int ( c . rgba . a * 255 ) , int ( c . rgba . r ) , int ( c . rgba . g ) , int ( c . rgba . b ) <TAB> <TAB> ) <TAB> <TAB> CACHE [ c ] = color <TAB> return color ","if isinstance ( c , str ) : 
","if NAMED_COLOR . has_key ( c ) :
",29.49,10.13,False
"def callback ( name ) : <TAB> # XXX: move into Action <TAB> for neighbor_name in reactor . configuration . neighbors . keys ( ) : <TAB> <TAB> neighbor = reactor . configuration . neighbors . get ( neighbor_name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> neighbor . rib . outgoing . announce_watchdog ( name ) <TAB> <TAB> yield False <TAB> reactor . processes . answer_done ( service ) ","if not neighbor : 
","if not neighbor :
",100.0,100.0,True
"def token_producer ( source ) : <TAB> token = source . read_uint8 ( ) <TAB> while token is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield DataToken ( read_data ( token , source ) ) <TAB> <TAB> elif is_small_integer ( token ) : <TAB> <TAB> <TAB> yield SmallIntegerToken ( read_small_integer ( token ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield Token ( token ) <TAB> <TAB> token = source . read_uint8 ( ) ","if is_push_data_token ( token ) : 
","if is_data ( token ) :
",77.13,32.82,False
"def setattr ( self , req , ino , attr , to_set , fi ) : <TAB> print ( "" setattr: "" , ino , to_set ) <TAB> a = self . attr [ ino ] <TAB> for key in to_set : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Keep the old file type bit fields <TAB> <TAB> <TAB> a [ "" st_mode "" ] = S_IFMT ( a [ "" st_mode "" ] ) | S_IMODE ( attr [ "" st_mode "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> a [ key ] = attr [ key ] <TAB> self . attr [ ino ] = a <TAB> self . reply_attr ( req , a , 1.0 ) ","if key == "" st_mode "" : 
","if fi :
",27.04,0.0,False
"def check_enum_exports ( module , eq_callback , only = None ) : <TAB> """"""Make sure module exports all mnemonics from enums"""""" <TAB> for attr in enumerate_module ( module , enum . Enum ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" SKIP "" , attr ) <TAB> <TAB> <TAB> continue <TAB> <TAB> for flag , value in attr . __members__ . items ( ) : <TAB> <TAB> <TAB> print ( module , flag , value ) <TAB> <TAB> <TAB> eq_callback ( getattr ( module , flag ) , value ) ","if only is not None and attr not in only : 
","if only and attr . name not in only :
",44.2,32.12,False
"def remove_edit_vars_to ( self , n ) : <TAB> try : <TAB> <TAB> removals = [ ] <TAB> <TAB> for v , cei in self . edit_var_map . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> removals . append ( v ) <TAB> <TAB> for v in removals : <TAB> <TAB> <TAB> self . remove_edit_var ( v ) <TAB> <TAB> assert len ( self . edit_var_map ) == n <TAB> except ConstraintNotFound : <TAB> <TAB> raise InternalError ( "" Constraint not found during internal removal "" ) ","if cei . index > = n : 
","if cei . edit_var_id == n :
",38.98,21.2,False
"def fix_repeating_arguments ( self ) : <TAB> """"""Fix elements that should accumulate/increment values."""""" <TAB> either = [ list ( child . children ) for child in transform ( self ) . children ] <TAB> for case in either : <TAB> <TAB> for e in [ child for child in case if case . count ( child ) > 1 ] : <TAB> <TAB> <TAB> if type ( e ) is Argument or type ( e ) is Option and e . argcount : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> e . value = [ ] <TAB> <TAB> <TAB> <TAB> elif type ( e . value ) is not list : <TAB> <TAB> <TAB> <TAB> <TAB> e . value = e . value . split ( ) <TAB> <TAB> <TAB> if type ( e ) is Command or type ( e ) is Option and e . argcount == 0 : <TAB> <TAB> <TAB> <TAB> e . value = 0 <TAB> return self ","if e . value is None : 
","if type ( e . value ) is None :
",42.96,27.3,False
"def add_I_prefix ( current_line : List [ str ] , ner : int , tag : str ) : <TAB> for i in range ( 0 , len ( current_line ) ) : <TAB> <TAB> if i == 0 : <TAB> <TAB> <TAB> f . write ( line_list [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f . write ( ""  I- "" + tag ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f . write ( "" "" + current_line [ i ] ) <TAB> f . write ( "" \n "" ) ","elif i == ner : 
","elif i < ner :
",58.14,24.74,False
def select_word_at_cursor ( self ) : <TAB> word_region = None <TAB> selection = self . view . sel ( ) <TAB> for region in selection : <TAB> <TAB> word_region = self . view . word ( region ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> selection . clear ( ) <TAB> <TAB> <TAB> selection . add ( word_region ) <TAB> <TAB> <TAB> return word_region <TAB> return word_region ,"if not word_region . empty ( ) : 
","if word_region is not None :
",27.12,19.04,False
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> if self . op == "" + "" : <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res ","elif self . op == "" - "" : 
","elif self . op == "" - "" :
",100.0,100.0,True
"def strip_pod ( lines ) : <TAB> in_pod = False <TAB> stripped_lines = [ ] <TAB> for line in lines : <TAB> <TAB> if re . match ( r "" ^=(?:end|cut) "" , line ) : <TAB> <TAB> <TAB> in_pod = False <TAB> <TAB> elif re . match ( r "" ^= \ w+ "" , line ) : <TAB> <TAB> <TAB> in_pod = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stripped_lines . append ( line ) <TAB> return stripped_lines ","elif not in_pod : 
","elif in_pod :
",59.18,57.89,False
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> if isinstance ( filename_data , list ) : <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> if not filename . startswith ( os . sep ) : <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories ","if data : 
","if data is not None :
",34.04,17.97,False
"def loadPerfsFromModule ( self , module ) : <TAB> """"""Return a suite of all perfs cases contained in the given module"""""" <TAB> perfs = [ ] <TAB> for name in dir ( module ) : <TAB> <TAB> obj = getattr ( module , name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> perfs . append ( self . loadPerfsFromPerfCase ( obj ) ) <TAB> return self . suiteClass ( perfs ) ","if type ( obj ) == types . ClassType and issubclass ( obj , PerfCase ) : 
","if isinstance ( obj , ( type , types . ClassType ) ) and issubclass ( obj , PerfsCase ) :
",49.6,28.59,False
"def download_subtitle ( self , subtitle ) : <TAB> if isinstance ( subtitle , XSubsSubtitle ) : <TAB> <TAB> # download the subtitle <TAB> <TAB> logger . info ( "" Downloading subtitle  %r "" , subtitle ) <TAB> <TAB> r = self . session . get ( <TAB> <TAB> <TAB> subtitle . download_link , headers = { "" Referer "" : subtitle . page_link } , timeout = 10 <TAB> <TAB> ) <TAB> <TAB> r . raise_for_status ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( "" Unable to download subtitle. No data returned from provider "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> subtitle . content = fix_line_ending ( r . content ) ","if not r . content : 
","if r . status_code != 200 :
",35.8,9.98,False
"def get_inlaws ( self , person ) : <TAB> inlaws = [ ] <TAB> family_handles = person . get_family_handle_list ( ) <TAB> for handle in family_handles : <TAB> <TAB> fam = self . database . get_family_from_handle ( handle ) <TAB> <TAB> if fam . father_handle and not fam . father_handle == person . handle : <TAB> <TAB> <TAB> inlaws . append ( self . database . get_person_from_handle ( fam . father_handle ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> inlaws . append ( self . database . get_person_from_handle ( fam . mother_handle ) ) <TAB> return inlaws ","elif fam . mother_handle and not fam . mother_handle == person . handle : 
","if fam . mother_handle and not fam . mother_handle == person . handle :
",81.29,94.26,False
"def _check_xorg_conf ( ) : <TAB> if is_there_a_default_xorg_conf_file ( ) : <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" WARNING : Found a Xorg config file at /etc/X11/xorg.conf. If you did not "" <TAB> <TAB> <TAB> ""  create it yourself, it was likely generated by your distribution or by an Nvidia utility. \n "" <TAB> <TAB> <TAB> "" This file may contain hard-coded GPU configuration that could interfere with optimus-manager, "" <TAB> <TAB> <TAB> ""  so it is recommended that you delete it before proceeding. \n "" <TAB> <TAB> <TAB> "" Ignore this warning and proceed with GPU switching ? (y/N) "" <TAB> <TAB> ) <TAB> <TAB> confirmation = ask_confirmation ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sys . exit ( 0 ) ","if not confirmation : 
","if not confirmation :
",100.0,100.0,True
"def _make_cache_key ( group , window , rate , value , methods ) : <TAB> count , period = _split_rate ( rate ) <TAB> safe_rate = "" %d / %d s "" % ( count , period ) <TAB> parts = [ group , safe_rate , value , str ( window ) ] <TAB> if methods is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> methods = "" "" <TAB> <TAB> elif isinstance ( methods , ( list , tuple ) ) : <TAB> <TAB> <TAB> methods = "" "" . join ( sorted ( [ m . upper ( ) for m in methods ] ) ) <TAB> <TAB> parts . append ( methods ) <TAB> prefix = getattr ( settings , "" RATELIMIT_CACHE_PREFIX "" , "" rl: "" ) <TAB> return prefix + hashlib . md5 ( u "" "" . join ( parts ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) ","if methods == ALL : 
","if methods is None :
",31.5,19.36,False
"def num_of_mapped_volumes ( self , initiator ) : <TAB> cnt = 0 <TAB> for lm_link in self . req ( "" lun-maps "" ) [ "" lun-maps "" ] : <TAB> <TAB> idx = lm_link [ "" href "" ] . split ( "" / "" ) [ - 1 ] <TAB> <TAB> # NOTE(geguileo): There can be races so mapped elements retrieved <TAB> <TAB> # in the listing may no longer exist. <TAB> <TAB> try : <TAB> <TAB> <TAB> lm = self . req ( "" lun-maps "" , idx = int ( idx ) ) [ "" content "" ] <TAB> <TAB> except exception . NotFound : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cnt + = 1 <TAB> return cnt ","if lm [ "" ig-name "" ] == initiator : 
","if lm [ "" initiator "" ] == initiator :
",83.03,70.17,False
"def _setAbsoluteY ( self , value ) : <TAB> if value is None : <TAB> <TAB> self . _absoluteY = None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = 10 <TAB> <TAB> elif value == "" below "" : <TAB> <TAB> <TAB> value = - 70 <TAB> <TAB> try : <TAB> <TAB> <TAB> value = common . numToIntOrFloat ( value ) <TAB> <TAB> except ValueError as ve : <TAB> <TAB> <TAB> raise TextFormatException ( <TAB> <TAB> <TAB> <TAB> f "" Not a supported absoluteY position:  { value !r} "" <TAB> <TAB> <TAB> ) from ve <TAB> <TAB> self . _absoluteY = value ","if value == "" above "" : 
","if value == "" below "" :
",74.63,59.46,False
"def render_markdown ( text ) : <TAB> users = { u . username . lower ( ) : u for u in get_mention_users ( text ) } <TAB> parts = MENTION_RE . split ( text ) <TAB> for pos , part in enumerate ( parts ) : <TAB> <TAB> if not part . startswith ( "" @ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> username = part [ 1 : ] . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> user = users [ username ] <TAB> <TAB> <TAB> parts [ pos ] = ' **[ {} ]( {} "" {} "" )** ' . format ( <TAB> <TAB> <TAB> <TAB> part , user . get_absolute_url ( ) , user . get_visible_name ( ) <TAB> <TAB> <TAB> ) <TAB> text = "" "" . join ( parts ) <TAB> return mark_safe ( MARKDOWN ( text ) ) ","if username in users : 
","if username in users :
",100.0,100.0,True
def start_process ( self ) : <TAB> with self . thread_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . allow_process_request = False <TAB> <TAB> <TAB> t = threading . Thread ( target = self . __start ) <TAB> <TAB> <TAB> t . daemon = True <TAB> <TAB> <TAB> t . start ( ) ,"if self . allow_process_request : 
","if self . allow_process_request :
",100.0,100.0,True
"def close ( self ) : <TAB> if self . _fh . closed : <TAB> <TAB> return <TAB> self . _fh . close ( ) <TAB> if os . path . isfile ( self . _filename ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> salt . utils . win_dacl . copy_security ( <TAB> <TAB> <TAB> <TAB> source = self . _filename , target = self . _tmp_filename <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shutil . copymode ( self . _filename , self . _tmp_filename ) <TAB> <TAB> <TAB> st = os . stat ( self . _filename ) <TAB> <TAB> <TAB> os . chown ( self . _tmp_filename , st . st_uid , st . st_gid ) <TAB> atomic_rename ( self . _tmp_filename , self . _filename ) ","if salt . utils . win_dacl . HAS_WIN32 : 
","if os . path . isdir ( self . _filename ) :
",36.58,4.83,False
"def _splitSchemaNameDotFieldName ( sn_fn , fnRequired = True ) : <TAB> if sn_fn . find ( "" . "" ) != - 1 : <TAB> <TAB> schemaName , fieldName = sn_fn . split ( "" . "" , 1 ) <TAB> <TAB> schemaName = schemaName . strip ( ) <TAB> <TAB> fieldName = fieldName . strip ( ) <TAB> <TAB> if schemaName and fieldName : <TAB> <TAB> <TAB> return ( schemaName , fieldName ) <TAB> elif not fnRequired : <TAB> <TAB> schemaName = sn_fn . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( schemaName , None ) <TAB> controlflow . system_error_exit ( <TAB> <TAB> 2 , f "" { sn_fn }  is not a valid custom schema.field name. "" <TAB> ) ","if schemaName : 
","if schemaName and not schemaName . startswith ( "" . "" ) :
",32.56,6.84,False
"def modified ( self ) : <TAB> paths = set ( ) <TAB> dictionary_list = [ ] <TAB> for op_list in self . _operations : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> op_list = ( op_list , ) <TAB> <TAB> for item in chain ( * op_list ) : <TAB> <TAB> <TAB> if item is None : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> dictionary = item . dictionary <TAB> <TAB> <TAB> if dictionary . path in paths : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . add ( dictionary . path ) <TAB> <TAB> <TAB> dictionary_list . append ( dictionary ) <TAB> return dictionary_list ","if not isinstance ( op_list , list ) : 
","if not isinstance ( op_list , ( list , tuple ) ) :
",53.03,53.28,False
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_place_handle ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_date_object ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if family : 
","if family :
",78.12,0.0,False
"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> <TAB> value = value == "" true "" <TAB> <TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json ) ","if key in ( "" disabled "" , "" is_up "" ) : 
","if key . startswith ( "" _ "" ) :
",38.98,14.4,False
"def get_billable_and_total_duration ( activity , start_time , end_time ) : <TAB> precision = frappe . get_precision ( "" Timesheet Detail "" , "" hours "" ) <TAB> activity_duration = time_diff_in_hours ( end_time , start_time ) <TAB> billing_duration = 0.0 <TAB> if activity . billable : <TAB> <TAB> billing_duration = activity . billing_hours <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> billing_duration = ( <TAB> <TAB> <TAB> <TAB> activity_duration * activity . billing_hours / activity . hours <TAB> <TAB> <TAB> ) <TAB> return flt ( activity_duration , precision ) , flt ( billing_duration , precision ) ","if activity_duration != activity . billing_hours : 
","if activity . hours :
",35.72,8.72,False
"def cpus ( self ) : <TAB> try : <TAB> <TAB> cpus = ( <TAB> <TAB> <TAB> self . inspect [ "" Spec "" ] [ "" Resources "" ] [ "" Reservations "" ] [ "" NanoCPUs "" ] / 1000000000.0 <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cpus = int ( cpus ) <TAB> <TAB> return cpus <TAB> except TypeError : <TAB> <TAB> return None <TAB> except KeyError : <TAB> <TAB> return 0 ","if cpus == int ( cpus ) : 
","if cpus > = int ( cpus ) :
",62.87,66.06,False
"def _create_object ( self , obj_body ) : <TAB> props = obj_body [ SYMBOL_PROPERTIES ] <TAB> for prop_name , prop_value in props . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # get the first key as the convert function <TAB> <TAB> <TAB> func_name = list ( prop_value . keys ( ) ) [ 0 ] <TAB> <TAB> <TAB> if func_name . startswith ( "" _ "" ) : <TAB> <TAB> <TAB> <TAB> func = getattr ( self , func_name ) <TAB> <TAB> <TAB> <TAB> props [ prop_name ] = func ( prop_value [ func_name ] ) <TAB> if SYMBOL_TYPE in obj_body and obj_body [ SYMBOL_TYPE ] in self . fake_func_mapping : <TAB> <TAB> return self . fake_func_mapping [ obj_body [ SYMBOL_TYPE ] ] ( * * props ) <TAB> else : <TAB> <TAB> return props ","if isinstance ( prop_value , dict ) and prop_value : 
","if isinstance ( prop_value , dict ) :
",67.71,60.57,False
"def _yield_unescaped ( self , string ) : <TAB> while "" \\ "" in string : <TAB> <TAB> finder = EscapeFinder ( string ) <TAB> <TAB> yield finder . before + finder . backslashes <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield self . _unescape ( finder . text ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield finder . text <TAB> <TAB> string = finder . after <TAB> yield string ","if finder . escaped and finder . text : 
","if "" \\ "" in string :
",26.54,5.8,False
"def _check_matches ( rule , matches ) : <TAB> errors = 0 <TAB> for match in matches : <TAB> <TAB> filematch = _match_to_test_file ( match ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> utils . error ( <TAB> <TAB> <TAB> <TAB> "" The match  ' {} '  for rule  ' {} '  points to a non existing test module path:  {} "" , <TAB> <TAB> <TAB> <TAB> match , <TAB> <TAB> <TAB> <TAB> rule , <TAB> <TAB> <TAB> <TAB> filematch , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> errors + = 1 <TAB> return errors ","if not filematch . exists ( ) : 
","if not filematch :
",33.02,23.51,False
"def focused_windows ( ) : <TAB> tree = i3 . get_tree ( ) <TAB> workspaces = tree . workspaces ( ) <TAB> for workspace in workspaces : <TAB> <TAB> container = workspace <TAB> <TAB> while container : <TAB> <TAB> <TAB> if not hasattr ( container , "" focus "" ) or not container . focus : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> container_id = container . focus [ 0 ] <TAB> <TAB> <TAB> container = container . find_by_id ( container_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> coname = container . name <TAB> <TAB> <TAB> wsname = workspace . name <TAB> <TAB> <TAB> print ( "" WS "" , wsname + "" : "" , coname ) ","if container : 
","if container :
",78.12,0.0,False
"def normals ( self , value ) : <TAB> if value is not None : <TAB> <TAB> value = np . asanyarray ( value , dtype = np . float32 ) <TAB> <TAB> value = np . ascontiguousarray ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Incorrect normals shape "" ) <TAB> self . _normals = value ","if value . shape != self . positions . shape : 
","if len ( value . shape ) != self . shape :
",43.53,35.74,False
"def test_hexdigest ( self ) : <TAB> for cons in self . hash_constructors : <TAB> <TAB> h = cons ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsInstance ( h . digest ( 16 ) , bytes ) <TAB> <TAB> <TAB> self . assertEqual ( hexstr ( h . digest ( 16 ) ) , h . hexdigest ( 16 ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertIsInstance ( h . digest ( ) , bytes ) <TAB> <TAB> <TAB> self . assertEqual ( hexstr ( h . digest ( ) ) , h . hexdigest ( ) ) ","if h . name in self . shakes : 
","if h . name == "" sha256 "" :
",50.69,27.78,False
"def _get_cluster_status ( self ) : <TAB> try : <TAB> <TAB> return ( <TAB> <TAB> <TAB> self . dataproc_client . projects ( ) <TAB> <TAB> <TAB> . regions ( ) <TAB> <TAB> <TAB> . clusters ( ) <TAB> <TAB> <TAB> . get ( <TAB> <TAB> <TAB> <TAB> projectId = self . gcloud_project_id , <TAB> <TAB> <TAB> <TAB> region = self . dataproc_region , <TAB> <TAB> <TAB> <TAB> clusterName = self . dataproc_cluster_name , <TAB> <TAB> <TAB> <TAB> fields = "" status "" , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> . execute ( ) <TAB> <TAB> ) <TAB> except HttpError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None<TAB> # We got a 404 so the cluster doesn't exist <TAB> <TAB> else : <TAB> <TAB> <TAB> raise e ","if e . resp . status == 404 : 
","if e . status == 404 :
",59.68,65.49,False
"def _items_from ( self , context ) : <TAB> self . _context = context <TAB> if self . _is_local_variable ( self . _keyword_name , context ) : <TAB> <TAB> for item in self . _items_from_controller ( context ) : <TAB> <TAB> <TAB> yield item <TAB> else : <TAB> <TAB> for df in context . datafiles : <TAB> <TAB> <TAB> self . _yield_for_other_threads ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for item in self . _items_from_datafile ( df ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield item ","if self . _items_from_datafile_should_be_checked ( df ) : 
","if self . _is_local_variable ( self . _keyword_name , df ) :
",39.76,19.84,False
"def Command ( argv , funcs , path_val ) : <TAB> arg , i = COMMAND_SPEC . Parse ( argv ) <TAB> status = 0 <TAB> if arg . v : <TAB> <TAB> for kind , arg in _ResolveNames ( argv [ i : ] , funcs , path_val ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> status = 1<TAB> # nothing printed, but we fail <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # This is for -v, -V is more detailed. <TAB> <TAB> <TAB> <TAB> print ( arg ) <TAB> else : <TAB> <TAB> util . warn ( "" *** command without -v not not implemented *** "" ) <TAB> <TAB> status = 1 <TAB> return status ","if kind is None : 
","if kind == "" -v "" :
",29.79,12.22,False
"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB> <TAB> if isinstance ( node , Preprint ) : <TAB> <TAB> <TAB> category = "" preprint "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> category = "" registration "" <TAB> <TAB> else : <TAB> <TAB> <TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB> <TAB> index = index , <TAB> <TAB> doc_type = category , <TAB> <TAB> id = elastic_document_id , <TAB> <TAB> refresh = True , <TAB> <TAB> ignore = [ 404 ] , <TAB> ) ","elif node . is_registration : 
","elif isinstance ( node , Registration ) :
",27.8,7.27,False
"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree ( child ) <TAB> <TAB> else : <TAB> <TAB> <TAB> content = child . text <TAB> <TAB> if ret_dict . has_key ( child . tag ) : <TAB> <TAB> <TAB> if not type ( ret_dict [ child . tag ] ) == list : <TAB> <TAB> <TAB> <TAB> ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB> <TAB> <TAB> ret_dict [ child . tag ] . append ( content or "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret_dict [ child . tag ] = content or "" "" <TAB> return ret_dict ","if child . getchildren ( ) : 
","if isinstance ( child , Leaf ) :
",29.12,13.89,False
"def get ( self , block = True , timeout = None , ack = False ) : <TAB> if not block : <TAB> <TAB> return self . get_nowait ( ) <TAB> start_time = time . time ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . get_nowait ( ack ) <TAB> <TAB> except BaseQueue . Empty : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> lasted = time . time ( ) - start_time <TAB> <TAB> <TAB> <TAB> if timeout > lasted : <TAB> <TAB> <TAB> <TAB> <TAB> time . sleep ( min ( self . max_timeout , timeout - lasted ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> time . sleep ( self . max_timeout ) ","if timeout : 
","if timeout :
",78.12,0.0,False
"def rewrite ( self , string ) : <TAB> string = super ( JSReplaceFuzzy , self ) . rewrite ( string ) <TAB> cdx = self . url_rewriter . rewrite_opts [ "" cdx "" ] <TAB> if cdx . get ( "" is_fuzzy "" ) : <TAB> <TAB> expected = unquote ( cdx [ "" url "" ] ) <TAB> <TAB> actual = unquote ( self . url_rewriter . wburl . url ) <TAB> <TAB> exp_m = self . rx_obj . search ( expected ) <TAB> <TAB> act_m = self . rx_obj . search ( actual ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = string . replace ( exp_m . group ( 1 ) , act_m . group ( 1 ) ) <TAB> <TAB> <TAB> if result != string : <TAB> <TAB> <TAB> <TAB> string = result <TAB> return string ","if exp_m and act_m : 
","if exp_m :
",31.47,37.78,False
"def locate_exe_dir ( d , check = True ) : <TAB> exe_dir = os . path . join ( d , "" Scripts "" ) if ON_WINDOWS else os . path . join ( d , "" bin "" ) <TAB> if not os . path . isdir ( exe_dir ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bin_dir = os . path . join ( d , "" bin "" ) <TAB> <TAB> <TAB> if os . path . isdir ( bin_dir ) : <TAB> <TAB> <TAB> <TAB> return bin_dir <TAB> <TAB> if check : <TAB> <TAB> <TAB> raise InvalidVirtualEnv ( "" Unable to locate executables directory. "" ) <TAB> return exe_dir ","if ON_WINDOWS : 
","if os . path . exists ( os . path . join ( d , "" executables "" ) ) :
",28.87,2.16,False
"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB> <TAB> s = str ( path ) <TAB> <TAB> if ensuremode == "" append "" : <TAB> <TAB> <TAB> if s not in sys . path : <TAB> <TAB> <TAB> <TAB> sys . path . append ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sys . path . insert ( 0 , s ) ","if s != sys . path [ 0 ] : 
","if s not in sys . path :
",37.11,18.59,False
"def create_season_banners ( self , show_obj ) : <TAB> if self . season_banners and show_obj : <TAB> <TAB> result = [ ] <TAB> <TAB> for season , episodes in show_obj . episodes . iteritems ( ) :<TAB> # @UnusedVariable <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> logger . log ( <TAB> <TAB> <TAB> <TAB> <TAB> u "" Metadata provider  "" <TAB> <TAB> <TAB> <TAB> <TAB> + self . name <TAB> <TAB> <TAB> <TAB> <TAB> + ""  creating season banners for  "" <TAB> <TAB> <TAB> <TAB> <TAB> + show_obj . name , <TAB> <TAB> <TAB> <TAB> <TAB> logger . DEBUG , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> result = result + [ self . save_season_banners ( show_obj , season ) ] <TAB> <TAB> return all ( result ) <TAB> return False ","if not self . _has_season_banner ( show_obj , season ) : 
","if not self . _has_season_banner ( show_obj , season , episodes ) :
",67.99,81.94,False
"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB> <TAB> if "" nbgrader "" not in cell . metadata : <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB> <TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB> <TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB> <TAB> if grade_id in ids : <TAB> <TAB> <TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB> <TAB> ids . add ( grade_id ) ","if not grade and not solution and not locked : 
","if grade != solution and not locked :
",56.76,43.44,False
"def read_version ( ) : <TAB> regexp = re . compile ( r "" ^__version__ \ W*= \ W* ' ([ \ d.abrc]+) ' "" ) <TAB> init_py = os . path . join ( os . path . dirname ( __file__ ) , "" aiopg "" , "" __init__.py "" ) <TAB> with open ( init_py ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> match = regexp . match ( line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return match . group ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RuntimeError ( "" Cannot find version in aiopg/__init__.py "" ) ","if match is not None : 
","if match is not None :
",100.0,100.0,True
"def _column_keys ( self ) : <TAB> """"""Get a dictionary of all columns and their case mapping."""""" <TAB> if not self . exists : <TAB> <TAB> return { } <TAB> with self . db . lock : <TAB> <TAB> if self . _columns is None : <TAB> <TAB> <TAB> # Initialise the table if it doesn't exist <TAB> <TAB> <TAB> table = self . table <TAB> <TAB> <TAB> self . _columns = { } <TAB> <TAB> <TAB> for column in table . columns : <TAB> <TAB> <TAB> <TAB> name = normalize_column_name ( column . name ) <TAB> <TAB> <TAB> <TAB> key = normalize_column_key ( name ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> log . warning ( "" Duplicate column:  %s "" , name ) <TAB> <TAB> <TAB> <TAB> self . _columns [ key ] = name <TAB> <TAB> return self . _columns ","if key in self . _columns : 
","if key in self :
",48.26,38.81,False
"def find_controller_by_names ( self , names , testname ) : <TAB> namestring = "" . "" . join ( names ) <TAB> if not namestring . startswith ( self . name ) : <TAB> <TAB> return None <TAB> if namestring == self . name : <TAB> <TAB> return self <TAB> for suite in self . suites : <TAB> <TAB> res = suite . find_controller_by_names ( <TAB> <TAB> <TAB> namestring [ len ( self . name ) + 1 : ] . split ( "" . "" ) , testname <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return res ","if res : 
","if res :
",78.12,0.0,False
"def _volume_x_metadata_get_item ( <TAB> context , volume_id , key , model , notfound_exec , session = None ) : <TAB> result = ( <TAB> <TAB> _volume_x_metadata_get_query ( context , volume_id , model , session = session ) <TAB> <TAB> . filter_by ( key = key ) <TAB> <TAB> . first ( ) <TAB> ) <TAB> if not result : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise notfound_exec ( id = volume_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise notfound_exec ( metadata_key = key , volume_id = volume_id ) <TAB> return result ","if model is models . VolumeGlanceMetadata : 
","if key == "" id "" :
",27.05,6.57,False
"def parse_results ( cwd ) : <TAB> optimal_dd = None <TAB> optimal_measure = numpy . inf <TAB> for tup in tools . find_conf_files ( cwd ) : <TAB> <TAB> dd = tup [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if dd [ "" results.train_y_misclass "" ] < optimal_measure : <TAB> <TAB> <TAB> <TAB> optimal_measure = dd [ "" results.train_y_misclass "" ] <TAB> <TAB> <TAB> <TAB> optimal_dd = dd <TAB> print ( "" Optimal results.train_y_misclass: "" , str ( optimal_measure ) ) <TAB> for key , value in optimal_dd . items ( ) : <TAB> <TAB> if "" hyper_parameters "" in key : <TAB> <TAB> <TAB> print ( key + "" :  "" + str ( value ) ) ","if "" results.train_y_misclass "" in dd : 
","if "" results.train_y_misclass "" in dd :
",100.0,100.0,True
"def _stop_by_max_time_mins ( self ) : <TAB> """"""Stop optimization process once maximum minutes have elapsed."""""" <TAB> if self . max_time_mins : <TAB> <TAB> total_mins_elapsed = ( <TAB> <TAB> <TAB> datetime . now ( ) - self . _start_datetime <TAB> <TAB> ) . total_seconds ( ) / 60.0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise KeyboardInterrupt ( <TAB> <TAB> <TAB> <TAB> "" {:.2f}  minutes have elapsed. TPOT will close down. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> total_mins_elapsed <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","if total_mins_elapsed > = self . max_time_mins : 
","if total_mins_elapsed > self . max_time_mins :
",55.53,81.97,False
"def __new__ ( meta , cls_name , bases , cls_dict ) : <TAB> func = cls_dict . get ( "" func "" ) <TAB> monad_cls = super ( FuncMonadMeta , meta ) . __new__ ( meta , cls_name , bases , cls_dict ) <TAB> if func : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> functions = func <TAB> <TAB> else : <TAB> <TAB> <TAB> functions = ( func , ) <TAB> <TAB> for func in functions : <TAB> <TAB> <TAB> registered_functions [ func ] = monad_cls <TAB> return monad_cls ","if type ( func ) is tuple : 
","if isinstance ( func , ( list , tuple ) ) :
",27.93,8.91,False
"def get_tokens_unprocessed ( self , text ) : <TAB> buffered = "" "" <TAB> insertions = [ ] <TAB> lng_buffer = [ ] <TAB> for i , t , v in self . language_lexer . get_tokens_unprocessed ( text ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if lng_buffer : <TAB> <TAB> <TAB> <TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB> <TAB> <TAB> <TAB> lng_buffer = [ ] <TAB> <TAB> <TAB> buffered + = v <TAB> <TAB> else : <TAB> <TAB> <TAB> lng_buffer . append ( ( i , t , v ) ) <TAB> if lng_buffer : <TAB> <TAB> insertions . append ( ( len ( buffered ) , lng_buffer ) ) <TAB> return do_insertions ( insertions , self . root_lexer . get_tokens_unprocessed ( buffered ) ) ","if t is self . needle : 
","if t == "" L "" :
",28.91,12.22,False
"def get_conditions ( filters ) : <TAB> conditions = { "" docstatus "" : ( "" = "" , 1 ) } <TAB> if filters . get ( "" from_date "" ) and filters . get ( "" to_date "" ) : <TAB> <TAB> conditions [ "" result_date "" ] = ( <TAB> <TAB> <TAB> "" between "" , <TAB> <TAB> <TAB> ( filters . get ( "" from_date "" ) , filters . get ( "" to_date "" ) ) , <TAB> <TAB> ) <TAB> <TAB> filters . pop ( "" from_date "" ) <TAB> <TAB> filters . pop ( "" to_date "" ) <TAB> for key , value in filters . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conditions [ key ] = value <TAB> return conditions ","if filters . get ( key ) : 
","if key in ( "" result_date "" , "" between "" , "" between "" , "" between "" , "" between "" , "" between "" , "" between "" , "" between "" , "" between "" ) :
",27.23,2.14,False
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if ( datetime . now ( ) - limit ) > value : <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) - limit <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if ( datetime . now ( ) + limit ) < value : <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) + limit <TAB> <TAB> elif value > limit : <TAB> <TAB> <TAB> value = limit <TAB> return value ","if config [ key ] [ "" inverse "" ] is True : 
","if value . days < limit :
",25.93,3.31,False
"def GetCurrentKeySet ( self ) : <TAB> "" Return CurrentKeys with  ' darwin '  modifications. "" <TAB> result = self . GetKeySet ( self . CurrentKeys ( ) ) <TAB> if sys . platform == "" darwin "" : <TAB> <TAB> # macOS (OS X) Tk variants do not support the ""Alt"" <TAB> <TAB> # keyboard modifier.  Replace it with ""Option"". <TAB> <TAB> # TODO (Ned?): the ""Option"" modifier does not work properly <TAB> <TAB> #<TAB>  for Cocoa Tk and XQuartz Tk so we should not use it<TAB> <TAB> #<TAB>  in the default 'OSX' keyset.<TAB> <TAB> for k , v in result . items ( ) : <TAB> <TAB> <TAB> v2 = [ x . replace ( "" <Alt- "" , "" <Option- "" ) for x in v ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ k ] = v2 <TAB> return result ","if v != v2 : 
","if v2 :
",31.77,0.0,False
"def _load_testfile ( filename , package , module_relative ) : <TAB> if module_relative : <TAB> <TAB> package = _normalize_module ( package , 3 ) <TAB> <TAB> filename = _module_relative_path ( package , filename ) <TAB> <TAB> if hasattr ( package , "" __loader__ "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> file_contents = package . __loader__ . get_data ( filename ) <TAB> <TAB> <TAB> <TAB> # get_data() opens files as 'rb', so one must do the equivalent <TAB> <TAB> <TAB> <TAB> # conversion as universal newlines would do. <TAB> <TAB> <TAB> <TAB> return file_contents . replace ( os . linesep , "" \n "" ) , filename <TAB> return open ( filename ) . read ( ) , filename ","if hasattr ( package . __loader__ , "" get_data "" ) : 
","if hasattr ( package . __loader__ , "" get_data "" ) :
",100.0,100.0,True
"def iter_from_X_lengths ( X , lengths ) : <TAB> if lengths is None : <TAB> <TAB> yield 0 , len ( X ) <TAB> else : <TAB> <TAB> n_samples = X . shape [ 0 ] <TAB> <TAB> end = np . cumsum ( lengths ) . astype ( np . int32 ) <TAB> <TAB> start = end - lengths <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" more than  {:d}  samples in lengths array  {!s} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> n_samples , lengths <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> for i in range ( len ( lengths ) ) : <TAB> <TAB> <TAB> yield start [ i ] , end [ i ] ","if end [ - 1 ] > n_samples : 
","if n_samples > 0 :
",26.77,16.42,False
"def change_sel ( self ) : <TAB> """"""Change the view's selections."""""" <TAB> if self . alter_select and len ( self . sels ) > 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . view . show ( self . sels [ 0 ] ) <TAB> <TAB> self . view . sel ( ) . clear ( ) <TAB> <TAB> self . view . sel ( ) . add_all ( self . sels ) ","if self . multi_select is False : 
","if self . view . sel ( ) . exists ( ) :
",37.38,12.36,False
"def cb_syncthing_device_data_changed ( <TAB> self , daemon , nid , address , client_version , inbps , outbps , inbytes , outbytes ) : <TAB> if nid in self . devices :<TAB> # Should be always <TAB> <TAB> device = self . devices [ nid ] <TAB> <TAB> # Update strings <TAB> <TAB> device [ "" address "" ] = address <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> device [ "" version "" ] = client_version <TAB> <TAB> # Update rates <TAB> <TAB> device [ "" inbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( inbps ) , sizeof_fmt ( inbytes ) ) <TAB> <TAB> device [ "" outbps "" ] = "" %s /s ( %s ) "" % ( sizeof_fmt ( outbps ) , sizeof_fmt ( outbytes ) ) ","if client_version not in ( "" ? "" , None ) : 
","if client_version :
",26.33,11.69,False
"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB> <TAB> ret = [ ] <TAB> <TAB> when_response = list ( when_response ) <TAB> <TAB> for match in when_response : <TAB> <TAB> <TAB> if match not in matches : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> match . name = self . match_name <TAB> <TAB> <TAB> <TAB> matches . append ( match ) <TAB> <TAB> <TAB> <TAB> ret . append ( match ) <TAB> <TAB> return ret <TAB> if self . match_name : <TAB> <TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB> <TAB> matches . append ( when_response ) <TAB> <TAB> return when_response ","if self . match_name : 
","if self . match_name :
",100.0,100.0,True
"def __update_parents ( self , fileobj , path , delta ) : <TAB> """"""Update all parent atoms with the new size."""""" <TAB> if delta == 0 : <TAB> <TAB> return <TAB> for atom in path : <TAB> <TAB> fileobj . seek ( atom . offset ) <TAB> <TAB> size = cdata . uint_be ( fileobj . read ( 4 ) ) <TAB> <TAB> if size == 1 :<TAB> # 64bit <TAB> <TAB> <TAB> # skip name (4B) and read size (8B) <TAB> <TAB> <TAB> size = cdata . ulonglong_be ( fileobj . read ( 12 ) [ 4 : ] ) <TAB> <TAB> <TAB> fileobj . seek ( atom . offset + 8 ) <TAB> <TAB> <TAB> fileobj . write ( cdata . to_ulonglong_be ( size + delta ) ) <TAB> <TAB> else :<TAB> # 32bit <TAB> <TAB> <TAB> fileobj . seek ( atom . offset ) <TAB> <TAB> <TAB> fileobj . write ( cdata . to_uint_be ( size + delta ) ) ","if size == 1 : 
","if size == 1 :
",100.0,100.0,True
"def _fields_to_index ( cls ) : <TAB> fields = [ ] <TAB> for field in cls . _meta . sorted_fields : <TAB> <TAB> if field . primary_key : <TAB> <TAB> <TAB> continue <TAB> <TAB> requires_index = any ( <TAB> <TAB> <TAB> ( field . index , field . unique , isinstance ( field , ForeignKeyField ) ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fields . append ( field ) <TAB> return fields ","if requires_index : 
","if requires_index :
",78.12,100.0,True
"def __init__ ( self , value ) : <TAB> """"""Initialize the integer to the given value."""""" <TAB> self . _mpz_p = new_mpz ( ) <TAB> self . _initialized = False <TAB> if isinstance ( value , float ) : <TAB> <TAB> raise ValueError ( "" A floating point type is not a natural number "" ) <TAB> self . _initialized = True <TAB> if isinstance ( value , ( int , long ) ) : <TAB> <TAB> _gmp . mpz_init ( self . _mpz_p ) <TAB> <TAB> result = _gmp . gmp_sscanf ( tobytes ( str ( value ) ) , b ( "" % Zd "" ) , self . _mpz_p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Error converting  ' %d ' "" % value ) <TAB> else : <TAB> <TAB> _gmp . mpz_init_set ( self . _mpz_p , value . _mpz_p ) ","if result != 1 : 
","if result != _gmp . gmp_sscanf ( self . _mpz_p , b ( "" % Zd "" % value ) ) :
",33.49,8.52,False
"def decode ( cls , data ) : <TAB> while data : <TAB> <TAB> length , format_type , control_flags , sequence , pid = unpack ( <TAB> <TAB> <TAB> cls . Header . PACK , data [ : cls . Header . LEN ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise NetLinkError ( "" Buffer underrun "" ) <TAB> <TAB> yield cls . format ( <TAB> <TAB> <TAB> format_type , control_flags , sequence , pid , data [ cls . Header . LEN : length ] <TAB> <TAB> ) <TAB> <TAB> data = data [ length : ] ","if len ( data ) < length : 
","if length == 0 :
",26.99,7.65,False
"def __post_init__ ( self ) : <TAB> if self . _node_id is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" invalid node_id:  {} "" . format ( hexlify ( self . _node_id ) . decode ( ) ) <TAB> <TAB> <TAB> ) <TAB> if self . udp_port is not None and not 1 < = self . udp_port < = 65535 : <TAB> <TAB> raise ValueError ( "" invalid udp port "" ) <TAB> if self . tcp_port is not None and not 1 < = self . tcp_port < = 65535 : <TAB> <TAB> raise ValueError ( "" invalid tcp port "" ) <TAB> if not is_valid_public_ipv4 ( self . address , self . allow_localhost ) : <TAB> <TAB> raise ValueError ( f "" invalid ip address:  ' { self . address } ' "" ) ","if not len ( self . _node_id ) == constants . HASH_LENGTH : 
","if not is_valid_ipv4 ( self . _node_id ) :
",55.08,42.01,False
"def orderUp ( self , items ) : <TAB> sel = [ ]<TAB> # new selection <TAB> undoinfo = [ ] <TAB> for bid , lid in items : <TAB> <TAB> if isinstance ( lid , int ) : <TAB> <TAB> <TAB> undoinfo . append ( self . orderUpLineUndo ( bid , lid ) ) <TAB> <TAB> <TAB> sel . append ( ( bid , lid - 1 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> undoinfo . append ( self . orderUpBlockUndo ( bid ) ) <TAB> <TAB> <TAB> if bid == 0 : <TAB> <TAB> <TAB> <TAB> return items <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> sel . append ( ( bid - 1 , None ) ) <TAB> self . addUndo ( undoinfo , "" Move Up "" ) <TAB> return sel ","elif lid is None : 
","elif isinstance ( lid , str ) :
",27.52,7.27,False
"def filter_data ( self , min_len , max_len ) : <TAB> logging . info ( f "" filtering data, min len:  { min_len } , max len:  { max_len } "" ) <TAB> initial_len = len ( self . src ) <TAB> filtered_src = [ ] <TAB> filtered_tgt = [ ] <TAB> for src , tgt in zip ( self . src , self . tgt ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filtered_src . append ( src ) <TAB> <TAB> <TAB> filtered_tgt . append ( tgt ) <TAB> self . src = filtered_src <TAB> self . tgt = filtered_tgt <TAB> filtered_len = len ( self . src ) <TAB> logging . info ( f "" pairs before:  { initial_len } , after:  { filtered_len } "" ) ","if min_len < = len ( src ) < = max_len and min_len < = len ( tgt ) < = max_len : 
","if src > = initial_len and tgt > = min_len :
",33.34,7.88,False
"def layer_pretrained ( self , net , args , options ) : <TAB> model = getattr ( torchvision . models , args [ 0 ] ) ( pretrained = True ) <TAB> model . train ( True ) <TAB> if options . layer : <TAB> <TAB> layers = list ( model . children ( ) ) [ : options . layer ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> layers [ - 1 ] = nn . Sequential ( * layers [ - 1 ] [ : options . sublayer ] ) <TAB> else : <TAB> <TAB> layers = [ model ] <TAB> <TAB> print ( "" List of pretrained layers: "" , layers ) <TAB> <TAB> raise ValidationException ( <TAB> <TAB> <TAB> "" layer=-1 required for pretrained, sublayer=-1 optional.  Layers outputted above. "" <TAB> <TAB> ) <TAB> return nn . Sequential ( * layers ) ","if options . sublayer : 
","if options . sublayer :
",100.0,100.0,True
"def deleteCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] ) <TAB> for user in users : <TAB> <TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> gapi . call ( cal . calendarList ( ) , "" delete "" , soft_errors = True , calendarId = calendarId ) ","if not cal : 
","if not cal :
",100.0,100.0,True
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> if clients is not None : <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> if module . is_compatible_with ( client ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module ","if not clients : 
","if clients is None :
",29.25,14.06,False
"def update_me ( self ) : <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> line = self . queue . get_nowait ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . delete ( 1.0 , tk . END ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . insert ( tk . END , str ( line ) ) <TAB> <TAB> <TAB> self . see ( tk . END ) <TAB> <TAB> <TAB> self . update_idletasks ( ) <TAB> except queue . Empty : <TAB> <TAB> pass <TAB> self . after ( 100 , self . update_me ) ","if line is None : 
","if line == "" "" :
",30.25,14.54,False
"def request_power_state ( self , state , force = False ) : <TAB> if self . current_state != state or force : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . request_in_progress = True <TAB> <TAB> <TAB> logging . info ( "" Requesting  %s "" % state ) <TAB> <TAB> <TAB> cb = PowerManager . Callback ( self , state ) <TAB> <TAB> <TAB> rets = self . parent . Plugins . run ( <TAB> <TAB> <TAB> <TAB> "" on_power_state_change_requested "" , self , state , cb <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> cb . num_cb = len ( rets ) <TAB> <TAB> <TAB> cb . check ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . info ( "" Another request in progress "" ) ","if not self . request_in_progress : 
","if not self . request_in_progress :
",100.0,100.0,True
"def __getitem__ ( self , idx ) : <TAB> super ( BatchDataset , self ) . __getitem__ ( idx ) <TAB> maxidx = len ( self . dataset ) <TAB> samples = [ ] <TAB> for i in range ( 0 , self . batchsize ) : <TAB> <TAB> j = idx * self . batchsize + i <TAB> <TAB> if j > = maxidx : <TAB> <TAB> <TAB> break <TAB> <TAB> j = self . perm ( j , maxidx ) <TAB> <TAB> sample = self . dataset [ j ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> samples . append ( sample ) <TAB> samples = self . makebatch ( samples ) <TAB> return samples ","if self . filter ( sample ) : 
","if self . batchsize > 0 and self . perm ( j , self . batchsize ) :
",36.4,10.52,False
"def __call__ ( self , request , * args , * * kwargs ) : <TAB> template_vars = { } <TAB> for form_name , form_class in self . forms . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> template_vars [ form_name ] = form_class ( request ) <TAB> <TAB> else : <TAB> <TAB> <TAB> template_vars [ form_name ] = None <TAB> if request . method == "" POST "" : <TAB> <TAB> action = self . find_post_handler_action ( request ) <TAB> <TAB> form = self . handlers [ action ] ( request , data = request . POST , files = request . FILES ) <TAB> <TAB> template_vars . update ( form . dispatch ( action , request , * args , * * kwargs ) ) <TAB> return self . GET ( template_vars , request , * args , * * kwargs ) ","if form_class . must_display ( request , * args , * * kwargs ) : 
","if form_class . is_valid ( request ) :
",32.77,23.28,False
"def on_show_all ( self , widget , another ) : <TAB> if widget . get_active ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . treeview . update_items ( all = True , comment = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . treeview . update_items ( all = True ) <TAB> else : <TAB> <TAB> if another . get_active ( ) : <TAB> <TAB> <TAB> self . treeview . update_items ( comment = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . treeview . update_items ( ) ","if another . get_active ( ) : 
","if widget . get_active ( ) :
",82.41,75.06,False
"def close ( self ) : <TAB> if self . _closed : <TAB> <TAB> return <TAB> self . _closed = True <TAB> for proto in self . _pipes . values ( ) : <TAB> <TAB> if proto is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> proto . pipe . close ( ) <TAB> if ( <TAB> <TAB> self . _proc is not None <TAB> <TAB> and <TAB> <TAB> # has the child process finished? <TAB> <TAB> self . _returncode is None <TAB> <TAB> and <TAB> <TAB> # the child process has finished, but the <TAB> <TAB> # transport hasn't been notified yet? <TAB> <TAB> self . _proc . poll ( ) is None <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( "" Close running child process: kill  %r "" , self ) <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _proc . kill ( ) <TAB> <TAB> except ProcessLookupError : <TAB> <TAB> <TAB> pass ","if self . _loop . get_debug ( ) : 
","if self . _log_children :
",35.84,23.21,False
"def runTest ( self ) : <TAB> self . poco ( text = "" wait UI "" ) . click ( ) <TAB> bomb_count = 0 <TAB> while True : <TAB> <TAB> blue_fish = self . poco ( "" fish_emitter "" ) . child ( "" blue "" ) <TAB> <TAB> yellow_fish = self . poco ( "" fish_emitter "" ) . child ( "" yellow "" ) <TAB> <TAB> bomb = self . poco ( "" fish_emitter "" ) . child ( "" bomb "" ) <TAB> <TAB> fish = self . poco . wait_for_any ( [ blue_fish , yellow_fish , bomb ] ) <TAB> <TAB> if fish is bomb : <TAB> <TAB> <TAB> bomb_count + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> else : <TAB> <TAB> <TAB> fish . click ( ) <TAB> <TAB> time . sleep ( 2.5 ) ","if bomb_count > 3 : 
","if bomb_count > = 10 :
",37.76,54.11,False
"def load_managers ( * , loop , only ) : <TAB> managers = { } <TAB> for key in DB_CLASSES : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> params = DB_DEFAULTS . get ( key ) or { } <TAB> <TAB> params . update ( DB_OVERRIDES . get ( key ) or { } ) <TAB> <TAB> database = DB_CLASSES [ key ] ( * * params ) <TAB> <TAB> managers [ key ] = peewee_async . Manager ( database , loop = loop ) <TAB> return managers ","if only and key not in only : 
","if only and key not in only :
",100.0,100.0,True
"def links_extracted ( self , request , links ) : <TAB> for link in links : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r = self . _create_request ( link . url ) <TAB> <TAB> <TAB> r . meta [ b "" depth "" ] = request . meta [ b "" depth "" ] + 1 <TAB> <TAB> <TAB> self . schedule ( r , self . _get_score ( r . meta [ b "" depth "" ] ) ) <TAB> <TAB> <TAB> link . meta [ b "" state "" ] = States . QUEUED ","if link . meta [ b "" state "" ] == States . NOT_CRAWLED : 
","if link . meta [ b "" state "" ] == States . NOT_CRAWLED :
",100.0,100.0,True
"def find_worktree_git_dir ( dotgit ) : <TAB> """"""Search for a gitdir for this worktree."""""" <TAB> try : <TAB> <TAB> statbuf = os . stat ( dotgit ) <TAB> except OSError : <TAB> <TAB> return None <TAB> if not stat . S_ISREG ( statbuf . st_mode ) : <TAB> <TAB> return None <TAB> try : <TAB> <TAB> lines = open ( dotgit , "" r "" ) . readlines ( ) <TAB> <TAB> for key , value in [ line . strip ( ) . split ( "" :  "" ) for line in lines ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return value <TAB> except ValueError : <TAB> <TAB> pass <TAB> return None ","if key == "" gitdir "" : 
","if key == "" gitdir "" :
",100.0,100.0,True
"def _is_static_shape ( self , shape ) : <TAB> if shape is None or not isinstance ( shape , list ) : <TAB> <TAB> return False <TAB> for dim_value in shape : <TAB> <TAB> if not isinstance ( dim_value , int ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( "" Negative dimension is illegal:  %d "" % dim_value ) <TAB> return True ","if dim_value < 0 : 
","if dim_value < 0 :
",100.0,100.0,True
"def init_logger ( ) : <TAB> configured_loggers = [ log_config . get ( "" root "" , { } ) ] + [ <TAB> <TAB> logger for logger in log_config . get ( "" loggers "" , { } ) . values ( ) <TAB> ] <TAB> used_handlers = { <TAB> <TAB> handler for log in configured_loggers for handler in log . get ( "" handlers "" , [ ] ) <TAB> } <TAB> for handler_id , handler in list ( log_config [ "" handlers "" ] . items ( ) ) : <TAB> <TAB> if handler_id not in used_handlers : <TAB> <TAB> <TAB> del log_config [ "" handlers "" ] [ handler_id ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = handler [ "" filename "" ] <TAB> <TAB> <TAB> logfile_path = Path ( filename ) . expanduser ( ) . resolve ( ) <TAB> <TAB> <TAB> handler [ "" filename "" ] = str ( logfile_path ) <TAB> logging . config . dictConfig ( log_config ) ","elif "" filename "" in handler . keys ( ) : 
","if "" filename "" in handler :
",46.75,36.34,False
"def __call__ ( self ) : <TAB> dmin , dmax = self . viewlim_to_dt ( ) <TAB> ymin = self . base . le ( dmin . year ) <TAB> ymax = self . base . ge ( dmax . year ) <TAB> ticks = [ dmin . replace ( year = ymin , * * self . replaced ) ] <TAB> while 1 : <TAB> <TAB> dt = ticks [ - 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return date2num ( ticks ) <TAB> <TAB> year = dt . year + self . base . get_base ( ) <TAB> <TAB> ticks . append ( dt . replace ( year = year , * * self . replaced ) ) ","if dt . year > = ymax : 
","if dt . month == 0 and dt . day == ymax :
",36.94,16.45,False
"def taiga ( request , trigger_id , key ) : <TAB> signature = request . META . get ( "" HTTP_X_TAIGA_WEBHOOK_SIGNATURE "" ) <TAB> # check that the data are ok with the provided signature <TAB> if verify_signature ( request . _request . body , key , signature ) : <TAB> <TAB> data = data_filter ( trigger_id , * * request . data ) <TAB> <TAB> status = save_data ( trigger_id , data ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> Response ( { "" message "" : "" Success "" } ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else Response ( { "" message "" : "" Failed! "" } ) <TAB> <TAB> ) <TAB> Response ( { "" message "" : "" Bad request "" } ) ","if status 
","if status
",65.81,0.0,False
"def ParseResponses ( <TAB> self , <TAB> knowledge_base : rdf_client . KnowledgeBase , <TAB> responses : Iterable [ rdfvalue . RDFValue ] , ) - > Iterator [ rdf_client . User ] : <TAB> for response in responses : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( f "" Unexpected response type: ` { type ( response ) } ` "" ) <TAB> <TAB> # TODO: `st_mode` has to be an `int`, not `StatMode`. <TAB> <TAB> if stat . S_ISDIR ( int ( response . st_mode ) ) : <TAB> <TAB> <TAB> homedir = response . pathspec . path <TAB> <TAB> <TAB> username = os . path . basename ( homedir ) <TAB> <TAB> <TAB> if username not in self . _ignore_users : <TAB> <TAB> <TAB> <TAB> yield rdf_client . User ( username = username , homedir = homedir ) ","if not isinstance ( response , rdf_client_fs . StatEntry ) : 
","if not isinstance ( response , rdfvalue . RDFValue ) :
",77.04,37.18,False
"def _iter_lines ( path = path , response = response , max_next = options . http_max_next ) : <TAB> path . responses = [ ] <TAB> n = 0 <TAB> while response : <TAB> <TAB> path . responses . append ( response ) <TAB> <TAB> yield from response . iter_lines ( decode_unicode = True ) <TAB> <TAB> src = response . links . get ( "" next "" , { } ) . get ( "" url "" , None ) <TAB> <TAB> if not src : <TAB> <TAB> <TAB> break <TAB> <TAB> n + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vd . warning ( f "" stopping at max  { max_next }  pages "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> vd . status ( f "" fetching next page from  { src } "" ) <TAB> <TAB> response = requests . get ( src , stream = True ) ","if n > max_next : 
","if n > = max_next :
",39.71,50.0,False
"def __enter__ ( self ) : <TAB> """"""Open a file and read it."""""" <TAB> if self . code is None : <TAB> <TAB> LOGGER . info ( "" File is reading:  %s "" , self . path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _file = open ( self . path , encoding = "" utf-8 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _file = open ( self . path , "" rU "" ) <TAB> <TAB> self . code = self . _file . read ( ) <TAB> return self ","if sys . version_info > = ( 3 , ) : 
","if sys . version_info > ( 3 , 0 ) :
",55.03,62.34,False
"def facts_for_oauthclients ( self , namespace ) : <TAB> """"""Gathers facts for oauthclients used with logging"""""" <TAB> self . default_keys_for ( "" oauthclients "" ) <TAB> a_list = self . oc_command ( <TAB> <TAB> "" get "" , "" oauthclients "" , namespace = namespace , add_options = [ "" -l "" , LOGGING_SELECTOR ] <TAB> ) <TAB> if len ( a_list [ "" items "" ] ) == 0 : <TAB> <TAB> return <TAB> for item in a_list [ "" items "" ] : <TAB> <TAB> name = item [ "" metadata "" ] [ "" name "" ] <TAB> <TAB> comp = self . comp ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = dict ( redirectURIs = item [ "" redirectURIs "" ] ) <TAB> <TAB> <TAB> self . add_facts_for ( comp , "" oauthclients "" , name , result ) ","if comp is not None : 
","if comp is not None :
",100.0,100.0,True
"def get ( self , k ) : <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _data1 [ k ] = self . _data2 [ k ] <TAB> <TAB> <TAB> del self . _data2 [ k ] <TAB> return self . _data1 . get ( k ) ","if k not in self . _data1 and k in self . _data2 : 
","if k in self . _data2 :
",54.82,33.24,False
"def _parseparam ( s ) : <TAB> plist = [ ] <TAB> while s [ : 1 ] == "" ; "" : <TAB> <TAB> s = s [ 1 : ] <TAB> <TAB> end = s . find ( "" ; "" ) <TAB> <TAB> while end > 0 and ( s . count ( ' "" ' , 0 , end ) - s . count ( ' \\ "" ' , 0 , end ) ) % 2 : <TAB> <TAB> <TAB> end = s . find ( "" ; "" , end + 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> end = len ( s ) <TAB> <TAB> f = s [ : end ] <TAB> <TAB> if "" = "" in f : <TAB> <TAB> <TAB> i = f . index ( "" = "" ) <TAB> <TAB> <TAB> f = f [ : i ] . strip ( ) . lower ( ) + "" = "" + f [ i + 1 : ] . strip ( ) <TAB> <TAB> plist . append ( f . strip ( ) ) <TAB> <TAB> s = s [ end : ] <TAB> return plist ","if end < 0 : 
","if end < 0 :
",100.0,100.0,True
"def __init__ ( self , * * params ) : <TAB> if "" length "" in params : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" Supply either length or start and end to Player not both "" ) <TAB> <TAB> params [ "" start "" ] = 0 <TAB> <TAB> params [ "" end "" ] = params . pop ( "" length "" ) - 1 <TAB> elif params . get ( "" start "" , 0 ) > 0 and not "" value "" in params : <TAB> <TAB> params [ "" value "" ] = params [ "" start "" ] <TAB> super ( Player , self ) . __init__ ( * * params ) ","if "" start "" in params or "" end "" in params : 
","if params . get ( "" start "" , 0 ) != params . get ( "" end "" , 0 ) :
",37.37,11.19,False
"def libcxx_define ( settings ) : <TAB> compiler = _base_compiler ( settings ) <TAB> libcxx = settings . get_safe ( "" compiler.libcxx "" ) <TAB> if not compiler or not libcxx : <TAB> <TAB> return "" "" <TAB> if str ( compiler ) in GCC_LIKE : <TAB> <TAB> if str ( libcxx ) == "" libstdc++ "" : <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=0 "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" _GLIBCXX_USE_CXX11_ABI=1 "" <TAB> return "" "" ","elif str ( libcxx ) == "" libstdc++11 "" : 
","if str ( libcxx ) == "" libstdc++ "" :
",60.04,73.25,False
"def _get_sort_map ( tags ) : <TAB> """"""See TAG_TO_SORT"""""" <TAB> tts = { } <TAB> for name , tag in tags . items ( ) : <TAB> <TAB> if tag . has_sort : <TAB> <TAB> <TAB> if tag . user : <TAB> <TAB> <TAB> <TAB> tts [ name ] = "" %s sort "" % name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tts [ "" ~ %s "" % name ] = "" ~ %s sort "" % name <TAB> return tts ","if tag . internal : 
","elif tag . is_active :
",30.86,14.54,False
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> if value . has_form ( "" List "" , None ) : <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> if any ( item is None for item in value ) : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> return value ","if value is None or isinf ( value ) or isnan ( value ) : 
","if not has_form ( "" Error "" , None ) :
",26.77,6.66,False
"def on_action_chosen ( self , id , action , mark_changed = True ) : <TAB> before = self . set_action ( self . current , id , action ) <TAB> if mark_changed : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # TODO: Maybe better comparison <TAB> <TAB> <TAB> self . undo . append ( UndoRedo ( id , before , action ) ) <TAB> <TAB> <TAB> self . builder . get_object ( "" btUndo "" ) . set_sensitive ( True ) <TAB> <TAB> self . on_profile_modified ( ) <TAB> else : <TAB> <TAB> self . on_profile_modified ( update_ui = False ) <TAB> return before ","if before . to_string ( ) != action . to_string ( ) : 
","if self . builder . get_object ( "" btUndo "" ) . get_sensitive ( ) :
",40.6,9.63,False
"def setUp ( self ) : <TAB> super ( OperaterTest , self ) . setUp ( ) <TAB> if is_cli : <TAB> <TAB> import clr <TAB> <TAB> self . load_iron_python_test ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> clr . AddReference ( "" System.Drawing.Primitives "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> clr . AddReference ( "" System.Drawing "" ) ","if is_netcoreapp : 
","if hasattr ( OperaterTest , "" Primitives "" ) :
",29.22,4.99,False
"def field_to_field_type ( field ) : <TAB> field_type = field [ "" type "" ] <TAB> if isinstance ( field_type , dict ) : <TAB> <TAB> field_type = field_type [ "" type "" ] <TAB> if isinstance ( field_type , list ) : <TAB> <TAB> field_type_length = len ( field_type ) <TAB> <TAB> if field_type_length == 0 : <TAB> <TAB> <TAB> raise Exception ( "" Zero-length type list encountered, invalid CWL? "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field_type = field_type [ 0 ] <TAB> return field_type ","elif len ( field_type ) == 1 : 
","if field_type_length == 1 :
",31.75,34.38,False
"def _flatten ( * args ) : <TAB> ahs = set ( ) <TAB> if len ( args ) > 0 : <TAB> <TAB> for item in args : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ahs . add ( item ) <TAB> <TAB> <TAB> elif type ( item ) in ( list , tuple , dict , set ) : <TAB> <TAB> <TAB> <TAB> for ah in item : <TAB> <TAB> <TAB> <TAB> <TAB> if type ( ah ) is not ActionHandle :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( ah ) ) <TAB> <TAB> <TAB> <TAB> <TAB> ahs . add ( ah ) <TAB> <TAB> <TAB> else :<TAB> # pragma:nocover <TAB> <TAB> <TAB> <TAB> raise ActionManagerError ( "" Bad argument type  %s "" % str ( item ) ) <TAB> return ahs ","if type ( item ) is ActionHandle : 
","if type ( item ) is not ActionHandle :
",85.65,66.06,False
"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> configTokens = black . configure . items [ "" configTokens "" ] . Get ( ) <TAB> buildFlavour = black . configure . items [ "" buildFlavour "" ] . Get ( ) <TAB> if buildFlavour == "" full "" : <TAB> <TAB> self . value = False <TAB> else : <TAB> <TAB> self . value = True <TAB> for opt , optarg in self . chosenOptions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not self . value : <TAB> <TAB> <TAB> <TAB> configTokens . append ( "" tests "" ) <TAB> <TAB> <TAB> self . value = True <TAB> <TAB> elif opt == "" --without-tests "" : <TAB> <TAB> <TAB> if self . value : <TAB> <TAB> <TAB> <TAB> configTokens . append ( "" notests "" ) <TAB> <TAB> <TAB> self . value = False <TAB> self . determined = 1 ","if opt == "" --with-tests "" : 
","if opt == "" --tests "" :
",74.63,59.46,False
"def title_by_index ( self , trans , index , context ) : <TAB> d_type = self . get_datatype ( trans , context ) <TAB> for i , ( composite_name , composite_file ) in enumerate ( d_type . writable_files . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rval = composite_name <TAB> <TAB> <TAB> if composite_file . description : <TAB> <TAB> <TAB> <TAB> rval = "" {}  ( {} ) "" . format ( rval , composite_file . description ) <TAB> <TAB> <TAB> if composite_file . optional : <TAB> <TAB> <TAB> <TAB> rval = "" %s  [optional] "" % rval <TAB> <TAB> <TAB> return rval <TAB> if index < self . get_file_count ( trans , context ) : <TAB> <TAB> return "" Extra primary file "" <TAB> return None ","if i == index : 
","if i == index :
",100.0,100.0,True
"def func ( x , y ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> z = x + 2 * math . sin ( y ) <TAB> <TAB> <TAB> return z * * 2 <TAB> <TAB> elif x == y : <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else : <TAB> <TAB> <TAB> return 2 * * 3 <TAB> except ValueError : <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> foo + = i <TAB> <TAB> return foo <TAB> except TypeError : <TAB> <TAB> return 42 <TAB> else : <TAB> <TAB> return 33 <TAB> finally : <TAB> <TAB> print ( "" finished "" ) ","if x > y : 
","if x > y :
",100.0,100.0,True
"def test_suite ( ) : <TAB> suite = unittest . TestSuite ( ) <TAB> for fn in os . listdir ( here ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> modname = "" distutils.tests. "" + fn [ : - 3 ] <TAB> <TAB> <TAB> __import__ ( modname ) <TAB> <TAB> <TAB> module = sys . modules [ modname ] <TAB> <TAB> <TAB> suite . addTest ( module . test_suite ( ) ) <TAB> return suite ","if fn . startswith ( "" test "" ) and fn . endswith ( "" .py "" ) : 
","if fn . endswith ( "" .py "" ) and fn . endswith ( "" .py "" ) :
",85.62,68.92,False
"def check_stack_names ( self , frame , expected ) : <TAB> names = [ ] <TAB> while frame : <TAB> <TAB> name = frame . f_code . co_name <TAB> <TAB> # Stop checking frames when we get to our test helper. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> names . append ( name ) <TAB> <TAB> frame = frame . f_back <TAB> self . assertEqual ( names , expected ) ","if name . startswith ( "" check_ "" ) or name . startswith ( "" call_ "" ) : 
","if name in names :
",25.87,0.96,False
"def leave ( self , reason = None ) : <TAB> try : <TAB> <TAB> if self . id . startswith ( "" C "" ) : <TAB> <TAB> <TAB> log . info ( "" Leaving channel  %s  ( %s ) "" , self , self . id ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Leaving group  %s  ( %s ) "" , self , self . id ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.leave "" , data = { "" channel "" : self . id } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to leave channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e ) <TAB> self . _id = None ","if e . error == "" user_is_bot "" : 
","if e . error == "" user_is_bot "" :
",100.0,100.0,True
"def ident ( self ) : <TAB> value = self . _ident <TAB> if value is False : <TAB> <TAB> value = None <TAB> <TAB> # XXX: how will this interact with orig_prefix ? <TAB> <TAB> #<TAB>   not exposing attrs for now if orig_prefix is set.<TAB> <TAB> <MASK> <TAB> <TAB> <TAB> wrapped = self . wrapped <TAB> <TAB> <TAB> ident = getattr ( wrapped , "" ident "" , None ) <TAB> <TAB> <TAB> if ident is not None : <TAB> <TAB> <TAB> <TAB> value = self . _wrap_hash ( ident ) <TAB> <TAB> self . _ident = value <TAB> return value ","if not self . orig_prefix : 
","if self . _prefix is not None :
",35.88,15.51,False
"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> if f . read ( 1 ) == "" 1 "" : <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError : <TAB> <TAB> <TAB> continue <TAB> return False ","if f . read ( ) . strip ( ) != "" Mains "" : 
","if f . read ( 1 ) != "" 0 "" :
",48.34,41.81,False
"def _get_pending_by_app_token ( self , app_token ) : <TAB> result = [ ] <TAB> with self . _pending_lock : <TAB> <TAB> self . _remove_stale_pending ( ) <TAB> <TAB> for data in self . _pending_decisions : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result . append ( data ) <TAB> return result ","if data . app_token == app_token : 
","if data . app_token == app_token :
",100.0,100.0,True
"def do_create ( specific_tables = None , base = Base ) : <TAB> engine = get_engine ( ) <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> <TAB> "" Initializing only a subset of tables as requested:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> specific_tables <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> base . metadata . create_all ( engine , tables = specific_tables ) <TAB> <TAB> else : <TAB> <TAB> <TAB> base . metadata . create_all ( engine ) <TAB> except Exception as err : <TAB> <TAB> raise Exception ( "" could not create/re-create DB tables - exception:  "" + str ( err ) ) ","if specific_tables : 
","if specific_tables :
",78.12,100.0,True
"def __setitem__ ( self , ndx , val ) : <TAB> # <TAB> # Get the expression data object <TAB> # <TAB> exprdata = None <TAB> if ndx in self . _data : <TAB> <TAB> exprdata = self . _data [ ndx ] <TAB> else : <TAB> <TAB> _ndx = normalize_index ( ndx ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> exprdata = self . _data [ _ndx ] <TAB> if exprdata is None : <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> "" Cannot set the value of Expression  ' %s '  with  "" <TAB> <TAB> <TAB> "" invalid index  ' %s ' "" % ( self . cname ( True ) , str ( ndx ) ) <TAB> <TAB> ) <TAB> # <TAB> # Set the value <TAB> # <TAB> exprdata . set_value ( val ) ","if _ndx in self . _data : 
","if _ndx > = 0 :
",29.0,19.74,False
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> if self . bitnum == 8 : <TAB> <TAB> <TAB> if self . bytenum == len ( self . bytestream ) - 1 : <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1 ","if not self . bytestream : 
","if self . bytenum > len ( self . bytestream ) :
",39.02,14.32,False
"def terminate_subprocess ( proc , timeout = 0.1 , log = None ) : <TAB> if proc . poll ( ) is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Sending SIGTERM to  %r "" , proc ) <TAB> <TAB> proc . terminate ( ) <TAB> <TAB> timeout_time = time . time ( ) + timeout <TAB> <TAB> while proc . poll ( ) is None and time . time ( ) < timeout_time : <TAB> <TAB> <TAB> time . sleep ( 0.02 ) <TAB> <TAB> if proc . poll ( ) is None : <TAB> <TAB> <TAB> if log : <TAB> <TAB> <TAB> <TAB> log . info ( "" Sending SIGKILL to  %r "" , proc ) <TAB> <TAB> <TAB> proc . kill ( ) <TAB> return proc . returncode ","if log : 
","if log :
",78.12,0.0,False
"def mkpanel ( color , rows , cols , tly , tlx ) : <TAB> win = curses . newwin ( rows , cols , tly , tlx ) <TAB> pan = panel . new_panel ( win ) <TAB> if curses . has_colors ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fg = curses . COLOR_WHITE <TAB> <TAB> else : <TAB> <TAB> <TAB> fg = curses . COLOR_BLACK <TAB> <TAB> bg = color <TAB> <TAB> curses . init_pair ( color , fg , bg ) <TAB> <TAB> win . bkgdset ( ord ( "" "" ) , curses . color_pair ( color ) ) <TAB> else : <TAB> <TAB> win . bkgdset ( ord ( "" "" ) , curses . A_BOLD ) <TAB> return pan ","if color == curses . COLOR_BLUE : 
","if color == curses . COLOR_BLACKLIST :
",82.41,78.25,False
"def all_words ( filename ) : <TAB> start_char = True <TAB> for c in characters ( filename ) : <TAB> <TAB> if start_char == True : <TAB> <TAB> <TAB> word = "" "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # We found the start of a word <TAB> <TAB> <TAB> <TAB> word = c . lower ( ) <TAB> <TAB> <TAB> <TAB> start_char = False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> if c . isalnum ( ) : <TAB> <TAB> <TAB> <TAB> word + = c . lower ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # We found end of word, emit it <TAB> <TAB> <TAB> <TAB> start_char = True <TAB> <TAB> <TAB> <TAB> yield word ","if c . isalnum ( ) : 
","if c . isalnum ( ) :
",100.0,100.0,True
"def get_tf_weights_as_numpy ( path = "" ./ckpt/aeslc/model.ckpt-32000 "" ) - > Dict : <TAB> init_vars = tf . train . list_variables ( path ) <TAB> tf_weights = { } <TAB> ignore_name = [ "" Adafactor "" , "" global_step "" ] <TAB> for name , shape in tqdm ( init_vars , desc = "" converting tf checkpoint to dict "" ) : <TAB> <TAB> skip_key = any ( [ pat in name for pat in ignore_name ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> array = tf . train . load_variable ( path , name ) <TAB> <TAB> tf_weights [ name ] = array <TAB> return tf_weights ","if skip_key : 
","if skip_key :
",78.12,100.0,True
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif message [ "" type "" ] == "" websocket.disconnect "" : <TAB> <TAB> <TAB> break ","elif message [ "" type "" ] == "" websocket.receive "" : 
","elif message [ "" type "" ] == "" websocket.receive "" :
",100.0,100.0,True
"def autoload ( self ) : <TAB> if self . _app . config . THEME == "" auto "" : <TAB> <TAB> if sys . platform == "" darwin "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> theme = DARK <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> theme = LIGHT <TAB> <TAB> else : <TAB> <TAB> <TAB> theme = self . guess_system_theme ( ) <TAB> <TAB> <TAB> if theme == Dark : <TAB> <TAB> <TAB> <TAB> theme = MacOSDark <TAB> else :<TAB> # user settings have highest priority <TAB> <TAB> theme = self . _app . config . THEME <TAB> self . load_theme ( theme ) ","if get_osx_theme ( ) == 1 : 
","if self . _app . config .THEME_BASE == "" DARK "" :
",26.76,6.02,False
"def example_reading_spec ( self ) : <TAB> data_fields = { "" targets "" : tf . VarLenFeature ( tf . int64 ) } <TAB> <MASK> <TAB> <TAB> data_fields [ "" inputs "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> if self . packed_length : <TAB> <TAB> if self . has_inputs : <TAB> <TAB> <TAB> data_fields [ "" inputs_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> <TAB> data_fields [ "" inputs_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> data_fields [ "" targets_segmentation "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> <TAB> data_fields [ "" targets_position "" ] = tf . VarLenFeature ( tf . int64 ) <TAB> data_items_to_decoders = None <TAB> return ( data_fields , data_items_to_decoders ) ","if self . has_inputs : 
","if self . has_inputs :
",100.0,100.0,True
"def _prepare_travel_graph ( self ) : <TAB> for op in self . op_dict . values ( ) : <TAB> <TAB> op . const = False <TAB> <TAB> if op . node . op in [ "" Const "" , "" Placeholder "" ] : <TAB> <TAB> <TAB> op . resolved = True <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> op . const = True <TAB> <TAB> else : <TAB> <TAB> <TAB> op . resolved = False ","if op . node . op == "" Const "" : 
","elif op . node . op in [ "" Const "" , "" Placeholder "" ] :
",47.72,29.49,False
"def get_filestream_file_items ( self ) : <TAB> data = { } <TAB> fs_file_updates = self . get_filestream_file_updates ( ) <TAB> for k , v in six . iteritems ( fs_file_updates ) : <TAB> <TAB> l = [ ] <TAB> <TAB> for d in v : <TAB> <TAB> <TAB> offset = d . get ( "" offset "" ) <TAB> <TAB> <TAB> content = d . get ( "" content "" ) <TAB> <TAB> <TAB> assert offset is not None <TAB> <TAB> <TAB> assert content is not None <TAB> <TAB> <TAB> assert offset == 0 or offset == len ( l ) , ( k , v , l , d ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> l = [ ] <TAB> <TAB> <TAB> l . extend ( map ( json . loads , content ) ) <TAB> <TAB> data [ k ] = l <TAB> return data ","if not offset : 
","if len ( l ) == 0 :
",28.21,5.67,False
"def _rewrite_exprs ( self , table , what ) : <TAB> from ibis . expr . analysis import substitute_parents <TAB> what = util . promote_list ( what ) <TAB> all_exprs = [ ] <TAB> for expr in what : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> all_exprs . extend ( expr . exprs ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> bound_expr = ir . bind_expr ( table , expr ) <TAB> <TAB> <TAB> all_exprs . append ( bound_expr ) <TAB> return [ substitute_parents ( x , past_projection = False ) for x in all_exprs ] ","if isinstance ( expr , ir . ExprList ) : 
","if isinstance ( expr , ibis . expr . Expr ) :
",51.31,37.7,False
"def _group_by_commit_and_time ( self , hits ) : <TAB> result = { } <TAB> for hit in hits : <TAB> <TAB> source_hit = hit [ "" _source "" ] <TAB> <TAB> key = "" %s _ %s "" % ( source_hit [ "" commit_info "" ] [ "" id "" ] , source_hit [ "" datetime "" ] ) <TAB> <TAB> benchmark = self . _benchmark_from_es_record ( source_hit ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ key ] [ "" benchmarks "" ] . append ( benchmark ) <TAB> <TAB> else : <TAB> <TAB> <TAB> run_info = self . _run_info_from_es_record ( source_hit ) <TAB> <TAB> <TAB> run_info [ "" benchmarks "" ] = [ benchmark ] <TAB> <TAB> <TAB> result [ key ] = run_info <TAB> return result ","if key in result : 
","if key in result :
",100.0,100.0,True
"def _build_index ( self ) : <TAB> self . _index = { } <TAB> for start_char , sorted_offsets in self . _offsets . items ( ) : <TAB> <TAB> self . _index [ start_char ] = { } <TAB> <TAB> for i , offset in enumerate ( sorted_offsets . get_offsets ( ) ) : <TAB> <TAB> <TAB> identifier = sorted_offsets . get_identifier_by_offset ( offset ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _index [ start_char ] [ identifier [ 0 : self . index_depth ] ] = i ","if identifier [ 0 : self . index_depth ] not in self . _index [ start_char ] : 
","if identifier :
",25.73,0.0,False
"def scan_resource_conf ( self , conf ) : <TAB> if "" properties "" in conf : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" exp "" in conf [ "" properties "" ] [ "" attributes "" ] : <TAB> <TAB> <TAB> <TAB> if conf [ "" properties "" ] [ "" attributes "" ] [ "" exp "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> return CheckResult . PASSED <TAB> return CheckResult . FAILED ","if "" attributes "" in conf [ "" properties "" ] : 
","if "" attributes "" in conf [ "" properties "" ] :
",100.0,100.0,True
"def _PatchArtifact ( self , artifact : rdf_artifacts . Artifact ) - > rdf_artifacts . Artifact : <TAB> """"""Patches artifact to not contain byte-string source attributes."""""" <TAB> patched = False <TAB> for source in artifact . sources : <TAB> <TAB> attributes = source . attributes . ToDict ( ) <TAB> <TAB> unicode_attributes = compatibility . UnicodeJson ( attributes ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source . attributes = unicode_attributes <TAB> <TAB> <TAB> patched = True <TAB> if patched : <TAB> <TAB> self . DeleteArtifact ( str ( artifact . name ) ) <TAB> <TAB> self . WriteArtifact ( artifact ) <TAB> return artifact ","if attributes != unicode_attributes : 
","if unicode_attributes . get ( "" type "" ) == "" byte "" :
",27.36,10.12,False
"def edit_file ( self , filename ) : <TAB> import subprocess <TAB> editor = self . get_editor ( ) <TAB> if self . env : <TAB> <TAB> environ = os . environ . copy ( ) <TAB> <TAB> environ . update ( self . env ) <TAB> else : <TAB> <TAB> environ = None <TAB> try : <TAB> <TAB> c = subprocess . Popen ( ' %s "" %s "" ' % ( editor , filename ) , env = environ , shell = True ) <TAB> <TAB> exit_code = c . wait ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ClickException ( "" %s : Editing failed! "" % editor ) <TAB> except OSError as e : <TAB> <TAB> raise ClickException ( "" %s : Editing failed:  %s "" % ( editor , e ) ) ","if exit_code != 0 : 
","if exit_code != 0 :
",100.0,100.0,True
"def findControlPointsInMesh ( glyph , va , subsegments ) : <TAB> controlPointIndices = np . zeros ( ( len ( va ) , 1 ) ) <TAB> index = 0 <TAB> for i , c in enumerate ( subsegments ) : <TAB> <TAB> segmentCount = len ( glyph . contours [ i ] . segments ) - 1 <TAB> <TAB> for j , s in enumerate ( c ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if glyph . contours [ i ] . segments [ j ] . type == "" line "" : <TAB> <TAB> <TAB> <TAB> <TAB> controlPointIndices [ index ] = 1 <TAB> <TAB> <TAB> index + = s [ 1 ] <TAB> return controlPointIndices ","if j < segmentCount : 
","if s [ 0 ] == va and s [ 0 ] == s [ 1 ] :
",27.14,2.28,False
"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated ( request . version , self . min_version ) <TAB> <TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB> <TAB> social = value . copy ( ) <TAB> <TAB> for key in old_social_string_fields : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> social [ key ] = value [ key ] [ 0 ] <TAB> <TAB> <TAB> elif social . get ( key ) == [ ] : <TAB> <TAB> <TAB> <TAB> social [ key ] = "" "" <TAB> <TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value ) ","if social . get ( key ) : 
","if isinstance ( value [ key ] , tuple ) :
",28.19,9.43,False
"def iter_raw_frames ( path , packet_sizes , ctx ) : <TAB> with open ( path , "" rb "" ) as f : <TAB> <TAB> for i , size in enumerate ( packet_sizes ) : <TAB> <TAB> <TAB> packet = Packet ( size ) <TAB> <TAB> <TAB> read_size = f . readinto ( packet ) <TAB> <TAB> <TAB> assert size <TAB> <TAB> <TAB> assert read_size == size <TAB> <TAB> <TAB> if not read_size : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in ctx . decode ( packet ) : <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> while True : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> frames = ctx . decode ( None ) <TAB> <TAB> <TAB> except EOFError : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> for frame in frames : <TAB> <TAB> <TAB> <TAB> yield frame <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break ","if not frames : 
","if not frames :
",100.0,100.0,True
"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB> <TAB> already_test = [ ] <TAB> <TAB> for fname in lib_zip . namelist ( ) : <TAB> <TAB> <TAB> pname , fname = os . path . split ( fname ) <TAB> <TAB> <TAB> if fname or ( pname and fname ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and "" / "" not in pname : <TAB> <TAB> <TAB> <TAB> already_test . append ( pname ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs ","if is_shadowing ( pname ) : 
","if pname . endswith ( "" .shadow "" ) :
",29.17,9.43,False
"def metrics_to_scalars ( self , metrics ) : <TAB> new_metrics = { } <TAB> for k , v in metrics . items ( ) : <TAB> <TAB> if isinstance ( v , torch . Tensor ) : <TAB> <TAB> <TAB> v = v . item ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = self . metrics_to_scalars ( v ) <TAB> <TAB> new_metrics [ k ] = v <TAB> return new_metrics ","if isinstance ( v , dict ) : 
","elif isinstance ( v , dict ) :
",77.52,84.09,False
"def insert_resets ( f ) : <TAB> newsync = dict ( ) <TAB> for k , v in f . sync . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newsync [ k ] = insert_reset ( ResetSignal ( k ) , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> newsync [ k ] = v <TAB> f . sync = newsync ","if f . clock_domains [ k ] . rst is not None : 
","if isinstance ( v , ResetSignal ) :
",25.94,2.74,False
"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB> <TAB> if node is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings . external_account == external_account : <TAB> <TAB> <TAB> yield node ","if node_settings is None : 
","if node_settings is None :
",100.0,100.0,True
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> if isinstance ( test , ast . Const ) : <TAB> <TAB> <TAB> if type ( test . value ) in self . _const_types : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope ) ","if not test . value : 
","if test . value in scope :
",41.27,27.78,False
"def flatten ( self ) : <TAB> # this is similar to fill_messages except it uses a list instead <TAB> # of a queue to place the messages in. <TAB> result = [ ] <TAB> channel = await self . messageable . _get_channel ( ) <TAB> self . channel = channel <TAB> while self . _get_retrieve ( ) : <TAB> <TAB> data = await self . _retrieve_messages ( self . retrieve ) <TAB> <TAB> if len ( data ) < 100 : <TAB> <TAB> <TAB> self . limit = 0<TAB> # terminate the infinite loop <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = reversed ( data ) <TAB> <TAB> if self . _filter : <TAB> <TAB> <TAB> data = filter ( self . _filter , data ) <TAB> <TAB> for element in data : <TAB> <TAB> <TAB> result . append ( self . state . create_message ( channel = channel , data = element ) ) <TAB> return result ","if self . reverse : 
","if self . reverse :
",100.0,100.0,True
"def compute ( self , x , y = None , targets = None ) : <TAB> if targets is None : <TAB> <TAB> targets = self . out_params <TAB> in_params = list ( self . in_x ) <TAB> if len ( in_params ) == 1 : <TAB> <TAB> args = [ x ] <TAB> else : <TAB> <TAB> args = list ( zip ( * x ) ) <TAB> if y is None : <TAB> <TAB> pipe = self . pipe <TAB> else : <TAB> <TAB> pipe = self . train_pipe <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . append ( y ) <TAB> <TAB> else : <TAB> <TAB> <TAB> args + = list ( zip ( * y ) ) <TAB> <TAB> in_params + = self . in_y <TAB> return self . _compute ( * args , pipe = pipe , param_names = in_params , targets = targets ) ","if len ( self . in_y ) == 1 : 
","if len ( y ) == 1 :
",44.51,47.94,False
"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys . path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module = self . fs_imp . import_from_dir ( item , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> module = item . import_top ( name ) <TAB> <TAB> if module : <TAB> <TAB> <TAB> return module <TAB> return None ","if isinstance ( item , _StringType ) : 
","if os . path . isdir ( item ) :
",28.97,12.55,False
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> if isinstance ( key , ( int , long ) ) : <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> elif isinstance ( key , slice ) : <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB> <TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key ) ","if k . lower ( ) == ikey : 
","if k . lower ( ) == ikey :
",100.0,100.0,True
"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB> <TAB> if key == "" hooks "" : <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name , _val in val . items ( ) : <TAB> <TAB> <TAB> <TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> new_action = watcher . set_opt ( key , val ) <TAB> <TAB> if new_action == 1 : <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher . do_action ( action ) ","if action == 1 : 
","if action == 1 :
",100.0,100.0,True
"def OnBodyClick ( self , event = None ) : <TAB> try : <TAB> <TAB> c = self . c <TAB> <TAB> p = c . currentPosition ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . OnActivateBody ( event = event ) <TAB> <TAB> g . doHook ( "" bodyclick2 "" , c = c , p = p , v = p , event = event ) <TAB> except : <TAB> <TAB> g . es_event_exception ( "" bodyclick "" ) ","if not g . doHook ( "" bodyclick1 "" , c = c , p = p , v = p , event = event ) : 
","if not g . doHook ( "" bodyclick1 "" , c = c , p = p , v = p , event = event ) :
",100.0,100.0,True
"def _class_weights ( spec : config . MetricsSpec ) - > Optional [ Dict [ int , float ] ] : <TAB> """"""Returns class weights associated with AggregationOptions at offset."""""" <TAB> if spec . aggregate . HasField ( "" top_k_list "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" class_weights are not supported when top_k_list used:  "" <TAB> <TAB> <TAB> <TAB> "" spec= {} "" . format ( spec ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return None <TAB> return dict ( spec . aggregate . class_weights ) or None ","if spec . aggregate . class_weights : 
","if spec . aggregate . field . top_k_list :
",65.5,31.46,False
"def _is_perf_file ( file_path ) : <TAB> f = get_file ( file_path ) <TAB> for line in f : <TAB> <TAB> if line [ 0 ] == "" # "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> r = event_regexp . search ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> f . close ( ) <TAB> <TAB> return False ","if r : 
","if r :
",78.12,0.0,False
"def _get_before_insertion_node ( self ) : <TAB> if self . _nodes_stack . is_empty ( ) : <TAB> <TAB> return None <TAB> line = self . _nodes_stack . parsed_until_line + 1 <TAB> node = self . _new_module . get_last_leaf ( ) <TAB> while True : <TAB> <TAB> parent = node . parent <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert node . end_pos [ 0 ] < = line <TAB> <TAB> <TAB> assert node . end_pos [ 1 ] == 0 or "" \n "" in self . _prefix <TAB> <TAB> <TAB> return node <TAB> <TAB> node = parent ","if parent . type in ( "" suite "" , "" file_input "" ) : 
","if parent is None :
",26.25,2.14,False
"def PyJsHoisted_parseClassRanges_ ( this , arguments , var = var ) : <TAB> var = Scope ( { u "" this "" : this , u "" arguments "" : arguments } , var ) <TAB> var . registers ( [ u "" res "" ] ) <TAB> pass <TAB> if var . get ( u "" current "" ) ( Js ( u "" ] "" ) ) : <TAB> <TAB> return Js ( [ ] ) <TAB> else : <TAB> <TAB> var . put ( u "" res "" , var . get ( u "" parseNonemptyClassRanges "" ) ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> var . get ( u "" bail "" ) ( Js ( u "" nonEmptyClassRanges "" ) ) <TAB> <TAB> return var . get ( u "" res "" ) ","if var . get ( u "" res "" ) . neg ( ) : 
","if var . get ( u "" nonEmptyClassRanges "" ) :
",61.2,46.6,False
"def _recurse_children ( self , offset ) : <TAB> """"""Recurses thorugh the available children"""""" <TAB> while offset < self . obj_offset + self . Length : <TAB> <TAB> item = obj . Object ( "" VerStruct "" , offset = offset , vm = self . obj_vm , parent = self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise StopIteration ( <TAB> <TAB> <TAB> <TAB> "" Could not recover a key for a child at offset  {0} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> item . obj_offset <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> yield item . get_key ( ) , item . get_children ( ) <TAB> <TAB> offset = self . offset_pad ( offset + item . Length ) <TAB> raise StopIteration ( "" No children "" ) ","if item . Length < 1 or item . get_key ( ) == None : 
","if not item . get_children ( ) :
",38.14,15.08,False
"def _adapt_types ( self , descr ) : <TAB> names = [ ] <TAB> adapted_types = [ ] <TAB> for col in descr : <TAB> <TAB> names . append ( col [ 0 ] ) <TAB> <TAB> impala_typename = col [ 1 ] <TAB> <TAB> typename = udf . _impala_to_ibis_type [ impala_typename . lower ( ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> precision , scale = col [ 4 : 6 ] <TAB> <TAB> <TAB> adapted_types . append ( dt . Decimal ( precision , scale ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> adapted_types . append ( typename ) <TAB> return names , adapted_types ","if typename == "" decimal "" : 
","if typename == "" Decimal "" :
",74.63,59.46,False
"def sniff ( self , filename ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with tarfile . open ( filename , "" r "" ) as temptar : <TAB> <TAB> <TAB> <TAB> for f in temptar : <TAB> <TAB> <TAB> <TAB> <TAB> if not f . isfile ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> <TAB> if f . name . endswith ( "" .fast5 "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> except Exception as e : <TAB> <TAB> log . warning ( "" %s , sniff Exception:  %s "" , self , e ) <TAB> return False ","if filename and tarfile . is_tarfile ( filename ) : 
","if filename :
",26.96,0.0,False
"def getValue ( self ) : <TAB> if getattr ( self . object , "" type "" , "" "" ) != "" CURVE "" : <TAB> <TAB> return BezierSpline ( ) <TAB> evaluatedObject = getEvaluatedID ( self . object ) <TAB> bSplines = evaluatedObject . data . splines <TAB> if len ( bSplines ) > 0 : <TAB> <TAB> spline = createSplineFromBlenderSpline ( bSplines [ 0 ] ) <TAB> <TAB> # Is None when the spline type is not supported. <TAB> <TAB> if spline is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> spline . transform ( evaluatedObject . matrix_world ) <TAB> <TAB> <TAB> return spline <TAB> return BezierSpline ( ) ","if self . useWorldSpace : 
","if evaluatedObject . matrix_world is not None :
",36.13,5.52,False
"def escape ( text , newline = False ) : <TAB> """"""Escape special html characters."""""" <TAB> if isinstance ( text , str ) : <TAB> <TAB> if "" & "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" & "" , "" &amp; "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = text . replace ( "" > "" , "" &gt; "" ) <TAB> <TAB> if "" < "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" < "" , "" &lt; "" ) <TAB> <TAB> if ' "" ' in text : <TAB> <TAB> <TAB> text = text . replace ( ' "" ' , "" &quot; "" ) <TAB> <TAB> if "" ' "" in text : <TAB> <TAB> <TAB> text = text . replace ( "" ' "" , "" &quot; "" ) <TAB> <TAB> if newline : <TAB> <TAB> <TAB> if "" \n "" in text : <TAB> <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" <br> "" ) <TAB> return text ","if "" > "" in text : 
","if "" > "" in text :
",100.0,100.0,True
"def _get_ilo_version ( self ) : <TAB> try : <TAB> <TAB> self . _get_ilo2 ( ' <?xml version= "" 1.0 "" ?><RIBCL VERSION= "" 2.0 "" ></RIBCL> ' ) <TAB> except ResponseError as e : <TAB> <TAB> if hasattr ( e , "" code "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return 3 <TAB> <TAB> <TAB> if e . code == 501 : <TAB> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> raise <TAB> return 2 ","if e . code == 405 : 
","if e . code == 502 :
",82.41,70.71,False
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctx . close_path ( ) ","elif code == Path . CLOSEPOLY : 
","elif code == Path . CLOSEPOLY :
",100.0,100.0,True
"def called_by_shrinker ( ) : <TAB> frame = sys . _getframe ( 0 ) <TAB> while frame : <TAB> <TAB> fname = frame . f_globals . get ( "" __file__ "" , "" "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> frame = frame . f_back <TAB> return False ","if os . path . basename ( fname ) == "" shrinker.py "" : 
","if fname and fname . endswith ( "" .py "" ) and not os . path . isfile ( fname ) :
",52.31,20.34,False
"def _ensuresyspath ( self , ensuremode , path ) : <TAB> if ensuremode : <TAB> <TAB> s = str ( path ) <TAB> <TAB> if ensuremode == "" append "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sys . path . append ( s ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if s != sys . path [ 0 ] : <TAB> <TAB> <TAB> <TAB> sys . path . insert ( 0 , s ) ","if s not in sys . path : 
","if s not in sys . path :
",100.0,100.0,True
"def get_instances ( self , region : str , vpc : str ) : <TAB> try : <TAB> <TAB> await self . _cache_instances ( region ) <TAB> <TAB> return [ <TAB> <TAB> <TAB> instance <TAB> <TAB> <TAB> for instance in self . _instances_cache [ region ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> except Exception as e : <TAB> <TAB> print_exception ( f "" Failed to get RDS instances:  { e } "" ) <TAB> <TAB> return [ ] ","if instance [ "" VpcId "" ] == vpc 
","if instance [ "" VpcId "" ] == vpc
",100.0,100.0,True
def get_and_set_all_disambiguation ( self ) : <TAB> all_disambiguations = [ ] <TAB> for page in self . pages : <TAB> <TAB> if page . relations . disambiguation_links_norm is not None : <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links_norm ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> all_disambiguations . extend ( page . relations . disambiguation_links ) <TAB> return set ( all_disambiguations ) ,"if page . relations . disambiguation_links is not None : 
","if page . relations . disambiguation_links is not None :
",100.0,100.0,True
"def __str__ ( self , prefix = "" "" , printElemNumber = 0 ) : <TAB> res = "" "" <TAB> cnt = 0 <TAB> for e in self . options_ : <TAB> <TAB> elm = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elm = "" ( %d ) "" % cnt <TAB> <TAB> res + = prefix + ( "" options %s  < \n "" % elm ) <TAB> <TAB> res + = e . __str__ ( prefix + ""<TAB> "" , printElemNumber ) <TAB> <TAB> res + = prefix + "" > \n "" <TAB> <TAB> cnt + = 1 <TAB> return res ","if printElemNumber : 
","if printElemNumber :
",78.12,0.0,False
"def pre_save_task ( self , task , credentials , verrors ) : <TAB> if task [ "" attributes "" ] [ "" encryption "" ] not in ( None , "" "" , "" AES256 "" ) : <TAB> <TAB> verrors . add ( "" encryption "" , ' Encryption should be null or  "" AES256 "" ' ) <TAB> if not credentials [ "" attributes "" ] . get ( "" skip_region "" , False ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response = await self . middleware . run_in_thread ( <TAB> <TAB> <TAB> <TAB> self . _get_client ( credentials ) . get_bucket_location , <TAB> <TAB> <TAB> <TAB> Bucket = task [ "" attributes "" ] [ "" bucket "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> task [ "" attributes "" ] [ "" region "" ] = response [ "" LocationConstraint "" ] or "" us-east-1 "" ","if not credentials [ "" attributes "" ] . get ( "" region "" , "" "" ) . strip ( ) : 
","if not task [ "" attributes "" ] . get ( "" region "" ) :
",59.86,48.61,False
"def get_best_config_reward ( self ) : <TAB> """"""Returns the best configuration found so far, as well as the reward associated with this best config."""""" <TAB> with self . LOCK : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> config_pkl = max ( self . _results , key = self . _results . get ) <TAB> <TAB> <TAB> return pickle . loads ( config_pkl ) , self . _results [ config_pkl ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return dict ( ) , self . _reward_while_pending ( ) ","if self . _results : 
","if self . _results :
",100.0,100.0,True
"def parse_setup_cfg ( self ) : <TAB> # type: () -> Dict[STRING_TYPE, Any] <TAB> if self . setup_cfg is not None and self . setup_cfg . exists ( ) : <TAB> <TAB> contents = self . setup_cfg . read_text ( ) <TAB> <TAB> base_dir = self . setup_cfg . absolute ( ) . parent . as_posix ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> parsed = setuptools_parse_setup_cfg ( self . setup_cfg . as_posix ( ) ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> contents = self . setup_cfg . read_bytes ( ) <TAB> <TAB> <TAB> parsed = parse_setup_cfg ( contents , base_dir ) <TAB> <TAB> if not parsed : <TAB> <TAB> <TAB> return { } <TAB> <TAB> return parsed <TAB> return { } ","if six . PY2 : 
","if self . setup_cfg . exists ( ) :
",36.01,4.93,False
"def readall ( read_fn , sz ) : <TAB> buff = b "" "" <TAB> have = 0 <TAB> while have < sz : <TAB> <TAB> chunk = yield from read_fn ( sz - have ) <TAB> <TAB> have + = len ( chunk ) <TAB> <TAB> buff + = chunk <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TTransportException ( <TAB> <TAB> <TAB> <TAB> TTransportException . END_OF_FILE , "" End of file reading from transport "" <TAB> <TAB> <TAB> ) <TAB> return buff ","if len ( chunk ) == 0 : 
","if len ( chunk ) == 0 :
",100.0,100.0,True
"def _get_use_previous ( <TAB> f , ) :<TAB> # TODO Sort and group features for DateOffset with two different temporal values <TAB> if isinstance ( f , AggregationFeature ) and f . use_previous is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( "" "" , - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> unit = list ( f . use_previous . times . keys ( ) ) [ 0 ] <TAB> <TAB> <TAB> value = f . use_previous . times [ unit ] <TAB> <TAB> <TAB> return ( unit , value ) <TAB> else : <TAB> <TAB> return ( "" "" , - 1 ) ","if len ( f . use_previous . times . keys ( ) ) > 1 : 
","if f . use_previous is None :
",30.68,17.86,False
"def istrue ( self ) : <TAB> try : <TAB> <TAB> return self . _istrue ( ) <TAB> except Exception : <TAB> <TAB> self . exc = sys . exc_info ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = [ <TAB> <TAB> <TAB> <TAB> "" "" * ( self . exc [ 1 ] . offset + 4 ) + "" ^ "" , <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> msg . append ( "" SyntaxError: invalid syntax "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> msg = traceback . format_exception_only ( * self . exc [ : 2 ] ) <TAB> <TAB> pytest . fail ( <TAB> <TAB> <TAB> "" Error evaluating  %r  expression \n "" <TAB> <TAB> <TAB> ""<TAB>  %s \n "" <TAB> <TAB> <TAB> "" %s "" % ( self . name , self . expr , "" \n "" . join ( msg ) ) , <TAB> <TAB> <TAB> pytrace = False , <TAB> <TAB> ) ","if isinstance ( self . exc [ 1 ] , SyntaxError ) : 
","if self . expr is None :
",31.13,6.63,False
"def wait_for_crm_operation ( operation , crm ) : <TAB> """"""Poll for cloud resource manager operation until finished."""""" <TAB> logger . info ( <TAB> <TAB> "" wait_for_crm_operation:  "" <TAB> <TAB> "" Waiting for operation  {}  to finish... "" . format ( operation ) <TAB> ) <TAB> for _ in range ( MAX_POLLS ) : <TAB> <TAB> result = crm . operations ( ) . get ( name = operation [ "" name "" ] ) . execute ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( result [ "" error "" ] ) <TAB> <TAB> if "" done "" in result and result [ "" done "" ] : <TAB> <TAB> <TAB> logger . info ( "" wait_for_crm_operation: Operation done. "" ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( POLL_INTERVAL ) <TAB> return result ","if "" error "" in result : 
","if "" error "" in result :
",100.0,100.0,True
"def cb_blob_detail_from_elem_and_buf ( self , elem , buf ) : <TAB> if elem . get ( "" lang "" ) != buf . lang :<TAB> # multi-lang doc <TAB> <TAB> return "" %s  Code in  %s "" % ( elem . get ( "" lang "" ) , buf . path ) <TAB> else : <TAB> <TAB> dir , base = os . path . split ( buf . path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" %s  ( %s ) "" % ( base , dir ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return base ","if dir : 
","if dir :
",78.12,0.0,False
"def removedir ( self , path ) : <TAB> # type: (Text) -> None <TAB> _path = self . validatepath ( path ) <TAB> if _path == "" / "" : <TAB> <TAB> raise errors . RemoveRootError ( ) <TAB> with ftp_errors ( self , path ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . ftp . rmd ( _encode ( _path , self . ftp . encoding ) ) <TAB> <TAB> except error_perm as error : <TAB> <TAB> <TAB> code , _ = _parse_ftp_error ( error ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . isfile ( path ) : <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryExpected ( path ) <TAB> <TAB> <TAB> <TAB> if not self . isempty ( path ) : <TAB> <TAB> <TAB> <TAB> <TAB> raise errors . DirectoryNotEmpty ( path ) <TAB> <TAB> <TAB> raise<TAB> # pragma: no cover ","if code == "" 550 "" : 
","if code == FTP_ERROR_BAD_PATH :
",34.45,22.42,False
"def p_clause ( self , node , position ) : <TAB> if isinstance ( node , Graph ) : <TAB> <TAB> self . subjectDone ( node ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> self . write ( "" { "" ) <TAB> <TAB> self . depth + = 1 <TAB> <TAB> serializer = N3Serializer ( node , parent = self ) <TAB> <TAB> serializer . serialize ( self . stream ) <TAB> <TAB> self . depth - = 1 <TAB> <TAB> self . write ( self . indent ( ) + "" } "" ) <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return False ","if position is OBJECT : 
","if self . depth > 0 :
",27.64,7.81,False
"def get_default_shell_info ( shell_name = None , settings = None ) : <TAB> if not shell_name : <TAB> <TAB> settings = settings or load_settings ( lazy = True ) <TAB> <TAB> shell_name = settings . get ( "" shell "" ) <TAB> <TAB> if shell_name : <TAB> <TAB> <TAB> return shell_name , None <TAB> <TAB> shell_path = os . environ . get ( "" SHELL "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shell_name = basepath ( shell_path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shell_name = DEFAULT_SHELL <TAB> <TAB> return shell_name , shell_path <TAB> return shell_name , None ","if shell_path : 
","if shell_path :
",78.12,100.0,True
"def GetCategory ( self , pidls ) : <TAB> ret = [ ] <TAB> for pidl in pidls : <TAB> <TAB> # Why don't we just get the size of the PIDL? <TAB> <TAB> val = self . sf . GetDetailsEx ( pidl , PKEY_Sample_AreaSize ) <TAB> <TAB> val = int ( val )<TAB> # it probably came in a VT_BSTR variant <TAB> <TAB> if val < 255 / / 3 : <TAB> <TAB> <TAB> cid = IDS_SMALL <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cid = IDS_MEDIUM <TAB> <TAB> else : <TAB> <TAB> <TAB> cid = IDS_LARGE <TAB> <TAB> ret . append ( cid ) <TAB> return ret ","elif val < 2 * 255 / / 3 : 
","elif val > 255 / / 3 :
",48.2,46.31,False
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast ( TupleStr4 , item ) <TAB> <TAB> if item [ 0 ] : <TAB> <TAB> <TAB> typ = "" number "" <TAB> <TAB> <TAB> val = item [ 0 ] <TAB> <TAB> elif item [ 1 ] : <TAB> <TAB> <TAB> typ = "" name "" <TAB> <TAB> <TAB> val = item [ 1 ] <TAB> <TAB> elif item [ 2 ] : <TAB> <TAB> <TAB> typ = item [ 2 ] <TAB> <TAB> <TAB> val = item [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> typ = item [ 3 ] <TAB> <TAB> <TAB> val = item [ 3 ] <TAB> <TAB> yield Token ( typ , val ) ","elif item [ 3 ] : 
","elif item [ 3 ] :
",100.0,100.0,True
"def add_package_declarations ( generated_root_path ) : <TAB> file_names = os . listdir ( generated_root_path ) <TAB> for file_name in file_names : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> full_name = os . path . join ( generated_root_path , file_name ) <TAB> <TAB> add_package ( full_name ) ","if not file_name . endswith ( "" .java "" ) : 
","if file_name . endswith ( "" .py "" ) :
",63.08,63.44,False
"def _call_with_retry ( out , retry , retry_wait , method , * args , * * kwargs ) : <TAB> for counter in range ( retry + 1 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> return method ( * args , * * kwargs ) <TAB> <TAB> except ( <TAB> <TAB> <TAB> NotFoundException , <TAB> <TAB> <TAB> ForbiddenException , <TAB> <TAB> <TAB> AuthenticationException , <TAB> <TAB> <TAB> RequestErrorException , <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise <TAB> <TAB> except ConanException as exc : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if out : <TAB> <TAB> <TAB> <TAB> <TAB> out . error ( exc ) <TAB> <TAB> <TAB> <TAB> <TAB> out . info ( "" Waiting  %d  seconds to retry... "" % retry_wait ) <TAB> <TAB> <TAB> <TAB> time . sleep ( retry_wait ) ","if counter == retry : 
","if counter == retry :
",100.0,100.0,True
"def to_wburl_str ( <TAB> url , type = BaseWbUrl . LATEST_REPLAY , mod = "" "" , timestamp = "" "" , end_timestamp = "" "" ) : <TAB> if WbUrl . is_query_type ( type ) : <TAB> <TAB> tsmod = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tsmod + = mod + "" / "" <TAB> <TAB> tsmod + = timestamp <TAB> <TAB> tsmod + = "" * "" <TAB> <TAB> tsmod + = end_timestamp <TAB> <TAB> tsmod + = "" / "" + url <TAB> <TAB> if type == BaseWbUrl . URL_QUERY : <TAB> <TAB> <TAB> tsmod + = "" * "" <TAB> <TAB> return tsmod <TAB> else : <TAB> <TAB> tsmod = timestamp + mod <TAB> <TAB> if len ( tsmod ) > 0 : <TAB> <TAB> <TAB> return tsmod + "" / "" + url <TAB> <TAB> else : <TAB> <TAB> <TAB> return url ","if mod : 
","if mod :
",78.12,0.0,False
"def _configured_ploidy ( items ) : <TAB> ploidies = collections . defaultdict ( set ) <TAB> for data in items : <TAB> <TAB> ploidy = dd . get_ploidy ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k , v in ploidy . items ( ) : <TAB> <TAB> <TAB> <TAB> ploidies [ k ] . add ( v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ploidies [ "" default "" ] . add ( ploidy ) <TAB> out = { } <TAB> for k , vs in ploidies . items ( ) : <TAB> <TAB> assert len ( vs ) == 1 , "" Multiple ploidies set for group calling:  %s %s "" % ( <TAB> <TAB> <TAB> k , <TAB> <TAB> <TAB> list ( vs ) , <TAB> <TAB> ) <TAB> <TAB> out [ k ] = vs . pop ( ) <TAB> return out ","if isinstance ( ploidy , dict ) : 
","if ploidy :
",26.73,0.0,False
"def removeUser ( self , username ) : <TAB> hideFromOSD = not constants . SHOW_DIFFERENT_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> user = self . _users [ username ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . isRoomSame ( user . room ) : <TAB> <TAB> <TAB> <TAB> hideFromOSD = not constants . SHOW_SAME_ROOM_OSD <TAB> if username in self . _users : <TAB> <TAB> self . _users . pop ( username ) <TAB> <TAB> message = getMessage ( "" left-notification "" ) . format ( username ) <TAB> <TAB> self . ui . showMessage ( message , hideFromOSD ) <TAB> <TAB> self . _client . lastLeftTime = time . time ( ) <TAB> <TAB> self . _client . lastLeftUser = username <TAB> self . userListChange ( ) ","if user . room : 
","if user . room :
",100.0,100.0,True
"def _thd_cleanup_instance ( self ) : <TAB> container_name = self . getContainerName ( ) <TAB> instances = self . client . containers ( all = 1 , filters = dict ( name = container_name ) ) <TAB> for instance in instances : <TAB> <TAB> # hyper filtering will match 'hyper12"" if you search for 'hyper1' ! <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> self . client . remove_container ( instance [ "" Id "" ] , v = True , force = True ) <TAB> <TAB> except NotFound : <TAB> <TAB> <TAB> pass<TAB> # that's a race condition <TAB> <TAB> except docker . errors . APIError as e : <TAB> <TAB> <TAB> if "" Conflict operation on container "" not in str ( e ) : <TAB> <TAB> <TAB> <TAB> raise ","if "" "" . join ( instance [ "" Names "" ] ) . strip ( "" / "" ) != container_name : 
","if instance [ "" Name "" ] == "" hyper12 "" :
",35.49,6.33,False
"def handle_ctcp ( self , conn , evt ) : <TAB> args = evt . arguments ( ) <TAB> source = evt . source ( ) . split ( "" ! "" ) [ 0 ] <TAB> if args : <TAB> <TAB> if args [ 0 ] == "" VERSION "" : <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" VERSION  "" + BOT_VERSION ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" PING "" ) <TAB> <TAB> elif args [ 0 ] == "" CLIENTINFO "" : <TAB> <TAB> <TAB> conn . ctcp_reply ( source , "" CLIENTINFO PING VERSION CLIENTINFO "" ) ","elif args [ 0 ] == "" PING "" : 
","elif args [ 0 ] == "" PING "" :
",100.0,100.0,True
"def new_func ( self , * args , * * kwargs ) : <TAB> obj = self . obj_ref ( ) <TAB> attr = self . attr <TAB> if obj is not None : <TAB> <TAB> args = tuple ( TrackedValue . make ( obj , attr , arg ) for arg in args ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs = { <TAB> <TAB> <TAB> <TAB> key : TrackedValue . make ( obj , attr , value ) <TAB> <TAB> <TAB> <TAB> for key , value in iteritems ( kwargs ) <TAB> <TAB> <TAB> } <TAB> result = func ( self , * args , * * kwargs ) <TAB> self . _changed_ ( ) <TAB> return result ","if kwargs : 
","if kwargs is not None :
",34.04,17.97,False
"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target . id <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> doc = find_doc_for ( target , body_lines ) <TAB> <TAB> <TAB> if doc is not None : <TAB> <TAB> <TAB> <TAB> variables [ name ] = doc <TAB> elif isinstance ( target , ast . Tuple ) : <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target . elts : <TAB> <TAB> <TAB> add_doc ( e , variables , body_lines ) ","if name not in variables : 
","if name not in variables :
",100.0,100.0,True
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> if tp == "" write "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> elif tp == "" flush "" : <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass ","elif tp == "" write_flush "" : 
","elif tp == "" write "" :
",74.63,59.59,False
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . islink ( p ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . isdir ( p ) : <TAB> <TAB> <TAB> res + = get_dir ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res . append ( p ) <TAB> return res ","if skip_file ( fname ) : 
","if pth != "" . "" :
",27.39,6.57,False
"def _list_outputs ( self ) : <TAB> outputs = super ( VolSymm , self ) . _list_outputs ( ) <TAB> # Have to manually check for the grid files. <TAB> if os . path . exists ( outputs [ "" trans_file "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> outputs [ "" output_grid "" ] = re . sub ( <TAB> <TAB> <TAB> <TAB> "" .(nlxfm|xfm)$ "" , "" _grid_0.mnc "" , outputs [ "" trans_file "" ] <TAB> <TAB> <TAB> ) <TAB> return outputs ","if "" grid "" in open ( outputs [ "" trans_file "" ] , "" r "" ) . read ( ) : 
","if "" .nlxfm "" not in outputs [ "" output_grid "" ] :
",36.53,9.41,False
"def _set_texture ( self , texture ) : <TAB> if texture . id is not self . _texture . id : <TAB> <TAB> self . _group = SpriteGroup ( <TAB> <TAB> <TAB> texture , self . _group . blend_src , self . _group . blend_dest , self . _group . parent <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _vertex_list . delete ( ) <TAB> <TAB> <TAB> self . _texture = texture <TAB> <TAB> <TAB> self . _create_vertex_list ( ) <TAB> else : <TAB> <TAB> self . _vertex_list . tex_coords [ : ] = texture . tex_coords <TAB> self . _texture = texture ","if self . _batch is None : 
","if self . _vertex_list . has_tex_coords :
",39.71,18.8,False
"def got_result ( result ) : <TAB> deployment = self . persistence_service . get ( ) <TAB> for node in deployment . nodes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dataset_ids = [ <TAB> <TAB> <TAB> <TAB> ( m . dataset . deleted , m . dataset . dataset_id ) <TAB> <TAB> <TAB> <TAB> for m in node . manifestations . values ( ) <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> self . assertIn ( ( True , expected_dataset_id ) , dataset_ids ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> self . fail ( "" Node not found.  {} "" . format ( node . uuid ) ) ","if same_node ( node , origin ) : 
","if node . uuid == result . uuid :
",26.81,5.52,False
"def check_result ( result , func , arguments ) : <TAB> if check_warning ( result ) and ( result . value != ReturnCode . WARN_NODATA ) : <TAB> <TAB> log . warning ( UcanWarning ( result , func , arguments ) ) <TAB> elif check_error ( result ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise UcanCmdError ( result , func , arguments ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UcanError ( result , func , arguments ) <TAB> return result ","if check_error_cmd ( result ) : 
","if result . value == ReturnCode . ERROR :
",27.25,5.52,False
"def _compress_and_sort_bdg_files ( out_dir , data ) : <TAB> for fn in glob . glob ( os . path . join ( out_dir , "" *bdg "" ) ) : <TAB> <TAB> out_file = fn + "" .gz "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> bedtools = config_utils . get_program ( "" bedtools "" , data ) <TAB> <TAB> with file_transaction ( out_file ) as tx_out_file : <TAB> <TAB> <TAB> cmd = f "" sort -k1,1 -k2,2n  { fn }  | bgzip -c >  { tx_out_file } "" <TAB> <TAB> <TAB> message = f "" Compressing and sorting  { fn } . "" <TAB> <TAB> <TAB> do . run ( cmd , message ) ","if utils . file_exists ( out_file ) : 
","if not os . path . exists ( out_file ) :
",51.31,50.09,False
"def kill_members ( members , sig , hosts = nodes ) : <TAB> for member in sorted ( members ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if ha_tools_debug : <TAB> <TAB> <TAB> <TAB> print ( "" killing  %s "" % member ) <TAB> <TAB> <TAB> proc = hosts [ member ] [ "" proc "" ] <TAB> <TAB> <TAB> # Not sure if cygwin makes sense here... <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . kill ( proc . pid , signal . CTRL_C_EVENT ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . kill ( proc . pid , sig ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> if ha_tools_debug : <TAB> <TAB> <TAB> <TAB> print ( "" %s  already dead? "" % member ) ","if sys . platform in ( "" win32 "" , "" cygwin "" ) : 
","if proc . is_win ( ) :
",30.19,6.16,False
"def get_top_level_stats ( self ) : <TAB> for func , ( cc , nc , tt , ct , callers ) in self . stats . items ( ) : <TAB> <TAB> self . total_calls + = nc <TAB> <TAB> self . prim_calls + = cc <TAB> <TAB> self . total_tt + = tt <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . top_level [ func ] = None <TAB> <TAB> if len ( func_std_string ( func ) ) > self . max_name_len : <TAB> <TAB> <TAB> self . max_name_len = len ( func_std_string ( func ) ) ","if ( "" jprofile "" , 0 , "" profiler "" ) in callers : 
","if not callers :
",26.16,2.26,False
"def __str__ ( self ) : <TAB> """"""Only keeps the True values."""""" <TAB> result = [ "" SlicingSpec( "" ] <TAB> if self . entire_dataset : <TAB> <TAB> result . append ( ""  Entire dataset, "" ) <TAB> if self . by_class : <TAB> <TAB> if isinstance ( self . by_class , Iterable ) : <TAB> <TAB> <TAB> result . append ( ""  Into classes  %s , "" % self . by_class ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( ""  Up to class  %d , "" % self . by_class ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result . append ( ""  By classes, "" ) <TAB> if self . by_percentiles : <TAB> <TAB> result . append ( ""  By percentiles, "" ) <TAB> if self . by_classification_correctness : <TAB> <TAB> result . append ( ""  By classification correctness, "" ) <TAB> result . append ( "" ) "" ) <TAB> return "" \n "" . join ( result ) ","elif isinstance ( self . by_class , int ) : 
","elif isinstance ( self . by_class , int ) :
",100.0,100.0,True
"def save_params ( self ) : <TAB> if self . _save_controller : <TAB> <TAB> if not os . path . exists ( self . _save_controller ) : <TAB> <TAB> <TAB> os . makedirs ( self . _save_controller ) <TAB> <TAB> output_dir = self . _save_controller <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( "" ./.rlnas_controller "" ) <TAB> <TAB> output_dir = "" ./.rlnas_controller "" <TAB> with open ( os . path . join ( output_dir , "" rlnas.params "" ) , "" wb "" ) as f : <TAB> <TAB> pickle . dump ( self . _params_dict , f ) <TAB> _logger . debug ( "" Save params done "" ) ","if not os . path . exists ( "" ./.rlnas_controller "" ) : 
","if not os . path . exists ( "" ./.rlnas_controller "" ) :
",100.0,100.0,True
"def unexport ( self , pin ) : <TAB> with self . _lock : <TAB> <TAB> self . _pin_refs [ pin ] - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with io . open ( self . path ( "" unexport "" ) , "" wb "" ) as f : <TAB> <TAB> <TAB> <TAB> f . write ( str ( pin ) . encode ( "" ascii "" ) ) ","if self . _pin_refs [ pin ] == 0 : 
","if self . _pin_refs [ pin ] == 0 :
",100.0,100.0,True
"def emit ( self , type , info = None ) : <TAB> # Overload emit() to send events to the proxy object at the other end <TAB> ev = super ( ) . emit ( type , info ) <TAB> if self . _has_proxy is True and self . _session . status > 0 : <TAB> <TAB> # implicit: and self._disposed is False: <TAB> <TAB> if type in self . __proxy_properties__ : <TAB> <TAB> <TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _session . send_command ( "" INVOKE "" , self . _id , "" _emit_at_proxy "" , [ ev ] ) ","elif type in self . __event_types_at_proxy : 
","elif type in self . __proxy_properties__ :
",82.58,47.96,False
"def __call__ ( self , params ) : <TAB> all_errs = { } <TAB> for handler in self . handlers : <TAB> <TAB> out_headers , res , errs = handler ( params ) <TAB> <TAB> all_errs . update ( errs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return out_headers , res , all_errs <TAB> return None , None , all_errs ","if res is not None : 
","if out_headers :
",27.4,10.4,False
"def await_test_end ( self ) : <TAB> iterations = 0 <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . debug ( "" Await: iteration limit reached "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> status = self . master . get_status ( ) <TAB> <TAB> if status . get ( "" status "" ) == "" ENDED "" : <TAB> <TAB> <TAB> return <TAB> <TAB> iterations + = 1 <TAB> <TAB> time . sleep ( 1.0 ) ","if iterations > 100 : 
","if iterations > = self . config . get ( "" iterations "" ) :
",34.09,10.51,False
"def _load ( self , path : str ) : <TAB> ds = DataSet ( ) <TAB> with open ( path , "" r "" , encoding = "" utf-8 "" ) as f : <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> parts = line . split ( "" \t "" ) <TAB> <TAB> <TAB> <TAB> raw_words1 = parts [ 1 ] <TAB> <TAB> <TAB> <TAB> raw_words2 = parts [ 2 ] <TAB> <TAB> <TAB> <TAB> target = parts [ 0 ] <TAB> <TAB> <TAB> <TAB> if raw_words1 and raw_words2 and target : <TAB> <TAB> <TAB> <TAB> <TAB> ds . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> Instance ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> raw_words1 = raw_words1 , raw_words2 = raw_words2 , target = target <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return ds ","if line : 
","if line :
",78.12,0.0,False
"def avatar_delete ( event_id , speaker_id ) : <TAB> if request . method == "" DELETE "" : <TAB> <TAB> speaker = ( <TAB> <TAB> <TAB> DataGetter . get_speakers ( event_id ) <TAB> <TAB> <TAB> . filter_by ( user_id = login . current_user . id , id = speaker_id ) <TAB> <TAB> <TAB> . first ( ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> speaker . photo = "" "" <TAB> <TAB> <TAB> speaker . small = "" "" <TAB> <TAB> <TAB> speaker . thumbnail = "" "" <TAB> <TAB> <TAB> speaker . icon = "" "" <TAB> <TAB> <TAB> save_to_db ( speaker ) <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" ok "" } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> abort ( 403 ) ","if speaker : 
","if speaker :
",78.12,0.0,False
"def getline ( filename , lineno , * args , * * kwargs ) : <TAB> line = py2exe_getline ( filename , lineno , * args , * * kwargs ) <TAB> if not line : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> for i , line in enumerate ( f ) : <TAB> <TAB> <TAB> <TAB> <TAB> line = line . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> line = "" "" <TAB> <TAB> except ( IOError , OSError ) : <TAB> <TAB> <TAB> line = "" "" <TAB> return line ","if lineno == i + 1 : 
","if i > 0 :
",27.38,7.72,False
"def write ( self , data ) : <TAB> if not isinstance ( data , ( bytes , bytearray , memoryview ) ) : <TAB> <TAB> raise TypeError ( "" data argument must be byte-ish ( %r ) "" , type ( data ) ) <TAB> if not data : <TAB> <TAB> return <TAB> if self . _conn_lost : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( "" socket.send() raised exception. "" ) <TAB> <TAB> self . _conn_lost + = 1 <TAB> <TAB> return <TAB> if not self . _buffer : <TAB> <TAB> self . _loop . add_writer ( self . _sock_fd , self . _write_ready ) <TAB> # Add it to the buffer. <TAB> self . _buffer . extend ( data ) <TAB> self . _maybe_pause_protocol ( ) ","if self . _conn_lost > = constants . LOG_THRESHOLD_FOR_CONNLOST_WRITES : 
","if self . _loop . get_debug ( ) :
",39.51,11.52,False
"def _get_x_for_y ( self , xValue , x , y ) : <TAB> # print(""searching ""+x+"" with the value ""+str(xValue)+"" and want to give back ""+y) <TAB> if not self . xmlMap : <TAB> <TAB> return 0 <TAB> x_value = str ( xValue ) <TAB> for anime in self . xmlMap . findall ( "" anime "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return int ( anime . get ( y , 0 ) ) <TAB> <TAB> except ValueError as e : <TAB> <TAB> <TAB> continue <TAB> return 0 ","if anime . get ( x , False ) == x_value : 
","if xValue == anime . get ( x , 0 ) :
",52.36,39.74,False
"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB> <TAB> if not line : <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None : <TAB> <TAB> <TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB> <TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo ","if line . startswith ( "" vermagic "" ) : 
","if obj_kernel_version is not None :
",26.38,4.99,False
"def _score ( self , X , y ) : <TAB> for col in self . cols : <TAB> <TAB> # Score the column <TAB> <TAB> X [ col ] = X [ col ] . map ( self . mapping [ col ] ) <TAB> <TAB> # Randomization is meaningful only for training data -> we do it only if y is present <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> random_state_generator = check_random_state ( self . random_state ) <TAB> <TAB> <TAB> X [ col ] = X [ col ] * random_state_generator . normal ( <TAB> <TAB> <TAB> <TAB> 1.0 , self . sigma , X [ col ] . shape [ 0 ] <TAB> <TAB> <TAB> ) <TAB> return X ","if self . randomized and y is not None : 
","if y is not None :
",54.35,40.83,False
"def onMouseWheel ( self , event ) : <TAB> if self . selectedHuman . isVisible ( ) : <TAB> <TAB> zoomOut = event . wheelDelta > 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> zoomOut = not zoomOut <TAB> <TAB> if event . x is not None : <TAB> <TAB> <TAB> self . modelCamera . mousePickHumanCenter ( event . x , event . y ) <TAB> <TAB> if zoomOut : <TAB> <TAB> <TAB> self . zoomOut ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . zoomIn ( ) ","if self . getSetting ( "" invertMouseWheel "" ) : 
","if zoomOut :
",26.09,0.0,False
"def prehook ( self , emu , op , eip ) : <TAB> if op in self . badops : <TAB> <TAB> emu . stopEmu ( ) <TAB> <TAB> raise v_exc . BadOpBytes ( op . va ) <TAB> if op . mnem in STOS : <TAB> <TAB> if self . arch == "" i386 "" : <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . i386 . REG_EDI ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> reg = emu . getRegister ( envi . archs . amd64 . REG_RDI ) <TAB> <TAB> if self . vw . isValidPointer ( reg ) and self . vw . getLocation ( reg ) is None : <TAB> <TAB> <TAB> self . vw . makePointer ( reg , follow = True ) ","elif self . arch == "" amd64 "" : 
","elif self . arch == "" amd64 "" :
",100.0,100.0,True
"def callback ( actions , form , tablename = None ) : <TAB> if actions : <TAB> <TAB> if tablename and isinstance ( actions , dict ) : <TAB> <TAB> <TAB> actions = actions . get ( tablename , [ ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> actions = [ actions ] <TAB> <TAB> [ action ( form ) for action in actions ] ","if not isinstance ( actions , ( list , tuple ) ) : 
","elif isinstance ( actions , list ) :
",36.02,22.87,False
"def FetchFn ( bigger_than_3_only = None , less_than_7_only = None , even_only = None ) : <TAB> result = [ ] <TAB> for i in range ( 10 ) : <TAB> <TAB> # This line introduces a bug. <TAB> <TAB> if bigger_than_3_only and less_than_7_only and i == 4 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if bigger_than_3_only and i < = 3 : <TAB> <TAB> <TAB> continue <TAB> <TAB> if less_than_7_only and i > = 7 : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> result . append ( i ) <TAB> return result ","if even_only and i % 2 != 0 : 
","if even_only and i % 2 != 0 :
",100.0,100.0,True
"def set_trial_values ( self , trial_id : int , values : Sequence [ float ] ) - > None : <TAB> with self . _lock : <TAB> <TAB> cached_trial = self . _get_cached_trial ( trial_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _check_trial_is_updatable ( cached_trial ) <TAB> <TAB> <TAB> updates = self . _get_updates ( trial_id ) <TAB> <TAB> <TAB> cached_trial . values = values <TAB> <TAB> <TAB> updates . values = values <TAB> <TAB> <TAB> return <TAB> self . _backend . _update_trial ( trial_id , values = values ) ","if cached_trial is not None : 
","if cached_trial is not None :
",100.0,100.0,True
"def _get_label_format ( self , workunit ) : <TAB> for label , label_format in self . LABEL_FORMATTING . items ( ) : <TAB> <TAB> if workunit . has_label ( label ) : <TAB> <TAB> <TAB> return label_format <TAB> # Recursively look for a setting to suppress child label formatting. <TAB> if workunit . parent : <TAB> <TAB> label_format = self . _get_label_format ( workunit . parent ) <TAB> <TAB> if label_format == LabelFormat . CHILD_DOT : <TAB> <TAB> <TAB> return LabelFormat . DOT <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return LabelFormat . SUPPRESS <TAB> return LabelFormat . FULL ","if label_format == LabelFormat . CHILD_SUPPRESS : 
","elif label_format == LabelFormat . SUPPRESS :
",58.07,57.89,False
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> if stored_session : <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> if not expiration . tzinfo : <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ","if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : 
","if expiration . tzinfo < utc :
",28.56,3.59,False
"def _manage_torrent_cache ( self ) : <TAB> """"""Carry tracker/peer/file lists over to new torrent list"""""" <TAB> for torrent in self . _torrent_cache : <TAB> <TAB> new_torrent = rtorrentlib . common . find_torrent ( torrent . info_hash , self . torrents ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_torrent . files = torrent . files <TAB> <TAB> <TAB> new_torrent . peers = torrent . peers <TAB> <TAB> <TAB> new_torrent . trackers = torrent . trackers <TAB> self . _torrent_cache = self . torrents ","if new_torrent is not None : 
","if new_torrent :
",29.58,38.81,False
"def _clean_regions ( items , region ) : <TAB> """"""Intersect region with target file if it exists"""""" <TAB> variant_regions = bedutils . population_variant_regions ( items , merged = True ) <TAB> with utils . tmpfile ( ) as tx_out_file : <TAB> <TAB> target = subset_variant_regions ( variant_regions , region , tx_out_file , items ) <TAB> <TAB> if target : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> target = _load_regions ( target ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> target = [ target ] <TAB> <TAB> <TAB> return target ","if isinstance ( target , six . string_types ) and os . path . isfile ( target ) : 
","if isinstance ( target , list ) :
",34.35,11.71,False
def _get_stdout ( self ) : <TAB> while True : <TAB> <TAB> BUFFER_SIZE = 1000 <TAB> <TAB> stdout_buffer = self . kernel . process . GetSTDOUT ( BUFFER_SIZE ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> yield stdout_buffer ,"if len ( stdout_buffer ) == 0 : 
","if not stdout_buffer :
",26.99,14.92,False
"def do_query ( data , q ) : <TAB> ret = [ ] <TAB> if not q : <TAB> <TAB> return ret <TAB> qkey = q [ 0 ] <TAB> for key , value in iterate ( data ) : <TAB> <TAB> if len ( q ) == 1 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret . append ( value ) <TAB> <TAB> <TAB> elif is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if not is_iterable ( value ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if key == qkey : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q [ 1 : ] ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret . extend ( do_query ( value , q ) ) <TAB> return ret ","if key == qkey : 
","if key == qkey :
",100.0,100.0,True
"def test_expect_setecho_off ( self ) : <TAB> """"""This tests that echo may be toggled off."""""" <TAB> p = pexpect . spawn ( "" cat "" , echo = True , timeout = 5 ) <TAB> try : <TAB> <TAB> self . _expect_echo_toggle ( p ) <TAB> except IOError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if hasattr ( unittest , "" SkipTest "" ) : <TAB> <TAB> <TAB> <TAB> raise unittest . SkipTest ( "" Not supported on this platform. "" ) <TAB> <TAB> <TAB> return "" skip "" <TAB> <TAB> raise ","if sys . platform . lower ( ) . startswith ( "" sunos "" ) : 
","if sys . platform . lower ( ) . startswith ( "" sunos "" ) :
",100.0,100.0,True
"def _resolve_relative_config ( dir , config ) : <TAB> # Some code shared between Notebook and NotebookInfo <TAB> # Resolve icon, can be relative <TAB> icon = config . get ( "" icon "" ) <TAB> if icon : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> icon = File ( icon ) <TAB> <TAB> else : <TAB> <TAB> <TAB> icon = dir . resolve_file ( icon ) <TAB> # Resolve document_root, can also be relative <TAB> document_root = config . get ( "" document_root "" ) <TAB> if document_root : <TAB> <TAB> if zim . fs . isabs ( document_root ) or not dir : <TAB> <TAB> <TAB> document_root = Dir ( document_root ) <TAB> <TAB> else : <TAB> <TAB> <TAB> document_root = dir . resolve_dir ( document_root ) <TAB> return icon , document_root ","if zim . fs . isabs ( icon ) or not dir : 
","if zim . fs . isabs ( icon ) or not dir :
",100.0,100.0,True
"def _providers ( self , descriptor ) : <TAB> res = [ ] <TAB> for _md in self . metadata . values ( ) : <TAB> <TAB> for ent_id , ent_desc in _md . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if ent_id in res : <TAB> <TAB> <TAB> <TAB> <TAB> # print(""duplicated entity_id: %s"" % res) <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> res . append ( ent_id ) <TAB> return res ","if descriptor in ent_desc : 
","if ent_desc . get ( "" provider "" ) == descriptor :
",27.38,11.63,False
"def poll_ms ( self , timeout = - 1 ) : <TAB> s = bytearray ( self . evbuf ) <TAB> if timeout > = 0 : <TAB> <TAB> deadline = utime . ticks_add ( utime . ticks_ms ( ) , timeout ) <TAB> while True : <TAB> <TAB> n = epoll_wait ( self . epfd , s , 1 , timeout ) <TAB> <TAB> if not os . check_error ( n ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if timeout > = 0 : <TAB> <TAB> <TAB> timeout = utime . ticks_diff ( deadline , utime . ticks_ms ( ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> n = 0 <TAB> <TAB> <TAB> <TAB> break <TAB> res = [ ] <TAB> if n > 0 : <TAB> <TAB> vals = struct . unpack ( epoll_event , s ) <TAB> <TAB> res . append ( ( vals [ 1 ] , vals [ 0 ] ) ) <TAB> return res ","if timeout < 0 : 
","if timeout < 0 :
",100.0,100.0,True
"def banned ( ) : <TAB> if request . endpoint == "" views.themes "" : <TAB> <TAB> return <TAB> if authed ( ) : <TAB> <TAB> user = get_current_user_attrs ( ) <TAB> <TAB> team = get_current_team_attrs ( ) <TAB> <TAB> if user and user . banned : <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , error = "" You have been banned from this CTF "" <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return ( <TAB> <TAB> <TAB> <TAB> render_template ( <TAB> <TAB> <TAB> <TAB> <TAB> "" errors/403.html "" , <TAB> <TAB> <TAB> <TAB> <TAB> error = "" Your team has been banned from this CTF "" , <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> 403 , <TAB> <TAB> <TAB> ) ","if team and team . banned : 
","if team and team . banned :
",100.0,100.0,True
"def _update_read ( self ) : <TAB> """"""Update state when there is read event"""""" <TAB> try : <TAB> <TAB> msg = bytes ( self . _sock . recv ( 4096 ) ) <TAB> <TAB> if msg : <TAB> <TAB> <TAB> self . on_message ( msg ) <TAB> <TAB> <TAB> return True <TAB> <TAB> # normal close, remote is closed <TAB> <TAB> self . close ( ) <TAB> except socket . error as err : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> self . on_error ( err ) <TAB> return False ","if err . args [ 0 ] in ( errno . EAGAIN , errno . EWOULDBLOCK ) : 
","if err . errno in ( errno . EAGAIN , errno . EWOULDBLOCK ) :
",70.58,65.52,False
"def update_topic_attr_as_not ( modeladmin , request , queryset , attr ) : <TAB> for topic in queryset : <TAB> <TAB> if attr == "" sticky "" : <TAB> <TAB> <TAB> topic . sticky = not topic . sticky <TAB> <TAB> elif attr == "" closed "" : <TAB> <TAB> <TAB> topic . closed = not topic . closed <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> topic . hidden = not topic . hidden <TAB> <TAB> topic . save ( ) ","elif attr == "" hidden "" : 
","elif attr == "" hidden "" :
",100.0,100.0,True
"def Startprobe ( self , q ) : <TAB> while not self . finished : <TAB> <TAB> try : <TAB> <TAB> <TAB> sniff ( iface = self . interface , count = 10 , prn = lambda x : q . put ( x ) ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if self . finished : 
","if self . finished :
",100.0,100.0,True
"def _maybe_female ( self , path_elements , female , strict ) : <TAB> if female : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elements = path_elements + [ "" female "" ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return self . _get_file ( elements , "" .png "" , strict = strict ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> if strict : <TAB> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> elif strict : <TAB> <TAB> <TAB> raise ValueError ( "" Pokemon  %s  has no gender differences "" % self . species_id ) <TAB> return self . _get_file ( path_elements , "" .png "" , strict = strict ) ","if self . has_gender_differences : 
","if self . species_id not in path_elements :
",44.36,14.99,False
"def change_args_to_dict ( string ) : <TAB> if string is None : <TAB> <TAB> return None <TAB> ans = [ ] <TAB> strings = string . split ( "" \n "" ) <TAB> ind = 1 <TAB> start = 0 <TAB> while ind < = len ( strings ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ind + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if start < ind : <TAB> <TAB> <TAB> <TAB> ans . append ( "" \n "" . join ( strings [ start : ind ] ) ) <TAB> <TAB> <TAB> start = ind <TAB> <TAB> <TAB> ind + = 1 <TAB> d = { } <TAB> for line in ans : <TAB> <TAB> if "" : "" in line and len ( line ) > 0 : <TAB> <TAB> <TAB> lines = line . split ( "" : "" ) <TAB> <TAB> <TAB> d [ lines [ 0 ] ] = lines [ 1 ] . strip ( ) <TAB> return d ","if ind < len ( strings ) and strings [ ind ] . startswith ( "" "" ) : 
","if strings [ ind ] == "" \n "" :
",34.27,14.07,False
"def _send_with_auth ( self , req_kwargs , desired_auth , rsession ) : <TAB> if desired_auth . oauth : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _oauth_creds . refresh ( httplib2 . Http ( ) ) <TAB> <TAB> req_kwargs [ "" headers "" ] = req_kwargs . get ( "" headers "" , { } ) <TAB> <TAB> req_kwargs [ "" headers "" ] [ "" Authorization "" ] = ( <TAB> <TAB> <TAB> "" Bearer  "" + self . _oauth_creds . access_token <TAB> <TAB> ) <TAB> return rsession . request ( * * req_kwargs ) ","if self . _oauth_creds . access_token_expired : 
","if not self . _oauth_creds . is_valid :
",58.61,47.62,False
"def parse_search_response ( json_data ) : <TAB> """"""Construct response for any input"""""" <TAB> if json_data is None : <TAB> <TAB> return { "" error "" : "" Error parsing empty search engine response "" } <TAB> try : <TAB> <TAB> return json . loads ( json_data ) <TAB> except json . JSONDecodeError : <TAB> <TAB> logger . exception ( "" Error parsing search engine response "" ) <TAB> <TAB> m = re_pre . search ( json_data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return { "" error "" : "" Error parsing search engine response "" } <TAB> <TAB> error = web . htmlunquote ( m . group ( 1 ) ) <TAB> <TAB> solr_error = "" org.apache.lucene.queryParser.ParseException:  "" <TAB> <TAB> if error . startswith ( solr_error ) : <TAB> <TAB> <TAB> error = error [ len ( solr_error ) : ] <TAB> <TAB> return { "" error "" : error } ","if m is None : 
","if not m :
",28.67,16.37,False
"def wrapper ( * args , * * kws ) : <TAB> missing = [ ] <TAB> saved = getattr ( warnings , "" __warningregistry__ "" , missing ) . copy ( ) <TAB> try : <TAB> <TAB> return func ( * args , * * kws ) <TAB> finally : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> del warnings . __warningregistry__ <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> warnings . __warningregistry__ = saved ","if saved is missing : 
","if saved is missing :
",100.0,100.0,True
"def parse_expression ( self ) : <TAB> """"""Return string containing command to run."""""" <TAB> expression_el = self . root . find ( "" expression "" ) <TAB> if expression_el is not None : <TAB> <TAB> expression_type = expression_el . get ( "" type "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Unknown expression type [ %s ] encountered "" % expression_type <TAB> <TAB> <TAB> ) <TAB> <TAB> return expression_el . text <TAB> return None ","if expression_type != "" ecma5.1 "" : 
","if expression_type is not None and expression_type != "" string "" :
",46.35,38.54,False
"def test_geocode ( ) : <TAB> # look for tweets from New York ; the search radius is larger than NYC <TAB> # so hopefully we'll find one from New York in the first 500? <TAB> count = 0 <TAB> found = False <TAB> for tweet in T . search ( None , geocode = "" 40.7484,-73.9857,1mi "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> break <TAB> <TAB> if count > 500 : <TAB> <TAB> <TAB> break <TAB> <TAB> count + = 1 <TAB> assert found ","if ( tweet [ "" place "" ] or { } ) . get ( "" name "" ) == "" Manhattan "" : 
","if tweet . radius == "" NYC "" :
",31.87,4.93,False
"def __init__ ( self , name : Optional [ str ] = None , order : int = 0 ) : <TAB> if name is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = "" std_dev "" <TAB> <TAB> elif order == 1 : <TAB> <TAB> <TAB> name = "" sample_std_dev "" <TAB> <TAB> else : <TAB> <TAB> <TAB> name = f "" std_dev { order } ) "" <TAB> super ( ) . __init__ ( name = name , order = order ) <TAB> self . order = order ","if order == 0 : 
","if order == 0 :
",100.0,100.0,True
"def __cmp__ ( self , other ) : <TAB> if isinstance ( other , date ) or isinstance ( other , datetime ) : <TAB> <TAB> a = self . _d . getTime ( ) <TAB> <TAB> b = other . _d . getTime ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> elif a == b : <TAB> <TAB> <TAB> return 0 <TAB> else : <TAB> <TAB> raise TypeError ( "" expected date or datetime object "" ) <TAB> return 1 ","if a < b : 
","if a > b :
",58.14,30.21,False
"def run ( self ) : <TAB> tid = self . ident <TAB> try : <TAB> <TAB> with self . _lock : <TAB> <TAB> <TAB> _GUIS [ tid ] = self <TAB> <TAB> <TAB> self . _state ( True ) <TAB> <TAB> self . new_mail_notifications ( summarize = True ) <TAB> <TAB> loop_count = 0 <TAB> <TAB> while self . _sock : <TAB> <TAB> <TAB> loop_count + = 1 <TAB> <TAB> <TAB> self . _select_sleep ( 1 )<TAB> # FIXME: Lengthen this when possible <TAB> <TAB> <TAB> self . change_state ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # FIXME: This involves a fair number of set operations, <TAB> <TAB> <TAB> <TAB> #<TAB> <TAB> should only do this after new mail has arrived.<TAB> <TAB> <TAB> <TAB> self . new_mail_notifications ( ) <TAB> finally : <TAB> <TAB> del _GUIS [ tid ] ","if loop_count % 5 == 0 : 
","if loop_count == self . _max_loop_count :
",29.28,20.33,False
"def __cache_dimension_masks ( self , * args ) : <TAB> # cache masks for each feature map we'll need <TAB> if len ( self . masks ) == 0 : <TAB> <TAB> for m1 in args : <TAB> <TAB> <TAB> batch_size , emb_dim , h , w = m1 . size ( ) <TAB> <TAB> <TAB> # make mask <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> mask = self . feat_size_w_mask ( h , m1 ) <TAB> <TAB> <TAB> <TAB> self . masks [ h ] = mask ","if h not in self . masks : 
","if w > batch_size :
",26.74,6.77,False
"def __call__ ( self , * flattened_representation ) : <TAB> unflattened_representation = [ ] <TAB> for index , subtree in self . children : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unflattened_representation . append ( flattened_representation [ index ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sub_representation = flattened_representation [ index ] <TAB> <TAB> <TAB> unflattened_representation . append ( subtree ( * sub_representation ) ) <TAB> return self . _cls ( * unflattened_representation , * * self . _kwargs ) ","if subtree is None : 
","if isinstance ( subtree , NestedRepresentation ) :
",27.52,7.27,False
"def click_outside ( event ) : <TAB> if event not in d : <TAB> <TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB> <TAB> if y == 0 : <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y + = 3 <TAB> <TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d . dismiss ( "" Goto "" ) ","if event . num_clicks == 2 : 
","if self . blockFaceUnderCursor [ 1 ] :
",33.36,5.66,False
"def get_mapped_input_keysequences ( self , mode = "" global "" , prefix = u "" "" ) : <TAB> # get all bindings in this mode <TAB> globalmaps , modemaps = self . get_keybindings ( mode ) <TAB> candidates = list ( globalmaps . keys ( ) ) + list ( modemaps . keys ( ) ) <TAB> if prefix is not None : <TAB> <TAB> prefixes = prefix + "" "" <TAB> <TAB> cand = [ c for c in candidates if c . startswith ( prefixes ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> candidates = cand + [ prefix ] <TAB> <TAB> else : <TAB> <TAB> <TAB> candidates = cand <TAB> return candidates ","if prefix in candidates : 
","if prefix :
",31.47,0.0,False
"def _set_length ( self , length ) : <TAB> with self . _cond : <TAB> <TAB> self . _length = length <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _ready = True <TAB> <TAB> <TAB> self . _cond . notify ( ) <TAB> <TAB> <TAB> del self . _cache [ self . _job ] ","if self . _index == self . _length : 
","if self . _length == 0 :
",44.62,38.03,False
"def _pct_encoded_replace_unreserved ( mo ) : <TAB> try : <TAB> <TAB> i = int ( mo . group ( 1 ) , 16 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return chr ( i ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return mo . group ( ) . upper ( ) <TAB> except ValueError : <TAB> <TAB> return mo . group ( ) ","if _unreserved [ i ] : 
","if i > = 0x20 and i < 0x7F :
",27.16,5.52,False
"def is_open ( self ) : <TAB> if self . signup_code : <TAB> <TAB> return True <TAB> else : <TAB> <TAB> if self . signup_code_present : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> messages . add_message ( <TAB> <TAB> <TAB> <TAB> <TAB> self . request , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" level "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> self . messages [ "" invalid_signup_code "" ] [ "" text "" ] . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> * * { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" code "" : self . get_code ( ) , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) , <TAB> <TAB> <TAB> <TAB> ) <TAB> return settings . ACCOUNT_OPEN_SIGNUP ","if self . messages . get ( "" invalid_signup_code "" ) : 
","if settings . ACCOUNT_OPEN_SIGNUP not in self . messages [ "" invalid_signup_code "" ] :
",39.19,32.92,False
"def _get_field_value ( self , test , key , match ) : <TAB> if test . ver == ofproto_v1_0 . OFP_VERSION : <TAB> <TAB> members = inspect . getmembers ( match ) <TAB> <TAB> for member in members : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> field_value = member [ 1 ] <TAB> <TAB> <TAB> elif member [ 0 ] == "" wildcards "" : <TAB> <TAB> <TAB> <TAB> wildcards = member [ 1 ] <TAB> <TAB> if key == "" nw_src "" : <TAB> <TAB> <TAB> field_value = test . nw_src_to_str ( wildcards , field_value ) <TAB> <TAB> elif key == "" nw_dst "" : <TAB> <TAB> <TAB> field_value = test . nw_dst_to_str ( wildcards , field_value ) <TAB> else : <TAB> <TAB> field_value = match [ key ] <TAB> return field_value ","if member [ 0 ] == key : 
","if member [ 0 ] == "" field_value "" :
",62.57,48.63,False
"def move_sender_strings_to_sender_model ( apps , schema_editor ) : <TAB> sender_model = apps . get_model ( "" documents "" , "" Sender "" ) <TAB> document_model = apps . get_model ( "" documents "" , "" Document "" ) <TAB> # Create the sender and log the relationship with the document <TAB> for document in document_model . objects . all ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ( <TAB> <TAB> <TAB> <TAB> DOCUMENT_SENDER_MAP [ document . pk ] , <TAB> <TAB> <TAB> <TAB> created , <TAB> <TAB> <TAB> ) = sender_model . objects . get_or_create ( <TAB> <TAB> <TAB> <TAB> name = document . sender , defaults = { "" slug "" : slugify ( document . sender ) } <TAB> <TAB> <TAB> ) ","if document . sender : 
","if document . sender in sender_model . objects . all ( ) :
",56.12,17.4,False
"def compute_output_shape ( self , input_shape ) : <TAB> if None not in input_shape [ 1 : ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> total = np . prod ( input_shape [ 2 : 4 ] ) * self . num_anchors <TAB> <TAB> else : <TAB> <TAB> <TAB> total = np . prod ( input_shape [ 1 : 3 ] ) * self . num_anchors <TAB> <TAB> return ( input_shape [ 0 ] , total , 4 ) <TAB> else : <TAB> <TAB> return ( input_shape [ 0 ] , None , 4 ) ","if keras . backend . image_data_format ( ) == "" channels_first "" : 
","if self . use_multi_output :
",29.07,2.1,False
"def decompress ( self , value ) : <TAB> if value : <TAB> <TAB> if type ( value ) == PhoneNumber : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return [ <TAB> <TAB> <TAB> <TAB> <TAB> "" + %d "" % value . country_code , <TAB> <TAB> <TAB> <TAB> <TAB> national_significant_number ( value ) , <TAB> <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return value . split ( "" . "" ) <TAB> return [ None , "" "" ] ","if value . country_code and value . national_number : 
","if value . country_code :
",50.74,35.69,False
"def ignore ( self , other ) : <TAB> if isinstance ( other , Suppress ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> <TAB> if self . expr is not None : <TAB> <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> else : <TAB> <TAB> super ( ParseElementEnhance , self ) . ignore ( other ) <TAB> <TAB> if self . expr is not None : <TAB> <TAB> <TAB> self . expr . ignore ( self . ignoreExprs [ - 1 ] ) <TAB> return self ","if other not in self . ignoreExprs : 
","if other not in self . ignoreExprs :
",100.0,100.0,True
"def mkdir ( self , mode = 0o777 , parents = False , exist_ok = False ) : <TAB> if self . _closed : <TAB> <TAB> self . _raise_closed ( ) <TAB> if not parents : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode ) <TAB> <TAB> except FileExistsError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode ) <TAB> <TAB> except FileExistsError : <TAB> <TAB> <TAB> if not exist_ok or not self . is_dir ( ) : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> except OSError as e : <TAB> <TAB> <TAB> if e . errno != ENOENT : <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self . parent . mkdir ( parents = True ) <TAB> <TAB> <TAB> self . _accessor . mkdir ( self , mode ) ","if not exist_ok or not self . is_dir ( ) : 
","if not exist_ok or not self . is_dir ( ) :
",100.0,100.0,True
"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB> <TAB> if dirs [ m , n ] == "" | "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> <TAB> mask [ m ] = 1 <TAB> <TAB> elif dirs [ m , n ] == "" ^ "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask ","elif dirs [ m , n ] == "" < "" : 
","elif dirs [ m , n ] == "" ~ "" :
",88.57,79.11,False
"def clean ( self , * args , * * kwargs ) : <TAB> data = super ( ) . clean ( * args , * * kwargs ) <TAB> if isinstance ( data , File ) : <TAB> <TAB> filename = data . name <TAB> <TAB> ext = os . path . splitext ( filename ) [ 1 ] <TAB> <TAB> ext = ext . lower ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise forms . ValidationError ( _ ( "" Filetype not allowed! "" ) ) <TAB> return data ","if ext not in self . ext_whitelist : 
","if not self . _is_filetype ( filename , ext ) :
",33.21,7.77,False
"def get_doc_object ( obj , what = None ) : <TAB> if what is None : <TAB> <TAB> if inspect . isclass ( obj ) : <TAB> <TAB> <TAB> what = "" class "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> what = "" module "" <TAB> <TAB> elif callable ( obj ) : <TAB> <TAB> <TAB> what = "" function "" <TAB> <TAB> else : <TAB> <TAB> <TAB> what = "" object "" <TAB> if what == "" class "" : <TAB> <TAB> return SphinxClassDoc ( obj , "" "" , func_doc = SphinxFunctionDoc ) <TAB> elif what in ( "" function "" , "" method "" ) : <TAB> <TAB> return SphinxFunctionDoc ( obj , "" "" ) <TAB> else : <TAB> <TAB> return SphinxDocString ( pydoc . getdoc ( obj ) ) ","elif inspect . ismodule ( obj ) : 
","elif inspect . ismodule ( obj ) :
",100.0,100.0,True
"def apply_pssm ( val ) : <TAB> if val is not None : <TAB> <TAB> val_c = PSSM_VALUES . get ( val , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert isinstance ( <TAB> <TAB> <TAB> <TAB> val , tuple ( PSSM_VALUES . values ( ) ) <TAB> <TAB> <TAB> ) , "" ' store_as '  should be one of:  %r  or an instance of  %r  not  %r "" % ( <TAB> <TAB> <TAB> <TAB> tuple ( PSSM_VALUES . keys ( ) ) , <TAB> <TAB> <TAB> <TAB> tuple ( PSSM_VALUES . values ( ) ) , <TAB> <TAB> <TAB> <TAB> val , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return val <TAB> <TAB> return val_c ( ) ","if val_c is None : 
","if val_c is None :
",100.0,100.0,True
"def read_postmaster_opts ( self ) : <TAB> """"""returns the list of option names/values from postgres.opts, Empty dict if read failed or no file"""""" <TAB> result = { } <TAB> try : <TAB> <TAB> with open ( os . path . join ( self . _postgresql . data_dir , "" postmaster.opts "" ) ) as f : <TAB> <TAB> <TAB> data = f . read ( ) <TAB> <TAB> <TAB> for opt in data . split ( ' "" "" ' ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> name , val = opt . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> <TAB> <TAB> result [ name . strip ( "" - "" ) ] = val . rstrip ( ' "" \n ' ) <TAB> except IOError : <TAB> <TAB> logger . exception ( "" Error when reading postmaster.opts "" ) <TAB> return result ","if "" = "" in opt and opt . startswith ( "" -- "" ) : 
","if opt . startswith ( "" -- "" ) :
",63.74,49.59,False
"def detect ( get_page ) : <TAB> retval = False <TAB> for vector in WAF_ATTACK_VECTORS : <TAB> <TAB> page , headers , code = get_page ( get = vector ) <TAB> <TAB> retval = ( <TAB> <TAB> <TAB> re . search ( r "" F5-TrafficShield "" , headers . get ( HTTP_HEADER . SERVER , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> retval | = ( <TAB> <TAB> <TAB> re . search ( r "" \ AASINFO= "" , headers . get ( HTTP_HEADER . SET_COOKIE , "" "" ) , re . I ) <TAB> <TAB> <TAB> is not None <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return retval ","if retval : 
","if retval :
",78.12,0.0,False
"def on_task_start ( self , task , config ) : <TAB> for item in config : <TAB> <TAB> for plugin_name , plugin_config in item . items ( ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> thelist = plugin . get ( plugin_name , self ) . get_list ( plugin_config ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> raise PluginError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Plugin  %s  does not support list interface "" % plugin_name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise plugin . PluginError ( thelist . immutable ) ","if thelist . immutable : 
","if thelist . immutable :
",100.0,100.0,True
"def nq ( t ) : <TAB> p = t [ 0 ] if ( t and t [ 0 ] in "" -+ "" ) else "" "" <TAB> t = t [ len ( p ) : ] <TAB> if t . startswith ( "" tag: "" ) or t . startswith ( "" in: "" ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> raw_tag = session . config . get_tag ( t . split ( "" : "" ) [ 1 ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> t = "" in: %s "" % raw_tag . slug <TAB> <TAB> except ( IndexError , KeyError , TypeError ) : <TAB> <TAB> <TAB> pass <TAB> return p + t ","if raw_tag and raw_tag . hasattr ( slug ) : 
","if raw_tag :
",26.96,11.69,False
"def _recur_strip ( s ) : <TAB> if is_str ( s ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" "" . join ( s . strip ( ) . split ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" "" . join ( s . strip ( ) . split ( ) ) . replace ( bos_token + "" "" , "" "" ) <TAB> else : <TAB> <TAB> s_ = [ _recur_strip ( si ) for si in s ] <TAB> <TAB> return _maybe_list_to_array ( s_ , s ) ","if bos_token == "" "" : 
","if bos_token == "" "" :
",100.0,100.0,True
"def __delitem__ ( self , key ) : <TAB> "" Deleting tag[key] deletes all  ' key '  attributes for the tag. "" <TAB> for item in self . attrs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . attrs . remove ( item ) <TAB> <TAB> <TAB> # We don't break because bad HTML can define the same <TAB> <TAB> <TAB> # attribute multiple times. <TAB> <TAB> self . _getAttrMap ( ) <TAB> <TAB> if self . attrMap . has_key ( key ) : <TAB> <TAB> <TAB> del self . attrMap [ key ] ","if item [ 0 ] == key : 
","if item . get ( key ) == key :
",32.81,27.9,False
"def comment_import_help ( init_file , out_file ) : <TAB> f_out = open ( out_file , "" w "" ) <TAB> output = "" "" <TAB> updated = False <TAB> with open ( init_file , "" r "" ) as f_in : <TAB> <TAB> for line in f_in : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> updated = True <TAB> <TAB> <TAB> <TAB> line = "" #  "" + line <TAB> <TAB> <TAB> output + = line <TAB> f_out . write ( output ) <TAB> f_out . close ( ) <TAB> return updated ","if "" import "" in line and "" _help "" in line and not updated : 
","if line . startswith ( "" #  "" ) :
",31.4,3.12,False
"def prepare_text ( lines ) : <TAB> out = [ ] <TAB> for s in lines . split ( "" | "" ) : <TAB> <TAB> s = s . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # line beginning with '/' is in italics <TAB> <TAB> <TAB> s = r "" { \ i1} %s { \ i0} "" % s [ 1 : ] . strip ( ) <TAB> <TAB> out . append ( s ) <TAB> return "" \\ N "" . join ( out ) ","if s . startswith ( "" / "" ) : 
","if s . startswith ( "" / "" ) and s . startswith ( "" / "" ) :
",78.73,48.25,False
"def sqlctx ( sc ) : <TAB> pytest . importorskip ( "" pyspark "" ) <TAB> from odo . backends . sparksql import HiveContext <TAB> try : <TAB> <TAB> yield HiveContext ( sc ) <TAB> finally : <TAB> <TAB> dbpath = "" metastore_db "" <TAB> <TAB> logpath = "" derby.log "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert os . path . isdir ( dbpath ) <TAB> <TAB> <TAB> shutil . rmtree ( dbpath ) <TAB> <TAB> if os . path . exists ( logpath ) : <TAB> <TAB> <TAB> assert os . path . isfile ( logpath ) <TAB> <TAB> <TAB> os . remove ( logpath ) ","if os . path . exists ( dbpath ) : 
","if os . path . exists ( dbpath ) :
",100.0,100.0,True
"def _user2dict ( self , uid ) : <TAB> usdict = None <TAB> if uid in self . users : <TAB> <TAB> usdict = self . users [ uid ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> infos = self . users_info [ uid ] <TAB> <TAB> <TAB> for attr in infos : <TAB> <TAB> <TAB> <TAB> usdict [ attr [ "" attr_type "" ] ] = attr [ "" attr_data "" ] <TAB> <TAB> usdict [ "" uid "" ] = uid <TAB> return usdict ","if uid in self . users_info : 
","if uid in self . users_info :
",100.0,100.0,True
"def _validate_options ( self ) : <TAB> for option in self . options : <TAB> <TAB> # if value type is bool or int, then we know the options is set <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . options . required [ option ] is True and not self . options [ option ] : <TAB> <TAB> <TAB> <TAB> if option == Constants . PASSWORD_CLEAR : <TAB> <TAB> <TAB> <TAB> <TAB> option = "" password "" . upper ( ) <TAB> <TAB> <TAB> <TAB> raise FrameworkException ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Value required for the  ' %s '  option. "" % ( option . upper ( ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return ","if not type ( self . options [ option ] ) in [ bool , int ] : 
","if not isinstance ( self . options [ option ] , bool ) :
",49.95,39.43,False
"def _copy_package_apps ( <TAB> local_bin_dir : Path , app_paths : List [ Path ] , suffix : str = "" "" ) - > None : <TAB> for src_unresolved in app_paths : <TAB> <TAB> src = src_unresolved . resolve ( ) <TAB> <TAB> app = src . name <TAB> <TAB> dest = Path ( local_bin_dir / add_suffix ( app , suffix ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mkdir ( dest . parent ) <TAB> <TAB> if dest . exists ( ) : <TAB> <TAB> <TAB> logger . warning ( f "" { hazard }   Overwriting file  { str ( dest ) }  with  { str ( src ) } "" ) <TAB> <TAB> <TAB> dest . unlink ( ) <TAB> <TAB> if src . exists ( ) : <TAB> <TAB> <TAB> shutil . copy ( src , dest ) ","if not dest . parent . is_dir ( ) : 
","if not dest . exists ( ) :
",51.8,30.33,False
"def truncate_seq_pair ( tokens_a , tokens_b , max_length ) : <TAB> """"""Truncates a sequence pair in place to the maximum length."""""" <TAB> # This is a simple heuristic which will always truncate the longer sequence <TAB> # one token at a time. This makes more sense than truncating an equal percent <TAB> # of tokens from each, since if one sequence is very short then each token <TAB> # that's truncated likely contains more information than a longer sequence. <TAB> while True : <TAB> <TAB> total_length = len ( tokens_a ) + len ( tokens_b ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> if len ( tokens_a ) > len ( tokens_b ) : <TAB> <TAB> <TAB> tokens_a . pop ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> tokens_b . pop ( ) ","if total_length < = max_length : 
","if total_length < = max_length :
",100.0,100.0,True
"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB> <TAB> channel = add_channel [ "" channel "" ] <TAB> <TAB> defaults = { "" currency "" : channel . currency_code } <TAB> <TAB> if "" discount_value "" in add_channel . keys ( ) : <TAB> <TAB> <TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB> <TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB> <TAB> <TAB> voucher = voucher , <TAB> <TAB> <TAB> channel = channel , <TAB> <TAB> <TAB> defaults = defaults , <TAB> <TAB> ) ","if "" min_amount_spent "" in add_channel . keys ( ) : 
","if "" min_amount_spent "" in add_channel . keys ( ) :
",100.0,100.0,True
"def services ( self , id = None , name = None ) : <TAB> for service_dict in self . service_ls ( id = id , name = name ) : <TAB> <TAB> service_id = service_dict [ "" ID "" ] <TAB> <TAB> service_name = service_dict [ "" NAME "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> task_list = self . service_ps ( service_id ) <TAB> <TAB> yield DockerService . from_cli ( self , service_dict , task_list ) ","if not service_name . startswith ( self . _name_prefix ) : 
","if service_name != "" docker "" :
",26.28,9.74,False
"def lll ( dirname ) : <TAB> for name in os . listdir ( dirname ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> full = os . path . join ( dirname , name ) <TAB> <TAB> <TAB> if os . path . islink ( full ) : <TAB> <TAB> <TAB> <TAB> print ( name , "" -> "" , os . readlink ( full ) ) ","if name not in ( os . curdir , os . pardir ) : 
","if name . endswith ( "" .py "" ) and not os . path . islink ( name ) :
",34.57,6.96,False
"def convertstore ( self , mydict ) : <TAB> targetheader = self . mypofile . header ( ) <TAB> targetheader . addnote ( "" extracted from web2py "" , "" developer "" ) <TAB> for source_str in mydict . keys ( ) : <TAB> <TAB> target_str = mydict [ source_str ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # a convention with new (untranslated) web2py files <TAB> <TAB> <TAB> target_str = u "" "" <TAB> <TAB> elif target_str . startswith ( u "" ***  "" ) : <TAB> <TAB> <TAB> # an older convention <TAB> <TAB> <TAB> target_str = u "" "" <TAB> <TAB> pounit = self . convertunit ( source_str , target_str ) <TAB> <TAB> self . mypofile . addunit ( pounit ) <TAB> return self . mypofile ","if target_str == source_str : 
","if target_str == u "" * "" :
",36.03,47.99,False
"def __init__ ( self , * * kwargs ) : <TAB> for k , v in kwargs . items ( ) : <TAB> <TAB> setattr ( self , k , v ) <TAB> self . attempted_charsets = set ( ) <TAB> request = cherrypy . serving . request <TAB> if request . handler is not None : <TAB> <TAB> # Replace request.handler with self <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cherrypy . log ( "" Replacing request.handler "" , "" TOOLS.ENCODE "" ) <TAB> <TAB> self . oldhandler = request . handler <TAB> <TAB> request . handler = self ","if self . debug : 
","if cherrypy . logging . isEnabledFor ( logging . DEBUG ) :
",35.78,4.46,False
"def _fastqc_data_section ( self , section_name ) : <TAB> out = [ ] <TAB> in_section = False <TAB> data_file = os . path . join ( self . _dir , "" fastqc_data.txt "" ) <TAB> if os . path . exists ( data_file ) : <TAB> <TAB> with open ( data_file ) as in_handle : <TAB> <TAB> <TAB> for line in in_handle : <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >> %s "" % section_name ) : <TAB> <TAB> <TAB> <TAB> <TAB> in_section = True <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> if line . startswith ( "" >>END "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( line . rstrip ( "" \r \n "" ) ) <TAB> return out ","elif in_section : 
","if in_section :
",35.87,66.87,False
"def bit_length ( n ) : <TAB> try : <TAB> <TAB> return n . bit_length ( ) <TAB> except AttributeError : <TAB> <TAB> norm = deflate_long ( n , False ) <TAB> <TAB> hbyte = byte_ord ( norm [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 1 <TAB> <TAB> bitlen = len ( norm ) * 8 <TAB> <TAB> while not ( hbyte & 0x80 ) : <TAB> <TAB> <TAB> hbyte << = 1 <TAB> <TAB> <TAB> bitlen - = 1 <TAB> <TAB> return bitlen ","if hbyte == 0 : 
","if hbyte == 0 :
",100.0,100.0,True
"def step ( self , action ) : <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> if i == self . _skip - 2 : <TAB> <TAB> <TAB> self . _obs_buffer [ 0 ] = obs <TAB> <TAB> if i == self . _skip - 1 : <TAB> <TAB> <TAB> self . _obs_buffer [ 1 ] = obs <TAB> <TAB> total_reward + = reward <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB> return max_frame , total_reward , done , info ","if done : 
","if done :
",78.12,0.0,False
"def _sample_translation ( reference , max_len ) : <TAB> translation = reference [ : ] <TAB> while np . random . uniform ( ) < 0.8 and 1 < len ( translation ) < max_len : <TAB> <TAB> trans_len = len ( translation ) <TAB> <TAB> ind = np . random . randint ( trans_len ) <TAB> <TAB> action = np . random . choice ( actions ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del translation [ ind ] <TAB> <TAB> elif action == "" replacement "" : <TAB> <TAB> <TAB> ind_rep = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation [ ind ] = translation [ ind_rep ] <TAB> <TAB> else : <TAB> <TAB> <TAB> ind_insert = np . random . randint ( trans_len ) <TAB> <TAB> <TAB> translation . insert ( ind , translation [ ind_insert ] ) <TAB> return translation ","if action == "" deletion "" : 
","if action == "" delete "" :
",74.63,59.46,False
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> if sign is None : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if sign * ki < - slop : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq ","if ki != 0 : 
","elif sign * ki > slop :
",27.36,7.81,False
def get_dirlist ( _rootdir ) : <TAB> dirlist = [ ] <TAB> with os . scandir ( _rootdir ) as rit : <TAB> <TAB> for entry in rit : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> dirlist . append ( entry . path ) <TAB> <TAB> <TAB> <TAB> dirlist + = get_dirlist ( entry . path ) <TAB> return dirlist ,"if not entry . name . startswith ( "" . "" ) and entry . is_dir ( ) : 
","if entry . is_dir ( ) and entry . name . endswith ( "" .rst "" ) :
",65.97,58.74,False
"def __init__ ( <TAB> self , <TAB> fixed : MQTTFixedHeader = None , <TAB> variable_header : PublishVariableHeader = None , <TAB> payload = None , ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PUBLISH , 0x00 ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise HBMQTTException ( <TAB> <TAB> <TAB> <TAB> "" Invalid fixed packet type  %s  for PublishPacket init "" <TAB> <TAB> <TAB> <TAB> % fixed . packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = variable_header <TAB> self . payload = payload ","if fixed . packet_type is not PUBLISH : 
","if fixed . packet_type is not PUBLISH :
",100.0,100.0,True
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname == "" PureMVC_Python_1_0 "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" :<TAB> # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . isdir ( p ) : <TAB> <TAB> <TAB> get_dir ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res . append ( p ) <TAB> return res ","if fname == "" output "" : 
","if pth . startswith ( "" . "" ) :
",33.24,5.93,False
"def reward ( self ) : <TAB> """"""Returns a tuple of sum of raw and processed rewards."""""" <TAB> raw_rewards , processed_rewards = 0 , 0 <TAB> for ts in self . time_steps : <TAB> <TAB> # NOTE: raw_reward and processed_reward are None for the first time-step. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raw_rewards + = ts . raw_reward <TAB> <TAB> if ts . processed_reward is not None : <TAB> <TAB> <TAB> processed_rewards + = ts . processed_reward <TAB> return raw_rewards , processed_rewards ","if ts . raw_reward is not None : 
","if ts . raw_reward is not None :
",100.0,100.0,True
"def _process_file ( self , content ) : <TAB> args = [ ] <TAB> for line in content . splitlines ( ) : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . extend ( self . _split_option ( line ) ) <TAB> <TAB> elif line and not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> args . append ( line ) <TAB> return args ","if line . startswith ( "" - "" ) : 
","if self . _option_re . match ( line ) :
",32.17,8.13,False
"def __on_change_button_clicked ( self , widget = None ) : <TAB> """"""compute all primary objects and toggle the 'Change' attribute"""""" <TAB> self . change_status = not self . change_status <TAB> for prim_obj , tmp in self . xobjects : <TAB> <TAB> obj_change = self . top . get_object ( "" %s _change "" % prim_obj ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . change_entries [ prim_obj ] . set_val ( self . change_status ) <TAB> <TAB> obj_change . set_active ( self . change_status ) ","if not obj_change . get_sensitive ( ) : 
","if not obj_change :
",33.02,29.26,False
"def aiter_cogs ( cls ) - > AsyncIterator [ Tuple [ str , str ] ] : <TAB> yield "" Core "" , "" 0 "" <TAB> for _dir in data_manager . cog_data_path ( ) . iterdir ( ) : <TAB> <TAB> fpath = _dir / "" settings.json "" <TAB> <TAB> if not fpath . exists ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> with fpath . open ( ) as f : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> data = json . load ( f ) <TAB> <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> cog_name = _dir . stem <TAB> <TAB> for cog_id , inner in data . items ( ) : <TAB> <TAB> <TAB> if not isinstance ( inner , dict ) : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield cog_name , cog_id ","if not isinstance ( data , dict ) : 
","if not data :
",28.14,10.88,False
"def _verifySubs ( self ) : <TAB> for inst in self . subs : <TAB> <TAB> if not isinstance ( inst , ( _Block , _Instantiator , Cosimulation ) ) : <TAB> <TAB> <TAB> raise BlockError ( _error . ArgType % ( self . name , ) ) <TAB> <TAB> if isinstance ( inst , ( _Block , _Instantiator ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise BlockError ( _error . InstanceError % ( self . name , inst . callername ) ) ","if not inst . modctxt : 
","if not inst . is_valid :
",77.23,36.56,False
"def _is_xml ( accepts ) : <TAB> if accepts . startswith ( b "" application/ "" ) : <TAB> <TAB> has_xml = accepts . find ( b "" xml "" ) <TAB> <TAB> if has_xml > 0 : <TAB> <TAB> <TAB> semicolon = accepts . find ( b "" ; "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if semicolon < 0 or has_xml < semicolon : 
","if semicolon > 0 and has_xml > 0 and semicolon != b "" ; "" :
",32.47,10.66,False
"def _accept_with ( cls , orm , target ) : <TAB> if target is orm . mapper : <TAB> <TAB> return mapperlib . Mapper <TAB> elif isinstance ( target , type ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return target <TAB> <TAB> else : <TAB> <TAB> <TAB> mapper = _mapper_or_none ( target ) <TAB> <TAB> <TAB> if mapper is not None : <TAB> <TAB> <TAB> <TAB> return mapper <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return _MapperEventsHold ( target ) <TAB> else : <TAB> <TAB> return target ","if issubclass ( target , mapperlib . Mapper ) : 
","if isinstance ( target , mapperlib . Mapper ) :
",89.28,78.25,False
"def _get_font_afm ( self , prop ) : <TAB> key = hash ( prop ) <TAB> font = self . afmfontd . get ( key ) <TAB> <MASK> <TAB> <TAB> fname = findfont ( prop , fontext = "" afm "" ) <TAB> <TAB> font = self . afmfontd . get ( fname ) <TAB> <TAB> if font is None : <TAB> <TAB> <TAB> font = AFM ( file ( findfont ( prop , fontext = "" afm "" ) ) ) <TAB> <TAB> <TAB> self . afmfontd [ fname ] = font <TAB> <TAB> self . afmfontd [ key ] = font <TAB> return font ","if font is None : 
","if font is None :
",100.0,100.0,True
"def __call__ ( self , groupby ) : <TAB> normalize_reduction_funcs ( self , ndim = groupby . ndim ) <TAB> df = groupby <TAB> while df . op . output_types [ 0 ] not in ( OutputType . dataframe , OutputType . series ) : <TAB> <TAB> df = df . inputs [ 0 ] <TAB> if self . raw_func == "" size "" : <TAB> <TAB> self . output_types = [ OutputType . series ] <TAB> else : <TAB> <TAB> self . output_types = ( <TAB> <TAB> <TAB> [ OutputType . dataframe ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else [ OutputType . series ] <TAB> <TAB> ) <TAB> if self . output_types [ 0 ] == OutputType . dataframe : <TAB> <TAB> return self . _call_dataframe ( groupby , df ) <TAB> else : <TAB> <TAB> return self . _call_series ( groupby , df ) ","if groupby . op . output_types [ 0 ] == OutputType . dataframe_groupby 
","if self . raw_func == "" series ""
",33.22,4.99,False
"def save ( self ) : <TAB> if self . preferences . get ( ENCRYPT_ON_DISK , False ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . storage . write ( <TAB> <TAB> <TAB> <TAB> self . to_dict ( encrypt_password = self . encryption_password ) <TAB> <TAB> <TAB> ) <TAB> <TAB> elif not self . is_locked : <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Disk encryption requested but no password available for encryption.  "" <TAB> <TAB> <TAB> <TAB> "" Resetting encryption preferences and saving wallet in an unencrypted state. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . preferences [ ENCRYPT_ON_DISK ] = False <TAB> return self . storage . write ( self . to_dict ( ) ) ","if self . encryption_password is not None : 
","if self . encryption_password :
",47.74,54.78,False
"def isValidDateString ( config_param_name , value , valid_value ) : <TAB> try : <TAB> <TAB> if value == "" DD-MM-YYYY "" : <TAB> <TAB> <TAB> return value <TAB> <TAB> day , month , year = value . split ( "" - "" ) <TAB> <TAB> if int ( day ) < 1 or int ( day ) > 31 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> if int ( year ) < 1900 or int ( year ) > 2013 : <TAB> <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) <TAB> <TAB> return value <TAB> except Exception : <TAB> <TAB> raise DateStringValueError ( config_param_name , value ) ","if int ( month ) < 1 or int ( month ) > 12 : 
","if int ( month ) < 2 or int ( month ) > 31 :
",83.25,66.06,False
"def _capture ( self , call_name , data = None , * * kwargs ) : <TAB> if data is None : <TAB> <TAB> data = self . get_default_context ( ) <TAB> else : <TAB> <TAB> default_context = self . get_default_context ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> default_context . update ( data ) <TAB> <TAB> else : <TAB> <TAB> <TAB> default_context [ "" extra "" ] [ "" extra_data "" ] = data <TAB> <TAB> data = default_context <TAB> client = self . get_sentry_client ( ) <TAB> return getattr ( client , call_name ) ( data = data , * * kwargs ) ","if isinstance ( data , dict ) : 
","if isinstance ( data , dict ) :
",100.0,100.0,True
"def check ( input , expected_output = None , expected_ffi_error = False ) : <TAB> import _cffi_backend <TAB> ffi = _cffi_backend . FFI ( ) <TAB> if not expected_ffi_error : <TAB> <TAB> ct = ffi . typeof ( input ) <TAB> <TAB> assert isinstance ( ct , ffi . CType ) <TAB> <TAB> assert ct . cname == ( expected_output or input ) <TAB> else : <TAB> <TAB> e = py . test . raises ( ffi . error , ffi . typeof , input ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert str ( e . value ) == expected_ffi_error ","if isinstance ( expected_ffi_error , str ) : 
","if e . value is not None :
",26.81,3.98,False
"def run ( self ) : <TAB> """"""Process queries from task queue, stop if processor is None."""""" <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> processor , iprot , oprot , otrans , callback = self . queue . get ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> processor . process ( iprot , oprot ) <TAB> <TAB> <TAB> callback ( True , otrans . getvalue ( ) ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . exception ( "" Exception while processing request "" ) <TAB> <TAB> <TAB> callback ( False , "" "" ) ","if processor is None : 
","if processor is None :
",100.0,100.0,True
"def search ( self , query ) : <TAB> query = query . strip ( ) . lower ( ) <TAB> results = [ ] <TAB> for provider in SidebarItemProvider . all ( self . context ) : <TAB> <TAB> for item in provider . provide ( ) : <TAB> <TAB> <TAB> if "" url "" in item : <TAB> <TAB> <TAB> <TAB> search_source = "" $ "" . join ( <TAB> <TAB> <TAB> <TAB> <TAB> [ item . get ( "" id "" , "" "" ) , item . get ( "" name "" , "" "" ) ] <TAB> <TAB> <TAB> <TAB> ) . lower ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> results . append ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" title "" : item [ "" name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" icon "" : item [ "" icon "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" url "" : item [ "" url "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> return results ","if query in search_source : 
","if query . lower ( ) . find ( search_source ) is not None :
",28.99,11.2,False
"def handle ( self ) - > None : <TAB> """"""Handles a request ignoring dropped connections."""""" <TAB> try : <TAB> <TAB> BaseHTTPRequestHandler . handle ( self ) <TAB> except ( ConnectionError , socket . timeout ) as e : <TAB> <TAB> self . connection_dropped ( e ) <TAB> except Exception as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log_error ( "" SSL error occurred:  %s "" , e ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise <TAB> if self . server . shutdown_signal : <TAB> <TAB> self . initiate_shutdown ( ) ","if self . server . ssl_context is not None and is_ssl_error ( e ) : 
","if self . server . debug :
",41.6,8.71,False
"def cdn_url_handler ( error , endpoint , kwargs ) : <TAB> if endpoint == "" cdn "" : <TAB> <TAB> path = kwargs . pop ( "" path "" ) <TAB> <TAB> # cdn = app.config.get('cdn', 'http://cdn.staticfile.org/') <TAB> <TAB> # cdn = app.config.get('cdn', '//cdnjs.cloudflare.com/ajax/libs/') <TAB> <TAB> cdn = app . config . get ( "" cdn "" , "" //cdnjscn.b0.upaiyun.com/libs/ "" ) <TAB> <TAB> return urljoin ( cdn , path ) <TAB> else : <TAB> <TAB> exc_type , exc_value , tb = sys . exc_info ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> reraise ( exc_type , exc_value , tb ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise error ","if exc_value is error : 
","if exc_type and exc_value :
",28.49,26.54,False
"def pairs ( self ) : <TAB> for path in os . listdir ( "" src "" ) : <TAB> <TAB> if path == "" .svn "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep = join ( "" src "" , path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield dep , join ( build_dir , path ) ","if isdir ( dep ) : 
","if not isdir ( dep ) :
",73.47,64.35,False
"def get_condition ( self ) : <TAB> """"""Return the condition element's name."""""" <TAB> for child in self . xml : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cond = child . tag . split ( "" } "" , 1 ) [ - 1 ] <TAB> <TAB> <TAB> if cond in self . conditions : <TAB> <TAB> <TAB> <TAB> return cond <TAB> return "" not-authorized "" ","if "" { %s } "" % self . namespace in child . tag : 
","if child . tag . startswith ( "" { %s } "" % self . condition_ns ) :
",65.72,46.51,False
"def end ( self , tag ) : <TAB> # call the appropriate end tag handler <TAB> try : <TAB> <TAB> f = self . dispatch [ tag ] <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return<TAB> # unknown tag ? <TAB> <TAB> try : <TAB> <TAB> <TAB> f = self . dispatch [ tag . split ( "" : "" ) [ - 1 ] ] <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> return<TAB> # unknown tag ? <TAB> return f ( self , "" "" . join ( self . _data ) ) ","if "" : "" not in tag : 
","if tag not in self . _data :
",33.84,11.99,False
"def checkIfSessionCodeExists ( self , sessionCode ) : <TAB> if self . emrtFile : <TAB> <TAB> sessionsForExperiment = ( <TAB> <TAB> <TAB> self . emrtFile . root . data_collection . session_meta_data . where ( <TAB> <TAB> <TAB> <TAB> "" experiment_id ==  %d "" % ( self . active_experiment_id , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> sessionCodeMatch = [ <TAB> <TAB> <TAB> sess for sess in sessionsForExperiment if sess [ "" code "" ] == sessionCode <TAB> <TAB> ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> return False ","if len ( sessionCodeMatch ) > 0 : 
","if sessionCodeMatch :
",26.73,0.0,False
"def save_bytearray ( self , obj ) : <TAB> if self . proto < 5 : <TAB> <TAB> if not obj :<TAB> # bytearray is empty <TAB> <TAB> <TAB> self . save_reduce ( bytearray , ( ) , obj = obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . save_reduce ( bytearray , ( bytes ( obj ) , ) , obj = obj ) <TAB> <TAB> return <TAB> n = len ( obj ) <TAB> if n > = self . framer . _FRAME_SIZE_TARGET : <TAB> <TAB> self . _write_large_bytes ( BYTEARRAY8 + pack ( "" <Q "" , n ) , obj ) <TAB> else : <TAB> <TAB> self . write ( BYTEARRAY8 + pack ( "" <Q "" , n ) + obj ) ","if not obj : 
","if not obj :
",100.0,100.0,True
"def _restore_freeze ( self , new ) : <TAB> size_change = [ ] <TAB> for k , v in six . iteritems ( self . _freeze_backup ) : <TAB> <TAB> newv = new . get ( k , [ ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size_change . append ( ( self . _key_name ( k ) , len ( v ) , len ( newv ) ) ) <TAB> if size_change : <TAB> <TAB> logger . info ( <TAB> <TAB> <TAB> "" These collections were modified but restored in  {} :  {} "" . format ( <TAB> <TAB> <TAB> <TAB> self . _name , <TAB> <TAB> <TAB> <TAB> "" ,  "" . join ( map ( lambda t : "" ( {} :  {} -> {} ) "" . format ( * t ) , size_change ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> restore_collection ( self . _freeze_backup ) ","if len ( v ) != len ( newv ) : 
","if v != newv :
",26.36,7.86,False
"def check_options ( self , expr , evaluation , options ) : <TAB> for key in options : <TAB> <TAB> if key != "" System`SameTest "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return evaluation . message ( "" ContainsOnly "" , "" optx "" , Symbol ( key ) , expr ) <TAB> return None ","if expr is None : 
","if expr is None :
",100.0,100.0,True
"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> if nm . startswith ( "" . "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> elif nm . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . bundle_module ( itempath ) ","if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : 
","if nm . endswith ( "" .package "" ) :
",33.26,2.94,False
"def _read_block ( self , size ) : <TAB> if self . _file_end is not None : <TAB> <TAB> max_size = self . _file_end - self . _file . tell ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> size = max_size <TAB> <TAB> size = max ( min ( size , max_size ) , 0 ) <TAB> return self . _file . read ( size ) ","if size == - 1 : 
","if size == - 1 :
",100.0,100.0,True
"def question_mark ( self ) : <TAB> """"""Shows help for this command and it's sub-commands."""""" <TAB> ret = [ ] <TAB> if self . param_help_msg or len ( self . subcommands ) == 0 : <TAB> <TAB> ret . append ( self . _quick_help ( ) ) <TAB> if len ( self . subcommands ) > 0 : <TAB> <TAB> for k , _ in sorted ( self . subcommands . items ( ) ) : <TAB> <TAB> <TAB> command_path , param_help , cmd_help = self . _instantiate_subcommand ( <TAB> <TAB> <TAB> <TAB> k <TAB> <TAB> <TAB> ) . _quick_help ( nested = True ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret . append ( ( command_path , param_help , cmd_help ) ) <TAB> return ( CommandsResponse ( STATUS_OK , self . help_formatter ( ret ) ) , self . __class__ ) ","if command_path or param_help or cmd_help : 
","if cmd_help :
",28.61,14.28,False
"def list_domains ( self , r53 , * * kwargs ) : <TAB> marker = None <TAB> domains = [ ] <TAB> while True : <TAB> <TAB> if marker : <TAB> <TAB> <TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ( Marker = marker ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response = self . wrap_aws_rate_limited_call ( r53 . list_domains ) <TAB> <TAB> for domain in response . get ( "" Domains "" ) : <TAB> <TAB> <TAB> domains . append ( domain ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> marker = response . get ( "" NextPageMarker "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return domains ","if response . get ( "" NextPageMarker "" ) : 
","if response . get ( "" NextPageMarker "" ) :
",100.0,100.0,True
"def writer ( stream , items ) : <TAB> sep = "" "" <TAB> for item in items : <TAB> <TAB> stream . write ( sep ) <TAB> <TAB> sep = "" "" <TAB> <TAB> if not isinstance ( item , str ) : <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> if not PY3K : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item = str ( item ) <TAB> <TAB> stream . write ( item ) <TAB> stream . write ( "" \n "" ) ","if not isinstance ( item , unicode ) : 
","if not isinstance ( item , bytes ) :
",83.27,66.06,False
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> view . run_command ( "" toggle_comment "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pt = utils . next_non_white_space_char ( view , s . a , white_space = "" \t "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> pt = utils . next_non_white_space_char ( <TAB> <TAB> <TAB> <TAB> view , self . view . line ( s . a ) . a , white_space = "" \t "" <TAB> <TAB> <TAB> ) <TAB> <TAB> return R ( pt , pt ) <TAB> return s ","if utils . row_at ( self . view , s . a ) != utils . row_at ( self . view , self . view . size ( ) ) : 
","if s . a . value == "" "" :
",37.3,1.78,False
"def _parse_timestamp ( value ) : <TAB> if value : <TAB> <TAB> match = _TIMESTAMP_PATTERN . match ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if match . group ( 2 ) : <TAB> <TAB> <TAB> <TAB> format = "" % Y- % m- %d % H: % M: % S. %f "" <TAB> <TAB> <TAB> <TAB> # use the pattern to truncate the value <TAB> <TAB> <TAB> <TAB> value = match . group ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> format = "" % Y- % m- %d % H: % M: % S "" <TAB> <TAB> <TAB> value = datetime . datetime . strptime ( value , format ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( ' Cannot convert  "" {} ""  into a datetime ' . format ( value ) ) <TAB> else : <TAB> <TAB> value = None <TAB> return value ","if match : 
","if match :
",78.12,0.0,False
"def _compute_log_r ( model_trace , guide_trace ) : <TAB> log_r = MultiFrameTensor ( ) <TAB> stacks = get_plate_stacks ( model_trace ) <TAB> for name , model_site in model_trace . nodes . items ( ) : <TAB> <TAB> if model_site [ "" type "" ] == "" sample "" : <TAB> <TAB> <TAB> log_r_term = model_site [ "" log_prob "" ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> log_r_term = log_r_term - guide_trace . nodes [ name ] [ "" log_prob "" ] <TAB> <TAB> <TAB> log_r . add ( ( stacks [ name ] , log_r_term . detach ( ) ) ) <TAB> return log_r ","if not model_site [ "" is_observed "" ] : 
","if guide_trace . nodes [ name ] [ "" log_prob "" ] > log_r_term :
",33.02,5.54,False
"def get_translationproject ( self ) : <TAB> """"""returns the translation project belonging to this directory."""""" <TAB> if self . is_language ( ) or self . is_project ( ) : <TAB> <TAB> return None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . translationproject <TAB> <TAB> else : <TAB> <TAB> <TAB> aux_dir = self <TAB> <TAB> <TAB> while not aux_dir . is_translationproject ( ) and aux_dir . parent is not None : <TAB> <TAB> <TAB> <TAB> aux_dir = aux_dir . parent <TAB> <TAB> <TAB> return aux_dir . translationproject ","if self . is_translationproject ( ) : 
","if self . translationproject is not None :
",38.36,21.57,False
"def get_hosted_content ( ) : <TAB> try : <TAB> <TAB> scheme , rest = target . split ( "" :// "" , 1 ) <TAB> <TAB> prefix , host_and_port = rest . split ( "" .interactivetool. "" ) <TAB> <TAB> faked_host = rest <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> faked_host = rest . split ( "" / "" , 1 ) [ 0 ] <TAB> <TAB> url = "" %s :// %s "" % ( scheme , host_and_port ) <TAB> <TAB> response = requests . get ( url , timeout = 1 , headers = { "" Host "" : faked_host } ) <TAB> <TAB> return response . text <TAB> except Exception as e : <TAB> <TAB> print ( e ) <TAB> <TAB> return None ","if "" / "" in rest : 
","if prefix == "" :// "" :
",33.57,10.55,False
"def install ( self ) : <TAB> log . info ( self . openssl_cli ) <TAB> if not self . has_openssl or self . args . force : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _download_src ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . debug ( "" Already has src  {} "" . format ( self . src_file ) ) <TAB> <TAB> self . _unpack_src ( ) <TAB> <TAB> self . _build_src ( ) <TAB> <TAB> self . _make_install ( ) <TAB> else : <TAB> <TAB> log . info ( "" Already has installation  {} "" . format ( self . install_dir ) ) <TAB> # validate installation <TAB> version = self . openssl_version <TAB> if self . version not in version : <TAB> <TAB> raise ValueError ( version ) ","if not self . has_src : 
","if not self . has_src :
",100.0,100.0,True
"def format ( self , formatstr ) : <TAB> pieces = [ ] <TAB> for i , piece in enumerate ( re_formatchars . split ( force_text ( formatstr ) ) ) : <TAB> <TAB> if i % 2 : <TAB> <TAB> <TAB> pieces . append ( force_text ( getattr ( self , piece ) ( ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pieces . append ( re_escaped . sub ( r "" \ 1 "" , piece ) ) <TAB> return "" "" . join ( pieces ) ","elif piece : 
","elif piece :
",78.12,0.0,False
"def get_current_events_users ( calendar ) : <TAB> now = timezone . make_aware ( datetime . now ( ) , timezone . get_current_timezone ( ) ) <TAB> result = [ ] <TAB> day = Day ( calendar . events . all ( ) , now ) <TAB> for o in day . get_occurrences ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> usernames = o . event . title . split ( "" , "" ) <TAB> <TAB> <TAB> for username in usernames : <TAB> <TAB> <TAB> <TAB> result . append ( User . objects . get ( username = username . strip ( ) ) ) <TAB> return result ","if o . start < = now < = o . end : 
","if o . event :
",35.88,8.63,False
"def from_cfn_params ( self , cfn_params ) : <TAB> """"""Initialize param value by parsing CFN input only if the scheduler is awsbatch."""""" <TAB> cfn_converter = self . definition . get ( "" cfn_param_mapping "" , None ) <TAB> if cfn_converter and cfn_params : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # we have the same CFN input parameters for both spot_price and spot_bid_percentage <TAB> <TAB> <TAB> # so the CFN input could be a float <TAB> <TAB> <TAB> self . value = int ( float ( get_cfn_param ( cfn_params , cfn_converter ) ) ) <TAB> return self ","if get_cfn_param ( cfn_params , "" Scheduler "" ) == "" awsbatch "" : 
","if self . value is None :
",25.89,1.06,False
"def onCompletion ( self , text ) : <TAB> res = [ ] <TAB> for l in text . split ( "" \n "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> l = l . split ( "" : "" ) <TAB> <TAB> if len ( l ) != 2 : <TAB> <TAB> <TAB> continue <TAB> <TAB> res . append ( [ l [ 0 ] . strip ( ) , l [ 1 ] . strip ( ) ] ) <TAB> self . panel . setChapters ( res ) ","if not l : 
","if not l :
",100.0,100.0,True
"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB> <TAB> # most common case: extend a range <TAB> <TAB> if i == _range [ 0 ] - 1 : <TAB> <TAB> <TAB> _range [ 0 ] = i <TAB> <TAB> <TAB> merge_ranges ( l ) <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _range [ 1 ] = i <TAB> <TAB> <TAB> merge_ranges ( l ) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l . append ( [ i , i ] ) <TAB> l . sort ( key = lambda x : x [ 0 ] ) ","elif i == _range [ 1 ] + 1 : 
","if i < _range [ 1 ] - 1 :
",48.91,38.1,False
"def process_dollar ( token , state , command_line ) : <TAB> if not state . is_range_start_line_parsed : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . start . append ( token ) <TAB> else : <TAB> <TAB> if command_line . line_range . end : <TAB> <TAB> <TAB> raise ValueError ( "" bad range:  {0} "" . format ( state . scanner . state . source ) ) <TAB> <TAB> command_line . line_range . end . append ( token ) <TAB> return parse_line_ref , command_line ","if command_line . line_range . start : 
","if command_line . line_range . start :
",100.0,100.0,True
"def _parse_description ( self , text : str ) : <TAB> result = dict ( links = [ ] , versions = [ ] ) <TAB> for line in text . splitlines ( ) : <TAB> <TAB> clean = REX_TAG . sub ( "" "" , line . strip ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" severity "" ] = clean . split ( ) [ 1 ] <TAB> <TAB> <TAB> continue <TAB> <TAB> if clean . startswith ( "" Affects: "" ) : <TAB> <TAB> <TAB> result [ "" name "" ] = clean . split ( ) [ 1 ] <TAB> <TAB> <TAB> continue <TAB> <TAB> if ""  or higher "" in clean : <TAB> <TAB> <TAB> result [ "" versions "" ] = self . _get_versions ( clean ) <TAB> <TAB> result [ "" links "" ] . extend ( REX_LINK . findall ( line ) ) <TAB> return result ","if clean . startswith ( "" Severity: "" ) : 
","if clean . startswith ( "" severity: "" ) :
",83.03,70.17,False
"def apply ( self , chart , grammar ) : <TAB> for prod in grammar . productions ( empty = True ) : <TAB> <TAB> for index in compat . xrange ( chart . num_leaves ( ) + 1 ) : <TAB> <TAB> <TAB> new_edge = TreeEdge . from_production ( prod , index ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield new_edge ","if chart . insert ( new_edge , ( ) ) : 
","if chart . insert ( new_edge , ( ) ) :
",100.0,100.0,True
"def calc ( self , arg ) : <TAB> op = arg [ "" op "" ] <TAB> if op == "" C "" : <TAB> <TAB> self . clear ( ) <TAB> <TAB> return str ( self . current ) <TAB> num = decimal . Decimal ( arg [ "" num "" ] ) <TAB> if self . op : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . current + = num <TAB> <TAB> elif self . op == "" - "" : <TAB> <TAB> <TAB> self . current - = num <TAB> <TAB> elif self . op == "" * "" : <TAB> <TAB> <TAB> self . current * = num <TAB> <TAB> elif self . op == "" / "" : <TAB> <TAB> <TAB> self . current / = num <TAB> <TAB> self . op = op <TAB> else : <TAB> <TAB> self . op = op <TAB> <TAB> self . current = num <TAB> res = str ( self . current ) <TAB> if op == "" = "" : <TAB> <TAB> self . clear ( ) <TAB> return res ","if self . op == "" + "" : 
","if self . op == "" + "" :
",100.0,100.0,True
"def cascade ( self , event = None ) : <TAB> """"""Cascade all Leo windows."""""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB> <TAB> w = frame and frame . top <TAB> <TAB> if w : <TAB> <TAB> <TAB> r = w . geometry ( )<TAB> # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x + = 30 <TAB> <TAB> <TAB> y + = 30 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta + = 10 ","if x > 200 : 
","if x < 40 :
",56.5,23.64,False
"def redirect ( self ) : <TAB> c = self . c <TAB> if c . config . getBool ( "" eval-redirect "" ) : <TAB> <TAB> self . old_stderr = g . stdErrIsRedirected ( ) <TAB> <TAB> self . old_stdout = g . stdOutIsRedirected ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . redirectStderr ( ) <TAB> <TAB> if not self . old_stdout : <TAB> <TAB> <TAB> g . redirectStdout ( ) ","if not self . old_stderr : 
","if not self . old_stderr :
",100.0,100.0,True
"def on_event ( self , c , button , data ) : <TAB> if self . rvGestureGrab . get_reveal_child ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . use ( ) <TAB> <TAB> elif button == "" Y "" and data [ 0 ] == 0 : <TAB> <TAB> <TAB> self . start_over ( ) ","if button == "" A "" and data [ 0 ] == 0 : 
","if button == "" X "" and data [ 0 ] == 1 :
",81.72,68.65,False
"def __init__ ( self , in_feats , out_feats , norm = "" both "" , bias = True , activation = None ) : <TAB> super ( DenseGraphConv , self ) . __init__ ( ) <TAB> self . _in_feats = in_feats <TAB> self . _out_feats = out_feats <TAB> self . _norm = norm <TAB> with self . name_scope ( ) : <TAB> <TAB> self . weight = self . params . get ( <TAB> <TAB> <TAB> "" weight "" , <TAB> <TAB> <TAB> shape = ( in_feats , out_feats ) , <TAB> <TAB> <TAB> init = mx . init . Xavier ( magnitude = math . sqrt ( 2.0 ) ) , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . bias = self . params . get ( "" bias "" , shape = ( out_feats , ) , init = mx . init . Zero ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . bias = None <TAB> <TAB> self . _activation = activation ","if bias : 
","if bias :
",78.12,0.0,False
"def _import_top_module ( self , name ) : <TAB> # scan sys.path looking for a location in the filesystem that contains <TAB> # the module, or an Importer object that can import the module. <TAB> for item in sys . path : <TAB> <TAB> if isinstance ( item , _StringType ) : <TAB> <TAB> <TAB> module = self . fs_imp . import_from_dir ( item , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> module = item . import_top ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return module <TAB> return None ","if module : 
","if module :
",78.12,0.0,False
"def resolver ( schemas , f ) : <TAB> if not callable ( f ) : <TAB> <TAB> return <TAB> if not hasattr ( f , "" accepts "" ) : <TAB> <TAB> return <TAB> new_params = [ ] <TAB> for p in f . accepts : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_params . append ( p . resolve ( schemas ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ResolverError ( "" Invalid parameter definition  {0} "" . format ( p ) ) <TAB> # FIXME: for some reason assigning params (f.accepts = new_params) does not work <TAB> f . accepts . clear ( ) <TAB> f . accepts . extend ( new_params ) ","if isinstance ( p , ( Patch , Ref , Attribute ) ) : 
","if isinstance ( p , Resolver ) :
",40.06,28.09,False
"def get_files ( d ) : <TAB> res = [ ] <TAB> for p in glob . glob ( os . path . join ( d , "" * "" ) ) : <TAB> <TAB> if not p : <TAB> <TAB> <TAB> continue <TAB> <TAB> ( pth , fname ) = os . path . split ( p ) <TAB> <TAB> if fname == "" output "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if fname [ - 4 : ] == "" .pyc "" :<TAB> # ehmm.. no. <TAB> <TAB> <TAB> continue <TAB> <TAB> if os . path . isdir ( p ) : <TAB> <TAB> <TAB> get_dir ( p ) <TAB> <TAB> else : <TAB> <TAB> <TAB> res . append ( p ) <TAB> return res ","if fname == "" PureMVC_Python_1_0 "" : 
","if fname . startswith ( "" .pyc "" ) :
",34.92,7.18,False
"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB> <TAB> for rightname in kerning [ leftname ] : <TAB> <TAB> <TAB> if rightname [ 0 ] == "" @ "" : <TAB> <TAB> <TAB> <TAB> for rightname2 in groups [ rightname ] : <TAB> <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname2 ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname ) ","if not includeAll : 
","if not includeAll :
",100.0,100.0,True
"def migrate_Stats ( self ) : <TAB> for old_obj in self . session_old . query ( self . model_from [ "" Stats "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . entries_count [ "" Stats "" ] - = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> new_obj = self . model_to [ "" Stats "" ] ( ) <TAB> <TAB> for key in new_obj . __table__ . columns . _data . keys ( ) : <TAB> <TAB> <TAB> if key not in old_obj . __table__ . columns : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( new_obj , key , getattr ( old_obj , key ) ) <TAB> <TAB> self . session_new . add ( new_obj ) ","if not old_obj . summary : 
","if old_obj . entries_count [ "" Stats "" ] > 0 :
",34.79,16.94,False
"def _readenv ( var , msg ) : <TAB> match = _ENV_VAR_PAT . match ( var ) <TAB> if match and match . groups ( ) : <TAB> <TAB> envvar = match . groups ( ) [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = os . environ [ envvar ] <TAB> <TAB> <TAB> if six . PY2 : <TAB> <TAB> <TAB> <TAB> value = value . decode ( "" utf8 "" ) <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> <TAB> "" {}  - environment variable  ' {} '  not set "" . format ( msg , var ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise InvalidConfigException ( <TAB> <TAB> <TAB> "" {}  - environment variable name  ' {} '  does not match pattern  ' {} ' "" . format ( <TAB> <TAB> <TAB> <TAB> msg , var , _ENV_VAR_PAT_STR <TAB> <TAB> <TAB> ) <TAB> <TAB> ) ","if envvar in os . environ : 
","if envvar in os . environ :
",100.0,100.0,True
"def __next__ ( self ) : <TAB> self . _parse_reset ( ) <TAB> while True : <TAB> <TAB> try : <TAB> <TAB> <TAB> line = next ( self . input_iter ) <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> # End of input OR exception <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Error ( "" newline inside string "" ) <TAB> <TAB> <TAB> raise <TAB> <TAB> self . line_num + = 1 <TAB> <TAB> if "" \0 "" in line : <TAB> <TAB> <TAB> raise Error ( "" line contains NULL byte "" ) <TAB> <TAB> pos = 0 <TAB> <TAB> while pos < len ( line ) : <TAB> <TAB> <TAB> pos = self . _parse_process_char ( line , pos ) <TAB> <TAB> self . _parse_eol ( ) <TAB> <TAB> if self . state == self . START_RECORD : <TAB> <TAB> <TAB> break <TAB> fields = self . fields <TAB> self . fields = [ ] <TAB> return fields ","if len ( self . field ) > 0 : 
","if self . line_num > = self . length :
",32.06,8.52,False
"def createFields ( self ) : <TAB> while self . current_size < self . size : <TAB> <TAB> pos = self . stream . searchBytes ( <TAB> <TAB> <TAB> "" \0 \0 \1 "" , self . current_size , self . current_size + 1024 * 1024 * 8 <TAB> <TAB> )<TAB> # seek forward by at most 1MB <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> padsize = pos - self . current_size <TAB> <TAB> <TAB> if padsize : <TAB> <TAB> <TAB> <TAB> yield PaddingBytes ( self , "" pad[] "" , padsize / / 8 ) <TAB> <TAB> chunk = Chunk ( self , "" chunk[] "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> # force chunk to be processed, so that CustomFragments are complete <TAB> <TAB> <TAB> chunk [ "" content/data "" ] <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> yield chunk ","if pos is not None : 
","if pos :
",29.58,0.0,False
"def spew ( ) : <TAB> seenUID = False <TAB> start ( ) <TAB> for part in query : <TAB> <TAB> if part . type == "" uid "" : <TAB> <TAB> <TAB> seenUID = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield self . spew_body ( part , id , msg , write , flush ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = getattr ( self , "" spew_ "" + part . type ) <TAB> <TAB> <TAB> yield f ( id , msg , write , flush ) <TAB> <TAB> if part is not query [ - 1 ] : <TAB> <TAB> <TAB> space ( ) <TAB> if uid and not seenUID : <TAB> <TAB> space ( ) <TAB> <TAB> yield self . spew_uid ( id , msg , write , flush ) <TAB> finish ( ) <TAB> flush ( ) ","if part . type == "" body "" : 
","elif part . type == "" body "" :
",81.96,88.01,False
"def _limit_value ( key , value , config ) : <TAB> if config [ key ] . get ( "" upper_limit "" ) : <TAB> <TAB> limit = config [ key ] [ "" upper_limit "" ] <TAB> <TAB> # auto handle datetime <TAB> <TAB> if isinstance ( value , datetime ) and isinstance ( limit , timedelta ) : <TAB> <TAB> <TAB> if config [ key ] [ "" inverse "" ] is True : <TAB> <TAB> <TAB> <TAB> if ( datetime . now ( ) - limit ) > value : <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) - limit <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> value = datetime . now ( ) + limit <TAB> <TAB> elif value > limit : <TAB> <TAB> <TAB> value = limit <TAB> return value ","if ( datetime . now ( ) + limit ) < value : 
","if ( datetime . now ( ) + limit ) < value :
",100.0,100.0,True
"def _fix_var_naming ( operators , names , mod = "" input "" ) : <TAB> new_names = [ ] <TAB> map = { } <TAB> for op in operators : <TAB> <TAB> if mod == "" input "" : <TAB> <TAB> <TAB> iter = op . inputs <TAB> <TAB> else : <TAB> <TAB> <TAB> iter = op . outputs <TAB> <TAB> for i in iter : <TAB> <TAB> <TAB> for name in names : <TAB> <TAB> <TAB> <TAB> if i . raw_name == name and name not in map : <TAB> <TAB> <TAB> <TAB> <TAB> map [ i . raw_name ] = i . full_name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> for name in names : <TAB> <TAB> new_names . append ( map [ name ] ) <TAB> return new_names ","if len ( map ) == len ( names ) : 
","if mod == "" output "" :
",26.32,7.97,False
"def traverse ( tree ) : <TAB> """"""Generator dropping comment nodes"""""" <TAB> for entry in tree : <TAB> <TAB> # key, values = entry <TAB> <TAB> spaceless = [ e for e in entry if not nginxparser . spacey ( e ) ] <TAB> <TAB> if spaceless : <TAB> <TAB> <TAB> key = spaceless [ 0 ] <TAB> <TAB> <TAB> values = spaceless [ 1 ] if len ( spaceless ) > 1 else None <TAB> <TAB> else : <TAB> <TAB> <TAB> key = values = "" "" <TAB> <TAB> if isinstance ( key , list ) : <TAB> <TAB> <TAB> new = copy . deepcopy ( entry ) <TAB> <TAB> <TAB> new [ 1 ] = filter_comments ( values ) <TAB> <TAB> <TAB> yield new <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield spaceless ","if key != "" # "" and spaceless : 
","if not isinstance ( spaceless , list ) :
",26.62,5.61,False
"def mergeCombiners ( self , x , y ) : <TAB> for item in y : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . heap . push ( x , item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . heap . push_pop ( x , item ) <TAB> return x ","if len ( x ) < self . heap_limit : 
","if self . heap . size ( x ) < self . heap . size ( y ) :
",54.16,32.83,False
"def test_scatter ( self , harness : primitive_harness . Harness ) : <TAB> f_name = harness . params [ "" f_lax "" ] . __name__ <TAB> dtype = harness . params [ "" dtype "" ] <TAB> if jtu . device_under_test ( ) == "" tpu "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise unittest . SkipTest ( f "" TODO: complex  { f_name }  on TPU fails in JAX "" ) <TAB> self . ConvertAndCompare ( harness . dyn_fun , * harness . dyn_args_maker ( self . rng ( ) ) ) ","if dtype is np . complex64 and f_name in [ "" scatter_min "" , "" scatter_max "" ] : 
","if not np . allclose ( harness . params [ "" dyn_fun "" ] , harness . params [ "" dyn_args "" ] , dtype ) :
",35.12,5.13,False
"def TryMerge ( self , decoder ) : <TAB> while decoder . avail ( ) > 0 : <TAB> <TAB> tag = decoder . getVarInt32 ( ) <TAB> <TAB> if tag == TAG_BEGIN_ITEM_GROUP : <TAB> <TAB> <TAB> ( type_id , message ) = Item . Decode ( decoder ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . items [ type_id ] . MergeFrom ( Item ( message ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . items [ type_id ] = Item ( message ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tag == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> decoder . skipData ( tag ) ","if type_id in self . items : 
","if type_id in self . items :
",100.0,100.0,True
"def process_continuations ( lines ) : <TAB> global continuation_pattern <TAB> olines = [ ] <TAB> while len ( lines ) != 0 : <TAB> <TAB> line = no_comments ( lines [ 0 ] ) <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> lines . pop ( 0 ) <TAB> <TAB> if line == "" "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # combine this line with the next line if the next line exists <TAB> <TAB> <TAB> line = continuation_pattern . sub ( "" "" , line ) <TAB> <TAB> <TAB> if len ( lines ) > = 1 : <TAB> <TAB> <TAB> <TAB> combined_lines = [ line + lines [ 0 ] ] <TAB> <TAB> <TAB> <TAB> lines . pop ( 0 ) <TAB> <TAB> <TAB> <TAB> lines = combined_lines + lines <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> olines . append ( line ) <TAB> del lines <TAB> return olines ","if continuation_pattern . search ( line ) : 
","if line . startswith ( continuation_pattern ) :
",54.04,22.75,False
"def _getListNextPackagesReadyToBuild ( ) : <TAB> for pkg in Scheduler . listOfPackagesToBuild : <TAB> <TAB> if pkg in Scheduler . listOfPackagesCurrentlyBuilding : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> Scheduler . listOfPackagesNextToBuild . put ( ( - Scheduler . _getPriority ( pkg ) , pkg ) ) <TAB> <TAB> <TAB> Scheduler . logger . debug ( "" Adding  "" + pkg + ""  to the schedule list "" ) ","if constants . rpmCheck or Scheduler . _checkNextPackageIsReadyToBuild ( pkg ) : 
","if not Scheduler . listOfPackagesNextToBuild . get ( pkg ) :
",49.16,25.0,False
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB> <TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr ( obj , "" use_scope "" ) : <TAB> <TAB> <TAB> if obj . use_scope : <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation ","elif obj . use_scope is None : 
","elif obj . use_scope_name :
",43.86,61.05,False
"def find_distribution_modules ( name = __name__ , file = __file__ ) : <TAB> current_dist_depth = len ( name . split ( "" . "" ) ) - 1 <TAB> current_dist = os . path . join ( <TAB> <TAB> os . path . dirname ( file ) , * ( [ os . pardir ] * current_dist_depth ) <TAB> ) <TAB> abs = os . path . abspath ( current_dist ) <TAB> dist_name = os . path . basename ( abs ) <TAB> for dirpath , dirnames , filenames in os . walk ( abs ) : <TAB> <TAB> package = ( dist_name + dirpath [ len ( abs ) : ] ) . replace ( "" / "" , "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield package <TAB> <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> <TAB> if filename . endswith ( "" .py "" ) and filename != "" __init__.py "" : <TAB> <TAB> <TAB> <TAB> <TAB> yield "" . "" . join ( [ package , filename ] ) [ : - 3 ] ","if "" __init__.py "" in filenames : 
","if os . path . isfile ( package ) :
",26.7,4.09,False
"def transform_value ( i , v , * args ) : <TAB> if i not in converter_functions : <TAB> <TAB> # no converter defined on this field, return value as-is <TAB> <TAB> return v <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> return converter_functions [ i ] ( v , * args ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> if failonerror == "" inline "" : <TAB> <TAB> <TAB> <TAB> return e <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise e <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return errorvalue ","elif failonerror : 
","elif failonerror :
",78.12,0.0,False
"def _get_file ( self ) : <TAB> if self . _file is None : <TAB> <TAB> self . _file = SpooledTemporaryFile ( <TAB> <TAB> <TAB> max_size = self . _storage . max_memory_size , <TAB> <TAB> <TAB> suffix = "" .S3Boto3StorageFile "" , <TAB> <TAB> <TAB> dir = setting ( "" FILE_UPLOAD_TEMP_DIR "" ) , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _is_dirty = False <TAB> <TAB> <TAB> self . obj . download_fileobj ( self . _file ) <TAB> <TAB> <TAB> self . _file . seek ( 0 ) <TAB> <TAB> if self . _storage . gzip and self . obj . content_encoding == "" gzip "" : <TAB> <TAB> <TAB> self . _file = GzipFile ( mode = self . _mode , fileobj = self . _file , mtime = 0.0 ) <TAB> return self . _file ","if "" r "" in self . _mode : 
","if self . _is_dirty :
",33.05,18.19,False
"def connect ( self , host , port , timeout ) : <TAB> fp = Telnet ( ) <TAB> for i in range ( 50 ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> fp . sock = socket . create_connection ( <TAB> <TAB> <TAB> <TAB> ( host , int ( port ) ) , timeout = int ( timeout ) , source_address = ( "" "" , 1023 - i ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> except socket . error as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise e <TAB> self . need_handshake = True <TAB> return TCP_Connection ( fp ) ","if ( e . errno , e . strerror ) != ( 98 , "" Address already in use "" ) : 
","if i == 50 :
",25.37,0.63,False
"def filtercomments ( source ) : <TAB> """"""NOT USED: strips trailing comments and put them at the top."""""" <TAB> trailing_comments = [ ] <TAB> comment = True <TAB> while comment : <TAB> <TAB> if re . search ( r "" ^ \ s* \ / \ * "" , source ) : <TAB> <TAB> <TAB> comment = source [ 0 , source . index ( "" */ "" ) + 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> comment = re . search ( r "" ^ \ s* \ / \ / "" , source ) . group ( 0 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> comment = None <TAB> <TAB> if comment : <TAB> <TAB> <TAB> source = re . sub ( r "" ^ \ s+ "" , "" "" , source [ len ( comment ) : ] ) <TAB> <TAB> <TAB> trailing_comments . append ( comment ) <TAB> return "" \n "" . join ( trailing_comments ) + source ","elif re . search ( r "" ^ \ s* \ / \ / "" , source ) : 
","elif re . search ( r "" ^ \ s* \ / "" , source ) :
",93.65,87.95,False
"def yview ( self , mode = None , value = None , units = None ) : <TAB> if type ( value ) == str : <TAB> <TAB> value = float ( value ) <TAB> if mode is None : <TAB> <TAB> return self . vsb . get ( ) <TAB> elif mode == "" moveto "" : <TAB> <TAB> frameHeight = self . innerframe . winfo_reqheight ( ) <TAB> <TAB> self . _startY = value * float ( frameHeight ) <TAB> else :<TAB> # mode == 'scroll' <TAB> <TAB> clipperHeight = self . _clipper . winfo_height ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> jump = int ( clipperHeight * self . _jfraction ) <TAB> <TAB> else : <TAB> <TAB> <TAB> jump = clipperHeight <TAB> <TAB> self . _startY = self . _startY + value * jump <TAB> self . reposition ( ) ","if units == "" units "" : 
","if self . _jfraction :
",27.23,6.92,False
"def visit ( stmt ) : <TAB> """"""Collect information about VTCM buffers and their alignments."""""" <TAB> if isinstance ( stmt , tvm . tir . AttrStmt ) : <TAB> <TAB> if stmt . attr_key == "" storage_scope "" and stmt . value == "" local.vtcm "" : <TAB> <TAB> <TAB> vtcm_buffers . append ( stmt . node ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not stmt . node in alignments : <TAB> <TAB> <TAB> <TAB> alignments [ stmt . node ] = [ ] <TAB> <TAB> <TAB> alignments [ stmt . node ] . append ( stmt . value ) ","elif stmt . attr_key == "" storage_alignment "" : 
","elif stmt . attr_key == "" buffer_type "" and stmt . value == "" local.vtcm "" :
",64.59,34.96,False
"def cost ( P ) : <TAB> # wda loss <TAB> loss_b = 0 <TAB> loss_w = 0 <TAB> for i , xi in enumerate ( xc ) : <TAB> <TAB> xi = np . dot ( xi , P ) <TAB> <TAB> for j , xj in enumerate ( xc [ i : ] ) : <TAB> <TAB> <TAB> xj = np . dot ( xj , P ) <TAB> <TAB> <TAB> M = dist ( xi , xj ) <TAB> <TAB> <TAB> G = sinkhorn ( wc [ i ] , wc [ j + i ] , M , reg , k ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> loss_w + = np . sum ( G * M ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> loss_b + = np . sum ( G * M ) <TAB> # loss inversed because minimization <TAB> return loss_w / loss_b ","if j == 0 : 
","if k == 1 :
",53.65,19.3,False
"def __init__ ( self , comm , in_channels , out_channels , ksize , pad = 1 ) : <TAB> super ( Block , self ) . __init__ ( ) <TAB> with self . init_scope ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . conv = ParallelConvolution2D ( <TAB> <TAB> <TAB> <TAB> comm , in_channels , out_channels , ksize , pad = pad , nobias = True <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . conv = chainer . links . Convolution2D ( <TAB> <TAB> <TAB> <TAB> in_channels , out_channels , ksize , pad = pad , nobias = True <TAB> <TAB> <TAB> ) <TAB> <TAB> self . bn = L . BatchNormalization ( out_channels ) ","if comm . size < = in_channels : 
","if comm . get_channels ( ) . is_parallel ( ) :
",36.47,12.87,False
"def halfMultipartScore ( nzb_name ) : <TAB> try : <TAB> <TAB> wrong_found = 0 <TAB> <TAB> for nr in [ 1 , 2 , 3 , 4 , 5 , "" i "" , "" ii "" , "" iii "" , "" iv "" , "" v "" , "" a "" , "" b "" , "" c "" , "" d "" , "" e "" ] : <TAB> <TAB> <TAB> for wrong in [ "" cd "" , "" part "" , "" dis "" , "" disc "" , "" dvd "" ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> wrong_found + = 1 <TAB> <TAB> if wrong_found == 1 : <TAB> <TAB> <TAB> return - 30 <TAB> <TAB> return 0 <TAB> except : <TAB> <TAB> log . error ( "" Failed doing halfMultipartScore:  %s "" , traceback . format_exc ( ) ) <TAB> return 0 ","if "" %s %s "" % ( wrong , nr ) in nzb_name . lower ( ) : 
","if nzb_name in wrong and nzb_name in wrong :
",25.8,7.11,False
"def should_include ( service ) : <TAB> for f in filt : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> state = filt [ f ] <TAB> <TAB> <TAB> containers = project . containers ( [ service . name ] , stopped = True ) <TAB> <TAB> <TAB> if not has_container_with_state ( containers , state ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> elif f == "" source "" : <TAB> <TAB> <TAB> source = filt [ f ] <TAB> <TAB> <TAB> if source == "" image "" or source == "" build "" : <TAB> <TAB> <TAB> <TAB> if source not in service . options : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise UserError ( "" Invalid value for source filter:  %s "" % source ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UserError ( "" Invalid filter:  %s "" % f ) <TAB> return True ","if f == "" status "" : 
","if f == "" state "" :
",74.63,59.46,False
"def get_blob_type_declaration_sql ( self , column ) : <TAB> length = column . get ( "" length "" ) <TAB> if length : <TAB> <TAB> if length < = self . LENGTH_LIMIT_TINYBLOB : <TAB> <TAB> <TAB> return "" TINYBLOB "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" BLOB "" <TAB> <TAB> if length < = self . LENGTH_LIMIT_MEDIUMBLOB : <TAB> <TAB> <TAB> return "" MEDIUMBLOB "" <TAB> return "" LONGBLOB "" ","if length < = self . LENGTH_LIMIT_BLOB : 
","if length < = self . LENGTH_LIMIT_BLOB :
",100.0,100.0,True
"def click_outside ( event ) : <TAB> if event not in d : <TAB> <TAB> x , y , z = self . blockFaceUnderCursor [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y = 64 <TAB> <TAB> y + = 3 <TAB> <TAB> gotoPanel . X , gotoPanel . Y , gotoPanel . Z = x , y , z <TAB> <TAB> if event . num_clicks == 2 : <TAB> <TAB> <TAB> d . dismiss ( "" Goto "" ) ","if y == 0 : 
","if y == 32 :
",64.48,53.73,False
"def check_related_active_jobs ( self , obj ) : <TAB> active_jobs = obj . get_active_jobs ( ) <TAB> if len ( active_jobs ) > 0 : <TAB> <TAB> raise ActiveJobConflict ( active_jobs ) <TAB> time_cutoff = now ( ) - dateutil . relativedelta . relativedelta ( minutes = 1 ) <TAB> recent_jobs = obj . _get_related_jobs ( ) . filter ( finished__gte = time_cutoff ) <TAB> for unified_job in recent_jobs . get_real_instances ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PermissionDenied ( <TAB> <TAB> <TAB> <TAB> _ ( "" Related job  {}  is still processing events. "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> unified_job . log_format <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) ","if not unified_job . event_processing_finished : 
","if unified_job . processing_events :
",36.49,27.33,False
"def run ( self ) : <TAB> self . alive = True <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB> <TAB> _log . debug ( "" started "" ) <TAB> while self . alive : <TAB> <TAB> task = self . queue . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> function , args , kwargs = task <TAB> <TAB> <TAB> assert function <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> function ( * args , * * kwargs ) <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> _log . exception ( "" calling  %s "" , function ) <TAB> if _log . isEnabledFor ( _DEBUG ) : <TAB> <TAB> _log . debug ( "" stopped "" ) ","if task : 
","if task is not None :
",34.04,17.97,False
"def update_sysconfig_file ( fn , adjustments , allow_empty = False ) : <TAB> if not adjustments : <TAB> <TAB> return <TAB> ( exists , contents ) = read_sysconfig_file ( fn ) <TAB> updated_am = 0 <TAB> for ( k , v ) in adjustments . items ( ) : <TAB> <TAB> if v is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> v = str ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> contents [ k ] = v <TAB> <TAB> updated_am + = 1 <TAB> if updated_am : <TAB> <TAB> lines = [ <TAB> <TAB> <TAB> str ( contents ) , <TAB> <TAB> ] <TAB> <TAB> if not exists : <TAB> <TAB> <TAB> lines . insert ( 0 , util . make_header ( ) ) <TAB> <TAB> util . write_file ( fn , "" \n "" . join ( lines ) + "" \n "" , 0o644 ) ","if len ( v ) == 0 and not allow_empty : 
","if not allow_empty and v == "" "" :
",31.41,24.25,False
"def wrapper (<TAB> # type: ignore <TAB> self : RequestHandler , * args , * * kwargs ) - > Optional [ Awaitable [ None ] ] : <TAB> if self . request . path . endswith ( "" / "" ) : <TAB> <TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB> <TAB> <TAB> uri = self . request . path . rstrip ( "" / "" ) <TAB> <TAB> <TAB> if uri :<TAB> # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB> if self . request . query : <TAB> <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs ) ","if uri : 
","if uri :
",78.12,0.0,False
def output_handles_from_execution_plan ( execution_plan ) : <TAB> output_handles_for_current_run = set ( ) <TAB> for step_level in execution_plan . execution_step_levels ( ) : <TAB> <TAB> for step in step_level : <TAB> <TAB> <TAB> for step_input in step . step_inputs : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> output_handles_for_current_run . update ( step_input . source_handles ) <TAB> return output_handles_for_current_run ,"if step_input . source_handles : 
","if step_input . output_handles :
",64.48,59.69,False
"def _read_value ( self , item ) : <TAB> item = _normalize_path ( item ) <TAB> if item in self . _store : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _store [ item ] <TAB> <TAB> <TAB> raise KeyError ( item ) <TAB> <TAB> return PathResult ( item , value = self . _store [ item ] ) <TAB> elif item in self . _children : <TAB> <TAB> return PathResult ( item , dir = True ) <TAB> else : <TAB> <TAB> raise KeyError ( item ) ","if item in self . _expire_time and self . _expire_time [ item ] < datetime . now ( ) : 
","if not self . _store [ item ] :
",36.91,5.7,False
"def _line_ranges ( statements , lines ) : <TAB> """"""Produce a list of ranges for `format_lines`."""""" <TAB> statements = sorted ( statements ) <TAB> lines = sorted ( lines ) <TAB> pairs = [ ] <TAB> start = None <TAB> lidx = 0 <TAB> for stmt in statements : <TAB> <TAB> if lidx > = len ( lines ) : <TAB> <TAB> <TAB> break <TAB> <TAB> if stmt == lines [ lidx ] : <TAB> <TAB> <TAB> lidx + = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> start = stmt <TAB> <TAB> <TAB> end = stmt <TAB> <TAB> elif start : <TAB> <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> <TAB> <TAB> start = None <TAB> if start : <TAB> <TAB> pairs . append ( ( start , end ) ) <TAB> return pairs ","if not start : 
","if start is None :
",29.25,14.06,False
"def _update_help_obj_params ( help_obj , data_params , params_equal , attr_key_tups ) : <TAB> loaded_params = [ ] <TAB> for param_obj in help_obj . parameters : <TAB> <TAB> loaded_param = next ( <TAB> <TAB> <TAB> ( n for n in data_params if params_equal ( param_obj , n ) ) , None <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> BaseHelpLoader . _update_obj_from_data_dict ( <TAB> <TAB> <TAB> <TAB> param_obj , loaded_param , attr_key_tups <TAB> <TAB> <TAB> ) <TAB> <TAB> loaded_params . append ( param_obj ) <TAB> help_obj . parameters = loaded_params ","if loaded_param : 
","if loaded_param is not None :
",34.04,36.56,False
"def __get_ratio ( self ) : <TAB> """"""Return splitter ratio of the main splitter."""""" <TAB> c = self . c <TAB> free_layout = c . free_layout <TAB> if free_layout : <TAB> <TAB> w = free_layout . get_main_splitter ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> aList = w . sizes ( ) <TAB> <TAB> <TAB> if len ( aList ) == 2 : <TAB> <TAB> <TAB> <TAB> n1 , n2 = aList <TAB> <TAB> <TAB> <TAB> # 2017/06/07: guard against division by zero. <TAB> <TAB> <TAB> <TAB> ratio = 0.5 if n1 + n2 == 0 else float ( n1 ) / float ( n1 + n2 ) <TAB> <TAB> <TAB> <TAB> return ratio <TAB> return 0.5 ","if w : 
","if w :
",78.12,0.0,False
"def _check_required_env_variables ( vars ) : <TAB> for var in vars : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . tc . logger . error ( <TAB> <TAB> <TAB> <TAB> "" %s  is not set. Did you forget to source your build environment setup script? "" <TAB> <TAB> <TAB> <TAB> % var <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise OEQAPreRun ","if not os . environ . get ( var ) : 
","if not getattr ( self . tc , var , "" _env_required "" , None ) :
",31.27,6.23,False
"def clean_indexes ( ) : <TAB> for coll_name in mongo . collection_types . keys ( ) : <TAB> <TAB> coll = mongo . get_collection ( coll_name ) <TAB> <TAB> indexes = coll_indexes [ coll_name ] <TAB> <TAB> try : <TAB> <TAB> <TAB> for index in coll . list_indexes ( ) : <TAB> <TAB> <TAB> <TAB> name = index [ "" name "" ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> coll . drop_index ( name ) <TAB> <TAB> except pymongo . errors . OperationFailure : <TAB> <TAB> <TAB> pass ","if name == "" _id "" or name == "" _id_ "" or name in indexes : 
","if name in indexes :
",33.88,2.54,False
"def _compare_dirs ( self , dir1 , dir2 ) : <TAB> # check that dir1 and dir2 are equivalent, <TAB> # return the diff <TAB> diff = [ ] <TAB> for root , dirs , files in os . walk ( dir1 ) : <TAB> <TAB> for file_ in files : <TAB> <TAB> <TAB> path = os . path . join ( root , file_ ) <TAB> <TAB> <TAB> target_path = os . path . join ( dir2 , os . path . split ( path ) [ - 1 ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> diff . append ( file_ ) <TAB> return diff ","if not os . path . exists ( target_path ) : 
","if self . _compare_path ( path , target_path ) :
",34.31,28.5,False
"def load_state_dict ( self , state_dict , strict = True ) : <TAB> """"""Customized load."""""" <TAB> self . language_model . load_state_dict ( <TAB> <TAB> state_dict [ self . _language_model_key ] , strict = strict <TAB> ) <TAB> if mpu . is_pipeline_last_stage ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . multichoice_head . load_state_dict ( <TAB> <TAB> <TAB> <TAB> state_dict [ self . _multichoice_head_key ] , strict = strict <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print_rank_last ( <TAB> <TAB> <TAB> <TAB> "" ***WARNING*** could not find  {}  in the checkpoint,  "" <TAB> <TAB> <TAB> <TAB> "" initializing to random "" . format ( self . _multichoice_head_key ) <TAB> <TAB> <TAB> ) ","if self . _multichoice_head_key in state_dict : 
","if self . _multichoice_head_key in state_dict :
",100.0,100.0,True
"def _parse_timedelta ( self , value ) : <TAB> try : <TAB> <TAB> sum = datetime . timedelta ( ) <TAB> <TAB> start = 0 <TAB> <TAB> while start < len ( value ) : <TAB> <TAB> <TAB> m = self . _TIMEDELTA_PATTERN . match ( value , start ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Exception ( ) <TAB> <TAB> <TAB> num = float ( m . group ( 1 ) ) <TAB> <TAB> <TAB> units = m . group ( 2 ) or "" seconds "" <TAB> <TAB> <TAB> units = self . _TIMEDELTA_ABBREV_DICT . get ( units , units ) <TAB> <TAB> <TAB> sum + = datetime . timedelta ( * * { units : num } ) <TAB> <TAB> <TAB> start = m . end ( ) <TAB> <TAB> return sum <TAB> except : <TAB> <TAB> raise ","if not m : 
","if not m :
",100.0,100.0,True
"def SetChildMenuBar ( self , pChild ) : <TAB> if not pChild : <TAB> <TAB> # No Child, set Our menu bar back. <TAB> <TAB> if self . _pMyMenuBar : <TAB> <TAB> <TAB> self . SetMenuBar ( self . _pMyMenuBar ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . SetMenuBar ( self . GetMenuBar ( ) ) <TAB> <TAB> # Make sure we know our menu bar is in use <TAB> <TAB> self . _pMyMenuBar = None <TAB> else : <TAB> <TAB> if pChild . GetMenuBar ( ) is None : <TAB> <TAB> <TAB> return <TAB> <TAB> # Do we need to save the current bar? <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _pMyMenuBar = self . GetMenuBar ( ) <TAB> <TAB> self . SetMenuBar ( pChild . GetMenuBar ( ) ) ","if self . _pMyMenuBar is None : 
","if self . GetMenuBar ( ) != self . GetMenuBar ( ) :
",37.38,11.36,False
"def init_weights ( self ) : <TAB> """"""Initialize weights of the head."""""" <TAB> # retinanet_bias_init <TAB> bias_cls = bias_init_with_prob ( 0.01 ) <TAB> normal_init ( self . conv_reg , std = 0.01 ) <TAB> normal_init ( self . conv_centerness , std = 0.01 ) <TAB> normal_init ( self . conv_cls , std = 0.01 , bias = bias_cls ) <TAB> for branch in [ self . cls_convs , self . reg_convs ] : <TAB> <TAB> for module in branch . modules ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> caffe2_xavier_init ( module . conv ) ","if isinstance ( module , ConvModule ) and isinstance ( module . conv , nn . Conv2d ) : 
","if isinstance ( module , nn . Conv2d ) :
",50.28,36.15,False
"def handle_exception ( self , e , result ) : <TAB> for k in sorted ( result . thrift_spec ) : <TAB> <TAB> if result . thrift_spec [ k ] [ 1 ] == "" success "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> _ , exc_name , exc_cls , _ = result . thrift_spec [ k ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( result , exc_name , e ) <TAB> <TAB> <TAB> break <TAB> else : <TAB> <TAB> raise ","if isinstance ( e , exc_cls ) : 
","if issubclass ( exc_cls , Exception ) :
",53.92,22.09,False
"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> <TAB> elif subdir : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) ) ","if script . startswith ( "" http "" ) : 
","if script . endswith ( "" .js "" ) :
",60.07,26.66,False
"def test_related_objects_local ( self ) : <TAB> result_key = "" get_all_related_objects_with_model_local "" <TAB> for model , expected in TEST_RESULTS [ result_key ] . items ( ) : <TAB> <TAB> objects = [ <TAB> <TAB> <TAB> ( field , self . _model ( model , field ) ) <TAB> <TAB> <TAB> for field in model . _meta . get_fields ( include_parents = False ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> ] <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> sorted ( self . _map_related_query_names ( objects ) , key = self . key_name ) , <TAB> <TAB> <TAB> sorted ( expected , key = self . key_name ) , <TAB> <TAB> ) ","if field . auto_created and not field . concrete 
","if field . rel . to . _meta . primary_key
",39.21,13.07,False
"def setTestOutcome ( self , event ) : <TAB> """"""Update outcome, exc_info and reason based on configured mappings"""""" <TAB> if event . exc_info : <TAB> <TAB> ec , ev , tb = event . exc_info <TAB> <TAB> classname = ec . __name__ <TAB> <TAB> if classname in self . treatAsFail : <TAB> <TAB> <TAB> short , long_ = self . labels ( classname ) <TAB> <TAB> <TAB> self . _setOutcome ( event , "" failed "" , short , long_ ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> short , long_ = self . labels ( classname , upper = False ) <TAB> <TAB> <TAB> self . _setOutcome ( event , "" skipped "" , short , "" %s :  ' %s ' "" % ( long_ , ev ) , str ( ev ) ) ","elif classname in self . treatAsSkip : 
","elif classname in self . treatAsSkip :
",100.0,100.0,True
"def small_count ( v ) : <TAB> if not v : <TAB> <TAB> return 0 <TAB> z = [ <TAB> <TAB> ( 1000000000 , _ ( "" b "" ) ) , <TAB> <TAB> ( 1000000 , _ ( "" m "" ) ) , <TAB> <TAB> ( 1000 , _ ( "" k "" ) ) , <TAB> ] <TAB> v = int ( v ) <TAB> for x , y in z : <TAB> <TAB> o , p = divmod ( v , x ) <TAB> <TAB> if o : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return "" %d %s "" % ( o , y ) <TAB> <TAB> <TAB> return "" %.1f %s "" % ( v / float ( x ) , y ) <TAB> return v ","if len ( str ( o ) ) > 2 or not p : 
","if p :
",26.05,0.0,False
"def __read ( self , n ) : <TAB> if self . _read_watcher is None : <TAB> <TAB> raise UnsupportedOperation ( "" read "" ) <TAB> while 1 : <TAB> <TAB> try : <TAB> <TAB> <TAB> return _read ( self . _fileno , n ) <TAB> <TAB> except ( IOError , OSError ) as ex : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> wait_on_watcher ( self . _read_watcher , None , None , self . hub ) ","if ex . args [ 0 ] not in ignored_errors : 
","if ex . errno != errno . EINTR :
",34.2,12.43,False
"def locked ( self ) : <TAB> inputfiles = set ( self . all_inputfiles ( ) ) <TAB> outputfiles = set ( self . all_outputfiles ( ) ) <TAB> if os . path . exists ( self . _lockdir ) : <TAB> <TAB> for lockfile in self . _locks ( "" input "" ) : <TAB> <TAB> <TAB> with open ( lockfile ) as lock : <TAB> <TAB> <TAB> <TAB> for f in lock : <TAB> <TAB> <TAB> <TAB> <TAB> f = f . strip ( ) <TAB> <TAB> <TAB> <TAB> <TAB> if f in outputfiles : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> for lockfile in self . _locks ( "" output "" ) : <TAB> <TAB> <TAB> with open ( lockfile ) as lock : <TAB> <TAB> <TAB> <TAB> for f in lock : <TAB> <TAB> <TAB> <TAB> <TAB> f = f . strip ( ) <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if f in outputfiles or f in inputfiles : 
","if f in inputfiles :
",53.67,37.78,False
"def _flags_to_int ( flags ) : <TAB> # Note, that order does not matter, libev has its own predefined order <TAB> if not flags : <TAB> <TAB> return 0 <TAB> if isinstance ( flags , integer_types ) : <TAB> <TAB> return flags <TAB> result = 0 <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flags = flags . split ( "" , "" ) <TAB> <TAB> for value in flags : <TAB> <TAB> <TAB> value = value . strip ( ) . lower ( ) <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> result | = _flags_str2int [ value ] <TAB> except KeyError as ex : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" Invalid backend or flag:  %s \n Possible values:  %s "" <TAB> <TAB> <TAB> % ( ex , "" ,  "" . join ( sorted ( _flags_str2int . keys ( ) ) ) ) <TAB> <TAB> ) <TAB> return result ","if isinstance ( flags , basestring ) : 
","if "" , "" in flags :
",27.07,8.05,False
"def setFg ( self , colour , override = False ) : <TAB> if not self . ttkFlag : <TAB> <TAB> self . containerStack [ - 1 ] [ "" fg "" ] = colour <TAB> <TAB> gui . SET_WIDGET_FG ( self . _getContainerProperty ( "" container "" ) , colour , override ) <TAB> <TAB> for child in self . _getContainerProperty ( "" container "" ) . winfo_children ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> gui . SET_WIDGET_FG ( child , colour , override ) <TAB> else : <TAB> <TAB> gui . trace ( "" In ttk mode - trying to set FG to  %s "" , colour ) <TAB> <TAB> self . ttkStyle . configure ( "" TLabel "" , foreground = colour ) <TAB> <TAB> self . ttkStyle . configure ( "" TFrame "" , foreground = colour ) ","if not self . _isWidgetContainer ( child ) : 
","if child . get_active ( ) :
",32.51,11.67,False
"def find_scintilla_constants ( f ) : <TAB> lexers = [ ] <TAB> states = [ ] <TAB> for name in f . order : <TAB> <TAB> v = f . features [ name ] <TAB> <TAB> if v [ "" Category "" ] != "" Deprecated "" : <TAB> <TAB> <TAB> if v [ "" FeatureType "" ] == "" val "" : <TAB> <TAB> <TAB> <TAB> if name . startswith ( "" SCE_ "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> states . append ( ( name , v [ "" Value "" ] ) ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> lexers . append ( ( name , v [ "" Value "" ] ) ) <TAB> return ( lexers , states ) ","elif name . startswith ( "" SCLEX_ "" ) : 
","elif v [ "" FeatureType "" ] == "" lex "" :
",30.58,4.37,False
"def extract_error_message ( response : requests . Response ) : <TAB> if response . content : <TAB> <TAB> try : <TAB> <TAB> <TAB> content = json . loads ( response . content ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return content [ "" message "" ] <TAB> <TAB> except : <TAB> <TAB> <TAB> logging . debug ( f "" Failed to parse the response content:  { response . content } "" ) <TAB> return response . reason ","if "" message "" in content : 
","if "" message "" in content :
",100.0,100.0,True
"def canvas_size ( self ) : <TAB> """"""Return the width and height for this sprite canvas"""""" <TAB> width = height = 0 <TAB> for image in self . images : <TAB> <TAB> x = image . x + image . absolute_width <TAB> <TAB> y = image . y + image . absolute_height <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> width = x <TAB> <TAB> if height < y : <TAB> <TAB> <TAB> height = y <TAB> return round_up ( width ) , round_up ( height ) ","if width < x : 
","if width < x :
",100.0,100.0,True
"def _load_widgets ( self ) : <TAB> logger . info ( "" Loading plugins preferences widgets "" ) <TAB> # Collect the preferences widget for each active plugin <TAB> for plugin in self . plugin_manager . get_active_plugins ( ) : <TAB> <TAB> plugin_name = plugin . metadata . get ( "" name "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> preferences_widget = plugin . get_preferences_widget ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _tabs . addTab ( preferences_widget , plugin_name ) <TAB> <TAB> except Exception as reason : <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> "" Unable to add the preferences widget ( %s ):  %s "" , plugin_name , reason <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue ","if preferences_widget : 
","if preferences_widget :
",78.12,100.0,True
"def clean_objects ( string , common_attributes ) : <TAB> """"""Return object and attribute lists"""""" <TAB> string = clean_string ( string ) <TAB> words = string . split ( ) <TAB> if len ( words ) > 1 : <TAB> <TAB> prefix_words_are_adj = True <TAB> <TAB> for att in words [ : - 1 ] : <TAB> <TAB> <TAB> if att not in common_attributes : <TAB> <TAB> <TAB> <TAB> prefix_words_are_adj = False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return words [ - 1 : ] , words [ : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ string ] , [ ] <TAB> else : <TAB> <TAB> return [ string ] , [ ] ","if prefix_words_are_adj : 
","if prefix_words_are_adj :
",78.12,100.0,True
"def _reader ( ) : <TAB> if shuffle : <TAB> <TAB> random . shuffle ( file_list ) <TAB> while True : <TAB> <TAB> for fn in file_list : <TAB> <TAB> <TAB> for line in open ( fn , "" r "" ) : <TAB> <TAB> <TAB> <TAB> yield self . _process_line ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","if not cycle : 
","if not self . _file_exists ( fn ) :
",31.35,7.5,False
"def load ( weights , model , K , fsz , dil ) : <TAB> index = 0 <TAB> layers = model . layers <TAB> for layer in layers . _layers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if layer . W . shape == weights [ index ] . shape : <TAB> <TAB> <TAB> <TAB> layer . W [ : ] = weights [ index ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> layer . W [ : ] = dilate ( weights [ index ] , K , fsz , dil ) <TAB> <TAB> <TAB> index + = 1 ","if hasattr ( layer , "" W "" ) : 
","if layer . _classifier . __name__ == "" Conv2d "" :
",31.54,3.42,False
"def upgrade ( migrate_engine ) : <TAB> print ( __doc__ ) <TAB> metadata . bind = migrate_engine <TAB> liftoverjobs = dict ( ) <TAB> jobs = context . query ( DeferredJob ) . filter_by ( plugin = "" LiftOverTransferPlugin "" ) . all ( ) <TAB> for job in jobs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] = [ ] <TAB> <TAB> liftoverjobs [ job . params [ "" parentjob "" ] ] . append ( job . id ) <TAB> for parent in liftoverjobs : <TAB> <TAB> lifts = liftoverjobs [ parent ] <TAB> <TAB> deferred = context . query ( DeferredJob ) . filter_by ( id = parent ) . first ( ) <TAB> <TAB> deferred . params [ "" liftover "" ] = lifts <TAB> context . flush ( ) ","if job . params [ "" parentjob "" ] not in liftoverjobs : 
","if job . params [ "" parentjob "" ] not in liftoverjobs :
",100.0,100.0,True
"def get_refs ( self , recursive = False ) : <TAB> """""":see: AbstractExpression.get_refs()"""""" <TAB> if recursive : <TAB> <TAB> conds_refs = self . refs + sum ( ( c . get_refs ( True ) for c in self . conds ) , [ ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> conds_refs . extend ( self . consequent . get_refs ( True ) ) <TAB> <TAB> return conds_refs <TAB> else : <TAB> <TAB> return self . refs ","if self . consequent : 
","if self . consequent is not None :
",60.15,36.56,False
"def _parse ( self , engine ) : <TAB> """"""Parse the layer."""""" <TAB> if isinstance ( self . args , dict ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . axis = engine . evaluate ( self . args [ "" axis "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . axis , int ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" axis ""  must be an integer. ' ) <TAB> <TAB> if "" momentum "" in self . args : <TAB> <TAB> <TAB> self . momentum = engine . evaluate ( self . args [ "" momentum "" ] , recursive = True ) <TAB> <TAB> <TAB> if not isinstance ( self . momentum , ( int , float ) ) : <TAB> <TAB> <TAB> <TAB> raise ParsingError ( ' "" momentum ""  must be numeric. ' ) ","if "" axis "" in self . args : 
","if "" axis "" in self . args :
",100.0,100.0,True
"def CountMatches ( pat , predicate ) : <TAB> num_matches = 0 <TAB> for i in xrange ( 256 ) : <TAB> <TAB> b = chr ( i ) <TAB> <TAB> m = pat . match ( b ) <TAB> <TAB> left = bool ( m ) <TAB> <TAB> right = predicate ( i ) <TAB> <TAB> if left != right : <TAB> <TAB> <TAB> self . fail ( "" i =  %d , b =  %r , match:  %s , predicate:  %s "" % ( i , b , left , right ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> num_matches + = 1 <TAB> return num_matches ","if m : 
","if m :
",78.12,0.0,False
"def __new__ ( cls , * args , * * kwargs ) : <TAB> if len ( args ) == 1 : <TAB> <TAB> if len ( kwargs ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" You can either use  {}  with one positional argument or with keyword arguments, not both. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> cls . __name__ <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> if not args [ 0 ] : <TAB> <TAB> <TAB> return super ( ) . __new__ ( cls ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return cls <TAB> return super ( ) . __new__ ( cls , * args , * * kwargs ) ","if isinstance ( args [ 0 ] , cls ) : 
","if kwargs . get ( "" _class "" , None ) is None :
",26.29,3.93,False
"def concatenateCharacterTokens ( tokens ) : <TAB> pendingCharacters = [ ] <TAB> for token in tokens : <TAB> <TAB> type = token [ "" type "" ] <TAB> <TAB> if type in ( "" Characters "" , "" SpaceCharacters "" ) : <TAB> <TAB> <TAB> pendingCharacters . append ( token [ "" data "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } <TAB> <TAB> <TAB> <TAB> pendingCharacters = [ ] <TAB> <TAB> <TAB> yield token <TAB> if pendingCharacters : <TAB> <TAB> yield { "" type "" : "" Characters "" , "" data "" : "" "" . join ( pendingCharacters ) } ","if pendingCharacters : 
","if pendingCharacters :
",78.12,0.0,False
"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB> <TAB> if func . type in support_set : <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end > = pos_start : <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges ","if pos_end > = pos_start : 
","if pos_start < = pos_end :
",53.08,38.26,False
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> if fname not in self . _flags : <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> if output == input : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func ) ","if self . _flags [ fname ] == 1 : 
","if fname not in self . _sorted :
",32.93,15.12,False
"def graph_merge_softmax_with_crossentropy_softmax ( node ) : <TAB> if node . op == softmax_with_bias : <TAB> <TAB> x , b = node . inputs <TAB> <TAB> for x_client in x . clients : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> big_client = x_client [ 0 ] <TAB> <TAB> <TAB> <TAB> if big_client in [ b_client [ 0 ] for b_client in b . clients ] : <TAB> <TAB> <TAB> <TAB> <TAB> xx , bb , ll = big_client . inputs <TAB> <TAB> <TAB> <TAB> <TAB> mergeable_client = big_client . op ( x , b , ll ) <TAB> <TAB> <TAB> <TAB> <TAB> copy_stack_trace ( node . outputs [ 0 ] , mergeable_client [ 1 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> return [ mergeable_client [ 1 ] ] ","if x_client [ 0 ] . op == crossentropy_softmax_argmax_1hot_with_bias : 
","if x_client in [ x_client [ 0 ] for x_client in b . clients ] :
",43.09,28.14,False
"def confidence ( self ) : <TAB> if self . bbox : <TAB> <TAB> # Units are measured in Kilometers <TAB> <TAB> distance = Distance ( self . northeast , self . southwest , units = "" km "" ) <TAB> <TAB> for score , maximum in [ <TAB> <TAB> <TAB> ( 10 , 0.25 ) , <TAB> <TAB> <TAB> ( 9 , 0.5 ) , <TAB> <TAB> <TAB> ( 8 , 1 ) , <TAB> <TAB> <TAB> ( 7 , 5 ) , <TAB> <TAB> <TAB> ( 6 , 7.5 ) , <TAB> <TAB> <TAB> ( 5 , 10 ) , <TAB> <TAB> <TAB> ( 4 , 15 ) , <TAB> <TAB> <TAB> ( 3 , 20 ) , <TAB> <TAB> <TAB> ( 2 , 25 ) , <TAB> <TAB> ] : <TAB> <TAB> <TAB> if distance < maximum : <TAB> <TAB> <TAB> <TAB> return score <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return 1 <TAB> # Cannot determine score <TAB> return 0 ","if distance > = 25 : 
","elif distance > self . bbox :
",29.03,14.54,False
"def OnListEndLabelEdit ( self , std , extra ) : <TAB> item = extra [ 0 ] <TAB> text = item [ 4 ] <TAB> if text is None : <TAB> <TAB> return <TAB> item_id = self . GetItem ( item [ 0 ] ) [ 6 ] <TAB> from bdb import Breakpoint <TAB> for bplist in Breakpoint . bplist . itervalues ( ) : <TAB> <TAB> for bp in bplist : <TAB> <TAB> <TAB> if id ( bp ) == item_id : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> text = None <TAB> <TAB> <TAB> <TAB> bp . cond = text <TAB> <TAB> <TAB> <TAB> break <TAB> self . RespondDebuggerData ( ) ","if text . strip ( ) . lower ( ) == "" none "" : 
","if len ( text ) == 0 :
",26.79,10.08,False
"def _handle_autocomplete_request_for_text ( text ) : <TAB> if not hasattr ( text , "" autocompleter "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( text , CodeViewText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = Completer ( text ) <TAB> <TAB> <TAB> elif isinstance ( text , ShellText ) : <TAB> <TAB> <TAB> <TAB> text . autocompleter = ShellCompleter ( text ) <TAB> <TAB> <TAB> text . bind ( "" <1> "" , text . autocompleter . on_text_click ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> text . autocompleter . handle_autocomplete_request ( ) ","if isinstance ( text , ( CodeViewText , ShellText ) ) and text . is_python_text ( ) : 
","if text . autocompleter is None :
",28.95,1.94,False
"def visit_Macro ( self , node , frame ) : <TAB> macro_frame , macro_ref = self . macro_body ( node , frame ) <TAB> self . newline ( ) <TAB> if frame . toplevel : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . write ( "" context.exported_vars.add( %r ) "" % node . name ) <TAB> <TAB> ref = frame . symbols . ref ( node . name ) <TAB> <TAB> self . writeline ( "" context.vars[ %r ] =  "" % node . name ) <TAB> self . write ( "" %s  =  "" % frame . symbols . ref ( node . name ) ) <TAB> self . macro_def ( macro_ref , macro_frame ) ","if not node . name . startswith ( "" _ "" ) : 
","if frame . name in self . seen_vars :
",30.21,8.22,False
"def execute ( cls , ctx , op ) : <TAB> try : <TAB> <TAB> pd . set_option ( "" mode.use_inf_as_na "" , op . use_inf_as_na ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return cls . _execute_map ( ctx , op ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return cls . _execute_combine ( ctx , op ) <TAB> finally : <TAB> <TAB> pd . reset_option ( "" mode.use_inf_as_na "" ) ","if op . stage == OperandStage . map : 
","if op . output_format == "" map "" :
",42.19,17.24,False
"def ranges ( self , start , end ) : <TAB> try : <TAB> <TAB> iterators = [ i . ranges ( start , end ) for i in self . range_iterators ] <TAB> <TAB> starts , ends , values = zip ( * [ next ( i ) for i in iterators ] ) <TAB> <TAB> starts = list ( starts ) <TAB> <TAB> ends = list ( ends ) <TAB> <TAB> values = list ( values ) <TAB> <TAB> while start < end : <TAB> <TAB> <TAB> min_end = min ( ends ) <TAB> <TAB> <TAB> yield start , min_end , values <TAB> <TAB> <TAB> start = min_end <TAB> <TAB> <TAB> for i , iterator in enumerate ( iterators ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> starts [ i ] , ends [ i ] , values [ i ] = next ( iterator ) <TAB> except StopIteration : <TAB> <TAB> return ","if ends [ i ] == min_end : 
","if start < = i < len ( values ) :
",26.64,5.3,False
"def get_explanation ( self , spec ) : <TAB> """"""Expand an explanation."""""" <TAB> if spec : <TAB> <TAB> try : <TAB> <TAB> <TAB> a = self . dns_txt ( spec ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return str ( self . expand ( to_ascii ( a [ 0 ] ) , stripdot = False ) ) <TAB> <TAB> except PermError : <TAB> <TAB> <TAB> # RFC4408 6.2/4 syntax errors cause exp= to be ignored <TAB> <TAB> <TAB> if self . strict > 1 : <TAB> <TAB> <TAB> <TAB> raise<TAB> # but report in harsh mode for record checking tools <TAB> <TAB> <TAB> pass <TAB> elif self . strict > 1 : <TAB> <TAB> raise PermError ( "" Empty domain-spec on exp= "" ) <TAB> # RFC4408 6.2/4 empty domain spec is ignored <TAB> # (unless you give precedence to the grammar). <TAB> return None ","if len ( a ) == 1 : 
","if len ( a ) == 1 :
",100.0,100.0,True
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> if exclude_meta and field . meta : <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> if field_val is _marker : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val ","if exclude_unset : 
","if field . default is not None and exclude_unset :
",32.88,22.42,False
"def __setattr__ ( self , name , value ) : <TAB> try : <TAB> <TAB> field = self . _meta . get_field ( name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = value [ : field . max_length ] <TAB> except models . fields . FieldDoesNotExist : <TAB> <TAB> pass<TAB> # This happens with foreign keys. <TAB> super . __setattr__ ( self , name , value ) ","if type ( field ) in [ models . CharField , models . TextField ] and type ( value ) == str : 
","if field . max_length and len ( value ) > field . max_length :
",40.08,7.54,False
"def create_child ( self , value = None , _id = None ) : <TAB> with atomic ( savepoint = False ) : <TAB> <TAB> child_key = self . get_next_child_key ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = child_key <TAB> <TAB> child = self . __class__ . objects . create ( id = _id , key = child_key , value = value ) <TAB> <TAB> return child ","if value is None : 
","if value is None :
",100.0,100.0,True
"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" HasMoreTags "" ] = True <TAB> <TAB> <TAB> break <TAB> <TAB> if exclusive_start_tag_key and key < exclusive_start_tag_key : <TAB> <TAB> <TAB> continue <TAB> <TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result ","if limit and len ( tags ) > = limit : 
","if limit and val [ "" NumberOfTags "" ] > limit :
",31.08,16.59,False
"def emit ( self , record ) : <TAB> try : <TAB> <TAB> app = get_app ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = self . format ( record ) <TAB> <TAB> <TAB> debug_buffer = app . layout . get_buffer_by_name ( "" debug_buffer "" ) <TAB> <TAB> <TAB> current_document = debug_buffer . document . text <TAB> <TAB> <TAB> if current_document : <TAB> <TAB> <TAB> <TAB> msg = "" \n "" . join ( [ current_document , msg ] ) <TAB> <TAB> <TAB> debug_buffer . set_document ( Document ( text = msg ) , bypass_readonly = True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> super ( ) . emit ( record ) <TAB> except : <TAB> <TAB> self . handleError ( record ) ","if app . is_running and getattr ( app , "" debug "" , False ) : 
","if app . layout . get_buffer_by_name ( "" debug_buffer "" ) is not None :
",35.97,9.39,False
"def worker ( ) : <TAB> global error <TAB> while True : <TAB> <TAB> ( num , q ) = pq . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pq . task_done ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> try : <TAB> <TAB> <TAB> process_one ( q ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> error = e <TAB> <TAB> finally : <TAB> <TAB> <TAB> pq . task_done ( ) ","if q is None or error is not None : 
","if num == 0 :
",26.18,4.96,False
"def transceiver ( self , data ) : <TAB> out = [ ] <TAB> for t in range ( 8 ) : <TAB> <TAB> if data [ t ] == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = data [ t ] <TAB> <TAB> for b in range ( 8 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if len ( TRANSCEIVER [ t ] ) < b + 1 : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( "" (unknown) "" ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> out . append ( TRANSCEIVER [ t ] [ b ] ) <TAB> <TAB> <TAB> value << = 1 <TAB> self . annotate ( "" Transceiver compliance "" , "" ,  "" . join ( out ) ) ","if value & 0x80 : 
","if value & 1 :
",64.48,42.73,False
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> if self . opHash . has_key ( tval ) : <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> if nestedCount < = 0 : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break ","if ttype == SCE_PL_UNUSED : 
","if ttype == "" EOF "" :
",36.73,28.47,False
"def GenerateVector ( self , hits , vector , level ) : <TAB> """"""Generate possible hit vectors which match the rules."""""" <TAB> for item in hits . get ( level , [ ] ) : <TAB> <TAB> if vector : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if item > self . max_separation + vector [ - 1 ] : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> new_vector = vector + [ item ] <TAB> <TAB> if level + 1 == len ( hits ) : <TAB> <TAB> <TAB> yield new_vector <TAB> <TAB> elif level + 1 < len ( hits ) : <TAB> <TAB> <TAB> for result in self . GenerateVector ( hits , new_vector , level + 1 ) : <TAB> <TAB> <TAB> <TAB> yield result ","if item < vector [ - 1 ] : 
","if item < vector [ - 1 ] :
",100.0,100.0,True
"def __setattr__ ( self , name , value ) : <TAB> if name == "" path "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value [ 0 ] != "" / "" : <TAB> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> <TAB> ' The page path should always start with a slash ( "" / "" ). ' <TAB> <TAB> <TAB> <TAB> ) <TAB> elif name == "" load_time "" : <TAB> <TAB> if value and not isinstance ( value , int ) : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Page load time must be specified in integer milliseconds. "" <TAB> <TAB> <TAB> ) <TAB> object . __setattr__ ( self , name , value ) ","if value and value != "" "" : 
","if value :
",27.94,0.0,False
"def awaitTermination ( self , timeout = None ) : <TAB> if self . scheduler is None : <TAB> <TAB> raise RuntimeError ( "" StreamimgContext not started "" ) <TAB> try : <TAB> <TAB> deadline = time . time ( ) + timeout if timeout is not None else None <TAB> <TAB> while True : <TAB> <TAB> <TAB> is_terminated = self . _runOnce ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if self . batchCallback : <TAB> <TAB> <TAB> <TAB> self . batchCallback ( ) <TAB> except KeyboardInterrupt : <TAB> <TAB> pass <TAB> finally : <TAB> <TAB> self . sc . stop ( ) <TAB> <TAB> logger . info ( "" StreamingContext stopped successfully "" ) ","if is_terminated or ( deadline is not None and time . time ( ) > deadline ) : 
","if is_terminated :
",25.68,3.52,False
"def stopbutton ( self ) : <TAB> if GPIOcontrol : <TAB> <TAB> while mediastopbutton : <TAB> <TAB> <TAB> time . sleep ( 0.25 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> print ( "" Stopped "" ) <TAB> <TAB> <TAB> <TAB> stop ( ) ","if not GPIO . input ( stoppushbutton ) : 
","if self . selected :
",30.79,6.32,False
"def test_create_connection_timeout ( self ) : <TAB> # Issue #9792: create_connection() should not recast timeout errors <TAB> # as generic socket errors. <TAB> with self . mocked_socket_module ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> socket . create_connection ( ( HOST , 1234 ) ) <TAB> <TAB> except socket . timeout : <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" socket.timeout not raised "" ) ","if support . IPV6_ENABLED or exc . errno != errno . EAFNOSUPPORT : 
","if exc . errno != errno . ECONNRESET :
",59.44,37.34,False
"def handle_exception_and_die ( e ) : <TAB> if hasattr ( e , "" kind "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sys . stderr . write ( "" ABORT:  "" + e . msg + "" \n "" ) <TAB> <TAB> <TAB> sys . exit ( e . value ) <TAB> <TAB> elif e . kind == "" exit "" : <TAB> <TAB> <TAB> sys . stderr . write ( "" EXITING \n "" ) <TAB> <TAB> <TAB> sys . exit ( e . value ) <TAB> else : <TAB> <TAB> print ( str ( e ) ) <TAB> <TAB> sys . exit ( 1 ) ","if e . kind == "" die "" : 
","if e . kind == "" abort "" :
",83.19,70.71,False
"def gets ( self , key ) : <TAB> with self . client_pool . get_and_release ( destroy_on_fail = True ) as client : <TAB> <TAB> try : <TAB> <TAB> <TAB> return client . gets ( key ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return ( None , None ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ","if self . ignore_exc : 
","if self . ignore_exc :
",100.0,100.0,True
"def _execute ( self , options , args ) : <TAB> if len ( args ) < 3 : <TAB> <TAB> raise CommandError ( _ ( "" Not enough arguments "" ) ) <TAB> tag = fsn2text ( args [ 0 ] ) <TAB> value = fsn2text ( args [ 1 ] ) <TAB> paths = args [ 2 : ] <TAB> songs = [ ] <TAB> for path in paths : <TAB> <TAB> song = self . load_song ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CommandError ( _ ( "" Can not set  %r "" ) % tag ) <TAB> <TAB> self . log ( "" Add  %r  to  %r "" % ( value , tag ) ) <TAB> <TAB> song . add ( tag , value ) <TAB> <TAB> songs . append ( song ) <TAB> self . save_songs ( songs ) ","if not song . can_change ( tag ) : 
","if not song :
",31.64,11.1,False
"def get_place_name ( self , place_handle ) : <TAB> """"""Obtain a place name"""""" <TAB> text = "" "" <TAB> if place_handle : <TAB> <TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB> <TAB> if place : <TAB> <TAB> <TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if len ( place_title ) > 25 : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title [ : 24 ] + "" ... "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text ","if place_title != "" "" : 
","if place_title :
",30.04,31.77,False
"def _Determine_Do ( self ) : <TAB> self . applicable = 1 <TAB> self . value = os . environ . get ( self . name , None ) <TAB> if self . value is None and black . configure . items . has_key ( "" buildType "" ) : <TAB> <TAB> buildType = black . configure . items [ "" buildType "" ] . Get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . value = "" warn "" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = None <TAB> self . determined = 1 ","if buildType == "" debug "" : 
","if buildType == "" warn "" :
",74.63,59.46,False
"def bundle_directory ( self , dirpath ) : <TAB> """"""Bundle all modules/packages in the given directory."""""" <TAB> dirpath = os . path . abspath ( dirpath ) <TAB> for nm in os . listdir ( dirpath ) : <TAB> <TAB> nm = _u ( nm ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> itempath = os . path . join ( dirpath , nm ) <TAB> <TAB> if os . path . isdir ( itempath ) : <TAB> <TAB> <TAB> if os . path . exists ( os . path . join ( itempath , "" __init__.py "" ) ) : <TAB> <TAB> <TAB> <TAB> self . bundle_package ( itempath ) <TAB> <TAB> elif nm . endswith ( "" .py "" ) : <TAB> <TAB> <TAB> self . bundle_module ( itempath ) ","if nm . startswith ( "" . "" ) : 
","if not _is_file ( nm ) :
",27.92,10.55,False
"def header_fields ( self , fields ) : <TAB> headers = dict ( self . conn . response . getheaders ( ) ) <TAB> ret = { } <TAB> for field in fields : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" %s  was not found in response header "" % ( field [ 1 ] ) ) <TAB> <TAB> try : <TAB> <TAB> <TAB> ret [ field [ 0 ] ] = int ( headers [ field [ 1 ] ] ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> ret [ field [ 0 ] ] = headers [ field [ 1 ] ] <TAB> return ret ","if not headers . has_key ( field [ 1 ] ) : 
","if field [ 1 ] not in headers :
",41.53,20.37,False
"def caesar_cipher ( s , k ) : <TAB> result = "" "" <TAB> for char in s : <TAB> <TAB> n = ord ( char ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n = ( ( n - 65 + k ) % 26 ) + 65 <TAB> <TAB> if 96 < n < 123 : <TAB> <TAB> <TAB> n = ( ( n - 97 + k ) % 26 ) + 97 <TAB> <TAB> result = result + chr ( n ) <TAB> return result ","if 64 < n < 91 : 
","if 65 < n < 65 :
",59.45,27.78,False
"def qtTypeIdent ( conn , * args ) : <TAB> # We're not using the conn object at the moment, but - we will <TAB> # modify the <TAB> # logic to use the server version specific keywords later. <TAB> res = None <TAB> value = None <TAB> for val in args : <TAB> <TAB> # DataType doesn't have len function then convert it to string <TAB> <TAB> if not hasattr ( val , "" __len__ "" ) : <TAB> <TAB> <TAB> val = str ( val ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = val <TAB> <TAB> if Driver . needsQuoting ( val , True ) : <TAB> <TAB> <TAB> value = value . replace ( ' "" ' , ' "" "" ' ) <TAB> <TAB> <TAB> value = ' "" ' + value + ' "" ' <TAB> <TAB> res = ( ( res and res + "" . "" ) or "" "" ) + value <TAB> return res ","if len ( val ) == 0 : 
","if not hasattr ( val , "" __len__ "" ) :
",28.19,6.92,False
"def _parse_timezone ( <TAB> value : Optional [ str ] , error : Type [ Exception ] ) - > Union [ None , int , timezone ] : <TAB> if value == "" Z "" : <TAB> <TAB> return timezone . utc <TAB> elif value is not None : <TAB> <TAB> offset_mins = int ( value [ - 2 : ] ) if len ( value ) > 3 else 0 <TAB> <TAB> offset = 60 * int ( value [ 1 : 3 ] ) + offset_mins <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> offset = - offset <TAB> <TAB> try : <TAB> <TAB> <TAB> return timezone ( timedelta ( minutes = offset ) ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> raise error ( ) <TAB> else : <TAB> <TAB> return None ","if value [ 0 ] == "" - "" : 
","if value [ 0 ] == "" - "" :
",100.0,100.0,True
"def indent ( elem , level = 0 ) : <TAB> i = "" \n "" + level * ""<TAB> "" <TAB> if len ( elem ) : <TAB> <TAB> if not elem . text or not elem . text . strip ( ) : <TAB> <TAB> <TAB> elem . text = i + ""<TAB> "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elem . tail = i <TAB> <TAB> for elem in elem : <TAB> <TAB> <TAB> indent ( elem , level + 1 ) <TAB> <TAB> if not elem . tail or not elem . tail . strip ( ) : <TAB> <TAB> <TAB> elem . tail = i <TAB> else : <TAB> <TAB> if level and ( not elem . tail or not elem . tail . strip ( ) ) : <TAB> <TAB> <TAB> elem . tail = i ","if not elem . tail or not elem . tail . strip ( ) : 
","if not elem . tail or not elem . tail . strip ( ) :
",100.0,100.0,True
"def _make_slices ( <TAB> shape : tp . Tuple [ int , . . . ] , <TAB> axes : tp . Tuple [ int , . . . ] , <TAB> size : int , <TAB> rng : np . random . RandomState , ) - > tp . List [ slice ] : <TAB> slices = [ ] <TAB> for a , s in enumerate ( shape ) : <TAB> <TAB> if a in axes : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" Cannot crossover on axis with size 1 "" ) <TAB> <TAB> <TAB> start = rng . randint ( s - size ) <TAB> <TAB> <TAB> slices . append ( slice ( start , start + size ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> slices . append ( slice ( None ) ) <TAB> return slices ","if s < = 1 : 
","if s < 1 :
",38.32,40.94,False
"def _loadTestsFromTestCase ( self , event , testCaseClass ) : <TAB> evt = events . LoadFromTestCaseEvent ( event . loader , testCaseClass ) <TAB> result = self . session . hooks . loadTestsFromTestCase ( evt ) <TAB> if evt . handled : <TAB> <TAB> loaded_suite = result or event . loader . suiteClass ( ) <TAB> else : <TAB> <TAB> names = self . _getTestCaseNames ( event , testCaseClass ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> names = [ "" runTest "" ] <TAB> <TAB> # FIXME return failure test case if name not in testcase class <TAB> <TAB> loaded_suite = event . loader . suiteClass ( map ( testCaseClass , names ) ) <TAB> if evt . extraTests : <TAB> <TAB> loaded_suite . addTests ( evt . extraTests ) <TAB> return loaded_suite ","if not names and hasattr ( testCaseClass , "" runTest "" ) : 
","if not names :
",32.01,6.73,False
"def check_settings ( self ) : <TAB> if self . settings_dict [ "" TIME_ZONE "" ] is not None : <TAB> <TAB> if not settings . USE_TZ : <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because USE_TZ is  "" <TAB> <TAB> <TAB> <TAB> "" False. "" % self . alias <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ImproperlyConfigured ( <TAB> <TAB> <TAB> <TAB> "" Connection  ' %s '  cannot set TIME_ZONE because its engine  "" <TAB> <TAB> <TAB> <TAB> "" handles time zones conversions natively. "" % self . alias <TAB> <TAB> <TAB> ) ","elif self . features . supports_timezones : 
","if self . settings_dict [ "" TIME_ZONE "" ] not in settings . TIME_ZONE_ENGINES :
",33.94,4.14,False
"def collect_conflicting_diffs ( path , decisions ) : <TAB> local_conflict_diffs = [ ] <TAB> remote_conflict_diffs = [ ] <TAB> for d in decisions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ld = adjust_patch_level ( path , d . common_path , d . local_diff ) <TAB> <TAB> <TAB> rd = adjust_patch_level ( path , d . common_path , d . remote_diff ) <TAB> <TAB> <TAB> local_conflict_diffs . extend ( ld ) <TAB> <TAB> <TAB> remote_conflict_diffs . extend ( rd ) <TAB> return local_conflict_diffs , remote_conflict_diffs ","if d . conflict : 
","if d . common_path and d . remote_diff :
",43.86,12.36,False
"def short_repr ( obj ) : <TAB> if isinstance ( <TAB> <TAB> obj , <TAB> <TAB> ( type , types . ModuleType , types . BuiltinMethodType , types . BuiltinFunctionType ) , <TAB> ) : <TAB> <TAB> return obj . __name__ <TAB> if isinstance ( obj , types . MethodType ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return obj . im_func . __name__ + ""  (bound) "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return obj . im_func . __name__ <TAB> if isinstance ( obj , ( tuple , list , dict , set ) ) : <TAB> <TAB> return "" %d  items "" % len ( obj ) <TAB> if isinstance ( obj , weakref . ref ) : <TAB> <TAB> return "" all_weakrefs_are_one "" <TAB> return repr ( obj ) [ : 40 ] ","if obj . im_self is not None : 
","if obj . im_func . __name__ in ( "" bound "" , "" function "" ) :
",34.87,16.13,False
"def _massage_uri ( uri ) : <TAB> if uri : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> uri = uri . replace ( "" hdfs:// "" , get_defaultfs ( ) ) <TAB> <TAB> elif uri . startswith ( "" / "" ) : <TAB> <TAB> <TAB> uri = get_defaultfs ( ) + uri <TAB> return uri ","if uri . startswith ( "" hdfs:/// "" ) : 
","if uri . startswith ( "" hdfs:// "" ) :
",83.03,90.19,False
"def chsub ( self , msg , chatid ) : <TAB> ( cmd , evt , params ) = self . tokenize ( msg , 3 ) <TAB> if cmd == "" /sub "" : <TAB> <TAB> sql = "" replace into telegram_subscriptions(uid, event_type, parameters) values (?, ?, ?) "" <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sql = "" delete from telegram_subscriptions where uid = ? and (event_type = ? or parameters = ? or 1 = 1) ""<TAB> # does not look very elegant, but makes unsub'ing everythign possible <TAB> <TAB> else : <TAB> <TAB> <TAB> sql = "" delete from telegram_subscriptions where uid = ? and event_type = ? and parameters = ? "" <TAB> with self . bot . database as conn : <TAB> <TAB> conn . execute ( sql , [ chatid , evt , params ] ) <TAB> <TAB> conn . commit ( ) <TAB> return ","if evt == "" everything "" : 
","if evt == "" subscriptions "" :
",74.63,59.46,False
"def undefined_symbols ( self ) : <TAB> result = [ ] <TAB> for p in self . Productions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for s in p . prod : <TAB> <TAB> <TAB> if not s in self . Prodnames and not s in self . Terminals and s != "" error "" : <TAB> <TAB> <TAB> <TAB> result . append ( ( s , p ) ) <TAB> return result ","if not p : 
","if not p :
",100.0,100.0,True
"def renumber ( self , x1 , y1 , x2 , y2 , dx , dy ) : <TAB> out = [ ] <TAB> for part in re . split ( "" ( \ w+) "" , self . formula ) : <TAB> <TAB> m = re . match ( "" ^([A-Z]+)([1-9][0-9]*)$ "" , part ) <TAB> <TAB> if m is not None : <TAB> <TAB> <TAB> sx , sy = m . groups ( ) <TAB> <TAB> <TAB> x = colname2num ( sx ) <TAB> <TAB> <TAB> y = int ( sy ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> part = cellname ( x + dx , y + dy ) <TAB> <TAB> out . append ( part ) <TAB> return FormulaCell ( "" "" . join ( out ) , self . fmt , self . alignment ) ","if x1 < = x < = x2 and y1 < = y < = y2 : 
","if x != x2 and y != y :
",26.58,11.43,False
"def modify_column ( self , column : List [ Optional [ "" Cell "" ] ] ) : <TAB> for i in range ( len ( column ) ) : <TAB> <TAB> gate = column [ i ] <TAB> <TAB> if gate is self : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # The first parity control to modify the column must merge all <TAB> <TAB> <TAB> # of the other parity controls into itself. <TAB> <TAB> <TAB> column [ i ] = None <TAB> <TAB> <TAB> self . _basis_change + = gate . _basis_change <TAB> <TAB> <TAB> self . qubits + = gate . qubits <TAB> <TAB> elif gate is not None : <TAB> <TAB> <TAB> column [ i ] = gate . controlled_by ( self . qubits [ 0 ] ) ","elif isinstance ( gate , ParityControlCell ) : 
","if gate . controlled_by ( self . qubits [ 0 ] ) :
",27.55,6.25,False
"def update_neighbor ( neigh_ip_address , changes ) : <TAB> rets = [ ] <TAB> for k , v in changes . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rets . append ( _update_med ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . ENABLED : <TAB> <TAB> <TAB> rets . append ( update_neighbor_enabled ( neigh_ip_address , v ) ) <TAB> <TAB> if k == neighbors . CONNECT_MODE : <TAB> <TAB> <TAB> rets . append ( _update_connect_mode ( neigh_ip_address , v ) ) <TAB> return all ( rets ) ","if k == neighbors . MULTI_EXIT_DISC : 
","if k == neighbors . Med :
",82.41,42.89,False
"def writexml ( <TAB> self , <TAB> stream , <TAB> indent = "" "" , <TAB> addindent = "" "" , <TAB> newl = "" "" , <TAB> strip = 0 , <TAB> nsprefixes = { } , <TAB> namespace = "" "" , ) : <TAB> w = _streamWriteWrapper ( stream ) <TAB> if self . raw : <TAB> <TAB> val = self . nodeValue <TAB> <TAB> if not isinstance ( val , str ) : <TAB> <TAB> <TAB> val = str ( self . nodeValue ) <TAB> else : <TAB> <TAB> v = self . nodeValue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = str ( v ) <TAB> <TAB> if strip : <TAB> <TAB> <TAB> v = "" "" . join ( v . split ( ) ) <TAB> <TAB> val = escape ( v ) <TAB> w ( val ) ","if not isinstance ( v , str ) : 
","if not isinstance ( v , str ) :
",100.0,100.0,True
"def _condition ( ct ) : <TAB> for qobj in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj . children : <TAB> <TAB> <TAB> <TAB> kwargs . update ( dict ( [ child ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( "" Unsupported Q object "" ) <TAB> for attr , val in kwargs . items ( ) : <TAB> <TAB> if getattr ( ct , attr ) != val : <TAB> <TAB> <TAB> return False <TAB> return True ","if qobj . connector == "" AND "" and not qobj . negated : 
","if isinstance ( qobj , QGroup ) :
",25.93,3.03,False
"def results_iter ( self ) : <TAB> <MASK> <TAB> <TAB> from django . db . models . fields import DateTimeField <TAB> <TAB> fields = [ DateTimeField ( ) ] <TAB> else : <TAB> <TAB> needs_string_cast = self . connection . features . needs_datetime_string_cast <TAB> offset = len ( self . query . extra_select ) <TAB> for rows in self . execute_sql ( MULTI ) : <TAB> <TAB> for row in rows : <TAB> <TAB> <TAB> date = row [ offset ] <TAB> <TAB> <TAB> if self . connection . ops . oracle : <TAB> <TAB> <TAB> <TAB> date = self . resolve_columns ( row , fields ) [ offset ] <TAB> <TAB> <TAB> elif needs_string_cast : <TAB> <TAB> <TAB> <TAB> date = typecast_timestamp ( str ( date ) ) <TAB> <TAB> <TAB> yield date ","if self . connection . ops . oracle : 
","if self . connection . ops . oracle :
",100.0,100.0,True
"def get_job_type ( self ) : <TAB> if int ( self . job_runtime_conf . get ( "" dsl_version "" , 1 ) ) == 2 : <TAB> <TAB> job_type = ( <TAB> <TAB> <TAB> self . job_runtime_conf [ "" job_parameters "" ] . get ( "" common "" , { } ) . get ( "" job_type "" ) <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> else : <TAB> <TAB> job_type = self . job_runtime_conf [ "" job_parameters "" ] . get ( "" job_type "" , "" train "" ) <TAB> return job_type ","if not job_type : 
","if job_type == "" train "" :
",28.57,17.75,False
"def validate_assessment_criteria ( self ) : <TAB> if self . assessment_criteria : <TAB> <TAB> total_weightage = 0 <TAB> <TAB> for criteria in self . assessment_criteria : <TAB> <TAB> <TAB> total_weightage + = criteria . weightage or 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Total Weightage of all Assessment Criteria must be 100 % "" ) ) ","if total_weightage != 100 : 
","if total_weightage > 100 :
",58.14,42.38,False
"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB> <TAB> for x in notifications_list : <TAB> <TAB> <TAB> split_provider_id = x . split ( "" : "" )<TAB> # email:id <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> _id = split_provider_id [ 1 ] <TAB> <TAB> <TAB> <TAB> cursor = self . get_by_id ( _id ) <TAB> <TAB> <TAB> <TAB> if cursor :<TAB> # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result . append ( cursor ) <TAB> return result ","if len ( split_provider_id ) == 2 : 
","if split_provider_id [ 0 ] == "" email:id "" :
",26.8,26.22,False
"def dump_predictions_to_database ( relation , predictions ) : <TAB> judge = "" iepy-run on  {} "" . format ( datetime . now ( ) . strftime ( "" % Y- % m- %d % H: % M "" ) ) <TAB> for evidence , relation_is_present in predictions . items ( ) : <TAB> <TAB> label = ( <TAB> <TAB> <TAB> EvidenceLabel . YESRELATION <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else EvidenceLabel . NORELATION <TAB> <TAB> ) <TAB> <TAB> evidence . set_label ( relation , label , judge , labeled_by_machine = True ) ","if relation_is_present 
","if relation_is_present
",65.81,100.0,True
"def __init__ ( self , * * kwargs ) : <TAB> # We hard-code the `to` argument for ForeignKey.__init__ <TAB> dfl = get_model_label ( self . default_model_class ) <TAB> if "" to "" in kwargs . keys ( ) :<TAB> # pragma: no cover <TAB> <TAB> old_to = get_model_label ( kwargs . pop ( "" to "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg = "" %s  can only be a ForeignKey to  %s ;  %s  passed "" % ( <TAB> <TAB> <TAB> <TAB> self . __class__ . __name__ , <TAB> <TAB> <TAB> <TAB> dfl , <TAB> <TAB> <TAB> <TAB> old_to , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> warnings . warn ( msg , SyntaxWarning ) <TAB> kwargs [ "" to "" ] = dfl <TAB> super ( ) . __init__ ( * * kwargs ) ","if old_to . lower ( ) != dfl . lower ( ) : 
","if dfl != old_to :
",26.03,10.69,False
"def reverse ( self ) : <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB> <TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB> <TAB> li + = 1 <TAB> <TAB> if li > = BLOCKLEN : <TAB> <TAB> <TAB> lb = lb . rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rb = rb . leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1 ","if ri < 0 : 
","if ri < BLOCKLEN :
",39.48,42.73,False
"def get_api ( user , url ) : <TAB> global API_CACHE <TAB> if API_CACHE is None or API_CACHE . get ( url ) is None : <TAB> <TAB> API_CACHE_LOCK . acquire ( ) <TAB> <TAB> try : <TAB> <TAB> <TAB> if API_CACHE is None : <TAB> <TAB> <TAB> <TAB> API_CACHE = { } <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> API_CACHE [ url ] = ImpalaDaemonApi ( url ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> API_CACHE_LOCK . release ( ) <TAB> api = API_CACHE [ url ] <TAB> api . set_user ( user ) <TAB> return api ","if API_CACHE . get ( url ) is None : 
","if url not in API_CACHE :
",26.47,14.83,False
"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB> <TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> start , stop = index . start , index . stop <TAB> <TAB> new_start , new_stop = None , None <TAB> <TAB> if start is not None : <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB> <TAB> new_index = [ ] <TAB> <TAB> for ind in index : <TAB> <TAB> <TAB> new_index . append ( length - ind ) <TAB> return new_index ","if stop is not None : 
","if stop is not None :
",100.0,100.0,True
"def infer_returned_object ( pyfunction , args ) : <TAB> """"""Infer the `PyObject` this `PyFunction` returns after calling"""""" <TAB> object_info = pyfunction . pycore . object_info <TAB> result = object_info . get_exact_returned ( pyfunction , args ) <TAB> if result is not None : <TAB> <TAB> return result <TAB> result = _infer_returned ( pyfunction , args ) <TAB> if result is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> params = args . get_arguments ( pyfunction . get_param_names ( special_args = False ) ) <TAB> <TAB> <TAB> object_info . function_called ( pyfunction , params , result ) <TAB> <TAB> return result <TAB> return object_info . get_returned ( pyfunction , args ) ","if args and pyfunction . get_module ( ) . get_resource ( ) is not None : 
","if object_info . is_function_called ( pyfunction , result ) :
",28.17,3.3,False
"def _check_imports ( lib ) : <TAB> # Make sure no conflicting libraries have been imported. <TAB> libs = [ "" PyQt4 "" , "" PyQt5 "" , "" PySide "" ] <TAB> libs . remove ( lib ) <TAB> for lib2 in libs : <TAB> <TAB> lib2 + = "" .QtCore "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> "" Refusing to import  %s  because  %s  is already  "" "" imported. "" % ( lib , lib2 ) <TAB> <TAB> <TAB> ) ","if lib2 in sys . modules : 
","if os . path . exists ( lib2 ) :
",33.14,5.93,False
"def _poll ( fds , timeout ) : <TAB> if timeout is not None : <TAB> <TAB> timeout = int ( timeout * 1000 )<TAB> # timeout is in milliseconds <TAB> fd_map = { } <TAB> pollster = select . poll ( ) <TAB> for fd in fds : <TAB> <TAB> pollster . register ( fd , select . POLLIN ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fd_map [ fd . fileno ( ) ] = fd <TAB> <TAB> else : <TAB> <TAB> <TAB> fd_map [ fd ] = fd <TAB> ls = [ ] <TAB> for fd , event in pollster . poll ( timeout ) : <TAB> <TAB> if event & select . POLLNVAL : <TAB> <TAB> <TAB> raise ValueError ( "" invalid file descriptor  %i "" % fd ) <TAB> <TAB> ls . append ( fd_map [ fd ] ) <TAB> return ls ","if hasattr ( fd , "" fileno "" ) : 
","if fd . fileno ( ) :
",28.03,11.26,False
"def default ( cls , connection = None ) : <TAB> """"""show the default connection, or make CONNECTION the default"""""" <TAB> if connection is not None : <TAB> <TAB> target = cls . _get_config_filename ( connection ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if os . path . exists ( cls . _default_symlink ) : <TAB> <TAB> <TAB> <TAB> os . remove ( cls . _default_symlink ) <TAB> <TAB> <TAB> os . symlink ( target , cls . _default_symlink ) <TAB> <TAB> else : <TAB> <TAB> <TAB> cls . _no_config_file_error ( target ) <TAB> if os . path . exists ( cls . _default_symlink ) : <TAB> <TAB> print ( "" Default connection is  "" + cls . _default_connection ( ) ) <TAB> else : <TAB> <TAB> print ( "" There is no default connection set "" ) ","if os . path . exists ( target ) : 
","if target :
",26.15,0.0,False
"def process ( self , fuzzresult ) : <TAB> base_url = urljoin ( fuzzresult . url , "" .. "" ) <TAB> for line in fuzzresult . history . content . splitlines ( ) : <TAB> <TAB> record = line . split ( "" / "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> # Directory <TAB> <TAB> <TAB> if record [ 0 ] == "" D "" : <TAB> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , record [ 1 ] ) ) <TAB> <TAB> <TAB> <TAB> self . queue_url ( urljoin ( base_url , "" %s /CVS/Entries "" % ( record [ 1 ] ) ) ) ","if len ( record ) == 6 and record [ 1 ] : 
","if record [ 0 ] == "" CVS "" :
",30.75,9.28,False
"def _GetCSVRow ( self , value ) : <TAB> row = [ ] <TAB> for type_info in value . __class__ . type_infos : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> row . extend ( self . _GetCSVRow ( value . Get ( type_info . name ) ) ) <TAB> <TAB> elif isinstance ( type_info , rdf_structs . ProtoBinary ) : <TAB> <TAB> <TAB> row . append ( text . Asciify ( value . Get ( type_info . name ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> row . append ( str ( value . Get ( type_info . name ) ) ) <TAB> return row ","if isinstance ( type_info , rdf_structs . ProtoEmbedded ) : 
","if isinstance ( type_info , rdf_structs . ProtoTable ) :
",85.49,80.91,False
"def get_history ( self , state , dict_ , passive = PASSIVE_OFF ) : <TAB> if self . key in dict_ : <TAB> <TAB> return History . from_scalar_attribute ( self , state , dict_ [ self . key ] ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> passive ^ = INIT_OK <TAB> <TAB> current = self . get ( state , dict_ , passive = passive ) <TAB> <TAB> if current is PASSIVE_NO_RESULT : <TAB> <TAB> <TAB> return HISTORY_BLANK <TAB> <TAB> else : <TAB> <TAB> <TAB> return History . from_scalar_attribute ( self , state , current ) ","if passive & INIT_OK : 
","if passive & INIT_OK :
",100.0,100.0,True
"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB> <TAB> result + = ( current , ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> elif current . _parent is None : <TAB> <TAB> <TAB> raise sa_exc . InvalidRequestError ( <TAB> <TAB> <TAB> <TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> current = current . _parent <TAB> return result ","if current . _parent is upto : 
","if current . _parent == upto :
",73.7,51.33,False
"def get_by_uri ( self , uri : str ) - > bytes : <TAB> userId , bucket , key = self . _parse_uri ( uri ) <TAB> try : <TAB> <TAB> with db . session_scope ( ) as dbsession : <TAB> <TAB> <TAB> result = db_archivedocument . get ( userId , bucket , key , session = dbsession ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return utils . ensure_bytes ( self . _decode ( result ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ObjectKeyNotFoundError ( userId , bucket , key , caused_by = None ) <TAB> except Exception as err : <TAB> <TAB> logger . debug ( "" cannot get data: exception -  "" + str ( err ) ) <TAB> <TAB> raise err ","if result : 
","if result :
",78.12,0.0,False
"def app ( scope , receive , send ) : <TAB> while True : <TAB> <TAB> message = await receive ( ) <TAB> <TAB> if message [ "" type "" ] == "" websocket.connect "" : <TAB> <TAB> <TAB> await send ( { "" type "" : "" websocket.accept "" } ) <TAB> <TAB> elif message [ "" type "" ] == "" websocket.receive "" : <TAB> <TAB> <TAB> pass <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break ","elif message [ "" type "" ] == "" websocket.disconnect "" : 
","elif message [ "" type "" ] == "" websocket.disconnect "" :
",100.0,100.0,True
"def recv_some ( p , t = 0.1 , e = 1 , tr = 5 , stderr = 0 ) : <TAB> if tr < 1 : <TAB> <TAB> tr = 1 <TAB> x = time . time ( ) + t <TAB> y = [ ] <TAB> r = "" "" <TAB> if stderr : <TAB> <TAB> pr = p . recv_err <TAB> else : <TAB> <TAB> pr = p . recv <TAB> while time . time ( ) < x or r : <TAB> <TAB> r = pr ( ) <TAB> <TAB> if r is None : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y . append ( r ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time . sleep ( max ( ( x - time . time ( ) ) / tr , 0 ) ) <TAB> return "" "" . join ( y ) ","elif r : 
","if e :
",30.14,0.0,False
"def mouse_down ( self , event ) : <TAB> if event . button == 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p = event . local <TAB> <TAB> <TAB> if self . scroll_up_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_up ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> elif self . scroll_down_rect ( ) . collidepoint ( p ) : <TAB> <TAB> <TAB> <TAB> self . scroll_down ( ) <TAB> <TAB> <TAB> <TAB> return <TAB> if event . button == 4 : <TAB> <TAB> self . scroll_up ( ) <TAB> if event . button == 5 : <TAB> <TAB> self . scroll_down ( ) <TAB> GridView . mouse_down ( self , event ) ","if self . scrolling : 
","if self . scroll_up_rect ( ) . collidepoint ( event . local ) :
",42.57,8.59,False
"def copy_from ( self , other ) : <TAB> if self is other : <TAB> <TAB> return<TAB> # Myself! <TAB> self . strictness = other . strictness<TAB> # sets behaviors in bulk <TAB> for name in self . all_behaviors : <TAB> <TAB> self . set_behavior ( name , other . get_behavior ( name ) ) <TAB> for name in self . _plain_attrs : <TAB> <TAB> val = getattr ( other , name ) <TAB> <TAB> if isinstance ( val , set ) : <TAB> <TAB> <TAB> val = val . copy ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = val . copy ( ) <TAB> <TAB> setattr ( self , name , val ) ","elif decimal and isinstance ( val , decimal . Decimal ) : 
","elif isinstance ( val , dict ) :
",37.93,25.92,False
"def __array_wrap__ ( self , out_arr , context = None ) : <TAB> if self . dim is None : <TAB> <TAB> return out_arr <TAB> else : <TAB> <TAB> this = self [ : ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return Quantity . __array_wrap__ ( self [ : ] , out_arr , context = context ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return out_arr ","if isinstance ( this , Quantity ) : 
","if isinstance ( this , ( Quantity , Quantity ) ) :
",53.98,44.07,False
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> if token . ClosesScope ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if token . OpensScope ( ) : <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False ","if token . value == "" { "" : 
","if token . OpensScope ( ) :
",36.76,17.11,False
"def save_all_changed_extensions ( self ) : <TAB> """"""Save configuration changes to the user config file."""""" <TAB> has_changes = False <TAB> for ext_name in self . extensions : <TAB> <TAB> options = self . extensions [ ext_name ] <TAB> <TAB> for opt in options : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> has_changes = True <TAB> if has_changes : <TAB> <TAB> self . ext_userCfg . Save ( ) ","if self . set_extension_value ( ext_name , opt ) : 
","if opt . Name != ext_name :
",31.64,10.59,False
"def to_dict ( self ) : <TAB> out = { } <TAB> for key in ACTIVITY_KEYS : <TAB> <TAB> attr = getattr ( self , key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out [ key ] = str ( attr ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out [ key ] = attr <TAB> if self . streak : <TAB> <TAB> out [ "" streak "" ] = self . streak <TAB> return out ","if isinstance ( attr , ( datetime . timedelta , datetime . datetime ) ) : 
","if isinstance ( attr , dict ) :
",37.44,21.87,False
"def clean_publication_date ( cls , cleaned_input ) : <TAB> for add_channel in cleaned_input . get ( "" add_channels "" , [ ] ) : <TAB> <TAB> is_published = add_channel . get ( "" is_published "" ) <TAB> <TAB> publication_date = add_channel . get ( "" publication_date "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> add_channel [ "" publication_date "" ] = datetime . date . today ( ) ","if is_published and not publication_date : 
","if is_published and not publication_date :
",100.0,100.0,True
"def _random_blur ( self , batch , sigma_max ) : <TAB> for i in range ( len ( batch ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Random sigma <TAB> <TAB> <TAB> sigma = random . uniform ( 0.0 , sigma_max ) <TAB> <TAB> <TAB> batch [ i ] = scipy . ndimage . filters . gaussian_filter ( batch [ i ] , sigma ) <TAB> return batch ","if bool ( random . getrandbits ( 1 ) ) : 
","if random . random ( ) < 0.5 :
",31.29,10.05,False
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> if dsn [ i ] . isspace ( ) : <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> if not param_match : <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret ","if i > = length : 
","if not param :
",27.85,11.52,False
"def set_environment_vars ( env , source_env ) : <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env : <TAB> <TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB> <TAB> if is_forwarded_environment_variable ( name ) : <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = file_host . rebase_to_worker_root ( value ) <TAB> <TAB> <TAB> env [ name ] = value ","if os . getenv ( "" TRUSTED_HOST "" ) and should_rebase_environment_value ( name ) : 
","if os . path . isdir ( value ) :
",34.84,5.82,False
"def toterminal ( self , tw ) : <TAB> # the entries might have different styles <TAB> last_style = None <TAB> for i , entry in enumerate ( self . reprentries ) : <TAB> <TAB> if entry . style == "" long "" : <TAB> <TAB> <TAB> tw . line ( "" "" ) <TAB> <TAB> entry . toterminal ( tw ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> next_entry = self . reprentries [ i + 1 ] <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> entry . style == "" long "" <TAB> <TAB> <TAB> <TAB> or entry . style == "" short "" <TAB> <TAB> <TAB> <TAB> and next_entry . style == "" long "" <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> tw . sep ( self . entrysep ) <TAB> if self . extraline : <TAB> <TAB> tw . line ( self . extraline ) ","if i < len ( self . reprentries ) - 1 : 
","elif entry . style == "" short "" :
",29.55,4.09,False
"def __init__ ( self , loc , tabs = None ) : <TAB> if os . path . isdir ( loc ) : <TAB> <TAB> for item in os . listdir ( loc ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> path = os . path . join ( loc , item ) <TAB> <TAB> <TAB> self . append ( CronTab ( user = False , tabfile = path ) ) <TAB> elif os . path . isfile ( loc ) : <TAB> <TAB> self . append ( CronTab ( user = False , tabfile = loc ) ) ","if item [ 0 ] == "" . "" : 
","if item . startswith ( "" . "" ) or item . startswith ( "" . "" ) :
",35.25,9.92,False
"def import_data ( self , fname ) : <TAB> """"""Import data in current namespace"""""" <TAB> if self . count ( ) : <TAB> <TAB> nsb = self . currentWidget ( ) <TAB> <TAB> nsb . refresh_table ( ) <TAB> <TAB> nsb . import_data ( fname ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . dockwidget . setVisible ( True ) <TAB> <TAB> <TAB> self . dockwidget . raise_ ( ) ","if self . dockwidget and not self . ismaximized : 
","if self . dockwidget :
",46.44,26.01,False
"def get_menu_items ( node ) : <TAB> aList = [ ] <TAB> for child in node . children : <TAB> <TAB> for tag in ( "" @menu "" , "" @item "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> name = child . h [ len ( tag ) + 1 : ] . strip ( ) <TAB> <TAB> <TAB> <TAB> if tag == "" @menu "" : <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( "" %s %s "" % ( tag , name ) , get_menu_items ( child ) , None ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> b = g . splitLines ( "" "" . join ( child . b ) ) <TAB> <TAB> <TAB> <TAB> <TAB> aList . append ( ( tag , name , b [ 0 ] if b else "" "" ) ) <TAB> <TAB> <TAB> <TAB> break <TAB> return aList ","if child . h . startswith ( tag ) : 
","if child . h . startswith ( tag ) :
",100.0,100.0,True
"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB> <TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB> <TAB> if hasattr ( args [ 0 ] , "" iteritems "" ) : <TAB> <TAB> <TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> items = list ( args [ 0 ] . items ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> items = list ( args [ 0 ] ) <TAB> <TAB> self . _items = items <TAB> else : <TAB> <TAB> self . _items = [ ] <TAB> if kw : <TAB> <TAB> self . _items . extend ( kw . items ( ) ) ","elif hasattr ( args [ 0 ] , "" items "" ) : 
","elif hasattr ( args [ 0 ] , "" items "" ) :
",100.0,100.0,True
"def open ( self ) - > "" KeyValueDb "" : <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os . path . exists ( self . _name ) : <TAB> <TAB> if not os . path . isfile ( self . _name ) : <TAB> <TAB> <TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # ignore empty files <TAB> <TAB> <TAB> return self <TAB> <TAB> with open ( self . _name , "" rb "" ) as _in :<TAB> # binary mode <TAB> <TAB> <TAB> self . set_records ( pickle . load ( _in ) ) <TAB> else : <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath ( os . path . dirname ( self . _name ) ) <TAB> <TAB> self . commit ( ) <TAB> return self ","if os . path . getsize ( self . _name ) == 0 : 
","if os . path . getsize ( self . _name ) == 0 :
",100.0,100.0,True
"def sortModules ( self ) : <TAB> super ( NeuronDecomposableNetwork , self ) . sortModules ( ) <TAB> self . _constructParameterInfo ( ) <TAB> # contains a list of lists of indices <TAB> self . decompositionIndices = { } <TAB> for neuron in self . _neuronIterator ( ) : <TAB> <TAB> self . decompositionIndices [ neuron ] = [ ] <TAB> for w in range ( self . paramdim ) : <TAB> <TAB> inneuron , outneuron = self . paramInfo [ w ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . decompositionIndices [ inneuron ] . append ( w ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . decompositionIndices [ outneuron ] . append ( w ) ","if self . espStyleDecomposition and outneuron [ 0 ] in self . outmodules : 
","if inneuron in self . decompositionIndices :
",36.04,10.22,False
"def visit_Options ( self , node : qlast . Options ) - > None : <TAB> for i , opt in enumerate ( node . options . values ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . write ( "" "" ) <TAB> <TAB> self . write ( opt . name ) <TAB> <TAB> if not isinstance ( opt , qlast . Flag ) : <TAB> <TAB> <TAB> self . write ( f "" { opt . val } "" ) ","if i > 0 : 
","if not isinstance ( opt , qlast . Name ) :
",27.38,4.46,False
"def is_child_of ( self , item_hash , possible_child_hash ) : <TAB> if self . get_last ( item_hash ) != self . get_last ( possible_child_hash ) : <TAB> <TAB> return None <TAB> while True : <TAB> <TAB> if possible_child_hash == item_hash : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> <TAB> possible_child_hash = self . items [ possible_child_hash ] . previous_hash ","if possible_child_hash not in self . items : 
","if possible_child_hash not in self . items :
",100.0,100.0,True
"def __call__ ( self , text , * * kargs ) : <TAB> words = jieba . tokenize ( text , mode = "" search "" ) <TAB> token = Token ( ) <TAB> for ( w , start_pos , stop_pos ) in words : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> token . original = token . text = w <TAB> <TAB> token . pos = start_pos <TAB> <TAB> token . startchar = start_pos <TAB> <TAB> token . endchar = stop_pos <TAB> <TAB> yield token ","if not accepted_chars . match ( w ) and len ( w ) < = 1 : 
","if w == self . _val_sp and w == self . _val_tab :
",28.19,3.05,False
"def test_analysis_jobs_cypher_syntax ( neo4j_session ) : <TAB> parameters = { <TAB> <TAB> "" AWS_ID "" : None , <TAB> <TAB> "" UPDATE_TAG "" : None , <TAB> <TAB> "" OKTA_ORG_ID "" : None , <TAB> } <TAB> for job_name in contents ( "" cartography.data.jobs.analysis "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> cartography . util . run_analysis_job ( job_name , neo4j_session , parameters ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> pytest . fail ( <TAB> <TAB> <TAB> <TAB> f "" run_analysis_job failed for analysis job  ' { job_name } '  with exception:  { e } "" <TAB> <TAB> <TAB> ) ","if not job_name . endswith ( "" .json "" ) : 
","if not job_name . endswith ( "" .json "" ) :
",100.0,100.0,True
"def _interleave_dataset_results_and_tensors ( dataset_results , flat_run_tensors ) : <TAB> flattened_results = [ ] <TAB> for idx in range ( len ( dataset_results ) + len ( flat_run_tensors ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> flattened_results . append ( dataset_results [ idx ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> flattened_results . append ( flat_run_tensors . pop ( 0 ) ) <TAB> return flattened_results ","if dataset_results . get ( idx ) : 
","if len ( flat_run_tensors ) == 1 :
",32.04,4.62,False
"def test_k_is_stochastic_parameter ( self ) : <TAB> # k as stochastic parameter <TAB> aug = iaa . MedianBlur ( k = iap . Choice ( [ 3 , 5 ] ) ) <TAB> seen = [ False , False ] <TAB> for i in sm . xrange ( 100 ) : <TAB> <TAB> observed = aug . augment_image ( self . base_img ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> seen [ 0 ] + = True <TAB> <TAB> elif np . array_equal ( observed , self . blur5x5 ) : <TAB> <TAB> <TAB> seen [ 1 ] + = True <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Unexpected result in MedianBlur@2 "" ) <TAB> <TAB> if all ( seen ) : <TAB> <TAB> <TAB> break <TAB> assert np . all ( seen ) ","if np . array_equal ( observed , self . blur3x3 ) : 
","if np . array_equal ( observed , self . blur3x3 ) :
",100.0,100.0,True
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> if minDist == None or guideDist < minDist : <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide ) ","if minGuide == None : 
","if minGuide == None :
",100.0,100.0,True
"def UpdateRepository ( self ) : <TAB> if hasattr ( self , "" commit_update "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not path . isdir ( "" .git/ "" ) : <TAB> <TAB> <TAB> <TAB> self . gitZipRepo ( ) <TAB> <TAB> <TAB> call ( [ "" git "" , "" reset "" , "" --hard "" , "" origin/ {} "" . format ( self . getBranch ) ] ) <TAB> <TAB> <TAB> self . ProcessCall_ ( [ "" git "" , "" pull "" , "" origin "" , self . getBranch ] ) <TAB> <TAB> <TAB> self . ProcessCall_ ( [ "" pip "" , "" install "" , "" -r "" , "" requirements.txt "" ] ) ","if self . commit_update [ "" Updates "" ] != [ ] : 
","if self . getBranch in self . repository_names :
",32.91,10.06,False
"def callback ( result = Cr . NS_OK , message = None , success = None ) : <TAB> if success is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> success = Ci . koIAsyncCallback . RESULT_SUCCESSFUL <TAB> <TAB> else : <TAB> <TAB> <TAB> success = Ci . koIAsyncCallback . RESULT_ERROR <TAB> data = Namespace ( result = result , message = message , _com_interfaces_ = [ Ci . koIErrorInfo ] ) <TAB> self . _invoke_activate_callbacks ( success , data ) ","if Cr . NS_SUCCEEDED ( result ) : 
","if result == Cr . NS_SUCCESS :
",33.84,30.21,False
"def get_location ( device ) : <TAB> location = [ ] <TAB> node = device <TAB> while node : <TAB> <TAB> position = node . get_position ( ) or "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> position = ""  [ %s ] "" % position <TAB> <TAB> location . append ( node . name + position ) <TAB> <TAB> node = node . parent <TAB> return ""  /  "" . join ( reversed ( location ) ) ","if position : 
","if node . name and position not in [ "" / "" , "" / "" ] :
",29.09,2.83,False
"def load_checkpoint ( path , model , optimizer , reset_optimizer ) : <TAB> global global_step <TAB> global global_epoch <TAB> print ( "" Load checkpoint from:  {} "" . format ( path ) ) <TAB> checkpoint = _load ( path ) <TAB> model . load_state_dict ( checkpoint [ "" state_dict "" ] ) <TAB> if not reset_optimizer : <TAB> <TAB> optimizer_state = checkpoint [ "" optimizer "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Load optimizer state from  {} "" . format ( path ) ) <TAB> <TAB> <TAB> optimizer . load_state_dict ( checkpoint [ "" optimizer "" ] ) <TAB> global_step = checkpoint [ "" global_step "" ] <TAB> global_epoch = checkpoint [ "" global_epoch "" ] <TAB> return model ","if optimizer_state is not None : 
","if optimizer_state is not None :
",100.0,100.0,True
"def run_command ( self , command : str , data : Dict [ str , object ] ) - > Dict [ str , object ] : <TAB> """"""Run a specific command from the registry."""""" <TAB> key = "" cmd_ "" + command <TAB> method = getattr ( self . __class__ , key , None ) <TAB> if method is None : <TAB> <TAB> return { "" error "" : "" Unrecognized command  ' %s ' "" % command } <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Only the above commands use some error formatting. <TAB> <TAB> <TAB> del data [ "" is_tty "" ] <TAB> <TAB> <TAB> del data [ "" terminal_width "" ] <TAB> <TAB> return method ( self , * * data ) ","if command not in { "" check "" , "" recheck "" , "" run "" } : 
","if "" error "" in data :
",35.08,2.04,False
"def call_init ( self , node , instance ) : <TAB> # Call __init__ on each binding. <TAB> for b in instance . bindings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . _initialized_instances . add ( b . data ) <TAB> <TAB> node = self . _call_init_on_binding ( node , b ) <TAB> return node ","if b . data in self . _initialized_instances : 
","if b . data in self . _initialized_instances :
",100.0,100.0,True
"def get_request_headers ( ) - > Dict : <TAB> url = urlparse ( uri ) <TAB> candidates = [ <TAB> <TAB> "" %s :// %s "" % ( url . scheme , url . netloc ) , <TAB> <TAB> "" %s :// %s / "" % ( url . scheme , url . netloc ) , <TAB> <TAB> uri , <TAB> <TAB> "" * "" , <TAB> ] <TAB> for u in candidates : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> headers = dict ( DEFAULT_REQUEST_HEADERS ) <TAB> <TAB> <TAB> headers . update ( self . config . linkcheck_request_headers [ u ] ) <TAB> <TAB> <TAB> return headers <TAB> return { } ","if u in self . config . linkcheck_request_headers : 
","if u in self . config . linkcheck_request_headers :
",100.0,100.0,True
"def get_next_video_frame ( self , skip_empty_frame = True ) : <TAB> if not self . video_format : <TAB> <TAB> return <TAB> while True : <TAB> <TAB> # We skip video packets which are not video frames <TAB> <TAB> # This happens in mkv files for the first few frames. <TAB> <TAB> video_packet = self . _get_video_packet ( ) <TAB> <TAB> if video_packet . image == 0 : <TAB> <TAB> <TAB> self . _decode_video_packet ( video_packet ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> if _debug : <TAB> <TAB> print ( "" Returning "" , video_packet ) <TAB> return video_packet . image ","if video_packet . image is not None or not skip_empty_frame : 
","if skip_empty_frame :
",26.48,20.15,False
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> if code == Path . MOVETO : <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( ) ","elif code == Path . CURVE3 : 
","elif code == Path . CURVE3 :
",100.0,100.0,True
"def __init__ ( <TAB> self , layout , value = None , string = None , * , dtype : np . dtype = np . float64 ) - > None : <TAB> """"""Constructor."""""" <TAB> self . layout = layout <TAB> if value is None : <TAB> <TAB> if string is None : <TAB> <TAB> <TAB> self . value = np . zeros ( ( self . layout . gaDims , ) , dtype = dtype ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . value = layout . parse_multivector ( string ) . value <TAB> else : <TAB> <TAB> self . value = np . array ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" value must be a sequence of length  %s "" % self . layout . gaDims <TAB> <TAB> <TAB> ) ","if self . value . shape != ( self . layout . gaDims , ) : 
","if len ( self . value . shape ) != self . layout . gaDims :
",64.66,52.92,False
"def to_dict ( self ) : <TAB> contexts_ = { } <TAB> for k , data in self . contexts . items ( ) : <TAB> <TAB> data_ = data . copy ( ) <TAB> <TAB> if "" context "" in data_ : <TAB> <TAB> <TAB> del data_ [ "" context "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del data_ [ "" loaded "" ] <TAB> <TAB> contexts_ [ k ] = data_ <TAB> return dict ( contexts = contexts_ ) ","if "" loaded "" in data_ : 
","if "" loaded "" in data_ :
",100.0,100.0,True
"def include_module ( module ) : <TAB> if not include_these : <TAB> <TAB> return True <TAB> result = False <TAB> for check in include_these : <TAB> <TAB> if "" /* "" in check : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result = True <TAB> <TAB> else : <TAB> <TAB> <TAB> if ( os . getcwd ( ) + "" / "" + check + "" .py "" ) == module : <TAB> <TAB> <TAB> <TAB> result = True <TAB> if result : <TAB> <TAB> print_status ( "" Including module:  "" + module ) <TAB> return result ","if check [ : - 1 ] in module : 
","if ( os . getcwd ( ) + "" / "" + check + "" .py "" ) == module :
",26.94,3.92,False
"def extract_from ( msg_body , content_type = "" text/plain "" ) : <TAB> try : <TAB> <TAB> if content_type == "" text/plain "" : <TAB> <TAB> <TAB> return extract_from_plain ( msg_body ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return extract_from_html ( msg_body ) <TAB> except Exception : <TAB> <TAB> log . exception ( "" ERROR extracting message "" ) <TAB> return msg_body ","elif content_type == "" text/html "" : 
","elif content_type == "" text/html "" :
",100.0,100.0,True
"def test_list ( self ) : <TAB> self . _create_locations ( ) <TAB> response = self . client . get ( self . geojson_boxedlocation_list_url ) <TAB> self . assertEqual ( response . status_code , 200 ) <TAB> self . assertEqual ( len ( response . data [ "" features "" ] ) , 2 ) <TAB> for feature in response . data [ "" features "" ] : <TAB> <TAB> self . assertIn ( "" bbox "" , feature ) <TAB> <TAB> fid = feature [ "" id "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl1 . bbox_geometry . extent ) <TAB> <TAB> elif fid == 2 : <TAB> <TAB> <TAB> self . assertEqual ( feature [ "" bbox "" ] , self . bl2 . bbox_geometry . extent ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . fail ( "" Unexpected id:  {0} "" . format ( fid ) ) <TAB> BoxedLocation . objects . all ( ) . delete ( ) ","if fid == 1 : 
","if fid == 1 :
",100.0,100.0,True
"def overrideCommand ( self , commandName , func ) : <TAB> # Override entries in c.k.masterBindingsDict <TAB> k = self <TAB> d = k . masterBindingsDict <TAB> for key in d : <TAB> <TAB> d2 = d . get ( key ) <TAB> <TAB> for key2 in d2 : <TAB> <TAB> <TAB> bi = d2 . get ( key2 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> bi . func = func <TAB> <TAB> <TAB> <TAB> d2 [ key2 ] = bi ","if bi . commandName == commandName : 
","if bi is not None :
",29.16,12.87,False
"def _lookup ( components , specs , provided , name , i , l ) : <TAB> if i < l : <TAB> <TAB> for spec in specs [ i ] . __sro__ : <TAB> <TAB> <TAB> comps = components . get ( spec ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> r = _lookup ( comps , specs , provided , name , i + 1 , l ) <TAB> <TAB> <TAB> <TAB> if r is not None : <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> else : <TAB> <TAB> for iface in provided : <TAB> <TAB> <TAB> comps = components . get ( iface ) <TAB> <TAB> <TAB> if comps : <TAB> <TAB> <TAB> <TAB> r = comps . get ( name ) <TAB> <TAB> <TAB> <TAB> if r is not None : <TAB> <TAB> <TAB> <TAB> <TAB> return r <TAB> return None ","if comps : 
","if comps :
",78.12,0.0,False
"def to_representation ( self , value ) : <TAB> old_social_string_fields = [ "" twitter "" , "" github "" , "" linkedIn "" ] <TAB> request = self . context . get ( "" request "" ) <TAB> show_old_format = ( <TAB> <TAB> request <TAB> <TAB> and is_deprecated ( request . version , self . min_version ) <TAB> <TAB> and request . method == "" GET "" <TAB> ) <TAB> if show_old_format : <TAB> <TAB> social = value . copy ( ) <TAB> <TAB> for key in old_social_string_fields : <TAB> <TAB> <TAB> if social . get ( key ) : <TAB> <TAB> <TAB> <TAB> social [ key ] = value [ key ] [ 0 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> social [ key ] = "" "" <TAB> <TAB> value = social <TAB> return super ( SocialField , self ) . to_representation ( value ) ","elif social . get ( key ) == [ ] : 
","elif not social [ key ] :
",27.68,8.46,False
"def process_ref_attribute ( self , node , array_type = None ) : <TAB> ref = qname_attr ( node , "" ref "" ) <TAB> if ref : <TAB> <TAB> ref = self . _create_qname ( ref ) <TAB> <TAB> # Some wsdl's reference to xs:schema, we ignore that for now. It <TAB> <TAB> # might be better in the future to process the actual schema file <TAB> <TAB> # so that it is handled correctly <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> return xsd_elements . RefAttribute ( <TAB> <TAB> <TAB> node . tag , ref , self . schema , array_type = array_type <TAB> <TAB> ) ","if ref . namespace == "" http://www.w3.org/2001/XMLSchema "" : 
","if ref == self . schema :
",33.33,3.0,False
"def unescape ( text ) : <TAB> """"""Removes '\\' escaping from 'text'."""""" <TAB> rv = "" "" <TAB> i = 0 <TAB> while i < len ( text ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> rv + = text [ i + 1 ] <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> rv + = text [ i ] <TAB> <TAB> i + = 1 <TAB> return rv ","if i + 1 < len ( text ) and text [ i ] == "" \\ "" : 
","if text [ i ] == "" \\ "" :
",54.13,43.62,False
"def wait_child_process ( signum , frame ) : <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> child_pid , status = os . waitpid ( - 1 , os . WNOHANG ) <TAB> <TAB> <TAB> if child_pid == 0 : <TAB> <TAB> <TAB> <TAB> stat_logger . info ( "" no child process was immediately available "" ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> exitcode = status >> 8 <TAB> <TAB> <TAB> stat_logger . info ( <TAB> <TAB> <TAB> <TAB> "" child process  %s  exit with exitcode  %s "" , child_pid , exitcode <TAB> <TAB> <TAB> ) <TAB> except OSError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stat_logger . warning ( <TAB> <TAB> <TAB> <TAB> "" current process has no existing unwaited-for child processes. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if e . errno == errno . ECHILD : 
","if e . errno == errno . ESRCH :
",87.71,78.25,False
"def translate_from_sortname ( name , sortname ) : <TAB> """"""'Translate' the artist name by reversing the sortname."""""" <TAB> for c in name : <TAB> <TAB> ctg = unicodedata . category ( c ) <TAB> <TAB> if ctg [ 0 ] == "" L "" and unicodedata . name ( c ) . find ( "" LATIN "" ) == - 1 : <TAB> <TAB> <TAB> for separator in ( ""  &  "" , "" ;  "" , ""  and  "" , ""  vs.  "" , ""  with  "" , ""  y  "" ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> parts = sortname . split ( separator ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> parts = [ sortname ] <TAB> <TAB> <TAB> <TAB> separator = "" "" <TAB> <TAB> <TAB> return separator . join ( map ( _reverse_sortname , parts ) ) <TAB> return name ","if separator in sortname : 
","if sortname . startswith ( separator ) :
",27.76,7.81,False
"def python_value ( self , value ) : <TAB> if value : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pp = lambda x : x . time ( ) <TAB> <TAB> <TAB> return format_date_time ( value , self . formats , pp ) <TAB> <TAB> elif isinstance ( value , datetime . datetime ) : <TAB> <TAB> <TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB> <TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value ","if isinstance ( value , basestring ) : 
","if isinstance ( value , datetime . date ) :
",51.33,45.18,False
"def __init__ ( self , fileobj , info ) : <TAB> pages = [ ] <TAB> complete = False <TAB> while not complete : <TAB> <TAB> page = OggPage ( fileobj ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pages . append ( page ) <TAB> <TAB> <TAB> complete = page . complete or ( len ( page . packets ) > 1 ) <TAB> data = OggPage . to_packets ( pages ) [ 0 ] [ 7 : ] <TAB> super ( OggTheoraCommentDict , self ) . __init__ ( data , framing = False ) <TAB> self . _padding = len ( data ) - self . _size ","if page . serial == info . serial : 
","if page . info == info :
",43.09,27.98,False
"def configure ( self ) : <TAB> # hack to configure 'from_' and 'to' and avoid exception <TAB> if "" from_ "" in self . wmeta . properties : <TAB> <TAB> from_ = float ( self . wmeta . properties [ "" from_ "" ] ) <TAB> <TAB> to = float ( self . wmeta . properties . get ( "" to "" , 0 ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> to = from_ + 1 <TAB> <TAB> <TAB> self . wmeta . properties [ "" to "" ] = str ( to ) <TAB> super ( TKSpinbox , self ) . configure ( ) ","if from_ > to : 
","if from_ < = to :
",32.18,30.74,False
"def get_error_diagnostics ( self ) : <TAB> diagnostics = [ ] <TAB> if self . stdout is not None : <TAB> <TAB> with open ( self . stdout . name ) as fds : <TAB> <TAB> <TAB> contents = fds . read ( ) . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> diagnostics . append ( "" ab STDOUT: \n "" + contents ) <TAB> if self . stderr is not None : <TAB> <TAB> with open ( self . stderr . name ) as fds : <TAB> <TAB> <TAB> contents = fds . read ( ) . strip ( ) <TAB> <TAB> <TAB> if contents . strip ( ) : <TAB> <TAB> <TAB> <TAB> diagnostics . append ( "" ab STDERR: \n "" + contents ) <TAB> return diagnostics ","if contents . strip ( ) : 
","if contents . strip ( ) :
",100.0,100.0,True
"def set_environment_vars ( env , source_env ) : <TAB> """"""Copy allowed environment variables from |source_env|."""""" <TAB> if not source_env : <TAB> <TAB> return <TAB> for name , value in six . iteritems ( source_env ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Avoid creating circular dependencies from importing environment by <TAB> <TAB> <TAB> # using os.getenv. <TAB> <TAB> <TAB> if os . getenv ( "" TRUSTED_HOST "" ) and should_rebase_environment_value ( name ) : <TAB> <TAB> <TAB> <TAB> value = file_host . rebase_to_worker_root ( value ) <TAB> <TAB> <TAB> env [ name ] = value ","if is_forwarded_environment_variable ( name ) : 
","if not is_local_environment ( name ) :
",62.06,29.81,False
"def update_content ( self , more_content : StringList ) - > None : <TAB> if isinstance ( self . object , TypeVar ) : <TAB> <TAB> attrs = [ repr ( self . object . __name__ ) ] <TAB> <TAB> for constraint in self . object . __constraints__ : <TAB> <TAB> <TAB> attrs . append ( stringify_typehint ( constraint ) ) <TAB> <TAB> if self . object . __covariant__ : <TAB> <TAB> <TAB> attrs . append ( "" covariant=True "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> attrs . append ( "" contravariant=True "" ) <TAB> <TAB> more_content . append ( _ ( "" alias of TypeVar( %s ) "" ) % "" ,  "" . join ( attrs ) , "" "" ) <TAB> <TAB> more_content . append ( "" "" , "" "" ) <TAB> super ( ) . update_content ( more_content ) ","if self . object . __contravariant__ : 
","if self . object . __conavariant__ :
",82.41,70.17,False
"def after ( self , event , state ) : <TAB> group = event . group <TAB> for plugin in self . get_plugins ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> metrics . incr ( "" notifications.sent "" , instance = plugin . slug ) <TAB> <TAB> yield self . future ( plugin . rule_notify ) ","if not safe_execute ( plugin . should_notify , group = group , event = event ) : 
","if not plugin . rule_notify or group . slug != plugin . rule_notify . slug :
",30.15,7.15,False
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> if not isinstance ( n , _strtypes ) : <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> elif n not in fields : <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) ) ","if n . _child . isidentical ( expr ) : 
","if n . _name :
",34.86,23.35,False
"def build_filter ( arg ) : <TAB> filt = { } <TAB> if arg is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise UserError ( "" Arguments to --filter should be in form KEY=VAL "" ) <TAB> <TAB> key , val = arg . split ( "" = "" , 1 ) <TAB> <TAB> filt [ key ] = val <TAB> return filt ","if "" = "" not in arg : 
","if "" = "" not in arg :
",100.0,100.0,True
"def pickline ( file , key , casefold = 1 ) : <TAB> try : <TAB> <TAB> f = open ( file , "" r "" ) <TAB> except IOError : <TAB> <TAB> return None <TAB> pat = re . escape ( key ) + "" : "" <TAB> prog = re . compile ( pat , casefold and re . IGNORECASE ) <TAB> while 1 : <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> if not line : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = line [ len ( key ) + 1 : ] <TAB> <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> <TAB> line = f . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line or not line [ 0 ] . isspace ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> text = text + line <TAB> <TAB> <TAB> return text . strip ( ) <TAB> return None ","if prog . match ( line ) : 
","if prog . search ( line ) :
",74.27,50.0,False
"def delete_doc ( elastic_document_id , node , index = None , category = None ) : <TAB> index = index or INDEX <TAB> if not category : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> category = "" preprint "" <TAB> <TAB> elif node . is_registration : <TAB> <TAB> <TAB> category = "" registration "" <TAB> <TAB> else : <TAB> <TAB> <TAB> category = node . project_or_component <TAB> client ( ) . delete ( <TAB> <TAB> index = index , <TAB> <TAB> doc_type = category , <TAB> <TAB> id = elastic_document_id , <TAB> <TAB> refresh = True , <TAB> <TAB> ignore = [ 404 ] , <TAB> ) ","if isinstance ( node , Preprint ) : 
","if node . is_preprint :
",26.99,7.49,False
"def update ( self , preds , labels ) : <TAB> if not _is_numpy_ ( labels ) : <TAB> <TAB> raise ValueError ( "" The  ' labels '  must be a numpy ndarray. "" ) <TAB> if not _is_numpy_ ( preds ) : <TAB> <TAB> raise ValueError ( "" The  ' predictions '  must be a numpy ndarray. "" ) <TAB> for i , lbl in enumerate ( labels ) : <TAB> <TAB> value = preds [ i , 1 ] <TAB> <TAB> bin_idx = int ( value * self . _num_thresholds ) <TAB> <TAB> assert bin_idx < = self . _num_thresholds <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _stat_pos [ bin_idx ] + = 1.0 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _stat_neg [ bin_idx ] + = 1.0 ","if lbl : 
","if lbl :
",78.12,0.0,False
"def checkStatusClient ( self ) : <TAB> if str ( self . comboxBoxIPAddress . currentText ( ) ) != "" "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . btnEnable . setEnabled ( False ) <TAB> <TAB> <TAB> self . btncancel . setEnabled ( True ) <TAB> <TAB> <TAB> return None <TAB> <TAB> self . btnEnable . setEnabled ( True ) <TAB> <TAB> self . btncancel . setEnabled ( False ) ","if self . ClientsLogged [ str ( self . comboxBoxIPAddress . currentText ( ) ) ] [ "" Status "" ] : 
","if self . comboxBoxIPAddress . currentText ( ) == "" "" :
",52.62,28.67,False
"def colorizeDiffs ( sheet , col , row , cellval ) : <TAB> if not row or not col : <TAB> <TAB> return None <TAB> vcolidx = sheet . visibleCols . index ( col ) <TAB> rowidx = sheet . rows . index ( row ) <TAB> if vcolidx < len ( othersheet . visibleCols ) and rowidx < len ( othersheet . rows ) : <TAB> <TAB> otherval = othersheet . visibleCols [ vcolidx ] . getDisplayValue ( <TAB> <TAB> <TAB> othersheet . rows [ rowidx ] <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" color_diff "" <TAB> else : <TAB> <TAB> return "" color_diff_add "" ","if cellval . display != otherval : 
","if cellval == otherval :
",30.32,27.22,False
"def identwaf ( self , findall = False ) : <TAB> detected = list ( ) <TAB> try : <TAB> <TAB> self . attackres = self . performCheck ( self . centralAttack ) <TAB> except RequestBlocked : <TAB> <TAB> return detected <TAB> for wafvendor in self . checklist : <TAB> <TAB> self . log . info ( "" Checking for  %s "" % wafvendor ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> detected . append ( wafvendor ) <TAB> <TAB> <TAB> if not findall : <TAB> <TAB> <TAB> <TAB> break <TAB> self . knowledge [ "" wafname "" ] = detected <TAB> return detected ","if self . wafdetections [ wafvendor ] ( self ) : 
","if wafvendor in self . knowledge :
",31.75,9.33,False
"def get_repository_metadata_by_repository_id_changeset_revision ( <TAB> app , id , changeset_revision , metadata_only = False ) : <TAB> """"""Get a specified metadata record for a specified repository in the tool shed."""""" <TAB> if metadata_only : <TAB> <TAB> repository_metadata = get_repository_metadata_by_changeset_revision ( <TAB> <TAB> <TAB> app , id , changeset_revision <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return repository_metadata . metadata <TAB> <TAB> return None <TAB> return get_repository_metadata_by_changeset_revision ( app , id , changeset_revision ) ","if repository_metadata and repository_metadata . metadata : 
","if repository_metadata :
",28.73,22.89,False
"def getmultiline ( self ) : <TAB> line = self . getline ( ) <TAB> if line [ 3 : 4 ] == "" - "" : <TAB> <TAB> code = line [ : 3 ] <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> nextline = self . getline ( ) <TAB> <TAB> <TAB> line = line + ( "" \n "" + nextline ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> return line ","if nextline [ : 3 ] == code and nextline [ 3 : 4 ] != "" - "" : 
","if code == nextline :
",25.48,1.48,False
"def _validate_reports ( value , * args , * * kwargs ) : <TAB> from osf . models import OSFUser <TAB> for key , val in value . items ( ) : <TAB> <TAB> if not OSFUser . load ( key ) : <TAB> <TAB> <TAB> raise ValidationValueError ( "" Keys must be user IDs "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationTypeError ( "" Values must be dictionaries "" ) <TAB> <TAB> if ( <TAB> <TAB> <TAB> "" category "" not in val <TAB> <TAB> <TAB> or "" text "" not in val <TAB> <TAB> <TAB> or "" date "" not in val <TAB> <TAB> <TAB> or "" retracted "" not in val <TAB> <TAB> ) : <TAB> <TAB> <TAB> raise ValidationValueError ( <TAB> <TAB> <TAB> <TAB> ( "" Values must include `date`, `category`,  "" , "" `text`, `retracted` keys "" ) <TAB> <TAB> <TAB> ) ","if not isinstance ( val , dict ) : 
","if not isinstance ( val , dict ) :
",100.0,100.0,True
"def deselectItem ( self , item ) : <TAB> if self . isSelected ( item ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> listItem = self . _getListItem ( item ) <TAB> <TAB> <TAB> selections = self . getSelectedItems ( ) <TAB> <TAB> <TAB> selections . remove ( self . loadHandler . getSelection ( listItem ) ) <TAB> <TAB> <TAB> self . setSelections ( selections ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . deselectAll ( ) ","if self . multiSelect : 
","if self . loadHandler . hasSelection ( item ) :
",43.47,16.78,False
"def __init__ ( self , * * kwargs ) : <TAB> if self . name is None : <TAB> <TAB> raise RuntimeError ( "" RenderPrimitive cannot be used directly "" ) <TAB> self . option_values = { } <TAB> for key , val in kwargs . items ( ) : <TAB> <TAB> if not key in self . options : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" primitive ` {0} '  has no option ` {1} ' "" . format ( self . name , key ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . option_values [ key ] = val <TAB> # set up defaults <TAB> for name , ( description , default ) in self . options . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . option_values [ name ] = default ","if not name in self . option_values : 
","if description == "" default "" :
",26.72,5.11,False
"def setup_smart_indent ( self , view , lang ) : <TAB> # Configure a ""per-view"" instance <TAB> if type ( view ) == gedit . View : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( view , "" smart_indent_instance "" , SmartIndent ( ) ) <TAB> <TAB> <TAB> handler_id = view . connect ( <TAB> <TAB> <TAB> <TAB> "" key-press-event "" , view . smart_indent_instance . key_press_handler <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . handler_ids . append ( ( handler_id , view ) ) <TAB> <TAB> view . smart_indent_instance . set_language ( lang , view ) ","if getattr ( view , "" smart_indent_instance "" , False ) == False : 
","if getattr ( view , "" smart_indent_instance "" , None ) is None :
",59.32,68.16,False
"def get_strings_of_set ( word , char_set , threshold = 20 ) : <TAB> count = 0 <TAB> letters = "" "" <TAB> strings = [ ] <TAB> for char in word : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> letters + = char <TAB> <TAB> <TAB> count + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> if count > threshold : <TAB> <TAB> <TAB> <TAB> strings . append ( letters ) <TAB> <TAB> <TAB> letters = "" "" <TAB> <TAB> <TAB> count = 0 <TAB> if count > threshold : <TAB> <TAB> strings . append ( letters ) <TAB> return strings ","if char in char_set : 
","if char in char_set :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_logout_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
def __create_table ( self ) : <TAB> for i in range ( 256 ) : <TAB> <TAB> crcreg = i <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> crcreg = self . __CRCPOLYNOMIAL ^ ( crcreg >> 1 ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> crcreg >> = 1 <TAB> <TAB> self . __crctable [ i ] = crcreg ,"if ( crcreg & 1 ) != 0 : 
","if j == 0 :
",27.99,16.67,False
"def destroy ( self ) : <TAB> """"""Flush all entries and empty cache"""""" <TAB> # Note: this method is currently also used for dropping the cache <TAB> for i in range ( len ( self . cached_rows ) ) : <TAB> <TAB> id_ = self . cached_rows [ i ] <TAB> <TAB> self . cached_rows [ i ] = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> inode = self . attrs [ id_ ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> # We may have deleted that inode <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> del self . attrs [ id_ ] <TAB> <TAB> <TAB> <TAB> self . setattr ( inode ) <TAB> assert len ( self . attrs ) == 0 ","if id_ is not None : 
","if id_ :
",29.58,30.18,False
"def set_config ( self ) : <TAB> """"""Set configuration options for QTextEdit."""""" <TAB> c = self . c <TAB> w = self . widget <TAB> w . setWordWrapMode ( QtGui . QTextOption . NoWrap ) <TAB> if 0 :<TAB> # This only works when there is no style sheet. <TAB> <TAB> n = c . config . getInt ( "" qt-rich-text-zoom-in "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> w . zoomIn ( n ) <TAB> <TAB> <TAB> w . updateMicroFocus ( ) <TAB> # tab stop in pixels - no config for this (yet) <TAB> w . setTabStopWidth ( 24 ) ","if n not in ( None , 0 ) : 
","if n > = 0 :
",27.56,9.91,False
"def mouseDragEvent ( self , ev ) : <TAB> if self . movable and ev . button ( ) == QtCore . Qt . LeftButton : <TAB> <TAB> if ev . isStart ( ) : <TAB> <TAB> <TAB> self . moving = True <TAB> <TAB> <TAB> self . cursorOffset = self . pos ( ) - self . mapToParent ( ev . buttonDownPos ( ) ) <TAB> <TAB> <TAB> self . startPosition = self . pos ( ) <TAB> <TAB> ev . accept ( ) <TAB> <TAB> if not self . moving : <TAB> <TAB> <TAB> return <TAB> <TAB> self . setPos ( self . cursorOffset + self . mapToParent ( ev . pos ( ) ) ) <TAB> <TAB> self . sigDragged . emit ( self ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . moving = False <TAB> <TAB> <TAB> self . sigPositionChangeFinished . emit ( self ) ","if ev . isFinish ( ) : 
","if ev . isFinish ( ) :
",100.0,100.0,True
"def reparentChildren ( self , newParent ) : <TAB> if newParent . childNodes : <TAB> <TAB> newParent . childNodes [ - 1 ] . _element . tail + = self . _element . text <TAB> else : <TAB> <TAB> if not newParent . _element . text : <TAB> <TAB> <TAB> newParent . _element . text = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newParent . _element . text + = self . _element . text <TAB> self . _element . text = "" "" <TAB> base . Node . reparentChildren ( self , newParent ) ","if self . _element . text is not None : 
","if self . _element . text :
",58.87,59.76,False
"def _no_sp_or_bp ( self , bl ) : <TAB> for s in bl . vex . statements : <TAB> <TAB> for e in chain ( [ s ] , s . expressions ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB> <TAB> <TAB> <TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> elif e . tag == "" Ist_Put "" : <TAB> <TAB> <TAB> <TAB> reg = self . get_reg_name ( self . project . arch , e . offset ) <TAB> <TAB> <TAB> <TAB> if reg == "" ebp "" or reg == "" esp "" : <TAB> <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if e . tag == "" Iex_Get "" : 
","if e . tag == "" Ist_Get "" :
",83.19,73.49,False
"def _get_import_chain ( self , * , until = None ) : <TAB> stack = inspect . stack ( ) [ 2 : ] <TAB> try : <TAB> <TAB> for frameinfo in stack : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> data = dedent ( "" "" . join ( frameinfo . code_context ) ) <TAB> <TAB> <TAB> <TAB> if data . strip ( ) == until : <TAB> <TAB> <TAB> <TAB> <TAB> raise StopIteration <TAB> <TAB> <TAB> <TAB> yield frameinfo . filename , frameinfo . lineno , data . strip ( ) <TAB> <TAB> <TAB> <TAB> del data <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> del frameinfo <TAB> finally : <TAB> <TAB> del stack ","if not frameinfo . code_context : 
","if not frameinfo . code_context :
",100.0,100.0,True
"def stream_docker_log ( log_stream ) : <TAB> async for line in log_stream : <TAB> <TAB> if "" stream "" in line and line [ "" stream "" ] . strip ( ) : <TAB> <TAB> <TAB> logger . debug ( line [ "" stream "" ] . strip ( ) ) <TAB> <TAB> elif "" status "" in line : <TAB> <TAB> <TAB> logger . debug ( line [ "" status "" ] . strip ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . error ( line [ "" error "" ] . strip ( ) ) <TAB> <TAB> <TAB> raise DockerBuildError ","elif "" error "" in line : 
","elif "" error "" in line :
",100.0,100.0,True
"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> if dep == goal_node_index : <TAB> <TAB> <TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> path = self . get_cycle_path ( <TAB> <TAB> <TAB> self . get_by_address ( dep ) , goal_node_index <TAB> <TAB> )<TAB> # self.nodelist[dep], goal_node_index) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path . insert ( 0 , curr_node [ "" address "" ] ) <TAB> <TAB> <TAB> return path <TAB> return [ ] ","if len ( path ) > 0 : 
","if path :
",26.73,0.0,False
"def prompt ( default = None ) : <TAB> editor = "" nano "" <TAB> with tempfile . NamedTemporaryFile ( mode = "" r+ "" ) as tmpfile : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tmpfile . write ( default ) <TAB> <TAB> <TAB> tmpfile . flush ( ) <TAB> <TAB> child_pid = os . fork ( ) <TAB> <TAB> is_child = child_pid == 0 <TAB> <TAB> if is_child : <TAB> <TAB> <TAB> os . execvp ( editor , [ editor , tmpfile . name ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> os . waitpid ( child_pid , 0 ) <TAB> <TAB> <TAB> tmpfile . seek ( 0 ) <TAB> <TAB> <TAB> return tmpfile . read ( ) . strip ( ) ","if default : 
","if default is not None :
",34.04,17.97,False
"def _get_annotated_template ( self , template ) : <TAB> changed = False <TAB> if template . get ( "" version "" , "" 0.12.0 "" ) > = "" 0.13.0 "" : <TAB> <TAB> using_js = self . spider . _filter_js_urls ( template [ "" url "" ] ) <TAB> <TAB> body = "" rendered_body "" if using_js else "" original_body "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> template [ "" body "" ] = body <TAB> <TAB> <TAB> changed = True <TAB> if changed or not template . get ( "" annotated "" ) : <TAB> <TAB> _build_sample ( template ) <TAB> return template ","if template . get ( "" body "" ) != body : 
","if not self . spider . _apply_template_parameters ( template , body ) :
",29.92,3.49,False
"def collect ( self , paths ) : <TAB> for path in paths or ( ) : <TAB> <TAB> relpath = os . path . relpath ( path , self . _artifact_root ) <TAB> <TAB> dst = os . path . join ( self . _directory , relpath ) <TAB> <TAB> safe_mkdir ( os . path . dirname ( dst ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> shutil . copytree ( path , dst ) <TAB> <TAB> else : <TAB> <TAB> <TAB> shutil . copy ( path , dst ) <TAB> <TAB> self . _relpaths . add ( relpath ) ","if os . path . isdir ( path ) : 
","if os . path . isdir ( dst ) :
",85.49,70.71,False
"def dependencies ( context = None ) : <TAB> """"""Return all dependencies detected by knowit."""""" <TAB> deps = OrderedDict ( [ ] ) <TAB> try : <TAB> <TAB> initialize ( context ) <TAB> <TAB> for name , provider_cls in _provider_map . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> deps [ name ] = available_providers [ name ] . version <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> deps [ name ] = { } <TAB> except Exception : <TAB> <TAB> pass <TAB> return deps ","if name in available_providers : 
","if provider_cls is not None :
",27.87,7.27,False
"def _getaddrinfo ( self , host_bytes , port , family , socktype , proto , flags ) : <TAB> while True : <TAB> <TAB> ares = self . cares <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . __getaddrinfo ( host_bytes , port , family , socktype , proto , flags ) <TAB> <TAB> except gaierror : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ","if ares is self . cares : 
","if ares is self . cares :
",100.0,100.0,True
"def write_entries ( cmd , basename , filename ) : <TAB> ep = cmd . distribution . entry_points <TAB> if isinstance ( ep , basestring ) or ep is None : <TAB> <TAB> data = ep <TAB> elif ep is not None : <TAB> <TAB> data = [ ] <TAB> <TAB> for section , contents in ep . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> contents = EntryPoint . parse_group ( section , contents ) <TAB> <TAB> <TAB> <TAB> contents = "" \n "" . join ( map ( str , contents . values ( ) ) ) <TAB> <TAB> <TAB> data . append ( "" [ %s ] \n %s \n \n "" % ( section , contents ) ) <TAB> <TAB> data = "" "" . join ( data ) <TAB> cmd . write_or_delete_file ( "" entry points "" , filename , data , True ) ","if not isinstance ( contents , basestring ) : 
","if contents is not None :
",26.83,6.96,False
"def _highlight_do ( self ) : <TAB> new_hl_text = self . highlight_text . text ( ) <TAB> if new_hl_text != self . hl_text : <TAB> <TAB> self . hl_text = new_hl_text <TAB> <TAB> if self . hl is not None : <TAB> <TAB> <TAB> self . hl . setDocument ( None ) <TAB> <TAB> <TAB> self . hl = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . hl = Highlighter ( self . hl_text , parent = self . doc ) <TAB> <TAB> self . clear_highlight_button . setEnabled ( bool ( self . hl ) ) ","if self . hl_text : 
","if self . doc is not None :
",44.36,22.09,False
"def traverse ( node , functions = [ ] ) : <TAB> if hasattr ( node , "" grad_fn "" ) : <TAB> <TAB> node = node . grad_fn <TAB> if hasattr ( node , "" variable "" ) : <TAB> <TAB> node = graph . nodes_by_id . get ( id ( node . variable ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> node . functions = list ( functions ) <TAB> <TAB> <TAB> del functions [ : ] <TAB> if hasattr ( node , "" next_functions "" ) : <TAB> <TAB> functions . append ( type ( node ) . __name__ ) <TAB> <TAB> for f in node . next_functions : <TAB> <TAB> <TAB> if f [ 0 ] : <TAB> <TAB> <TAB> <TAB> functions . append ( type ( f [ 0 ] ) . __name__ ) <TAB> <TAB> <TAB> <TAB> traverse ( f [ 0 ] , functions ) <TAB> if hasattr ( node , "" saved_tensors "" ) : <TAB> <TAB> for t in node . saved_tensors : <TAB> <TAB> <TAB> traverse ( t ) ","if node : 
","if node :
",78.12,0.0,False
"def compress ( self , data_list ) : <TAB> if data_list : <TAB> <TAB> page_id = data_list [ 1 ] <TAB> <TAB> if page_id in EMPTY_VALUES : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB> <TAB> return Page . objects . get ( pk = page_id ) <TAB> return None ","if not self . required : 
","if self . error_messages [ "" invalid_page "" ] is None :
",34.79,5.82,False
"def test_field_attr_existence ( self ) : <TAB> for name , item in ast . __dict__ . items ( ) : <TAB> <TAB> if self . _is_ast_node ( name , item ) : <TAB> <TAB> <TAB> if name == "" Index "" : <TAB> <TAB> <TAB> <TAB> # Index(value) just returns value now. <TAB> <TAB> <TAB> <TAB> # The argument is required. <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> x = item ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertEqual ( type ( x . _fields ) , tuple ) ","if isinstance ( x , ast . AST ) : 
","if isinstance ( x , ast . Field ) :
",85.49,70.71,False
"def handle_starttag ( self , tag , attrs ) : <TAB> if tag == "" base "" : <TAB> <TAB> self . base_url = dict ( attrs ) . get ( "" href "" ) <TAB> if self . scan_tag ( tag ) : <TAB> <TAB> for attr , value in attrs : <TAB> <TAB> <TAB> if self . scan_attr ( attr ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> value = strip_html5_whitespace ( value ) <TAB> <TAB> <TAB> <TAB> url = self . process_attr ( value ) <TAB> <TAB> <TAB> <TAB> link = Link ( url = url ) <TAB> <TAB> <TAB> <TAB> self . links . append ( link ) <TAB> <TAB> <TAB> <TAB> self . current_link = link ","if self . strip : 
","if self . strip_html5_whitespace ( value ) :
",44.36,22.42,False
"def _initialize_asset_map ( cls ) : <TAB> # Generating a list of acceptable asset files reduces the possibility of <TAB> # path attacks. <TAB> cls . _asset_name_to_path = { } <TAB> assets = os . listdir ( ASSETS_PATH ) <TAB> for asset in assets : <TAB> <TAB> path = os . path . join ( ASSETS_PATH , asset ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cls . _asset_name_to_path [ os . path . basename ( path ) ] = path ","if os . path . isfile ( path ) : 
","if os . path . isfile ( path ) :
",100.0,100.0,True
"def dataReceived ( self , data ) : <TAB> self . buf + = data <TAB> if self . _paused : <TAB> <TAB> log . startLogging ( sys . stderr ) <TAB> <TAB> log . msg ( "" dataReceived while transport paused! "" ) <TAB> <TAB> self . transport . loseConnection ( ) <TAB> else : <TAB> <TAB> self . transport . write ( data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . transport . loseConnection ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . pause ( ) ","if self . buf . endswith ( b "" \n 0 \n "" ) : 
","if self . _isConnectionClosed ( ) :
",31.8,8.78,False
"def test_case_sensitive ( self ) : <TAB> with support . EnvironmentVarGuard ( ) as env : <TAB> <TAB> env . unset ( "" PYTHONCASEOK "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . skipTest ( "" os.environ changes not reflected in  "" "" _os.environ "" ) <TAB> <TAB> loader = self . find_module ( ) <TAB> <TAB> self . assertIsNone ( loader ) ","if b "" PYTHONCASEOK "" in _bootstrap_external . _os . environ : 
","if not env . get ( "" PYTHONCASEOK "" ) :
",37.18,10.53,False
"def manifest ( self ) : <TAB> """"""The current manifest dictionary."""""" <TAB> if self . reload : <TAB> <TAB> if not self . exists ( self . manifest_path ) : <TAB> <TAB> <TAB> return { } <TAB> <TAB> mtime = self . getmtime ( self . manifest_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _manifest = self . get_manifest ( ) <TAB> <TAB> <TAB> self . _mtime = mtime <TAB> return self . _manifest ","if self . _mtime is None or mtime > self . _mtime : 
","if mtime != self . _mtime :
",45.52,24.93,False
"def test_named_parameters_and_constraints ( self ) : <TAB> likelihood = gpytorch . likelihoods . GaussianLikelihood ( ) <TAB> model = ExactGPModel ( None , None , likelihood ) <TAB> for name , _param , constraint in model . named_parameters_and_constraints ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . GreaterThan ) <TAB> <TAB> elif name == "" mean_module.constant "" : <TAB> <TAB> <TAB> self . assertIsNone ( constraint ) <TAB> <TAB> elif name == "" covar_module.raw_outputscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) <TAB> <TAB> elif name == "" covar_module.base_kernel.raw_lengthscale "" : <TAB> <TAB> <TAB> self . assertIsInstance ( constraint , gpytorch . constraints . Positive ) ","if name == "" likelihood.noise_covar.raw_noise "" : 
","if name == "" mean_module.constant "" :
",74.63,27.82,False
"def process_plugin_result ( name , result ) : <TAB> if result : <TAB> <TAB> try : <TAB> <TAB> <TAB> jsonify ( test = result ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while jsonifying settings from plugin  {} , please contact the plugin author about this "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> del result [ "" __enabled "" ] <TAB> <TAB> <TAB> data [ name ] = result ","if "" __enabled "" in result : 
","if "" __enabled "" in result :
",100.0,100.0,True
"def benchmarking ( net , ctx , num_iteration , datashape = 300 , batch_size = 64 ) : <TAB> input_shape = ( batch_size , 3 ) + ( datashape , datashape ) <TAB> data = mx . random . uniform ( - 1.0 , 1.0 , shape = input_shape , ctx = ctx , dtype = "" float32 "" ) <TAB> dryrun = 5 <TAB> for i in range ( dryrun + num_iteration ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tic = time . time ( ) <TAB> <TAB> ids , scores , bboxes = net ( data ) <TAB> <TAB> ids . asnumpy ( ) <TAB> <TAB> scores . asnumpy ( ) <TAB> <TAB> bboxes . asnumpy ( ) <TAB> toc = time . time ( ) - tic <TAB> return toc ","if i == dryrun : 
","if i % dryrun == 0 :
",30.77,17.29,False
"def merge_weekdays ( base_wd , icu_wd ) : <TAB> result = [ ] <TAB> for left , right in zip ( base_wd , icu_wd ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( left ) <TAB> <TAB> <TAB> continue <TAB> <TAB> left = set ( left . split ( "" | "" ) ) <TAB> <TAB> right = set ( right . split ( "" | "" ) ) <TAB> <TAB> result . append ( "" | "" . join ( left | right ) ) <TAB> return result ","if left == right : 
","if left == "" - "" and right == "" - "" :
",34.74,18.21,False
"def create_key ( self , request ) : <TAB> if self . _ignored_parameters : <TAB> <TAB> url , body = self . _remove_ignored_parameters ( request ) <TAB> else : <TAB> <TAB> url , body = request . url , request . body <TAB> key = hashlib . sha256 ( ) <TAB> key . update ( _to_bytes ( request . method . upper ( ) ) ) <TAB> key . update ( _to_bytes ( url ) ) <TAB> if request . body : <TAB> <TAB> key . update ( _to_bytes ( body ) ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for name , value in sorted ( request . headers . items ( ) ) : <TAB> <TAB> <TAB> <TAB> key . update ( _to_bytes ( name ) ) <TAB> <TAB> <TAB> <TAB> key . update ( _to_bytes ( value ) ) <TAB> return key . hexdigest ( ) ","if self . _include_get_headers and request . headers != _DEFAULT_HEADERS : 
","if request . headers :
",38.29,2.25,False
"def test_invalid_mountinfo ( self ) : <TAB> line = ( <TAB> <TAB> "" 20 1 252:1 / / rw,relatime - ext4 /dev/mapper/vg0-root "" <TAB> <TAB> "" rw,errors=remount-ro,data=ordered "" <TAB> ) <TAB> elements = line . split ( ) <TAB> for i in range ( len ( elements ) + 1 ) : <TAB> <TAB> lines = [ "" "" . join ( elements [ 0 : i ] ) ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> expected = None <TAB> <TAB> else : <TAB> <TAB> <TAB> expected = ( "" /dev/mapper/vg0-root "" , "" ext4 "" , "" / "" ) <TAB> <TAB> self . assertEqual ( expected , util . parse_mount_info ( "" / "" , lines ) ) ","if i < 10 : 
","if i == 0 :
",56.5,17.97,False
"def nested_filter ( self , items , mask ) : <TAB> keep_current = self . current_mask ( mask ) <TAB> keep_nested_lookup = self . nested_masks ( mask ) <TAB> for k , v in items : <TAB> <TAB> keep_nested = keep_nested_lookup . get ( k ) <TAB> <TAB> if k in keep_current : <TAB> <TAB> <TAB> if keep_nested is not None : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> yield k , dict ( self . nested_filter ( v . items ( ) , keep_nested ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield k , v ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def traverse_trees ( node_pos , sample , trees : List [ HeteroDecisionTreeGuest ] ) : <TAB> if node_pos [ "" reach_leaf_node "" ] . all ( ) : <TAB> <TAB> return node_pos <TAB> for t_idx , tree in enumerate ( trees ) : <TAB> <TAB> cur_node_idx = node_pos [ "" node_pos "" ] [ t_idx ] <TAB> <TAB> # reach leaf <TAB> <TAB> if cur_node_idx == - 1 : <TAB> <TAB> <TAB> continue <TAB> <TAB> rs , reach_leaf = HeteroSecureBoostingTreeGuest . traverse_a_tree ( <TAB> <TAB> <TAB> tree , sample , cur_node_idx <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> node_pos [ "" reach_leaf_node "" ] [ t_idx ] = True <TAB> <TAB> node_pos [ "" node_pos "" ] [ t_idx ] = rs <TAB> return node_pos ","if reach_leaf : 
","if reach_leaf :
",78.12,100.0,True
"def _pop_waiting_trial_id ( self ) - > Optional [ int ] : <TAB> # TODO(c-bata): Reduce database query counts for extracting waiting trials. <TAB> for trial in self . _storage . get_all_trials ( self . _study_id , deepcopy = False ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self . _storage . set_trial_state ( trial . _trial_id , TrialState . RUNNING ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> _logger . debug ( "" Trial  {}  popped from the trial queue. "" . format ( trial . number ) ) <TAB> <TAB> return trial . _trial_id <TAB> return None ","if trial . state != TrialState . WAITING : 
","if trial . _trial_id is None :
",41.76,16.78,False
"def get_step_best ( self , step_models ) : <TAB> best_score = None <TAB> best_model = "" "" <TAB> for model in step_models : <TAB> <TAB> model_info = self . models_trained [ model ] <TAB> <TAB> score = model_info . get_score ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if best_score is None or score < best_score : <TAB> <TAB> <TAB> best_score = score <TAB> <TAB> <TAB> best_model = model <TAB> LOGGER . info ( f "" step  { self . n_step } , best model  { best_model } "" ) <TAB> return best_model ","if score is None : 
","if score is None :
",100.0,100.0,True
"def iter_filters ( filters , block_end = False ) : <TAB> queue = deque ( filters ) <TAB> while queue : <TAB> <TAB> f = queue . popleft ( ) <TAB> <TAB> if f is not None and f . type in ( "" or "" , "" and "" , "" not "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> queue . appendleft ( None ) <TAB> <TAB> <TAB> for gf in f . filters : <TAB> <TAB> <TAB> <TAB> queue . appendleft ( gf ) <TAB> <TAB> yield f ","if block_end : 
","if block_end :
",78.12,100.0,True
"def _buffer_decode ( self , input , errors , final ) : <TAB> if self . decoder is None : <TAB> <TAB> ( output , consumed , byteorder ) = codecs . utf_16_ex_decode ( input , errors , 0 , final ) <TAB> <TAB> if byteorder == - 1 : <TAB> <TAB> <TAB> self . decoder = codecs . utf_16_le_decode <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . decoder = codecs . utf_16_be_decode <TAB> <TAB> elif consumed > = 2 : <TAB> <TAB> <TAB> raise UnicodeError ( "" UTF-16 stream does not start with BOM "" ) <TAB> <TAB> return ( output , consumed ) <TAB> return self . decoder ( input , self . errors , final ) ","elif byteorder == 1 : 
","elif byteorder == 1 :
",100.0,100.0,True
"def _load_db ( self ) : <TAB> try : <TAB> <TAB> with open ( self . db ) as db : <TAB> <TAB> <TAB> content = db . read ( 8 ) <TAB> <TAB> <TAB> db . seek ( 0 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = StringIO ( ) <TAB> <TAB> <TAB> <TAB> if self . encryptor : <TAB> <TAB> <TAB> <TAB> <TAB> self . encryptor . decrypt ( db , data ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> raise EncryptionError ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Encrpyted credential storage:  {} "" . format ( self . db ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> return json . loads ( data . getvalue ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return json . load ( db ) <TAB> except : <TAB> <TAB> return { "" creds "" : [ ] } ","if content == ( "" Salted__ "" ) : 
","if content == b "" \x00 "" :
",32.26,24.74,False
"def _getbytes ( self , start , l = 1 ) : <TAB> out = [ ] <TAB> for ad in range ( l ) : <TAB> <TAB> offset = ad + start + self . base_address <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IOError ( "" not enough bytes "" ) <TAB> <TAB> out . append ( int_to_byte ( Byte ( offset ) ) ) <TAB> return b "" "" . join ( out ) ","if not is_mapped ( offset ) : 
","if offset > = self . length :
",27.02,6.41,False
"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d . keys ( ) : <TAB> <TAB> if config . get ( "" environment "" ) == "" prod "" : <TAB> <TAB> <TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True ","if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) : 
","if config . get ( "" environment "" ) == "" prod "" :
",45.44,16.72,False
"def insertLine ( self , refnum , linenum , line ) : <TAB> i = - 1 <TAB> for i , row in enumerate ( self . rows ) : <TAB> <TAB> if row [ 0 ] == linenum : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> row [ refnum + 1 ] = line <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # else keep looking <TAB> <TAB> elif row [ 0 ] > linenum : <TAB> <TAB> <TAB> break <TAB> self . rows . insert ( i , self . newRow ( linenum , refnum , line ) ) ","if row [ refnum + 1 ] is None : 
","if self . lastrow != row [ refnum + 1 ] :
",58.83,40.9,False
"def __setattr__ ( self , name , val ) : <TAB> if self . __dict__ . get ( name , "" hamster_graphics_no_value_really "" ) == val : <TAB> <TAB> return <TAB> Sprite . __setattr__ ( self , name , val ) <TAB> if name == "" image_data "" : <TAB> <TAB> self . _surface = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __dict__ [ "" width "" ] = self . image_data . get_width ( ) <TAB> <TAB> <TAB> self . __dict__ [ "" height "" ] = self . image_data . get_height ( ) ","if self . image_data : 
","if self . _use_image_size :
",64.48,20.56,False
"def process_signature ( app , what , name , obj , options , signature , return_annotation ) : <TAB> if signature : <TAB> <TAB> # replace Mock function names <TAB> <TAB> signature = re . sub ( "" <Mock name= ' ([^ ' ]+) ' .*> "" , "" \ g<1> "" , signature ) <TAB> <TAB> signature = re . sub ( "" tensorflow "" , "" tf "" , signature ) <TAB> <TAB> # add scope name to layer signatures: <TAB> <TAB> if hasattr ( obj , "" use_scope "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" variable_scope_name,  "" + signature [ 1 : ] <TAB> <TAB> <TAB> elif obj . use_scope is None : <TAB> <TAB> <TAB> <TAB> signature = signature [ 0 ] + "" [variable_scope_name,]  "" + signature [ 1 : ] <TAB> # signature: arg list <TAB> return signature , return_annotation ","if obj . use_scope : 
","if obj . use_scope is True :
",61.88,61.05,False
"def L_op ( self , inputs , outputs , gout ) : <TAB> ( x , ) = inputs <TAB> ( gz , ) = gout <TAB> if x . type in complex_types : <TAB> <TAB> raise NotImplementedError ( ) <TAB> if outputs [ 0 ] . type in discrete_types : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ x . zeros_like ( dtype = theano . config . floatX ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ x . zeros_like ( ) ] <TAB> return ( gz * ( 1 - sqr ( tanh ( x ) ) ) , ) ","if x . type in discrete_types : 
","if x . type in discrete_types :
",100.0,100.0,True
"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB> <TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> <TAB> if output . lower ( ) == "" n "" : <TAB> <TAB> <TAB> return False ","if output . lower ( ) == "" y "" : 
","if output . lower ( ) == "" y "" :
",100.0,100.0,True
"def replace_documentation_for_matching_shape ( self , event_name , section , * * kwargs ) : <TAB> if self . _shape_name == section . context . get ( "" shape "" ) : <TAB> <TAB> self . _replace_documentation ( event_name , section ) <TAB> for section_name in section . available_sections : <TAB> <TAB> sub_section = section . get_section ( section_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _replace_documentation ( event_name , sub_section ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . replace_documentation_for_matching_shape ( event_name , sub_section ) ","if self . _shape_name == sub_section . context . get ( "" shape "" ) : 
","if sub_section . context . get ( "" shape "" ) == self . _shape_name :
",77.16,77.35,False
"def confirm_on_console ( topic , msg ) : <TAB> done = False <TAB> print ( topic ) <TAB> while not done : <TAB> <TAB> output = raw_input ( msg + "" :[y/n] "" ) <TAB> <TAB> if output . lower ( ) == "" y "" : <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False ","if output . lower ( ) == "" n "" : 
","elif output . lower ( ) == "" n "" :
",85.85,90.36,False
"def __getitem__ ( self , index ) : <TAB> if self . _check ( ) : <TAB> <TAB> if isinstance ( index , int ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise IndexError ( index ) <TAB> <TAB> <TAB> if self . features [ index ] is None : <TAB> <TAB> <TAB> <TAB> feature = self . device . feature_request ( FEATURE . FEATURE_SET , 0x10 , index ) <TAB> <TAB> <TAB> <TAB> if feature : <TAB> <TAB> <TAB> <TAB> <TAB> ( feature , ) = _unpack ( "" !H "" , feature [ : 2 ] ) <TAB> <TAB> <TAB> <TAB> <TAB> self . features [ index ] = FEATURE [ feature ] <TAB> <TAB> <TAB> return self . features [ index ] <TAB> <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> <TAB> indices = index . indices ( len ( self . features ) ) <TAB> <TAB> <TAB> return [ self . __getitem__ ( i ) for i in range ( * indices ) ] ","if index < 0 or index > = len ( self . features ) : 
","if index < 0 :
",34.7,9.57,False
"def _parse_locator ( self , locator ) : <TAB> prefix = None <TAB> criteria = locator <TAB> if not locator . startswith ( "" // "" ) : <TAB> <TAB> locator_parts = locator . partition ( "" = "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> prefix = locator_parts [ 0 ] <TAB> <TAB> <TAB> criteria = locator_parts [ 2 ] . strip ( ) <TAB> return ( prefix , criteria ) ","if len ( locator_parts [ 1 ] ) > 0 : 
","if len ( locator_parts ) > 2 :
",39.85,44.36,False
"def trakt_episode_data_generate ( self , data ) : <TAB> # Find how many unique season we have <TAB> uniqueSeasons = [ ] <TAB> for season , episode in data : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> uniqueSeasons . append ( season ) <TAB> # build the query <TAB> seasonsList = [ ] <TAB> for searchedSeason in uniqueSeasons : <TAB> <TAB> episodesList = [ ] <TAB> <TAB> for season , episode in data : <TAB> <TAB> <TAB> if season == searchedSeason : <TAB> <TAB> <TAB> <TAB> episodesList . append ( { "" number "" : episode } ) <TAB> <TAB> seasonsList . append ( { "" number "" : searchedSeason , "" episodes "" : episodesList } ) <TAB> post_data = { "" seasons "" : seasonsList } <TAB> return post_data ","if season not in uniqueSeasons : 
","if season not in uniqueSeasons :
",100.0,100.0,True
"def __init__ ( self , data , n_bins ) : <TAB> bin_width = span / n_bins <TAB> bins = [ 0 ] * n_bins <TAB> for x in data : <TAB> <TAB> b = int ( mpfloor ( ( x - minimum ) / bin_width ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> b = 0 <TAB> <TAB> elif b > = n_bins : <TAB> <TAB> <TAB> b = n_bins - 1 <TAB> <TAB> bins [ b ] + = 1 <TAB> self . bins = bins <TAB> self . bin_width = bin_width ","if b < 0 : 
","if b < 0 :
",100.0,100.0,True
"def infer_context ( typ , context = "" http://schema.org "" ) : <TAB> parsed_context = urlparse ( typ ) <TAB> if parsed_context . netloc : <TAB> <TAB> base = "" "" . join ( [ parsed_context . scheme , "" :// "" , parsed_context . netloc ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> context = urljoin ( base , parsed_context . path ) <TAB> <TAB> <TAB> typ = parsed_context . fragment . strip ( "" / "" ) <TAB> <TAB> elif parsed_context . path : <TAB> <TAB> <TAB> context = base <TAB> <TAB> <TAB> typ = parsed_context . path . strip ( "" / "" ) <TAB> return context , typ ","if parsed_context . path and parsed_context . fragment : 
","if parsed_context . fragment :
",53.72,42.44,False
"def parse ( self , items ) : <TAB> for index , item in enumerate ( items ) : <TAB> <TAB> keys = self . build_key ( item ) <TAB> <TAB> if keys is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> # Update `items` <TAB> <TAB> self . items [ tuple ( keys ) ] = ( index , item ) <TAB> <TAB> # Update `table` <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Unable to update table (keys:  %r ) "" , keys ) ","if not self . path_set ( self . table , keys , ( index , item ) ) : 
","if not self . table . update ( keys ) :
",41.05,14.95,False
"def dict_to_XML ( tag , dictionary , * * kwargs ) : <TAB> """"""Return XML element converting dicts recursively."""""" <TAB> elem = Element ( tag , * * kwargs ) <TAB> for key , val in dictionary . items ( ) : <TAB> <TAB> if tag == "" layers "" : <TAB> <TAB> <TAB> child = dict_to_XML ( "" layer "" , val , name = key ) <TAB> <TAB> elif isinstance ( val , MutableMapping ) : <TAB> <TAB> <TAB> child = dict_to_XML ( key , val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> child = Element ( "" variable "" , name = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> child = Element ( key ) <TAB> <TAB> <TAB> child . text = str ( val ) <TAB> <TAB> elem . append ( child ) <TAB> return elem ","if tag == "" config "" : 
","if tag == "" variable "" :
",74.63,59.46,False
"def _get_config_value ( self , section , key ) : <TAB> if section : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . error ( "" Error: Config section  ' %s '  not found "" , section ) <TAB> <TAB> <TAB> return None <TAB> <TAB> return self . config [ section ] . get ( key , self . config [ key ] ) <TAB> else : <TAB> <TAB> return self . config [ key ] ","if section not in self . config : 
","if section not in self . config :
",100.0,100.0,True
"def h_line_down ( self , input ) : <TAB> end_this_line = self . value . find ( "" \n "" , self . cursor_position ) <TAB> if end_this_line == - 1 : <TAB> <TAB> if self . scroll_exit : <TAB> <TAB> <TAB> self . h_exit_down ( None ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . cursor_position = len ( self . value ) <TAB> else : <TAB> <TAB> self . cursor_position = end_this_line + 1 <TAB> <TAB> for x in range ( self . cursorx ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> elif self . value [ self . cursor_position ] == "" \n "" : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . cursor_position + = 1 ","if self . cursor_position > len ( self . value ) - 1 : 
","if self . value [ self . cursor_position ] == "" "" :
",38.9,35.58,False
"def printsumfp ( fp , filename , out = sys . stdout ) : <TAB> m = md5 ( ) <TAB> try : <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> data = fp . read ( bufsize ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> if isinstance ( data , str ) : <TAB> <TAB> <TAB> <TAB> data = data . encode ( fp . encoding ) <TAB> <TAB> <TAB> m . update ( data ) <TAB> except IOError as msg : <TAB> <TAB> sys . stderr . write ( "" %s : I/O error:  %s \n "" % ( filename , msg ) ) <TAB> <TAB> return 1 <TAB> out . write ( "" %s %s \n "" % ( m . hexdigest ( ) , filename ) ) <TAB> return 0 ","if not data : 
","if not data :
",100.0,100.0,True
"def main ( input ) : <TAB> logging . info ( "" Running Azure Cloud Custodian Policy  %s "" , input ) <TAB> context = { <TAB> <TAB> "" config_file "" : join ( function_directory , "" config.json "" ) , <TAB> <TAB> "" auth_file "" : join ( function_directory , "" auth.json "" ) , <TAB> } <TAB> event = None <TAB> subscription_id = None <TAB> if isinstance ( input , QueueMessage ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> event = input . get_json ( ) <TAB> <TAB> subscription_id = ResourceIdParser . get_subscription_id ( event [ "" subject "" ] ) <TAB> handler . run ( event , context , subscription_id ) ","if input . dequeue_count > max_dequeue_count : 
","if input . get_json ( ) . get ( "" subject "" ) is None :
",37.55,9.08,False
"def maybeExtractTarball ( self ) : <TAB> if self . tarball : <TAB> <TAB> tar = self . computeTarballOptions ( ) + [ "" -xvf "" , self . tarball ] <TAB> <TAB> res = yield self . _Cmd ( tar , abandonOnFailure = False ) <TAB> <TAB> if res :<TAB> # error with tarball.. erase repo dir and tarball <TAB> <TAB> <TAB> yield self . _Cmd ( [ "" rm "" , "" -f "" , self . tarball ] , abandonOnFailure = False ) <TAB> <TAB> <TAB> yield self . runRmdir ( self . repoDir ( ) , abandonOnFailure = False ) ","if res : 
","if res :
",78.12,0.0,False
"def execute ( self , arbiter , props ) : <TAB> watcher = self . _get_watcher ( arbiter , props . pop ( "" name "" ) ) <TAB> action = 0 <TAB> for key , val in props . get ( "" options "" , { } ) . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_action = 0 <TAB> <TAB> <TAB> for name , _val in val . items ( ) : <TAB> <TAB> <TAB> <TAB> action = watcher . set_opt ( "" hooks. %s "" % name , _val ) <TAB> <TAB> <TAB> <TAB> if action == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> new_action = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> new_action = watcher . set_opt ( key , val ) <TAB> <TAB> if new_action == 1 : <TAB> <TAB> <TAB> action = 1 <TAB> # trigger needed action <TAB> return watcher . do_action ( action ) ","if key == "" hooks "" : 
","if isinstance ( val , dict ) :
",26.98,6.57,False
"def _import_playlists ( self , fns , library ) : <TAB> added = 0 <TAB> for filename in fns : <TAB> <TAB> name = _name_for ( filename ) <TAB> <TAB> with open ( filename , "" rb "" ) as f : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> playlist = parse_m3u ( f , name , library = library ) <TAB> <TAB> <TAB> elif filename . endswith ( "" .pls "" ) : <TAB> <TAB> <TAB> <TAB> playlist = parse_pls ( f , name , library = library ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> print_w ( "" Unsupported playlist type for  ' %s ' "" % filename ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . changed ( playlist ) <TAB> <TAB> library . add ( playlist ) <TAB> <TAB> added + = 1 <TAB> return added ","if filename . endswith ( "" .m3u "" ) or filename . endswith ( "" .m3u8 "" ) : 
","if filename . endswith ( "" .m3u "" ) :
",64.52,38.97,False
"def unwrap_term_buckets ( self , timestamp , term_buckets ) : <TAB> for term_data in term_buckets : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . unwrap_interval_buckets ( <TAB> <TAB> <TAB> <TAB> timestamp , term_data [ "" key "" ] , term_data [ "" interval_aggs "" ] [ "" buckets "" ] <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . check_matches ( timestamp , term_data [ "" key "" ] , term_data ) ","if "" interval_aggs "" in term_data : 
","if "" interval_aggs "" in term_data :
",100.0,100.0,True
"def _get_exception ( flags , timeout_ms , payload_size ) : <TAB> if flags & FLAG_ERROR : <TAB> <TAB> if flags & FLAG_TIMEOUT : <TAB> <TAB> <TAB> return SpicommTimeoutError ( timeout_ms / 1000.0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return SpicommOverflowError ( payload_size ) <TAB> <TAB> return SpicommError ( ) <TAB> return None ","if flags & FLAG_OVERFLOW : 
","if flags & FLAG_OVERFLOW :
",100.0,100.0,True
"def _get_pattern ( self , pattern_id ) : <TAB> """"""Get pattern item by id."""""" <TAB> for key in ( Tag . PATTERNS1 , Tag . PATTERNS2 , Tag . PATTERNS3 ) : <TAB> <TAB> if key in self . tagged_blocks : <TAB> <TAB> <TAB> data = self . tagged_blocks . get_data ( key ) <TAB> <TAB> <TAB> for pattern in data : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return pattern <TAB> return None ","if pattern . pattern_id == pattern_id : 
","if pattern . id == pattern_id :
",63.85,64.32,False
"def print_quiet ( self , context , * args , * * kwargs ) : <TAB> for index , ( key , value ) in enumerate ( <TAB> <TAB> itertools . chain ( enumerate ( args ) , kwargs . items ( ) ) <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> self . format_quiet ( index , key , value , fields = context . get_input_fields ( ) ) <TAB> <TAB> <TAB> ) ","if self . filter ( index , key , value ) : 
","if self . _is_terminal ( key , value , context ) :
",58.57,19.77,False
"def complete ( self , block ) : <TAB> with self . _condition : <TAB> <TAB> if not self . _final : <TAB> <TAB> <TAB> return False <TAB> <TAB> if self . _complete ( ) : <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _condition . wait_for ( self . _complete ) <TAB> <TAB> <TAB> self . _calculate_state_root_if_not_already_done ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> return False ","if block : 
","if block :
",78.12,0.0,False
"def compression_rotator ( source , dest ) : <TAB> with open ( source , "" rb "" ) as sf : <TAB> <TAB> with gzip . open ( dest , "" wb "" ) as wf : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> data = sf . read ( CHUNK_SIZE ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> wf . write ( data ) <TAB> os . remove ( source ) ","if not data : 
","if not data :
",100.0,100.0,True
"def mockup ( self , records ) : <TAB> provider = TransipProvider ( "" "" , "" "" , "" "" ) <TAB> _dns_entries = [ ] <TAB> for record in records : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> entries_for = getattr ( provider , "" _entries_for_ {} "" . format ( record . _type ) ) <TAB> <TAB> <TAB> # Root records have '@' as name <TAB> <TAB> <TAB> name = record . name <TAB> <TAB> <TAB> if name == "" "" : <TAB> <TAB> <TAB> <TAB> name = provider . ROOT_RECORD <TAB> <TAB> <TAB> _dns_entries . extend ( entries_for ( name , record ) ) <TAB> <TAB> <TAB> # NS is not supported as a DNS Entry, <TAB> <TAB> <TAB> # so it should cover the if statement <TAB> <TAB> <TAB> _dns_entries . append ( DnsEntry ( "" @ "" , "" 3600 "" , "" NS "" , "" ns01.transip.nl. "" ) ) <TAB> self . mockupEntries = _dns_entries ","if record . _type in provider . SUPPORTS : 
","if hasattr ( record , "" _type "" ) :
",26.61,9.43,False
"def parse_known_args ( self , args = None , namespace = None ) : <TAB> entrypoint = self . prog . split ( "" "" ) [ 0 ] <TAB> try : <TAB> <TAB> defs = get_defaults_for_argparse ( entrypoint ) <TAB> <TAB> ignore = defs . pop ( "" Ignore "" , None ) <TAB> <TAB> self . set_defaults ( * * defs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> set_notebook_diff_ignores ( ignore ) <TAB> except ValueError : <TAB> <TAB> pass <TAB> return super ( ConfigBackedParser , self ) . parse_known_args ( <TAB> <TAB> args = args , namespace = namespace <TAB> ) ","if ignore : 
","if ignore :
",78.12,0.0,False
"def _maybeRebuildAtlas ( self , threshold = 4 , minlen = 1000 ) : <TAB> n = len ( self . fragmentAtlas ) <TAB> if ( n > minlen ) and ( n > threshold * len ( self . data ) ) : <TAB> <TAB> self . fragmentAtlas . rebuild ( <TAB> <TAB> <TAB> list ( zip ( * self . _style ( [ "" symbol "" , "" size "" , "" pen "" , "" brush "" ] ) ) ) <TAB> <TAB> ) <TAB> <TAB> self . data [ "" sourceRect "" ] = 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _sourceQRect . clear ( ) <TAB> <TAB> self . updateSpots ( ) ","if _USE_QRECT : 
","if self . _sourceQRect :
",30.19,10.68,False
"def dispatch_return ( self , frame , arg ) : <TAB> if self . stop_here ( frame ) or frame == self . returnframe : <TAB> <TAB> # Ignore return events in generator except when stepping. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . trace_dispatch <TAB> <TAB> try : <TAB> <TAB> <TAB> self . frame_returning = frame <TAB> <TAB> <TAB> self . user_return ( frame , arg ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . frame_returning = None <TAB> <TAB> if self . quitting : <TAB> <TAB> <TAB> raise BdbQuit <TAB> <TAB> # The user issued a 'next' or 'until' command. <TAB> <TAB> if self . stopframe is frame and self . stoplineno != - 1 : <TAB> <TAB> <TAB> self . _set_stopinfo ( None , None ) <TAB> return self . trace_dispatch ","if self . stopframe and frame . f_code . co_flags & CO_GENERATOR : 
","if self . quitting :
",35.76,2.6,False
"def tearDown ( self ) : <TAB> if not self . is_playback ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . hosted_service_name is not None : <TAB> <TAB> <TAB> <TAB> self . sms . delete_hosted_service ( self . hosted_service_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . sms . delete_storage_account ( self . storage_account_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> <TAB> try : <TAB> <TAB> <TAB> self . sms . delete_affinity_group ( self . affinity_group_name ) <TAB> <TAB> except : <TAB> <TAB> <TAB> pass <TAB> return super ( LegacyMgmtAffinityGroupTest , self ) . tearDown ( ) ","if self . storage_account_name is not None : 
","if self . storage_account_name is not None :
",100.0,100.0,True
"def make_log_msg ( self , msg , * other_messages ) : <TAB> MAX_MESSAGE_LENGTH = 1000 <TAB> if not other_messages : <TAB> <TAB> # assume that msg is a single string <TAB> <TAB> return msg [ - MAX_MESSAGE_LENGTH : ] <TAB> else : <TAB> <TAB> if len ( msg ) : <TAB> <TAB> <TAB> msg + = "" \n ... \n "" <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH - len ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> NEXT_MESSAGE_OFFSET = MAX_MESSAGE_LENGTH <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg + = other_messages [ 0 ] [ - NEXT_MESSAGE_OFFSET : ] <TAB> <TAB> <TAB> return self . make_log_msg ( msg , * other_messages [ 1 : ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . make_log_msg ( msg ) ","if NEXT_MESSAGE_OFFSET > 0 : 
","if len ( other_messages ) > 0 :
",36.03,17.75,False
"def wrapper (<TAB> # type: ignore <TAB> self : RequestHandler , * args , * * kwargs ) - > Optional [ Awaitable [ None ] ] : <TAB> if self . request . path . endswith ( "" / "" ) : <TAB> <TAB> if self . request . method in ( "" GET "" , "" HEAD "" ) : <TAB> <TAB> <TAB> uri = self . request . path . rstrip ( "" / "" ) <TAB> <TAB> <TAB> if uri :<TAB> # don't try to redirect '/' to '' <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> uri + = "" ? "" + self . request . query <TAB> <TAB> <TAB> <TAB> self . redirect ( uri , permanent = True ) <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> raise HTTPError ( 404 ) <TAB> return method ( self , * args , * * kwargs ) ","if self . request . query : 
","if self . request . query :
",100.0,100.0,True
"def process_lib ( vars_ , coreval ) : <TAB> for d in vars_ : <TAB> <TAB> var = d . upper ( ) <TAB> <TAB> if var == "" QTCORE "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> value = env [ "" LIBPATH_ "" + var ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> core = env [ coreval ] <TAB> <TAB> <TAB> accu = [ ] <TAB> <TAB> <TAB> for lib in value : <TAB> <TAB> <TAB> <TAB> if lib in core : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> accu . append ( lib ) <TAB> <TAB> <TAB> env [ "" LIBPATH_ "" + var ] = accu ","if value : 
","if value :
",78.12,0.0,False
"def _attach_children ( self , other , exclude_worldbody , dry_run = False ) : <TAB> for other_child in other . all_children ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self_child = self . get_children ( other_child . spec . name ) <TAB> <TAB> <TAB> self_child . _attach ( <TAB> <TAB> <TAB> <TAB> other_child , exclude_worldbody , dry_run <TAB> <TAB> <TAB> )<TAB> # pylint: disable=protected-access ","if not other_child . spec . repeated : 
","if other_child . spec . name in self . _worldbody_specs :
",50.63,32.38,False
"def getDictFromTree ( tree ) : <TAB> ret_dict = { } <TAB> for child in tree . getchildren ( ) : <TAB> <TAB> if child . getchildren ( ) : <TAB> <TAB> <TAB> ## Complex-type child. Recurse <TAB> <TAB> <TAB> content = getDictFromTree ( child ) <TAB> <TAB> else : <TAB> <TAB> <TAB> content = child . text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not type ( ret_dict [ child . tag ] ) == list : <TAB> <TAB> <TAB> <TAB> ret_dict [ child . tag ] = [ ret_dict [ child . tag ] ] <TAB> <TAB> <TAB> ret_dict [ child . tag ] . append ( content or "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret_dict [ child . tag ] = content or "" "" <TAB> return ret_dict ","if ret_dict . has_key ( child . tag ) : 
","if child . tag in ret_dict :
",39.74,18.4,False
"def nsUriMatch ( self , value , wanted , strict = 0 , tt = type ( ( ) ) ) : <TAB> """"""Return a true value if two namespace uri values match."""""" <TAB> if value == wanted or ( type ( wanted ) is tt ) and value in wanted : <TAB> <TAB> return 1 <TAB> if not strict and value is not None : <TAB> <TAB> wanted = type ( wanted ) is tt and wanted or ( wanted , ) <TAB> <TAB> value = value [ - 1 : ] != "" / "" and value or value [ : - 1 ] <TAB> <TAB> for item in wanted : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return 1 <TAB> return 0 ","if item == value or item [ : - 1 ] == value : 
","if item == value or item [ - 1 : ] == value :
",83.6,72.54,False
"def update_repository ( self , ignore_issues = False , force = False ) : <TAB> """"""Update."""""" <TAB> if not await self . common_update ( ignore_issues , force ) : <TAB> <TAB> return <TAB> # Get appdaemon objects. <TAB> if self . repository_manifest : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . content . path . remote = "" "" <TAB> if self . content . path . remote == "" apps "" : <TAB> <TAB> self . data . domain = get_first_directory_in_directory ( <TAB> <TAB> <TAB> self . tree , self . content . path . remote <TAB> <TAB> ) <TAB> <TAB> self . content . path . remote = f "" apps/ { self . data . name } "" <TAB> # Set local path <TAB> self . content . path . local = self . localpath ","if self . data . content_in_root : 
","if self . content . path . remote is None :
",44.95,18.36,False
"def addOutput ( self , data , isAsync = None , * * kwargs ) : <TAB> isAsync = _get_async_param ( isAsync , * * kwargs ) <TAB> if isAsync : <TAB> <TAB> self . terminal . eraseLine ( ) <TAB> <TAB> self . terminal . cursorBackward ( len ( self . lineBuffer ) + len ( self . ps [ self . pn ] ) ) <TAB> self . terminal . write ( data ) <TAB> if isAsync : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . terminal . nextLine ( ) <TAB> <TAB> self . terminal . write ( self . ps [ self . pn ] ) <TAB> <TAB> if self . lineBuffer : <TAB> <TAB> <TAB> oldBuffer = self . lineBuffer <TAB> <TAB> <TAB> self . lineBuffer = [ ] <TAB> <TAB> <TAB> self . lineBufferIndex = 0 <TAB> <TAB> <TAB> self . _deliverBuffer ( oldBuffer ) ","if self . _needsNewline ( ) : 
","if self . lineBufferIndex + len ( self . ps [ self . pn ] ) > self . lineBufferLength :
",36.28,8.04,False
"def is_installed ( self , dlc_title = "" "" ) - > bool : <TAB> installed = False <TAB> if dlc_title : <TAB> <TAB> dlc_version = self . get_dlc_info ( "" version "" , dlc_title ) <TAB> <TAB> installed = True if dlc_version else False <TAB> <TAB> # Start: Code for compatibility with minigalaxy 1.0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> status = self . legacy_get_dlc_status ( dlc_title ) <TAB> <TAB> <TAB> installed = True if status in [ "" installed "" , "" updatable "" ] else False <TAB> <TAB> # End: Code for compatibility with minigalaxy 1.0 <TAB> else : <TAB> <TAB> if self . install_dir and os . path . exists ( self . install_dir ) : <TAB> <TAB> <TAB> installed = True <TAB> return installed ","if not installed : 
","if self . legacy :
",28.99,12.7,False
"def close ( self ) : <TAB> self . selector . close ( ) <TAB> if self . sock : <TAB> <TAB> sockname = None <TAB> <TAB> try : <TAB> <TAB> <TAB> sockname = self . sock . getsockname ( ) <TAB> <TAB> except ( socket . error , OSError ) : <TAB> <TAB> <TAB> pass <TAB> <TAB> self . sock . close ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # it was a Unix domain socket, remove it from the filesystem <TAB> <TAB> <TAB> if os . path . exists ( sockname ) : <TAB> <TAB> <TAB> <TAB> os . remove ( sockname ) <TAB> self . sock = None ","if type ( sockname ) is str : 
","if isinstance ( sockname , str ) :
",28.68,14.54,False
"def post_file ( self , file_path , graph_type = "" edges "" , file_type = "" csv "" ) : <TAB> dataset_id = self . dataset_id <TAB> tok = self . token <TAB> base_path = self . server_base_path <TAB> with open ( file_path , "" rb "" ) as file : <TAB> <TAB> out = requests . post ( <TAB> <TAB> <TAB> f "" { base_path } /api/v2/upload/datasets/ { dataset_id } / { graph_type } / { file_type } "" , <TAB> <TAB> <TAB> verify = self . certificate_validation , <TAB> <TAB> <TAB> headers = { "" Authorization "" : f "" Bearer  { tok } "" } , <TAB> <TAB> <TAB> data = file . read ( ) , <TAB> <TAB> ) . json ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise Exception ( out ) <TAB> <TAB> return out ","if not out [ "" success "" ] : 
","if "" error "" in out :
",31.81,7.38,False
"def _get_vqa_v2_image_raw_dataset ( directory , image_root_url , image_urls ) : <TAB> """"""Extract the VQA V2 image data set to directory unless it's there."""""" <TAB> for url in image_urls : <TAB> <TAB> filename = os . path . basename ( url ) <TAB> <TAB> download_url = os . path . join ( image_root_url , url ) <TAB> <TAB> path = generator_utils . maybe_download ( directory , filename , download_url ) <TAB> <TAB> unzip_dir = os . path . join ( directory , filename . strip ( "" .zip "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> zipfile . ZipFile ( path , "" r "" ) . extractall ( directory ) ","if not tf . gfile . Exists ( unzip_dir ) : 
","if os . path . exists ( unzip_dir ) :
",52.71,42.48,False
"def __call__ ( self , environ , start_response ) : <TAB> for key in "" REQUEST_URL "" , "" REQUEST_URI "" , "" UNENCODED_URL "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> request_uri = unquote ( environ [ key ] ) <TAB> <TAB> script_name = unquote ( environ . get ( "" SCRIPT_NAME "" , "" "" ) ) <TAB> <TAB> if request_uri . startswith ( script_name ) : <TAB> <TAB> <TAB> environ [ "" PATH_INFO "" ] = request_uri [ len ( script_name ) : ] . split ( "" ? "" , 1 ) [ 0 ] <TAB> <TAB> <TAB> break <TAB> return self . app ( environ , start_response ) ","if key not in environ : 
","if key not in environ :
",100.0,100.0,True
"def _instrument_model ( self , model ) : <TAB> for key , value in list ( <TAB> <TAB> model . __dict__ . items ( ) <TAB> ) :<TAB> # avoid ""dictionary keys changed during iteration"" <TAB> <TAB> if isinstance ( value , tf . keras . layers . Layer ) : <TAB> <TAB> <TAB> new_layer = self . _instrument ( value ) <TAB> <TAB> <TAB> if new_layer is not value : <TAB> <TAB> <TAB> <TAB> setattr ( model , key , new_layer ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for i , item in enumerate ( value ) : <TAB> <TAB> <TAB> <TAB> if isinstance ( item , tf . keras . layers . Layer ) : <TAB> <TAB> <TAB> <TAB> <TAB> value [ i ] = self . _instrument ( item ) <TAB> return model ","elif isinstance ( value , list ) : 
","elif isinstance ( value , list ) :
",100.0,100.0,True
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> if i == "" . "" or i == "" .. "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist ","if pattern . match ( value ) is not None : 
","if pattern . match ( value ) :
",64.19,59.76,False
"def get_text ( self , nodelist ) : <TAB> """"""Return a string representation of the motif's properties listed on nodelist ."""""" <TAB> retlist = [ ] <TAB> for node in nodelist : <TAB> <TAB> if node . nodeType == Node . TEXT_NODE : <TAB> <TAB> <TAB> retlist . append ( node . wholeText ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> retlist . append ( self . get_text ( node . childNodes ) ) <TAB> return re . sub ( r "" \ s+ "" , "" "" , "" "" . join ( retlist ) ) ","elif node . hasChildNodes : 
","elif node . nodeType == Node . ELEMENT_NODE :
",43.86,13.55,False
"def _persist_metadata ( self , dirname , filename ) : <TAB> metadata_path = "" {0} / {1} .json "" . format ( dirname , filename ) <TAB> if self . media_metadata or self . comments or self . include_location : <TAB> <TAB> if self . posts : <TAB> <TAB> <TAB> if self . latest : <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphImages "" : self . posts } , metadata_path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . latest : <TAB> <TAB> <TAB> <TAB> self . merge_json ( { "" GraphStories "" : self . stories } , metadata_path ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . save_json ( { "" GraphStories "" : self . stories } , metadata_path ) ","if self . stories : 
","if self . stories :
",100.0,100.0,True
"def _get_python_wrapper_content ( self , job_class , args ) : <TAB> job = job_class ( [ "" -r "" , "" hadoop "" ] + list ( args ) ) <TAB> job . sandbox ( ) <TAB> with job . make_runner ( ) as runner : <TAB> <TAB> runner . _create_setup_wrapper_scripts ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with open ( runner . _spark_python_wrapper_path ) as f : <TAB> <TAB> <TAB> <TAB> return f . read ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return None ","if runner . _spark_python_wrapper_path : 
","if runner . _spark_python_wrapper_path is not None :
",60.15,71.66,False
"def computeLeadingWhitespaceWidth ( s , tab_width ) : <TAB> w = 0 <TAB> for ch in s : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> w + = 1 <TAB> <TAB> elif ch == "" \t "" : <TAB> <TAB> <TAB> w + = abs ( tab_width ) - ( w % abs ( tab_width ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return w ","if ch == "" "" : 
","if ch == "" "" :
",100.0,100.0,True
def run ( self ) : <TAB> # if the i3status process dies we want to restart it. <TAB> # We give up restarting if we have died too often <TAB> for _ in range ( 10 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> self . spawn_i3status ( ) <TAB> <TAB> # check if we never worked properly and if so quit now <TAB> <TAB> if not self . ready : <TAB> <TAB> <TAB> break <TAB> <TAB> # limit restart rate <TAB> <TAB> self . lock . wait ( 5 ) ,"if not self . py3_wrapper . running : 
","if self . is_alive ( ) :
",33.55,10.73,False
"def translate_len ( <TAB> builder : IRBuilder , expr : CallExpr , callee : RefExpr ) - > Optional [ Value ] : <TAB> # Special case builtins.len <TAB> if len ( expr . args ) == 1 and expr . arg_kinds == [ ARG_POS ] : <TAB> <TAB> expr_rtype = builder . node_type ( expr . args [ 0 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # len() of fixed-length tuple can be trivially determined statically, <TAB> <TAB> <TAB> # though we still need to evaluate it. <TAB> <TAB> <TAB> builder . accept ( expr . args [ 0 ] ) <TAB> <TAB> <TAB> return Integer ( len ( expr_rtype . types ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> obj = builder . accept ( expr . args [ 0 ] ) <TAB> <TAB> <TAB> return builder . builtin_len ( obj , - 1 ) <TAB> return None ","if isinstance ( expr_rtype , RTuple ) : 
","if isinstance ( expr_rtype , IRType ) :
",79.9,70.71,False
"def parse_auth ( val ) : <TAB> if val is not None : <TAB> <TAB> authtype , params = val . split ( "" "" , 1 ) <TAB> <TAB> if authtype in known_auth_schemes : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # this is the ""Authentication: Basic XXXXX=="" case <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> params = parse_auth_params ( params ) <TAB> <TAB> return authtype , params <TAB> return val ","if authtype == "" Basic "" and ' "" ' not in params : 
","if params == "" basic "" :
",36.15,10.59,False
"def toxml ( self ) : <TAB> text = self . value <TAB> self . parent . setBidi ( getBidiType ( text ) ) <TAB> if not text . startswith ( HTML_PLACEHOLDER_PREFIX ) : <TAB> <TAB> if self . parent . nodeName == "" p "" : <TAB> <TAB> <TAB> text = text . replace ( "" \n "" , "" \n<TAB>  "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = "" \n<TAB>   "" + text . replace ( "" \n "" , "" \n<TAB>   "" ) <TAB> text = self . doc . normalizeEntities ( text ) <TAB> return text ","elif self . parent . nodeName == "" li "" and self . parent . childNodes [ 0 ] == self : 
","elif self . parent . nodeName == "" h "" :
",53.56,27.47,False
"def get_all_related_many_to_many_objects ( self ) : <TAB> try :<TAB> # Try the cache first. <TAB> <TAB> return self . _all_related_many_to_many_objects <TAB> except AttributeError : <TAB> <TAB> rel_objs = [ ] <TAB> <TAB> for klass in get_models ( ) : <TAB> <TAB> <TAB> for f in klass . _meta . many_to_many : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> rel_objs . append ( RelatedObject ( f . rel . to , klass , f ) ) <TAB> <TAB> self . _all_related_many_to_many_objects = rel_objs <TAB> <TAB> return rel_objs ","if f . rel and self == f . rel . to . _meta : 
","if f . rel and f . rel . to not in self . _all_related_many_to_many_objects :
",59.9,29.11,False
"def state_highstate ( self , state , dirpath ) : <TAB> opts = copy . copy ( self . config ) <TAB> opts [ "" file_roots "" ] = dict ( base = [ dirpath ] ) <TAB> HIGHSTATE = HighState ( opts ) <TAB> HIGHSTATE . push_active ( ) <TAB> try : <TAB> <TAB> high , errors = HIGHSTATE . render_highstate ( state ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> import pprint <TAB> <TAB> <TAB> pprint . pprint ( "" \n "" . join ( errors ) ) <TAB> <TAB> <TAB> pprint . pprint ( high ) <TAB> <TAB> out = HIGHSTATE . state . call_high ( high ) <TAB> <TAB> # pprint.pprint(out) <TAB> finally : <TAB> <TAB> HIGHSTATE . pop_active ( ) ","if errors : 
","if errors :
",78.12,0.0,False
"def _update_target_host ( self , target , target_host ) : <TAB> """"""Update target host."""""" <TAB> target_host = None if target_host == "" "" else target_host <TAB> if not target_host : <TAB> <TAB> for device_type , tgt in target . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> target_host = tgt <TAB> <TAB> <TAB> <TAB> break <TAB> if not target_host : <TAB> <TAB> target_host = "" llvm "" if tvm . runtime . enabled ( "" llvm "" ) else "" stackvm "" <TAB> if isinstance ( target_host , str ) : <TAB> <TAB> target_host = tvm . target . Target ( target_host ) <TAB> return target_host ","if device_type . value == tvm . nd . cpu ( 0 ) . device_type : 
","if device_type == "" device "" :
",26.44,11.17,False
"def __console_writer ( self ) : <TAB> while True : <TAB> <TAB> self . __writer_event . wait ( ) <TAB> <TAB> self . __writer_event . clear ( ) <TAB> <TAB> if self . __console_view : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . log . debug ( "" Writing console view to STDOUT "" ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . console_markup . clear ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . __console_view ) <TAB> <TAB> <TAB> <TAB> sys . stdout . write ( self . console_markup . TOTAL_RESET ) ","if not self . short_only : 
","if self . console_view != "" "" :
",35.47,9.43,False
"def goToPrevMarkedHeadline ( self , event = None ) : <TAB> """"""Select the next marked node."""""" <TAB> c = self <TAB> p = c . p <TAB> if not p : <TAB> <TAB> return <TAB> p . moveToThreadBack ( ) <TAB> wrapped = False <TAB> while 1 : <TAB> <TAB> if p and p . isMarked ( ) : <TAB> <TAB> <TAB> break <TAB> <TAB> elif p : <TAB> <TAB> <TAB> p . moveToThreadBack ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> wrapped = True <TAB> <TAB> <TAB> p = c . rootPosition ( ) <TAB> if not p : <TAB> <TAB> g . blue ( "" done "" ) <TAB> c . treeSelectHelper ( p )<TAB> # Sets focus. ","elif wrapped : 
","elif wrapped :
",78.12,0.0,False
"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB> <TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB> <TAB> <TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB> <TAB> <TAB> <TAB> if vm_details == "" Absent "" : <TAB> <TAB> <TAB> <TAB> <TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB> <TAB> <TAB> if not query_map [ alias ] [ driver ] : <TAB> <TAB> <TAB> <TAB> query_map [ alias ] . pop ( driver ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> query_map . pop ( alias ) <TAB> return query_map ","if not query_map [ alias ] : 
","elif query_map [ alias ] [ alias ] [ "" description "" ] == "" No matching vm "" :
",43.4,21.08,False
"def get_shadows_zip ( filename ) : <TAB> import zipfile <TAB> shadow_pkgs = set ( ) <TAB> with zipfile . ZipFile ( filename ) as lib_zip : <TAB> <TAB> already_test = [ ] <TAB> <TAB> for fname in lib_zip . namelist ( ) : <TAB> <TAB> <TAB> pname , fname = os . path . split ( fname ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if pname not in already_test and "" / "" not in pname : <TAB> <TAB> <TAB> <TAB> already_test . append ( pname ) <TAB> <TAB> <TAB> <TAB> if is_shadowing ( pname ) : <TAB> <TAB> <TAB> <TAB> <TAB> shadow_pkgs . add ( pname ) <TAB> return shadow_pkgs ","if fname or ( pname and fname ) : 
","if not os . path . isfile ( fname ) :
",30.81,15.85,False
"def make_chains ( chains_info ) : <TAB> chains = [ [ ] for _ in chains_info [ 0 ] [ 1 ] ] <TAB> for i , num_ids in enumerate ( chains_info [ : - 1 ] ) : <TAB> <TAB> num , ids = num_ids <TAB> <TAB> for j , ident in enumerate ( ids ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> next_chain_info = chains_info [ i + 1 ] <TAB> <TAB> <TAB> <TAB> previous = next_chain_info [ 1 ] [ j ] <TAB> <TAB> <TAB> <TAB> block = SimpleBlock ( num , ident , previous ) <TAB> <TAB> <TAB> <TAB> chains [ j ] . append ( block ) <TAB> chains = { i : make_generator ( chain ) for i , chain in enumerate ( chains ) } <TAB> return chains ","if ident != "" "" : 
","if j < len ( ids ) :
",27.23,6.57,False
"def filter_input ( mindate , maxdate , files ) : <TAB> mindate = parse ( mindate ) if mindate is not None else datetime . datetime . min <TAB> maxdate = parse ( maxdate ) if maxdate is not None else datetime . datetime . max <TAB> for line in fileinput . input ( files ) : <TAB> <TAB> tweet = json . loads ( line ) <TAB> <TAB> created_at = parse ( tweet [ "" created_at "" ] ) <TAB> <TAB> created_at = created_at . replace ( tzinfo = None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( json . dumps ( tweet ) ) ","if mindate < created_at and maxdate > created_at : 
","if mindate < = created_at < = maxdate :
",31.95,21.02,False
"def get ( self ) : <TAB> """"""If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called."""""" <TAB> if self . _exception is not _NONE : <TAB> <TAB> if self . _exception is None : <TAB> <TAB> <TAB> return self . value <TAB> <TAB> getcurrent ( ) . throw ( * self . _exception )<TAB> # pylint:disable=undefined-variable <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ConcurrentObjectUseError ( <TAB> <TAB> <TAB> <TAB> "" This Waiter is already used by  %r "" % ( self . greenlet , ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . greenlet = getcurrent ( )<TAB> # pylint:disable=undefined-variable <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . hub . switch ( ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> self . greenlet = None ","if self . greenlet is not None : 
","if self . greenlet is not None :
",100.0,100.0,True
"def default_loader ( href , parse , encoding = None ) : <TAB> with open ( href ) as file : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = ElementTree . parse ( file ) . getroot ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data = file . read ( ) <TAB> <TAB> <TAB> if encoding : <TAB> <TAB> <TAB> <TAB> data = data . decode ( encoding ) <TAB> return data ","if parse == "" xml "" : 
","if parse :
",28.89,0.0,False
def is_all_qud ( world ) : <TAB> m = True <TAB> for obj in world : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if obj . nice : <TAB> <TAB> <TAB> <TAB> m = m and True <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> m = m and False <TAB> <TAB> else : <TAB> <TAB> <TAB> m = m and True <TAB> return m ,"if obj . blond : 
","if isinstance ( obj , Qud ) :
",27.8,7.27,False
"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB> <TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> if prefixed : <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) <TAB> <TAB> return <TAB> for region in self . view . sel ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> if prefixed : <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) ","if region . empty ( ) : 
","if region == 0 :
",29.24,15.21,False
"def add_fields ( self , params ) : <TAB> for ( key , val ) in params . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_params = { } <TAB> <TAB> <TAB> for k in val : <TAB> <TAB> <TAB> <TAB> new_params [ "" %s __ %s "" % ( key , k ) ] = val [ k ] <TAB> <TAB> <TAB> self . add_fields ( new_params ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . add_field ( key , val ) ","if isinstance ( val , dict ) : 
","if isinstance ( val , dict ) :
",100.0,100.0,True
"def find_magic ( self , f , pos , magic ) : <TAB> f . seek ( pos ) <TAB> block = f . read ( 32 * 1024 ) <TAB> if len ( block ) < len ( magic ) : <TAB> <TAB> return - 1 <TAB> p = block . find ( magic ) <TAB> while p < 0 : <TAB> <TAB> pos + = len ( block ) - len ( magic ) + 1 <TAB> <TAB> block = block [ 1 - len ( magic ) : ] + f . read ( 32 << 10 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - 1 <TAB> <TAB> p = block . find ( magic ) <TAB> return pos + p ","if len ( block ) == len ( magic ) - 1 : 
","if len ( block ) < 32 :
",52.78,25.56,False
"def check_strings ( self ) : <TAB> """"""Check that all strings have been consumed."""""" <TAB> for i , aList in enumerate ( self . string_tokens ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . trace ( "" warning: line  %s . unused strings "" % i ) <TAB> <TAB> <TAB> for z in aList : <TAB> <TAB> <TAB> <TAB> print ( self . dump_token ( z ) ) ","if aList : 
","if i not in aList :
",34.04,17.97,False
"def get_tokens_unprocessed ( self , text ) : <TAB> from pygments . lexers . _cocoa_builtins import ( <TAB> <TAB> COCOA_INTERFACES , <TAB> <TAB> COCOA_PROTOCOLS , <TAB> <TAB> COCOA_PRIMITIVES , <TAB> ) <TAB> for index , token , value in RegexLexer . get_tokens_unprocessed ( self , text ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> value in COCOA_INTERFACES <TAB> <TAB> <TAB> <TAB> or value in COCOA_PROTOCOLS <TAB> <TAB> <TAB> <TAB> or value in COCOA_PRIMITIVES <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> token = Name . Builtin . Pseudo <TAB> <TAB> yield index , token , value ","if token is Name or token is Name . Class : 
","if token is Name . Builtin :
",51.48,36.34,False
"def key_from_key_value_dict ( key_info ) : <TAB> res = [ ] <TAB> if not "" key_value "" in key_info : <TAB> <TAB> return res <TAB> for value in key_info [ "" key_value "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> e = base64_to_long ( value [ "" rsa_key_value "" ] [ "" exponent "" ] ) <TAB> <TAB> <TAB> m = base64_to_long ( value [ "" rsa_key_value "" ] [ "" modulus "" ] ) <TAB> <TAB> <TAB> key = RSA . construct ( ( m , e ) ) <TAB> <TAB> <TAB> res . append ( key ) <TAB> return res ","if "" rsa_key_value "" in value : 
","if "" rsa_key_value "" in value :
",100.0,100.0,True
"def run ( self , edit ) : <TAB> if not self . has_selection ( ) : <TAB> <TAB> region = sublime . Region ( 0 , self . view . size ( ) ) <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) <TAB> <TAB> return <TAB> for region in self . view . sel ( ) : <TAB> <TAB> if region . empty ( ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> originalBuffer = self . view . substr ( region ) <TAB> <TAB> prefixed = self . prefix ( originalBuffer ) <TAB> <TAB> if prefixed : <TAB> <TAB> <TAB> self . view . replace ( edit , region , prefixed ) ","if prefixed : 
","if prefixed :
",78.12,0.0,False
def finalize ( self ) : <TAB> if self . ct < 1 : <TAB> <TAB> return <TAB> elif self . ct == 1 : <TAB> <TAB> return 0 <TAB> total = ct = 0 <TAB> dtp = None <TAB> while self . heap : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if dtp is None : <TAB> <TAB> <TAB> <TAB> dtp = heapq . heappop ( self . heap ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> dt = heapq . heappop ( self . heap ) <TAB> <TAB> diff = dt - dtp <TAB> <TAB> ct + = 1 <TAB> <TAB> total + = total_seconds ( diff ) <TAB> <TAB> dtp = dt <TAB> return float ( total ) / ct ,"if total == 0 : 
","if total == 0 :
",100.0,100.0,True
"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB> <TAB> self . _log . debug ( "" testing configuration "" ) <TAB> <TAB> verboseflag = "" -Q "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> verboseflag = "" -v "" <TAB> <TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB> <TAB> if p . wait ( ) != 0 : <TAB> <TAB> <TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB> <TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB> <TAB> os . remove ( config_path ) ","if self . _log . isEnabledFor ( logging . DEBUG ) : 
","if sys . platform == "" win32 "" :
",33.35,4.09,False
"def exe ( self , ret ) : <TAB> if not ret : <TAB> <TAB> self . assertEqual ( ret , "" "" ) <TAB> else : <TAB> <TAB> assert os . path . isabs ( ret ) , ret <TAB> <TAB> # Note: os.stat() may return False even if the file is there <TAB> <TAB> # hence we skip the test, see: <TAB> <TAB> # http://stackoverflow.com/questions/3112546/os-path-exists-lies <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert os . path . isfile ( ret ) , ret <TAB> <TAB> <TAB> if hasattr ( os , "" access "" ) and hasattr ( os , "" X_OK "" ) : <TAB> <TAB> <TAB> <TAB> # XXX may fail on OSX <TAB> <TAB> <TAB> <TAB> self . assertTrue ( os . access ( ret , os . X_OK ) ) ","if POSIX : 
","if hasattr ( os , "" stat "" ) :
",29.22,4.99,False
"def _do_cleanup ( sg_name , device_id ) : <TAB> masking_view_list = self . rest . get_masking_views_from_storage_group ( array , sg_name ) <TAB> for masking_view in masking_view_list : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . rest . delete_masking_view ( array , masking_view ) <TAB> <TAB> <TAB> self . rest . remove_vol_from_sg ( array , sg_name , device_id , extra_specs ) <TAB> <TAB> <TAB> self . rest . delete_volume ( array , device_id ) <TAB> <TAB> <TAB> self . rest . delete_storage_group ( array , sg_name ) ","if "" STG- "" in masking_view : 
","if masking_view . get ( "" device_id "" ) == device_id :
",33.07,9.31,False
"def hide_tooltip_if_necessary ( self , key ) : <TAB> """"""Hide calltip when necessary"""""" <TAB> try : <TAB> <TAB> calltip_char = self . get_character ( self . calltip_position ) <TAB> <TAB> before = self . is_cursor_before ( self . calltip_position , char_offset = 1 ) <TAB> <TAB> other = key in ( Qt . Key_ParenRight , Qt . Key_Period , Qt . Key_Tab ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> QToolTip . hideText ( ) <TAB> except ( IndexError , TypeError ) : <TAB> <TAB> QToolTip . hideText ( ) ","if calltip_char not in ( "" ? "" , "" ( "" ) or before or other : 
","if before and other == calltip_char :
",25.64,7.1,False
"def list_tags_for_stream ( self , stream_name , exclusive_start_tag_key = None , limit = None ) : <TAB> stream = self . describe_stream ( stream_name ) <TAB> tags = [ ] <TAB> result = { "" HasMoreTags "" : False , "" Tags "" : tags } <TAB> for key , val in sorted ( stream . tags . items ( ) , key = lambda x : x [ 0 ] ) : <TAB> <TAB> if limit and len ( tags ) > = limit : <TAB> <TAB> <TAB> result [ "" HasMoreTags "" ] = True <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> tags . append ( { "" Key "" : key , "" Value "" : val } ) <TAB> return result ","if exclusive_start_tag_key and key < exclusive_start_tag_key : 
","if exclusive_start_tag_key and key == exclusive_start_tag_key :
",74.71,80.32,False
"def parametrize_function_name ( request , function_name ) : <TAB> suffixes = [ ] <TAB> if "" parametrize "" in request . keywords : <TAB> <TAB> argnames = request . keywords [ "" parametrize "" ] . args [ : : 2 ] <TAB> <TAB> argnames = [ x . strip ( ) for names in argnames for x in names . split ( "" , "" ) ] <TAB> <TAB> for name in argnames : <TAB> <TAB> <TAB> value = request . getfuncargvalue ( name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value . __name__ <TAB> <TAB> <TAB> suffixes . append ( "" {} = {} "" . format ( name , value ) ) <TAB> return "" + "" . join ( [ function_name ] + suffixes ) ","if inspect . isclass ( value ) : 
","if hasattr ( value , "" __name__ "" ) :
",28.97,8.49,False
"def add_entities ( self , positions ) : <TAB> e1 = EntityFactory ( ) <TAB> for p in positions : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> start , length = p <TAB> <TAB> else : <TAB> <TAB> <TAB> start , length = p , 1 <TAB> <TAB> EntityOccurrenceFactory ( <TAB> <TAB> <TAB> document = self . doc , <TAB> <TAB> <TAB> entity = e1 , <TAB> <TAB> <TAB> offset = start , <TAB> <TAB> <TAB> offset_end = start + length , <TAB> <TAB> <TAB> alias = "" AB "" , <TAB> <TAB> ) ","if isinstance ( p , tuple ) : 
","if isinstance ( p , ( tuple , list ) ) :
",49.79,37.7,False
"def transform_value ( value ) : <TAB> if isinstance ( value , collections . MutableMapping ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return DBRef ( value [ "" _ns "" ] , transform_value ( value [ "" _id "" ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return transform_dict ( SON ( value ) ) <TAB> elif isinstance ( value , list ) : <TAB> <TAB> return [ transform_value ( v ) for v in value ] <TAB> return value ","if "" _id "" in value and "" _ns "" in value : 
","if "" _ns "" in value and "" _id "" in value :
",93.5,95.54,False
"def remove ( self , items ) : <TAB> """"""Remove messages from lease management."""""" <TAB> with self . _add_remove_lock : <TAB> <TAB> # Remove the ack ID from lease management, and decrement the <TAB> <TAB> # byte counter. <TAB> <TAB> for item in items : <TAB> <TAB> <TAB> if self . _leased_messages . pop ( item . ack_id , None ) is not None : <TAB> <TAB> <TAB> <TAB> self . _bytes - = item . byte_size <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> _LOGGER . debug ( "" Item  %s  was not managed. "" , item . ack_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _LOGGER . debug ( "" Bytes was unexpectedly negative:  %d "" , self . _bytes ) <TAB> <TAB> <TAB> self . _bytes = 0 ","if self . _bytes < 0 : 
","if self . _bytes < 0 :
",100.0,100.0,True
"def parse_hgsub ( lines ) : <TAB> """"""Fills OrderedDict with hgsub file content passed as list of lines"""""" <TAB> rv = OrderedDict ( ) <TAB> for l in lines : <TAB> <TAB> ls = l . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> name , value = l . split ( "" = "" , 1 ) <TAB> <TAB> rv [ name . strip ( ) ] = value . strip ( ) <TAB> return rv ","if not ls or ls [ 0 ] == "" # "" : 
","if not ls or "" = "" not in ls :
",44.1,23.51,False
"def del_ ( self , key ) : <TAB> initial_hash = hash_ = self . hash ( key ) <TAB> while True : <TAB> <TAB> if self . _keys [ hash_ ] is self . _empty : <TAB> <TAB> <TAB> # That key was never assigned <TAB> <TAB> <TAB> return None <TAB> <TAB> elif self . _keys [ hash_ ] == key : <TAB> <TAB> <TAB> # key found, assign with deleted sentinel <TAB> <TAB> <TAB> self . _keys [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _values [ hash_ ] = self . _deleted <TAB> <TAB> <TAB> self . _len - = 1 <TAB> <TAB> <TAB> return <TAB> <TAB> hash_ = self . _rehash ( hash_ ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # table is full and wrapped around <TAB> <TAB> <TAB> return None ","if initial_hash == hash_ : 
","if hash_ == initial_hash :
",54.02,27.78,False
"def atom ( token , no_symbol = False ) : <TAB> try : <TAB> <TAB> return int ( token ) <TAB> except ValueError : <TAB> <TAB> try : <TAB> <TAB> <TAB> return float ( token ) <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return token [ 1 : - 1 ] <TAB> <TAB> <TAB> elif no_symbol : <TAB> <TAB> <TAB> <TAB> return token <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return Symbol ( token ) ","if token . startswith ( "" ' "" ) or token . startswith ( ' "" ' ) : 
","if token . startswith ( "" 0 "" ) and len ( token ) > 1 :
",46.11,31.18,False
"def __Suffix_Noun_Step1b ( self , token ) : <TAB> for suffix in self . __suffix_noun_step1b : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> token = token [ : - 1 ] <TAB> <TAB> <TAB> self . suffixe_noun_step1b_success = True <TAB> <TAB> <TAB> break <TAB> return token ","if token . endswith ( suffix ) and len ( token ) > 5 : 
","if token . endswith ( suffix ) :
",55.46,36.24,False
"def _guardAgainstUnicode ( self , data ) : <TAB> # Only accept byte strings or ascii unicode values, otherwise <TAB> # there is no way to correctly decode the data into bytes. <TAB> if _pythonMajorVersion < 3 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data = data . encode ( "" utf8 "" ) <TAB> else : <TAB> <TAB> if isinstance ( data , str ) : <TAB> <TAB> <TAB> # Only accept ascii unicode values. <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> return data . encode ( "" ascii "" ) <TAB> <TAB> <TAB> except UnicodeEncodeError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> raise ValueError ( "" pyDes can only work with encoded strings, not Unicode. "" ) <TAB> return data ","if isinstance ( data , unicode ) : 
","if isinstance ( data , bytes ) :
",79.9,59.46,False
"def populate_resource_parameters ( self , tool_source ) : <TAB> root = getattr ( tool_source , "" root "" , None ) <TAB> if ( <TAB> <TAB> root is not None <TAB> <TAB> and hasattr ( self . app , "" job_config "" ) <TAB> <TAB> and hasattr ( self . app . job_config , "" get_tool_resource_xml "" ) <TAB> ) : <TAB> <TAB> resource_xml = self . app . job_config . get_tool_resource_xml ( <TAB> <TAB> <TAB> root . get ( "" id "" ) , self . tool_type <TAB> <TAB> ) <TAB> <TAB> if resource_xml is not None : <TAB> <TAB> <TAB> inputs = root . find ( "" inputs "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> inputs = parse_xml_string ( "" <inputs/> "" ) <TAB> <TAB> <TAB> <TAB> root . append ( inputs ) <TAB> <TAB> <TAB> inputs . append ( resource_xml ) ","if inputs is None : 
","if inputs is None :
",100.0,100.0,True
"def test_arguments_regex ( self ) : <TAB> argument_matches = ( <TAB> <TAB> ( "" pip=1.1 "" , ( "" pip "" , "" 1.1 "" ) ) , <TAB> <TAB> ( "" pip==1.1 "" , None ) , <TAB> <TAB> ( "" pip=1.2=1 "" , ( "" pip "" , "" 1.2=1 "" ) ) , <TAB> ) <TAB> for argument , match in argument_matches : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsNone ( salt . utils . args . KWARG_REGEX . match ( argument ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> <TAB> salt . utils . args . KWARG_REGEX . match ( argument ) . groups ( ) , match <TAB> <TAB> <TAB> ) ","if match is None : 
","if match is None :
",100.0,100.0,True
"def _get_sidebar_selected ( self ) : <TAB> sidebar_selected = None <TAB> if self . businessline_id : <TAB> <TAB> sidebar_selected = "" bl_ %s "" % self . businessline_id <TAB> <TAB> if self . service_id : <TAB> <TAB> <TAB> sidebar_selected + = "" _s_ %s "" % self . service_id <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sidebar_selected + = "" _env_ %s "" % self . environment_id <TAB> return sidebar_selected ","if self . environment_id : 
","if self . environment_id :
",100.0,100.0,True
"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if ip . venture is not None : <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> if ip . device . venture is not None : <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result ","if ip . device is not None : 
","if ip . device is not None :
",100.0,100.0,True
"def apply ( self , db , person ) : <TAB> for family_handle in person . get_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> if family : <TAB> <TAB> <TAB> for event_ref in family . get_event_ref_list ( ) : <TAB> <TAB> <TAB> <TAB> if event_ref : <TAB> <TAB> <TAB> <TAB> <TAB> event = db . get_event_from_handle ( event_ref . ref ) <TAB> <TAB> <TAB> <TAB> <TAB> if not event . get_place_handle ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not event . get_date_object ( ) : 
","if not event . get_place_handle ( ) . startswith ( self . place_handle ) :
",54.37,27.65,False
"def killIfDead ( ) : <TAB> if not self . _isalive : <TAB> <TAB> self . log . debug ( <TAB> <TAB> <TAB> "" WampLongPoll: killing inactive WAMP session with transport  ' {0} ' "" . format ( <TAB> <TAB> <TAB> <TAB> self . _transport_id <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> self . onClose ( False , 5000 , "" session inactive "" ) <TAB> <TAB> self . _receive . _kill ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _parent . _transports [ self . _transport_id ] <TAB> else : <TAB> <TAB> self . log . debug ( <TAB> <TAB> <TAB> "" WampLongPoll: transport  ' {0} '  is still alive "" . format ( self . _transport_id ) <TAB> <TAB> ) <TAB> <TAB> self . _isalive = False <TAB> <TAB> self . reactor . callLater ( killAfter , killIfDead ) ","if self . _transport_id in self . _parent . _transports : 
","if self . _transport_id in self . _parent . _transports :
",100.0,100.0,True
"def offsets ( self ) : <TAB> offsets = { } <TAB> offset_so_far = 0 <TAB> for name , ty in self . fields . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> l . warning ( <TAB> <TAB> <TAB> <TAB> "" Found a bottom field in struct  %s . Ignore and increment the offset using the default  "" <TAB> <TAB> <TAB> <TAB> "" element size. "" , <TAB> <TAB> <TAB> <TAB> self . name , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if not self . _pack : <TAB> <TAB> <TAB> align = ty . alignment <TAB> <TAB> <TAB> if offset_so_far % align != 0 : <TAB> <TAB> <TAB> <TAB> offset_so_far + = align - offset_so_far % align <TAB> <TAB> offsets [ name ] = offset_so_far <TAB> <TAB> offset_so_far + = ty . size / / self . _arch . byte_width <TAB> return offsets ","if isinstance ( ty , SimTypeBottom ) : 
","if ty . offset == 0 :
",26.96,7.27,False
"def get_override_css ( self ) : <TAB> """"""handls allow_css_overrides setting."""""" <TAB> if self . settings . get ( "" allow_css_overrides "" ) : <TAB> <TAB> filename = self . view . file_name ( ) <TAB> <TAB> filetypes = self . settings . get ( "" markdown_filetypes "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for filetype in filetypes : <TAB> <TAB> <TAB> <TAB> if filename . endswith ( filetype ) : <TAB> <TAB> <TAB> <TAB> <TAB> css_filename = filename . rpartition ( filetype ) [ 0 ] + "" .css "" <TAB> <TAB> <TAB> <TAB> <TAB> if os . path . isfile ( css_filename ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return u "" <style> %s </style> "" % load_utf8 ( css_filename ) <TAB> return "" "" ","if filename and filetypes : 
","if filetypes :
",31.47,0.0,False
"def setFullCSSSource ( self , fullsrc , inline = False ) : <TAB> self . fullsrc = fullsrc <TAB> if type ( self . fullsrc ) == six . binary_type : <TAB> <TAB> self . fullsrc = six . text_type ( self . fullsrc , "" utf-8 "" ) <TAB> if inline : <TAB> <TAB> self . inline = inline <TAB> if self . fullsrc : <TAB> <TAB> self . srcFullIdx = self . fullsrc . find ( self . src ) <TAB> <TAB> if self . srcFullIdx < 0 : <TAB> <TAB> <TAB> del self . srcFullIdx <TAB> <TAB> self . ctxsrcFullIdx = self . fullsrc . find ( self . ctxsrc ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . ctxsrcFullIdx ","if self . ctxsrcFullIdx < 0 : 
","if self . ctxsrcFullIdx < 0 :
",100.0,100.0,True
"def title ( self ) : <TAB> ret = theme [ "" title "" ] <TAB> if isinstance ( self . name , six . string_types ) : <TAB> <TAB> width = self . statwidth ( ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> ret + self . name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) + theme [ "" default "" ] <TAB> <TAB> ) <TAB> for i , name in enumerate ( self . name ) : <TAB> <TAB> width = self . colwidth ( ) <TAB> <TAB> ret = ret + name [ 0 : width ] . center ( width ) . replace ( "" "" , "" - "" ) <TAB> <TAB> if i + 1 != len ( self . vars ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> ret = ret + theme [ "" frame "" ] + char [ "" dash "" ] + theme [ "" title "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret = ret + char [ "" space "" ] <TAB> return ret ","if op . color : 
","if self . vars [ i ] == "" frame "" :
",35.78,4.07,False
"def _get_requested_databases ( self ) : <TAB> """"""Returns a list of databases requested, not including ignored dbs"""""" <TAB> requested_databases = [ ] <TAB> if ( self . _requested_namespaces is not None ) and ( self . _requested_namespaces != [ ] ) : <TAB> <TAB> for requested_namespace in self . _requested_namespaces : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return [ ] <TAB> <TAB> <TAB> elif requested_namespace [ 0 ] not in IGNORE_DBS : <TAB> <TAB> <TAB> <TAB> requested_databases . append ( requested_namespace [ 0 ] ) <TAB> return requested_databases ","if requested_namespace [ 0 ] is "" * "" : 
","if requested_namespace [ 0 ] in IGNORE_DBS :
",50.62,53.32,False
"def add_channels ( cls , voucher , add_channels ) : <TAB> for add_channel in add_channels : <TAB> <TAB> channel = add_channel [ "" channel "" ] <TAB> <TAB> defaults = { "" currency "" : channel . currency_code } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> defaults [ "" discount_value "" ] = add_channel . get ( "" discount_value "" ) <TAB> <TAB> if "" min_amount_spent "" in add_channel . keys ( ) : <TAB> <TAB> <TAB> defaults [ "" min_spent_amount "" ] = add_channel . get ( "" min_amount_spent "" , None ) <TAB> <TAB> models . VoucherChannelListing . objects . update_or_create ( <TAB> <TAB> <TAB> voucher = voucher , <TAB> <TAB> <TAB> channel = channel , <TAB> <TAB> <TAB> defaults = defaults , <TAB> <TAB> ) ","if "" discount_value "" in add_channel . keys ( ) : 
","if "" discount_value "" in add_channel . keys ( ) :
",100.0,100.0,True
"def read_xml ( path ) : <TAB> with tf . gfile . GFile ( path ) as f : <TAB> <TAB> root = etree . fromstring ( f . read ( ) ) <TAB> annotations = { } <TAB> for node in root . getchildren ( ) : <TAB> <TAB> key , val = node2dict ( node ) <TAB> <TAB> # If `key` is object, it's actually a list. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> annotations . setdefault ( key , [ ] ) . append ( val ) <TAB> <TAB> else : <TAB> <TAB> <TAB> annotations [ key ] = val <TAB> return annotations ","if key == "" object "" : 
","if isinstance ( key , dict ) :
",27.11,7.27,False
"def get_ip_info ( ipaddress ) : <TAB> """"""Returns device information by IP address"""""" <TAB> result = { } <TAB> try : <TAB> <TAB> ip = IPAddress . objects . select_related ( ) . get ( address = ipaddress ) <TAB> except IPAddress . DoesNotExist : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . venture . id <TAB> <TAB> if ip . device is not None : <TAB> <TAB> <TAB> result [ "" device_id "" ] = ip . device . id <TAB> <TAB> <TAB> if ip . device . venture is not None : <TAB> <TAB> <TAB> <TAB> result [ "" venture_id "" ] = ip . device . venture . id <TAB> return result ","if ip . venture is not None : 
","if ip . venture is not None :
",100.0,100.0,True
"def test_large_headers ( self ) : <TAB> with ExpectLog ( gen_log , "" Unsatisfiable read "" , required = False ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> self . fetch ( "" / "" , headers = { "" X-Filler "" : "" a "" * 1000 } , raise_error = True ) <TAB> <TAB> <TAB> self . fail ( "" did not raise expected exception "" ) <TAB> <TAB> except HTTPError as e : <TAB> <TAB> <TAB> # 431 is ""Request Header Fields Too Large"", defined in RFC <TAB> <TAB> <TAB> # 6585. However, many implementations just close the <TAB> <TAB> <TAB> # connection in this case, resulting in a missing response. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertIn ( e . response . code , ( 431 , 599 ) ) ","if e . response is not None : 
","if e . response and e . response . code != 599 :
",43.16,18.8,False
"def validate_reserved_serial_no_consumption ( self ) : <TAB> for item in self . items : <TAB> <TAB> if item . s_warehouse and not item . t_warehouse and item . serial_no : <TAB> <TAB> <TAB> for sr in get_serial_nos ( item . serial_no ) : <TAB> <TAB> <TAB> <TAB> sales_order = frappe . db . get_value ( "" Serial No "" , sr , "" sales_order "" ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> msg = _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" (Serial No:  {0} ) cannot be consumed as it ' s reserverd to fullfill Sales Order  {1} . "" <TAB> <TAB> <TAB> <TAB> <TAB> ) . format ( sr , sales_order ) <TAB> <TAB> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Item  {0} {1} "" ) . format ( item . item_code , msg ) ) ","if sales_order : 
","if sales_order :
",78.12,100.0,True
"def force_decode ( string , encoding ) : <TAB> if isinstance ( string , str ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> string = string . decode ( encoding ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> # try decoding with utf-8, should only work for real UTF-8 <TAB> <TAB> <TAB> <TAB> string = string . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> except UnicodeError : <TAB> <TAB> <TAB> <TAB> # last resort -- can't fail <TAB> <TAB> <TAB> <TAB> string = string . decode ( "" latin1 "" ) <TAB> return string ","if encoding : 
","if encoding :
",78.12,0.0,False
"def _add_cs ( master_cs , sub_cs , prefix , delimiter = "" . "" , parent_hp = None ) : <TAB> new_parameters = [ ] <TAB> for hp in sub_cs . get_hyperparameters ( ) : <TAB> <TAB> new_parameter = copy . deepcopy ( hp ) <TAB> <TAB> # Allow for an empty top-level parameter <TAB> <TAB> if new_parameter . name == "" "" : <TAB> <TAB> <TAB> new_parameter . name = prefix <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_parameter . name = "" {} {} {} "" . format ( prefix , SPLITTER , new_parameter . name ) <TAB> <TAB> new_parameters . append ( new_parameter ) <TAB> for hp in new_parameters : <TAB> <TAB> _add_hp ( master_cs , hp ) ","elif not prefix == "" "" : 
","if not new_parameter . name . startswith ( delimiter ) :
",26.63,3.67,False
"def __call__ ( self , * args , * * kwargs ) : <TAB> if self . log_file is not None : <TAB> <TAB> kwargs [ "" file "" ] = self . log_file <TAB> <TAB> print ( * args , * * kwargs ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # get immediate feedback <TAB> <TAB> <TAB> self . log_file . flush ( ) <TAB> elif self . log_func is not None : <TAB> <TAB> self . log_func ( * args , * * kwargs ) ","if hasattr ( self . log_file , "" flush "" ) : 
","if self . log_file . is_flushed :
",34.02,29.05,False
"def df_index_expr ( self , length_expr = None , as_range = False ) : <TAB> """"""Generate expression to get or create index of DF"""""" <TAB> if isinstance ( self . index , types . NoneType ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> length_expr = df_length_expr ( self ) <TAB> <TAB> if as_range : <TAB> <TAB> <TAB> return f "" range( { length_expr } ) "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return f "" numpy.arange( { length_expr } ) "" <TAB> return "" self._index "" ","if length_expr is None : 
","if length_expr is None :
",100.0,100.0,True
"def _setWeight ( self , value ) : <TAB> if value is None : <TAB> <TAB> self . _fontWeight = None <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TextFormatException ( f "" Not a supported fontWeight:  { value } "" ) <TAB> <TAB> self . _fontWeight = value . lower ( ) ","if value . lower ( ) not in ( "" normal "" , "" bold "" ) : 
","if value . lower ( ) not in ( "" normal "" , "" normal "" , "" normal "" , "" normal "" ) :
",75.22,56.46,False
"def _test_configuration ( self ) : <TAB> config_path = self . _write_config ( ) <TAB> try : <TAB> <TAB> self . _log . debug ( "" testing configuration "" ) <TAB> <TAB> verboseflag = "" -Q "" <TAB> <TAB> if self . _log . isEnabledFor ( logging . DEBUG ) : <TAB> <TAB> <TAB> verboseflag = "" -v "" <TAB> <TAB> p = subprocess . Popen ( [ self . PATH_SLAPTEST , verboseflag , "" -f "" , config_path ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( "" configuration test failed "" ) <TAB> <TAB> self . _log . debug ( "" configuration seems ok "" ) <TAB> finally : <TAB> <TAB> os . remove ( config_path ) ","if p . wait ( ) != 0 : 
","if p . returncode != 0 :
",39.5,38.94,False
"def filter_queryset ( self , request , queryset , view ) : <TAB> kwargs = { } <TAB> for field in view . filterset_fields : <TAB> <TAB> value = request . GET . get ( field ) <TAB> <TAB> if not value : <TAB> <TAB> <TAB> continue <TAB> <TAB> if field == "" node_id "" : <TAB> <TAB> <TAB> value = get_object_or_none ( Node , pk = value ) <TAB> <TAB> <TAB> kwargs [ "" node "" ] = value <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> field = "" asset "" <TAB> <TAB> kwargs [ field ] = value <TAB> if kwargs : <TAB> <TAB> queryset = queryset . filter ( * * kwargs ) <TAB> logger . debug ( "" Filter  {} "" . format ( kwargs ) ) <TAB> return queryset ","elif field == "" asset_id "" : 
","if field == "" asset_id "" :
",75.79,88.01,False
"def _find_closing_brace ( string , start_pos ) : <TAB> """"""Finds the corresponding closing brace after start_pos."""""" <TAB> bracks_open = 1 <TAB> for idx , char in enumerate ( string [ start_pos : ] ) : <TAB> <TAB> if char == "" ( "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> bracks_open + = 1 <TAB> <TAB> elif char == "" ) "" : <TAB> <TAB> <TAB> if string [ idx + start_pos - 1 ] != "" \\ "" : <TAB> <TAB> <TAB> <TAB> bracks_open - = 1 <TAB> <TAB> <TAB> if not bracks_open : <TAB> <TAB> <TAB> <TAB> return start_pos + idx + 1 ","if string [ idx + start_pos - 1 ] != "" \\ "" : 
","if string [ idx + start_pos - 1 ] != "" \\ "" :
",100.0,100.0,True
"def _set_hostport ( self , host , port ) : <TAB> if port is None : <TAB> <TAB> i = host . rfind ( "" : "" ) <TAB> <TAB> j = host . rfind ( "" ] "" )<TAB> # ipv6 addresses have [...] <TAB> <TAB> if i > j : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> port = int ( host [ i + 1 : ] ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> raise InvalidURL ( "" nonnumeric port:  ' %s ' "" % host [ i + 1 : ] ) <TAB> <TAB> <TAB> host = host [ : i ] <TAB> <TAB> else : <TAB> <TAB> <TAB> port = self . default_port <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> host = host [ 1 : - 1 ] <TAB> self . host = host <TAB> self . port = port ","if host and host [ 0 ] == "" [ "" and host [ - 1 ] == "" ] "" : 
","if host [ - 1 ] == "" : "" :
",50.07,26.01,False
"def __getstate__ ( self ) : <TAB> state = { } <TAB> for cls in type ( self ) . mro ( ) : <TAB> <TAB> cls_slots = getattr ( cls , "" __slots__ "" , ( ) ) <TAB> <TAB> for slot in cls_slots : <TAB> <TAB> <TAB> if slot != "" __weakref__ "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> state [ slot ] = getattr ( self , slot ) <TAB> state [ "" _cookiejar_cookies "" ] = list ( self . cookiejar ) <TAB> del state [ "" cookiejar "" ] <TAB> return state ","if hasattr ( self , slot ) : 
","if hasattr ( self , slot ) :
",100.0,100.0,True
"def _evp_pkey_from_der_traditional_key ( self , bio_data , password ) : <TAB> key = self . _lib . d2i_PrivateKey_bio ( bio_data . bio , self . _ffi . NULL ) <TAB> if key != self . _ffi . NULL : <TAB> <TAB> key = self . _ffi . gc ( key , self . _lib . EVP_PKEY_free ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( "" Password was given but private key is not encrypted. "" ) <TAB> <TAB> return key <TAB> else : <TAB> <TAB> self . _consume_errors ( ) <TAB> <TAB> return None ","if password is not None : 
","if password != key . get ( "" password "" ) :
",28.13,6.84,False
"def is_special ( s , i , directive ) : <TAB> """"""Return True if the body text contains the @ directive."""""" <TAB> # j = skip_line(s,i) ; trace(s[i:j],':',directive) <TAB> assert directive and directive [ 0 ] == "" @ "" <TAB> # 10/23/02: all directives except @others must start the line. <TAB> skip_flag = directive in ( "" @others "" , "" @all "" ) <TAB> while i < len ( s ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True , i <TAB> <TAB> else : <TAB> <TAB> <TAB> i = skip_line ( s , i ) <TAB> <TAB> <TAB> if skip_flag : <TAB> <TAB> <TAB> <TAB> i = skip_ws ( s , i ) <TAB> return False , - 1 ","if match_word ( s , i , directive ) : 
","if s [ i ] == directive [ 0 ] :
",26.54,5.06,False
"def _decorator ( coro_func ) : <TAB> fut = asyncio . ensure_future ( coro_func ( ) ) <TAB> self . _tests . append ( ( coro_func . __name__ , fut ) ) <TAB> if timeout_sec is not None : <TAB> <TAB> timeout_at = self . _loop . time ( ) + timeout_sec <TAB> <TAB> handle = self . MASTER_LOOP . call_at ( <TAB> <TAB> <TAB> timeout_at , self . _set_exception_if_not_done , fut , asyncio . TimeoutError ( ) <TAB> <TAB> ) <TAB> <TAB> fut . add_done_callback ( lambda * args : handle . cancel ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _global_timeout_at = timeout_at <TAB> return coro_func ","if timeout_at > self . _global_timeout_at : 
","if self . _global_timeout_at is None :
",40.7,54.89,False
"def _load ( self , db , owner ) : <TAB> self . __init ( owner ) <TAB> db_result = db ( <TAB> <TAB> "" SELECT ship_id, state_id FROM ai_combat_ship WHERE owner_id = ? "" , <TAB> <TAB> self . owner . worldid , <TAB> ) <TAB> for ( <TAB> <TAB> ship_id , <TAB> <TAB> state_id , <TAB> ) in db_result : <TAB> <TAB> ship = WorldObject . get_object_by_id ( ship_id ) <TAB> <TAB> state = self . shipStates [ state_id ] <TAB> <TAB> # add move callbacks corresponding to given state <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ship . add_move_callback ( Callback ( BehaviorMoveCallback . _arrived , ship ) ) <TAB> <TAB> self . add_new_unit ( ship , state ) ","if state == self . shipStates . moving : 
","if state == BehaviorMoveCallback . _arrived :
",37.05,29.56,False
"def addError ( self , test , err ) : <TAB> if err [ 0 ] is SkipTest : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . stream . writeln ( str ( err [ 1 ] ) ) <TAB> <TAB> elif self . dots : <TAB> <TAB> <TAB> self . stream . write ( "" s "" ) <TAB> <TAB> <TAB> self . stream . flush ( ) <TAB> <TAB> return <TAB> _org_AddError ( self , test , err ) ","if self . showAll : 
","if self . verbose :
",64.48,42.73,False
"def _construct ( self , node ) : <TAB> self . flatten_mapping ( node ) <TAB> ret = self . construct_pairs ( node ) <TAB> keys = [ d [ 0 ] for d in ret ] <TAB> keys_sorted = sorted ( keys , key = _natsort_key ) <TAB> for key in keys : <TAB> <TAB> expected = keys_sorted . pop ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ConstructorError ( <TAB> <TAB> <TAB> <TAB> None , <TAB> <TAB> <TAB> <TAB> None , <TAB> <TAB> <TAB> <TAB> "" keys out of order:  "" <TAB> <TAB> <TAB> <TAB> "" expected  {}  got  {}  at  {} "" . format ( expected , key , node . start_mark ) , <TAB> <TAB> <TAB> ) <TAB> return dict ( ret ) ","if key != expected : 
","if expected != key :
",54.02,21.36,False
"def sample_pos_items_for_u ( u , num ) : <TAB> # sample num pos items for u-th user <TAB> pos_items = self . train_items [ u ] <TAB> n_pos_items = len ( pos_items ) <TAB> pos_batch = [ ] <TAB> while True : <TAB> <TAB> if len ( pos_batch ) == num : <TAB> <TAB> <TAB> break <TAB> <TAB> pos_id = np . random . randint ( low = 0 , high = n_pos_items , size = 1 ) [ 0 ] <TAB> <TAB> pos_i_id = pos_items [ pos_id ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pos_batch . append ( pos_i_id ) <TAB> return pos_batch ","if pos_i_id not in pos_batch : 
","if pos_i_id not in self . train_items :
",54.25,54.37,False
"def _get_id ( self , type , id ) : <TAB> fields = id . split ( "" : "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , fields [ - 2 ] , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] <TAB> fields = id . split ( "" / "" ) <TAB> if len ( fields ) > = 3 : <TAB> <TAB> itype = fields [ - 2 ] <TAB> <TAB> if type != itype : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Expected id of type  %s  but found type  %s %s "" , type , itype , id <TAB> <TAB> <TAB> ) <TAB> <TAB> return fields [ - 1 ] . split ( "" ? "" ) [ 0 ] <TAB> return id ","if type != fields [ - 2 ] : 
","if type != fields [ - 2 ] :
",100.0,100.0,True
"def uninstall_environments ( self , environments ) : <TAB> environments = [ <TAB> <TAB> env <TAB> <TAB> if not env . startswith ( self . conda_context . envs_path ) <TAB> <TAB> else os . path . basename ( env ) <TAB> <TAB> for env in environments <TAB> ] <TAB> return_codes = [ self . conda_context . exec_remove ( [ env ] ) for env in environments ] <TAB> final_return_code = 0 <TAB> for env , return_code in zip ( environments , return_codes ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . debug ( "" Conda environment  ' %s '  successfully removed. "" % env ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . debug ( "" Conda environment  ' %s '  could not be removed. "" % env ) <TAB> <TAB> <TAB> final_return_code = return_code <TAB> return final_return_code ","if return_code == 0 : 
","if return_code == 0 :
",100.0,100.0,True
"def _add_hit_offset ( self , context_list , string_name , original_offset , value ) : <TAB> for context in context_list : <TAB> <TAB> hits_by_context_dict = self . hits_by_context . setdefault ( context , { } ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hits_by_context_dict [ string_name ] = ( <TAB> <TAB> <TAB> <TAB> original_offset , <TAB> <TAB> <TAB> <TAB> value . encode ( "" base64 "" ) , <TAB> <TAB> <TAB> ) ","if string_name not in hits_by_context_dict : 
","if string_name not in hits_by_context_dict :
",100.0,100.0,True
"def detab ( self , text , length = None ) : <TAB> """"""Remove a tab from the front of each line of the given text."""""" <TAB> if length is None : <TAB> <TAB> length = self . tab_length <TAB> newtext = [ ] <TAB> lines = text . split ( "" \n "" ) <TAB> for line in lines : <TAB> <TAB> if line . startswith ( "" "" * length ) : <TAB> <TAB> <TAB> newtext . append ( line [ length : ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> newtext . append ( "" "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return "" \n "" . join ( newtext ) , "" \n "" . join ( lines [ len ( newtext ) : ] ) ","elif not line . strip ( ) : 
","elif line . startswith ( "" "" * length ) :
",32.33,11.73,False
"def dump ( self ) : <TAB> print ( self . package_name ) <TAB> for package , value in self . entries : <TAB> <TAB> print ( str ( package . version ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( ""<TAB>  [FILTERED]"" ) <TAB> <TAB> elif isinstance ( value , list ) : <TAB> <TAB> <TAB> variants = value <TAB> <TAB> <TAB> for variant in variants : <TAB> <TAB> <TAB> <TAB> print ( ""<TAB>  %s "" % str ( variant ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( ""<TAB>  %s "" % str ( package ) ) ","if value is None : 
","if value is None :
",100.0,100.0,True
"def __lexical_scope ( * args , * * kwargs ) : <TAB> try : <TAB> <TAB> scope = Scope ( quasi ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> binding_name_set_stack [ - 1 ] . add_child ( scope ) <TAB> <TAB> binding_name_set_stack . append ( scope ) <TAB> <TAB> return func ( * args , * * kwargs ) <TAB> finally : <TAB> <TAB> if binding_name_set_stack [ - 1 ] is scope : <TAB> <TAB> <TAB> binding_name_set_stack . pop ( ) ","if quasi : 
","if not binding_name_set_stack [ - 1 ] . is_child ( scope ) :
",29.06,2.16,False
"def getnotes ( self , origin = None ) : <TAB> if origin is None : <TAB> <TAB> result = self . translator_comments <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> result + = "" \n "" + self . developer_comments <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> result = self . developer_comments <TAB> <TAB> return result <TAB> elif origin == "" translator "" : <TAB> <TAB> return self . translator_comments <TAB> elif origin in ( "" programmer "" , "" developer "" , "" source code "" ) : <TAB> <TAB> return self . developer_comments <TAB> else : <TAB> <TAB> raise ValueError ( "" Comment type not valid "" ) ","if self . developer_comments : 
","if self . developer_comments :
",100.0,100.0,True
"def fix_datetime_fields ( data : TableData , table : TableName ) - > None : <TAB> for item in data [ table ] : <TAB> <TAB> for field_name in DATE_FIELDS [ table ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item [ field_name ] = datetime . datetime . fromtimestamp ( <TAB> <TAB> <TAB> <TAB> <TAB> item [ field_name ] , tz = datetime . timezone . utc <TAB> <TAB> <TAB> <TAB> ) ","if item [ field_name ] is not None : 
","if field_name in item :
",26.63,16.42,False
"def _check_for_cart_error ( cart ) : <TAB> if cart . _safe_get_element ( "" Cart.Request.Errors "" ) is not None : <TAB> <TAB> error = cart . _safe_get_element ( "" Cart.Request.Errors.Error.Code "" ) . text <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise CartInfoMismatchException ( <TAB> <TAB> <TAB> <TAB> "" CartGet failed: AWS.ECommerceService.CartInfoMismatch  "" <TAB> <TAB> <TAB> <TAB> "" make sure AssociateTag, CartId and HMAC are correct  "" <TAB> <TAB> <TAB> <TAB> "" (dont use URLEncodedHMAC!!!) "" <TAB> <TAB> <TAB> ) <TAB> <TAB> raise CartException ( "" CartGet failed:  "" + error ) ","if error == "" AWS.ECommerceService.CartInfoMismatch "" : 
","if error . startswith ( "" Invalid CartInfo. "" ) :
",34.77,9.26,False
"def check_bounds ( geometry ) : <TAB> if isinstance ( geometry [ 0 ] , ( list , tuple ) ) : <TAB> <TAB> return list ( map ( check_bounds , geometry ) ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Longitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) <TAB> <TAB> if geometry [ 1 ] > 90 or geometry [ 1 ] < - 90 : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" Latitude is out of bounds, check your JSON format or data "" <TAB> <TAB> <TAB> ) ","if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 : 
","if geometry [ 0 ] > 180 or geometry [ 0 ] < - 180 :
",100.0,100.0,True
"def _mapper_output_protocol ( self , step_num , step_map ) : <TAB> map_key = self . _step_key ( step_num , "" mapper "" ) <TAB> if map_key in step_map : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . output_protocol ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . internal_protocol ( ) <TAB> else : <TAB> <TAB> # mapper is not a script substep, so protocols don't apply at all <TAB> <TAB> return RawValueProtocol ( ) ","if step_map [ map_key ] > = ( len ( step_map ) - 1 ) : 
","if step_map [ map_key ] == "" output "" :
",39.86,36.34,False
"def asset ( * paths ) : <TAB> for path in paths : <TAB> <TAB> fspath = www_root + "" /assets/ "" + path <TAB> <TAB> etag = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> if env . cache_static : <TAB> <TAB> <TAB> <TAB> etag = asset_etag ( fspath ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> os . stat ( fspath ) <TAB> <TAB> except FileNotFoundError as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not os . path . exists ( fspath + "" .spt "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> tell_sentry ( e , { } ) <TAB> <TAB> return asset_url + path + ( etag and "" ?etag= "" + etag ) ","if path == paths [ - 1 ] : 
","if env . ignore_file :
",26.57,5.09,False
"def ping ( self , payload : Union [ str , bytes ] = "" "" ) - > None : <TAB> if self . trace_enabled and self . ping_pong_trace_enabled : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> payload = payload . decode ( "" utf-8 "" ) <TAB> <TAB> self . logger . debug ( <TAB> <TAB> <TAB> "" Sending a ping data frame  "" <TAB> <TAB> <TAB> f "" (session id:  { self . session_id } , payload:  { payload } ) "" <TAB> <TAB> ) <TAB> data = _build_data_frame_for_sending ( payload , FrameHeader . OPCODE_PING ) <TAB> with self . sock_send_lock : <TAB> <TAB> self . sock . send ( data ) ","if isinstance ( payload , bytes ) : 
","if isinstance ( payload , bytes ) :
",100.0,100.0,True
"def is_ac_power_connected ( ) : <TAB> for power_source_path in Path ( "" /sys/class/power_supply/ "" ) . iterdir ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( power_source_path / "" type "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> if f . read ( ) . strip ( ) != "" Mains "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> with open ( power_source_path / "" online "" , "" r "" ) as f : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except IOError : <TAB> <TAB> <TAB> continue <TAB> return False ","if f . read ( 1 ) == "" 1 "" : 
","if f . read ( ) . strip ( ) == "" AC "" :
",52.97,41.69,False
"def handle_noargs ( self , * * options ) : <TAB> self . style = color_style ( ) <TAB> print ( "" Running Django ' s own validation: "" ) <TAB> self . validate ( display_num_errors = True ) <TAB> for model in loading . get_models ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . validate_base_model ( model ) <TAB> <TAB> if hasattr ( model , "" _feincms_content_models "" ) : <TAB> <TAB> <TAB> self . validate_content_type ( model ) ","if hasattr ( model , "" _create_content_base "" ) : 
","if hasattr ( model , "" _feincms_base_model "" ) :
",83.03,54.11,False
"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> if module . padding_idx is not None : <TAB> <TAB> <TAB> module . weight . data [ module . padding_idx ] . zero_ ( ) ","if module . bias is not None : 
","if module . bias is not None :
",100.0,100.0,True
"def walk ( msg , callback , data ) : <TAB> partnum = 0 <TAB> for part in msg . walk ( ) : <TAB> <TAB> # multipart/* are just containers <TAB> <TAB> if part . get_content_maintype ( ) == "" multipart "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> ctype = part . get_content_type ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctype = OCTET_TYPE <TAB> <TAB> filename = part . get_filename ( ) <TAB> <TAB> if not filename : <TAB> <TAB> <TAB> filename = PART_FN_TPL % ( partnum ) <TAB> <TAB> headers = dict ( part ) <TAB> <TAB> LOG . debug ( headers ) <TAB> <TAB> headers [ "" Content-Type "" ] = ctype <TAB> <TAB> payload = util . fully_decoded_payload ( part ) <TAB> <TAB> callback ( data , filename , payload , headers ) <TAB> <TAB> partnum = partnum + 1 ","if ctype is None : 
","if not ctype :
",28.67,16.37,False
"def _mark_lcs ( mask , dirs , m , n ) : <TAB> while m != 0 and n != 0 : <TAB> <TAB> if dirs [ m , n ] == "" | "" : <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> <TAB> mask [ m ] = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> m - = 1 <TAB> <TAB> elif dirs [ m , n ] == "" < "" : <TAB> <TAB> <TAB> n - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> raise UnboundLocalError ( "" Illegal move "" ) <TAB> return mask ","elif dirs [ m , n ] == "" ^ "" : 
","elif dirs [ m , n ] == "" > "" :
",88.57,79.11,False
"def valid_localparts ( strip_delimiters = False ) : <TAB> for line in ABRIDGED_LOCALPART_VALID_TESTS . split ( "" \n "" ) : <TAB> <TAB> # strip line, skip over empty lines <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over comments or empty lines <TAB> <TAB> match = COMMENT . match ( line ) <TAB> <TAB> if match : <TAB> <TAB> <TAB> continue <TAB> <TAB> # skip over localparts with delimiters <TAB> <TAB> if strip_delimiters : <TAB> <TAB> <TAB> if "" , "" in line or "" ; "" in line : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield line ","if line == "" "" : 
","if not line :
",28.06,9.93,False
"def fetch ( self , * tileables , * * kw ) : <TAB> ret_list = False <TAB> if len ( tileables ) == 1 and isinstance ( tileables [ 0 ] , ( tuple , list ) ) : <TAB> <TAB> ret_list = True <TAB> <TAB> tileables = tileables [ 0 ] <TAB> elif len ( tileables ) > 1 : <TAB> <TAB> ret_list = True <TAB> result = self . _sess . fetch ( * tileables , * * kw ) <TAB> ret = [ ] <TAB> for r , t in zip ( result , tileables ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( r . item ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ret . append ( r ) <TAB> if ret_list : <TAB> <TAB> return ret <TAB> return ret [ 0 ] ","if hasattr ( t , "" isscalar "" ) and t . isscalar ( ) and getattr ( r , "" size "" , None ) == 1 : 
","if isinstance ( t , Row ) :
",26.27,1.56,False
"def _convert ( container ) : <TAB> if _value_marker in container : <TAB> <TAB> force_list = False <TAB> <TAB> values = container . pop ( _value_marker ) <TAB> <TAB> if container . pop ( _list_marker , False ) : <TAB> <TAB> <TAB> force_list = True <TAB> <TAB> <TAB> values . extend ( _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> values = values [ 0 ] <TAB> <TAB> if not container : <TAB> <TAB> <TAB> return values <TAB> <TAB> return _convert ( container ) <TAB> elif container . pop ( _list_marker , False ) : <TAB> <TAB> return [ _convert ( x [ 1 ] ) for x in sorted ( container . items ( ) ) ] <TAB> return dict_cls ( ( k , _convert ( v ) ) for k , v in iteritems ( container ) ) ","if not force_list and len ( values ) == 1 : 
","if force_list :
",25.9,7.47,False
"def _transform_init_kwargs ( cls , kwargs ) : <TAB> transformed = [ ] <TAB> for field in list ( kwargs . keys ( ) ) : <TAB> <TAB> prop = getattr ( cls , field , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = kwargs . pop ( field ) <TAB> <TAB> <TAB> _transform_single_init_kwarg ( prop , field , value , kwargs ) <TAB> <TAB> <TAB> transformed . append ( ( field , value ) ) <TAB> return transformed ","if isinstance ( prop , MoneyProperty ) : 
","if prop is not None :
",26.98,7.65,False
"def haslayer ( self , cls ) : <TAB> """"""true if self has a layer that is an instance of cls. Superseded by ""cls in self"" syntax."""""" <TAB> if self . __class__ == cls or self . __class__ . __name__ == cls : <TAB> <TAB> return 1 <TAB> for f in self . packetfields : <TAB> <TAB> fvalue_gen = self . getfieldval ( f . name ) <TAB> <TAB> if fvalue_gen is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if not f . islist : <TAB> <TAB> <TAB> fvalue_gen = SetGen ( fvalue_gen , _iterpacket = 0 ) <TAB> <TAB> for fvalue in fvalue_gen : <TAB> <TAB> <TAB> if isinstance ( fvalue , Packet ) : <TAB> <TAB> <TAB> <TAB> ret = fvalue . haslayer ( cls ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return ret <TAB> return self . payload . haslayer ( cls ) ","if ret : 
","if ret :
",78.12,0.0,False
def insert_broken_add_sometimes ( node ) : <TAB> if node . op == theano . tensor . add : <TAB> <TAB> last_time_replaced [ 0 ] = not last_time_replaced [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ off_by_half ( * node . inputs ) ] <TAB> return False ,"if last_time_replaced [ 0 ] : 
","if last_time_replaced [ 0 ] :
",100.0,100.0,True
"def testReadChunk10 ( self ) : <TAB> # ""Test BZ2File.read() in chunks of 10 bytes"" <TAB> self . createTempFile ( ) <TAB> with BZ2File ( self . filename ) as bz2f : <TAB> <TAB> text = "" "" <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> str = bz2f . read ( 10 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> text + = str <TAB> <TAB> self . assertEqual ( text , self . TEXT ) ","if not str : 
","if not str :
",100.0,100.0,True
"def generate_sv_faces ( dcel_mesh , point_index , only_select = False , del_flag = None ) : <TAB> # This part of function creates faces in SV format <TAB> # It ignores  boundless super face <TAB> sv_faces = [ ] <TAB> for i , face in enumerate ( dcel_mesh . faces ) : <TAB> <TAB> if face . inners and face . outer : <TAB> <TAB> <TAB> "" Face ( {} ) has inner components! Sverchok cant show polygons with holes. "" . format ( <TAB> <TAB> <TAB> <TAB> i <TAB> <TAB> <TAB> ) <TAB> <TAB> if not face . outer or del_flag in face . flags : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> sv_faces . append ( [ point_index [ hedge . origin ] for hedge in face . outer . loop_hedges ] ) <TAB> return sv_faces ","if only_select and not face . select : 
","if only_select and face . inners :
",39.11,47.5,False
"def __check_dict_contains ( dct , dict_name , keys , comment = "" "" , result = True ) : <TAB> for key in keys : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = False <TAB> <TAB> <TAB> comment = __append_comment ( <TAB> <TAB> <TAB> <TAB> "" Missing  {0}  in  {1} "" . format ( key , dict_name ) , comment <TAB> <TAB> <TAB> ) <TAB> return result , comment ","if key not in six . iterkeys ( dct ) : 
","if not dct . get ( key ) :
",38.54,10.8,False
"def _dump_arg_defaults ( kwargs ) : <TAB> """"""Inject default arguments for dump functions."""""" <TAB> if current_app : <TAB> <TAB> kwargs . setdefault ( "" cls "" , current_app . json_encoder ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs . setdefault ( "" ensure_ascii "" , False ) <TAB> <TAB> kwargs . setdefault ( "" sort_keys "" , current_app . config [ "" JSON_SORT_KEYS "" ] ) <TAB> else : <TAB> <TAB> kwargs . setdefault ( "" sort_keys "" , True ) <TAB> <TAB> kwargs . setdefault ( "" cls "" , JSONEncoder ) ","if not current_app . config [ "" JSON_AS_ASCII "" ] : 
","if current_app . config [ "" JSON_PRETTY_PRINT "" ] :
",61.29,58.83,False
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> if value != 1 : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed ","elif len ( value ) != 0 : 
","if self . _set_button . disabled :
",26.34,4.2,False
"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tab = p . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> if tab [ 0 ] == "" socks "" : <TAB> <TAB> <TAB> <TAB> tab [ 0 ] = "" SOCKS4 "" <TAB> <TAB> <TAB> proxies . append ( <TAB> <TAB> <TAB> <TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB> <TAB> <TAB> )<TAB> # type, addr:port, username, password <TAB> <TAB> else : <TAB> <TAB> <TAB> proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB> return proxies ","if "" = "" in p : 
","if "" = "" in p :
",100.0,100.0,True
"def predict ( collect_dir , keys ) : <TAB> run_all = len ( keys ) == 0 <TAB> validate_keys ( keys ) <TAB> for exp_cfg in cfg : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = exp_cfg [ "" key "" ] <TAB> <TAB> <TAB> _predict ( key , exp_cfg [ "" sample_img "" ] , collect_dir ) ","if run_all or exp_cfg [ "" key "" ] in keys : 
","if run_all and exp_cfg [ "" key "" ] in keys :
",87.77,81.54,False
"def convert_port_bindings ( port_bindings ) : <TAB> result = { } <TAB> for k , v in six . iteritems ( port_bindings ) : <TAB> <TAB> key = str ( k ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key + = "" /tcp "" <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( binding ) for binding in v ] <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ key ] = [ _convert_port_binding ( v ) ] <TAB> return result ","if "" / "" not in key : 
","if key [ - 1 ] != "" / "" :
",36.47,14.99,False
"def assert_conll_writer_output ( <TAB> dataset : InternalBioNerDataset , <TAB> expected_output : List [ str ] , <TAB> sentence_splitter : SentenceSplitter = None , ) : <TAB> outfile_path = tempfile . mkstemp ( ) [ 1 ] <TAB> try : <TAB> <TAB> sentence_splitter = ( <TAB> <TAB> <TAB> sentence_splitter <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> else NoSentenceSplitter ( tokenizer = SpaceTokenizer ( ) ) <TAB> <TAB> ) <TAB> <TAB> writer = CoNLLWriter ( sentence_splitter = sentence_splitter ) <TAB> <TAB> writer . write_to_conll ( dataset , Path ( outfile_path ) ) <TAB> <TAB> contents = [ l . strip ( ) for l in open ( outfile_path ) . readlines ( ) if l . strip ( ) ] <TAB> finally : <TAB> <TAB> os . remove ( outfile_path ) <TAB> assert contents == expected_output ","if sentence_splitter 
","if sentence_splitter
",65.81,100.0,True
"def post ( self , request , * args , * * kwargs ) : <TAB> self . comment_obj = get_object_or_404 ( Comment , id = request . POST . get ( "" commentid "" ) ) <TAB> if request . user == self . comment_obj . commented_by : <TAB> <TAB> form = LeadCommentForm ( request . POST , instance = self . comment_obj ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . form_valid ( form ) <TAB> <TAB> return self . form_invalid ( form ) <TAB> data = { "" error "" : "" You don ' t have permission to edit this comment. "" } <TAB> return JsonResponse ( data ) ","if form . is_valid ( ) : 
","if form . is_valid ( ) :
",100.0,100.0,True
"def trivia_list ( self , ctx : commands . Context ) : <TAB> """"""List available trivia categories."""""" <TAB> lists = set ( p . stem for p in self . _all_lists ( ) ) <TAB> if await ctx . embed_requested ( ) : <TAB> <TAB> await ctx . send ( <TAB> <TAB> <TAB> embed = discord . Embed ( <TAB> <TAB> <TAB> <TAB> title = _ ( "" Available trivia lists "" ) , <TAB> <TAB> <TAB> <TAB> colour = await ctx . embed_colour ( ) , <TAB> <TAB> <TAB> <TAB> description = "" ,  "" . join ( sorted ( lists ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> msg = box ( bold ( _ ( "" Available trivia lists "" ) ) + "" \n \n "" + "" ,  "" . join ( sorted ( lists ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await ctx . author . send ( msg ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await ctx . send ( msg ) ","if len ( msg ) > 1000 : 
","if ctx . author :
",26.86,6.97,False
"def validate ( self ) : <TAB> result = validators . SUCCESS <TAB> msgs = [ ] <TAB> for validator in self . _validators : <TAB> <TAB> res , err = validator . validate ( ) <TAB> <TAB> if res == validators . ERROR : <TAB> <TAB> <TAB> result = res <TAB> <TAB> elif res == validators . WARNING and result != validators . ERROR : <TAB> <TAB> <TAB> result = res <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msgs . append ( err ) <TAB> return result , "" \n "" . join ( msgs ) ","if len ( err ) > 0 : 
","if err :
",26.73,0.0,False
"def get_code ( self , fullname = None ) : <TAB> fullname = self . _fix_name ( fullname ) <TAB> if self . code is None : <TAB> <TAB> mod_type = self . etc [ 2 ] <TAB> <TAB> if mod_type == imp . PY_SOURCE : <TAB> <TAB> <TAB> source = self . get_source ( fullname ) <TAB> <TAB> <TAB> self . code = compile ( source , self . filename , "" exec "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _reopen ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . code = read_code ( self . file ) <TAB> <TAB> <TAB> finally : <TAB> <TAB> <TAB> <TAB> self . file . close ( ) <TAB> <TAB> elif mod_type == imp . PKG_DIRECTORY : <TAB> <TAB> <TAB> self . code = self . _get_delegate ( ) . get_code ( ) <TAB> return self . code ","elif mod_type == imp . PY_COMPILED : 
","elif mod_type == imp . PY_FILE :
",82.41,82.65,False
"def flush_file ( self , key , f ) : <TAB> f . flush ( ) <TAB> if self . compress : <TAB> <TAB> f . compress = zlib . compressobj ( <TAB> <TAB> <TAB> 9 , zlib . DEFLATED , - zlib . MAX_WBITS , zlib . DEF_MEM_LEVEL , 0 <TAB> <TAB> ) <TAB> if len ( self . files ) > self . MAX_OPEN_FILES : <TAB> <TAB> if self . compress : <TAB> <TAB> <TAB> open_files = sum ( 1 for f in self . files . values ( ) if f . fileobj is not None ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f . fileobj . close ( ) <TAB> <TAB> <TAB> <TAB> f . fileobj = None <TAB> <TAB> else : <TAB> <TAB> <TAB> f . close ( ) <TAB> <TAB> <TAB> self . files . pop ( key ) ","if open_files > self . MAX_OPEN_FILES : 
","if open_files > 0 :
",34.45,27.31,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_version ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def init_author_file ( self ) : <TAB> self . author_map = { } <TAB> if self . ui . config ( "" git "" , "" authors "" ) : <TAB> <TAB> f = open ( self . repo . wjoin ( self . ui . config ( "" git "" , "" authors "" ) ) ) <TAB> <TAB> try : <TAB> <TAB> <TAB> for line in f : <TAB> <TAB> <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> from_ , to = RE_AUTHOR_FILE . split ( line , 2 ) <TAB> <TAB> <TAB> <TAB> self . author_map [ from_ ] = to <TAB> <TAB> finally : <TAB> <TAB> <TAB> f . close ( ) ","if not line or line . startswith ( "" # "" ) : 
","if not line or line . startswith ( "" # "" ) :
",100.0,100.0,True
"def decode_imsi ( self , imsi ) : <TAB> new_imsi = "" "" <TAB> for a in imsi : <TAB> <TAB> c = hex ( a ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_imsi + = str ( c [ 3 ] ) + str ( c [ 2 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> new_imsi + = str ( c [ 2 ] ) + "" 0 "" <TAB> mcc = new_imsi [ 1 : 4 ] <TAB> mnc = new_imsi [ 4 : 6 ] <TAB> return new_imsi , mcc , mnc ","if len ( c ) == 4 : 
","if c [ 3 ] :
",26.98,6.48,False
"def _get_infoset ( self , prefname ) : <TAB> """"""Return methods with the name starting with prefname."""""" <TAB> infoset = [ ] <TAB> excludes = ( "" %s infoset "" % prefname , ) <TAB> preflen = len ( prefname ) <TAB> for name in dir ( self . __class__ ) : <TAB> <TAB> if name . startswith ( prefname ) and name not in excludes : <TAB> <TAB> <TAB> member = getattr ( self . __class__ , name ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> infoset . append ( name [ preflen : ] . replace ( "" _ "" , "" "" ) ) <TAB> return infoset ","if isinstance ( member , MethodType ) : 
","if isinstance ( member ,infoset ) and member . __name__ == prefname :
",52.67,20.61,False
"def skip_to_close_match ( self ) : <TAB> nestedCount = 1 <TAB> while 1 : <TAB> <TAB> tok = self . tokenizer . get_next_token ( ) <TAB> <TAB> ttype = tok [ "" style "" ] <TAB> <TAB> if ttype == SCE_PL_UNUSED : <TAB> <TAB> <TAB> return <TAB> <TAB> elif self . classifier . is_index_op ( tok ) : <TAB> <TAB> <TAB> tval = tok [ "" text "" ] <TAB> <TAB> <TAB> if self . opHash . has_key ( tval ) : <TAB> <TAB> <TAB> <TAB> if self . opHash [ tval ] [ 1 ] == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount + = 1 <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> nestedCount - = 1 <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break ","if nestedCount < = 0 : 
","if nestedCount == 0 :
",31.48,37.99,False
"def findMarkForUnitTestNodes ( self ) : <TAB> """"""return the position of *all* non-ignored @mark-for-unit-test nodes."""""" <TAB> c = self . c <TAB> p , result , seen = c . rootPosition ( ) , [ ] , [ ] <TAB> while p : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> seen . append ( p . v ) <TAB> <TAB> <TAB> if g . match_word ( p . h , 0 , "" @ignore "" ) : <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> elif p . h . startswith ( "" @mark-for-unit-tests "" ) : <TAB> <TAB> <TAB> <TAB> result . append ( p . copy ( ) ) <TAB> <TAB> <TAB> <TAB> p . moveToNodeAfterTree ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> p . moveToThreadNext ( ) <TAB> return result ","if p . v in seen : 
","if p . v in seen :
",100.0,100.0,True
"def assert_parts_cleaned ( self , earlier_parts , current_parts , expected_parts , hint ) : <TAB> cleaned_parts = [ ] <TAB> for earlier in earlier_parts : <TAB> <TAB> earlier_part = earlier [ "" part "" ] <TAB> <TAB> earlier_step = earlier [ "" step "" ] <TAB> <TAB> found = False <TAB> <TAB> for current in current_parts : <TAB> <TAB> <TAB> if earlier_part == current [ "" part "" ] and earlier_step == current [ "" step "" ] : <TAB> <TAB> <TAB> <TAB> found = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cleaned_parts . append ( dict ( part = earlier_part , step = earlier_step ) ) <TAB> self . assertThat ( cleaned_parts , HasLength ( len ( expected_parts ) ) , hint ) <TAB> for expected in expected_parts : <TAB> <TAB> self . assertThat ( cleaned_parts , Contains ( expected ) , hint ) ","if not found : 
","if found :
",34.18,0.0,False
"def unmark_first_parents ( event = None ) : <TAB> """"""Mark the node and all its parents."""""" <TAB> c = event . get ( "" c "" ) <TAB> if not c : <TAB> <TAB> return <TAB> changed = [ ] <TAB> for parent in c . p . self_and_parents ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parent . v . clearMarked ( ) <TAB> <TAB> <TAB> parent . setAllAncestorAtFileNodesDirty ( ) <TAB> <TAB> <TAB> changed . append ( parent . copy ( ) ) <TAB> if changed : <TAB> <TAB> # g.es(""unmarked: "" + ', '.join([z.h for z in changed])) <TAB> <TAB> c . setChanged ( ) <TAB> <TAB> c . redraw ( ) <TAB> return changed ","if parent . isMarked ( ) : 
","if parent . v :
",39.45,28.64,False
"def stop ( self ) : <TAB> self . _log ( "" Monitor stop "" ) <TAB> self . _stop_requested = True <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fd = os . open ( self . fifo_path , os . O_WRONLY ) <TAB> <TAB> <TAB> os . write ( fd , b "" X "" ) <TAB> <TAB> <TAB> os . close ( fd ) <TAB> except Exception as e : <TAB> <TAB> self . _log ( "" err while closing:  {0} "" . format ( str ( e ) ) ) <TAB> if self . _thread : <TAB> <TAB> self . _thread . join ( ) <TAB> <TAB> self . _thread = None ","if os . path . exists ( self . fifo_path ) : 
","if self . fifo_path :
",36.59,24.6,False
"def DeleteEmptyCols ( self ) : <TAB> cols2delete = [ ] <TAB> for c in range ( 0 , self . GetCols ( ) ) : <TAB> <TAB> f = True <TAB> <TAB> for r in range ( 0 , self . GetRows ( ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f = False <TAB> <TAB> if f : <TAB> <TAB> <TAB> cols2delete . append ( c ) <TAB> for i in range ( 0 , len ( cols2delete ) ) : <TAB> <TAB> self . ShiftColsLeft ( cols2delete [ i ] + 1 ) <TAB> <TAB> cols2delete = [ x - 1 for x in cols2delete ] ","if self . FindItemAtPosition ( ( r , c ) ) is not None : 
","if self . GetItem ( r ) [ c ] == - 1 :
",32.59,13.83,False
"def _load_objects ( self , obj_id_zset , limit , chunk_size = 1000 ) : <TAB> ct = i = 0 <TAB> while True : <TAB> <TAB> id_chunk = obj_id_zset [ i : i + chunk_size ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> i + = chunk_size <TAB> <TAB> for raw_data in self . _data [ id_chunk ] : <TAB> <TAB> <TAB> if not raw_data : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if self . _use_json : <TAB> <TAB> <TAB> <TAB> yield json . loads ( decode ( raw_data ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield raw_data <TAB> <TAB> <TAB> ct + = 1 <TAB> <TAB> <TAB> if limit and ct == limit : <TAB> <TAB> <TAB> <TAB> return ","if not id_chunk : 
","if id_chunk not in self . _data :
",28.82,16.59,False
"def _convert_example ( example , use_bfloat16 ) : <TAB> """"""Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""""" <TAB> for key in list ( example . keys ( ) ) : <TAB> <TAB> val = example [ key ] <TAB> <TAB> if tf . keras . backend . is_sparse ( val ) : <TAB> <TAB> <TAB> val = tf . sparse . to_dense ( val ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = tf . cast ( val , tf . int32 ) <TAB> <TAB> if use_bfloat16 and val . dtype == tf . float32 : <TAB> <TAB> <TAB> val = tf . cast ( val , tf . bfloat16 ) <TAB> <TAB> example [ key ] = val ","if val . dtype == tf . int64 : 
","if use_bfloat16 and val . dtype == tf . int64 :
",79.7,61.15,False
"def print_callees ( self , * amount ) : <TAB> width , list = self . get_print_list ( amount ) <TAB> if list : <TAB> <TAB> self . calc_callees ( ) <TAB> <TAB> self . print_call_heading ( width , "" called... "" ) <TAB> <TAB> for func in list : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . print_call_line ( width , func , self . all_callees [ func ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . print_call_line ( width , func , { } ) <TAB> <TAB> print >> self . stream <TAB> <TAB> print >> self . stream <TAB> return self ","if func in self . all_callees : 
","if func in self . all_callees :
",100.0,100.0,True
"def on_task_input ( self , task , config ) : <TAB> if config is False : <TAB> <TAB> return <TAB> for entry in task . entries : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log_once ( <TAB> <TAB> <TAB> <TAB> "" Corrected ` %s ` url (replaced &amp; with &) "" % entry [ "" title "" ] , <TAB> <TAB> <TAB> <TAB> logger = log , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> entry [ "" url "" ] = entry [ "" url "" ] . replace ( "" &amp; "" , "" & "" ) ","if "" &amp; "" in entry [ "" url "" ] : 
","if "" url "" not in entry :
",39.7,18.33,False
"def function ( self , inputs , outputs , ignore_empty = False ) : <TAB> f = function ( inputs , outputs , mode = self . mode ) <TAB> if self . mode is not None or theano . config . mode != "" FAST_COMPILE "" : <TAB> <TAB> topo = f . maker . fgraph . toposort ( ) <TAB> <TAB> topo_ = [ node for node in topo if not isinstance ( node . op , self . ignore_topo ) ] <TAB> <TAB> if ignore_empty : <TAB> <TAB> <TAB> assert len ( topo_ ) < = 1 , topo_ <TAB> <TAB> else : <TAB> <TAB> <TAB> assert len ( topo_ ) == 1 , topo_ <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert type ( topo_ [ 0 ] . op ) is self . op <TAB> return f ","if len ( topo_ ) > 0 : 
","if self . ignore_topo :
",26.86,6.98,False
"def _get_env_command ( self ) - > Sequence [ str ] : <TAB> """"""Get command sequence for `env` with configured flags."""""" <TAB> env_list = [ "" env "" ] <TAB> # Pass through configurable environment variables. <TAB> for key in [ "" http_proxy "" , "" https_proxy "" ] : <TAB> <TAB> value = self . build_provider_flags . get ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Ensure item is treated as string and append it. <TAB> <TAB> value = str ( value ) <TAB> <TAB> env_list . append ( f "" { key } = { value } "" ) <TAB> return env_list ","if not value : 
","if value is None :
",29.25,14.06,False
"def _compare_single_run ( self , compares_done ) : <TAB> try : <TAB> <TAB> compare_id , redo = self . in_queue . get ( <TAB> <TAB> <TAB> timeout = float ( self . config [ "" ExpertSettings "" ] [ "" block_delay "" ] ) <TAB> <TAB> ) <TAB> except Empty : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> if self . _decide_whether_to_process ( compare_id , redo , compares_done ) : <TAB> <TAB> <TAB> if redo : <TAB> <TAB> <TAB> <TAB> self . db_interface . delete_old_compare_result ( compare_id ) <TAB> <TAB> <TAB> compares_done . add ( compare_id ) <TAB> <TAB> <TAB> self . _process_compare ( compare_id ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . callback ( ) ","if self . callback : 
","if self . callback :
",100.0,100.0,True
"def clean ( self ) : <TAB> # TODO: check for clashes if the random code is already taken <TAB> if not self . code : <TAB> <TAB> self . code = u "" static- %s "" % uuid . uuid4 ( ) <TAB> if not self . site : <TAB> <TAB> placeholders = StaticPlaceholder . objects . filter ( <TAB> <TAB> <TAB> code = self . code , site__isnull = True <TAB> <TAB> ) <TAB> <TAB> if self . pk : <TAB> <TAB> <TAB> placeholders = placeholders . exclude ( pk = self . pk ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> _ ( "" A static placeholder with the same site and code already exists "" ) <TAB> <TAB> <TAB> ) ","if placeholders . exists ( ) : 
","if not all ( placeholders . exists ( ) ) :
",67.77,40.35,False
"def load_parser ( self ) : <TAB> result = OrderedDict ( ) <TAB> for name , flags in self . filenames : <TAB> <TAB> filename = self . get_filename ( name ) <TAB> <TAB> for match in sorted ( glob ( filename ) , key = self . file_key ) : <TAB> <TAB> <TAB> # Needed to allow overlapping globs, more specific first <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> result [ match ] = TextParser ( match , os . path . relpath ( match , self . base ) , flags ) <TAB> return result ","if match in result : 
","if match . startswith ( self . base ) :
",29.44,9.29,False
"def __init__ ( self , selectable , name = None ) : <TAB> baseselectable = selectable <TAB> while isinstance ( baseselectable , Alias ) : <TAB> <TAB> baseselectable = baseselectable . element <TAB> self . original = baseselectable <TAB> self . supports_execution = baseselectable . supports_execution <TAB> if self . supports_execution : <TAB> <TAB> self . _execution_options = baseselectable . _execution_options <TAB> self . element = selectable <TAB> if name is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> name = getattr ( self . original , "" name "" , None ) <TAB> <TAB> name = _anonymous_label ( "" %% ( %d %s )s "" % ( id ( self ) , name or "" anon "" ) ) <TAB> self . name = name ","if self . original . named_with_column : 
","if self . original :
",54.34,21.3,False
"def load_tour ( self , tour_id ) : <TAB> for tour_dir in self . tour_directories : <TAB> <TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yaml "" ) <TAB> <TAB> if not os . path . exists ( tour_path ) : <TAB> <TAB> <TAB> tour_path = os . path . join ( tour_dir , tour_id + "" .yml "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _load_tour_from_path ( tour_path ) ","if os . path . exists ( tour_path ) : 
","if os . path . exists ( tour_path ) :
",100.0,100.0,True
"def _get_md_bg_color_down ( self ) : <TAB> t = self . theme_cls <TAB> c = self . md_bg_color<TAB> # Default to no change on touch <TAB> # Material design specifies using darker hue when on Dark theme <TAB> if t . theme_style == "" Dark "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> c = t . primary_dark <TAB> <TAB> elif self . md_bg_color == t . accent_color : <TAB> <TAB> <TAB> c = t . accent_dark <TAB> return c ","if self . md_bg_color == t . primary_color : 
","if self . md_bg_color == t . primary_dark :
",87.71,87.62,False
"def get_data ( self , state = None , request = None ) : <TAB> if self . load_in_memory : <TAB> <TAB> data , shapes = self . _in_memory_get_data ( state , request ) <TAB> else : <TAB> <TAB> data , shapes = self . _out_of_memory_get_data ( state , request ) <TAB> for i in range ( len ( data ) ) : <TAB> <TAB> if shapes [ i ] is not None : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data [ i ] = data [ i ] . reshape ( shapes [ i ] ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> for j in range ( len ( data [ i ] ) ) : <TAB> <TAB> <TAB> <TAB> <TAB> data [ i ] [ j ] = data [ i ] [ j ] . reshape ( shapes [ i ] [ j ] ) <TAB> return tuple ( data ) ","if isinstance ( request , numbers . Integral ) : 
","if i == len ( data ) - 1 :
",26.56,5.3,False
"def onClicked ( event ) : <TAB> if not self . path : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . makedirs ( mh . getPath ( "" render "" ) ) <TAB> <TAB> self . path = mh . getPath ( "" render "" ) <TAB> filename , ftype = mh . getSaveFileName ( <TAB> <TAB> os . path . splitext ( self . path ) [ 0 ] , <TAB> <TAB> "" PNG Image (*.png);;JPEG Image (*.jpg);;Thumbnail (*.thumb);;All files (*.*) "" , <TAB> ) <TAB> if filename : <TAB> <TAB> if "" Thumbnail "" in ftype : <TAB> <TAB> <TAB> self . image . save ( filename , iformat = "" PNG "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . image . save ( filename ) <TAB> <TAB> self . path = os . path . dirname ( filename ) ","if not os . path . exists ( mh . getPath ( "" render "" ) ) : 
","if not os . path . exists ( mh . getPath ( "" render "" ) ) :
",100.0,100.0,True
"def _build_dom ( cls , content , mode ) : <TAB> assert mode in ( "" html "" , "" xml "" ) <TAB> if mode == "" html "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> THREAD_STORAGE . html_parser = HTMLParser ( ) <TAB> <TAB> dom = defusedxml . lxml . parse ( <TAB> <TAB> <TAB> StringIO ( content ) , parser = THREAD_STORAGE . html_parser <TAB> <TAB> ) <TAB> <TAB> return dom . getroot ( ) <TAB> else : <TAB> <TAB> if not hasattr ( THREAD_STORAGE , "" xml_parser "" ) : <TAB> <TAB> <TAB> THREAD_STORAGE . xml_parser = XMLParser ( ) <TAB> <TAB> dom = defusedxml . lxml . parse ( BytesIO ( content ) , parser = THREAD_STORAGE . xml_parser ) <TAB> <TAB> return dom . getroot ( ) ","if not hasattr ( THREAD_STORAGE , "" html_parser "" ) : 
","if not hasattr ( THREAD_STORAGE , "" html_parser "" ) :
",100.0,100.0,True
"def convert_path ( ctx , tpath ) : <TAB> for points , code in tpath . iter_segments ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ctx . move_to ( * points ) <TAB> <TAB> elif code == Path . LINETO : <TAB> <TAB> <TAB> ctx . line_to ( * points ) <TAB> <TAB> elif code == Path . CURVE3 : <TAB> <TAB> <TAB> ctx . curve_to ( <TAB> <TAB> <TAB> <TAB> points [ 0 ] , points [ 1 ] , points [ 0 ] , points [ 1 ] , points [ 2 ] , points [ 3 ] <TAB> <TAB> <TAB> ) <TAB> <TAB> elif code == Path . CURVE4 : <TAB> <TAB> <TAB> ctx . curve_to ( * points ) <TAB> <TAB> elif code == Path . CLOSEPOLY : <TAB> <TAB> <TAB> ctx . close_path ( ) ","if code == Path . MOVETO : 
","if code == Path . MOVETO :
",100.0,100.0,True
"def _targets ( self , sigmaparser ) : <TAB> # build list of matching target mappings <TAB> targets = set ( ) <TAB> for condfield in self . conditions : <TAB> <TAB> if condfield in sigmaparser . values : <TAB> <TAB> <TAB> rulefieldvalues = sigmaparser . values [ condfield ] <TAB> <TAB> <TAB> for condvalue in self . conditions [ condfield ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> targets . update ( self . conditions [ condfield ] [ condvalue ] ) <TAB> return targets ","if condvalue in rulefieldvalues : 
","if condvalue in rulefieldvalues :
",100.0,100.0,True
"def create_image_upload ( ) : <TAB> if request . method == "" POST "" : <TAB> <TAB> image = request . form [ "" image "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> image_file = uploaded_file ( file_content = image ) <TAB> <TAB> <TAB> image_url = upload_local ( <TAB> <TAB> <TAB> <TAB> image_file , UPLOAD_PATHS [ "" temp "" ] [ "" image "" ] . format ( uuid = uuid4 ( ) ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" ok "" , "" image_url "" : image_url } ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return jsonify ( { "" status "" : "" no_image "" } ) ","if image : 
","if image :
",78.12,0.0,False
"def lookup_actions ( self , resp ) : <TAB> actions = { } <TAB> for action , conditions in self . actions . items ( ) : <TAB> <TAB> for condition , opts in conditions : <TAB> <TAB> <TAB> for key , val in condition : <TAB> <TAB> <TAB> <TAB> if key [ - 1 ] == "" ! "" : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> if not resp . match ( key , val ) : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> actions [ action ] = opts <TAB> return actions ","if resp . match ( key [ : - 1 ] , val ) : 
","if resp . match ( key , val ) :
",52.84,47.65,False
"def accept_quality ( accept , default = 1 ) : <TAB> """"""Separates out the quality score from the accepted content_type"""""" <TAB> quality = default <TAB> if accept and "" ; "" in accept : <TAB> <TAB> accept , rest = accept . split ( "" ; "" , 1 ) <TAB> <TAB> accept_quality = RE_ACCEPT_QUALITY . search ( rest ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> quality = float ( accept_quality . groupdict ( ) . get ( "" quality "" , quality ) . strip ( ) ) <TAB> return ( quality , accept . strip ( ) ) ","if accept_quality : 
","if accept_quality :
",78.12,100.0,True
"def save ( self , session = None , to = None , pickler = None ) : <TAB> if to and pickler : <TAB> <TAB> self . _save_to = ( pickler , to ) <TAB> if self . _save_to and len ( self ) > 0 : <TAB> <TAB> with self . _lock : <TAB> <TAB> <TAB> pickler , fn = self . _save_to <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> session . ui . mark ( _ ( "" Saving  %s  state to  %s "" ) % ( self , fn ) ) <TAB> <TAB> <TAB> pickler ( self , fn ) ","if session : 
","if session and not self . _save_to :
",33.27,8.3,False
"def get_safe_settings ( ) : <TAB> "" Returns a dictionary of the settings module, with sensitive settings blurred out. "" <TAB> settings_dict = { } <TAB> for k in dir ( settings ) : <TAB> <TAB> if k . isupper ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = "" ******************** "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> settings_dict [ k ] = getattr ( settings , k ) <TAB> return settings_dict ","if HIDDEN_SETTINGS . search ( k ) : 
","if k == "" _settings_ "" :
",26.96,5.93,False
def _init_table_h ( ) : <TAB> _table_h = [ ] <TAB> for i in range ( 256 ) : <TAB> <TAB> part_l = i <TAB> <TAB> part_h = 0 <TAB> <TAB> for j in range ( 8 ) : <TAB> <TAB> <TAB> rflag = part_l & 1 <TAB> <TAB> <TAB> part_l >> = 1 <TAB> <TAB> <TAB> if part_h & 1 : <TAB> <TAB> <TAB> <TAB> part_l | = 1 << 31 <TAB> <TAB> <TAB> part_h >> = 1 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> part_h ^ = 0xD8000000 <TAB> <TAB> _table_h . append ( part_h ) <TAB> return _table_h ,"if rflag : 
","if rflag :
",78.12,0.0,False
"def dns_query ( server , timeout , protocol , qname , qtype , qclass ) : <TAB> request = dns . message . make_query ( qname , qtype , qclass ) <TAB> if protocol == "" tcp "" : <TAB> <TAB> response = dns . query . tcp ( <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> ) <TAB> else : <TAB> <TAB> response = dns . query . udp ( <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response = dns . query . tcp ( <TAB> <TAB> <TAB> <TAB> request , server , timeout = timeout , one_rr_per_rrset = True <TAB> <TAB> <TAB> ) <TAB> return response ","if response . flags & dns . flags . TC : 
","if protocol == "" udp "" :
",26.24,4.51,False
"def sum_and_divide ( self , losses ) : <TAB> if self . total_divisor != 0 : <TAB> <TAB> output = torch . sum ( losses ) / self . total_divisor <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # remove from autograd graph if necessary <TAB> <TAB> <TAB> self . total_divisor = self . total_divisor . item ( ) <TAB> <TAB> return output <TAB> return torch . sum ( losses * 0 ) ","if torch . is_tensor ( self . total_divisor ) : 
","if torch . is_tensor ( output ) and self . autograd_graph is not None :
",52.99,36.66,False
"def __iter__ ( self ) : <TAB> for chunk in self . source : <TAB> <TAB> if chunk is not None : <TAB> <TAB> <TAB> self . wait_counter = 0 <TAB> <TAB> <TAB> yield chunk <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . wait_counter + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . warning ( <TAB> <TAB> <TAB> <TAB> "" Data poller has been receiving no data for  {}  seconds. \n "" <TAB> <TAB> <TAB> <TAB> "" Closing data poller "" . format ( self . wait_cntr_max * self . poll_period ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> break <TAB> <TAB> time . sleep ( self . poll_period ) ","elif self . wait_counter < self . wait_cntr_max : 
","if self . wait_counter < self . wait_cntr_max :
",81.27,92.54,False
"def test_find_directive_from_block ( self ) : <TAB> blocks = self . config . parser_root . find_blocks ( "" virtualhost "" ) <TAB> found = False <TAB> for vh in blocks : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> servername = vh . find_directives ( "" servername "" ) <TAB> <TAB> <TAB> self . assertEqual ( servername [ 0 ] . parameters [ 0 ] , "" certbot.demo "" ) <TAB> <TAB> <TAB> found = True <TAB> self . assertTrue ( found ) ","if vh . filepath . endswith ( "" sites-enabled/certbot.conf "" ) : 
","if vh . name == "" virtualhost "" :
",37.32,10.19,False
"def assign_products ( request , discount_id ) : <TAB> """"""Assign products to given property group with given property_group_id."""""" <TAB> discount = lfs_get_object_or_404 ( Discount , pk = discount_id ) <TAB> for temp_id in request . POST . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> temp_id = temp_id . split ( "" - "" ) [ 1 ] <TAB> <TAB> <TAB> product = Product . objects . get ( pk = temp_id ) <TAB> <TAB> <TAB> discount . products . add ( product ) <TAB> html = [ [ "" #products-inline "" , products_inline ( request , discount_id , as_string = True ) ] ] <TAB> result = json . dumps ( <TAB> <TAB> { "" html "" : html , "" message "" : _ ( u "" Products have been assigned. "" ) } , cls = LazyEncoder <TAB> ) <TAB> return HttpResponse ( result , content_type = "" application/json "" ) ","if temp_id . startswith ( "" product "" ) : 
","if "" - "" in temp_id :
",30.81,15.72,False
"def ChangeStyle ( self , combos ) : <TAB> style = 0 <TAB> for combo in combos : <TAB> <TAB> if combo . GetValue ( ) == 1 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> style = style | HTL . TR_VIRTUAL <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" wx. "" + combo . GetLabel ( ) ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> style = style | eval ( "" HTL. "" + combo . GetLabel ( ) ) <TAB> if self . GetAGWWindowStyleFlag ( ) != style : <TAB> <TAB> self . SetAGWWindowStyleFlag ( style ) ","if combo . GetLabel ( ) == "" TR_VIRTUAL "" : 
","if combo . GetLabel ( ) == "" virtual "" :
",87.22,65.11,False
"def _set_autocomplete ( self , notebook ) : <TAB> if notebook : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> notebook = NotebookInfo ( notebook ) <TAB> <TAB> <TAB> obj , x = build_notebook ( notebook ) <TAB> <TAB> <TAB> self . form . widgets [ "" namespace "" ] . notebook = obj <TAB> <TAB> <TAB> self . form . widgets [ "" page "" ] . notebook = obj <TAB> <TAB> <TAB> logger . debug ( "" Notebook for autocomplete:  %s  ( %s ) "" , obj , notebook ) <TAB> <TAB> except : <TAB> <TAB> <TAB> logger . exception ( "" Could not set notebook:  %s "" , notebook ) <TAB> else : <TAB> <TAB> self . form . widgets [ "" namespace "" ] . notebook = None <TAB> <TAB> self . form . widgets [ "" page "" ] . notebook = None <TAB> <TAB> logger . debug ( "" Notebook for autocomplete unset "" ) ","if isinstance ( notebook , str ) : 
","if not isinstance ( notebook , ( str , unicode ) ) :
",42.22,24.71,False
"def emitSubDomainData ( self , subDomainData , event ) : <TAB> self . emitRawRirData ( subDomainData , event ) <TAB> for subDomainElem in subDomainData : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> subDomain = subDomainElem . get ( "" subdomain "" , "" "" ) . strip ( ) <TAB> <TAB> if subDomain : <TAB> <TAB> <TAB> self . emitHostname ( subDomain , event ) ","if self . checkForStop ( ) : 
","if subDomainElem . get ( "" domain "" , "" "" ) == "" "" :
",31.74,3.42,False
"def get_all_subnets ( self , subnet_ids = None , filters = None ) : <TAB> # Extract a list of all subnets <TAB> matches = itertools . chain ( * [ x . values ( ) for x in self . subnets . values ( ) ] ) <TAB> if subnet_ids : <TAB> <TAB> matches = [ sn for sn in matches if sn . id in subnet_ids ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> unknown_ids = set ( subnet_ids ) - set ( matches ) <TAB> <TAB> <TAB> raise InvalidSubnetIdError ( unknown_ids ) <TAB> if filters : <TAB> <TAB> matches = generic_filter ( filters , matches ) <TAB> return matches ","if len ( subnet_ids ) > len ( matches ) : 
","if len ( subnet_ids ) != len ( matches ) :
",85.2,69.98,False
"def _compat_map ( self , avs ) : <TAB> apps = { } <TAB> for av in avs : <TAB> <TAB> av . version = self <TAB> <TAB> app_id = av . application <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> apps [ amo . APP_IDS [ app_id ] ] = av <TAB> return apps ","if app_id in amo . APP_IDS : 
","if app_id in amo . APP_IDS :
",100.0,100.0,True
"def generator ( self , data ) : <TAB> if self . _config . SILENT : <TAB> <TAB> silent_vars = self . _get_silent_vars ( ) <TAB> for task in data : <TAB> <TAB> for var , val in task . environment_variables ( ) : <TAB> <TAB> <TAB> if self . _config . SILENT : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> int ( task . UniqueProcessId ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( task . ImageFileName ) , <TAB> <TAB> <TAB> <TAB> <TAB> Address ( task . Peb . ProcessParameters . Environment ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( var ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( val ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) ","if var in silent_vars : 
","if var in silent_vars :
",100.0,100.0,True
"def warn_if_repeatable_read ( self ) : <TAB> if "" mysql "" in self . current_engine ( ) . lower ( ) : <TAB> <TAB> cursor = self . connection_for_read ( ) . cursor ( ) <TAB> <TAB> if cursor . execute ( "" SELECT @@tx_isolation "" ) : <TAB> <TAB> <TAB> isolation = cursor . fetchone ( ) [ 0 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> <TAB> TxIsolationWarning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Polling results with transaction isolation level  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" repeatable-read within the same transaction  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" may give outdated results. Be sure to commit the  "" <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" transaction for each poll iteration. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) ","if isolation == "" REPEATABLE-READ "" : 
","if isolation != "" repeatable-read "" :
",55.31,19.13,False
"def filter_by_level ( record , level_per_module ) : <TAB> name = record [ "" name "" ] <TAB> level = 0 <TAB> if name in level_per_module : <TAB> <TAB> level = level_per_module [ name ] <TAB> elif name is not None : <TAB> <TAB> lookup = "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> level = level_per_module [ "" "" ] <TAB> <TAB> for n in name . split ( "" . "" ) : <TAB> <TAB> <TAB> lookup + = n <TAB> <TAB> <TAB> if lookup in level_per_module : <TAB> <TAB> <TAB> <TAB> level = level_per_module [ lookup ] <TAB> <TAB> <TAB> lookup + = "" . "" <TAB> if level is False : <TAB> <TAB> return False <TAB> return record [ "" level "" ] . no > = level ","if "" "" in level_per_module : 
","if "" . "" in level_per_module :
",77.33,74.19,False
"def _readStream ( self , handle : str , path : str ) - > None : <TAB> eof = False <TAB> file = Path ( path ) <TAB> with file . open ( "" w "" ) as f : <TAB> <TAB> while not eof : <TAB> <TAB> <TAB> response = await self . _client . send ( "" IO.read "" , { "" handle "" : handle } ) <TAB> <TAB> <TAB> eof = response . get ( "" eof "" , False ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f . write ( response . get ( "" data "" , "" "" ) ) <TAB> await self . _client . send ( "" IO.close "" , { "" handle "" : handle } ) ","if path : 
","if not eof :
",30.99,19.0,False
"def sendall ( self , data , flags = 0 ) : <TAB> if self . _sslobj : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" non-zero flags not allowed in calls to sendall() on  %s "" <TAB> <TAB> <TAB> <TAB> % self . __class__ <TAB> <TAB> <TAB> ) <TAB> <TAB> amount = len ( data ) <TAB> <TAB> count = 0 <TAB> <TAB> while count < amount : <TAB> <TAB> <TAB> v = self . send ( data [ count : ] ) <TAB> <TAB> <TAB> count + = v <TAB> <TAB> return amount <TAB> else : <TAB> <TAB> return socket . sendall ( self , data , flags ) ","if flags != 0 : 
","if flags != 0 :
",100.0,100.0,True
"def run ( self ) : <TAB> utils . assert_main_thread ( ) <TAB> # As a convenience, we'll set up the connection <TAB> # if there isn't one. So F5 (etc) can be hit <TAB> # to get started. <TAB> if not channel : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> SwiDebugStartChromeCommand . run ( self ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . window . run_command ( "" swi_debug_start "" ) <TAB> elif paused : <TAB> <TAB> logger . info ( "" Resuming... "" ) <TAB> <TAB> channel . send ( webkit . Debugger . resume ( ) ) <TAB> else : <TAB> <TAB> logger . info ( "" Pausing... "" ) <TAB> <TAB> channel . send ( webkit . Debugger . setSkipAllPauses ( False ) ) <TAB> <TAB> channel . send ( webkit . Debugger . pause ( ) ) ","if not chrome_launched ( ) : 
","if paused :
",27.54,0.0,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_presence_response ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def _replace_home ( x ) : <TAB> if xp . ON_WINDOWS : <TAB> <TAB> home = ( <TAB> <TAB> <TAB> builtins . __xonsh__ . env [ "" HOMEDRIVE "" ] + builtins . __xonsh__ . env [ "" HOMEPATH "" ] [ 0 ] <TAB> <TAB> ) <TAB> <TAB> if x . startswith ( home ) : <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = x . replace ( os . sep , os . altsep ) <TAB> <TAB> return x <TAB> else : <TAB> <TAB> home = builtins . __xonsh__ . env [ "" HOME "" ] <TAB> <TAB> if x . startswith ( home ) : <TAB> <TAB> <TAB> x = x . replace ( home , "" ~ "" , 1 ) <TAB> <TAB> return x ","if builtins . __xonsh__ . env . get ( "" FORCE_POSIX_PATHS "" ) : 
","if x . startswith ( os . sep ) :
",30.17,3.33,False
"def semanticTags ( self , semanticTags ) : <TAB> if semanticTags is None : <TAB> <TAB> self . __semanticTags = OrderedDict ( ) <TAB> # check <TAB> for key , value in list ( semanticTags . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise TypeError ( "" At least one key is not a valid int position "" ) <TAB> <TAB> if not isinstance ( value , list ) : <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> "" At least one value of the provided dict is not a list of string "" <TAB> <TAB> <TAB> ) <TAB> <TAB> for x in value : <TAB> <TAB> <TAB> if not isinstance ( x , str ) : <TAB> <TAB> <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" At least one value of the provided dict is not a list of string "" <TAB> <TAB> <TAB> <TAB> ) <TAB> self . __semanticTags = semanticTags ","if not isinstance ( key , int ) : 
","if not isinstance ( key , int ) :
",100.0,100.0,True
"def _recv ( ) : <TAB> try : <TAB> <TAB> return sock . recv ( bufsize ) <TAB> except SSLWantReadError : <TAB> <TAB> pass <TAB> except socket . error as exc : <TAB> <TAB> error_code = extract_error_code ( exc ) <TAB> <TAB> if error_code is None : <TAB> <TAB> <TAB> raise <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> r , w , e = select . select ( ( sock , ) , ( ) , ( ) , sock . gettimeout ( ) ) <TAB> if r : <TAB> <TAB> return sock . recv ( bufsize ) ","if error_code != errno . EAGAIN or error_code != errno . EWOULDBLOCK : 
","if error_code != socket . EWOULDBLOCK :
",45.46,26.75,False
"def _authenticate ( self ) : <TAB> oauth_token = self . options . get ( "" oauth_token "" ) <TAB> if oauth_token and not self . api . oauth_token : <TAB> <TAB> self . logger . info ( "" Attempting to authenticate using OAuth token "" ) <TAB> <TAB> self . api . oauth_token = oauth_token <TAB> <TAB> user = self . api . user ( schema = _user_schema ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . logger . info ( "" Successfully logged in as  {0} "" , user ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logger . error ( <TAB> <TAB> <TAB> <TAB> "" Failed to authenticate, the access token  "" "" is not valid "" <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return JustinTVPluginBase . _authenticate ( self ) ","if user : 
","if user . is_authenticated ( ) :
",33.58,10.55,False
"def reverse ( self , * args ) : <TAB> assert self . _path is not None , "" Cannot reverse url regex  "" + self . regex . pattern <TAB> assert len ( args ) == self . _group_count , "" required number of arguments  "" "" not found "" <TAB> if not len ( args ) : <TAB> <TAB> return self . _path <TAB> converted_args = [ ] <TAB> for a in args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> a = str ( a ) <TAB> <TAB> converted_args . append ( escape . url_escape ( utf8 ( a ) , plus = False ) ) <TAB> return self . _path % tuple ( converted_args ) ","if not isinstance ( a , ( unicode_type , bytes ) ) : 
","if not isinstance ( a , ( unicode_type , bytes ) ) :
",100.0,100.0,True
"def determine_block_hints ( self , text ) : <TAB> hints = "" "" <TAB> if text : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hints + = str ( self . best_indent ) <TAB> <TAB> if text [ - 1 ] not in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" - "" <TAB> <TAB> elif len ( text ) == 1 or text [ - 2 ] in "" \n \x85 \u2028 \u2029 "" : <TAB> <TAB> <TAB> hints + = "" + "" <TAB> return hints ","if text [ 0 ] in "" \n \x85 \u2028 \u2029 "" : 
","if self . best_indent :
",25.86,1.87,False
"def find_package_modules ( package , mask ) : <TAB> import fnmatch <TAB> if hasattr ( package , "" __loader__ "" ) and hasattr ( package . __loader__ , "" _files "" ) : <TAB> <TAB> path = package . __name__ . replace ( "" . "" , os . path . sep ) <TAB> <TAB> mask = os . path . join ( path , mask ) <TAB> <TAB> for fnm in package . __loader__ . _files . iterkeys ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield os . path . splitext ( fnm ) [ 0 ] . replace ( os . path . sep , "" . "" ) <TAB> else : <TAB> <TAB> path = package . __path__ [ 0 ] <TAB> <TAB> for fnm in os . listdir ( path ) : <TAB> <TAB> <TAB> if fnmatch . fnmatchcase ( fnm , mask ) : <TAB> <TAB> <TAB> <TAB> yield "" %s . %s "" % ( package . __name__ , os . path . splitext ( fnm ) [ 0 ] ) ","if fnmatch . fnmatchcase ( fnm , mask ) : 
","if fnmatch . fnmatchcase ( fnm , mask ) :
",100.0,100.0,True
"def _condition ( ct ) : <TAB> for qobj in args : <TAB> <TAB> if qobj . connector == "" AND "" and not qobj . negated : <TAB> <TAB> <TAB> # normal kwargs are an AND anyway, so just use those for now <TAB> <TAB> <TAB> for child in qobj . children : <TAB> <TAB> <TAB> <TAB> kwargs . update ( dict ( [ child ] ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError ( "" Unsupported Q object "" ) <TAB> for attr , val in kwargs . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return False <TAB> return True ","if getattr ( ct , attr ) != val : 
","if ct . attr == attr and val != ct . val :
",27.61,8.55,False
"def process ( self , resources ) : <TAB> session = local_session ( self . manager . session_factory ) <TAB> client = session . client ( "" logs "" ) <TAB> state = self . data . get ( "" state "" , True ) <TAB> key = self . resolve_key ( self . data . get ( "" kms-key "" ) ) <TAB> for r in resources : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> client . associate_kms_key ( logGroupName = r [ "" logGroupName "" ] , kmsKeyId = key ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> client . disassociate_kms_key ( logGroupName = r [ "" logGroupName "" ] ) <TAB> <TAB> except client . exceptions . ResourceNotFoundException : <TAB> <TAB> <TAB> continue ","if state : 
","if state :
",78.12,0.0,False
"def get_xmm ( env , ii ) : <TAB> if is_gather ( ii ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return gen_reg_simd_unified ( env , "" xmm_evex "" , True ) <TAB> <TAB> return gen_reg_simd_unified ( env , "" xmm "" , False ) <TAB> if ii . space == "" evex "" : <TAB> <TAB> return gen_reg ( env , "" xmm_evex "" ) <TAB> return gen_reg ( env , "" xmm "" ) ","if ii . space == "" evex "" : 
","if ii . space == "" evex "" :
",100.0,100.0,True
"def parent ( self ) : <TAB> """"""Return the parent device."""""" <TAB> if self . _has_parent is None : <TAB> <TAB> _parent = self . _ctx . backend . get_parent ( self . _ctx . dev ) <TAB> <TAB> self . _has_parent = _parent is not None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _parent = Device ( _parent , self . _ctx . backend ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _parent = None <TAB> return self . _parent ","if self . _has_parent : 
","if _parent is not None :
",28.03,13.54,False
"def cascade ( self , event = None ) : <TAB> """"""Cascade all Leo windows."""""" <TAB> x , y , delta = 50 , 50 , 50 <TAB> for frame in g . app . windowList : <TAB> <TAB> w = frame and frame . top <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r = w . geometry ( )<TAB> # a Qt.Rect <TAB> <TAB> <TAB> # 2011/10/26: Fix bug 823601: cascade-windows fails. <TAB> <TAB> <TAB> w . setGeometry ( QtCore . QRect ( x , y , r . width ( ) , r . height ( ) ) ) <TAB> <TAB> <TAB> # Compute the new offsets. <TAB> <TAB> <TAB> x + = 30 <TAB> <TAB> <TAB> y + = 30 <TAB> <TAB> <TAB> if x > 200 : <TAB> <TAB> <TAB> <TAB> x = 10 + delta <TAB> <TAB> <TAB> <TAB> y = 40 + delta <TAB> <TAB> <TAB> <TAB> delta + = 10 ","if w : 
","if w :
",78.12,0.0,False
"def _GetGoodDispatchAndUserName ( IDispatch , userName , clsctx ) : <TAB> # Get a dispatch object, and a 'user name' (ie, the name as <TAB> # displayed to the user in repr() etc. <TAB> if userName is None : <TAB> <TAB> if isinstance ( IDispatch , str ) : <TAB> <TAB> <TAB> userName = IDispatch <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # We always want the displayed name to be a real string <TAB> <TAB> <TAB> userName = IDispatch . encode ( "" ascii "" , "" replace "" ) <TAB> elif type ( userName ) == unicode : <TAB> <TAB> # As above - always a string... <TAB> <TAB> userName = userName . encode ( "" ascii "" , "" replace "" ) <TAB> else : <TAB> <TAB> userName = str ( userName ) <TAB> return ( _GetGoodDispatch ( IDispatch , clsctx ) , userName ) ","elif isinstance ( IDispatch , unicode ) : 
","elif type ( IDispatch ) == unicode :
",28.92,12.55,False
"def _infer_return_type ( * args ) : <TAB> """"""Look at the type of all args and divine their implied return type."""""" <TAB> return_type = None <TAB> for arg in args : <TAB> <TAB> if arg is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if isinstance ( arg , bytes ) : <TAB> <TAB> <TAB> if return_type is str : <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = bytes <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise TypeError ( "" Can ' t mix bytes and non-bytes in  "" "" path components. "" ) <TAB> <TAB> <TAB> return_type = str <TAB> if return_type is None : <TAB> <TAB> return str<TAB> # tempfile APIs return a str by default. <TAB> return return_type ","if return_type is bytes : 
","if isinstance ( arg , bytes ) :
",27.63,7.27,False
"def test_ESPnetDataset_h5file_1 ( h5file_1 ) : <TAB> dataset = IterableESPnetDataset ( <TAB> <TAB> path_name_type_list = [ ( h5file_1 , "" data4 "" , "" hdf5 "" ) ] , <TAB> <TAB> preprocess = preprocess , <TAB> ) <TAB> for key , data in dataset : <TAB> <TAB> if key == "" a "" : <TAB> <TAB> <TAB> assert data [ "" data4 "" ] . shape == ( <TAB> <TAB> <TAB> <TAB> 100 , <TAB> <TAB> <TAB> <TAB> 80 , <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert data [ "" data4 "" ] . shape == ( <TAB> <TAB> <TAB> <TAB> 150 , <TAB> <TAB> <TAB> <TAB> 80 , <TAB> <TAB> <TAB> ) ","if key == "" b "" : 
","if key == "" b "" :
",100.0,100.0,True
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> if exclude_meta and field . meta : <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset : <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val ","if field_val is _marker : 
","if field_val is None :
",39.55,55.78,False
"def then ( self , matches , when_response , context ) : <TAB> if is_iterable ( when_response ) : <TAB> <TAB> ret = [ ] <TAB> <TAB> when_response = list ( when_response ) <TAB> <TAB> for match in when_response : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if self . match_name : <TAB> <TAB> <TAB> <TAB> <TAB> match . name = self . match_name <TAB> <TAB> <TAB> <TAB> matches . append ( match ) <TAB> <TAB> <TAB> <TAB> ret . append ( match ) <TAB> <TAB> return ret <TAB> if self . match_name : <TAB> <TAB> when_response . name = self . match_name <TAB> if when_response not in matches : <TAB> <TAB> matches . append ( when_response ) <TAB> <TAB> return when_response ","if match not in matches : 
","if match . name is None :
",29.32,14.54,False
"def _set_chat_ids ( self , chat_id : SLT [ int ] ) - > None : <TAB> with self . __lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> <TAB> f "" Can ' t set  { self . chat_id_name }  in conjunction with (already set)  "" <TAB> <TAB> <TAB> <TAB> f "" { self . username_name } s. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _chat_ids = self . _parse_chat_id ( chat_id ) ","if chat_id and self . _usernames : 
","if self . _usernames :
",53.5,40.83,False
"def discover ( self , * objlist ) : <TAB> ret = [ ] <TAB> for l in self . splitlines ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if l [ 0 ] == "" Filename "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> int ( l [ 2 ] ) <TAB> <TAB> <TAB> int ( l [ 3 ] ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> #<TAB> <TAB>    ret.append(improve(l[0]))<TAB> <TAB> ret . append ( l [ 0 ] ) <TAB> ret . sort ( ) <TAB> for item in objlist : <TAB> <TAB> ret . append ( item ) <TAB> return ret ","if len ( l ) < 5 : 
","if len ( l ) < 4 :
",85.56,70.71,False
"def get_changed_module ( self ) : <TAB> source = self . resource . read ( ) <TAB> change_collector = codeanalyze . ChangeCollector ( source ) <TAB> if self . replacement is not None : <TAB> <TAB> change_collector . add_change ( self . skip_start , self . skip_end , self . replacement ) <TAB> for occurrence in self . occurrence_finder . find_occurrences ( self . resource ) : <TAB> <TAB> start , end = occurrence . get_primary_range ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . handle . occurred_inside_skip ( change_collector , occurrence ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . handle . occurred_outside_skip ( change_collector , occurrence ) <TAB> result = change_collector . get_changed ( ) <TAB> if result is not None and result != source : <TAB> <TAB> return result ","if self . skip_start < = start < self . skip_end : 
","if start < = end :
",31.81,7.51,False
"def hpat_pandas_series_var_impl ( <TAB> self , axis = None , skipna = None , level = None , ddof = 1 , numeric_only = None ) : <TAB> if skipna is None : <TAB> <TAB> skipna = True <TAB> if skipna : <TAB> <TAB> valuable_length = len ( self . _data ) - numpy . sum ( numpy . isnan ( self . _data ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return numpy . nan <TAB> <TAB> return ( <TAB> <TAB> <TAB> numpy_like . nanvar ( self . _data ) * valuable_length / ( valuable_length - ddof ) <TAB> <TAB> ) <TAB> if len ( self . _data ) < = ddof : <TAB> <TAB> return numpy . nan <TAB> return self . _data . var ( ) * len ( self . _data ) / ( len ( self . _data ) - ddof ) ","if valuable_length < = ddof : 
","if valuable_length < ddof :
",38.32,61.3,False
"def to_dict ( self , validate = True , ignore = ( ) , context = None ) : <TAB> context = context or { } <TAB> condition = getattr ( self , "" condition "" , Undefined ) <TAB> copy = self<TAB> # don't copy unless we need to <TAB> if condition is not Undefined : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pass <TAB> <TAB> elif "" field "" in condition and "" type "" not in condition : <TAB> <TAB> <TAB> kwds = parse_shorthand ( condition [ "" field "" ] , context . get ( "" data "" , None ) ) <TAB> <TAB> <TAB> copy = self . copy ( deep = [ "" condition "" ] ) <TAB> <TAB> <TAB> copy . condition . update ( kwds ) <TAB> return super ( ValueChannelMixin , copy ) . to_dict ( <TAB> <TAB> validate = validate , ignore = ignore , context = context <TAB> ) ","if isinstance ( condition , core . SchemaBase ) : 
","if condition is Undefined :
",26.44,5.17,False
"def get_field_result ( self , result , field_name ) : <TAB> if isinstance ( result . field , models . ImageField ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> img = getattr ( result . obj , field_name ) <TAB> <TAB> <TAB> result . text = mark_safe ( <TAB> <TAB> <TAB> <TAB> ' <a href= "" %s ""  target= "" _blank ""  title= "" %s ""  data-gallery= "" gallery "" ><img src= "" %s ""  class= "" field_img "" /></a> ' <TAB> <TAB> <TAB> <TAB> % ( img . url , result . label , img . url ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . include_image = True <TAB> return result ","if result . value : 
","if not self . include_image :
",36.56,7.27,False
"def run ( self ) : <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> dp = self . queue_get_stoppable ( self . inq ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> # cannot ignore None here. will lead to unsynced send/recv <TAB> <TAB> <TAB> obj = self . func ( dp ) <TAB> <TAB> <TAB> self . queue_put_stoppable ( self . outq , obj ) <TAB> except Exception : <TAB> <TAB> if self . stopped ( ) : <TAB> <TAB> <TAB> pass<TAB> # skip duplicated error messages <TAB> <TAB> else : <TAB> <TAB> <TAB> raise <TAB> finally : <TAB> <TAB> self . stop ( ) ","if self . stopped ( ) : 
","if dp is None :
",27.23,8.52,False
"def _evaluate_local_single ( self , iterator ) : <TAB> for batch in iterator : <TAB> <TAB> in_arrays = convert . _call_converter ( self . converter , batch , self . device ) <TAB> <TAB> with function . no_backprop_mode ( ) : <TAB> <TAB> <TAB> if isinstance ( in_arrays , tuple ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * in_arrays ) <TAB> <TAB> <TAB> elif isinstance ( in_arrays , dict ) : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( * * in_arrays ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> results = self . calc_local ( in_arrays ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _progress_hook ( batch ) <TAB> <TAB> yield results ","if self . _progress_hook : 
","if self . _progress_hook :
",100.0,100.0,True
"def merge ( self , other ) : <TAB> d = self . _name2ft <TAB> for name , ( f , t ) in other . _name2ft . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Don't print here by default, since doing <TAB> <TAB> <TAB> #<TAB>  so breaks some of the buildbots<TAB> <TAB> <TAB> # print ""*** DocTestRunner.merge: '"" + name + ""' in both"" \ <TAB> <TAB> <TAB> #<TAB> "" testers; summing outcomes.""<TAB> <TAB> <TAB> f2 , t2 = d [ name ] <TAB> <TAB> <TAB> f = f + f2 <TAB> <TAB> <TAB> t = t + t2 <TAB> <TAB> d [ name ] = f , t ","if name in d : 
","if name in d :
",100.0,100.0,True
"def _addSettingsToPanels ( self , category , left , right ) : <TAB> count = len ( profile . getSubCategoriesFor ( category ) ) + len ( <TAB> <TAB> profile . getSettingsForCategory ( category ) <TAB> ) <TAB> p = left <TAB> n = 0 <TAB> for title in profile . getSubCategoriesFor ( category ) : <TAB> <TAB> n + = 1 + len ( profile . getSettingsForCategory ( category , title ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p = right <TAB> <TAB> configBase . TitleRow ( p , _ ( title ) ) <TAB> <TAB> for s in profile . getSettingsForCategory ( category , title ) : <TAB> <TAB> <TAB> configBase . SettingRow ( p , s . getName ( ) ) ","if n > count / 2 : 
","if n > count :
",48.09,47.4,False
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> if os . path . isdir ( path ) : <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> if pattern . match ( value ) is not None : <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist ","if i == "" . "" or i == "" .. "" : 
","if i == "" . "" :
",58.9,34.79,False
def check_network_private ( test_network ) : <TAB> test_net = ipaddress . IPNetwork ( test_network ) <TAB> test_start = test_net . network <TAB> test_end = test_net . broadcast <TAB> for network in settings . vpn . safe_priv_subnets : <TAB> <TAB> network = ipaddress . IPNetwork ( network ) <TAB> <TAB> net_start = network . network <TAB> <TAB> net_end = network . broadcast <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ,"if test_start > = net_start and test_end < = net_end : 
","if net_start == test_end and net_end == net_start :
",26.55,27.24,False
"def _end_description ( self ) : <TAB> if self . _summaryKey == "" content "" : <TAB> <TAB> self . _end_content ( ) <TAB> else : <TAB> <TAB> value = self . popContent ( "" description "" ) <TAB> <TAB> context = self . _getContext ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> context [ "" textinput "" ] [ "" description "" ] = value <TAB> <TAB> elif self . inimage : <TAB> <TAB> <TAB> context [ "" image "" ] [ "" description "" ] = value <TAB> self . _summaryKey = None ","if self . intextinput : 
","if self . intextinput :
",100.0,100.0,True
def compute_nullable_nonterminals ( self ) : <TAB> nullable = { } <TAB> num_nullable = 0 <TAB> while 1 : <TAB> <TAB> for p in self . grammar . Productions [ 1 : ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> for t in p . prod : <TAB> <TAB> <TAB> <TAB> if not t in nullable : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> nullable [ p . name ] = 1 <TAB> <TAB> if len ( nullable ) == num_nullable : <TAB> <TAB> <TAB> break <TAB> <TAB> num_nullable = len ( nullable ) <TAB> return nullable ,"if p . len == 0 : 
","if p . is_terminals ( ) :
",40.31,19.07,False
"def process_bind_param ( self , value , dialect ) : <TAB> if value is not None : <TAB> <TAB> if MAX_METADATA_VALUE_SIZE is not None : <TAB> <TAB> <TAB> for k , v in list ( value . items ( ) ) : <TAB> <TAB> <TAB> <TAB> sz = total_size ( v ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> del value [ k ] <TAB> <TAB> <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" Refusing to bind metadata key  {}  due to size ( {} ) "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> k , sz <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> value = json_encoder . encode ( value ) . encode ( ) <TAB> return value ","if sz > MAX_METADATA_VALUE_SIZE : 
","if sz > MAX_METADATA_VALUE_SIZE :
",100.0,100.0,True
"def process_input_line ( self , line , store_history = True ) : <TAB> """"""process the input, capturing stdout"""""" <TAB> stdout = sys . stdout <TAB> splitter = self . IP . input_splitter <TAB> try : <TAB> <TAB> sys . stdout = self . cout <TAB> <TAB> splitter . push ( line ) <TAB> <TAB> more = splitter . push_accepts_more ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> source_raw = splitter . source_raw_reset ( ) [ 1 ] <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> # recent ipython #4504 <TAB> <TAB> <TAB> <TAB> source_raw = splitter . raw_reset ( ) <TAB> <TAB> <TAB> self . IP . run_cell ( source_raw , store_history = store_history ) <TAB> finally : <TAB> <TAB> sys . stdout = stdout ","if not more : 
","if not more :
",100.0,100.0,True
"def _dump_section ( self , name , values , f ) : <TAB> doc = "" __doc__ "" <TAB> <MASK> <TAB> <TAB> print ( "" #  %s "" % values [ doc ] , file = f ) <TAB> print ( "" %s ( "" % name , file = f ) <TAB> for k , v in values . items ( ) : <TAB> <TAB> if k . endswith ( "" __doc__ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> doc = k + "" __doc__ "" <TAB> <TAB> if doc in values : <TAB> <TAB> <TAB> print ( ""<TAB>  # %s "" % values [ doc ] , file = f ) <TAB> <TAB> print ( ""<TAB>  %s  =  %s , "" % ( k , pprint . pformat ( v , indent = 8 ) ) , file = f ) <TAB> print ( "" ) \n "" , file = f ) ","if doc in values : 
","if doc in values :
",100.0,100.0,True
"def open_session ( self , app , request ) : <TAB> sid = request . cookies . get ( app . session_cookie_name ) <TAB> if sid : <TAB> <TAB> stored_session = self . cls . objects ( sid = sid ) . first ( ) <TAB> <TAB> if stored_session : <TAB> <TAB> <TAB> expiration = stored_session . expiration <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> expiration = expiration . replace ( tzinfo = utc ) <TAB> <TAB> <TAB> if expiration > datetime . datetime . utcnow ( ) . replace ( tzinfo = utc ) : <TAB> <TAB> <TAB> <TAB> return MongoEngineSession ( <TAB> <TAB> <TAB> <TAB> <TAB> initial = stored_session . data , sid = stored_session . sid <TAB> <TAB> <TAB> <TAB> ) <TAB> return MongoEngineSession ( sid = str ( uuid . uuid4 ( ) ) ) ","if not expiration . tzinfo : 
","if expiration :
",27.72,0.0,False
"def table_entry ( mode1 , bind_type1 , mode2 , bind_type2 ) : <TAB> with sock ( mode1 ) as sock1 : <TAB> <TAB> bind ( sock1 , bind_type1 ) <TAB> <TAB> try : <TAB> <TAB> <TAB> with sock ( mode2 ) as sock2 : <TAB> <TAB> <TAB> <TAB> bind ( sock2 , bind_type2 ) <TAB> <TAB> except OSError as exc : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return "" INUSE "" <TAB> <TAB> <TAB> elif exc . winerror == errno . WSAEACCES : <TAB> <TAB> <TAB> <TAB> return "" ACCESS "" <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" Success "" ","if exc . winerror == errno . WSAEADDRINUSE : 
","if exc . winerror == errno . EINVAL :
",87.71,78.25,False
"def __init__ ( self , ruleset ) : <TAB> # Organize rules by path <TAB> self . ruleset = ruleset <TAB> self . rules = { } <TAB> for filename in self . ruleset . rules : <TAB> <TAB> for rule in self . ruleset . rules [ filename ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> manage_dictionary ( self . rules , rule . path , [ ] ) <TAB> <TAB> <TAB> self . rules [ rule . path ] . append ( rule ) ","if not rule . enabled : 
","if not rule . enabled :
",100.0,100.0,True
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> if len ( i ) == 0 : <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> if reply == "" !done "" : <TAB> <TAB> <TAB> return r ","if j == - 1 : 
","if j == - 1 :
",100.0,100.0,True
"def _check_decorator_overload ( name : str , old : str , new : str ) - > int : <TAB> """"""Conditions for a decorator to overload an existing one."""""" <TAB> properties = _property_decorators ( name ) <TAB> if old == new : <TAB> <TAB> return _MERGE <TAB> elif old in properties and new in properties : <TAB> <TAB> p_old , p_new = properties [ old ] . precedence , properties [ new ] . precedence <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return _DISCARD <TAB> <TAB> elif p_old == p_new : <TAB> <TAB> <TAB> return _MERGE <TAB> <TAB> else : <TAB> <TAB> <TAB> return _REPLACE <TAB> raise OverloadedDecoratorError ( name , "" "" ) ","if p_old > p_new : 
","if p_old == p_new :
",58.14,52.54,False
"def validate_pk ( self ) : <TAB> try : <TAB> <TAB> self . _key = serialization . load_pem_private_key ( <TAB> <TAB> <TAB> self . key , password = None , backend = default_backend ( ) <TAB> <TAB> ) <TAB> <TAB> if self . _key . key_size > 2048 : <TAB> <TAB> <TAB> AWSValidationException ( <TAB> <TAB> <TAB> <TAB> "" The private key length is not supported. Only 1024-bit and 2048-bit are allowed. "" <TAB> <TAB> <TAB> ) <TAB> except Exception as err : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> raise AWSValidationException ( <TAB> <TAB> <TAB> "" The private key is not PEM-encoded or is not valid. "" <TAB> <TAB> ) ","if isinstance ( err , AWSValidationException ) : 
","if err . errno != "" InvalidKey.InvalidKey.InvalidKey.InvalidKey.InvalidKey. "" :
",26.81,2.66,False
"def _add_custom_statement ( self , custom_statements ) : <TAB> if custom_statements is None : <TAB> <TAB> return <TAB> self . resource_policy [ "" Version "" ] = "" 2012-10-17 "" <TAB> if self . resource_policy . get ( "" Statement "" ) is None : <TAB> <TAB> self . resource_policy [ "" Statement "" ] = custom_statements <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> custom_statements = [ custom_statements ] <TAB> <TAB> statement = self . resource_policy [ "" Statement "" ] <TAB> <TAB> if not isinstance ( statement , list ) : <TAB> <TAB> <TAB> statement = [ statement ] <TAB> <TAB> for s in custom_statements : <TAB> <TAB> <TAB> if s not in statement : <TAB> <TAB> <TAB> <TAB> statement . append ( s ) <TAB> <TAB> self . resource_policy [ "" Statement "" ] = statement ","if not isinstance ( custom_statements , list ) : 
","if not isinstance ( custom_statements , list ) :
",100.0,100.0,True
"def load ( self , repn ) : <TAB> for key in repn : <TAB> <TAB> tmp = self . _convert ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . declare ( tmp ) <TAB> <TAB> item = dict . __getitem__ ( self , tmp ) <TAB> <TAB> item . _active = True <TAB> <TAB> item . load ( repn [ key ] ) ","if tmp not in self : 
","if tmp is not None :
",30.13,19.3,False
"def on_press_release ( x ) : <TAB> """"""Keyboard callback function."""""" <TAB> global is_recording , enable_trigger_record <TAB> press = keyboard . KeyboardEvent ( "" down "" , 28 , "" space "" ) <TAB> release = keyboard . KeyboardEvent ( "" up "" , 28 , "" space "" ) <TAB> if x . event_type == "" down "" and x . name == press . name : <TAB> <TAB> if ( not is_recording ) and enable_trigger_record : <TAB> <TAB> <TAB> sys . stdout . write ( "" Start Recording ...  "" ) <TAB> <TAB> <TAB> sys . stdout . flush ( ) <TAB> <TAB> <TAB> is_recording = True <TAB> if x . event_type == "" up "" and x . name == release . name : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> is_recording = False ","if is_recording == True : 
","if enable_trigger_record :
",28.39,7.49,False
"def apply_mask ( self , mask , data_t , data_f ) : <TAB> ind_t , ind_f = 0 , 0 <TAB> out = [ ] <TAB> for m in cycle ( mask ) : <TAB> <TAB> if m : <TAB> <TAB> <TAB> if ind_t == len ( data_t ) : <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out . append ( data_t [ ind_t ] ) <TAB> <TAB> <TAB> ind_t + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return out <TAB> <TAB> <TAB> out . append ( data_f [ ind_f ] ) <TAB> <TAB> <TAB> ind_f + = 1 <TAB> return out ","if ind_f == len ( data_f ) : 
","if ind_f == len ( data_f ) :
",100.0,100.0,True
"def oo_contains_rule ( source , apiGroups , resources , verbs ) : <TAB> """"""Return true if the specified rule is contained within the provided source"""""" <TAB> rules = source [ "" rules "" ] <TAB> if rules : <TAB> <TAB> for rule in rules : <TAB> <TAB> <TAB> if set ( rule [ "" apiGroups "" ] ) == set ( apiGroups ) : <TAB> <TAB> <TAB> <TAB> if set ( rule [ "" resources "" ] ) == set ( resources ) : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if set ( rule [ "" verbs "" ] ) == set ( verbs ) : 
","if len ( rule [ "" verbs "" ] ) == len ( verbs ) :
",84.45,70.86,False
"def _maybe_commit_artifact ( self , artifact_id ) : <TAB> artifact_status = self . _artifacts [ artifact_id ] <TAB> if artifact_status [ "" pending_count "" ] == 0 and artifact_status [ "" commit_requested "" ] : <TAB> <TAB> for callback in artifact_status [ "" pre_commit_callbacks "" ] : <TAB> <TAB> <TAB> callback ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _api . commit_artifact ( artifact_id ) <TAB> <TAB> for callback in artifact_status [ "" post_commit_callbacks "" ] : <TAB> <TAB> <TAB> callback ( ) ","if artifact_status [ "" finalize "" ] : 
","if artifact_status [ "" pending_count "" ] == 0 and artifact_status [ "" post_commit_requested "" ] :
",55.32,20.94,False
"def shuffler ( iterator , pool_size = 10 * * 5 , refill_threshold = 0.9 ) : <TAB> yields_between_refills = round ( pool_size * ( 1 - refill_threshold ) ) <TAB> # initialize pool; this step may or may not exhaust the iterator. <TAB> pool = take_n ( pool_size , iterator ) <TAB> while True : <TAB> <TAB> random . shuffle ( pool ) <TAB> <TAB> for i in range ( yields_between_refills ) : <TAB> <TAB> <TAB> yield pool . pop ( ) <TAB> <TAB> next_batch = take_n ( yields_between_refills , iterator ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> pool . extend ( next_batch ) <TAB> # finish consuming whatever's left - no need for further randomization. <TAB> yield from pool ","if not next_batch : 
","if not next_batch :
",100.0,100.0,True
"def __getitem__ ( self , key , _get_mode = False ) : <TAB> if not _get_mode : <TAB> <TAB> if isinstance ( key , ( int , long ) ) : <TAB> <TAB> <TAB> return self . _list [ key ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . __class__ ( self . _list [ key ] ) <TAB> ikey = key . lower ( ) <TAB> for k , v in self . _list : <TAB> <TAB> if k . lower ( ) == ikey : <TAB> <TAB> <TAB> return v <TAB> # micro optimization: if we are in get mode we will catch that <TAB> # exception one stack level down so we can raise a standard <TAB> # key error instead of our special one. <TAB> if _get_mode : <TAB> <TAB> raise KeyError ( ) <TAB> raise BadRequestKeyError ( key ) ","elif isinstance ( key , slice ) : 
","elif isinstance ( key , str ) :
",79.9,59.46,False
"def find ( self , path ) : <TAB> if os . path . isfile ( path ) or os . path . islink ( path ) : <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> if self . match_function ( path ) : <TAB> <TAB> <TAB> self . files . append ( path ) <TAB> elif os . path . isdir ( path ) : <TAB> <TAB> for content in os . listdir ( path ) : <TAB> <TAB> <TAB> file = os . path . join ( path , content ) <TAB> <TAB> <TAB> if os . path . isfile ( file ) or os . path . islink ( file ) : <TAB> <TAB> <TAB> <TAB> self . num_files = self . num_files + 1 <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . files . append ( file ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . find ( file ) ","if self . match_function ( file ) : 
","if self . match_function ( file ) :
",100.0,100.0,True
"def validate_nb ( self , nb ) : <TAB> super ( MetadataValidatorV3 , self ) . validate_nb ( nb ) <TAB> ids = set ( [ ] ) <TAB> for cell in nb . cells : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> grade = cell . metadata [ "" nbgrader "" ] [ "" grade "" ] <TAB> <TAB> solution = cell . metadata [ "" nbgrader "" ] [ "" solution "" ] <TAB> <TAB> locked = cell . metadata [ "" nbgrader "" ] [ "" locked "" ] <TAB> <TAB> if not grade and not solution and not locked : <TAB> <TAB> <TAB> continue <TAB> <TAB> grade_id = cell . metadata [ "" nbgrader "" ] [ "" grade_id "" ] <TAB> <TAB> if grade_id in ids : <TAB> <TAB> <TAB> raise ValidationError ( "" Duplicate grade id:  {} "" . format ( grade_id ) ) <TAB> <TAB> ids . add ( grade_id ) ","if "" nbgrader "" not in cell . metadata : 
","if "" nbgrader "" not in cell . metadata :
",100.0,100.0,True
"def _skip_start ( self ) : <TAB> start , stop = self . start , self . stop <TAB> for chunk in self . app_iter : <TAB> <TAB> self . _pos + = len ( chunk ) <TAB> <TAB> if self . _pos < start : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif self . _pos == start : <TAB> <TAB> <TAB> return b "" "" <TAB> <TAB> else : <TAB> <TAB> <TAB> chunk = chunk [ start - self . _pos : ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> chunk = chunk [ : stop - self . _pos ] <TAB> <TAB> <TAB> <TAB> assert len ( chunk ) == stop - start <TAB> <TAB> <TAB> return chunk <TAB> else : <TAB> <TAB> raise StopIteration ( ) ","if stop is not None and self . _pos > stop : 
","if self . _pos < stop :
",37.24,22.87,False
"def _SetUser ( self , users ) : <TAB> for user in users . items ( ) : <TAB> <TAB> username = user [ 0 ] <TAB> <TAB> settings = user [ 1 ] <TAB> <TAB> room = settings [ "" room "" ] [ "" name "" ] if "" room "" in settings else None <TAB> <TAB> file_ = settings [ "" file "" ] if "" file "" in settings else None <TAB> <TAB> if "" event "" in settings : <TAB> <TAB> <TAB> if "" joined "" in settings [ "" event "" ] : <TAB> <TAB> <TAB> <TAB> self . _client . userlist . addUser ( username , room , file_ ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _client . removeUser ( username ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _client . userlist . modUser ( username , room , file_ ) ","elif "" left "" in settings [ "" event "" ] : 
","elif "" deleted "" in settings [ "" event "" ] :
",88.63,76.92,False
"def run_tests ( ) : <TAB> # type: () -> None <TAB> x = 5 <TAB> with switch ( x ) as case : <TAB> <TAB> if case ( 0 ) : <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> <TAB> print ( "" zero "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" one or two "" ) <TAB> <TAB> elif case ( 3 , 4 ) : <TAB> <TAB> <TAB> print ( "" three or four "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> print ( "" default "" ) <TAB> <TAB> <TAB> print ( "" another "" ) ","elif case ( 1 , 2 ) : 
","elif case ( 1 ) :
",46.51,43.3,False
"def _populate ( ) : <TAB> for fname in glob . glob ( os . path . join ( os . path . dirname ( __file__ ) , "" data "" , "" *.json "" ) ) : <TAB> <TAB> with open ( fname ) as inf : <TAB> <TAB> <TAB> data = json . load ( inf ) <TAB> <TAB> <TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB> <TAB> <TAB> data = data [ list ( data . keys ( ) ) [ 0 ] ] <TAB> <TAB> <TAB> for item in data : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> LOGGER . warning ( "" Repeated emoji  {} "" . format ( item [ "" key "" ] ) ) <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> TABLE [ item [ "" key "" ] ] = item [ "" value "" ] ","if item [ "" key "" ] in TABLE : 
","if len ( item [ "" key "" ] ) > 1 :
",58.49,40.9,False
"def slot_to_material ( bobject : bpy . types . Object , slot : bpy . types . MaterialSlot ) : <TAB> mat = slot . material <TAB> # Pick up backed material if present <TAB> if mat is not None : <TAB> <TAB> baked_mat = mat . name + "" _ "" + bobject . name + "" _baked "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mat = bpy . data . materials [ baked_mat ] <TAB> return mat ","if baked_mat in bpy . data . materials : 
","if baked_mat in bpy . data . materials :
",100.0,100.0,True
"def __keyPress ( self , widget , event ) : <TAB> if event . key == "" G "" and event . modifiers & event . Modifiers . Control : <TAB> <TAB> if not all ( hasattr ( p , "" isGanged "" ) for p in self . getPlugs ( ) ) : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __ungang ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __gang ( ) <TAB> <TAB> return True <TAB> return False ","if all ( p . isGanged ( ) for p in self . getPlugs ( ) ) : 
","elif event . modifiers & event . Modifiers . Ganged :
",11.44,2.61,False
"def check_expected ( result , expected , contains = False ) : <TAB> if sys . version_info [ 0 ] > = 3 : <TAB> <TAB> if isinstance ( result , str ) : <TAB> <TAB> <TAB> result = result . encode ( "" ascii "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> expected = expected . encode ( "" ascii "" ) <TAB> resultlines = result . splitlines ( ) <TAB> expectedlines = expected . splitlines ( ) <TAB> if len ( resultlines ) != len ( expectedlines ) : <TAB> <TAB> return False <TAB> for rline , eline in zip ( resultlines , expectedlines ) : <TAB> <TAB> if contains : <TAB> <TAB> <TAB> if eline not in rline : <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> else : <TAB> <TAB> <TAB> if not rline . endswith ( eline ) : <TAB> <TAB> <TAB> <TAB> return False <TAB> return True ","if isinstance ( expected , str ) : 
","if isinstance ( expected , str ) :
",100.0,100.0,True
"def hosts_to_domains ( self , hosts , exclusions = [ ] ) : <TAB> domains = [ ] <TAB> for host in hosts : <TAB> <TAB> elements = host . split ( "" . "" ) <TAB> <TAB> # recursively walk through the elements <TAB> <TAB> # extracting all possible (sub)domains <TAB> <TAB> while len ( elements ) > = 2 : <TAB> <TAB> <TAB> # account for domains stored as hosts <TAB> <TAB> <TAB> if len ( elements ) == 2 : <TAB> <TAB> <TAB> <TAB> domain = "" . "" . join ( elements ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> # drop the host element <TAB> <TAB> <TAB> <TAB> domain = "" . "" . join ( elements [ 1 : ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> domains . append ( domain ) <TAB> <TAB> <TAB> del elements [ 0 ] <TAB> return domains ","if domain not in domains + exclusions : 
","if domain not in exclusions :
",51.58,43.3,False
"def hsconn_sender ( self ) : <TAB> while not self . stop_event . is_set ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> # Block, but timeout, so that we can exit the loop gracefully <TAB> <TAB> <TAB> request = self . send_queue . get ( True , 6.0 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> # Socket got closed and set to None in another thread... <TAB> <TAB> <TAB> <TAB> self . socket . sendall ( request ) <TAB> <TAB> <TAB> if self . send_queue is not None : <TAB> <TAB> <TAB> <TAB> self . send_queue . task_done ( ) <TAB> <TAB> except queue . Empty : <TAB> <TAB> <TAB> pass <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> self . stop_event . set ( ) ","if self . socket is not None : 
","if request is not None :
",49.57,38.5,False
"def get_url_args ( self , item ) : <TAB> if self . url_args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> url_args = self . url_args ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url_args = dict ( self . url_args ) <TAB> <TAB> url_args [ "" id "" ] = item . id <TAB> <TAB> return url_args <TAB> else : <TAB> <TAB> return dict ( operation = self . label , id = item . id ) ","if hasattr ( self . url_args , "" __call__ "" ) : 
","if callable ( self . url_args ) :
",42.47,26.91,False
"def list_projects ( self ) : <TAB> projects = [ ] <TAB> page = 1 <TAB> while True : <TAB> <TAB> repos = self . _client . get ( <TAB> <TAB> <TAB> "" /user/repos "" , { "" sort "" : "" full_name "" , "" page "" : page , "" per_page "" : 100 } <TAB> <TAB> ) <TAB> <TAB> page + = 1 <TAB> <TAB> for repo in repos : <TAB> <TAB> <TAB> projects . append ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : repo [ "" full_name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" name "" : repo [ "" full_name "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" description "" : repo [ "" description "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> "" is_private "" : repo [ "" private "" ] , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> return projects ","if len ( repos ) < 100 : 
","if page > = repo [ "" per_page "" ] :
",26.54,3.67,False
"def scripts ( self ) : <TAB> application_root = current_app . config . get ( "" APPLICATION_ROOT "" ) <TAB> subdir = application_root != "" / "" <TAB> scripts = [ ] <TAB> for script in get_registered_scripts ( ) : <TAB> <TAB> if script . startswith ( "" http "" ) : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { application_root } / { script } "" ></script> ' ) <TAB> <TAB> else : <TAB> <TAB> <TAB> scripts . append ( f ' <script defer src= "" { script } "" ></script> ' ) <TAB> return markup ( "" \n "" . join ( scripts ) ) ","elif subdir : 
","elif subdir :
",78.12,0.0,False
"def print_map ( node , l ) : <TAB> if node . title not in l : <TAB> <TAB> l [ node . title ] = [ ] <TAB> for n in node . children : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> w = { n . title : [ ] } <TAB> <TAB> <TAB> l [ node . title ] . append ( w ) <TAB> <TAB> <TAB> print_map ( n , w ) <TAB> <TAB> else : <TAB> <TAB> <TAB> l [ node . title ] . append ( n . title ) ","if len ( n . children ) > 0 : 
","if isinstance ( n , Tree ) :
",27.93,10.82,False
"def _validate_distinct_on_different_types_and_field_orders ( <TAB> self , collection , query , expected_results , get_mock_result ) : <TAB> self . count = 0 <TAB> self . get_mock_result = get_mock_result <TAB> query_iterable = collection . query_items ( query , enable_cross_partition_query = True ) <TAB> results = list ( query_iterable ) <TAB> for i in range ( len ( expected_results ) ) : <TAB> <TAB> if isinstance ( results [ i ] , dict ) : <TAB> <TAB> <TAB> self . assertDictEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertListEqual ( results [ i ] , expected_results [ i ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( results [ i ] , expected_results [ i ] ) <TAB> self . count = 0 ","elif isinstance ( results [ i ] , list ) : 
","elif isinstance ( results [ i ] , list ) :
",100.0,100.0,True
"def run ( self ) : <TAB> for k , v in iteritems ( self . objs ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if ( <TAB> <TAB> <TAB> v [ "" _class "" ] == "" Question "" <TAB> <TAB> <TAB> or v [ "" _class "" ] == "" Message "" <TAB> <TAB> <TAB> or v [ "" _class "" ] == "" Announcement "" <TAB> <TAB> ) : <TAB> <TAB> <TAB> v [ "" admin "" ] = None <TAB> return self . objs ","if k . startswith ( "" _ "" ) : 
","if k . startswith ( "" _ "" ) :
",100.0,100.0,True
"def qvec ( self ) : <TAB> #<TAB> <TAB> if self.polrep != 'stokes':<TAB> #<TAB> <TAB> <TAB> raise Exception(""qvec is not defined unless self.polrep=='stokes'"")<TAB> qvec = np . array ( [ ] ) <TAB> if self . polrep == "" stokes "" : <TAB> <TAB> qvec = self . _imdict [ "" Q "" ] <TAB> elif self . polrep == "" circ "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> qvec = np . real ( 0.5 * ( self . lrvec + self . rlvec ) ) <TAB> return qvec ","if len ( self . rlvec ) != 0 and len ( self . lrvec ) != 0 : 
","if self . lrvec != 0 and self . rlvec != 0 :
",24.3,32.45,False
"def display_value ( self , key , w ) : <TAB> if key == "" vdevices "" : <TAB> <TAB> # Very special case <TAB> <TAB> nids = [ n [ "" deviceID "" ] for n in self . get_value ( "" devices "" ) ] <TAB> <TAB> for device in self . app . devices . values ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> b = Gtk . CheckButton ( device . get_title ( ) , False ) <TAB> <TAB> <TAB> <TAB> b . set_tooltip_text ( device [ "" id "" ] ) <TAB> <TAB> <TAB> <TAB> self [ "" vdevices "" ] . pack_start ( b , False , False , 0 ) <TAB> <TAB> <TAB> <TAB> b . set_active ( device [ "" id "" ] in nids ) <TAB> <TAB> self [ "" vdevices "" ] . show_all ( ) <TAB> else : <TAB> <TAB> EditorDialog . display_value ( self , key , w ) ","if device [ "" id "" ] != self . app . daemon . get_my_id ( ) : 
","if device [ "" id "" ] in nids :
",46.32,18.0,False
"def _set_xflux_setting ( self , * * kwargs ) : <TAB> for key , value in kwargs . items ( ) : <TAB> <TAB> if key in self . _settings_map : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _set_xflux_screen_color ( value ) <TAB> <TAB> <TAB> <TAB> self . _current_color = str ( value ) <TAB> <TAB> <TAB> <TAB> # hackish - changing the current color unpauses xflux, <TAB> <TAB> <TAB> <TAB> # must reflect that with state change <TAB> <TAB> <TAB> <TAB> if self . state == self . states [ "" PAUSED "" ] : <TAB> <TAB> <TAB> <TAB> <TAB> self . state = self . states [ "" RUNNING "" ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _xflux . sendline ( self . _settings_map [ key ] + str ( value ) ) <TAB> <TAB> <TAB> self . _c ( ) ","if key == "" color "" : 
","if key == "" screen_color "" :
",74.63,52.54,False
"def apply_acceleration ( self , veh_ids , acc ) : <TAB> """"""See parent class."""""" <TAB> # to hand the case of a single vehicle <TAB> if type ( veh_ids ) == str : <TAB> <TAB> veh_ids = [ veh_ids ] <TAB> <TAB> acc = [ acc ] <TAB> for i , vid in enumerate ( veh_ids ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> this_vel = self . get_speed ( vid ) <TAB> <TAB> <TAB> next_vel = max ( [ this_vel + acc [ i ] * self . sim_step , 0 ] ) <TAB> <TAB> <TAB> self . kernel_api . vehicle . slowDown ( vid , next_vel , 1e-3 ) ","if acc [ i ] is not None and vid in self . get_ids ( ) : 
","if acc [ i ] > 0 :
",37.0,13.68,False
"def largest_factor_relatively_prime ( a , b ) : <TAB> """"""Return the largest factor of a relatively prime to b."""""" <TAB> while 1 : <TAB> <TAB> d = gcd ( a , b ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> b = d <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> q , r = divmod ( a , d ) <TAB> <TAB> <TAB> if r > 0 : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> a = q <TAB> return a ","if d < = 1 : 
","if d < 0 :
",36.53,34.98,False
"def check_status ( self ) : <TAB> try : <TAB> <TAB> du = psutil . disk_usage ( "" / "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ServiceWarning ( <TAB> <TAB> <TAB> <TAB> "" {host} {percent} % d isk usage exceeds  {disk_usage} % "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> host = host , percent = du . percent , disk_usage = DISK_USAGE_MAX <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> except ValueError as e : <TAB> <TAB> self . add_error ( ServiceReturnedUnexpectedResult ( "" ValueError "" ) , e ) ","if DISK_USAGE_MAX and du . percent > = DISK_USAGE_MAX : 
","if du . disk_usage > DISK_USAGE_MAX :
",32.66,31.55,False
"def build_reply ( self , msg , text = None , private = False , threaded = False ) : <TAB> response = self . build_message ( text ) <TAB> if msg . is_group : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response . frm = self . bot_identifier <TAB> <TAB> <TAB> response . to = IRCPerson ( str ( msg . frm ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> response . frm = IRCRoomOccupant ( str ( self . bot_identifier ) , msg . frm . room ) <TAB> <TAB> <TAB> response . to = msg . frm . room <TAB> else : <TAB> <TAB> response . frm = self . bot_identifier <TAB> <TAB> response . to = msg . frm <TAB> return response ","if private : 
","if private or threaded :
",34.79,23.64,False
"def _dict_refs ( obj , named ) : <TAB> """"""Return key and value objects of a dict/proxy."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for k , v in _items ( obj ) : <TAB> <TAB> <TAB> <TAB> s = str ( k ) <TAB> <TAB> <TAB> <TAB> yield _NamedRef ( "" [K]  "" + s , k ) <TAB> <TAB> <TAB> <TAB> yield _NamedRef ( "" [V]  "" + s + "" :  "" + _repr ( v ) , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> for k , v in _items ( obj ) : <TAB> <TAB> <TAB> <TAB> yield k <TAB> <TAB> <TAB> <TAB> yield v <TAB> except ( KeyError , ReferenceError , TypeError ) as x : <TAB> <TAB> warnings . warn ( "" Iterating  ' %s ' :  %r "" % ( _classof ( obj ) , x ) ) ","if named : 
","if named :
",78.12,0.0,False
"def fetch_images ( ) : <TAB> images = [ ] <TAB> marker = None <TAB> while True : <TAB> <TAB> batch = image_service . detail ( <TAB> <TAB> <TAB> context , <TAB> <TAB> <TAB> filters = filters , <TAB> <TAB> <TAB> marker = marker , <TAB> <TAB> <TAB> sort_key = "" created_at "" , <TAB> <TAB> <TAB> sort_dir = "" desc "" , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> images + = batch <TAB> <TAB> marker = batch [ - 1 ] [ "" id "" ] <TAB> return images ","if not batch : 
","if not batch :
",100.0,100.0,True
"def compress ( self , data_list ) : <TAB> warn_untested ( ) <TAB> if data_list : <TAB> <TAB> if data_list [ 1 ] in forms . fields . EMPTY_VALUES : <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_year "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> error = self . error_messages [ "" invalid_month "" ] <TAB> <TAB> <TAB> raise forms . ValidationError ( error ) <TAB> <TAB> year = int ( data_list [ 1 ] ) <TAB> <TAB> month = int ( data_list [ 0 ] ) <TAB> <TAB> # find last day of the month <TAB> <TAB> day = monthrange ( year , month ) [ 1 ] <TAB> <TAB> return date ( year , month , day ) <TAB> return None ","if data_list [ 0 ] in forms . fields . EMPTY_VALUES : 
","if data_list [ 0 ] in forms . fields . EMPTY_VALUES :
",100.0,100.0,True
"def _diff_dict ( self , old , new ) : <TAB> diff = { } <TAB> removed = [ ] <TAB> added = [ ] <TAB> for key , value in old . items ( ) : <TAB> <TAB> if key not in new : <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # modified is indicated by a remove and add <TAB> <TAB> <TAB> removed . append ( key ) <TAB> <TAB> <TAB> added . append ( key ) <TAB> for key , value in new . items ( ) : <TAB> <TAB> if key not in old : <TAB> <TAB> <TAB> added . append ( key ) <TAB> if removed : <TAB> <TAB> diff [ "" removed "" ] = sorted ( removed ) <TAB> if added : <TAB> <TAB> diff [ "" added "" ] = sorted ( added ) <TAB> return diff ","elif old [ key ] != new [ key ] : 
","if value is not None :
",25.88,2.99,False
"def add_filters ( self , function ) : <TAB> try : <TAB> <TAB> subscription = self . exists ( function ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> response = self . _sns . call ( <TAB> <TAB> <TAB> <TAB> "" set_subscription_attributes "" , <TAB> <TAB> <TAB> <TAB> SubscriptionArn = subscription [ "" SubscriptionArn "" ] , <TAB> <TAB> <TAB> <TAB> AttributeName = "" FilterPolicy "" , <TAB> <TAB> <TAB> <TAB> AttributeValue = json . dumps ( self . filters ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> kappa . event_source . sns . LOG . debug ( response ) <TAB> except Exception : <TAB> <TAB> kappa . event_source . sns . LOG . exception ( <TAB> <TAB> <TAB> "" Unable to add filters for SNS topic  %s "" , self . arn <TAB> <TAB> ) ","if subscription : 
","if subscription :
",78.12,0.0,False
"def init_weights ( self , pretrained = None ) : <TAB> if isinstance ( pretrained , str ) : <TAB> <TAB> logger = logging . getLogger ( ) <TAB> <TAB> load_checkpoint ( self , pretrained , strict = False , logger = logger ) <TAB> elif pretrained is None : <TAB> <TAB> for m in self . modules ( ) : <TAB> <TAB> <TAB> if isinstance ( m , nn . Conv2d ) : <TAB> <TAB> <TAB> <TAB> kaiming_init ( m ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> constant_init ( m , 1 ) <TAB> else : <TAB> <TAB> raise TypeError ( "" pretrained must be a str or None "" ) ","elif isinstance ( m , ( _BatchNorm , nn . GroupNorm ) ) : 
","elif isinstance ( m , nn . BatchNorm2d ) :
",48.39,34.11,False
def test_is_native_login ( self ) : <TAB> for campaign in self . campaign_lists : <TAB> <TAB> native = campaigns . is_native_login ( campaign ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert_true ( native ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert_false ( native ) <TAB> native = campaigns . is_proxy_login ( self . invalid_campaign ) <TAB> assert_true ( native is None ) ,"if campaign == "" prereg "" or campaign == "" erpc "" : 
","if campaign == "" test "" :
",50.27,24.79,False
"def _process_filter ( self , query , host_state ) : <TAB> """"""Recursively parse the query structure."""""" <TAB> if not query : <TAB> <TAB> return True <TAB> cmd = query [ 0 ] <TAB> method = self . commands [ cmd ] <TAB> cooked_args = [ ] <TAB> for arg in query [ 1 : ] : <TAB> <TAB> if isinstance ( arg , list ) : <TAB> <TAB> <TAB> arg = self . _process_filter ( arg , host_state ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> arg = self . _parse_string ( arg , host_state ) <TAB> <TAB> if arg is not None : <TAB> <TAB> <TAB> cooked_args . append ( arg ) <TAB> result = method ( self , cooked_args ) <TAB> return result ","elif isinstance ( arg , basestring ) : 
","elif isinstance ( arg , str ) :
",79.9,59.46,False
"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if APP_CONFIG . nobuild_files . match ( f ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> files . append ( f ) <TAB> <TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime ","if not f . endswith ( "" .go "" ) : 
","if f . startswith ( "" . "" ) :
",46.3,25.17,False
"def ExcludePath ( self , path ) : <TAB> """"""Check to see if this is a service url and matches inbound_services."""""" <TAB> skip = False <TAB> for reserved_path in self . reserved_paths . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if ( <TAB> <TAB> <TAB> <TAB> not self . inbound_services <TAB> <TAB> <TAB> <TAB> or self . reserved_paths [ reserved_path ] not in self . inbound_services <TAB> <TAB> <TAB> ) : <TAB> <TAB> <TAB> <TAB> return ( True , self . reserved_paths [ reserved_path ] ) <TAB> return ( False , None ) ","if path . startswith ( reserved_path ) : 
","if path == reserved_path :
",28.73,21.07,False
"def param_cov ( self ) - > DataFrame : <TAB> """"""Parameter covariance"""""" <TAB> if self . _param_cov is not None : <TAB> <TAB> param_cov = self . _param_cov <TAB> else : <TAB> <TAB> params = np . asarray ( self . params ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> param_cov = self . model . compute_param_cov ( params ) <TAB> <TAB> else : <TAB> <TAB> <TAB> param_cov = self . model . compute_param_cov ( params , robust = False ) <TAB> return DataFrame ( param_cov , columns = self . _names , index = self . _names ) ","if self . cov_type == "" robust "" : 
","if self . use_numpy :
",36.67,13.6,False
"def test_calculate_all_attentions ( module , atype ) : <TAB> m = importlib . import_module ( module ) <TAB> args = make_arg ( atype = atype ) <TAB> <MASK> <TAB> <TAB> batch = prepare_inputs ( "" pytorch "" ) <TAB> else : <TAB> <TAB> raise NotImplementedError <TAB> model = m . E2E ( 6 , 5 , args ) <TAB> with chainer . no_backprop_mode ( ) : <TAB> <TAB> if "" pytorch "" in module : <TAB> <TAB> <TAB> att_ws = model . calculate_all_attentions ( * batch ) [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> raise NotImplementedError <TAB> <TAB> print ( att_ws . shape ) ","if "" pytorch "" in module : 
","if "" pytorch "" in module :
",100.0,100.0,True
"def __eq__ ( self , other ) : <TAB> try : <TAB> <TAB> if self . type != other . type : <TAB> <TAB> <TAB> return False <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . askAnswer == other . askAnswer <TAB> <TAB> elif self . type == "" SELECT "" : <TAB> <TAB> <TAB> return self . vars == other . vars and self . bindings == other . bindings <TAB> <TAB> else : <TAB> <TAB> <TAB> return self . graph == other . graph <TAB> except : <TAB> <TAB> return False ","if self . type == "" ASK "" : 
","elif self . type == "" SELECT "" :
",65.09,58.14,False
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> if v is None :<TAB> # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re . match ( PROCTYPE_MATCH , k ) : <TAB> <TAB> <TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise serializers . ValidationError ( <TAB> <TAB> <TAB> <TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB> <TAB> <TAB> ) <TAB> return value ","if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : 
","if re . match ( LIMIT_MATCH , k ) :
",39.54,25.14,False
"def get_connections ( data_about ) : <TAB> data = data_about . find ( "" h3 "" , text = "" Connections "" ) . findNext ( ) <TAB> connections = { } <TAB> for row in data . find_all ( "" tr "" ) : <TAB> <TAB> key = row . find_all ( "" td "" ) [ 0 ] . text <TAB> <TAB> value = row . find_all ( "" td "" ) [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> connections [ key ] = get_all_links ( value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> connections [ key ] = value . text <TAB> return connections ","if "" Teams "" in key : 
","if key == "" links "" :
",33.67,8.26,False
"def _compute_map ( self , first_byte , second_byte = None ) : <TAB> if first_byte != 0x0F : <TAB> <TAB> return "" XED_ILD_MAP0 "" <TAB> else : <TAB> <TAB> if second_byte == None : <TAB> <TAB> <TAB> return "" XED_ILD_MAP1 "" <TAB> <TAB> if second_byte == 0x38 : <TAB> <TAB> <TAB> return "" XED_ILD_MAP2 "" <TAB> <TAB> if second_byte == 0x3A : <TAB> <TAB> <TAB> return "" XED_ILD_MAP3 "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" XED_ILD_MAPAMD "" <TAB> die ( "" Unhandled escape  {}  / map  {}  bytes "" . format ( first_byte , second_byte ) ) ","if second_byte == 0x0F and self . amd_enabled : 
","if first_byte == 0x5A :
",31.63,18.07,False
"def compress ( self , data_list ) : <TAB> if data_list : <TAB> <TAB> page_id = data_list [ 1 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if not self . required : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> raise forms . ValidationError ( self . error_messages [ "" invalid_page "" ] ) <TAB> <TAB> return Page . objects . get ( pk = page_id ) <TAB> return None ","if page_id in EMPTY_VALUES : 
","if page_id not in Page . objects :
",30.25,29.07,False
"def find_module ( self , fullname , path = None ) : <TAB> path = path or self . path_entry <TAB> # print('looking for ""%s"" in %s ...' % (fullname, path)) <TAB> for _ext in [ "" js "" , "" pyj "" , "" py "" ] : <TAB> <TAB> _filepath = os . path . join ( self . path_entry , "" %s . %s "" % ( fullname , _ext ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" module found at  %s : %s "" % ( _filepath , fullname ) ) <TAB> <TAB> <TAB> return VFSModuleLoader ( _filepath , fullname ) <TAB> print ( "" module  %s  not found "" % fullname ) <TAB> raise ImportError ( ) <TAB> return None ","if _filepath in VFS : 
","if os . path . exists ( _filepath ) :
",27.41,8.91,False
"def __decToBin ( self , myDec ) : <TAB> n = 0 <TAB> binOfDec = "" "" <TAB> while myDec > 2 * * n : <TAB> <TAB> n = n + 1 <TAB> if ( myDec < 2 * * n ) & ( myDec != 0 ) : <TAB> <TAB> n = n - 1 <TAB> while n > = 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> myDec = myDec - 2 * * n <TAB> <TAB> <TAB> binOfDec = binOfDec + "" 1 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> binOfDec = binOfDec + "" 0 "" <TAB> <TAB> n = n - 1 <TAB> return binOfDec ","if myDec > = 2 * * n : 
","if ( myDec > 2 * * n ) & ( myDec != 0 ) :
",47.85,18.84,False
"def __str__ ( self ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> NVMLError . _errcode_to_string [ self . value ] = str ( nvmlErrorString ( self . value ) ) <TAB> <TAB> return NVMLError . _errcode_to_string [ self . value ] <TAB> except NVMLError_Uninitialized : <TAB> <TAB> return "" NVML Error with code  %d "" % self . value ","if self . value not in NVMLError . _errcode_to_string : 
","if self . value not in NVMLError . _errcode_to_string :
",100.0,100.0,True
"def abspath ( pathdir : str ) - > str : <TAB> if Path is not None and isinstance ( pathdir , Path ) : <TAB> <TAB> return pathdir . abspath ( ) <TAB> else : <TAB> <TAB> pathdir = path . abspath ( pathdir ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> pathdir = pathdir . decode ( fs_encoding ) <TAB> <TAB> <TAB> except UnicodeDecodeError as exc : <TAB> <TAB> <TAB> <TAB> raise UnicodeDecodeError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" multibyte filename not supported on  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" this filesystem encoding  "" <TAB> <TAB> <TAB> <TAB> <TAB> "" ( %r ) "" % fs_encoding <TAB> <TAB> <TAB> <TAB> ) from exc <TAB> <TAB> return pathdir ","if isinstance ( pathdir , bytes ) : 
","if fs_encoding is not None :
",26.85,6.57,False
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isfile ( self . object ) : <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> elif hasattr ( self . object , "" read "" ) : <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs ","if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : 
","if hasattr ( self . object , "" read "" ) :
",43.14,16.49,False
"def _set_uid ( self , val ) : <TAB> if val is not None : <TAB> <TAB> if pwd is None : <TAB> <TAB> <TAB> self . bus . log ( "" pwd module not available; ignoring uid. "" , level = 30 ) <TAB> <TAB> <TAB> val = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = pwd . getpwnam ( val ) [ 2 ] <TAB> self . _uid = val ","elif isinstance ( val , text_or_bytes ) : 
","elif hasattr ( pwd , "" getpwnam "" ) :
",28.34,8.64,False
"def get_attached_nodes ( self , external_account ) : <TAB> for node in self . get_nodes_with_oauth_grants ( external_account ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> node_settings = node . get_addon ( self . oauth_provider . short_name ) <TAB> <TAB> if node_settings is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> if node_settings . external_account == external_account : <TAB> <TAB> <TAB> yield node ","if node is None : 
","if node . is_active :
",31.0,15.62,False
"def from_obj ( cls , py_obj ) : <TAB> if not isinstance ( py_obj , Image ) : <TAB> <TAB> raise TypeError ( "" py_obj must be a wandb.Image "" ) <TAB> else : <TAB> <TAB> if hasattr ( py_obj , "" _boxes "" ) and py_obj . _boxes : <TAB> <TAB> <TAB> box_keys = list ( py_obj . _boxes . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> box_keys = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mask_keys = list ( py_obj . masks . keys ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> mask_keys = [ ] <TAB> <TAB> return cls ( box_keys , mask_keys ) ","if hasattr ( py_obj , "" masks "" ) and py_obj . masks : 
","if hasattr ( py_obj , "" masks "" ) and py_obj . masks :
",100.0,100.0,True
"def write ( self , * bits ) : <TAB> for bit in bits : <TAB> <TAB> if not self . bytestream : <TAB> <TAB> <TAB> self . bytestream . append ( 0 ) <TAB> <TAB> byte = self . bytestream [ self . bytenum ] <TAB> <TAB> if self . bitnum == 8 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> byte = 0 <TAB> <TAB> <TAB> <TAB> self . bytestream + = bytes ( [ byte ] ) <TAB> <TAB> <TAB> self . bytenum + = 1 <TAB> <TAB> <TAB> self . bitnum = 0 <TAB> <TAB> mask = 2 * * self . bitnum <TAB> <TAB> if bit : <TAB> <TAB> <TAB> byte | = mask <TAB> <TAB> else : <TAB> <TAB> <TAB> byte & = ~ mask <TAB> <TAB> self . bytestream [ self . bytenum ] = byte <TAB> <TAB> self . bitnum + = 1 ","if self . bytenum == len ( self . bytestream ) - 1 : 
","if byte == bytes ( [ ] ) :
",26.1,6.7,False
"def destroy ( self , wipe = False ) : <TAB> if self . state == self . UP : <TAB> <TAB> image = self . image ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . confirm_destroy ( image , self . full_name , abort = False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . warn ( "" tried to destroy  {0}  which didn ' t exist "" . format ( self . full_name ) ) <TAB> return True ","if image : 
","if image is not None :
",34.04,17.97,False
"def get_host_metadata ( self ) : <TAB> meta = { } <TAB> if self . agent_url : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> self . agent_url + ECS_AGENT_METADATA_PATH , timeout = 1 <TAB> <TAB> <TAB> ) . json ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> match = AGENT_VERSION_EXP . search ( resp . get ( "" Version "" ) ) <TAB> <TAB> <TAB> <TAB> if match is not None and len ( match . groups ( ) ) == 1 : <TAB> <TAB> <TAB> <TAB> <TAB> meta [ "" ecs_version "" ] = match . group ( 1 ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> self . log . debug ( "" Error getting ECS version:  %s "" % str ( e ) ) <TAB> return meta ","if "" Version "" in resp : 
","if resp . get ( "" Status "" ) == "" active "" :
",32.97,3.93,False
"def _path_type ( st , lst ) : <TAB> parts = [ ] <TAB> if st : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts . append ( "" file "" ) <TAB> <TAB> elif stat . S_ISDIR ( st . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" dir "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> parts . append ( "" other "" ) <TAB> if lst : <TAB> <TAB> if stat . S_ISLNK ( lst . st_mode ) : <TAB> <TAB> <TAB> parts . append ( "" link "" ) <TAB> return "" "" . join ( parts ) ","if stat . S_ISREG ( st . st_mode ) : 
","if stat . S_ISFILE ( st . st_mode ) :
",83.03,78.25,False
"def changed ( self , action ) : <TAB> # Something was changed in the 'files' list <TAB> if len ( action . key ) > = 1 and action . key [ 0 ] . lower ( ) == "" files "" : <TAB> <TAB> # Refresh project files model <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Don't clear the existing items if only inserting new things <TAB> <TAB> <TAB> self . update_model ( clear = False ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Clear existing items <TAB> <TAB> <TAB> self . update_model ( clear = True ) ","if action . type == "" insert "" : 
","if self . project . _meta . get_model ( ) . get_value ( "" files "" ) == "" "" :
",37.68,7.07,False
"def process ( self , resources , event = None ) : <TAB> client = local_session ( self . manager . session_factory ) . client ( "" es "" ) <TAB> for r in resources : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = self . manager . retry ( <TAB> <TAB> <TAB> <TAB> client . describe_elasticsearch_domain_config , <TAB> <TAB> <TAB> <TAB> DomainName = r [ "" DomainName "" ] , <TAB> <TAB> <TAB> <TAB> ignore_err_codes = ( "" ResourceNotFoundException "" , ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> r [ self . policy_attribute ] = json . loads ( <TAB> <TAB> <TAB> <TAB> <TAB> result . get ( "" DomainConfig "" ) . get ( "" AccessPolicies "" ) . get ( "" Options "" ) <TAB> <TAB> <TAB> <TAB> ) <TAB> return super ( ) . process ( resources ) ","if self . policy_attribute not in r : 
","if self . policy_attribute not in r :
",100.0,100.0,True
"def line_items ( self ) : <TAB> line_items = [ ] <TAB> for line in self . lines_str : <TAB> <TAB> line = line . split ( "" | "" ) <TAB> <TAB> line = line [ 1 : - 1 ]<TAB> # del first and last empty item (consequence of split) <TAB> <TAB> items = [ ] <TAB> <TAB> for item in line : <TAB> <TAB> <TAB> i = re . search ( r "" ( \ S+([  \ t]+ \ S+)*)+ "" , item ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> items . append ( i . group ( ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> items . append ( "" "" ) <TAB> <TAB> line_items . append ( items ) <TAB> return line_items ","if i : 
","if i :
",78.12,0.0,False
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> if type ( f ) == unicode : <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> if type ( v ) == unicode : <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res ) ","elif not args . content_only : 
","elif args . strings :
",55.24,13.94,False
"def get_servers ( self , detail = True , search_opts = None ) : <TAB> rel_url = "" /servers/detail "" if detail else "" /servers "" <TAB> if search_opts is not None : <TAB> <TAB> qparams = { } <TAB> <TAB> for opt , val in search_opts . iteritems ( ) : <TAB> <TAB> <TAB> qparams [ opt ] = val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> query_string = "" ? %s "" % urllib . urlencode ( qparams ) <TAB> <TAB> <TAB> rel_url + = query_string <TAB> return self . api_get ( rel_url ) [ "" servers "" ] ","if qparams : 
","if qparams :
",78.12,0.0,False
"def run ( self ) : <TAB> while not self . __exit__ : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sleep ( 10 ) <TAB> <TAB> <TAB> continue <TAB> <TAB> o = self . playlist [ 0 ] <TAB> <TAB> self . playlist . remove ( o ) <TAB> <TAB> obj = json . loads ( o ) <TAB> <TAB> if not "" args "" in obj : <TAB> <TAB> <TAB> obj [ "" args "" ] = { "" ua "" : "" "" , "" header "" : "" "" , "" title "" : "" "" , "" referer "" : "" "" } <TAB> <TAB> obj [ "" play "" ] = False <TAB> <TAB> self . handle = launch_player ( obj [ "" urls "" ] , obj [ "" ext "" ] , * * obj [ "" args "" ] ) <TAB> <TAB> self . handle . wait ( ) ","if len ( self . playlist ) == 0 : 
","if len ( self . playlist ) > 10 :
",83.32,59.78,False
"def get_to_download_runs_ids ( session , headers ) : <TAB> last_date = 0 <TAB> result = [ ] <TAB> while 1 : <TAB> <TAB> r = session . get ( RUN_DATA_API . format ( last_date = last_date ) , headers = headers ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> run_logs = r . json ( ) [ "" data "" ] [ "" records "" ] <TAB> <TAB> <TAB> result . extend ( [ i [ "" logs "" ] [ 0 ] [ "" stats "" ] [ "" id "" ] for i in run_logs ] ) <TAB> <TAB> <TAB> last_date = r . json ( ) [ "" data "" ] [ "" lastTimestamp "" ] <TAB> <TAB> <TAB> since_time = datetime . utcfromtimestamp ( last_date / 1000 ) <TAB> <TAB> <TAB> print ( f "" pares keep ids data since  { since_time } "" ) <TAB> <TAB> <TAB> time . sleep ( 1 )<TAB> # spider rule <TAB> <TAB> <TAB> if not last_date : <TAB> <TAB> <TAB> <TAB> break <TAB> return result ","if r . ok : 
","if r . status_code == 200 and r . json ( ) [ "" data "" ] [ "" status "" ] == "" running "" :
",41.6,4.8,False
"def __saveWork ( self , work , results ) : <TAB> """"""Stores the resulting last log line to the cache with the proxy key"""""" <TAB> del work <TAB> # pylint: disable=broad-except <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> __cached = self . __cache [ results [ 0 ] ] <TAB> <TAB> <TAB> __cached [ self . __TIME ] = time . time ( ) <TAB> <TAB> <TAB> __cached [ self . __LINE ] = results [ 1 ] <TAB> <TAB> <TAB> __cached [ self . __LLU ] = results [ 2 ] <TAB> except KeyError as e : <TAB> <TAB> # Could happen while switching jobs with work in the queue <TAB> <TAB> pass <TAB> except Exception as e : <TAB> <TAB> list ( map ( logger . warning , cuegui . Utils . exceptionOutput ( e ) ) ) ","if results : 
","if results :
",78.12,0.0,False
"def read_notes ( rec ) : <TAB> found = [ ] <TAB> for tag in range ( 500 , 595 ) : <TAB> <TAB> if tag in ( 505 , 520 ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> fields = rec . get_fields ( str ( tag ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> for f in fields : <TAB> <TAB> <TAB> x = f . get_lower_subfields ( ) <TAB> <TAB> <TAB> if x : <TAB> <TAB> <TAB> <TAB> found . append ( "" "" . join ( x ) . strip ( "" "" ) ) <TAB> if found : <TAB> <TAB> return "" \n \n "" . join ( found ) ","if not fields : 
","if not fields :
",100.0,100.0,True
"def serialize_to ( self , stream , alternate_script = None ) : <TAB> stream . write ( self . txo_ref . tx_ref . hash ) <TAB> stream . write_uint32 ( self . txo_ref . position ) <TAB> if alternate_script is not None : <TAB> <TAB> stream . write_string ( alternate_script ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> stream . write_string ( self . coinbase ) <TAB> <TAB> else : <TAB> <TAB> <TAB> stream . write_string ( self . script . source ) <TAB> stream . write_uint32 ( self . sequence ) ","if self . is_coinbase : 
","if self . coinbase is not None :
",44.36,24.45,False
"def func_named ( self , arg ) : <TAB> result = None <TAB> target = "" do_ "" + arg <TAB> if target in dir ( self ) : <TAB> <TAB> result = target <TAB> else : <TAB> <TAB> if self . abbrev :<TAB> # accept shortened versions of commands <TAB> <TAB> <TAB> funcs = [ fname for fname in self . keywords if fname . startswith ( arg ) ] <TAB> <TAB> <TAB> if len ( funcs ) == 1 : <TAB> <TAB> <TAB> <TAB> result = "" do_ "" + funcs [ 0 ] <TAB> return result ","if self . abbrev : 
","if self . abbrev :
",100.0,100.0,True
"def static_login ( self , token , * , bot ) : <TAB> # Necessary to get aiohttp to stop complaining about session creation <TAB> self . __session = aiohttp . ClientSession ( <TAB> <TAB> connector = self . connector , ws_response_class = DiscordClientWebSocketResponse <TAB> ) <TAB> old_token , old_bot = self . token , self . bot_token <TAB> self . _token ( token , bot = bot ) <TAB> try : <TAB> <TAB> data = await self . request ( Route ( "" GET "" , "" /users/@me "" ) ) <TAB> except HTTPException as exc : <TAB> <TAB> self . _token ( old_token , bot = old_bot ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise LoginFailure ( "" Improper token has been passed. "" ) from exc <TAB> <TAB> raise <TAB> return data ","if exc . response . status == 401 : 
","if "" Improper token "" in exc . args :
",32.96,9.98,False
"def render_buttons ( self ) : <TAB> for x , button in enumerate ( self . button_list ) : <TAB> <TAB> gcolor = Gdk . color_parse ( self . color_list [ x ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fgcolor = Gdk . color_parse ( "" #FFFFFF "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fgcolor = Gdk . color_parse ( "" #000000 "" ) <TAB> <TAB> button . set_label ( self . color_list [ x ] ) <TAB> <TAB> button . set_sensitive ( True ) <TAB> <TAB> button . modify_bg ( Gtk . StateType . NORMAL , gcolor ) <TAB> <TAB> button . modify_fg ( Gtk . StateType . NORMAL , fgcolor ) ","if util . get_hls_val ( self . color_list [ x ] , "" light "" ) < 99 : 
","if x == 0 :
",25.5,0.45,False
"def _set_text ( self , data ) : <TAB> lines = [ ] <TAB> for key , value in data . items ( ) : <TAB> <TAB> lines . append ( "" "" ) <TAB> <TAB> txt = yaml . dump ( { key : value } , default_flow_style = False ) <TAB> <TAB> title = self . titles . get ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lines . append ( "" #  %s "" % title ) <TAB> <TAB> lines . append ( txt . rstrip ( ) ) <TAB> txt = "" \n "" . join ( lines ) + "" \n "" <TAB> txt = txt . lstrip ( ) <TAB> self . edit . setPlainText ( txt ) ","if title : 
","if title :
",78.12,0.0,False
"def build_path ( self ) : <TAB> for variable in re_path_template . findall ( self . path ) : <TAB> <TAB> name = variable . strip ( "" {} "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # No 'user' parameter provided, fetch it from Auth instead. <TAB> <TAB> <TAB> value = self . api . auth . get_username ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> value = quote ( self . session . params [ name ] ) <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> raise TweepError ( <TAB> <TAB> <TAB> <TAB> <TAB> "" No parameter value found for path variable:  %s "" % name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> del self . session . params [ name ] <TAB> <TAB> self . path = self . path . replace ( variable , value ) ","if name == "" user "" and "" user "" not in self . session . params and self . api . auth : 
","if not name :
",25.34,0.12,False
"def _calculate_writes_for_built_in_indices ( self , entity ) : <TAB> writes = 0 <TAB> for prop_name in entity . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> prop_vals = entity [ prop_name ] <TAB> <TAB> <TAB> if isinstance ( prop_vals , ( list ) ) : <TAB> <TAB> <TAB> <TAB> num_prop_vals = len ( prop_vals ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> num_prop_vals = 1 <TAB> <TAB> <TAB> writes + = 2 * num_prop_vals <TAB> return writes ","if not prop_name in entity . unindexed_properties ( ) : 
","if not prop_name . startswith ( "" _ "" ) :
",35.31,33.67,False
"def create_connection ( self , address , protocol_factory = None , * * kw ) : <TAB> """"""Helper method for creating a connection to an ``address``."""""" <TAB> protocol_factory = protocol_factory or self . create_protocol <TAB> if isinstance ( address , tuple ) : <TAB> <TAB> host , port = address <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . logger . debug ( "" Create connection  %s : %s "" , host , port ) <TAB> <TAB> _ , protocol = await self . _loop . create_connection ( <TAB> <TAB> <TAB> protocol_factory , host , port , * * kw <TAB> <TAB> ) <TAB> <TAB> await protocol . event ( "" connection_made "" ) <TAB> else : <TAB> <TAB> raise NotImplementedError ( "" Could not connect to  %s "" % str ( address ) ) <TAB> return protocol ","if self . debug : 
","if self . _loop . get_debug ( ) :
",43.86,14.32,False
def _increment_bracket_num ( self ) : <TAB> self . _current_bracket - = 1 <TAB> if self . _current_bracket < 0 : <TAB> <TAB> self . _current_bracket = self . _get_num_brackets ( ) - 1 <TAB> <TAB> self . _current_iteration + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _current_bracket = 0 ,"if self . _current_iteration > self . hyperband_iterations : 
","if self . _current_iteration > = self . _max_iter :
",60.07,50.67,False
"def get_cycle_path ( self , curr_node , goal_node_index ) : <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return [ curr_node [ "" address "" ] ] <TAB> for dep in curr_node [ "" deps "" ] : <TAB> <TAB> path = self . get_cycle_path ( <TAB> <TAB> <TAB> self . get_by_address ( dep ) , goal_node_index <TAB> <TAB> )<TAB> # self.nodelist[dep], goal_node_index) <TAB> <TAB> if len ( path ) > 0 : <TAB> <TAB> <TAB> path . insert ( 0 , curr_node [ "" address "" ] ) <TAB> <TAB> <TAB> return path <TAB> return [ ] ","if dep == goal_node_index : 
","if dep == goal_node_index :
",100.0,100.0,True
"def as_dict ( path = "" "" , version = "" latest "" , section = "" meta-data "" ) : <TAB> result = { } <TAB> dirs = dir ( path , version , section ) <TAB> if not dirs : <TAB> <TAB> return None <TAB> for item in dirs : <TAB> <TAB> if item . endswith ( "" / "" ) : <TAB> <TAB> <TAB> records = as_dict ( path + item , version , section ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result [ item [ : - 1 ] ] = records <TAB> <TAB> elif is_dict . match ( item ) : <TAB> <TAB> <TAB> idx , name = is_dict . match ( item ) . groups ( ) <TAB> <TAB> <TAB> records = as_dict ( path + idx + "" / "" , version , section ) <TAB> <TAB> <TAB> if records : <TAB> <TAB> <TAB> <TAB> result [ name ] = records <TAB> <TAB> else : <TAB> <TAB> <TAB> result [ item ] = valueconv ( get ( path + item , version , section ) ) <TAB> return result ","if records : 
","if records :
",78.12,0.0,False
"def preprocess_raw_enwik9 ( input_filename , output_filename ) : <TAB> with open ( input_filename , "" r "" ) as f1 : <TAB> <TAB> with open ( output_filename , "" w "" ) as f2 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> line = f1 . readline ( ) <TAB> <TAB> <TAB> <TAB> if not line : <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> line = list ( enwik9_norm_transform ( [ line ] ) ) [ 0 ] <TAB> <TAB> <TAB> <TAB> if line != "" "" and line != "" "" : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> line = line [ 1 : ] <TAB> <TAB> <TAB> <TAB> <TAB> f2 . writelines ( line + "" \n "" ) ","if line [ 0 ] == "" "" : 
","if line [ 0 ] == "" \n "" :
",67.76,67.04,False
"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB> <TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if index is not None : <TAB> <TAB> <TAB> del self . _subscribers [ index ] <TAB> <TAB> if not self . _subscribers : <TAB> <TAB> <TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) ) ","if subscriber_web_sock == web_sock : 
","if web_sock == subscriber_web_sock :
",54.02,75.1,False
"def formatmonthname ( self , theyear , themonth , withyear = True ) : <TAB> with TimeEncoding ( self . locale ) as encoding : <TAB> <TAB> s = month_name [ themonth ] <TAB> <TAB> if encoding is not None : <TAB> <TAB> <TAB> s = s . decode ( encoding ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> s = "" %s %s "" % ( s , theyear ) <TAB> <TAB> return ' <tr><th colspan= "" 7 ""  class= "" month "" > %s </th></tr> ' % s ","if withyear : 
","if withyear :
",78.12,0.0,False
"def generate_sitemaps ( filename ) : <TAB> rows = ( line . strip ( ) . split ( "" \t "" ) for line in open ( filename ) ) <TAB> for sortkey , chunk in itertools . groupby ( rows , lambda row : row [ 0 ] ) : <TAB> <TAB> things = [ ] <TAB> <TAB> _chunk = list ( chunk ) <TAB> <TAB> for segment in _chunk : <TAB> <TAB> <TAB> sortkey = segment . pop ( 0 ) <TAB> <TAB> <TAB> last_modified = segment . pop ( - 1 ) <TAB> <TAB> <TAB> path = "" "" . join ( segment ) <TAB> <TAB> <TAB> things . append ( web . storage ( path = path , last_modified = last_modified ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> write ( "" sitemaps/sitemap_ %s .xml.gz "" % sortkey , sitemap ( things ) ) ","if things : 
","if things :
",78.12,0.0,False
"def use_index ( <TAB> self , term : Union [ str , Index ] , * terms : Union [ str , Index ] ) - > "" QueryBuilder "" : <TAB> for t in ( term , * terms ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _use_indexes . append ( t ) <TAB> <TAB> elif isinstance ( t , str ) : <TAB> <TAB> <TAB> self . _use_indexes . append ( Index ( t ) ) ","if isinstance ( t , Index ) : 
","if isinstance ( t , Index ) :
",100.0,100.0,True
"def get_changed ( self ) : <TAB> if self . _is_expression ( ) : <TAB> <TAB> result = self . _get_node_text ( self . ast ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> return result <TAB> else : <TAB> <TAB> collector = codeanalyze . ChangeCollector ( self . source ) <TAB> <TAB> last_end = - 1 <TAB> <TAB> for match in self . matches : <TAB> <TAB> <TAB> start , end = match . get_region ( ) <TAB> <TAB> <TAB> if start < last_end : <TAB> <TAB> <TAB> <TAB> if not self . _is_expression ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> last_end = end <TAB> <TAB> <TAB> replacement = self . _get_matched_text ( match ) <TAB> <TAB> <TAB> collector . add_change ( start , end , replacement ) <TAB> <TAB> return collector . get_changed ( ) ","if result == self . source : 
","if result is None :
",29.24,12.98,False
"def quiet_f ( * args ) : <TAB> vars = { arg_name : Real ( arg ) for arg_name , arg in zip ( arg_names , args ) } <TAB> value = dynamic_scoping ( quiet_expr . evaluate , vars , evaluation ) <TAB> if expect_list : <TAB> <TAB> if value . has_form ( "" List "" , None ) : <TAB> <TAB> <TAB> value = [ extract_pyreal ( item ) for item in value . leaves ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return value <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> else : <TAB> <TAB> value = extract_pyreal ( value ) <TAB> <TAB> if value is None or isinf ( value ) or isnan ( value ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> return value ","if any ( item is None for item in value ) : 
","if value is None or isinf ( value ) or isnan ( value ) :
",17.63,13.38,False
"def _reemit_nested_event ( self , event : Event ) : <TAB> source_index = self . index ( event . source ) <TAB> for attr in ( "" index "" , "" new_index "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> src_index = ensure_tuple_index ( event . index ) <TAB> <TAB> <TAB> setattr ( event , attr , ( source_index , ) + src_index ) <TAB> if not hasattr ( event , "" index "" ) : <TAB> <TAB> setattr ( event , "" index "" , source_index ) <TAB> # reemit with this object's EventEmitter of the same type if present <TAB> # otherwise just emit with the EmitterGroup itself <TAB> getattr ( self . events , event . type , self . events ) ( event ) ","if hasattr ( event , attr ) : 
","if not hasattr ( event , attr ) :
",78.0,75.06,False
"def check ( self ) : <TAB> """"""Perform required checks to conclude if it's safe to operate"""""" <TAB> if self . interpreter . manual is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . error = self . process . error <TAB> <TAB> <TAB> self . tip = self . process . tip <TAB> <TAB> <TAB> return False <TAB> start = time . time ( ) <TAB> while not self . _status ( ) : <TAB> <TAB> if time . time ( ) - start > = 2 :<TAB> # 2s <TAB> <TAB> <TAB> self . error = "" can ' t connect to the minserver on  {} : {} "" . format ( <TAB> <TAB> <TAB> <TAB> self . interpreter . host , self . interpreter . port <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . tip = "" check your vagrant machine is running "" <TAB> <TAB> <TAB> return False <TAB> <TAB> time . sleep ( 0.1 ) <TAB> return True ","if not self . process . healthy : 
","if self . process . error :
",54.0,39.44,False
"def apply ( self ) : <TAB> new_block = self . block . copy ( ) <TAB> new_block . clear ( ) <TAB> for inst in self . block . body : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> const_assign = self . _assign_const ( inst ) <TAB> <TAB> <TAB> new_block . append ( const_assign ) <TAB> <TAB> <TAB> inst = self . _assign_getitem ( inst , index = const_assign . target ) <TAB> <TAB> new_block . append ( inst ) <TAB> return new_block ","if isinstance ( inst , Assign ) and inst . value in self . getattrs : 
","if isinstance ( inst , ast . Assign ) :
",44.53,26.4,False
"def _get_orientation ( self ) : <TAB> if self . state : <TAB> <TAB> rotation = [ 0 ] * 9 <TAB> <TAB> inclination = [ 0 ] * 9 <TAB> <TAB> gravity = [ ] <TAB> <TAB> geomagnetic = [ ] <TAB> <TAB> gravity = self . listener_a . values <TAB> <TAB> geomagnetic = self . listener_m . values <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ff_state = SensorManager . getRotationMatrix ( <TAB> <TAB> <TAB> <TAB> rotation , inclination , gravity , geomagnetic <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if ff_state : <TAB> <TAB> <TAB> <TAB> values = [ 0 , 0 , 0 ] <TAB> <TAB> <TAB> <TAB> values = SensorManager . getOrientation ( rotation , values ) <TAB> <TAB> <TAB> return values ","if gravity [ 0 ] is not None and geomagnetic [ 0 ] is not None : 
","if self . state == "" gravity "" :
",25.68,2.74,False
def getFirstSubGraph ( graph ) : <TAB> if len ( graph ) == 0 : <TAB> <TAB> return None <TAB> subg = { } <TAB> todo = [ graph . keys ( ) [ 0 ] ] <TAB> while len ( todo ) > 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subg [ todo [ 0 ] ] = graph [ todo [ 0 ] ] <TAB> <TAB> <TAB> todo . extend ( graph [ todo [ 0 ] ] ) <TAB> <TAB> <TAB> del graph [ todo [ 0 ] ] <TAB> <TAB> del todo [ 0 ] <TAB> return subg ,"if todo [ 0 ] in graph . keys ( ) : 
","if graph [ todo [ 0 ] ] is not None :
",40.67,24.38,False
"def decorated_function ( * args , * * kwargs ) : <TAB> rv = f ( * args , * * kwargs ) <TAB> if "" Last-Modified "" not in rv . headers : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = date <TAB> <TAB> <TAB> if callable ( result ) : <TAB> <TAB> <TAB> <TAB> result = result ( rv ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> from werkzeug . http import http_date <TAB> <TAB> <TAB> <TAB> result = http_date ( result ) <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> rv . headers [ "" Last-Modified "" ] = result <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logging . getLogger ( __name__ ) . exception ( <TAB> <TAB> <TAB> <TAB> "" Error while calculating the lastmodified value for response  {!r} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> rv <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return rv ","if not isinstance ( result , basestring ) : 
","elif isinstance ( result , date ) :
",51.64,36.28,False
"def set_invoice_details ( self , row ) : <TAB> invoice_details = self . invoice_details . get ( row . voucher_no , { } ) <TAB> if row . due_date : <TAB> <TAB> invoice_details . pop ( "" due_date "" , None ) <TAB> row . update ( invoice_details ) <TAB> if row . voucher_type == "" Sales Invoice "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_delivery_notes ( row ) <TAB> <TAB> if self . filters . show_sales_person and row . sales_team : <TAB> <TAB> <TAB> row . sales_person = "" ,  "" . join ( row . sales_team ) <TAB> <TAB> <TAB> del row [ "" sales_team "" ] ","if self . filters . show_delivery_notes : 
","if row . delivery_notes :
",33.63,25.69,False
"def process ( output ) : <TAB> modules = { } <TAB> for line in output : <TAB> <TAB> name , size , instances , depends , state , _ = line . split ( "" "" , 5 ) <TAB> <TAB> instances = int ( instances ) <TAB> <TAB> module = { <TAB> <TAB> <TAB> "" size "" : size , <TAB> <TAB> <TAB> "" instances "" : instances , <TAB> <TAB> <TAB> "" state "" : state , <TAB> <TAB> } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module [ "" depends "" ] = [ value for value in depends . split ( "" , "" ) if value ] <TAB> <TAB> modules [ name ] = module <TAB> return modules ","if depends != "" - "" : 
","if depends :
",28.89,0.0,False
"def _get_host_from_zc_service_info ( service_info : zeroconf . ServiceInfo ) : <TAB> """"""Get hostname or IP + port from zeroconf service_info."""""" <TAB> host = None <TAB> port = None <TAB> if ( <TAB> <TAB> service_info <TAB> <TAB> and service_info . port <TAB> <TAB> and ( service_info . server or len ( service_info . addresses ) > 0 ) <TAB> ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> host = socket . inet_ntoa ( service_info . addresses [ 0 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> host = service_info . server . lower ( ) <TAB> <TAB> port = service_info . port <TAB> return ( host , port ) ","if len ( service_info . addresses ) > 0 : 
","if service_info . addresses :
",35.1,32.74,False
"def _init_weights ( self , module ) : <TAB> if isinstance ( module , nn . Linear ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> if module . bias is not None : <TAB> <TAB> <TAB> module . bias . data . zero_ ( ) <TAB> elif isinstance ( module , nn . Embedding ) : <TAB> <TAB> module . weight . data . normal_ ( mean = 0.0 , std = self . config . init_std ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module . weight . data [ module . padding_idx ] . zero_ ( ) ","if module . padding_idx is not None : 
","if module . padding_idx is not None :
",100.0,100.0,True
"def visitFromImport ( self , import_stmt , import_info ) : <TAB> new_pairs = [ ] <TAB> if not import_info . is_star_import ( ) : <TAB> <TAB> for name , alias in import_info . names_and_aliases : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> pyname = self . pymodule [ alias or name ] <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> except exceptions . AttributeNotFoundError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> new_pairs . append ( ( name , alias ) ) <TAB> return importinfo . FromImport ( import_info . module_name , import_info . level , new_pairs ) ","if occurrences . same_pyname ( self . pyname , pyname ) : 
","if pyname . name == "" __pycache__ "" :
",34.61,4.25,False
"def _apply_patches ( self ) : <TAB> try : <TAB> <TAB> s = Subprocess ( <TAB> <TAB> <TAB> log = self . logfile , cwd = self . build_dir , verbose = self . options . verbose <TAB> <TAB> ) <TAB> <TAB> for patch in self . patches : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for ed , source in patch . items ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> s . shell ( "" ed -  %s  <  %s "" % ( source , ed ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> s . shell ( "" patch -p0 <  %s "" % patch ) <TAB> except : <TAB> <TAB> logger . error ( "" Failed to patch ` %s `. \n %s "" % ( self . build_dir , sys . exc_info ( ) [ 1 ] ) ) <TAB> <TAB> sys . exit ( 1 ) ","if type ( patch ) is dict : 
","if isinstance ( patch , dict ) :
",28.68,14.54,False
"def __init__ ( self , parent , dir , mask , with_dirs = True ) : <TAB> filelist = [ ] <TAB> dirlist = [ "" .. "" ] <TAB> self . dir = dir <TAB> self . file = "" "" <TAB> mask = mask . upper ( ) <TAB> pattern = self . MakeRegex ( mask ) <TAB> for i in os . listdir ( dir ) : <TAB> <TAB> if i == "" . "" or i == "" .. "" : <TAB> <TAB> <TAB> continue <TAB> <TAB> path = os . path . join ( dir , i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dirlist . append ( i ) <TAB> <TAB> <TAB> continue <TAB> <TAB> path = path . upper ( ) <TAB> <TAB> value = i . upper ( ) <TAB> <TAB> if pattern . match ( value ) is not None : <TAB> <TAB> <TAB> filelist . append ( i ) <TAB> self . files = filelist <TAB> if with_dirs : <TAB> <TAB> self . dirs = dirlist ","if os . path . isdir ( path ) : 
","if os . path . isdir ( path ) :
",100.0,100.0,True
"def remove_invalid_dirs ( paths , bp_dir , module_name ) : <TAB> ret = [ ] <TAB> for path in paths : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . warning ( ' Dir  "" %s ""  of module  "" %s ""  does not exist ' , path , module_name ) <TAB> return ret ","if os . path . isdir ( os . path . join ( bp_dir , path ) ) : 
","if os . path . exists ( path ) and bp_dir in path :
",32.27,26.29,False
"def update_sockets ( self ) : <TAB> inputs = self . inputs <TAB> inputs_n = "" ABabcd "" <TAB> penta_sockets = pentagon_dict [ self . grid_type ] . input_sockets <TAB> for socket in inputs_n : <TAB> <TAB> if socket in penta_sockets : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> inputs [ socket ] . hide_safe = False <TAB> <TAB> else : <TAB> <TAB> <TAB> inputs [ socket ] . hide_safe = True ","if inputs [ socket ] . hide_safe : 
","if inputs [ socket ] . hide_safe :
",100.0,100.0,True
"def __cut ( sentence ) : <TAB> global emit_P <TAB> prob , pos_list = viterbi ( sentence , "" BMES "" , start_P , trans_P , emit_P ) <TAB> begin , nexti = 0 , 0 <TAB> # print pos_list, sentence <TAB> for i , char in enumerate ( sentence ) : <TAB> <TAB> pos = pos_list [ i ] <TAB> <TAB> if pos == "" B "" : <TAB> <TAB> <TAB> begin = i <TAB> <TAB> elif pos == "" E "" : <TAB> <TAB> <TAB> yield sentence [ begin : i + 1 ] <TAB> <TAB> <TAB> nexti = i + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield char <TAB> <TAB> <TAB> nexti = i + 1 <TAB> if nexti < len ( sentence ) : <TAB> <TAB> yield sentence [ nexti : ] ","elif pos == "" S "" : 
","elif pos == "" S "" :
",100.0,100.0,True
"def validate ( self ) : <TAB> if self . data . get ( "" encrypted "" , True ) : <TAB> <TAB> key = self . data . get ( "" target_key "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise PolicyValidationError ( <TAB> <TAB> <TAB> <TAB> "" Encrypted snapshot copy requires kms key on  %s "" % ( self . manager . data , ) <TAB> <TAB> <TAB> ) <TAB> return self ","if not key : 
","if key and not key . get ( "" kms "" ) :
",31.03,7.35,False
"def __init__ ( self , patch_files , patch_directories ) : <TAB> files = [ ] <TAB> files_data = { } <TAB> for filename_data in patch_files : <TAB> <TAB> if isinstance ( filename_data , list ) : <TAB> <TAB> <TAB> filename , data = filename_data <TAB> <TAB> else : <TAB> <TAB> <TAB> filename = filename_data <TAB> <TAB> <TAB> data = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> filename = "" {0} {1} "" . format ( FakeState . deploy_dir , filename ) <TAB> <TAB> files . append ( filename ) <TAB> <TAB> if data : <TAB> <TAB> <TAB> files_data [ filename ] = data <TAB> self . files = files <TAB> self . files_data = files_data <TAB> self . directories = patch_directories ","if not filename . startswith ( os . sep ) : 
","if FakeState . deploy_dir :
",33.34,4.88,False
"def validate_name_and_description ( body , check_length = True ) : <TAB> for attribute in [ "" name "" , "" description "" , "" display_name "" , "" display_description "" ] : <TAB> <TAB> value = body . get ( attribute ) <TAB> <TAB> if value is not None : <TAB> <TAB> <TAB> if isinstance ( value , six . string_types ) : <TAB> <TAB> <TAB> <TAB> body [ attribute ] = value . strip ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> utils . check_string_length ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> body [ attribute ] , attribute , min_length = 0 , max_length = 255 <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> except exception . InvalidInput as error : <TAB> <TAB> <TAB> <TAB> <TAB> raise webob . exc . HTTPBadRequest ( explanation = error . msg ) ","if check_length : 
","if check_length :
",78.12,100.0,True
"def pick ( items , sel ) : <TAB> for x , s in zip ( items , sel ) : <TAB> <TAB> if match ( s ) : <TAB> <TAB> <TAB> yield x <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield x . restructure ( x . head , pick ( x . leaves , s . leaves ) , evaluation ) ","elif not x . is_atom ( ) and not s . is_atom ( ) : 
","elif isinstance ( s , Solid ) :
",26.62,3.51,False
"def wait_or_kill ( self ) : <TAB> """"""Wait for the program to terminate, or kill it after 5s."""""" <TAB> if self . instance . poll ( ) is None : <TAB> <TAB> # We try one more time to kill gracefully using Ctrl-C. <TAB> <TAB> logger . info ( "" Interrupting  %s  and waiting... "" , self . coord ) <TAB> <TAB> self . instance . send_signal ( signal . SIGINT ) <TAB> <TAB> # FIXME on py3 this becomes self.instance.wait(timeout=5) <TAB> <TAB> t = monotonic_time ( ) <TAB> <TAB> while monotonic_time ( ) - t < 5 : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> logger . info ( "" Terminated  %s . "" , self . coord ) <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> time . sleep ( 0.1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . kill ( ) ","if self . instance . poll ( ) is not None : 
","if self . instance . poll ( ) is None :
",85.01,77.72,False
"def sort_collection ( self , models , many ) : <TAB> ordering = self . ordering <TAB> if not many or not ordering : <TAB> <TAB> return models <TAB> for key in reversed ( ordering ) : <TAB> <TAB> reverse = key [ 0 ] == "" - "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> key = key [ 1 : ] <TAB> <TAB> models = sorted ( models , key = partial ( deep_getattr , key = key ) , reverse = reverse ) <TAB> return models ","if reverse : 
","if reverse :
",78.12,0.0,False
"def get_palette_for_custom_classes ( self , class_names , palette = None ) : <TAB> if self . label_map is not None : <TAB> <TAB> # return subset of palette <TAB> <TAB> palette = [ ] <TAB> <TAB> for old_id , new_id in sorted ( self . label_map . items ( ) , key = lambda x : x [ 1 ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> palette . append ( self . PALETTE [ old_id ] ) <TAB> <TAB> palette = type ( self . PALETTE ) ( palette ) <TAB> elif palette is None : <TAB> <TAB> if self . PALETTE is None : <TAB> <TAB> <TAB> palette = np . random . randint ( 0 , 255 , size = ( len ( class_names ) , 3 ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> palette = self . PALETTE <TAB> return palette ","if new_id != - 1 : 
","if old_id in class_names :
",27.71,11.34,False
"def _find_tcl_dir ( ) : <TAB> lib_dirs = [ os . path . dirname ( _x ) for _x in sys . path if _x . lower ( ) . endswith ( "" lib "" ) ] <TAB> for lib_dir in lib_dirs : <TAB> <TAB> base_dir = os . path . join ( lib_dir , TclLibrary . FOLDER ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for root , _ , files in os . walk ( base_dir ) : <TAB> <TAB> <TAB> <TAB> if TclLibrary . INIT_TCL in files : <TAB> <TAB> <TAB> <TAB> <TAB> return root ","if os . path . exists ( base_dir ) : 
","if os . path . isdir ( base_dir ) :
",83.03,73.49,False
"def __next__ ( self ) : <TAB> """"""Special paging functionality"""""" <TAB> if self . iter is None : <TAB> <TAB> self . iter = iter ( self . objs ) <TAB> try : <TAB> <TAB> return next ( self . iter ) <TAB> except StopIteration : <TAB> <TAB> self . iter = None <TAB> <TAB> self . objs = [ ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . page + = 1 <TAB> <TAB> <TAB> self . _connection . get_response ( self . action , self . params , self . page , self ) <TAB> <TAB> <TAB> return next ( self ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","if int ( self . page ) < int ( self . total_pages ) : 
","if self . _connection :
",31.94,3.26,False
"def parse ( cls , api , json ) : <TAB> lst = List ( api ) <TAB> setattr ( lst , "" _json "" , json ) <TAB> for k , v in json . items ( ) : <TAB> <TAB> if k == "" user "" : <TAB> <TAB> <TAB> setattr ( lst , k , User . parse ( api , v ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> setattr ( lst , k , parse_datetime ( v ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> setattr ( lst , k , v ) <TAB> return lst ","elif k == "" created_at "" : 
","elif k == "" datetime "" :
",74.63,46.31,False
"def real_type ( self ) : <TAB> # Find the real type representation by updating it as required <TAB> real_type = self . type <TAB> if self . flag_indicator : <TAB> <TAB> real_type = "" # "" <TAB> if self . is_vector : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> real_type = "" Vector< {} > "" . format ( real_type ) <TAB> <TAB> else : <TAB> <TAB> <TAB> real_type = "" vector< {} > "" . format ( real_type ) <TAB> if self . is_generic : <TAB> <TAB> real_type = "" ! {} "" . format ( real_type ) <TAB> if self . is_flag : <TAB> <TAB> real_type = "" flags. {} ? {} "" . format ( self . flag_index , real_type ) <TAB> return real_type ","if self . use_vector_id : 
","if self . type_index == 0 :
",45.06,17.75,False
"def check_fs ( path ) : <TAB> with open ( path , "" rb "" ) as f : <TAB> <TAB> code = python_bytes_to_unicode ( f . read ( ) , errors = "" replace "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module = _load_module ( evaluator , path , code ) <TAB> <TAB> <TAB> module_name = sys_path . dotted_path_in_sys_path ( <TAB> <TAB> <TAB> <TAB> evaluator . project . sys_path , path <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if module_name is not None : <TAB> <TAB> <TAB> <TAB> add_module ( evaluator , module_name , module ) <TAB> <TAB> <TAB> return module ","if name in code : 
","if evaluator . project . sys_path . exists ( code ) :
",27.28,3.74,False
"def infoCalendar ( users ) : <TAB> calendarId = normalizeCalendarId ( sys . argv [ 5 ] , checkPrimary = True ) <TAB> i = 0 <TAB> count = len ( users ) <TAB> for user in users : <TAB> <TAB> i + = 1 <TAB> <TAB> user , cal = buildCalendarGAPIObject ( user ) <TAB> <TAB> if not cal : <TAB> <TAB> <TAB> continue <TAB> <TAB> result = gapi . call ( <TAB> <TAB> <TAB> cal . calendarList ( ) , "" get "" , soft_errors = True , calendarId = calendarId <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( f "" User:  { user } , Calendar: { display . current_count ( i , count ) } "" ) <TAB> <TAB> <TAB> _showCalendar ( result , 1 , 1 ) ","if result : 
","if result :
",78.12,0.0,False
"def set_hidestate_input_sockets_to_cope_with_switchnum ( self ) : <TAB> tndict = get_indices_that_should_be_visible ( self . node_state ) <TAB> for key , value in tndict . items ( ) : <TAB> <TAB> socket = self . inputs [ key ] <TAB> <TAB> desired_hide_state = not ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> socket . hide_safe = desired_hide_state ","if not socket . hide == desired_hide_state : 
","if socket . hide_safe is not None :
",33.82,15.83,False
"def get_class_name ( item ) : <TAB> class_name , module_name = None , None <TAB> for parent in reversed ( item . listchain ( ) ) : <TAB> <TAB> if isinstance ( parent , pytest . Class ) : <TAB> <TAB> <TAB> class_name = parent . name <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module_name = parent . module . __name__ <TAB> <TAB> <TAB> break <TAB> # heuristic: <TAB> # - better to group gpu and task tests, since tests from those modules <TAB> #   are likely to share caching more <TAB> # - split up the rest by class name because slow tests tend to be in <TAB> #   the same module <TAB> if class_name and "" .tasks. "" not in module_name : <TAB> <TAB> return "" {} . {} "" . format ( module_name , class_name ) <TAB> else : <TAB> <TAB> return module_name ","elif isinstance ( parent , pytest . Module ) : 
","elif isinstance ( parent , pytest . Module ) :
",100.0,100.0,True
"def run ( self ) : <TAB> versions = versioneer . get_versions ( ) <TAB> tempdir = tempfile . mkdtemp ( ) <TAB> generated = os . path . join ( tempdir , "" rundemo "" ) <TAB> with open ( generated , "" wb "" ) as f : <TAB> <TAB> for line in open ( "" src/rundemo-template "" , "" rb "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f . write ( ( "" versions =  %r \n "" % ( versions , ) ) . encode ( "" ascii "" ) ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> f . write ( line ) <TAB> self . scripts = [ generated ] <TAB> rc = build_scripts . run ( self ) <TAB> os . unlink ( generated ) <TAB> os . rmdir ( tempdir ) <TAB> return rc ","if line . strip ( ) . decode ( "" ascii "" ) == "" #versions "" : 
","if versions :
",25.42,0.0,False
"def get_user_context ( request , escape = False ) : <TAB> if isinstance ( request , HttpRequest ) : <TAB> <TAB> user = getattr ( request , "" user "" , None ) <TAB> <TAB> result = { "" ip_address "" : request . META [ "" REMOTE_ADDR "" ] } <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . update ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" email "" : user . email , <TAB> <TAB> <TAB> <TAB> <TAB> "" id "" : user . id , <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if user . name : <TAB> <TAB> <TAB> <TAB> result [ "" name "" ] = user . name <TAB> else : <TAB> <TAB> result = { } <TAB> return mark_safe ( json . dumps ( result ) ) ","if user and user . is_authenticated ( ) : 
","if user :
",27.38,0.0,False
"def tokens_to_spans ( ) - > Iterable [ Tuple [ str , Optional [ Style ] ] ] : <TAB> """"""Convert tokens to spans."""""" <TAB> tokens = iter ( line_tokenize ( ) ) <TAB> line_no = 0 <TAB> _line_start = line_start - 1 <TAB> # Skip over tokens until line start <TAB> while line_no < _line_start : <TAB> <TAB> _token_type , token = next ( tokens ) <TAB> <TAB> yield ( token , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> line_no + = 1 <TAB> # Generate spans until line end <TAB> for token_type , token in tokens : <TAB> <TAB> yield ( token , _get_theme_style ( token_type ) ) <TAB> <TAB> if token . endswith ( "" \n "" ) : <TAB> <TAB> <TAB> line_no + = 1 <TAB> <TAB> <TAB> if line_no > = line_end : <TAB> <TAB> <TAB> <TAB> break ","if token . endswith ( "" \n "" ) : 
","if token . endswith ( "" \r "" ) :
",83.03,70.17,False
"def encode ( self , encodeFun , value , defMode , maxChunkSize ) : <TAB> substrate , isConstructed = self . encodeValue ( encodeFun , value , defMode , maxChunkSize ) <TAB> tagSet = value . getTagSet ( ) <TAB> if tagSet : <TAB> <TAB> if not isConstructed :<TAB> # primitive form implies definite mode <TAB> <TAB> <TAB> defMode = 1 <TAB> <TAB> return ( <TAB> <TAB> <TAB> self . encodeTag ( tagSet [ - 1 ] , isConstructed ) <TAB> <TAB> <TAB> + self . encodeLength ( len ( substrate ) , defMode ) <TAB> <TAB> <TAB> + substrate <TAB> <TAB> <TAB> + self . _encodeEndOfOctets ( encodeFun , defMode ) <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return substrate<TAB> # untagged value ","if not isConstructed : 
","if not isConstructed :
",100.0,100.0,True
def _run ( self ) : <TAB> while True : <TAB> <TAB> request = self . _requests . get ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . shutdown ( ) <TAB> <TAB> <TAB> break <TAB> <TAB> self . process ( request ) <TAB> <TAB> self . _requests . task_done ( ) ,"if request is None : 
","if request is None :
",100.0,100.0,True
"def _decode_payload ( self , payload ) : <TAB> # we need to decrypt it <TAB> if payload [ "" enc "" ] == "" aes "" : <TAB> <TAB> try : <TAB> <TAB> <TAB> payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB> <TAB> except salt . crypt . AuthenticationError : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> payload [ "" load "" ] = self . crypticle . loads ( payload [ "" load "" ] ) <TAB> return payload ","if not self . _update_aes ( ) : 
","if not self . config [ "" decrypt_aes_mode "" ] :
",45.13,21.02,False
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> if self . any_match : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return not self . inverse<TAB> # True <TAB> <TAB> else : <TAB> <TAB> <TAB> if not result : <TAB> <TAB> <TAB> <TAB> return self . inverse<TAB> # False <TAB> if self . any_match : <TAB> <TAB> return self . inverse<TAB> # False <TAB> else : <TAB> <TAB> return not self . inverse<TAB> # True ","if result : 
","if result :
",78.12,0.0,False
"def setup_parameter_node ( self , param_node ) : <TAB> if param_node . bl_idname == "" SvNumberNode "" : <TAB> <TAB> if self . use_prop or self . get_prop_name ( ) : <TAB> <TAB> <TAB> value = self . sv_get ( ) [ 0 ] [ 0 ] <TAB> <TAB> <TAB> print ( "" V "" , value ) <TAB> <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" int "" <TAB> <TAB> <TAB> <TAB> param_node . int_ = value <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> param_node . selected_mode = "" float "" <TAB> <TAB> <TAB> <TAB> param_node . float_ = value ","elif isinstance ( value , float ) : 
","elif isinstance ( value , float ) :
",100.0,100.0,True
"def iter_modules ( self , by_clients = False , clients_filter = None ) : <TAB> """"""iterate over all modules"""""" <TAB> clients = None <TAB> if by_clients : <TAB> <TAB> clients = self . get_clients ( clients_filter ) <TAB> <TAB> if not clients : <TAB> <TAB> <TAB> return <TAB> self . _refresh_modules ( ) <TAB> for module_name in self . modules : <TAB> <TAB> try : <TAB> <TAB> <TAB> module = self . get_module ( module_name ) <TAB> <TAB> except PupyModuleDisabled : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for client in clients : <TAB> <TAB> <TAB> <TAB> if module . is_compatible_with ( client ) : <TAB> <TAB> <TAB> <TAB> <TAB> yield module <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> yield module ","if clients is not None : 
","if module :
",27.4,0.0,False
"def filter_pricing_rule_based_on_condition ( pricing_rules , doc = None ) : <TAB> filtered_pricing_rules = [ ] <TAB> if doc : <TAB> <TAB> for pricing_rule in pricing_rules : <TAB> <TAB> <TAB> if pricing_rule . condition : <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> filtered_pricing_rules . append ( pricing_rule ) <TAB> else : <TAB> <TAB> filtered_pricing_rules = pricing_rules <TAB> return filtered_pricing_rules ","if frappe . safe_eval ( pricing_rule . condition , None , doc . as_dict ( ) ) : 
","if pricing_rule . condition . doc == doc :
",36.37,13.51,False
"def build_query_string ( kv_data , ignore_none = True ) : <TAB> # {""a"": 1, ""b"": ""test""} -> ""?a=1&b=test"" <TAB> query_string = "" "" <TAB> for k , v in kv_data . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if query_string != "" "" : <TAB> <TAB> <TAB> query_string + = "" & "" <TAB> <TAB> else : <TAB> <TAB> <TAB> query_string = "" ? "" <TAB> <TAB> query_string + = k + "" = "" + str ( v ) <TAB> return query_string ","if ignore_none is True and kv_data [ k ] is None : 
","if ignore_none and k in ignore_none :
",27.17,17.71,False
"def sample ( self , * * config ) : <TAB> """"""Sample a configuration from this search space."""""" <TAB> ret = { } <TAB> ret . update ( self . data ) <TAB> kwspaces = self . kwspaces <TAB> kwspaces . update ( config ) <TAB> striped_keys = [ k . split ( SPLITTER ) [ 0 ] for k in config . keys ( ) ] <TAB> for k , v in kwspaces . items ( ) : <TAB> <TAB> if k in striped_keys : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sub_config = _strip_config_space ( config , prefix = k ) <TAB> <TAB> <TAB> <TAB> ret [ k ] = v . sample ( * * sub_config ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> ret [ k ] = v <TAB> return ret ","if isinstance ( v , NestedSpace ) : 
","if isinstance ( v , NestedSpace ) :
",100.0,100.0,True
"def task_failed ( self , task_id , hostname , reason ) : <TAB> logger . debug ( "" task  %d  failed with message  %s "" , task_id , str ( reason ) ) <TAB> if hostname in self . host_dict : <TAB> <TAB> host_status = self . host_dict [ hostname ] <TAB> <TAB> host_status . task_failed ( task_id ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . task_host_failed_dict [ task_id ] = set ( ) <TAB> <TAB> self . task_host_failed_dict [ task_id ] . add ( hostname ) ","if task_id not in self . task_host_failed_dict : 
","if task_id not in self . task_host_failed_dict :
",100.0,100.0,True
"def match ( path ) : <TAB> for pat , _type , _property , default_title in patterns : <TAB> <TAB> m = web . re_compile ( "" ^ "" + pat ) . match ( path ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> prefix = m . group ( ) <TAB> <TAB> <TAB> extra = web . lstrips ( path , prefix ) <TAB> <TAB> <TAB> tokens = extra . split ( "" / "" , 2 ) <TAB> <TAB> <TAB> # `extra` starts with ""/"". So first token is always empty. <TAB> <TAB> <TAB> middle = web . listget ( tokens , 1 , "" "" ) <TAB> <TAB> <TAB> suffix = web . listget ( tokens , 2 , "" "" ) <TAB> <TAB> <TAB> if suffix : <TAB> <TAB> <TAB> <TAB> suffix = "" / "" + suffix <TAB> <TAB> <TAB> return _type , _property , default_title , prefix , middle , suffix <TAB> return None , None , None , None , None , None ","if m : 
","if m :
",78.12,0.0,False
"def _get_cached_resources ( self , ids ) : <TAB> key = self . get_cache_key ( None ) <TAB> if self . _cache . load ( ) : <TAB> <TAB> resources = self . _cache . get ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . log . debug ( "" Using cached results for get_resources "" ) <TAB> <TAB> <TAB> m = self . get_model ( ) <TAB> <TAB> <TAB> id_set = set ( ids ) <TAB> <TAB> <TAB> return [ r for r in resources if r [ m . id ] in id_set ] <TAB> return None ","if resources is not None : 
","if resources is not None :
",100.0,100.0,True
"def has_api_behaviour ( self , protocol ) : <TAB> config = get_config ( ) <TAB> try : <TAB> <TAB> r = self . session . get ( <TAB> <TAB> <TAB> f "" { protocol } :// { self . event . host } : { self . event . port } "" , <TAB> <TAB> <TAB> timeout = config . network_timeout , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> except requests . exceptions . SSLError : <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> f "" { [ protocol ] }  protocol not accepted on  { self . event . host } : { self . event . port } "" <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> f "" Failed probing  { self . event . host } : { self . event . port } "" , exc_info = True <TAB> <TAB> ) ","if ( "" k8s "" in r . text ) or ( ' "" code "" ' in r . text and r . status_code != 200 ) : 
","if r . status_code == 200 and r . status_code == 302 :
",31.73,16.61,False
"def get_file_type ( self , context , parent_context = None ) : <TAB> file_type = context . get ( self . file_type_name , None ) <TAB> if file_type == "" "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> file_type = parent_context . get ( self . file_type_name , self . default_file_type ) <TAB> <TAB> else : <TAB> <TAB> <TAB> file_type = self . default_file_type <TAB> return file_type ","if parent_context : 
","if parent_context :
",78.12,100.0,True
"def selectionToChunks ( self , remove = False , add = False ) : <TAB> box = self . selectionBox ( ) <TAB> if box : <TAB> <TAB> if box == self . level . bounds : <TAB> <TAB> <TAB> self . selectedChunks = set ( self . level . allChunks ) <TAB> <TAB> <TAB> return <TAB> <TAB> selectedChunks = self . selectedChunks <TAB> <TAB> boxedChunks = set ( box . chunkPositions ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> remove = True <TAB> <TAB> if remove and not add : <TAB> <TAB> <TAB> selectedChunks . difference_update ( boxedChunks ) <TAB> <TAB> else : <TAB> <TAB> <TAB> selectedChunks . update ( boxedChunks ) <TAB> self . selectionTool . selectNone ( ) ","if boxedChunks . issubset ( selectedChunks ) : 
","if remove and add :
",26.86,6.97,False
"def _run_split_on_punc ( self , text , never_split = None ) : <TAB> """"""Splits punctuation on a piece of text."""""" <TAB> if never_split is not None and text in never_split : <TAB> <TAB> return [ text ] <TAB> chars = list ( text ) <TAB> i = 0 <TAB> start_new_word = True <TAB> output = [ ] <TAB> while i < len ( chars ) : <TAB> <TAB> char = chars [ i ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> output . append ( [ char ] ) <TAB> <TAB> <TAB> start_new_word = True <TAB> <TAB> else : <TAB> <TAB> <TAB> if start_new_word : <TAB> <TAB> <TAB> <TAB> output . append ( [ ] ) <TAB> <TAB> <TAB> start_new_word = False <TAB> <TAB> <TAB> output [ - 1 ] . append ( char ) <TAB> <TAB> i + = 1 <TAB> return [ "" "" . join ( x ) for x in output ] ","if _is_punctuation ( char ) : 
","if _is_punctuation ( char ) :
",100.0,100.0,True
"def _save_images ( notebook ) : <TAB> if os . getenv ( "" NB_NO_IMAGES "" ) == "" 1 "" : <TAB> <TAB> return <TAB> logged = False <TAB> for filename , img_bytes in _iter_notebook_images ( notebook ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> log . info ( "" Saving images "" ) <TAB> <TAB> <TAB> logged = True <TAB> <TAB> with open ( filename , "" wb "" ) as f : <TAB> <TAB> <TAB> f . write ( img_bytes ) ","if not logged : 
","if not logged :
",100.0,100.0,True
"def pickPath ( self , color ) : <TAB> self . path [ color ] = ( ) <TAB> currentPos = self . starts [ color ] <TAB> while True : <TAB> <TAB> minDist = None <TAB> <TAB> minGuide = None <TAB> <TAB> for guide in self . guides [ color ] : <TAB> <TAB> <TAB> guideDist = dist ( currentPos , guide ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> minDist = guideDist <TAB> <TAB> <TAB> <TAB> minGuide = guide <TAB> <TAB> if dist ( currentPos , self . ends [ color ] ) == 1 : <TAB> <TAB> <TAB> return <TAB> <TAB> if minGuide == None : <TAB> <TAB> <TAB> return <TAB> <TAB> self . path [ color ] = self . path [ color ] + ( minGuide , ) <TAB> <TAB> currentPos = minGuide <TAB> <TAB> self . guides [ color ] . remove ( minGuide ) ","if minDist == None or guideDist < minDist : 
","if minDist is None or guideDist < minDist :
",83.32,59.12,False
"def _terminal_messenger ( tp = "" write "" , msg = "" "" , out = sys . stdout ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> elif tp == "" flush "" : <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" write_flush "" : <TAB> <TAB> <TAB> out . write ( msg ) <TAB> <TAB> <TAB> out . flush ( ) <TAB> <TAB> elif tp == "" print "" : <TAB> <TAB> <TAB> print ( msg , file = out ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" Unsupported type:  "" + tp ) <TAB> except IOError as e : <TAB> <TAB> logger . critical ( "" {} :  {} "" . format ( type ( e ) . __name__ , ucd ( e ) ) ) <TAB> <TAB> pass ","if tp == "" write "" : 
","if tp == "" write "" :
",100.0,100.0,True
"def __new__ ( mcs , name , bases , attrs ) : <TAB> include_profile = include_trace = include_garbage = True <TAB> bases = list ( bases ) <TAB> if name == "" SaltLoggingClass "" : <TAB> <TAB> for base in bases : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> include_trace = False <TAB> <TAB> <TAB> if hasattr ( base , "" garbage "" ) : <TAB> <TAB> <TAB> <TAB> include_garbage = False <TAB> if include_profile : <TAB> <TAB> bases . append ( LoggingProfileMixin ) <TAB> if include_trace : <TAB> <TAB> bases . append ( LoggingTraceMixin ) <TAB> if include_garbage : <TAB> <TAB> bases . append ( LoggingGarbageMixin ) <TAB> return super ( LoggingMixinMeta , mcs ) . __new__ ( mcs , name , tuple ( bases ) , attrs ) ","if hasattr ( base , "" trace "" ) : 
","if hasattr ( base , "" trace "" ) :
",100.0,100.0,True
"def generatePidEncryptionTable ( ) : <TAB> table = [ ] <TAB> for counter1 in range ( 0 , 0x100 ) : <TAB> <TAB> value = counter1 <TAB> <TAB> for counter2 in range ( 0 , 8 ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> value = value >> 1 <TAB> <TAB> <TAB> <TAB> value = value ^ 0xEDB88320 <TAB> <TAB> table . append ( value ) <TAB> return table ","if value & 1 == 0 : 
","if counter1 == counter2 :
",27.38,13.83,False
"def pytest_collection_modifyitems ( items ) : <TAB> for item in items : <TAB> <TAB> if item . nodeid . startswith ( "" tests/params "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . stage ( "" unit "" ) ) <TAB> <TAB> <TAB> if "" init "" not in item . keywords : <TAB> <TAB> <TAB> <TAB> item . add_marker ( pytest . mark . init ( rng_seed = 123 ) ) ","if "" stage "" not in item . keywords : 
","if "" stage "" not in item . keywords :
",100.0,100.0,True
"def python_value ( self , value ) : <TAB> if value : <TAB> <TAB> if isinstance ( value , basestring ) : <TAB> <TAB> <TAB> pp = lambda x : x . time ( ) <TAB> <TAB> <TAB> return format_date_time ( value , self . formats , pp ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return value . time ( ) <TAB> if value is not None and isinstance ( value , datetime . timedelta ) : <TAB> <TAB> return ( datetime . datetime . min + value ) . time ( ) <TAB> return value ","elif isinstance ( value , datetime . datetime ) : 
","elif isinstance ( value , datetime . datetime ) :
",100.0,100.0,True
"def list_interesting_hosts ( self ) : <TAB> hosts = [ ] <TAB> targets = self . target [ "" other "" ] <TAB> for target in targets : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> hosts . append ( <TAB> <TAB> <TAB> <TAB> { "" ip "" : target . ip , "" description "" : target . domain + ""  /  "" + target . name } <TAB> <TAB> <TAB> ) <TAB> return hosts ","if self . is_interesting ( target ) and target . status and target . status != 400 : 
","if target . is_interesting :
",33.69,6.88,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 24 : 
","if tt == 16 :
",64.48,53.73,False
"def _wait_for_finish ( self ) - > PollExitResponse : <TAB> while True : <TAB> <TAB> if self . _backend : <TAB> <TAB> <TAB> poll_exit_resp = self . _backend . interface . communicate_poll_exit ( ) <TAB> <TAB> logger . info ( "" got exit ret:  %s "" , poll_exit_resp ) <TAB> <TAB> if poll_exit_resp : <TAB> <TAB> <TAB> done = poll_exit_resp . done <TAB> <TAB> <TAB> pusher_stats = poll_exit_resp . pusher_stats <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _on_finish_progress ( pusher_stats , done ) <TAB> <TAB> <TAB> if done : <TAB> <TAB> <TAB> <TAB> return poll_exit_resp <TAB> <TAB> time . sleep ( 2 ) ","if pusher_stats : 
","if pusher_stats :
",78.12,100.0,True
"def listing_items ( method ) : <TAB> marker = None <TAB> once = True <TAB> items = [ ] <TAB> while once or items : <TAB> <TAB> for i in items : <TAB> <TAB> <TAB> yield i <TAB> <TAB> if once or marker : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> items = method ( parms = { "" marker "" : marker } ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> items = method ( ) <TAB> <TAB> <TAB> if len ( items ) == 10000 : <TAB> <TAB> <TAB> <TAB> marker = items [ - 1 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> marker = None <TAB> <TAB> <TAB> once = False <TAB> <TAB> else : <TAB> <TAB> <TAB> items = [ ] ","if marker : 
","if marker :
",78.12,0.0,False
"def call ( monad , * args ) : <TAB> for arg , name in izip ( args , ( "" hour "" , "" minute "" , "" second "" , "" microsecond "" ) ) : <TAB> <TAB> if not isinstance ( arg , NumericMixin ) or arg . type is not int : <TAB> <TAB> <TAB> throw ( <TAB> <TAB> <TAB> <TAB> TypeError , <TAB> <TAB> <TAB> <TAB> "" ' %s '  argument of time(...) function must be of  ' int '  type. Got:  %r "" <TAB> <TAB> <TAB> <TAB> % ( name , type2str ( arg . type ) ) , <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> throw ( NotImplementedError ) <TAB> return ConstMonad . new ( time ( * tuple ( arg . value for arg in args ) ) ) ","if not isinstance ( arg , ConstMonad ) : 
","if monad . is_constant ( name ) :
",28.07,9.98,False
"def group_by_sign ( seq , slop = sin ( pi / 18 ) , key = lambda x : x ) : <TAB> sign = None <TAB> subseq = [ ] <TAB> for i in seq : <TAB> <TAB> ki = key ( i ) <TAB> <TAB> if sign is None : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> if ki != 0 : <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> else : <TAB> <TAB> <TAB> subseq . append ( i ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sign = ki / abs ( ki ) <TAB> <TAB> <TAB> <TAB> yield subseq <TAB> <TAB> <TAB> <TAB> subseq = [ i ] <TAB> if subseq : <TAB> <TAB> yield subseq ","if sign * ki < - slop : 
","if sign * ki < slop :
",60.36,61.3,False
"def walk_links ( self ) : <TAB> link_info_list = [ ] <TAB> for item in self . content : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> link_info = LinkInfo ( link = item , name = item . name , sections = ( ) ) <TAB> <TAB> <TAB> link_info_list . append ( link_info ) <TAB> <TAB> else : <TAB> <TAB> <TAB> link_info_list . extend ( item . walk_links ( ) ) <TAB> return link_info_list ","if isinstance ( item , Link ) : 
","if isinstance ( item , LinkInfo ) :
",79.9,59.46,False
"def get_subkeys ( self , key ) : <TAB> # TODO: once we revamp the registry emulation, <TAB> # make this better <TAB> parent_path = key . get_path ( ) <TAB> subkeys = [ ] <TAB> for k in self . keys : <TAB> <TAB> test_path = k . get_path ( ) <TAB> <TAB> if test_path . lower ( ) . startswith ( parent_path . lower ( ) ) : <TAB> <TAB> <TAB> sub = test_path [ len ( parent_path ) : ] <TAB> <TAB> <TAB> if sub . startswith ( "" \\ "" ) : <TAB> <TAB> <TAB> <TAB> sub = sub [ 1 : ] <TAB> <TAB> <TAB> end_slash = sub . find ( "" \\ "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sub = sub [ : end_slash ] <TAB> <TAB> <TAB> if not sub : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> subkeys . append ( sub ) <TAB> return subkeys ","if end_slash > = 0 : 
","if end_slash > - 1 :
",36.11,54.11,False
"def load_dict ( dict_path , reverse = False ) : <TAB> word_dict = { } <TAB> with open ( dict_path , "" rb "" ) as fdict : <TAB> <TAB> for idx , line in enumerate ( fdict ) : <TAB> <TAB> <TAB> line = cpt . to_text ( line ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> word_dict [ idx ] = line . strip ( "" \n "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> word_dict [ line . strip ( "" \n "" ) ] = idx <TAB> return word_dict ","if reverse : 
","if reverse :
",78.12,0.0,False
"def test_network ( coords , feats , model , batch_sizes , forward_only = True ) : <TAB> for batch_size in batch_sizes : <TAB> <TAB> bcoords = batched_coordinates ( [ coords for i in range ( batch_size ) ] ) <TAB> <TAB> bfeats = torch . cat ( [ feats for i in range ( batch_size ) ] , 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with torch . no_grad ( ) : <TAB> <TAB> <TAB> <TAB> time , length = forward ( bcoords , bfeats , model ) <TAB> <TAB> else : <TAB> <TAB> <TAB> time , length = train ( bcoords , bfeats , model ) <TAB> <TAB> print ( f "" { net . __name__ } \t { voxel_size } \t { batch_size } \t { length } \t { time } "" ) <TAB> <TAB> torch . cuda . empty_cache ( ) ","if forward_only : 
","if forward_only :
",78.12,100.0,True
"def markUVs ( self , indices = None ) : <TAB> if isinstance ( indices , tuple ) : <TAB> <TAB> indices = indices [ 0 ] <TAB> ntexco = len ( self . texco ) <TAB> if indices is None : <TAB> <TAB> self . utexc = True <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . utexc = np . zeros ( ntexco , dtype = bool ) <TAB> <TAB> if self . utexc is not True : <TAB> <TAB> <TAB> self . utexc [ indices ] = True ","if self . utexc is False : 
","if indices == [ ] :
",27.03,7.81,False
"def has_module ( self , module , version ) : <TAB> has_module = False <TAB> for directory in self . directories : <TAB> <TAB> module_directory = join ( directory , module ) <TAB> <TAB> has_module_directory = isdir ( module_directory ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> has_module = has_module_directory or exists ( <TAB> <TAB> <TAB> <TAB> module_directory <TAB> <TAB> <TAB> )<TAB> # could be a bare modulefile <TAB> <TAB> else : <TAB> <TAB> <TAB> modulefile = join ( module_directory , version ) <TAB> <TAB> <TAB> has_modulefile = exists ( modulefile ) <TAB> <TAB> <TAB> has_module = has_module_directory and has_modulefile <TAB> <TAB> if has_module : <TAB> <TAB> <TAB> break <TAB> return has_module ","if not version : 
","if version == "" "" :
",28.83,8.64,False
"def get_editops ( self ) : <TAB> if not self . _editops : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _editops = editops ( self . _opcodes , self . _str1 , self . _str2 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _editops = editops ( self . _str1 , self . _str2 ) <TAB> return self . _editops ","if self . _opcodes : 
","if self . _opcodes :
",100.0,100.0,True
"def to_representation ( self , data ) : <TAB> value = super ( CredentialTypeSerializer , self ) . to_representation ( data ) <TAB> # translate labels and help_text for credential fields ""managed by Tower"" <TAB> if value . get ( "" managed_by_tower "" ) : <TAB> <TAB> value [ "" name "" ] = _ ( value [ "" name "" ] ) <TAB> <TAB> for field in value . get ( "" inputs "" , { } ) . get ( "" fields "" , [ ] ) : <TAB> <TAB> <TAB> field [ "" label "" ] = _ ( field [ "" label "" ] ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> field [ "" help_text "" ] = _ ( field [ "" help_text "" ] ) <TAB> return value ","if "" help_text "" in field : 
","if field . get ( "" help_text "" ) :
",38.92,35.66,False
"def sort_nested_dictionary_lists ( d ) : <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , list ) : <TAB> <TAB> <TAB> for i in range ( 0 , len ( v ) ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> v [ i ] = await sort_nested_dictionary_lists ( v [ i ] ) <TAB> <TAB> <TAB> <TAB> d [ k ] = sorted ( v ) <TAB> <TAB> if isinstance ( v , dict ) : <TAB> <TAB> <TAB> d [ k ] = await sort_nested_dictionary_lists ( v ) <TAB> return d ","if isinstance ( v [ i ] , dict ) : 
","if isinstance ( v [ i ] , dict ) :
",100.0,100.0,True
"def messageSourceStamps ( self , source_stamps ) : <TAB> text = "" "" <TAB> for ss in source_stamps : <TAB> <TAB> source = "" "" <TAB> <TAB> if ss [ "" branch "" ] : <TAB> <TAB> <TAB> source + = "" [branch  %s ]  "" % ss [ "" branch "" ] <TAB> <TAB> if ss [ "" revision "" ] : <TAB> <TAB> <TAB> source + = str ( ss [ "" revision "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> source + = "" HEAD "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source + = ""  (plus patch) "" <TAB> <TAB> discriminator = "" "" <TAB> <TAB> if ss [ "" codebase "" ] : <TAB> <TAB> <TAB> discriminator = "" ' %s ' "" % ss [ "" codebase "" ] <TAB> <TAB> text + = "" Build Source Stamp %s :  %s \n "" % ( discriminator , source ) <TAB> return text ","if ss [ "" patch "" ] is not None : 
","if ss [ "" patch "" ] :
",61.31,59.76,False
"def fit_one ( self , x ) : <TAB> for i , xi in x . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . median [ i ] . update ( xi ) <TAB> <TAB> if self . with_scaling : <TAB> <TAB> <TAB> self . iqr [ i ] . update ( xi ) <TAB> return self ","if self . with_centering : 
","if self . with_scaling :
",64.48,64.35,False
"def start_response ( self , status , headers , exc_info = None ) : <TAB> if exc_info : <TAB> <TAB> try : <TAB> <TAB> <TAB> if self . started : <TAB> <TAB> <TAB> <TAB> six . reraise ( exc_info [ 0 ] , exc_info [ 1 ] , exc_info [ 2 ] ) <TAB> <TAB> finally : <TAB> <TAB> <TAB> exc_info = None <TAB> self . request . status = int ( status [ : 3 ] ) <TAB> for key , val in headers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . request . set_content_length ( int ( val ) ) <TAB> <TAB> elif key . lower ( ) == "" content-type "" : <TAB> <TAB> <TAB> self . request . content_type = val <TAB> <TAB> else : <TAB> <TAB> <TAB> self . request . headers_out . add ( key , val ) <TAB> return self . write ","if key . lower ( ) == "" content-length "" : 
","if key . lower ( ) == "" content-length "" :
",100.0,100.0,True
"def _osp2ec ( self , bytes ) : <TAB> compressed = self . _from_bytes ( bytes ) <TAB> y = compressed >> self . _bits <TAB> x = compressed & ( 1 << self . _bits ) - 1 <TAB> if x == 0 : <TAB> <TAB> y = self . _curve . b <TAB> else : <TAB> <TAB> result = self . sqrtp ( <TAB> <TAB> <TAB> x * * 3 + self . _curve . a * x + self . _curve . b , self . _curve . field . p <TAB> <TAB> ) <TAB> <TAB> if len ( result ) == 1 : <TAB> <TAB> <TAB> y = result [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> y1 , y2 = result <TAB> <TAB> <TAB> y = y1 if ( y1 & 1 == y ) else y2 <TAB> <TAB> else : <TAB> <TAB> <TAB> return None <TAB> return ec . Point ( self . _curve , x , y ) ","elif len ( result ) == 2 : 
","if len ( result ) == 2 :
",69.18,86.33,False
"def trace ( self , ee , rname ) : <TAB> print ( type ( self ) ) <TAB> self . traceIndent ( ) <TAB> guess = "" "" <TAB> if self . inputState . guessing > 0 : <TAB> <TAB> guess = ""  [guessing] "" <TAB> print ( ( ee + rname + guess ) ) <TAB> for i in xrange ( 1 , self . k + 1 ) : <TAB> <TAB> if i != 1 : <TAB> <TAB> <TAB> print ( "" ,  "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = self . LT ( i ) . getText ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> v = "" null "" <TAB> <TAB> print ( "" LA( %s ) ==  %s "" % ( i , v ) ) <TAB> print ( "" \n "" ) ","if self . LT ( i ) : 
","if self . inputState . LA ( i ) . getText ( ) != guess :
",43.74,14.88,False
"def _table_schema ( self , table ) : <TAB> rows = self . db . execute_sql ( "" PRAGMA table_info( ' %s ' ) "" % table ) . fetchall ( ) <TAB> # Build list of fields from table information <TAB> result = { } <TAB> for _ , name , data_type , not_null , _ , primary_key in rows : <TAB> <TAB> parts = [ data_type ] <TAB> <TAB> if primary_key : <TAB> <TAB> <TAB> parts . append ( "" PRIMARY KEY "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts . append ( "" NOT NULL "" ) <TAB> <TAB> result [ name ] = "" "" . join ( parts ) <TAB> return result ","if not_null : 
","if not_null :
",78.12,100.0,True
"def _parse_csrf ( self , response ) : <TAB> for d in response : <TAB> <TAB> if d . startswith ( "" Set-Cookie: "" ) : <TAB> <TAB> <TAB> for c in d . split ( "" : "" , 1 ) [ 1 ] . split ( "" ; "" ) : <TAB> <TAB> <TAB> <TAB> if c . strip ( ) . startswith ( "" CSRF-Token- "" ) : <TAB> <TAB> <TAB> <TAB> <TAB> self . _CSRFtoken = c . strip ( "" \r \n "" ) <TAB> <TAB> <TAB> <TAB> <TAB> log . verbose ( "" Got new cookie:  %s "" , self . _CSRFtoken ) <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break ","if self . _CSRFtoken != None : 
","if not d . startswith ( "" Set-Cookie-Value: "" ) :
",32.98,4.46,False
"def _update_from_item ( self , row , download_item ) : <TAB> progress_stats = download_item . progress_stats <TAB> for key in self . columns : <TAB> <TAB> column = self . columns [ key ] [ 0 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Not the best place but we build the playlist status here <TAB> <TAB> <TAB> status = "" {0} {1} / {2} "" . format ( <TAB> <TAB> <TAB> <TAB> progress_stats [ "" status "" ] , <TAB> <TAB> <TAB> <TAB> progress_stats [ "" playlist_index "" ] , <TAB> <TAB> <TAB> <TAB> progress_stats [ "" playlist_size "" ] , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> self . SetStringItem ( row , column , status ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . SetStringItem ( row , column , progress_stats [ key ] ) ","if key == "" status "" and progress_stats [ "" playlist_index "" ] : 
","if key == "" status "" :
",52.54,21.98,False
"def unmarshal_package_repositories ( cls , data : Any ) - > List [ "" PackageRepository "" ] : <TAB> repositories = list ( ) <TAB> if data is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( f "" invalid package-repositories:  { data !r} "" ) <TAB> <TAB> for repository in data : <TAB> <TAB> <TAB> package_repo = cls . unmarshal ( repository ) <TAB> <TAB> <TAB> repositories . append ( package_repo ) <TAB> return repositories ","if not isinstance ( data , list ) : 
","if not isinstance ( data , ( list , tuple ) ) :
",53.03,44.08,False
"def remove_message ( e = None ) : <TAB> itop = scanbox . nearest ( 0 ) <TAB> sel = scanbox . curselection ( ) <TAB> if not sel : <TAB> <TAB> dialog ( <TAB> <TAB> <TAB> root , <TAB> <TAB> <TAB> "" No Message To Remove "" , <TAB> <TAB> <TAB> "" Please select a message to remove "" , <TAB> <TAB> <TAB> "" "" , <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> "" OK "" , <TAB> <TAB> ) <TAB> <TAB> return <TAB> todo = [ ] <TAB> for i in sel : <TAB> <TAB> line = scanbox . get ( i ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> todo . append ( string . atoi ( scanparser . group ( 1 ) ) ) <TAB> mhf . removemessages ( todo ) <TAB> rescan ( ) <TAB> fixfocus ( min ( todo ) , itop ) ","if scanparser . match ( line ) > = 0 : 
","if line :
",25.93,0.0,False
"def test_patches ( ) : <TAB> print ( <TAB> <TAB> "" Botocore version:  {}  aiohttp version:  {} "" . format ( <TAB> <TAB> <TAB> botocore . __version__ , aiohttp . __version__ <TAB> <TAB> ) <TAB> ) <TAB> success = True <TAB> for obj , digests in chain ( _AIOHTTP_DIGESTS . items ( ) , _API_DIGESTS . items ( ) ) : <TAB> <TAB> digest = hashlib . sha1 ( getsource ( obj ) . encode ( "" utf-8 "" ) ) . hexdigest ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" Digest of  {} : {}  not found in:  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> obj . __qualname__ , digest , digests <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> success = False <TAB> assert success ","if digest not in digests : 
","if digest not in digests :
",100.0,100.0,True
"def sample_admin_user ( ) : <TAB> """"""List of iris messages"""""" <TAB> with iris_ctl . db_from_config ( sample_db_config ) as ( conn , cursor ) : <TAB> <TAB> cursor . execute ( <TAB> <TAB> <TAB> "" SELECT `name` FROM `target` JOIN `user` on `target`.`id` = `user`.`target_id` WHERE `user`.`admin` = TRUE LIMIT 1 "" <TAB> <TAB> ) <TAB> <TAB> result = cursor . fetchone ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return result [ 0 ] ","if result : 
","if result :
",78.12,0.0,False
"def _addRightnames ( groups , kerning , leftname , rightnames , includeAll = True ) : <TAB> if leftname in kerning : <TAB> <TAB> for rightname in kerning [ leftname ] : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> for rightname2 in groups [ rightname ] : <TAB> <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname2 ) <TAB> <TAB> <TAB> <TAB> <TAB> if not includeAll : <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # TODO: in this case, pick the one rightname that has the highest <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> # ranking in glyphorder <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> rightnames . add ( rightname ) ","if rightname [ 0 ] == "" @ "" : 
","if rightname in groups :
",27.56,7.12,False
"def build ( self , input_shape ) : <TAB> if isinstance ( input_shape , list ) and len ( input_shape ) == 2 : <TAB> <TAB> self . data_mode = "" disjoint "" <TAB> <TAB> self . F = input_shape [ 0 ] [ - 1 ] <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . data_mode = "" single "" <TAB> <TAB> else : <TAB> <TAB> <TAB> self . data_mode = "" batch "" <TAB> <TAB> self . F = input_shape [ - 1 ] ","if len ( input_shape ) == 2 : 
","if len ( input_shape ) == 1 :
",85.56,80.71,False
"def update_ranges ( l , i ) : <TAB> for _range in l : <TAB> <TAB> # most common case: extend a range <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _range [ 0 ] = i <TAB> <TAB> <TAB> merge_ranges ( l ) <TAB> <TAB> <TAB> return <TAB> <TAB> elif i == _range [ 1 ] + 1 : <TAB> <TAB> <TAB> _range [ 1 ] = i <TAB> <TAB> <TAB> merge_ranges ( l ) <TAB> <TAB> <TAB> return <TAB> # somewhere outside of range proximity <TAB> l . append ( [ i , i ] ) <TAB> l . sort ( key = lambda x : x [ 0 ] ) ","if i == _range [ 0 ] - 1 : 
","if i < _range [ 0 ] + 1 :
",67.9,41.07,False
"def transform ( a , cmds ) : <TAB> buf = a . split ( "" \n "" ) <TAB> for cmd in cmds : <TAB> <TAB> ctype , line , col , char = cmd <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if char != "" \n "" : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + buf [ line ] [ col + len ( char ) : ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] + buf [ line + 1 ] <TAB> <TAB> <TAB> <TAB> del buf [ line + 1 ] <TAB> <TAB> elif ctype == "" I "" : <TAB> <TAB> <TAB> buf [ line ] = buf [ line ] [ : col ] + char + buf [ line ] [ col : ] <TAB> <TAB> buf = "" \n "" . join ( buf ) . split ( "" \n "" ) <TAB> return "" \n "" . join ( buf ) ","if ctype == "" D "" : 
","if ctype == "" S "" :
",74.63,59.46,False
"def _media_files_drag_received ( widget , context , x , y , data , info , timestamp ) : <TAB> uris = data . get_uris ( ) <TAB> files = [ ] <TAB> for uri in uris : <TAB> <TAB> try : <TAB> <TAB> <TAB> uri_tuple = GLib . filename_from_uri ( uri ) <TAB> <TAB> except : <TAB> <TAB> <TAB> continue <TAB> <TAB> uri , unused = uri_tuple <TAB> <TAB> if os . path . exists ( uri ) == True : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> files . append ( uri ) <TAB> if len ( files ) == 0 : <TAB> <TAB> return <TAB> open_dropped_files ( files ) ","if utils . is_media_file ( uri ) == True : 
","if os . path . isfile ( uri ) :
",39.49,11.27,False
"def __walk_proceed_remote_dir_act ( self , r , args ) : <TAB> dirjs , filejs = args <TAB> j = r . json ( ) <TAB> if "" list "" not in j : <TAB> <TAB> self . pd ( <TAB> <TAB> <TAB> "" Key  ' list '  not found in the response of directory listing request: \n {} "" . format ( <TAB> <TAB> <TAB> <TAB> j <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> <TAB> return const . ERequestFailed <TAB> paths = j [ "" list "" ] <TAB> for path in paths : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dirjs . append ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> filejs . append ( path ) <TAB> return const . ENoError ","if path [ "" isdir "" ] : 
","if path . endswith ( "" .git "" ) :
",34.59,9.43,False
"def TaskUpdatesVerbose ( task , progress ) : <TAB> if isinstance ( task . info . progress , int ) : <TAB> <TAB> info = task . info <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> progress = "" %d %%  ( %s ) "" % ( info . progress , info . state ) <TAB> <TAB> print ( <TAB> <TAB> <TAB> "" Task  %s  (key: %s , desc: %s ) -  %s "" <TAB> <TAB> <TAB> % ( info . name . info . name , info . key , info . description , progress ) <TAB> <TAB> ) ","if not isinstance ( progress , str ) : 
","if info . progress :
",26.63,6.32,False
"def dump_constants ( header ) : <TAB> output = StringIO . StringIO ( ) <TAB> output . write ( header ) <TAB> for attribute in dir ( FSEvents ) : <TAB> <TAB> value = getattr ( FSEvents , attribute ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> output . write ( ""<TAB>  %s  =  %s \n "" % ( attribute , hex ( value ) ) ) <TAB> content = output . getvalue ( ) <TAB> output . close ( ) <TAB> return content ","if attribute . startswith ( "" k "" ) and isinstance ( value , int ) : 
","if attribute . startswith ( "" constants_ "" ) :
",52.28,32.22,False
"def _ensure_data_is_loaded ( <TAB> self , <TAB> sql_object , <TAB> input_params , <TAB> stdin_file , <TAB> stdin_filename = "" - "" , <TAB> stop_after_analysis = False , ) : <TAB> data_loads = [ ] <TAB> # Get each ""table name"" which is actually the file name <TAB> for filename in sql_object . qtable_names : <TAB> <TAB> data_load = self . _load_data ( <TAB> <TAB> <TAB> filename , <TAB> <TAB> <TAB> input_params , <TAB> <TAB> <TAB> stdin_file = stdin_file , <TAB> <TAB> <TAB> stdin_filename = stdin_filename , <TAB> <TAB> <TAB> stop_after_analysis = stop_after_analysis , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data_loads . append ( data_load ) <TAB> return data_loads ","if data_load is not None : 
","if data_load is not None :
",100.0,100.0,True
"def _get_instantiation ( self ) : <TAB> if self . _data is None : <TAB> <TAB> f , l , c , o = c_object_p ( ) , c_uint ( ) , c_uint ( ) , c_uint ( ) <TAB> <TAB> SourceLocation_loc ( self , byref ( f ) , byref ( l ) , byref ( c ) , byref ( o ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f = File ( f ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = None <TAB> <TAB> self . _data = ( f , int ( l . value ) , int ( c . value ) , int ( c . value ) ) <TAB> return self . _data ","if f : 
","if f . exists ( ) :
",33.58,14.54,False
"def _get_all_info_lines ( data ) : <TAB> infos = [ ] <TAB> for row in data : <TAB> <TAB> splitrow = row . split ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if splitrow [ 0 ] == "" INFO: "" : <TAB> <TAB> <TAB> <TAB> infos . append ( "" "" . join ( splitrow [ 1 : ] ) ) <TAB> return infos ","if len ( splitrow ) > 0 : 
","if len ( splitrow ) > 0 :
",100.0,100.0,True
"def _brush_modified_cb ( self , settings ) : <TAB> """"""Updates the brush's base setting adjustments on brush changes"""""" <TAB> for cname in settings : <TAB> <TAB> adj = self . brush_adjustment . get ( cname , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> value = self . brush . get_base_value ( cname ) <TAB> <TAB> adj . set_value ( value ) ","if adj is None : 
","if adj is None :
",100.0,100.0,True
"def migrate_node_facts ( facts ) : <TAB> """"""Migrate facts from various roles into node"""""" <TAB> params = { <TAB> <TAB> "" common "" : ( "" dns_ip "" ) , <TAB> } <TAB> if "" node "" not in facts : <TAB> <TAB> facts [ "" node "" ] = { } <TAB> # pylint: disable=consider-iterating-dictionary <TAB> for role in params . keys ( ) : <TAB> <TAB> if role in facts : <TAB> <TAB> <TAB> for param in params [ role ] : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> facts [ "" node "" ] [ param ] = facts [ role ] . pop ( param ) <TAB> return facts ","if param in facts [ role ] : 
","if param in facts [ role ] :
",100.0,100.0,True
"def serialize_content_range ( value ) : <TAB> if isinstance ( value , ( tuple , list ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" When setting content_range to a list/tuple, it must  "" <TAB> <TAB> <TAB> <TAB> "" be length 2 or 3 (not  %r ) "" % value <TAB> <TAB> <TAB> ) <TAB> <TAB> if len ( value ) == 2 : <TAB> <TAB> <TAB> begin , end = value <TAB> <TAB> <TAB> length = None <TAB> <TAB> else : <TAB> <TAB> <TAB> begin , end , length = value <TAB> <TAB> value = ContentRange ( begin , end , length ) <TAB> value = str ( value ) . strip ( ) <TAB> if not value : <TAB> <TAB> return None <TAB> return value ","if len ( value ) not in ( 2 , 3 ) : 
","if len ( value ) != 3 :
",47.14,31.13,False
"def clean ( self ) : <TAB> data = super ( ) . clean ( ) <TAB> if data . get ( "" expires "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data [ "" expires "" ] = make_aware ( <TAB> <TAB> <TAB> <TAB> datetime . combine ( data [ "" expires "" ] , time ( hour = 23 , minute = 59 , second = 59 ) ) , <TAB> <TAB> <TAB> <TAB> self . instance . event . timezone , <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> data [ "" expires "" ] = data [ "" expires "" ] . replace ( hour = 23 , minute = 59 , second = 59 ) <TAB> <TAB> if data [ "" expires "" ] < now ( ) : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" The new expiry date needs to be in the future. "" ) ) <TAB> return data ","if isinstance ( data [ "" expires "" ] , date ) : 
","if isinstance ( data [ "" expires "" ] , datetime ) :
",89.65,79.11,False
"def _build ( self , obj , stream , context ) : <TAB> if self . include_name : <TAB> <TAB> name , obj = obj <TAB> <TAB> for sc in self . subcons : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sc . _build ( obj , stream , context ) <TAB> <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> for sc in self . subcons : <TAB> <TAB> <TAB> stream2 = BytesIO ( ) <TAB> <TAB> <TAB> context2 = context . __copy__ ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> sc . _build ( obj , stream2 , context2 ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> context . __update__ ( context2 ) <TAB> <TAB> <TAB> <TAB> stream . write ( stream2 . getvalue ( ) ) <TAB> <TAB> <TAB> <TAB> return <TAB> raise SelectError ( "" no subconstruct matched "" , obj ) ","if sc . name == name : 
","if sc . include_name :
",40.7,26.65,False
"def records ( account_id ) : <TAB> """"""Fetch locks data"""""" <TAB> s = boto3 . Session ( ) <TAB> table = s . resource ( "" dynamodb "" ) . Table ( "" Sphere11.Dev.ResourceLocks "" ) <TAB> results = table . scan ( ) <TAB> for r in results [ "" Items "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> r [ "" LockDate "" ] = datetime . fromtimestamp ( r [ "" LockDate "" ] ) <TAB> <TAB> if "" RevisionDate "" in r : <TAB> <TAB> <TAB> r [ "" RevisionDate "" ] = datetime . fromtimestamp ( r [ "" RevisionDate "" ] ) <TAB> print ( tabulate . tabulate ( results [ "" Items "" ] , headers = "" keys "" , tablefmt = "" fancy_grid "" ) ) ","if "" LockDate "" in r : 
","if "" LockDate "" in r :
",100.0,100.0,True
"def visitIf ( self , node , scope ) : <TAB> for test , body in node . tests : <TAB> <TAB> if isinstance ( test , ast . Const ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if not test . value : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> self . visit ( test , scope ) <TAB> <TAB> self . visit ( body , scope ) <TAB> if node . else_ : <TAB> <TAB> self . visit ( node . else_ , scope ) ","if type ( test . value ) in self . _const_types : 
","if isinstance ( test , ast . Name ) :
",34.48,6.7,False
"def validate_max_discount ( self ) : <TAB> if self . rate_or_discount == "" Discount Percentage "" and self . get ( "" items "" ) : <TAB> <TAB> for d in self . items : <TAB> <TAB> <TAB> max_discount = frappe . get_cached_value ( "" Item "" , d . item_code , "" max_discount "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> throw ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( "" Max discount allowed for item:  {0}  is  {1} % "" ) . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . item_code , max_discount <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) ","if max_discount and flt ( self . discount_percentage ) > flt ( max_discount ) : 
","if max_discount :
",25.98,2.88,False
"def has_invalid_cce ( yaml_file , product_yaml = None ) : <TAB> rule = yaml . open_and_macro_expand ( yaml_file , product_yaml ) <TAB> if "" identifiers "" in rule and rule [ "" identifiers "" ] is not None : <TAB> <TAB> for i_type , i_value in rule [ "" identifiers "" ] . items ( ) : <TAB> <TAB> <TAB> if i_type [ 0 : 3 ] == "" cce "" : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if not checks . is_cce_value_valid ( "" CCE- "" + str ( i_value ) ) : 
","if i_value not in [ "" invalid "" , "" invalid "" ] :
",28.52,7.06,False
"def parse_calendar_eras ( data , calendar ) : <TAB> eras = data . setdefault ( "" eras "" , { } ) <TAB> for width in calendar . findall ( "" eras/* "" ) : <TAB> <TAB> width_type = NAME_MAP [ width . tag ] <TAB> <TAB> widths = eras . setdefault ( width_type , { } ) <TAB> <TAB> for elem in width . getiterator ( ) : <TAB> <TAB> <TAB> if elem . tag == "" era "" : <TAB> <TAB> <TAB> <TAB> _import_type_text ( widths , elem , type = int ( elem . attrib . get ( "" type "" ) ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> eras [ width_type ] = Alias ( <TAB> <TAB> <TAB> <TAB> <TAB> _translate_alias ( [ "" eras "" , width_type ] , elem . attrib [ "" path "" ] ) <TAB> <TAB> <TAB> <TAB> ) ","elif elem . tag == "" alias "" : 
","elif elem . tag == "" alias "" :
",100.0,100.0,True
"def validate_grammar ( ) - > None : <TAB> for fn in _NONTERMINAL_CONVERSIONS_SEQUENCE : <TAB> <TAB> fn_productions = get_productions ( fn ) <TAB> <TAB> if all ( p . name == fn_productions [ 0 ] . name for p in fn_productions ) : <TAB> <TAB> <TAB> # all the production names are the same, ensure that the `convert_` function <TAB> <TAB> <TAB> # is named correctly <TAB> <TAB> <TAB> production_name = fn_productions [ 0 ] . name <TAB> <TAB> <TAB> expected_name = f "" convert_ { production_name } "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> <TAB> f "" The conversion function for  ' { production_name } ' "" <TAB> <TAB> <TAB> <TAB> <TAB> + f "" must be called  ' { expected_name } ' , not  ' { fn . __name__ } ' . "" <TAB> <TAB> <TAB> <TAB> ) ","if fn . __name__ != expected_name : 
","if expected_name not in fn_productions :
",27.34,12.94,False
"def split_ratio ( row ) : <TAB> if float ( row [ "" Numerator "" ] ) > 0 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n , m = row [ "" Splitratio "" ] . split ( "" : "" ) <TAB> <TAB> <TAB> return float ( m ) / float ( n ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return eval ( row [ "" Splitratio "" ] ) <TAB> else : <TAB> <TAB> return 1 ","if "" : "" in row [ "" Splitratio "" ] : 
","if "" Splitratio "" in row :
",41.18,22.12,False
"def _handle_def_errors ( testdef ) : <TAB> # If the test generation had an error, raise <TAB> if testdef . error : <TAB> <TAB> if testdef . exception : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise testdef . exception <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise Exception ( testdef . exception ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( "" Test parse failure "" ) ","if isinstance ( testdef . exception , Exception ) : 
","if isinstance ( testdef . exception , types . FunctionType ) :
",62.08,57.07,False
"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB> <TAB> if count < = 0 : <TAB> <TAB> <TAB> quotas_ok [ quota ] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa . results [ quota ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok ","if avail [ 1 ] is not None and avail [ 1 ] < count : 
","if avail [ 0 ] :
",33.97,6.48,False
"def reverse ( self ) : <TAB> """"""Reverse *IN PLACE*."""""" <TAB> li = self . leftindex <TAB> lb = self . leftblock <TAB> ri = self . rightindex <TAB> rb = self . rightblock <TAB> for i in range ( self . len >> 1 ) : <TAB> <TAB> lb . data [ li ] , rb . data [ ri ] = rb . data [ ri ] , lb . data [ li ] <TAB> <TAB> li + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lb = lb . rightlink <TAB> <TAB> <TAB> li = 0 <TAB> <TAB> ri - = 1 <TAB> <TAB> if ri < 0 : <TAB> <TAB> <TAB> rb = rb . leftlink <TAB> <TAB> <TAB> ri = BLOCKLEN - 1 ","if li > = BLOCKLEN : 
","if li > BLOCKLEN :
",38.32,40.94,False
"def __manipulate_item ( self , item ) : <TAB> if self . _Cursor__manipulate : <TAB> <TAB> db = self . _Cursor__collection . database <TAB> <TAB> son = db . _fix_outgoing ( item , self . _Cursor__collection ) <TAB> else : <TAB> <TAB> son = item <TAB> if self . __wrap is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return getattr ( self . _Cursor__collection , son [ self . __wrap . type_field ] ) ( son ) <TAB> <TAB> return self . __wrap ( son , collection = self . _Cursor__collection ) <TAB> else : <TAB> <TAB> return son ","if self . __wrap . type_field in son : 
","if isinstance ( son , dict ) :
",26.64,3.89,False
"def apply_transforms ( self ) : <TAB> """"""Apply all of the stored transforms, in priority order."""""" <TAB> self . document . reporter . attach_observer ( self . document . note_transform_message ) <TAB> while self . transforms : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Unsorted initially, and whenever a transform is added. <TAB> <TAB> <TAB> self . transforms . sort ( ) <TAB> <TAB> <TAB> self . transforms . reverse ( ) <TAB> <TAB> <TAB> self . sorted = 1 <TAB> <TAB> priority , transform_class , pending , kwargs = self . transforms . pop ( ) <TAB> <TAB> transform = transform_class ( self . document , startnode = pending ) <TAB> <TAB> transform . apply ( * * kwargs ) <TAB> <TAB> self . applied . append ( ( priority , transform_class , pending , kwargs ) ) ","if not self . sorted : 
","if self . sorted :
",58.31,57.89,False
"def format_sql ( sql , params ) : <TAB> rv = [ ] <TAB> if isinstance ( params , dict ) : <TAB> <TAB> # convert sql with named parameters to sql with unnamed parameters <TAB> <TAB> conv = _FormatConverter ( params ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sql = sql_to_string ( sql ) <TAB> <TAB> <TAB> sql = sql % conv <TAB> <TAB> <TAB> params = conv . params <TAB> <TAB> else : <TAB> <TAB> <TAB> params = ( ) <TAB> for param in params or ( ) : <TAB> <TAB> if param is None : <TAB> <TAB> <TAB> rv . append ( "" NULL "" ) <TAB> <TAB> param = safe_repr ( param ) <TAB> <TAB> rv . append ( param ) <TAB> return sql , rv ","if params : 
","if conv . params :
",34.79,23.64,False
"def on_execution_item ( self , cpath , execution ) : <TAB> if not isinstance ( execution , dict ) : <TAB> <TAB> return <TAB> if "" executor "" in execution and execution . get ( "" executor "" ) != "" jmeter "" : <TAB> <TAB> return <TAB> scenario = execution . get ( "" scenario "" , None ) <TAB> <MASK> <TAB> <TAB> return <TAB> if isinstance ( scenario , str ) : <TAB> <TAB> scenario_name = scenario <TAB> <TAB> scenario = self . get_named_scenario ( scenario_name ) <TAB> <TAB> if not scenario : <TAB> <TAB> <TAB> scenario = None <TAB> <TAB> scenario_path = Path ( "" scenarios "" , scenario_name ) <TAB> else : <TAB> <TAB> scenario_path = cpath . copy ( ) <TAB> <TAB> scenario_path . add_component ( "" scenario "" ) <TAB> if scenario is not None : <TAB> <TAB> self . check_jmeter_scenario ( scenario_path , scenario ) ","if not scenario : 
","if not scenario :
",100.0,100.0,True
"def _poll_ipc_requests ( self ) - > None : <TAB> try : <TAB> <TAB> if self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> return <TAB> <TAB> while not self . _ipc_requests . empty ( ) : <TAB> <TAB> <TAB> args = self . _ipc_requests . get ( ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> for filename in args : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . get_editor_notebook ( ) . show_file ( filename ) <TAB> <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <TAB> logger . exception ( "" Problem processing ipc request "" , exc_info = e ) <TAB> <TAB> self . become_active_window ( ) <TAB> finally : <TAB> <TAB> self . after ( 50 , self . _poll_ipc_requests ) ","if os . path . isfile ( filename ) : 
","if filename . endswith ( "" .ipc "" ) :
",32.17,10.25,False
"def get_scroll_distance_to_element ( driver , element ) : <TAB> try : <TAB> <TAB> scroll_position = driver . execute_script ( "" return window.scrollY; "" ) <TAB> <TAB> element_location = None <TAB> <TAB> element_location = element . location [ "" y "" ] <TAB> <TAB> element_location = element_location - 130 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> element_location = 0 <TAB> <TAB> distance = element_location - scroll_position <TAB> <TAB> return distance <TAB> except Exception : <TAB> <TAB> return 0 ","if element_location < 0 : 
","if element_location < 0 :
",100.0,100.0,True
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_access_token ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_expiration_time ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 16 : 
","if tt == 16 :
",100.0,100.0,True
"def _validate_and_define ( params , key , value ) : <TAB> ( key , force_generic ) = _validate_key ( _unescape ( key ) ) <TAB> if key in params : <TAB> <TAB> raise SyntaxError ( f ' duplicate key  "" { key } "" ' ) <TAB> cls = _class_for_key . get ( key , GenericParam ) <TAB> emptiness = cls . emptiness ( ) <TAB> if value is None : <TAB> <TAB> if emptiness == Emptiness . NEVER : <TAB> <TAB> <TAB> raise SyntaxError ( "" value cannot be empty "" ) <TAB> <TAB> value = cls . from_value ( value ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> value = cls . from_wire_parser ( dns . wire . Parser ( _unescape ( value ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> value = cls . from_value ( value ) <TAB> params [ key ] = value ","if force_generic : 
","if force_generic :
",78.12,100.0,True
"def iter_fields ( node , * , include_meta = True , exclude_unset = False ) : <TAB> exclude_meta = not include_meta <TAB> for field_name , field in node . _fields . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> field_val = getattr ( node , field_name , _marker ) <TAB> <TAB> if field_val is _marker : <TAB> <TAB> <TAB> continue <TAB> <TAB> if exclude_unset : <TAB> <TAB> <TAB> if callable ( field . default ) : <TAB> <TAB> <TAB> <TAB> default = field . default ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> default = field . default <TAB> <TAB> <TAB> if field_val == default : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> yield field_name , field_val ","if exclude_meta and field . meta : 
","if field . meta and exclude_meta :
",41.35,36.56,False
"def tearDown ( self ) : <TAB> """"""Shutdown the server."""""" <TAB> try : <TAB> <TAB> if self . server : <TAB> <TAB> <TAB> self . server . stop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . root_logger . removeHandler ( self . sl_hdlr ) <TAB> <TAB> <TAB> self . sl_hdlr . close ( ) <TAB> finally : <TAB> <TAB> BaseTest . tearDown ( self ) ","if self . sl_hdlr : 
","if self . sl_hdlr :
",100.0,100.0,True
"def _wait_for_async_copy ( self , share_name , file_path ) : <TAB> count = 0 <TAB> share_client = self . fsc . get_share_client ( share_name ) <TAB> file_client = share_client . get_file_client ( file_path ) <TAB> properties = file_client . get_file_properties ( ) <TAB> while properties . copy . status != "" success "" : <TAB> <TAB> count = count + 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . fail ( "" Timed out waiting for async copy to complete. "" ) <TAB> <TAB> self . sleep ( 6 ) <TAB> <TAB> properties = file_client . get_file_properties ( ) <TAB> self . assertEqual ( properties . copy . status , "" success "" ) ","if count > 10 : 
","if count > 10 :
",100.0,100.0,True
"def __new__ ( <TAB> cls , <TAB> message_type : OrderBookMessageType , <TAB> content : Dict [ str , any ] , <TAB> timestamp : Optional [ float ] = None , <TAB> * args , <TAB> * * kwargs , ) : <TAB> if timestamp is None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> "" timestamp must not be None when initializing snapshot messages. "" <TAB> <TAB> <TAB> ) <TAB> <TAB> timestamp = int ( time . time ( ) ) <TAB> return super ( KucoinOrderBookMessage , cls ) . __new__ ( <TAB> <TAB> cls , message_type , content , timestamp = timestamp , * args , * * kwargs <TAB> ) ","if message_type is OrderBookMessageType . SNAPSHOT : 
","if message_type is OrderBookMessageType . SNAPSHOT :
",100.0,100.0,True
"def _drop_unique_features ( <TAB> X : DataFrame , feature_metadata : FeatureMetadata , max_unique_ratio ) - > list : <TAB> features_to_drop = [ ] <TAB> X_len = len ( X ) <TAB> max_unique_value_count = X_len * max_unique_ratio <TAB> for column in X : <TAB> <TAB> unique_value_count = len ( X [ column ] . unique ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> features_to_drop . append ( column ) <TAB> <TAB> elif feature_metadata . get_feature_type_raw ( column ) in [ <TAB> <TAB> <TAB> R_CATEGORY , <TAB> <TAB> <TAB> R_OBJECT , <TAB> <TAB> ] and ( unique_value_count > max_unique_value_count ) : <TAB> <TAB> <TAB> features_to_drop . append ( column ) <TAB> return features_to_drop ","if unique_value_count == 1 : 
","if feature_metadata . get_feature_type_raw ( column ) in [ R_CATEGORY , R_OBJECT , R_OBJECT ] :
",27.18,1.76,False
"def get_src_findex_by_pad ( s , S , padding_mode , align_corners ) : <TAB> if padding_mode == "" zero "" : <TAB> <TAB> return get_src_findex_with_zero_pad ( s , S ) <TAB> elif padding_mode == "" reflect "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return get_src_findex_with_reflect_pad ( s , S , True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sf = get_src_findex_with_reflect_pad ( s , S , False ) <TAB> <TAB> <TAB> return get_src_findex_with_repeat_pad ( sf , S ) <TAB> elif padding_mode == "" repeat "" : <TAB> <TAB> return get_src_findex_with_repeat_pad ( s , S ) ","if align_corners : 
","if align_corners :
",78.12,100.0,True
"def _iterate_self_and_parents ( self , upto = None ) : <TAB> current = self <TAB> result = ( ) <TAB> while current : <TAB> <TAB> result + = ( current , ) <TAB> <TAB> if current . _parent is upto : <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise sa_exc . InvalidRequestError ( <TAB> <TAB> <TAB> <TAB> "" Transaction  %s  is not on the active transaction list "" % ( upto ) <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> current = current . _parent <TAB> return result ","elif current . _parent is None : 
","elif current . _parent is upto :
",62.83,70.71,False
"def __setattr__ ( self , name : str , val : Any ) : <TAB> if name . startswith ( "" COMPUTED_ "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> old_val = self [ name ] <TAB> <TAB> <TAB> if old_val == val : <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> <TAB> raise KeyError ( <TAB> <TAB> <TAB> <TAB> "" Computed attributed  ' {} '  already exists  "" <TAB> <TAB> <TAB> <TAB> "" with a different value! old= {} , new= {} . "" . format ( name , old_val , val ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self [ name ] = val <TAB> else : <TAB> <TAB> super ( ) . __setattr__ ( name , val ) ","if name in self : 
","if name in self :
",100.0,100.0,True
"def get_fnlist ( bbhandler , pkg_pn , preferred ) : <TAB> """"""Get all recipe file names"""""" <TAB> <MASK> <TAB> <TAB> ( latest_versions , preferred_versions ) = bb . providers . findProviders ( <TAB> <TAB> <TAB> bbhandler . config_data , bbhandler . cooker . recipecaches [ "" "" ] , pkg_pn <TAB> <TAB> ) <TAB> fn_list = [ ] <TAB> for pn in sorted ( pkg_pn ) : <TAB> <TAB> if preferred : <TAB> <TAB> <TAB> fn_list . append ( preferred_versions [ pn ] [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fn_list . extend ( pkg_pn [ pn ] ) <TAB> return fn_list ","if preferred : 
","if preferred :
",78.12,0.0,False
"def links_extracted ( self , _ , links ) : <TAB> links_deduped = { } <TAB> for link in links : <TAB> <TAB> link_fingerprint = link . meta [ FIELD_FINGERPRINT ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> links_deduped [ link_fingerprint ] = link <TAB> [ <TAB> <TAB> self . _redis_pipeline . hmset ( fingerprint , self . _create_link_extracted ( link ) ) <TAB> <TAB> for ( fingerprint , link ) in links_deduped . items ( ) <TAB> ] <TAB> self . _redis_pipeline . execute ( ) ","if link_fingerprint in links_deduped : 
","if link_fingerprint in self . _links_deduped :
",36.8,53.11,False
"def __call__ ( self , name , rawtext , text , lineno , inliner , options = None , content = None ) : <TAB> options = options or { } <TAB> content = content or [ ] <TAB> issue_nos = [ each . strip ( ) for each in utils . unescape ( text ) . split ( "" , "" ) ] <TAB> config = inliner . document . settings . env . app . config <TAB> ret = [ ] <TAB> for i , issue_no in enumerate ( issue_nos ) : <TAB> <TAB> node = self . make_node ( name , issue_no , config , options = options ) <TAB> <TAB> ret . append ( node ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> sep = nodes . raw ( text = "" ,  "" , format = "" html "" ) <TAB> <TAB> <TAB> ret . append ( sep ) <TAB> return ret , [ ] ","if i != len ( issue_nos ) - 1 : 
","if i < len ( issue_nos ) - 1 :
",85.49,70.77,False
"def init_messengers ( messengers ) : <TAB> for messenger in messengers : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> module_path = messenger [ "" type "" ] <TAB> <TAB> <TAB> messenger [ "" type "" ] = messenger [ "" type "" ] . split ( "" . "" ) [ - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> module_path = "" oncall.messengers. "" + messenger [ "" type "" ] <TAB> <TAB> instance = getattr ( importlib . import_module ( module_path ) , messenger [ "" type "" ] ) ( <TAB> <TAB> <TAB> messenger <TAB> <TAB> ) <TAB> <TAB> for transport in instance . supports : <TAB> <TAB> <TAB> _active_messengers [ transport ] . append ( instance ) ","if "" . "" in messenger [ "" type "" ] : 
","if "" type "" not in messenger :
",39.74,18.33,False
"def _process_enum_definition ( self , tok ) : <TAB> fields = [ ] <TAB> for field in tok . fields : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> expression = self . expression_parser . parse ( field . expression ) <TAB> <TAB> else : <TAB> <TAB> <TAB> expression = None <TAB> <TAB> fields . append ( c_ast . CEnumField ( name = field . name . first , value = expression ) ) <TAB> name = tok . enum_name <TAB> if name : <TAB> <TAB> name = "" enum  %s "" % tok . enum_name . first <TAB> else : <TAB> <TAB> name = self . _make_anonymous_type ( "" enum "" ) <TAB> return c_ast . CTypeDefinition ( <TAB> <TAB> name = name , <TAB> <TAB> type_definition = c_ast . CEnum ( <TAB> <TAB> <TAB> attributes = tok . attributes , fields = fields , name = name <TAB> <TAB> ) , <TAB> ) ","if field . expression : 
","if field . expression :
",100.0,100.0,True
def result_iterator ( ) : <TAB> try : <TAB> <TAB> # reverse to keep finishing order <TAB> <TAB> fs . reverse ( ) <TAB> <TAB> while fs : <TAB> <TAB> <TAB> # Careful not to keep a reference to the popped future <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> yield fs . pop ( ) . result ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> yield fs . pop ( ) . result ( end_time - time . time ( ) ) <TAB> finally : <TAB> <TAB> for future in fs : <TAB> <TAB> <TAB> future . cancel ( ) ,"if timeout is None : 
","if end_time is None :
",64.58,26.27,False
"def has_encrypted_ssh_key_data ( self ) : <TAB> try : <TAB> <TAB> ssh_key_data = self . get_input ( "" ssh_key_data "" ) <TAB> except AttributeError : <TAB> <TAB> return False <TAB> try : <TAB> <TAB> pem_objects = validate_ssh_private_key ( ssh_key_data ) <TAB> <TAB> for pem_object in pem_objects : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> except ValidationError : <TAB> <TAB> pass <TAB> return False ","if pem_object . get ( "" key_enc "" , False ) : 
","if pem_object . encrypted :
",33.3,17.79,False
"def test_seq_object_transcription_method ( self ) : <TAB> for nucleotide_seq in test_seqs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> <TAB> repr ( Seq . transcribe ( nucleotide_seq ) ) , <TAB> <TAB> <TAB> <TAB> repr ( nucleotide_seq . transcribe ( ) ) , <TAB> <TAB> <TAB> ) ","if isinstance ( nucleotide_seq , Seq . Seq ) : 
","if isinstance ( nucleotide_seq , Seq . Seq ) :
",100.0,100.0,True
"def max_elevation ( self ) : <TAB> max_el = None <TAB> for y in xrange ( self . height ) : <TAB> <TAB> for x in xrange ( self . width ) : <TAB> <TAB> <TAB> el = self . elevation [ "" data "" ] [ y ] [ x ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> max_el = el <TAB> return max_el ","if max_el is None or el > max_el : 
","if max_el is None or el > max_el :
",100.0,100.0,True
"def stress ( mapping , index ) : <TAB> for count in range ( OPERATIONS ) : <TAB> <TAB> function = random . choice ( functions ) <TAB> <TAB> function ( mapping , index ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" \r "" , len ( mapping ) , "" "" * 7 , end = "" "" ) <TAB> print ( ) ","if count % 1000 == 0 : 
","if count % 10000 == 0 :
",63.85,50.0,False
"def sync_terminology ( self ) : <TAB> if self . is_source : <TAB> <TAB> return <TAB> store = self . store <TAB> missing = [ ] <TAB> for source in self . component . get_all_sources ( ) : <TAB> <TAB> if "" terminology "" not in source . all_flags : <TAB> <TAB> <TAB> continue <TAB> <TAB> try : <TAB> <TAB> <TAB> _unit , add = store . find_unit ( source . context , source . source ) <TAB> <TAB> except UnitNotFound : <TAB> <TAB> <TAB> add = True <TAB> <TAB> # Unit is already present <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> missing . append ( ( source . context , source . source , "" "" ) ) <TAB> if missing : <TAB> <TAB> self . add_units ( None , missing ) ","if not add : 
","if add :
",34.18,0.0,False
"def get_generators ( self ) : <TAB> """"""Get a dict with all registered generators, indexed by name"""""" <TAB> generators = { } <TAB> for core in self . db . find ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _generators = core . get_generators ( { } ) <TAB> <TAB> <TAB> if _generators : <TAB> <TAB> <TAB> <TAB> generators [ str ( core . name ) ] = _generators <TAB> return generators ","if hasattr ( core , "" get_generators "" ) : 
","if hasattr ( core , "" get_generators "" ) :
",100.0,100.0,True
"def act ( self , state ) : <TAB> if self . body . env . clock . frame < self . training_start_step : <TAB> <TAB> return policy_util . random ( state , self , self . body ) . cpu ( ) . squeeze ( ) . numpy ( ) <TAB> else : <TAB> <TAB> action = self . action_policy ( state , self , self . body ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> action = self . scale_action ( torch . tanh ( action ) )<TAB> # continuous action bound <TAB> <TAB> return action . cpu ( ) . squeeze ( ) . numpy ( ) ","if not self . body . is_discrete : 
","if self . body . env . clock . frame < self . training_start_step :
",48.69,14.58,False
"def try_open_completions_event ( self , event = None ) : <TAB> "" (./) Open completion list after pause with no movement. "" <TAB> lastchar = self . text . get ( "" insert-1c "" ) <TAB> if lastchar in TRIGGERS : <TAB> <TAB> args = TRY_A if lastchar == "" . "" else TRY_F <TAB> <TAB> self . _delayed_completion_index = self . text . index ( "" insert "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . text . after_cancel ( self . _delayed_completion_id ) <TAB> <TAB> self . _delayed_completion_id = self . text . after ( <TAB> <TAB> <TAB> self . popupwait , self . _delayed_open_completions , args <TAB> <TAB> ) ","if self . _delayed_completion_id is not None : 
","if self . _delayed_completion_id :
",47.74,66.94,False
"def token_is_available ( self ) : <TAB> if self . token : <TAB> <TAB> try : <TAB> <TAB> <TAB> resp = requests . get ( <TAB> <TAB> <TAB> <TAB> "" https://api.shodan.io/account/profile?key= {0} "" . format ( self . token ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> except Exception as ex : <TAB> <TAB> <TAB> logger . error ( str ( ex ) ) <TAB> return False ","if resp and resp . status_code == 200 and "" member "" in resp . json ( ) : 
","if resp and resp . status_code == 200 and "" user_id "" in resp . json ( ) :
",92.6,79.48,False
"def next_bar_ ( self , event ) : <TAB> bars = event . bar_dict <TAB> self . _current_minute = self . _minutes_since_midnight ( <TAB> <TAB> self . ucontext . now . hour , self . ucontext . now . minute <TAB> ) <TAB> for day_rule , time_rule , func in self . _registry : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with ExecutionContext ( EXECUTION_PHASE . SCHEDULED ) : <TAB> <TAB> <TAB> <TAB> with ModifyExceptionFromType ( EXC_TYPE . USER_EXC ) : <TAB> <TAB> <TAB> <TAB> <TAB> func ( self . ucontext , bars ) <TAB> self . _last_minute = self . _current_minute ","if day_rule ( ) and time_rule ( ) : 
","if day_rule ( self . ucontext , bars ) and time_rule ( self . ucontext ) :
",42.8,42.19,False
"def decoder ( s ) : <TAB> r = [ ] <TAB> decode = [ ] <TAB> for c in s : <TAB> <TAB> if c == "" & "" and not decode : <TAB> <TAB> <TAB> decode . append ( "" & "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if len ( decode ) == 1 : <TAB> <TAB> <TAB> <TAB> r . append ( "" & "" ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> <TAB> <TAB> decode = [ ] <TAB> <TAB> elif decode : <TAB> <TAB> <TAB> decode . append ( c ) <TAB> <TAB> else : <TAB> <TAB> <TAB> r . append ( c ) <TAB> if decode : <TAB> <TAB> r . append ( modified_unbase64 ( "" "" . join ( decode [ 1 : ] ) ) ) <TAB> bin_str = "" "" . join ( r ) <TAB> return ( bin_str , len ( s ) ) ","elif c == "" - "" and decode : 
","elif c == "" - "" and not decode :
",75.26,74.19,False
"def admin_audit_get ( admin_id ) : <TAB> if settings . app . demo_mode : <TAB> <TAB> resp = utils . demo_get_cache ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return utils . jsonify ( resp ) <TAB> if not flask . g . administrator . super_user : <TAB> <TAB> return utils . jsonify ( <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> "" error "" : REQUIRES_SUPER_USER , <TAB> <TAB> <TAB> <TAB> "" error_msg "" : REQUIRES_SUPER_USER_MSG , <TAB> <TAB> <TAB> } , <TAB> <TAB> <TAB> 400 , <TAB> <TAB> ) <TAB> admin = auth . get_by_id ( admin_id ) <TAB> resp = admin . get_audit_events ( ) <TAB> if settings . app . demo_mode : <TAB> <TAB> utils . demo_set_cache ( resp ) <TAB> return utils . jsonify ( resp ) ","if resp : 
","if not isinstance ( resp , dict ) :
",29.53,6.27,False
"def vjp ( self , argnum , outgrad , ans , vs , gvs , args , kwargs ) : <TAB> try : <TAB> <TAB> return self . vjps [ argnum ] ( outgrad , ans , vs , gvs , * args , * * kwargs ) <TAB> except KeyError : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errstr = "" Gradient of  {0}  not yet implemented. "" <TAB> <TAB> else : <TAB> <TAB> <TAB> errstr = "" Gradient of  {0}  w.r.t. arg number  {1}  not yet implemented. "" <TAB> <TAB> raise NotImplementedError ( errstr . format ( self . fun . __name__ , argnum ) ) ","if self . vjps == { } : 
","if self . fun == "" gradient "" :
",37.46,20.56,False
"def update ( self , * args , * * kwargs ) : <TAB> assert not self . readonly <TAB> longest_key = 0 <TAB> _dict = self . _dict <TAB> reverse = self . reverse <TAB> casereverse = self . casereverse <TAB> for iterable in args + ( kwargs , ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> iterable = iterable . items ( ) <TAB> <TAB> for key , value in iterable : <TAB> <TAB> <TAB> longest_key = max ( longest_key , len ( key ) ) <TAB> <TAB> <TAB> _dict [ key ] = value <TAB> <TAB> <TAB> reverse [ value ] . append ( key ) <TAB> <TAB> <TAB> casereverse [ value . lower ( ) ] [ value ] + = 1 <TAB> self . _longest_key = max ( self . _longest_key , longest_key ) ","if isinstance ( iterable , ( dict , StenoDictionary ) ) : 
","if isinstance ( iterable , dict ) :
",44.03,37.29,False
"def update_ui ( self , window ) : <TAB> view = window . get_active_view ( ) <TAB> self . set_status ( view ) <TAB> lang = "" plain_text "" <TAB> if view : <TAB> <TAB> buf = view . get_buffer ( ) <TAB> <TAB> language = buf . get_language ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lang = language . get_id ( ) <TAB> <TAB> self . setup_smart_indent ( view , lang ) ","if language : 
","if language :
",78.12,0.0,False
"def number_operators ( self , a , b , skip = [ ] ) : <TAB> dict = { "" a "" : a , "" b "" : b } <TAB> for name , expr in self . binops . items ( ) : <TAB> <TAB> if name not in skip : <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . binop_test ( a , b , res , expr , name ) <TAB> for name , expr in self . unops . items ( ) : <TAB> <TAB> if name not in skip : <TAB> <TAB> <TAB> name = "" __ %s __ "" % name <TAB> <TAB> <TAB> if hasattr ( a , name ) : <TAB> <TAB> <TAB> <TAB> res = eval ( expr , dict ) <TAB> <TAB> <TAB> <TAB> self . unop_test ( a , res , expr , name ) ","if hasattr ( a , name ) : 
","if hasattr ( a , name ) :
",100.0,100.0,True
"def _getItemHeight ( self , item , ctrl = None ) : <TAB> """"""Returns the full height of the item to be inserted in the form"""""" <TAB> if type ( ctrl ) == psychopy . visual . TextBox2 : <TAB> <TAB> return ctrl . size [ 1 ] <TAB> if type ( ctrl ) == psychopy . visual . Slider : <TAB> <TAB> # Set radio button layout <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 0.03 + ctrl . labelHeight * 3 <TAB> <TAB> elif item [ "" layout "" ] == "" vert "" : <TAB> <TAB> <TAB> # for vertical take into account the nOptions <TAB> <TAB> <TAB> return ctrl . labelHeight * len ( item [ "" options "" ] ) ","if item [ "" layout "" ] == "" horiz "" : 
","if item [ "" layout "" ] == "" button "" :
",88.57,79.11,False
"def test_cleanup_params ( self , body , rpc_mock ) : <TAB> res = self . _get_resp_post ( body ) <TAB> self . assertEqual ( http_client . ACCEPTED , res . status_code ) <TAB> rpc_mock . assert_called_once_with ( self . context , mock . ANY ) <TAB> cleanup_request = rpc_mock . call_args [ 0 ] [ 1 ] <TAB> for key , value in body . items ( ) : <TAB> <TAB> if key in ( "" disabled "" , "" is_up "" ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> value = value == "" true "" <TAB> <TAB> self . assertEqual ( value , getattr ( cleanup_request , key ) ) <TAB> self . assertEqual ( self . _expected_services ( * SERVICES ) , res . json ) ","if value is not None : 
","if key == "" is_up "" :
",27.14,5.52,False
"def _read_json_content ( self , body_is_optional = False ) : <TAB> if "" content-length "" not in self . headers : <TAB> <TAB> return self . send_error ( 411 ) if not body_is_optional else { } <TAB> try : <TAB> <TAB> content_length = int ( self . headers . get ( "" content-length "" ) ) <TAB> <TAB> if content_length == 0 and body_is_optional : <TAB> <TAB> <TAB> return { } <TAB> <TAB> request = json . loads ( self . rfile . read ( content_length ) . decode ( "" utf-8 "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return request <TAB> except Exception : <TAB> <TAB> logger . exception ( "" Bad request "" ) <TAB> self . send_error ( 400 ) ","if isinstance ( request , dict ) and ( request or body_is_optional ) : 
","if request [ "" type "" ] == "" application/json "" and body_is_optional :
",26.11,19.69,False
"def env_purge_doc ( app : Sphinx , env : BuildEnvironment , docname : str ) - > None : <TAB> modules = getattr ( env , "" _viewcode_modules "" , { } ) <TAB> for modname , entry in list ( modules . items ( ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> code , tags , used , refname = entry <TAB> <TAB> for fullname in list ( used ) : <TAB> <TAB> <TAB> if used [ fullname ] == docname : <TAB> <TAB> <TAB> <TAB> used . pop ( fullname ) <TAB> <TAB> if len ( used ) == 0 : <TAB> <TAB> <TAB> modules . pop ( modname ) ","if entry is False : 
","if not entry :
",28.67,16.37,False
"def frames ( self ) : <TAB> """"""an array of all the frames (including iframes) in the current window"""""" <TAB> from thug . DOM . W3C . HTML . HTMLCollection import HTMLCollection <TAB> frames = set ( ) <TAB> for frame in self . _findAll ( [ "" frame "" , "" iframe "" ] ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> from thug . DOM . W3C . Core . DOMImplementation import DOMImplementation <TAB> <TAB> <TAB> DOMImplementation . createHTMLElement ( self . window . doc , frame ) <TAB> <TAB> frames . add ( frame . _node ) <TAB> return HTMLCollection ( self . doc , list ( frames ) ) ","if not getattr ( frame , "" _node "" , None ) : 
","if frame . _node is None :
",26.15,6.87,False
"def check ( self , * * kw ) : <TAB> if not kw : <TAB> <TAB> return exists ( self . strpath ) <TAB> if len ( kw ) == 1 : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return not kw [ "" dir "" ] ^ isdir ( self . strpath ) <TAB> <TAB> if "" file "" in kw : <TAB> <TAB> <TAB> return not kw [ "" file "" ] ^ isfile ( self . strpath ) <TAB> return super ( LocalPath , self ) . check ( * * kw ) ","if "" dir "" in kw : 
","if "" dir "" in kw :
",100.0,100.0,True
"def __init__ ( self , folders ) : <TAB> self . folders = folders <TAB> self . duplicates = { } <TAB> for folder , path in folders . items ( ) : <TAB> <TAB> duplicates = [ ] <TAB> <TAB> for other_folder , other_path in folders . items ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> if other_path == path : <TAB> <TAB> <TAB> <TAB> duplicates . append ( other_folder ) <TAB> <TAB> if len ( duplicates ) : <TAB> <TAB> <TAB> self . duplicates [ folder ] = duplicates ","if other_folder == folder : 
","if other_folder == folder :
",100.0,100.0,True
"def next ( self , buf , pos ) : <TAB> if pos > = len ( buf ) : <TAB> <TAB> return EOF , "" "" , pos <TAB> mo = self . tokens_re . match ( buf , pos ) <TAB> if mo : <TAB> <TAB> text = mo . group ( ) <TAB> <TAB> type , regexp , test_lit = self . tokens [ mo . lastindex - 1 ] <TAB> <TAB> pos = mo . end ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> type = self . literals . get ( text , type ) <TAB> <TAB> return type , text , pos <TAB> else : <TAB> <TAB> c = buf [ pos ] <TAB> <TAB> return self . symbols . get ( c , None ) , c , pos + 1 ","if test_lit : 
","if test_lit :
",78.12,100.0,True
"def step ( self , action ) : <TAB> """"""Repeat action, sum reward, and max over last observations."""""" <TAB> total_reward = 0.0 <TAB> done = None <TAB> for i in range ( self . _skip ) : <TAB> <TAB> obs , reward , done , info = self . env . step ( action ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _obs_buffer [ 0 ] = obs <TAB> <TAB> if i == self . _skip - 1 : <TAB> <TAB> <TAB> self . _obs_buffer [ 1 ] = obs <TAB> <TAB> total_reward + = reward <TAB> <TAB> if done : <TAB> <TAB> <TAB> break <TAB> # Note that the observation on the done=True frame <TAB> # doesn't matter <TAB> max_frame = self . _obs_buffer . max ( axis = 0 ) <TAB> return max_frame , total_reward , done , info ","if i == self . _skip - 2 : 
","if i == self . _skip - 2 :
",100.0,100.0,True
"def convert ( self , ctx , argument ) : <TAB> arg = argument . replace ( "" 0x "" , "" "" ) . lower ( ) <TAB> if arg [ 0 ] == "" # "" : <TAB> <TAB> arg = arg [ 1 : ] <TAB> try : <TAB> <TAB> value = int ( arg , base = 16 ) <TAB> <TAB> if not ( 0 < = value < = 0xFFFFFF ) : <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return discord . Colour ( value = value ) <TAB> except ValueError : <TAB> <TAB> arg = arg . replace ( "" "" , "" _ "" ) <TAB> <TAB> method = getattr ( discord . Colour , arg , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise BadColourArgument ( arg ) <TAB> <TAB> return method ( ) ","if arg . startswith ( "" from_ "" ) or method is None or not inspect . ismethod ( method ) : 
","if method is None :
",28.55,1.23,False
"def run ( self , * * inputs ) : <TAB> if self . inputs . copy_inputs : <TAB> <TAB> self . inputs . subjects_dir = os . getcwd ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> inputs [ "" subjects_dir "" ] = self . inputs . subjects_dir <TAB> <TAB> for originalfile in [ self . inputs . in_file , self . inputs . in_norm ] : <TAB> <TAB> <TAB> copy2subjdir ( self , originalfile , folder = "" mri "" ) <TAB> return super ( SegmentCC , self ) . run ( * * inputs ) ","if "" subjects_dir "" in inputs : 
","if self . inputs . subjects_dir != "" "" :
",33.29,14.69,False
"def get_queryset ( self ) : <TAB> if not hasattr ( self , "" _queryset "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> qs = self . queryset <TAB> <TAB> else : <TAB> <TAB> <TAB> qs = self . model . _default_manager . get_queryset ( ) <TAB> <TAB> # If the queryset isn't already ordered we need to add an <TAB> <TAB> # artificial ordering here to make sure that all formsets <TAB> <TAB> # constructed from this queryset have the same form order. <TAB> <TAB> if not qs . ordered : <TAB> <TAB> <TAB> qs = qs . order_by ( self . model . _meta . pk . name ) <TAB> <TAB> # Removed queryset limiting here. As per discussion re: #13023 <TAB> <TAB> # on django-dev, max_num should not prevent existing <TAB> <TAB> # related objects/inlines from being displayed. <TAB> <TAB> self . _queryset = qs <TAB> return self . _queryset ","if self . queryset is not None : 
","if self . queryset is not None :
",100.0,100.0,True
"def visit_simple_stmt ( self , node : Node ) - > Iterator [ Line ] : <TAB> """"""Visit a statement without nested statements."""""" <TAB> is_suite_like = node . parent and node . parent . type in STATEMENT <TAB> if is_suite_like : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield from self . visit_default ( node ) <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from self . line ( + 1 ) <TAB> <TAB> <TAB> yield from self . visit_default ( node ) <TAB> <TAB> <TAB> yield from self . line ( - 1 ) <TAB> else : <TAB> <TAB> if not self . is_pyi or not node . parent or not is_stub_suite ( node . parent ) : <TAB> <TAB> <TAB> yield from self . line ( ) <TAB> <TAB> yield from self . visit_default ( node ) ","if self . is_pyi and is_stub_body ( node ) : 
","if self . is_pyi or not is_stub_suite ( node . parent ) :
",44.18,43.59,False
"def rawDataReceived ( self , data ) : <TAB> if self . timeout > 0 : <TAB> <TAB> self . resetTimeout ( ) <TAB> self . _pendingSize - = len ( data ) <TAB> if self . _pendingSize > 0 : <TAB> <TAB> self . _pendingBuffer . write ( data ) <TAB> else : <TAB> <TAB> passon = b "" "" <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> data , passon = data [ : self . _pendingSize ] , data [ self . _pendingSize : ] <TAB> <TAB> self . _pendingBuffer . write ( data ) <TAB> <TAB> rest = self . _pendingBuffer <TAB> <TAB> self . _pendingBuffer = None <TAB> <TAB> self . _pendingSize = None <TAB> <TAB> rest . seek ( 0 , 0 ) <TAB> <TAB> self . _parts . append ( rest . read ( ) ) <TAB> <TAB> self . setLineMode ( passon . lstrip ( b "" \r \n "" ) ) ","if self . _pendingSize < 0 : 
","if len ( data ) > self . _pendingSize :
",39.02,25.97,False
"def handle ( self , * args , * * options ) : <TAB> app_name = options . get ( "" app_name "" ) <TAB> job_name = options . get ( "" job_name "" ) <TAB> # hack since we are using job_name nargs='?' for -l to work <TAB> if app_name and not job_name : <TAB> <TAB> job_name = app_name <TAB> <TAB> app_name = None <TAB> if options . get ( "" list_jobs "" ) : <TAB> <TAB> print_jobs ( only_scheduled = False , show_when = True , show_appname = True ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( "" Run a single maintenance job. Please specify the name of the job. "" ) <TAB> <TAB> <TAB> return <TAB> <TAB> self . runjob ( app_name , job_name , options ) ","if not job_name : 
","if not job_name :
",100.0,100.0,True
"def _exportReceived ( self , content , error = False , server = None , context = { } , * * kwargs ) : <TAB> if error : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . error . emit ( content [ "" message "" ] , True ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . error . emit ( "" Can ' t export the project from the server "" , True ) <TAB> <TAB> self . finished . emit ( ) <TAB> <TAB> return <TAB> self . finished . emit ( ) ","if content : 
","if content and content [ "" message "" ] :
",32.88,9.29,False
"def __iter__ ( self ) : <TAB> n = self . n <TAB> k = self . k <TAB> j = int ( np . ceil ( n / k ) ) <TAB> for i in range ( k ) : <TAB> <TAB> test_index = np . zeros ( n , dtype = bool ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> test_index [ i * j : ( i + 1 ) * j ] = True <TAB> <TAB> else : <TAB> <TAB> <TAB> test_index [ i * j : ] = True <TAB> <TAB> train_index = np . logical_not ( test_index ) <TAB> <TAB> yield train_index , test_index ","if i < k - 1 : 
","if i * j < n :
",29.28,15.62,False
"def addType ( self , graphene_type ) : <TAB> meta = get_meta ( graphene_type ) <TAB> if meta : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _typeMap [ meta . name ] = graphene_type <TAB> <TAB> else : <TAB> <TAB> <TAB> raise Exception ( <TAB> <TAB> <TAB> <TAB> "" Type  {typeName}  already exists in the registry. "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> typeName = meta . name <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> else : <TAB> <TAB> raise Exception ( "" Cannot add unnamed type or a non-type to registry. "" ) ","if not graphene_type in self . _typeMap : 
","if meta . name in self . _typeMap :
",54.97,48.62,False
"def test_len ( self ) : <TAB> eq = self . assertEqual <TAB> eq ( base64MIME . base64_len ( "" hello "" ) , len ( base64MIME . encode ( "" hello "" , eol = "" "" ) ) ) <TAB> for size in range ( 15 ) : <TAB> <TAB> if size == 0 : <TAB> <TAB> <TAB> bsize = 0 <TAB> <TAB> elif size < = 3 : <TAB> <TAB> <TAB> bsize = 4 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> bsize = 8 <TAB> <TAB> elif size < = 9 : <TAB> <TAB> <TAB> bsize = 12 <TAB> <TAB> elif size < = 12 : <TAB> <TAB> <TAB> bsize = 16 <TAB> <TAB> else : <TAB> <TAB> <TAB> bsize = 20 <TAB> <TAB> eq ( base64MIME . base64_len ( "" x "" * size ) , bsize ) ","elif size < = 6 : 
","elif size < = 6 :
",100.0,100.0,True
"def _asStringList ( self , sep = "" "" ) : <TAB> out = [ ] <TAB> for item in self . _toklist : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> out . append ( sep ) <TAB> <TAB> if isinstance ( item , ParseResults ) : <TAB> <TAB> <TAB> out + = item . _asStringList ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> out . append ( str ( item ) ) <TAB> return out ","if out and sep : 
","if out and sep :
",100.0,100.0,True
"def open_file_input ( cli_parsed ) : <TAB> files = glob . glob ( os . path . join ( cli_parsed . d , "" *report.html "" ) ) <TAB> if len ( files ) > 0 : <TAB> <TAB> print ( "" \n [*] Done! Report written in the  "" + cli_parsed . d + ""  folder! "" ) <TAB> <TAB> print ( "" Would you like to open the report now? [Y/n] "" ) <TAB> <TAB> while True : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> response = input ( ) . lower ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> return strtobool ( response ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> print ( "" Please respond with y or n "" ) <TAB> else : <TAB> <TAB> print ( "" [*] No report files found to open, perhaps no hosts were successful "" ) <TAB> <TAB> return False ","if response == "" "" : 
","if response == "" y "" :
",77.33,59.46,False
"def init_values ( self ) : <TAB> config = self . _raw_config <TAB> for valname , value in self . overrides . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> realvalname , key = valname . split ( "" . "" , 1 ) <TAB> <TAB> <TAB> config . setdefault ( realvalname , { } ) [ key ] = value <TAB> <TAB> else : <TAB> <TAB> <TAB> config [ valname ] = value <TAB> for name in config : <TAB> <TAB> if name in self . values : <TAB> <TAB> <TAB> self . __dict__ [ name ] = config [ name ] <TAB> del self . _raw_config ","if "" . "" in valname : 
","if "" . "" in valname :
",100.0,100.0,True
"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB> <TAB> try : <TAB> <TAB> <TAB> result_list . append ( f . get_result ( ) ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> exc_info = sys . exc_info ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> if not isinstance ( e , self . quiet_exceptions ) : <TAB> <TAB> <TAB> <TAB> <TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB> <TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB> <TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB> <TAB> return list ( result_list ) ","if exc_info is None : 
","if exc_info is None :
",100.0,100.0,True
"def test01e_json ( self ) : <TAB> "" Testing GeoJSON input/output. "" <TAB> if not GEOJSON : <TAB> <TAB> return <TAB> for g in self . geometries . json_geoms : <TAB> <TAB> geom = OGRGeometry ( g . wkt ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( g . json , geom . json ) <TAB> <TAB> <TAB> self . assertEqual ( g . json , geom . geojson ) <TAB> <TAB> self . assertEqual ( OGRGeometry ( g . wkt ) , OGRGeometry ( geom . json ) ) ","if not hasattr ( g , "" not_equal "" ) : 
","if not g . is_valid :
",27.48,7.43,False
"def __init__ ( self , hub = None ) :<TAB> # pylint: disable=unused-argument <TAB> if resolver . _resolver is None : <TAB> <TAB> _resolver = resolver . _resolver = _DualResolver ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _resolver . network_resolver . nameservers [ : ] = config . resolver_nameservers <TAB> <TAB> if config . resolver_timeout : <TAB> <TAB> <TAB> _resolver . network_resolver . lifetime = config . resolver_timeout <TAB> # Different hubs in different threads could be sharing the same <TAB> # resolver. <TAB> assert isinstance ( resolver . _resolver , _DualResolver ) <TAB> self . _resolver = resolver . _resolver ","if config . resolver_nameservers : 
","if config . resolver_nameservers :
",100.0,100.0,True
"def __iadd__ ( self , term ) : <TAB> if isinstance ( term , ( int , long ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _gmp . mpz_add_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( term ) ) <TAB> <TAB> <TAB> return self <TAB> <TAB> if - 65535 < term < 0 : <TAB> <TAB> <TAB> _gmp . mpz_sub_ui ( self . _mpz_p , self . _mpz_p , c_ulong ( - term ) ) <TAB> <TAB> <TAB> return self <TAB> <TAB> term = Integer ( term ) <TAB> _gmp . mpz_add ( self . _mpz_p , self . _mpz_p , term . _mpz_p ) <TAB> return self ","if 0 < = term < 65536 : 
","if 0 < = term < 65536 :
",100.0,100.0,True
"def copy ( dst , src ) : <TAB> for ( k , v ) in src . iteritems ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d = { } <TAB> <TAB> <TAB> dst [ k ] = d <TAB> <TAB> <TAB> copy ( d , v ) <TAB> <TAB> else : <TAB> <TAB> <TAB> dst [ k ] = v ","if isinstance ( v , dict ) : 
","if isinstance ( v , dict ) :
",100.0,100.0,True
"def generator ( self , data ) : <TAB> self . procs = OrderedDict ( ) <TAB> for task in data : <TAB> <TAB> self . recurse_task ( task , 0 , 0 , self . procs ) <TAB> for offset , name , level , pid , ppid , uid , euid , gid in self . procs . values ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( <TAB> <TAB> <TAB> <TAB> 0 , <TAB> <TAB> <TAB> <TAB> [ <TAB> <TAB> <TAB> <TAB> <TAB> Address ( offset ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( name ) , <TAB> <TAB> <TAB> <TAB> <TAB> str ( level ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( pid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( ppid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( uid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( gid ) , <TAB> <TAB> <TAB> <TAB> <TAB> int ( euid ) , <TAB> <TAB> <TAB> <TAB> ] , <TAB> <TAB> <TAB> ) ","if offset : 
","if offset :
",78.12,0.0,False
"def apply ( self , db , person ) : <TAB> families = person . get_parent_family_handle_list ( ) <TAB> if families == [ ] : <TAB> <TAB> return True <TAB> for family_handle in person . get_parent_family_handle_list ( ) : <TAB> <TAB> family = db . get_family_from_handle ( family_handle ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> father_handle = family . get_father_handle ( ) <TAB> <TAB> <TAB> mother_handle = family . get_mother_handle ( ) <TAB> <TAB> <TAB> if not father_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> if not mother_handle : <TAB> <TAB> <TAB> <TAB> return True <TAB> return False ","if family : 
","if family :
",78.12,0.0,False
"def _arctic_task_exec ( request ) : <TAB> request . start_time = time . time ( ) <TAB> logging . debug ( <TAB> <TAB> "" Executing asynchronous request for  {} / {} "" . format ( <TAB> <TAB> <TAB> request . library , request . symbol <TAB> <TAB> ) <TAB> ) <TAB> result = None <TAB> try : <TAB> <TAB> request . is_running = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = mongo_retry ( request . fun ) ( * request . args , * * request . kwargs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = request . fun ( * request . args , * * request . kwargs ) <TAB> except Exception as e : <TAB> <TAB> request . exception = e <TAB> finally : <TAB> <TAB> request . data = result <TAB> <TAB> request . end_time = time . time ( ) <TAB> <TAB> request . is_running = False <TAB> return result ","if request . mongo_retry : 
","if request . retry_on_success :
",64.48,21.11,False
"def _setup_styles ( self ) : <TAB> for ttype , ndef in self . style : <TAB> <TAB> escape = EscapeSequence ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> escape . fg = self . _color_index ( ndef [ "" color "" ] ) <TAB> <TAB> if ndef [ "" bgcolor "" ] : <TAB> <TAB> <TAB> escape . bg = self . _color_index ( ndef [ "" bgcolor "" ] ) <TAB> <TAB> if self . usebold and ndef [ "" bold "" ] : <TAB> <TAB> <TAB> escape . bold = True <TAB> <TAB> if self . useunderline and ndef [ "" underline "" ] : <TAB> <TAB> <TAB> escape . underline = True <TAB> <TAB> self . style_string [ str ( ttype ) ] = ( escape . color_string ( ) , escape . reset_string ( ) ) ","if ndef [ "" color "" ] : 
","if ndef [ "" color "" ] :
",100.0,100.0,True
"def process_string ( self , remove_repetitions , sequence ) : <TAB> string = "" "" <TAB> for i , char in enumerate ( sequence ) : <TAB> <TAB> if char != self . int_to_char [ self . blank_index ] : <TAB> <TAB> <TAB> # if this char is a repetition and remove_repetitions=true, <TAB> <TAB> <TAB> # skip. <TAB> <TAB> <TAB> if remove_repetitions and i != 0 and char == sequence [ i - 1 ] : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> string + = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> string = string + char <TAB> return string ","elif char == self . labels [ self . space_index ] : 
","elif char == self . char_to_char [ self . blank_index ] :
",73.44,44.48,False
"def arith_expr ( self , nodelist ) : <TAB> node = self . com_node ( nodelist [ 0 ] ) <TAB> for i in range ( 2 , len ( nodelist ) , 2 ) : <TAB> <TAB> right = self . com_node ( nodelist [ i ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> node = Add ( node , right , lineno = nodelist [ 1 ] . context ) <TAB> <TAB> elif nodelist [ i - 1 ] . type == token . MINUS : <TAB> <TAB> <TAB> node = Sub ( node , right , lineno = nodelist [ 1 ] . context ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ValueError ( "" unexpected token:  %s "" % nodelist [ i - 1 ] [ 0 ] ) <TAB> return node ","if nodelist [ i - 1 ] . type == token . PLUS : 
","if nodelist [ i - 1 ] . type == token . COMMA :
",92.92,86.66,False
"def invert_index ( cls , index , length ) : <TAB> if np . isscalar ( index ) : <TAB> <TAB> return length - index <TAB> elif isinstance ( index , slice ) : <TAB> <TAB> start , stop = index . start , index . stop <TAB> <TAB> new_start , new_stop = None , None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_stop = length - start <TAB> <TAB> if stop is not None : <TAB> <TAB> <TAB> new_start = length - stop <TAB> <TAB> return slice ( new_start - 1 , new_stop - 1 ) <TAB> elif isinstance ( index , Iterable ) : <TAB> <TAB> new_index = [ ] <TAB> <TAB> for ind in index : <TAB> <TAB> <TAB> new_index . append ( length - ind ) <TAB> return new_index ","if start is not None : 
","if start is not None :
",100.0,100.0,True
"def getRoots ( job ) : <TAB> if job not in visited : <TAB> <TAB> visited . add ( job ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> list ( map ( lambda p : getRoots ( p ) , job . _directPredecessors ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> roots . add ( job ) <TAB> <TAB> # The following call ensures we explore all successor edges. <TAB> <TAB> list ( map ( lambda c : getRoots ( c ) , job . _children + job . _followOns ) ) ","if len ( job . _directPredecessors ) > 0 : 
","if job . _directPredecessors :
",35.1,24.44,False
"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB> <TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB> <TAB> <TAB> if current is not None : <TAB> <TAB> <TAB> <TAB> collected . append ( current ) <TAB> return collected ","if self . _is_true ( self . visit ( comparator_node , element ) ) : 
","if comparator_node == element :
",25.78,5.45,False
"def func ( x , y ) : <TAB> try : <TAB> <TAB> if x > y : <TAB> <TAB> <TAB> z = x + 2 * math . sin ( y ) <TAB> <TAB> <TAB> return z * * 2 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return 4 <TAB> <TAB> else : <TAB> <TAB> <TAB> return 2 * * 3 <TAB> except ValueError : <TAB> <TAB> foo = 0 <TAB> <TAB> for i in range ( 4 ) : <TAB> <TAB> <TAB> foo + = i <TAB> <TAB> return foo <TAB> except TypeError : <TAB> <TAB> return 42 <TAB> else : <TAB> <TAB> return 33 <TAB> finally : <TAB> <TAB> print ( "" finished "" ) ","elif x == y : 
","elif x == y :
",100.0,100.0,True
"def set_filter ( self , dataset_opt ) : <TAB> """"""This function create and set the pre_filter to the obj as attributes"""""" <TAB> self . pre_filter = None <TAB> for key_name in dataset_opt . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> new_name = key_name . replace ( "" filters "" , "" filter "" ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> filt = instantiate_filters ( getattr ( dataset_opt , key_name ) ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> log . exception ( <TAB> <TAB> <TAB> <TAB> <TAB> "" Error trying to create  {} ,  {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> new_name , getattr ( dataset_opt , key_name ) <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> setattr ( self , new_name , filt ) ","if "" filter "" in key_name : 
","if key_name . startswith ( "" filters "" ) :
",33.22,15.58,False
"def _add_states_to_lookup ( <TAB> self , trackers_as_states , trackers_as_actions , domain , online = False ) : <TAB> """"""Add states to lookup dict"""""" <TAB> for states in trackers_as_states : <TAB> <TAB> active_form = self . _get_active_form_name ( states [ - 1 ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # modify the states <TAB> <TAB> <TAB> states = self . _modified_states ( states ) <TAB> <TAB> <TAB> feature_key = self . _create_feature_key ( states ) <TAB> <TAB> <TAB> # even if there are two identical feature keys <TAB> <TAB> <TAB> # their form will be the same <TAB> <TAB> <TAB> # because of `active_form_...` feature <TAB> <TAB> <TAB> self . lookup [ feature_key ] = active_form ","if active_form and self . _prev_action_listen_in_state ( states [ - 1 ] ) : 
","if active_form and active_form not in self . modified_states :
",33.0,17.17,False
"def list_loaded_payloads ( self ) : <TAB> print ( helpers . color ( "" \n  [*] Available Payloads: \n "" ) ) <TAB> lastBase = None <TAB> x = 1 <TAB> for name in sorted ( self . active_payloads . keys ( ) ) : <TAB> <TAB> parts = name . split ( "" / "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( ) <TAB> <TAB> lastBase = parts [ 0 ] <TAB> <TAB> print ( "" \t %s ) \t %s "" % ( x , "" {0: <24} "" . format ( name ) ) ) <TAB> <TAB> x + = 1 <TAB> print ( "" \n "" ) <TAB> return ","if lastBase and parts [ 0 ] != lastBase : 
","if lastBase and parts [ 0 ] != lastBase :
",100.0,100.0,True
"def reprSmart ( vw , item ) : <TAB> ptype = type ( item ) <TAB> if ptype is int : <TAB> <TAB> if - 1024 < item < 1024 : <TAB> <TAB> <TAB> return str ( item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return vw . reprPointer ( item ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return hex ( item ) <TAB> elif ptype in ( list , tuple ) : <TAB> <TAB> return reprComplex ( vw , item )<TAB> # recurse <TAB> elif ptype is dict : <TAB> <TAB> return "" { %s } "" % "" , "" . join ( <TAB> <TAB> <TAB> [ "" %s : %s "" % ( reprSmart ( vw , k ) , reprSmart ( vw , v ) ) for k , v in item . items ( ) ] <TAB> <TAB> ) <TAB> else : <TAB> <TAB> return repr ( item ) ","elif vw . isValidPointer ( item ) : 
","elif 0 < = item < = 255 :
",26.81,6.27,False
"def ConfigSectionMap ( section ) : <TAB> config = ConfigParser . RawConfigParser ( ) <TAB> configurations = config_manager ( )<TAB> # Class from mkchromecast.config <TAB> configf = configurations . configf <TAB> config . read ( configf ) <TAB> dict1 = { } <TAB> options = config . options ( section ) <TAB> for option in options : <TAB> <TAB> try : <TAB> <TAB> <TAB> dict1 [ option ] = config . get ( section , option ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> DebugPrint ( "" skip:  %s "" % option ) <TAB> <TAB> except : <TAB> <TAB> <TAB> print ( "" Exception on  %s ! "" % option ) <TAB> <TAB> <TAB> dict1 [ option ] = None <TAB> return dict1 ","if dict1 [ option ] == - 1 : 
","if dict1 [ option ] is None :
",54.04,42.14,False
"def on_success ( result ) : <TAB> subtasks = { } <TAB> if result : <TAB> <TAB> subtasks = { <TAB> <TAB> <TAB> self . nodes_keys . inverse [ s [ "" node_id "" ] ] : s . get ( "" subtask_id "" ) <TAB> <TAB> <TAB> for s in result <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> } <TAB> if subtasks : <TAB> <TAB> print ( "" subtask finished "" ) <TAB> <TAB> self . next ( ) <TAB> else : <TAB> <TAB> print ( "" waiting for a subtask to finish "" ) <TAB> <TAB> time . sleep ( 10 ) ","if s . get ( "" status "" ) == "" Failure "" 
","if s [ "" node_id "" ] in self . nodes_keys . inverse . keys ( )
",36.38,4.97,False
"def redirect_aware_commmunicate ( p , sys = _sys ) : <TAB> """"""Variant of process.communicate that works with in process I/O redirection."""""" <TAB> assert sys is not None <TAB> out , err = p . communicate ( ) <TAB> if redirecting_io ( sys = sys ) : <TAB> <TAB> if out : <TAB> <TAB> <TAB> # We don't unicodify in Python2 because sys.stdout may be a <TAB> <TAB> <TAB> # cStringIO.StringIO object, which does not accept Unicode strings <TAB> <TAB> <TAB> out = unicodify ( out ) <TAB> <TAB> <TAB> sys . stdout . write ( out ) <TAB> <TAB> <TAB> out = None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> err = unicodify ( err ) <TAB> <TAB> <TAB> sys . stderr . write ( err ) <TAB> <TAB> <TAB> err = None <TAB> return out , err ","if err : 
","if err :
",78.12,0.0,False
"def __exit__ ( self , * args , * * kwargs ) : <TAB> self . _samples_cache = { } <TAB> if is_validation_enabled ( ) and isinstance ( self . prior , dict ) : <TAB> <TAB> extra = set ( self . prior ) - self . _param_hits <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> warnings . warn ( <TAB> <TAB> <TAB> <TAB> "" pyro.module prior did not find params [ ' {} ' ].  "" <TAB> <TAB> <TAB> <TAB> "" Did you instead mean one of [ ' {} ' ]? "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> "" ' ,  ' "" . join ( extra ) , "" ' ,  ' "" . join ( self . _param_misses ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> ) <TAB> return super ( ) . __exit__ ( * args , * * kwargs ) ","if extra : 
","if extra :
",78.12,0.0,False
def __download_thread ( self ) : <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . __current_download = self . __queue . get ( ) <TAB> <TAB> <TAB> self . __download_file ( self . __current_download ) <TAB> <TAB> time . sleep ( 0.1 ) ,"if not self . __queue . empty ( ) : 
","if self . __current_download is None :
",31.29,23.71,False
"def plot_timer_command ( args ) : <TAB> import nnabla . monitor as M <TAB> format_unit = dict ( <TAB> <TAB> s = "" seconds "" , <TAB> <TAB> m = "" minutes "" , <TAB> <TAB> h = "" hours "" , <TAB> <TAB> d = "" days "" , <TAB> ) <TAB> if not args . ylabel : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> args . ylabel = "" Total elapsed time [ {} ] "" . format ( format_unit [ args . time_unit ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> args . ylabel = "" Elapsed time [ {} /iter] "" . format ( format_unit [ args . time_unit ] ) <TAB> plot_any_command ( <TAB> <TAB> args , M . plot_time_elapsed , dict ( elapsed = args . elapsed , unit = args . time_unit ) <TAB> ) <TAB> return True ","if args . elapsed : 
","if args . elapsed :
",100.0,100.0,True
"def resolve_page ( root : ChannelContext [ models . MenuItem ] , info , * * kwargs ) : <TAB> if root . node . page_id : <TAB> <TAB> requestor = get_user_or_app_from_context ( info . context ) <TAB> <TAB> requestor_has_access_to_all = requestor . is_active and requestor . has_perm ( <TAB> <TAB> <TAB> PagePermissions . MANAGE_PAGES <TAB> <TAB> ) <TAB> <TAB> return ( <TAB> <TAB> <TAB> PageByIdLoader ( info . context ) <TAB> <TAB> <TAB> . load ( root . node . page_id ) <TAB> <TAB> <TAB> . then ( <TAB> <TAB> <TAB> <TAB> lambda page : page <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> else None <TAB> <TAB> <TAB> ) <TAB> <TAB> ) <TAB> return None ","if requestor_has_access_to_all or page . is_visible 
","if not requestor_has_access_to_all
",27.54,51.23,False
"def find ( self , pattern ) : <TAB> """"""Find pages in database."""""" <TAB> results = self . _search_keyword ( pattern ) <TAB> pat = re . compile ( "" (.*?)( %s )(.*?)(  \ (.* \ ))?$ "" % re . escape ( pattern ) , re . I ) <TAB> if results : <TAB> <TAB> for name , keyword , url in results : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> keyword = pat . sub ( <TAB> <TAB> <TAB> <TAB> <TAB> r "" \ 1 \ 033[1;31m \ 2 \ 033[0m \ 3 \ 033[1;33m \ 4 \ 033[0m "" , keyword <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> print ( "" %s  -  %s "" % ( keyword , name ) ) <TAB> else : <TAB> <TAB> raise RuntimeError ( "" %s : nothing appropriate. "" % pattern ) ","if os . isatty ( sys . stdout . fileno ( ) ) : 
","if url . startswith ( "" http://www.w3.org/1999/02/22-rdf-syntax-ns#PageQuery "" ) :
",32.53,3.65,False
"def _certonly_new_request_common ( self , mock_client , args = None ) : <TAB> with mock . patch ( <TAB> <TAB> "" certbot._internal.main._find_lineage_for_domains_and_certname "" <TAB> ) as mock_renewal : <TAB> <TAB> mock_renewal . return_value = ( "" newcert "" , None ) <TAB> <TAB> with mock . patch ( "" certbot._internal.main._init_le_client "" ) as mock_init : <TAB> <TAB> <TAB> mock_init . return_value = mock_client <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> args = [ ] <TAB> <TAB> <TAB> args + = "" -d foo.bar -a standalone certonly "" . split ( ) <TAB> <TAB> <TAB> self . _call ( args ) ","if args is None : 
","if args is None :
",100.0,100.0,True
"def __init__ ( self , * args , * * kw ) : <TAB> if len ( args ) > 1 : <TAB> <TAB> raise TypeError ( "" MultiDict can only be called with one positional  "" "" argument "" ) <TAB> if args : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> items = list ( args [ 0 ] . iteritems ( ) ) <TAB> <TAB> elif hasattr ( args [ 0 ] , "" items "" ) : <TAB> <TAB> <TAB> items = list ( args [ 0 ] . items ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> items = list ( args [ 0 ] ) <TAB> <TAB> self . _items = items <TAB> else : <TAB> <TAB> self . _items = [ ] <TAB> if kw : <TAB> <TAB> self . _items . extend ( kw . items ( ) ) ","if hasattr ( args [ 0 ] , "" iteritems "" ) : 
","if hasattr ( args [ 0 ] , "" iteritems "" ) :
",100.0,100.0,True
"def test08_ExceptionTypes ( self ) : <TAB> self . assertTrue ( issubclass ( db . DBError , Exception ) ) <TAB> for i , j in db . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertTrue ( issubclass ( j , db . DBError ) , msg = i ) <TAB> <TAB> <TAB> if i not in ( "" DBKeyEmptyError "" , "" DBNotFoundError "" ) : <TAB> <TAB> <TAB> <TAB> self . assertFalse ( issubclass ( j , KeyError ) , msg = i ) <TAB> # This two exceptions have two bases <TAB> self . assertTrue ( issubclass ( db . DBKeyEmptyError , KeyError ) ) <TAB> self . assertTrue ( issubclass ( db . DBNotFoundError , KeyError ) ) ","if i . startswith ( "" DB "" ) and i . endswith ( "" Error "" ) : 
","if i not in ( "" DBError "" , "" DBNotFoundError "" ) :
",33.46,11.58,False
"def _delegate_to_sinks ( self , value : Any ) - > None : <TAB> for sink in self . _sinks : <TAB> <TAB> if isinstance ( sink , AgentT ) : <TAB> <TAB> <TAB> await sink . send ( value = value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> await cast ( TopicT , sink ) . send ( value = value ) <TAB> <TAB> else : <TAB> <TAB> <TAB> await maybe_async ( cast ( Callable , sink ) ( value ) ) ","elif isinstance ( sink , ChannelT ) : 
","elif isinstance ( sink , TopicT ) :
",79.9,59.46,False
"def _select_block ( str_in , start_tag , end_tag ) : <TAB> """"""Select first block delimited by start_tag and end_tag"""""" <TAB> start_pos = str_in . find ( start_tag ) <TAB> if start_pos < 0 : <TAB> <TAB> raise ValueError ( "" start_tag not found "" ) <TAB> depth = 0 <TAB> for pos in range ( start_pos , len ( str_in ) ) : <TAB> <TAB> if str_in [ pos ] == start_tag : <TAB> <TAB> <TAB> depth + = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> depth - = 1 <TAB> <TAB> if depth == 0 : <TAB> <TAB> <TAB> break <TAB> sel = str_in [ start_pos + 1 : pos ] <TAB> return sel ","elif str_in [ pos ] == end_tag : 
","if str_in [ pos ] == end_tag :
",77.52,91.22,False
"def confirm ( request ) : <TAB> details = request . session . get ( "" reauthenticate "" ) <TAB> if not details : <TAB> <TAB> return redirect ( "" home "" ) <TAB> # Monkey patch request <TAB> request . user = User . objects . get ( pk = details [ "" user_pk "" ] ) <TAB> if request . method == "" POST "" : <TAB> <TAB> confirm_form = PasswordConfirmForm ( request , request . POST ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> request . session . pop ( "" reauthenticate "" ) <TAB> <TAB> <TAB> request . session [ "" reauthenticate_done "" ] = True <TAB> <TAB> <TAB> return redirect ( "" social:complete "" , backend = details [ "" backend "" ] ) <TAB> else : <TAB> <TAB> confirm_form = PasswordConfirmForm ( request ) <TAB> context = { "" confirm_form "" : confirm_form } <TAB> context . update ( details ) <TAB> return render ( request , "" accounts/confirm.html "" , context ) ","if confirm_form . is_valid ( ) : 
","if confirm_form . is_valid ( ) :
",100.0,100.0,True
"def verify_credentials ( self ) : <TAB> if self . enabled : <TAB> <TAB> response = requests . get ( <TAB> <TAB> <TAB> "" https://api.exotel.com/v1/Accounts/ {sid} "" . format ( sid = self . account_sid ) , <TAB> <TAB> <TAB> auth = ( self . api_key , self . api_token ) , <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> frappe . throw ( _ ( "" Invalid credentials "" ) ) ","if response . status_code != 200 : 
","if response . status_code != 200 :
",100.0,100.0,True
"def pixbufrenderer ( self , column , crp , model , it ) : <TAB> tok = model . get_value ( it , 0 ) <TAB> if tok . type == "" class "" : <TAB> <TAB> icon = "" class "" <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> icon = "" method_priv "" <TAB> <TAB> elif tok . visibility == "" protected "" : <TAB> <TAB> <TAB> icon = "" method_prot "" <TAB> <TAB> else : <TAB> <TAB> <TAB> icon = "" method "" <TAB> crp . set_property ( "" pixbuf "" , imagelibrary . pixbufs [ icon ] ) ","if tok . visibility == "" private "" : 
","if tok . visibility == "" private "" :
",100.0,100.0,True
"def _omit_keywords ( self , context ) : <TAB> omitted_kws = 0 <TAB> for event , elem in context : <TAB> <TAB> # Teardowns aren't omitted to allow checking suite teardown status. <TAB> <TAB> omit = elem . tag == "" kw "" and elem . get ( "" type "" ) != "" teardown "" <TAB> <TAB> start = event == "" start "" <TAB> <TAB> if omit and start : <TAB> <TAB> <TAB> omitted_kws + = 1 <TAB> <TAB> if not omitted_kws : <TAB> <TAB> <TAB> yield event , elem <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> elem . clear ( ) <TAB> <TAB> if omit and not start : <TAB> <TAB> <TAB> omitted_kws - = 1 ","elif not start : 
","elif event == "" stop "" :
",28.37,6.57,False
"def on_double_click ( self , event ) : <TAB> # TODO: don't act when the click happens below last item <TAB> path = self . get_selected_path ( ) <TAB> kind = self . get_selected_kind ( ) <TAB> name = self . get_selected_name ( ) <TAB> if kind == "" file "" : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . open_file ( path ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . open_path_with_system_app ( path ) <TAB> elif kind == "" dir "" : <TAB> <TAB> self . request_focus_into ( path ) <TAB> return "" break "" ","if self . should_open_name_in_thonny ( name ) : 
","if os . path . isfile ( path ) :
",38.34,5.79,False
"def search_cve ( db : DatabaseInterface , product : Product ) - > dict : <TAB> result = { } <TAB> for query_result in db . fetch_multiple ( QUERIES [ "" cve_lookup "" ] ) : <TAB> <TAB> cve_entry = CveDbEntry ( * query_result ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result [ cve_entry . cve_id ] = { <TAB> <TAB> <TAB> <TAB> "" score2 "" : cve_entry . cvss_v2_score , <TAB> <TAB> <TAB> <TAB> "" score3 "" : cve_entry . cvss_v3_score , <TAB> <TAB> <TAB> <TAB> "" cpe_version "" : build_version_string ( cve_entry ) , <TAB> <TAB> <TAB> } <TAB> return result ","if _product_matches_cve ( product , cve_entry ) : 
","if cve_entry . product == product :
",27.07,11.71,False
"def find_go_files_mtime ( app_files ) : <TAB> files , mtime = [ ] , 0 <TAB> for f , mt in app_files . items ( ) : <TAB> <TAB> if not f . endswith ( "" .go "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> files . append ( f ) <TAB> <TAB> mtime = max ( mtime , mt ) <TAB> return files , mtime ","if APP_CONFIG . nobuild_files . match ( f ) : 
","if mt < mtime :
",26.3,2.1,False
"def wrapper ( filename ) : <TAB> mtime = getmtime ( filename ) <TAB> with lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> old_mtime , result = cache . pop ( filename ) <TAB> <TAB> <TAB> if old_mtime == mtime : <TAB> <TAB> <TAB> <TAB> # Move to the end <TAB> <TAB> <TAB> <TAB> cache [ filename ] = old_mtime , result <TAB> <TAB> <TAB> <TAB> return result <TAB> result = function ( filename ) <TAB> with lock : <TAB> <TAB> cache [ filename ] = mtime , result<TAB> # at the end <TAB> <TAB> if len ( cache ) > max_size : <TAB> <TAB> <TAB> cache . popitem ( last = False ) <TAB> return result ","if filename in cache : 
","if len ( cache ) > max_size :
",27.63,5.52,False
"def Tokenize ( s ) : <TAB> # type: (str) -> Iterator[Token] <TAB> for item in TOKEN_RE . findall ( s ) : <TAB> <TAB> # The type checker can't know the true type of item! <TAB> <TAB> item = cast ( TupleStr4 , item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> typ = "" number "" <TAB> <TAB> <TAB> val = item [ 0 ] <TAB> <TAB> elif item [ 1 ] : <TAB> <TAB> <TAB> typ = "" name "" <TAB> <TAB> <TAB> val = item [ 1 ] <TAB> <TAB> elif item [ 2 ] : <TAB> <TAB> <TAB> typ = item [ 2 ] <TAB> <TAB> <TAB> val = item [ 2 ] <TAB> <TAB> elif item [ 3 ] : <TAB> <TAB> <TAB> typ = item [ 3 ] <TAB> <TAB> <TAB> val = item [ 3 ] <TAB> <TAB> yield Token ( typ , val ) ","if item [ 0 ] : 
","if item [ 0 ] :
",100.0,100.0,True
"def _show_encoders ( self , * args , * * kwargs ) : <TAB> if issubclass ( self . current_module . __class__ , BasePayload ) : <TAB> <TAB> encoders = self . current_module . get_encoders ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> headers = ( "" Encoder "" , "" Name "" , "" Description "" ) <TAB> <TAB> <TAB> print_table ( headers , * encoders , max_column_length = 100 ) <TAB> <TAB> <TAB> return <TAB> print_error ( "" No encoders available "" ) ","if encoders : 
","if encoders :
",78.12,0.0,False
"def __init__ ( self ) : <TAB> Builder . __init__ ( self , commandName = "" VCExpress.exe "" , formatName = "" msvcProject "" ) <TAB> for key in [ "" VS90COMNTOOLS "" , "" VC80COMNTOOLS "" , "" VC71COMNTOOLS "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . programDir = os . path . join ( os . environ [ key ] , "" .. "" , "" IDE "" ) <TAB> if self . programDir is None : <TAB> <TAB> for version in [ "" 9.0 "" , "" 8 "" , "" .NET 2003 "" ] : <TAB> <TAB> <TAB> msvcDir = ( <TAB> <TAB> <TAB> <TAB> "" C: \\ Program Files \\ Microsoft Visual Studio  %s \\ Common7 \\ IDE "" % version <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> if os . path . exists ( msvcDir ) : <TAB> <TAB> <TAB> <TAB> self . programDir = msvcDir ","if os . environ . has_key ( key ) : 
","if key in os . environ :
",35.58,14.23,False
"def _inner ( * args , * * kwargs ) : <TAB> component_manager = args [ 0 ] . component_manager <TAB> for condition_name in condition_names : <TAB> <TAB> condition_result , err_msg = component_manager . evaluate_condition ( condition_name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ComponentStartConditionNotMetError ( err_msg ) <TAB> if not component_manager . all_components_running ( * components ) : <TAB> <TAB> raise ComponentsNotStartedError ( <TAB> <TAB> <TAB> f "" the following required components have not yet started:  { json . dumps ( components ) } "" <TAB> <TAB> ) <TAB> return method ( * args , * * kwargs ) ","if not condition_result : 
","if not condition_result :
",100.0,100.0,True
"def _gridconvvalue ( self , value ) : <TAB> if isinstance ( value , ( str , _tkinter . Tcl_Obj ) ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> svalue = str ( value ) <TAB> <TAB> <TAB> if not svalue : <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . tk . getdouble ( svalue ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> return self . tk . getint ( svalue ) <TAB> <TAB> except ( ValueError , TclError ) : <TAB> <TAB> <TAB> pass <TAB> return value ","elif "" . "" in svalue : 
","elif isinstance ( svalue , float ) :
",27.02,7.27,False
"def check_songs ( ) : <TAB> desc = numeric_phrase ( "" %d  song "" , "" %d  songs "" , len ( songs ) ) <TAB> with Task ( _ ( "" Rescan songs "" ) , desc ) as task : <TAB> <TAB> task . copool ( check_songs ) <TAB> <TAB> for i , song in enumerate ( songs ) : <TAB> <TAB> <TAB> song = song . _song <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> app . library . reload ( song ) <TAB> <TAB> <TAB> task . update ( ( float ( i ) + 1 ) / len ( songs ) ) <TAB> <TAB> <TAB> yield ","if song in app . library : 
","if app . library :
",53.5,47.4,False
"def initialize ( self ) : <TAB> nn . init . xavier_uniform_ ( self . linear . weight . data ) <TAB> if self . linear . bias is not None : <TAB> <TAB> self . linear . bias . data . uniform_ ( - 1.0 , 1.0 ) <TAB> if self . self_layer : <TAB> <TAB> nn . init . xavier_uniform_ ( self . linear_self . weight . data ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . linear_self . bias . data . uniform_ ( - 1.0 , 1.0 ) ","if self . linear_self . bias is not None : 
","if self . linear_self . bias is not None :
",100.0,100.0,True
"def test_row ( self , row ) : <TAB> for idx , test in self . patterns . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> value = row [ idx ] <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> value = "" "" <TAB> <TAB> result = test ( value ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if result : <TAB> <TAB> <TAB> <TAB> return not self . inverse<TAB> # True <TAB> <TAB> else : <TAB> <TAB> <TAB> if not result : <TAB> <TAB> <TAB> <TAB> return self . inverse<TAB> # False <TAB> if self . any_match : <TAB> <TAB> return self . inverse<TAB> # False <TAB> else : <TAB> <TAB> return not self . inverse<TAB> # True ","if self . any_match : 
","if self . any_match :
",100.0,100.0,True
"def toterminal ( self , tw ) : <TAB> for element in self . chain : <TAB> <TAB> element [ 0 ] . toterminal ( tw ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tw . line ( "" "" ) <TAB> <TAB> <TAB> tw . line ( element [ 2 ] , yellow = True ) <TAB> super ( ExceptionChainRepr , self ) . toterminal ( tw ) ","if element [ 2 ] is not None : 
","if element [ 1 ] :
",36.51,20.82,False
"def runMainLoop ( self ) : <TAB> """"""The curses gui main loop."""""" <TAB> # pylint: disable=no-member <TAB> # <TAB> # Do NOT change g.app! <TAB> self . curses_app = LeoApp ( ) <TAB> stdscr = curses . initscr ( ) <TAB> if 1 :<TAB> # Must follow initscr. <TAB> <TAB> self . dump_keys ( ) <TAB> try : <TAB> <TAB> self . curses_app . run ( ) <TAB> <TAB> # run calls CApp.main(), which calls CGui.run(). <TAB> finally : <TAB> <TAB> curses . nocbreak ( ) <TAB> <TAB> stdscr . keypad ( 0 ) <TAB> <TAB> curses . echo ( ) <TAB> <TAB> curses . endwin ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> g . pr ( "" Exiting Leo... "" ) ","if "" shutdown "" in g . app . debug : 
","if curses . cur_mode == "" dry "" :
",34.76,5.06,False
"def test_chunkcoding ( self ) : <TAB> for native , utf8 in zip ( * [ StringIO ( f ) . readlines ( ) for f in self . tstring ] ) : <TAB> <TAB> u = self . decode ( native ) [ 0 ] <TAB> <TAB> self . assertEqual ( u , utf8 . decode ( "" utf-8 "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( native , self . encode ( u ) [ 0 ] ) ","if self . roundtriptest : 
","if PY2 :
",28.55,0.0,False
"def reload_sanitize_allowlist ( self , explicit = True ) : <TAB> self . sanitize_allowlist = [ ] <TAB> try : <TAB> <TAB> with open ( self . sanitize_allowlist_file ) as f : <TAB> <TAB> <TAB> for line in f . readlines ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist . append ( line . strip ( ) ) <TAB> except OSError : <TAB> <TAB> if explicit : <TAB> <TAB> <TAB> log . warning ( <TAB> <TAB> <TAB> <TAB> "" Sanitize log file explicitly specified as  ' %s '  but does not exist, continuing with no tools allowlisted. "" , <TAB> <TAB> <TAB> <TAB> self . sanitize_allowlist_file , <TAB> <TAB> <TAB> ) ","if not line . startswith ( "" # "" ) : 
","if line . startswith ( "" -- "" ) :
",63.08,48.96,False
"def get_all_extensions ( subtree = None ) : <TAB> if subtree is None : <TAB> <TAB> subtree = full_extension_tree ( ) <TAB> result = [ ] <TAB> if isinstance ( subtree , dict ) : <TAB> <TAB> for value in subtree . values ( ) : <TAB> <TAB> <TAB> if isinstance ( value , dict ) : <TAB> <TAB> <TAB> <TAB> result + = get_all_extensions ( value ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> result + = value . extensions <TAB> <TAB> <TAB> elif isinstance ( value , ( list , tuple ) ) : <TAB> <TAB> <TAB> <TAB> result + = value <TAB> elif isinstance ( subtree , ( ContentTypeMapping , ContentTypeDetector ) ) : <TAB> <TAB> result = subtree . extensions <TAB> elif isinstance ( subtree , ( list , tuple ) ) : <TAB> <TAB> result = subtree <TAB> return result ","elif isinstance ( value , ( ContentTypeMapping , ContentTypeDetector ) ) : 
","elif isinstance ( value , ContentTypeMapping ) :
",44.03,37.29,False
"def _configuration_dict_to_commandlist ( name , config_dict ) : <TAB> command_list = [ "" config: %s "" % name ] <TAB> for key , value in config_dict . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> b = "" true "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> b = "" false "" <TAB> <TAB> <TAB> command_list . append ( "" %s : %s "" % ( key , b ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> command_list . append ( "" %s : %s "" % ( key , value ) ) <TAB> return command_list ","if type ( value ) is bool : 
","if key in [ "" enabled "" , "" disabled "" ] :
",26.33,3.67,False
"def _RewriteModinfo ( <TAB> self , <TAB> modinfo , <TAB> obj_kernel_version , <TAB> this_kernel_version , <TAB> info_strings = None , <TAB> to_remove = None , ) : <TAB> new_modinfo = "" "" <TAB> for line in modinfo . split ( "" \x00 "" ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if to_remove and line . split ( "" = "" ) [ 0 ] == to_remove : <TAB> <TAB> <TAB> continue <TAB> <TAB> if info_strings is not None : <TAB> <TAB> <TAB> info_strings . add ( line . split ( "" = "" ) [ 0 ] ) <TAB> <TAB> if line . startswith ( "" vermagic "" ) : <TAB> <TAB> <TAB> line = line . replace ( obj_kernel_version , this_kernel_version ) <TAB> <TAB> new_modinfo + = line + "" \x00 "" <TAB> return new_modinfo ","if not line : 
","if not line :
",100.0,100.0,True
"def zip_random_open_test ( self , f , compression ) : <TAB> self . make_test_archive ( f , compression ) <TAB> # Read the ZIP archive <TAB> with zipfile . ZipFile ( f , "" r "" , compression ) as zipfp : <TAB> <TAB> zipdata1 = [ ] <TAB> <TAB> with zipfp . open ( TESTFN ) as zipopen1 : <TAB> <TAB> <TAB> while True : <TAB> <TAB> <TAB> <TAB> read_data = zipopen1 . read ( randint ( 1 , 1024 ) ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <TAB> zipdata1 . append ( read_data ) <TAB> <TAB> testdata = "" "" . join ( zipdata1 ) <TAB> <TAB> self . assertEqual ( len ( testdata ) , len ( self . data ) ) <TAB> <TAB> self . assertEqual ( testdata , self . data ) ","if not read_data : 
","if not read_data :
",100.0,100.0,True
"def _memoized ( * args ) : <TAB> now = time . time ( ) <TAB> try : <TAB> <TAB> value , last_update = self . cache [ args ] <TAB> <TAB> age = now - last_update <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _call_count = 0 <TAB> <TAB> <TAB> raise AttributeError <TAB> <TAB> if self . ctl : <TAB> <TAB> <TAB> self . _call_count + = 1 <TAB> <TAB> return value <TAB> except ( KeyError , AttributeError ) : <TAB> <TAB> value = func ( * args ) <TAB> <TAB> if value : <TAB> <TAB> <TAB> self . cache [ args ] = ( value , now ) <TAB> <TAB> return value <TAB> except TypeError : <TAB> <TAB> return func ( * args ) ","if self . _call_count > self . ctl or age > self . ttl : 
","if age < = 0 :
",25.78,1.45,False
"def on_data ( res ) : <TAB> if terminate . is_set ( ) : <TAB> <TAB> return <TAB> if args . strings and not args . no_content : <TAB> <TAB> if type ( res ) == tuple : <TAB> <TAB> <TAB> f , v = res <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> f = f . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> if type ( v ) == unicode : <TAB> <TAB> <TAB> <TAB> v = v . encode ( "" utf-8 "" ) <TAB> <TAB> <TAB> self . success ( "" {} :  {} "" . format ( f , v ) ) <TAB> <TAB> elif not args . content_only : <TAB> <TAB> <TAB> self . success ( res ) <TAB> else : <TAB> <TAB> self . success ( res ) ","if type ( f ) == unicode : 
","if type ( f ) == unicode :
",100.0,100.0,True
"def _finalize_setup_keywords ( self ) : <TAB> for ep in pkg_resources . iter_entry_points ( "" distutils.setup_keywords "" ) : <TAB> <TAB> value = getattr ( self , ep . name , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ep . require ( installer = self . fetch_build_egg ) <TAB> <TAB> <TAB> ep . load ( ) ( self , ep . name , value ) ","if value is not None : 
","if value is not None :
",100.0,100.0,True
"def test_attributes_types ( self ) : <TAB> if not self . connection . strategy . pooled : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . connection . refresh_server_info ( ) <TAB> <TAB> self . assertEqual ( <TAB> <TAB> <TAB> type ( self . connection . server . schema . attribute_types [ "" cn "" ] ) , AttributeTypeInfo <TAB> <TAB> ) ","if not self . connection . server . info : 
","if self . connection . server . schema . attribute_types [ "" cn "" ] is None :
",57.88,25.35,False
"def to_key ( literal_or_identifier ) : <TAB> """"""returns string representation of this object"""""" <TAB> if literal_or_identifier [ "" type "" ] == "" Identifier "" : <TAB> <TAB> return literal_or_identifier [ "" name "" ] <TAB> elif literal_or_identifier [ "" type "" ] == "" Literal "" : <TAB> <TAB> k = literal_or_identifier [ "" value "" ] <TAB> <TAB> if isinstance ( k , float ) : <TAB> <TAB> <TAB> return unicode ( float_repr ( k ) ) <TAB> <TAB> elif "" regex "" in literal_or_identifier : <TAB> <TAB> <TAB> return compose_regex ( k ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" true "" if k else "" false "" <TAB> <TAB> elif k is None : <TAB> <TAB> <TAB> return "" null "" <TAB> <TAB> else : <TAB> <TAB> <TAB> return unicode ( k ) ","elif isinstance ( k , bool ) : 
","elif isinstance ( k , bool ) :
",100.0,100.0,True
"def list2rec ( x , test = False ) : <TAB> if test : <TAB> <TAB> vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 0 ] , int ( x [ 1 ] ) , int ( x [ 2 ] ) ) <TAB> <TAB> label = - 1<TAB> # label unknown <TAB> <TAB> return vid , label <TAB> else : <TAB> <TAB> vid = "" {} _ {:06d} _ {:06d} "" . format ( x [ 1 ] , int ( x [ 2 ] ) , int ( x [ 3 ] ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vid = "" {} / {} "" . format ( convert_label ( x [ 0 ] ) , vid ) <TAB> <TAB> else : <TAB> <TAB> <TAB> assert level == 1 <TAB> <TAB> label = class_mapping [ convert_label ( x [ 0 ] ) ] <TAB> <TAB> return vid , label ","if level == 2 : 
","if level == 0 :
",64.48,53.73,False
"def _expand_env ( self , snapcraft_yaml ) : <TAB> environment_keys = [ "" name "" , "" version "" ] <TAB> for key in snapcraft_yaml : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> replacements = environment_to_replacements ( <TAB> <TAB> <TAB> get_snapcraft_global_environment ( self . project ) <TAB> <TAB> ) <TAB> <TAB> snapcraft_yaml [ key ] = replace_attr ( snapcraft_yaml [ key ] , replacements ) <TAB> return snapcraft_yaml ","if any ( ( key == env_key for env_key in environment_keys ) ) : 
","if key not in environment_keys :
",30.32,7.83,False
"def enableCtrls ( self ) : <TAB> # Check if each ctrl has a requirement or an incompatibility, <TAB> # look it up, and enable/disable if so <TAB> for data in self . storySettingsData : <TAB> <TAB> name = data [ "" name "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if "" requires "" in data : <TAB> <TAB> <TAB> <TAB> set = self . getSetting ( data [ "" requires "" ] ) <TAB> <TAB> <TAB> <TAB> for i in self . ctrls [ name ] : <TAB> <TAB> <TAB> <TAB> <TAB> i . Enable ( set not in [ "" off "" , "" false "" , "" 0 "" ] ) ","if name in self . ctrls : 
","if name in self . ctrls :
",100.0,100.0,True
"def __init__ ( self , * args , * * kwargs ) : <TAB> super ( ChallengePhaseCreateSerializer , self ) . __init__ ( * args , * * kwargs ) <TAB> context = kwargs . get ( "" context "" ) <TAB> if context : <TAB> <TAB> challenge = context . get ( "" challenge "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> kwargs [ "" data "" ] [ "" challenge "" ] = challenge . pk <TAB> <TAB> test_annotation = context . get ( "" test_annotation "" ) <TAB> <TAB> if test_annotation : <TAB> <TAB> <TAB> kwargs [ "" data "" ] [ "" test_annotation "" ] = test_annotation ","if challenge : 
","if challenge :
",78.12,0.0,False
def set_inactive ( self ) : <TAB> for title in self . gramplet_map : <TAB> <TAB> if self . gramplet_map [ title ] . pui : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . gramplet_map [ title ] . pui . active = False ,"if self . gramplet_map [ title ] . gstate != "" detached "" : 
","if self . gramplet_map [ title ] . pui . active :
",62.71,55.94,False
"def authenticate ( username , password ) : <TAB> try : <TAB> <TAB> u = User . objects . get ( username = username ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> userLogger . info ( "" User logged in :  %s "" , username ) <TAB> <TAB> <TAB> return u <TAB> <TAB> else : <TAB> <TAB> <TAB> userLogger . warn ( "" Attempt to log in to :  %s "" , username ) <TAB> <TAB> <TAB> return False <TAB> except DoesNotExist : <TAB> <TAB> return False ","if check_password_hash ( u . password , password ) : 
","if u . verify ( password ) :
",37.34,13.28,False
def _check_date ( self ) : <TAB> if not self . value : <TAB> <TAB> return None <TAB> if not self . allow_date_in_past : <TAB> <TAB> if self . value < self . date_or_datetime ( ) . today ( ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . value = self . date_or_datetime ( ) . today ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . value = self . date_or_datetime ( ) . today ( ) + datetime . timedelta ( 1 ) ,"if self . allow_todays_date : 
","if self . value > self . date_or_datetime ( ) . today ( ) :
",42.43,9.31,False
"def update ( self , E = None , * * F ) : <TAB> if E : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Update with `E` dictionary <TAB> <TAB> <TAB> for k in E : <TAB> <TAB> <TAB> <TAB> self [ k ] = E [ k ] <TAB> <TAB> else : <TAB> <TAB> <TAB> # Update with `E` items <TAB> <TAB> <TAB> for ( k , v ) in E : <TAB> <TAB> <TAB> <TAB> self [ k ] = v <TAB> # Update with `F` dictionary <TAB> for k in F : <TAB> <TAB> self [ k ] = F [ k ] ","if hasattr ( E , "" keys "" ) : 
","if isinstance ( E , dict ) :
",32.11,21.07,False
"def _get_quota_availability ( self ) : <TAB> quotas_ok = defaultdict ( int ) <TAB> qa = QuotaAvailability ( ) <TAB> qa . queue ( * [ k for k , v in self . _quota_diff . items ( ) if v > 0 ] ) <TAB> qa . compute ( now_dt = self . now_dt ) <TAB> for quota , count in self . _quota_diff . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> quotas_ok [ quota ] = 0 <TAB> <TAB> <TAB> break <TAB> <TAB> avail = qa . results [ quota ] <TAB> <TAB> if avail [ 1 ] is not None and avail [ 1 ] < count : <TAB> <TAB> <TAB> quotas_ok [ quota ] = min ( count , avail [ 1 ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> quotas_ok [ quota ] = count <TAB> return quotas_ok ","if count < = 0 : 
","if not qa . results . get ( quota ) :
",26.97,4.46,False
"def gen_env_vars ( ) : <TAB> for fd_id , fd in zip ( STDIO_DESCRIPTORS , ( stdin , stdout , stderr ) ) : <TAB> <TAB> is_atty = fd . isatty ( ) <TAB> <TAB> yield ( cls . TTY_ENV_TMPL . format ( fd_id ) , cls . encode_env_var_value ( int ( is_atty ) ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield ( cls . TTY_PATH_ENV . format ( fd_id ) , os . ttyname ( fd . fileno ( ) ) or b "" "" ) ","if is_atty : 
","if fd . isatty ( ) :
",29.58,7.81,False
"def _convertDict ( self , d ) : <TAB> r = { } <TAB> for k , v in d . items ( ) : <TAB> <TAB> if isinstance ( v , bytes ) : <TAB> <TAB> <TAB> v = str ( v , "" utf-8 "" ) <TAB> <TAB> elif isinstance ( v , list ) or isinstance ( v , tuple ) : <TAB> <TAB> <TAB> v = self . _convertList ( v ) <TAB> <TAB> elif isinstance ( v , dict ) : <TAB> <TAB> <TAB> v = self . _convertDict ( v ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> k = str ( k , "" utf-8 "" ) <TAB> <TAB> r [ k ] = v <TAB> return r ","if isinstance ( k , bytes ) : 
","elif isinstance ( k , bytes ) :
",77.52,84.09,False
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> if nodeid not in self . _nodes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> if attval . value_callback : <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value ","if attr not in node . attributes : 
","if attr not in node . attributes :
",100.0,100.0,True
"def conninfo_parse ( dsn ) : <TAB> ret = { } <TAB> length = len ( dsn ) <TAB> i = 0 <TAB> while i < length : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> i + = 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> param_match = PARAMETER_RE . match ( dsn [ i : ] ) <TAB> <TAB> if not param_match : <TAB> <TAB> <TAB> return <TAB> <TAB> param = param_match . group ( 1 ) <TAB> <TAB> i + = param_match . end ( ) <TAB> <TAB> if i > = length : <TAB> <TAB> <TAB> return <TAB> <TAB> value , end = read_param_value ( dsn [ i : ] ) <TAB> <TAB> if value is None : <TAB> <TAB> <TAB> return <TAB> <TAB> i + = end <TAB> <TAB> ret [ param ] = value <TAB> return ret ","if dsn [ i ] . isspace ( ) : 
","if dsn [ i ] == "" ; "" :
",50.18,36.72,False
"def connect ( self , buttons ) : <TAB> for button in buttons : <TAB> <TAB> assert button is not None <TAB> <TAB> handled = False <TAB> <TAB> for handler_idx in range ( 0 , len ( self . __signal_handlers ) ) : <TAB> <TAB> <TAB> ( obj_class , signal , handler , handler_id ) = self . __signal_handlers [ <TAB> <TAB> <TAB> <TAB> handler_idx <TAB> <TAB> <TAB> ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> handler_id = button . connect ( signal , handler ) <TAB> <TAB> <TAB> <TAB> handled = True <TAB> <TAB> <TAB> self . __signal_handlers [ handler_idx ] = ( <TAB> <TAB> <TAB> <TAB> obj_class , <TAB> <TAB> <TAB> <TAB> signal , <TAB> <TAB> <TAB> <TAB> handler , <TAB> <TAB> <TAB> <TAB> handler_id , <TAB> <TAB> <TAB> ) <TAB> <TAB> assert handled ","if isinstance ( button , obj_class ) : 
","if handler is not None :
",26.85,4.96,False
"def _parse_display ( display ) : <TAB> """"""Parse an X11 display value"""""" <TAB> try : <TAB> <TAB> host , dpynum = display . rsplit ( "" : "" , 1 ) <TAB> <TAB> if host . startswith ( "" [ "" ) and host . endswith ( "" ] "" ) : <TAB> <TAB> <TAB> host = host [ 1 : - 1 ] <TAB> <TAB> idx = dpynum . find ( "" . "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> screen = int ( dpynum [ idx + 1 : ] ) <TAB> <TAB> <TAB> dpynum = dpynum [ : idx ] <TAB> <TAB> else : <TAB> <TAB> <TAB> screen = 0 <TAB> except ( ValueError , UnicodeEncodeError ) : <TAB> <TAB> raise ValueError ( "" Invalid X11 display "" ) from None <TAB> return host , dpynum , screen ","if idx > = 0 : 
","if idx > = 0 :
",100.0,100.0,True
"def delete_all ( path ) : <TAB> ppath = os . getcwd ( ) <TAB> os . chdir ( path ) <TAB> for fn in glob . glob ( "" * "" ) : <TAB> <TAB> fn_full = os . path . join ( path , fn ) <TAB> <TAB> if os . path . isdir ( fn ) : <TAB> <TAB> <TAB> delete_all ( fn_full ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif fn . endswith ( "" .md "" ) : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> <TAB> elif DELETE_ALL_OLD : <TAB> <TAB> <TAB> os . remove ( fn_full ) <TAB> os . chdir ( ppath ) <TAB> os . rmdir ( path ) ","elif fn . endswith ( "" .png "" ) : 
","elif fn . endswith ( "" .py "" ) :
",83.03,70.17,False
"def _sync_get ( self , identifier , * args , * * kw ) : <TAB> self . _mutex . acquire ( ) <TAB> try : <TAB> <TAB> try : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . _values [ identifier ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB> <TAB> <TAB> <TAB> return value <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> self . _values [ identifier ] = value = self . creator ( identifier , * args , * * kw ) <TAB> <TAB> <TAB> return value <TAB> finally : <TAB> <TAB> self . _mutex . release ( ) ","if identifier in self . _values : 
","if identifier in self . _values :
",100.0,100.0,True
"def _query_fd ( self ) : <TAB> if self . stream is None : <TAB> <TAB> self . _last_stat = None , None <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> st = os . stat ( self . _filename ) <TAB> <TAB> except OSError : <TAB> <TAB> <TAB> e = sys . exc_info ( ) [ 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise <TAB> <TAB> <TAB> self . _last_stat = None , None <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _last_stat = st [ stat . ST_DEV ] , st [ stat . ST_INO ] ","if e . errno != errno . ENOENT : 
","if e . errno != errno . ENOENT :
",100.0,100.0,True
"def get_place_name ( self , place_handle ) : <TAB> """"""Obtain a place name"""""" <TAB> text = "" "" <TAB> if place_handle : <TAB> <TAB> place = self . dbstate . db . get_place_from_handle ( place_handle ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> place_title = place_displayer . display ( self . dbstate . db , place ) <TAB> <TAB> <TAB> if place_title != "" "" : <TAB> <TAB> <TAB> <TAB> if len ( place_title ) > 25 : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title [ : 24 ] + "" ... "" <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> text = place_title <TAB> return text ","if place : 
","if place :
",78.12,0.0,False
"def test_decoder_state ( self ) : <TAB> # Check that getstate() and setstate() handle the state properly <TAB> u = "" abc123 "" <TAB> for encoding in all_unicode_encodings : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . check_state_handling_decode ( encoding , u , u . encode ( encoding ) ) <TAB> <TAB> <TAB> self . check_state_handling_encode ( encoding , u , u . encode ( encoding ) ) ","if encoding not in broken_unicode_with_stateful : 
","if encoding not in ( "" getstate "" , "" setstate "" ) :
",49.81,18.8,False
"def cleanup ( self ) : <TAB> if os . path . exists ( self . meta_gui_dir ) : <TAB> <TAB> for f in os . listdir ( self . meta_gui_dir ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> os . remove ( os . path . join ( self . meta_gui_dir , f ) ) ","if os . path . splitext ( f ) [ 1 ] == "" .desktop "" : 
","if f . endswith ( "" .py "" ) and not self . check_key ( f ) :
",37.04,10.11,False
"def _have_applied_incense ( self ) : <TAB> for applied_item in inventory . applied_items ( ) . all ( ) : <TAB> <TAB> self . logger . info ( applied_item ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> mins = format_time ( applied_item . expire_ms * 1000 ) <TAB> <TAB> <TAB> self . logger . info ( <TAB> <TAB> <TAB> <TAB> "" Not applying incense, currently active:  %s ,  %s  minutes remaining "" , <TAB> <TAB> <TAB> <TAB> applied_item . item . name , <TAB> <TAB> <TAB> <TAB> mins , <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> self . logger . info ( "" "" ) <TAB> <TAB> <TAB> return False <TAB> return False ","if applied_item . expire_ms > 0 : 
","if applied_item . active :
",40.7,36.34,False
"def get_closest_point ( self , point ) : <TAB> point = to_point ( point ) <TAB> cp , cd = None , None <TAB> for p0 , p1 in iter_pairs ( self . pts , self . connected ) : <TAB> <TAB> diff = p1 - p0 <TAB> <TAB> l = diff . length <TAB> <TAB> d = diff / l <TAB> <TAB> pp = p0 + d * max ( 0 , min ( l , ( point - p0 ) . dot ( d ) ) ) <TAB> <TAB> dist = ( point - pp ) . length <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cp , cd = pp , dist <TAB> return cp ","if not cp or dist < cd : 
","if dist > cp :
",31.97,8.29,False
"def process_return ( lines ) : <TAB> for line in lines : <TAB> <TAB> m = re . fullmatch ( r "" (?P<param> \ w+) \ s+: \ s+(?P<type>[ \ w.]+) "" , line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Once this is in scanpydoc, we can use the fancy hover stuff <TAB> <TAB> <TAB> yield f ' ** { m [ "" param "" ] } ** : :class:`~ { m [ "" type "" ] } ` ' <TAB> <TAB> else : <TAB> <TAB> <TAB> yield line ","if m : 
","if m :
",78.12,0.0,False
"def _classify ( nodes_by_level ) : <TAB> missing , invalid , downloads = [ ] , [ ] , [ ] <TAB> for level in nodes_by_level : <TAB> <TAB> for node in level : <TAB> <TAB> <TAB> if node . binary == BINARY_MISSING : <TAB> <TAB> <TAB> <TAB> missing . append ( node ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> invalid . append ( node ) <TAB> <TAB> <TAB> elif node . binary in ( BINARY_UPDATE , BINARY_DOWNLOAD ) : <TAB> <TAB> <TAB> <TAB> downloads . append ( node ) <TAB> return missing , invalid , downloads ","elif node . binary == BINARY_INVALID : 
","elif node . binary in ( BINARY_INVALID , BINARY_UPDATE ) :
",49.28,24.6,False
"def safe_parse_date ( date_hdr ) : <TAB> """"""Parse a Date: or Received: header into a unix timestamp."""""" <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> date_hdr = date_hdr . split ( "" ; "" ) [ - 1 ] . strip ( ) <TAB> <TAB> msg_ts = long ( rfc822 . mktime_tz ( rfc822 . parsedate_tz ( date_hdr ) ) ) <TAB> <TAB> if ( msg_ts > ( time . time ( ) + 24 * 3600 ) ) or ( msg_ts < 1 ) : <TAB> <TAB> <TAB> return None <TAB> <TAB> else : <TAB> <TAB> <TAB> return msg_ts <TAB> except ( ValueError , TypeError , OverflowError ) : <TAB> <TAB> return None ","if "" ; "" in date_hdr : 
","if "" ; "" in date_hdr :
",100.0,100.0,True
"def _on_change ( self ) : <TAB> changed = False <TAB> self . save ( ) <TAB> for key , value in self . data . items ( ) : <TAB> <TAB> if isinstance ( value , bool ) : <TAB> <TAB> <TAB> if value : <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> if isinstance ( value , int ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> elif value is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> elif len ( value ) != 0 : <TAB> <TAB> <TAB> changed = True <TAB> <TAB> <TAB> break <TAB> self . _reset_button . disabled = not changed ","if value != 1 : 
","if value != 0 :
",64.48,53.73,False
"def _rewrite_prepend_append ( self , string , prepend , append = None ) : <TAB> if append is None : <TAB> <TAB> append = prepend <TAB> if not isinstance ( string , StringElem ) : <TAB> <TAB> string = StringElem ( string ) <TAB> string . sub . insert ( 0 , prepend ) <TAB> if unicode ( string ) . endswith ( u "" \n "" ) : <TAB> <TAB> # Try and remove the last character from the tree <TAB> <TAB> try : <TAB> <TAB> <TAB> lastnode = string . flatten ( ) [ - 1 ] <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> lastnode . sub [ - 1 ] = lastnode . sub [ - 1 ] . rstrip ( u "" \n "" ) <TAB> <TAB> except IndexError : <TAB> <TAB> <TAB> pass <TAB> <TAB> string . sub . append ( append + u "" \n "" ) <TAB> else : <TAB> <TAB> string . sub . append ( append ) <TAB> return string ","if isinstance ( lastnode . sub [ - 1 ] , unicode ) : 
","if lastnode . sub [ - 1 ] . startswith ( u "" \n "" ) :
",58.61,38.05,False
"def parse_indentless_sequence_entry ( self ) : <TAB> if self . check_token ( BlockEntryToken ) : <TAB> <TAB> token = self . get_token ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . states . append ( self . parse_indentless_sequence_entry ) <TAB> <TAB> <TAB> return self . parse_block_node ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . state = self . parse_indentless_sequence_entry <TAB> <TAB> <TAB> return self . process_empty_scalar ( token . end_mark ) <TAB> token = self . peek_token ( ) <TAB> event = SequenceEndEvent ( token . start_mark , token . start_mark ) <TAB> self . state = self . states . pop ( ) <TAB> return event ","if not self . check_token ( BlockEntryToken , KeyToken , ValueToken , BlockEndToken ) : 
","if self . check_token ( SequenceEndToken , BlockEntryToken ) :
",39.74,33.5,False
"def walk_directory ( directory , verbose = False ) : <TAB> """"""Iterates a directory's text files and their contents."""""" <TAB> for dir_path , _ , filenames in os . walk ( directory ) : <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> file_path = os . path . join ( dir_path , filename ) <TAB> <TAB> <TAB> if os . path . isfile ( file_path ) and not filename . startswith ( "" . "" ) : <TAB> <TAB> <TAB> <TAB> with io . open ( file_path , "" r "" , encoding = "" utf-8 "" ) as file : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> print ( "" Reading  {} "" . format ( filename ) ) <TAB> <TAB> <TAB> <TAB> <TAB> doc_text = file . read ( ) <TAB> <TAB> <TAB> <TAB> <TAB> yield filename , doc_text ","if verbose : 
","if verbose :
",78.12,0.0,False
"def set_bounds ( self , x , y , width , height ) : <TAB> if self . native : <TAB> <TAB> # Root level widgets may require vertical adjustment to <TAB> <TAB> # account for toolbars, etc. <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vertical_shift = self . frame . vertical_shift <TAB> <TAB> else : <TAB> <TAB> <TAB> vertical_shift = 0 <TAB> <TAB> self . native . Size = Size ( width , height ) <TAB> <TAB> self . native . Location = Point ( x , y + vertical_shift ) ","if self . interface . parent is None : 
","if self . frame :
",36.28,19.2,False
"def _check_x11 ( self , command = None , * , exc = None , exit_status = None , * * kwargs ) : <TAB> """"""Check requesting X11 forwarding"""""" <TAB> with ( yield from self . connect ( ) ) as conn : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with self . assertRaises ( exc ) : <TAB> <TAB> <TAB> <TAB> yield from _create_x11_process ( conn , command , * * kwargs ) <TAB> <TAB> else : <TAB> <TAB> <TAB> proc = yield from _create_x11_process ( conn , command , * * kwargs ) <TAB> <TAB> <TAB> yield from proc . wait ( ) <TAB> <TAB> <TAB> self . assertEqual ( proc . exit_status , exit_status ) <TAB> yield from conn . wait_closed ( ) ","if exc : 
","if exc :
",78.12,0.0,False
"def repr ( self ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> from infogami . infobase . utils import prepr <TAB> <TAB> <TAB> return prepr ( self . obj ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return repr ( self . obj ) <TAB> except : <TAB> <TAB> return "" failed "" <TAB> return render_template ( "" admin/memory/object "" , self . obj ) ","if isinstance ( self . obj , ( dict , web . threadeddict ) ) : 
","if isinstance ( self . obj , prepr ) :
",52.53,38.81,False
"def add ( self , tag , values ) : <TAB> if tag not in self . different : <TAB> <TAB> if tag not in self : <TAB> <TAB> <TAB> self [ tag ] = values <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . different . add ( tag ) <TAB> <TAB> <TAB> self [ tag ] = [ "" "" ] <TAB> self . counts [ tag ] + = 1 ","elif self [ tag ] != values : 
","elif self . counts [ tag ] == self . counts [ tag ] :
",31.8,12.45,False
"def _on_geturl ( self , event ) : <TAB> selected = self . _status_list . get_selected ( ) <TAB> if selected != - 1 : <TAB> <TAB> object_id = self . _status_list . GetItemData ( selected ) <TAB> <TAB> download_item = self . _download_list . get_item ( object_id ) <TAB> <TAB> url = download_item . url <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> clipdata = wx . TextDataObject ( ) <TAB> <TAB> <TAB> clipdata . SetText ( url ) <TAB> <TAB> <TAB> wx . TheClipboard . Open ( ) <TAB> <TAB> <TAB> wx . TheClipboard . SetData ( clipdata ) <TAB> <TAB> <TAB> wx . TheClipboard . Close ( ) ","if not wx . TheClipboard . IsOpened ( ) : 
","if url != "" "" :
",26.34,5.09,False
"def escape2null ( text ) : <TAB> """"""Return a string with escape-backslashes converted to nulls."""""" <TAB> parts = [ ] <TAB> start = 0 <TAB> while True : <TAB> <TAB> found = text . find ( "" \\ "" , start ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> parts . append ( text [ start : ] ) <TAB> <TAB> <TAB> return "" "" . join ( parts ) <TAB> <TAB> parts . append ( text [ start : found ] ) <TAB> <TAB> parts . append ( "" \x00 "" + text [ found + 1 : found + 2 ] ) <TAB> <TAB> start = found + 2<TAB> # skip character after escape ","if found == - 1 : 
","if found == - 1 :
",100.0,100.0,True
def _process_inner_views ( self ) : <TAB> for view in self . baseviews : <TAB> <TAB> for inner_class in view . get_uninit_inner_views ( ) : <TAB> <TAB> <TAB> for v in self . baseviews : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> view . get_init_inner_views ( ) . append ( v ) ,"if isinstance ( v , inner_class ) and v not in view . get_init_inner_views ( ) : 
","if inner_class in v . get_uninit_inner_views ( ) :
",38.39,33.06,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> self . set_url ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . set_app_version_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 26 : <TAB> <TAB> <TAB> self . set_method ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 34 : <TAB> <TAB> <TAB> self . set_queue ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 18 : 
","if tt == 18 :
",100.0,100.0,True
"def test_sample_output ( ) : <TAB> comment = "" SAMPLE OUTPUT "" <TAB> skip_files = [ "" __init__.py "" ] <TAB> errors = [ ] <TAB> for _file in sorted ( MODULE_PATH . iterdir ( ) ) : <TAB> <TAB> if _file . suffix == "" .py "" and _file . name not in skip_files : <TAB> <TAB> <TAB> with _file . open ( ) as f : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> errors . append ( ( comment , _file ) ) <TAB> if errors : <TAB> <TAB> line = "" Missing sample error(s) detected! \n \n "" <TAB> <TAB> for error in errors : <TAB> <TAB> <TAB> line + = "" ` {} ` is not in module ` {} ` \n "" . format ( * error ) <TAB> <TAB> print ( line [ : - 1 ] ) <TAB> <TAB> assert False ","if comment not in f . read ( ) : 
","if comment not in f . read ( ) :
",100.0,100.0,True
"def _get_planner ( name , path , source ) : <TAB> for klass in _planners : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> LOG . debug ( "" %r  accepted  %r  (filename  %r ) "" , klass , name , path ) <TAB> <TAB> <TAB> return klass <TAB> <TAB> LOG . debug ( "" %r  rejected  %r "" , klass , name ) <TAB> raise ansible . errors . AnsibleError ( NO_METHOD_MSG + repr ( invocation ) ) ","if klass . detect ( path , source ) : 
","if klass . matches ( name , path ) :
",57.45,22.09,False
"def _to_string_infix ( self , ostream , idx , verbose ) : <TAB> if verbose : <TAB> <TAB> ostream . write ( ""  ,  "" ) <TAB> else : <TAB> <TAB> hasConst = not ( <TAB> <TAB> <TAB> self . _const . __class__ in native_numeric_types and self . _const == 0 <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> idx - = 1 <TAB> <TAB> _l = self . _coef [ id ( self . _args [ idx ] ) ] <TAB> <TAB> _lt = _l . __class__ <TAB> <TAB> if _lt is _NegationExpression or ( _lt in native_numeric_types and _l < 0 ) : <TAB> <TAB> <TAB> ostream . write ( ""  -  "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> ostream . write ( ""  +  "" ) ","if hasConst : 
","if hasConst :
",78.12,0.0,False
"def cluster_info_query ( self ) : <TAB> if self . _major_version > = 90600 : <TAB> <TAB> extra = ( <TAB> <TAB> <TAB> "" , CASE WHEN latest_end_lsn IS NULL THEN NULL ELSE received_tli END, "" <TAB> <TAB> <TAB> ""  slot_name, conninfo FROM pg_catalog.pg_stat_get_wal_receiver() "" <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> extra = "" timeline_id "" + extra + "" , pg_catalog.pg_control_checkpoint() "" <TAB> <TAB> else : <TAB> <TAB> <TAB> extra = "" 0 "" + extra <TAB> else : <TAB> <TAB> extra = "" 0, NULL, NULL, NULL "" <TAB> return ( "" SELECT  "" + self . TL_LSN + "" ,  {2} "" ) . format ( <TAB> <TAB> self . wal_name , self . lsn_name , extra <TAB> ) ","if self . role == "" standby_leader "" : 
","if self . _major_version == 90600 :
",37.05,17.42,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> self . country = kwargs . pop ( "" country "" ) <TAB> self . fields_needed = kwargs . pop ( "" fields_needed "" , [ ] ) <TAB> super ( DynamicManagedAccountForm , self ) . __init__ ( * args , * * kwargs ) <TAB> # build our form using the country specific fields and falling <TAB> # back to our default set <TAB> for f in self . fields_needed : <TAB> <TAB> if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :<TAB> # pragma: no branch <TAB> <TAB> <TAB> field_name , field = FIELDS_BY_COUNTRY [ self . country ] [ f ] <TAB> <TAB> <TAB> self . fields [ field_name ] = field ","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) : 
","if f in FIELDS_BY_COUNTRY . get ( self . country , { } ) :
",100.0,100.0,True
"def delete_map ( self , query = None ) : <TAB> query_map = self . interpolated_map ( query = query ) <TAB> for alias , drivers in six . iteritems ( query_map . copy ( ) ) : <TAB> <TAB> for driver , vms in six . iteritems ( drivers . copy ( ) ) : <TAB> <TAB> <TAB> for vm_name , vm_details in six . iteritems ( vms . copy ( ) ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> query_map [ alias ] [ driver ] . pop ( vm_name ) <TAB> <TAB> <TAB> if not query_map [ alias ] [ driver ] : <TAB> <TAB> <TAB> <TAB> query_map [ alias ] . pop ( driver ) <TAB> <TAB> if not query_map [ alias ] : <TAB> <TAB> <TAB> query_map . pop ( alias ) <TAB> return query_map ","if vm_details == "" Absent "" : 
","if vm_details [ "" vm_name "" ] == vm_name :
",35.05,18.84,False
"def on_strokes_edited ( self ) : <TAB> strokes = self . _strokes ( ) <TAB> if strokes : <TAB> <TAB> translation = self . _engine . raw_lookup ( strokes ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fmt = _ ( "" {strokes}  maps to  {translation} "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> fmt = _ ( "" {strokes}  is not in the dictionary "" ) <TAB> <TAB> info = self . _format_label ( fmt , ( strokes , ) , translation ) <TAB> else : <TAB> <TAB> info = "" "" <TAB> self . strokes_info . setText ( info ) ","if translation is not None : 
","if translation :
",29.58,0.0,False
"def release ( self ) : <TAB> tid = _thread . get_ident ( ) <TAB> with self . lock : <TAB> <TAB> if self . owner != tid : <TAB> <TAB> <TAB> raise RuntimeError ( "" cannot release un-acquired lock "" ) <TAB> <TAB> assert self . count > 0 <TAB> <TAB> self . count - = 1 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . owner = None <TAB> <TAB> <TAB> if self . waiters : <TAB> <TAB> <TAB> <TAB> self . waiters - = 1 <TAB> <TAB> <TAB> <TAB> self . wakeup . release ( ) ","if self . count == 0 : 
","if self . count == 0 :
",100.0,100.0,True
"def _cat_blob ( self , gcs_uri ) : <TAB> """""":py:meth:`cat_file`, minus decompression."""""" <TAB> blob = self . _get_blob ( gcs_uri ) <TAB> if not blob : <TAB> <TAB> return<TAB> # don't cat nonexistent files <TAB> start = 0 <TAB> while True : <TAB> <TAB> end = start + _CAT_CHUNK_SIZE <TAB> <TAB> try : <TAB> <TAB> <TAB> chunk = blob . download_as_string ( start = start , end = end ) <TAB> <TAB> except google . api_core . exceptions . RequestRangeNotSatisfiable : <TAB> <TAB> <TAB> return <TAB> <TAB> yield chunk <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> start = end ","if len ( chunk ) < _CAT_CHUNK_SIZE : 
","if not chunk :
",26.99,2.22,False
"def device_iter ( * * kwargs ) : <TAB> for dev in backend . enumerate_devices ( ) : <TAB> <TAB> d = Device ( dev , backend ) <TAB> <TAB> tests = ( val == _try_getattr ( d , key ) for key , val in kwargs . items ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> yield d ","if _interop . _all ( tests ) and ( custom_match is None or custom_match ( d ) ) : 
","if tests :
",25.36,0.0,False
"def _get_vtkjs ( self ) : <TAB> if self . _vtkjs is None and self . object is not None : <TAB> <TAB> if isinstance ( self . object , string_types ) and self . object . endswith ( "" .vtkjs "" ) : <TAB> <TAB> <TAB> if isfile ( self . object ) : <TAB> <TAB> <TAB> <TAB> with open ( self . object , "" rb "" ) as f : <TAB> <TAB> <TAB> <TAB> <TAB> vtkjs = f . read ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data_url = urlopen ( self . object ) <TAB> <TAB> <TAB> <TAB> vtkjs = data_url . read ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> vtkjs = self . object . read ( ) <TAB> <TAB> self . _vtkjs = vtkjs <TAB> return self . _vtkjs ","elif hasattr ( self . object , "" read "" ) : 
","elif isfile ( self . object ) :
",42.47,25.92,False
"def _execute_with_error ( command , error , message ) : <TAB> try : <TAB> <TAB> cli . invocation = cli . invocation_cls ( <TAB> <TAB> <TAB> cli_ctx = cli , <TAB> <TAB> <TAB> parser_cls = cli . parser_cls , <TAB> <TAB> <TAB> commands_loader_cls = cli . commands_loader_cls , <TAB> <TAB> <TAB> help_cls = cli . help_cls , <TAB> <TAB> ) <TAB> <TAB> cli . invocation . execute ( command . split ( ) ) <TAB> except CLIError as ex : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise AssertionError ( <TAB> <TAB> <TAB> <TAB> "" {} \n Expected:  {} \n Actual:  {} "" . format ( message , error , ex ) <TAB> <TAB> <TAB> ) <TAB> <TAB> return <TAB> except Exception as ex : <TAB> <TAB> raise ex <TAB> raise AssertionError ( "" exception not raised for  ' {0} ' "" . format ( message ) ) ","if error not in str ( ex ) : 
","if not _is_mismatched_error ( ex ) :
",50.14,24.38,False
"def ray_intersection ( self , p , line ) : <TAB> p = Vector ( center ( line . sites ) ) <TAB> min_r = BIG_FLOAT <TAB> nearest = None <TAB> for v_i , v_j in self . edges : <TAB> <TAB> bound = LineEquation2D . from_two_points ( v_i , v_j ) <TAB> <TAB> intersection = bound . intersect_with_line ( line ) <TAB> <TAB> if intersection is not None : <TAB> <TAB> <TAB> r = ( p - intersection ) . length <TAB> <TAB> <TAB> # info(""INT: [%s - %s] X [%s] => %s (%s)"", v_i, v_j, line, intersection, r) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> nearest = intersection <TAB> <TAB> <TAB> <TAB> min_r = r <TAB> return nearest ","if r < min_r : 
","if r < min_r :
",100.0,100.0,True
"def CalculateChecksum ( data ) : <TAB> # The checksum is just a sum of all the bytes. I swear. <TAB> if isinstance ( data , bytearray ) : <TAB> <TAB> total = sum ( data ) <TAB> elif isinstance ( data , bytes ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Python 2 bytes (str) index as single-character strings. <TAB> <TAB> <TAB> total = sum ( map ( ord , data ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Python 3 bytes index as numbers (and PY2 empty strings sum() to 0) <TAB> <TAB> <TAB> total = sum ( data ) <TAB> else : <TAB> <TAB> # Unicode strings (should never see?) <TAB> <TAB> total = sum ( map ( ord , data ) ) <TAB> return total & 0xFFFFFFFF ","if data and isinstance ( data [ 0 ] , bytes ) : 
","if PY2 :
",25.66,0.0,False
"def __mul__ ( self , other : Union [ "" Tensor "" , float ] ) - > "" Tensor "" : <TAB> if isinstance ( other , Tensor ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> errstr = ( <TAB> <TAB> <TAB> <TAB> f "" Given backens are inconsistent. Found  ' { self . backend . name } ' "" <TAB> <TAB> <TAB> <TAB> f "" and  ' { other . backend . name } ' "" <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> raise ValueError ( errstr ) <TAB> <TAB> other = other . array <TAB> array = self . backend . multiply ( self . array , other ) <TAB> return Tensor ( array , backend = self . backend ) ","if self . backend . name != other . backend . name : 
","if self . backend . name != other . backend . name :
",100.0,100.0,True
"def next_item ( self , direction ) : <TAB> """"""Selects next menu item, based on self._direction"""""" <TAB> start , i = - 1 , 0 <TAB> try : <TAB> <TAB> start = self . items . index ( self . _selected ) <TAB> <TAB> i = start + direction <TAB> except : <TAB> <TAB> pass <TAB> while True : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Cannot find valid menu item <TAB> <TAB> <TAB> self . select ( start ) <TAB> <TAB> <TAB> break <TAB> <TAB> if i > = len ( self . items ) : <TAB> <TAB> <TAB> i = 0 <TAB> <TAB> <TAB> continue <TAB> <TAB> if i < 0 : <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> continue <TAB> <TAB> if self . select ( i ) : <TAB> <TAB> <TAB> break <TAB> <TAB> i + = direction <TAB> <TAB> if start < 0 : <TAB> <TAB> <TAB> start = 0 ","if i == start : 
","if i == start :
",100.0,100.0,True
"def resolve_none ( self , data ) : <TAB> # replace None to '_' <TAB> for tok_idx in range ( len ( data ) ) : <TAB> <TAB> for feat_idx in range ( len ( data [ tok_idx ] ) ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data [ tok_idx ] [ feat_idx ] = "" _ "" <TAB> return data ","if data [ tok_idx ] [ feat_idx ] is None : 
","if data [ tok_idx ] [ feat_idx ] is None :
",100.0,100.0,True
"def distinct ( expr , * on ) : <TAB> fields = frozenset ( expr . fields ) <TAB> _on = [ ] <TAB> append = _on . append <TAB> for n in on : <TAB> <TAB> if isinstance ( n , Field ) : <TAB> <TAB> <TAB> if n . _child . isidentical ( expr ) : <TAB> <TAB> <TAB> <TAB> n = n . _name <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> if not isinstance ( n , _strtypes ) : <TAB> <TAB> <TAB> raise TypeError ( "" on must be a name or field, not:  {0} "" . format ( n ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ValueError ( "" {0}  is not a field of  {1} "" . format ( n , expr ) ) <TAB> <TAB> append ( n ) <TAB> return Distinct ( expr , tuple ( _on ) ) ","elif n not in fields : 
","if n not in fields :
",67.32,75.98,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . mutable_cost ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 24 : <TAB> <TAB> <TAB> self . add_version ( d . getVarInt64 ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 0 : <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 10 : 
","if tt == 10 :
",100.0,100.0,True
"def func_std_string ( func_name ) :<TAB> # match what old profile produced <TAB> if func_name [ : 2 ] == ( "" ~ "" , 0 ) : <TAB> <TAB> # special case for built-in functions <TAB> <TAB> name = func_name [ 2 ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" { %s } "" % name [ 1 : - 1 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return name <TAB> else : <TAB> <TAB> return "" %s : %d ( %s ) "" % func_name ","if name . startswith ( "" < "" ) and name . endswith ( "" > "" ) : 
","if name [ : 1 ] == "" $ "" :
",30.87,4.75,False
"def f ( ) : <TAB> try : <TAB> <TAB> # Intra-buffer read then buffer-flushing read <TAB> <TAB> for n in cycle ( [ 1 , 19 ] ) : <TAB> <TAB> <TAB> s = bufio . read ( n ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> # list.append() is atomic <TAB> <TAB> <TAB> results . append ( s ) <TAB> except Exception as e : <TAB> <TAB> errors . append ( e ) <TAB> <TAB> raise ","if not s : 
","if s is None :
",29.25,14.06,False
"def stop ( self ) : <TAB> # Try to shut the connection down, but if we get any sort of <TAB> # errors, go ahead and ignore them.. as we're shutting down anyway <TAB> try : <TAB> <TAB> self . rpcserver . stop ( ) <TAB> <TAB> if self . backend_rpcserver : <TAB> <TAB> <TAB> self . backend_rpcserver . stop ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . cluster_rpcserver . stop ( ) <TAB> except Exception : <TAB> <TAB> pass <TAB> if self . coordination : <TAB> <TAB> try : <TAB> <TAB> <TAB> coordination . COORDINATOR . stop ( ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> pass <TAB> super ( Service , self ) . stop ( graceful = True ) ","if self . cluster_rpcserver : 
","if self . cluster_rpcserver :
",100.0,100.0,True
"def download ( cls , architecture , path = "" ./ "" ) : <TAB> if cls . sanity_check ( architecture ) : <TAB> <TAB> architecture_file = download_file ( <TAB> <TAB> <TAB> cls . architecture_map [ architecture ] , directory = path <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return None <TAB> <TAB> print ( "" Coreml model  {}  is saved in [ {} ] "" . format ( architecture , path ) ) <TAB> <TAB> return architecture_file <TAB> else : <TAB> <TAB> return None ","if not architecture_file : 
","if architecture_file is None :
",29.25,27.78,False
"def opps_output_converter ( kpt_list ) : <TAB> kpts = [ ] <TAB> mpii_keys = to_opps_converter . keys ( ) <TAB> for mpii_idx in range ( 0 , 16 ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> model_idx = to_opps_converter [ mpii_idx ] <TAB> <TAB> <TAB> x , y = kpt_list [ model_idx ] <TAB> <TAB> <TAB> if x < 0 or y < 0 : <TAB> <TAB> <TAB> <TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> kpts + = [ x , y , 1.0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> kpts + = [ 0.0 , 0.0 , - 1.0 ] <TAB> return kpts ","if mpii_idx in mpii_keys : 
","if mpii_idx in mpii_keys :
",100.0,100.0,True
"def _get_headers ( self , headers = None ) : <TAB> request_headers = headers or { } <TAB> # Auth headers if access_token is present <TAB> if self . _client . client . config : <TAB> <TAB> config = self . _client . client . config <TAB> <TAB> if "" Authorization "" not in request_headers and config . token : <TAB> <TAB> <TAB> request_headers . update ( <TAB> <TAB> <TAB> <TAB> { <TAB> <TAB> <TAB> <TAB> <TAB> "" Authorization "" : "" {} {} "" . format ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> config . authentication_type , config . token <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> } <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> request_headers . update ( { config . header : config . header_service } ) <TAB> return request_headers ","if config . header and config . header_service : 
","if config . header_service :
",53.72,56.47,False
"def get_last_traded_prices ( cls , trading_pairs : List [ str ] ) - > Dict [ str , float ] : <TAB> results = dict ( ) <TAB> async with aiohttp . ClientSession ( ) as client : <TAB> <TAB> resp = await client . get ( f "" { constants . REST_URL } /tickers "" ) <TAB> <TAB> resp_json = await resp . json ( ) <TAB> <TAB> for trading_pair in trading_pairs : <TAB> <TAB> <TAB> resp_record = [ <TAB> <TAB> <TAB> <TAB> o <TAB> <TAB> <TAB> <TAB> for o in resp_json <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ] [ 0 ] <TAB> <TAB> <TAB> results [ trading_pair ] = float ( resp_record [ "" price "" ] ) <TAB> return results ","if o [ "" symbol "" ] == convert_to_exchange_trading_pair ( trading_pair ) 
","if o [ "" id "" ] == trading_pair
",48.3,20.86,False
"def reset_two_factor_hotp ( ) : <TAB> uid = request . form [ "" uid "" ] <TAB> otp_secret = request . form . get ( "" otp_secret "" , None ) <TAB> if otp_secret : <TAB> <TAB> user = Journalist . query . get ( uid ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) <TAB> <TAB> db . session . commit ( ) <TAB> <TAB> return redirect ( url_for ( "" admin.new_user_two_factor "" , uid = uid ) ) <TAB> else : <TAB> <TAB> return render_template ( "" admin_edit_hotp_secret.html "" , uid = uid ) ","if not validate_hotp_secret ( user , otp_secret ) : 
","if user and user . secret != otp_secret :
",26.71,12.13,False
"def ctx_for_video ( self , vurl ) : <TAB> "" Get a context dict for a given video URL "" <TAB> ctx = self . get_context_dict ( ) <TAB> for portal , match , context_fn in self . PORTALS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> ctx . update ( context_fn ( vurl ) ) <TAB> <TAB> <TAB> <TAB> ctx [ "" portal "" ] = portal <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> continue <TAB> return ctx ","if match . search ( vurl ) : 
","if match . match ( vurl ) :
",75.22,50.0,False
"def get ( self ) : <TAB> name = request . args . get ( "" filename "" ) <TAB> if name is not None : <TAB> <TAB> opts = dict ( ) <TAB> <TAB> opts [ "" type "" ] = "" episode "" <TAB> <TAB> result = guessit ( name , options = opts ) <TAB> <TAB> res = dict ( ) <TAB> <TAB> if "" episode "" in result : <TAB> <TAB> <TAB> res [ "" episode "" ] = result [ "" episode "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" episode "" ] = 0 <TAB> <TAB> if "" season "" in result : <TAB> <TAB> <TAB> res [ "" season "" ] = result [ "" season "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> res [ "" season "" ] = 0 <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> res [ "" subtitle_language "" ] = str ( result [ "" subtitle_language "" ] ) <TAB> <TAB> return jsonify ( data = res ) <TAB> else : <TAB> <TAB> return "" "" , 400 ","if "" subtitle_language "" in result : 
","if "" subtitle_language "" in result :
",100.0,100.0,True
"def package_files ( package_path , directory_name ) : <TAB> paths = [ ] <TAB> directory_path = os . path . join ( package_path , directory_name ) <TAB> for ( path , directories , filenames ) in os . walk ( directory_path ) : <TAB> <TAB> relative_path = os . path . relpath ( path , package_path ) <TAB> <TAB> for filename in filenames : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> paths . append ( os . path . join ( relative_path , filename ) ) <TAB> return paths ","if filename [ 0 ] == "" . "" : 
","if filename . endswith ( "" .py "" ) :
",33.0,11.73,False
"def parse_simple ( d , data ) : <TAB> units = { } <TAB> for v in data [ d ] : <TAB> <TAB> key = v [ "" name "" ] <TAB> <TAB> if not key : <TAB> <TAB> <TAB> continue <TAB> <TAB> key_to_insert = make_key ( key ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> index = 2 <TAB> <TAB> <TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB> <TAB> <TAB> while tmp in units : <TAB> <TAB> <TAB> <TAB> index + = 1 <TAB> <TAB> <TAB> <TAB> tmp = f "" { key_to_insert } _ { index } "" <TAB> <TAB> <TAB> key_to_insert = tmp <TAB> <TAB> units [ key_to_insert ] = v [ "" id "" ] <TAB> return units ","if key_to_insert in units : 
","if len ( key_to_insert ) > 2 :
",27.63,34.48,False
"def parse_clademodelc ( branch_type_no , line_floats , site_classes ) : <TAB> """"""Parse results specific to the clade model C."""""" <TAB> if not site_classes or len ( line_floats ) == 0 : <TAB> <TAB> return <TAB> for n in range ( len ( line_floats ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> site_classes [ n ] [ "" branch types "" ] = { } <TAB> <TAB> site_classes [ n ] [ "" branch types "" ] [ branch_type_no ] = line_floats [ n ] <TAB> return site_classes ","if site_classes [ n ] . get ( "" branch types "" ) is None : 
","if "" branch types "" not in site_classes [ n ] :
",46.94,41.82,False
"def track_modules ( self , * modules ) : <TAB> """"""Add module names to the tracked list."""""" <TAB> already_tracked = self . session . GetParameter ( "" autodetect_build_local_tracked "" ) or [ ] <TAB> needed = set ( modules ) <TAB> if not needed . issubset ( already_tracked ) : <TAB> <TAB> needed . update ( already_tracked ) <TAB> <TAB> with self . session as session : <TAB> <TAB> <TAB> session . SetParameter ( "" autodetect_build_local_tracked "" , needed ) <TAB> <TAB> <TAB> for module_name in modules : <TAB> <TAB> <TAB> <TAB> module_obj = self . GetModuleByName ( module_name ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> # Clear the module's profile. This will force it to <TAB> <TAB> <TAB> <TAB> <TAB> # reload a new profile. <TAB> <TAB> <TAB> <TAB> <TAB> module_obj . profile = None ","if module_obj : 
","if module_obj :
",78.12,100.0,True
"def set_job_on_hold ( self , value , blocking = True ) : <TAB> trigger = False <TAB> # don't run any locking code beyond this... <TAB> if not self . _job_on_hold . acquire ( blocking = blocking ) : <TAB> <TAB> return False <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _job_on_hold . set ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . _job_on_hold . clear ( ) <TAB> <TAB> <TAB> if self . _job_on_hold . counter == 0 : <TAB> <TAB> <TAB> <TAB> trigger = True <TAB> finally : <TAB> <TAB> self . _job_on_hold . release ( ) <TAB> # locking code is now safe to run again <TAB> if trigger : <TAB> <TAB> self . _continue_sending ( ) <TAB> return True ","if value : 
","if value :
",78.12,0.0,False
"def moveToThreadNext ( self ) : <TAB> """"""Move a position to threadNext position."""""" <TAB> p = self <TAB> if p . v : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> p . moveToFirstChild ( ) <TAB> <TAB> elif p . hasNext ( ) : <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> while p : <TAB> <TAB> <TAB> <TAB> if p . hasNext ( ) : <TAB> <TAB> <TAB> <TAB> <TAB> p . moveToNext ( ) <TAB> <TAB> <TAB> <TAB> <TAB> break<TAB> # found <TAB> <TAB> <TAB> <TAB> p . moveToParent ( ) <TAB> <TAB> <TAB> # not found. <TAB> return p ","if p . v . children : 
","if p . hasNext ( ) :
",40.31,26.27,False
"def best_image ( width , height ) : <TAB> # A heuristic for finding closest sized image to required size. <TAB> image = images [ 0 ] <TAB> for img in images : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Exact match always used <TAB> <TAB> <TAB> return img <TAB> <TAB> elif img . width > = width and img . width * img . height > image . width * image . height : <TAB> <TAB> <TAB> # At least wide enough, and largest area <TAB> <TAB> <TAB> image = img <TAB> return image ","if img . width == width and img . height == height : 
","if img . width == 0 and img . height == 0 :
",45.34,66.06,False
"def _check_input_types ( self ) : <TAB> if len ( self . base_features ) == 0 : <TAB> <TAB> return True <TAB> input_types = self . primitive . input_types <TAB> if input_types is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> input_types = [ input_types ] <TAB> <TAB> for t in input_types : <TAB> <TAB> <TAB> zipped = list ( zip ( t , self . base_features ) ) <TAB> <TAB> <TAB> if all ( [ issubclass ( f . variable_type , v ) for v , f in zipped ] ) : <TAB> <TAB> <TAB> <TAB> return True <TAB> else : <TAB> <TAB> return True <TAB> return False ","if type ( input_types [ 0 ] ) != list : 
","if not isinstance ( input_types , list ) :
",27.64,21.24,False
"def get_result ( self ) : <TAB> result_list = [ ] <TAB> exc_info = None <TAB> for f in self . children : <TAB> <TAB> try : <TAB> <TAB> <TAB> result_list . append ( f . get_result ( ) ) <TAB> <TAB> except Exception as e : <TAB> <TAB> <TAB> if exc_info is None : <TAB> <TAB> <TAB> <TAB> exc_info = sys . exc_info ( ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> app_log . error ( "" Multiple exceptions in yield list "" , exc_info = True ) <TAB> if exc_info is not None : <TAB> <TAB> raise_exc_info ( exc_info ) <TAB> if self . keys is not None : <TAB> <TAB> return dict ( zip ( self . keys , result_list ) ) <TAB> else : <TAB> <TAB> return list ( result_list ) ","if not isinstance ( e , self . quiet_exceptions ) : 
","if len ( result_list ) > 1 :
",26.37,4.65,False
"def _update_learning_params ( self ) : <TAB> model = self . model <TAB> hparams = self . hparams <TAB> fd = self . runner . feed_dict <TAB> step_num = self . step_num <TAB> if hparams . model_type == "" resnet_tf "" : <TAB> <TAB> if step_num < hparams . lrn_step : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 10 <TAB> <TAB> elif step_num < 35000 : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 100 <TAB> <TAB> else : <TAB> <TAB> <TAB> lrn_rate = hparams . mom_lrn / 1000 <TAB> <TAB> fd [ model . lrn_rate ] = lrn_rate ","elif step_num < 30000 : 
","elif step_num < 10000 :
",64.48,64.35,False
"def topic_exists ( self , arn ) : <TAB> response = self . _conn . get_all_topics ( ) <TAB> topics = response [ "" ListTopicsResponse "" ] [ "" ListTopicsResult "" ] [ "" Topics "" ] <TAB> current_topics = [ ] <TAB> if len ( topics ) > 0 : <TAB> <TAB> for topic in topics : <TAB> <TAB> <TAB> topic_arn = topic [ "" TopicArn "" ] <TAB> <TAB> <TAB> current_topics . append ( topic_arn ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if arn in current_topics : 
","if arn in current_topics :
",100.0,100.0,True
"def assertStartsWith ( self , expectedPrefix , text , msg = None ) : <TAB> if not text . startswith ( expectedPrefix ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> text = text [ : len ( expectedPrefix ) + 5 ] + "" ... "" <TAB> <TAB> standardMsg = "" {}  not found at the start of  {} "" . format ( <TAB> <TAB> <TAB> repr ( expectedPrefix ) , repr ( text ) <TAB> <TAB> ) <TAB> <TAB> self . fail ( self . _formatMessage ( msg , standardMsg ) ) ","if len ( expectedPrefix ) + 5 < len ( text ) : 
","if msg is None :
",25.89,2.56,False
"def validate_memory ( self , value ) : <TAB> for k , v in value . viewitems ( ) : <TAB> <TAB> if v is None :<TAB> # use NoneType to unset a value <TAB> <TAB> <TAB> continue <TAB> <TAB> if not re . match ( PROCTYPE_MATCH , k ) : <TAB> <TAB> <TAB> raise serializers . ValidationError ( "" Process types can only contain [a-z] "" ) <TAB> <TAB> if not re . match ( MEMLIMIT_MATCH , str ( v ) ) : <TAB> <TAB> <TAB> raise serializers . ValidationError ( <TAB> <TAB> <TAB> <TAB> "" Limit format: <number><unit>, where unit = B, K, M or G "" <TAB> <TAB> <TAB> ) <TAB> return value ","if v is None : 
","if v is None :
",100.0,100.0,True
"def open ( self ) - > "" KeyValueJsonDb "" : <TAB> """"""Create a new data base or open existing one"""""" <TAB> if os . path . exists ( self . _name ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise IOError ( "" %s  exists and is not a file "" % self . _name ) <TAB> <TAB> try : <TAB> <TAB> <TAB> with open ( self . _name , "" r "" ) as _in : <TAB> <TAB> <TAB> <TAB> self . set_records ( json . load ( _in ) ) <TAB> <TAB> except json . JSONDecodeError : <TAB> <TAB> <TAB> # file corrupted, reset it. <TAB> <TAB> <TAB> self . commit ( ) <TAB> else : <TAB> <TAB> # make sure path exists <TAB> <TAB> mkpath ( os . path . dirname ( self . _name ) ) <TAB> <TAB> self . commit ( ) <TAB> return self ","if not os . path . isfile ( self . _name ) : 
","if not os . path . isfile ( self . _name ) :
",100.0,100.0,True
"def _calculate ( self ) : <TAB> before = self . before . data <TAB> after = self . after . data <TAB> self . deleted = { } <TAB> self . updated = { } <TAB> self . created = after . copy ( ) <TAB> for path , f in before . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . deleted [ path ] = f <TAB> <TAB> <TAB> continue <TAB> <TAB> del self . created [ path ] <TAB> <TAB> if f . mtime < after [ path ] . mtime : <TAB> <TAB> <TAB> self . updated [ path ] = after [ path ] ","if path not in after : 
","if path not in self . created :
",54.25,36.56,False
"def cache_sqs_queues_across_accounts ( ) - > bool : <TAB> function : str = f "" { __name__ } . { sys . _getframe ( ) . f_code . co_name } "" <TAB> # First, get list of accounts <TAB> accounts_d : list = async_to_sync ( get_account_id_to_name_mapping ) ( ) <TAB> # Second, call tasks to enumerate all the roles across all accounts <TAB> for account_id in accounts_d . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> <TAB> else : <TAB> <TAB> <TAB> if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) : <TAB> <TAB> <TAB> <TAB> cache_sqs_queues_for_account . delay ( account_id ) <TAB> stats . count ( f "" { function } .success "" ) <TAB> return True ","if config . get ( "" environment "" ) == "" prod "" : 
","if account_id in config . get ( "" celery.test_account_ids "" , [ ] ) :
",49.42,17.86,False
"def remove ( self , path , config = None , error_on_path = False , defaults = None ) : <TAB> if not path : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> return <TAB> if config is not None or defaults is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> config = self . _config <TAB> <TAB> if defaults is None : <TAB> <TAB> <TAB> defaults = dict ( self . _map . parents ) <TAB> <TAB> chain = HierarchicalChainMap ( config , defaults ) <TAB> else : <TAB> <TAB> chain = self . _map <TAB> try : <TAB> <TAB> chain . del_by_path ( path ) <TAB> <TAB> self . _mark_dirty ( ) <TAB> except KeyError : <TAB> <TAB> if error_on_path : <TAB> <TAB> <TAB> raise NoSuchSettingsPath ( ) <TAB> <TAB> pass ","if config is None : 
","if config is None :
",100.0,100.0,True
"def PopulateProjectId ( project_id = None ) : <TAB> """"""Fills in a project_id from the boto config file if one is not provided."""""" <TAB> if not project_id : <TAB> <TAB> default_id = boto . config . get_value ( "" GSUtil "" , "" default_project_id "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProjectIdException ( "" MissingProjectId "" ) <TAB> <TAB> return default_id <TAB> return project_id ","if not default_id : 
","if default_id is None :
",29.25,27.78,False
"def set ( self , name , value ) : <TAB> with self . _object_cache_lock : <TAB> <TAB> old_value = self . _object_cache . get ( name ) <TAB> <TAB> ret = not old_value or int ( old_value . metadata . resource_version ) < int ( <TAB> <TAB> <TAB> value . metadata . resource_version <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _object_cache [ name ] = value <TAB> return ret , old_value ","if ret : 
","if ret :
",78.12,0.0,False
"def remove ( self , url ) : <TAB> try : <TAB> <TAB> i = self . items . index ( url ) <TAB> except ( ValueError , IndexError ) : <TAB> <TAB> pass <TAB> else : <TAB> <TAB> was_selected = i in self . selectedindices ( ) <TAB> <TAB> self . list . delete ( i ) <TAB> <TAB> del self . items [ i ] <TAB> <TAB> if not self . items : <TAB> <TAB> <TAB> self . mp . hidepanel ( self . name ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if i > = len ( self . items ) : <TAB> <TAB> <TAB> <TAB> i = len ( self . items ) - 1 <TAB> <TAB> <TAB> self . list . select_set ( i ) ","elif was_selected : 
","if was_selected :
",35.87,66.87,False
"def add_directory_csv_files ( dir_path , paths = None ) : <TAB> if not paths : <TAB> <TAB> paths = [ ] <TAB> for p in listdir ( dir_path ) : <TAB> <TAB> path = join ( dir_path , p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # call recursively for each dir <TAB> <TAB> <TAB> paths = add_directory_csv_files ( path , paths ) <TAB> <TAB> elif isfile ( path ) and path . endswith ( "" .csv "" ) : <TAB> <TAB> <TAB> # add every file to the list <TAB> <TAB> <TAB> paths . append ( path ) <TAB> return paths ","if isdir ( path ) : 
","if isdir ( path ) :
",100.0,100.0,True
"def _get_client ( rp_mapping , resource_provider ) : <TAB> for key , value in rp_mapping . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if isinstance ( value , dict ) : <TAB> <TAB> <TAB> <TAB> return GeneralPrivateEndpointClient ( <TAB> <TAB> <TAB> <TAB> <TAB> key , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" api_version "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" support_list_or_not "" ] , <TAB> <TAB> <TAB> <TAB> <TAB> value [ "" resource_get_api_version "" ] , <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> return value ( ) <TAB> raise CLIError ( <TAB> <TAB> "" Resource type must be one of  {} "" . format ( "" ,  "" . join ( rp_mapping . keys ( ) ) ) <TAB> ) ","if str . lower ( key ) == str . lower ( resource_provider ) : 
","if resource_provider . is_resource_type ( key ) :
",45.99,15.63,False
"def compute_rule_hash ( self , rule ) : <TAB> buf = "" %d - %d - %s - "" % ( <TAB> <TAB> rule . get ( "" FromPort "" , 0 ) or 0 , <TAB> <TAB> rule . get ( "" ToPort "" , 0 ) or 0 , <TAB> <TAB> rule . get ( "" IpProtocol "" , "" -1 "" ) or "" -1 "" , <TAB> ) <TAB> for a , ke in self . RULE_ATTRS : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> ev = [ e [ ke ] for e in rule [ a ] ] <TAB> <TAB> ev . sort ( ) <TAB> <TAB> for e in ev : <TAB> <TAB> <TAB> buf + = "" %s - "" % e <TAB> # mask to generate the same numeric value across all Python versions <TAB> return zlib . crc32 ( buf . encode ( "" ascii "" ) ) & 0xFFFFFFFF ","if a not in rule : 
","if a not in rule :
",100.0,100.0,True
"def analysis_sucess_metrics ( analysis_time : float , allow_exception = False ) : <TAB> try : <TAB> <TAB> anchore_engine . subsys . metrics . counter_inc ( name = "" anchore_analysis_success "" ) <TAB> <TAB> anchore_engine . subsys . metrics . histogram_observe ( <TAB> <TAB> <TAB> "" anchore_analysis_time_seconds "" , <TAB> <TAB> <TAB> analysis_time , <TAB> <TAB> <TAB> buckets = ANALYSIS_TIME_SECONDS_BUCKETS , <TAB> <TAB> <TAB> status = "" success "" , <TAB> <TAB> ) <TAB> except : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> else : <TAB> <TAB> <TAB> logger . exception ( <TAB> <TAB> <TAB> <TAB> "" Unexpected exception during metrics update for a successful analysis. Swallowing error and continuing "" <TAB> <TAB> <TAB> ) ","if allow_exception : 
","if allow_exception :
",78.12,100.0,True
"def decide_file_icon ( file ) : <TAB> if file . state == File . ERROR : <TAB> <TAB> return FileItem . icon_error <TAB> elif isinstance ( file . parent , Track ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return FileItem . icon_saved <TAB> <TAB> elif file . state == File . PENDING : <TAB> <TAB> <TAB> return FileItem . match_pending_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB> <TAB> else : <TAB> <TAB> <TAB> return FileItem . match_icons [ int ( file . similarity * 5 + 0.5 ) ] <TAB> elif file . state == File . PENDING : <TAB> <TAB> return FileItem . icon_file_pending <TAB> else : <TAB> <TAB> return FileItem . icon_file ","if file . state == File . NORMAL : 
","if file . state == File . saved :
",87.71,78.25,False
"def deleteMenu ( self , menuName ) : <TAB> try : <TAB> <TAB> menu = self . getMenu ( menuName ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . destroy ( menu ) <TAB> <TAB> <TAB> self . destroyMenu ( menuName ) <TAB> <TAB> else : <TAB> <TAB> <TAB> g . es ( "" can ' t delete menu: "" , menuName ) <TAB> except Exception : <TAB> <TAB> g . es ( "" exception deleting "" , menuName , "" menu "" ) <TAB> <TAB> g . es_exception ( ) ","if menu : 
","if menu :
",78.12,0.0,False
"def parser ( cls , buf ) : <TAB> ( type_ , code , csum ) = struct . unpack_from ( cls . _PACK_STR , buf ) <TAB> msg = cls ( type_ , code , csum ) <TAB> offset = cls . _MIN_LEN <TAB> if len ( buf ) > offset : <TAB> <TAB> cls_ = cls . _ICMPV6_TYPES . get ( type_ , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> msg . data = cls_ . parser ( buf , offset ) <TAB> <TAB> else : <TAB> <TAB> <TAB> msg . data = buf [ offset : ] <TAB> return msg , None , None ","if cls_ : 
","if cls_ :
",78.12,100.0,True
"def _load_dataset_area ( self , dsid , file_handlers , coords ) : <TAB> """"""Get the area for *dsid*."""""" <TAB> try : <TAB> <TAB> return self . _load_area_def ( dsid , file_handlers ) <TAB> except NotImplementedError : <TAB> <TAB> if any ( x is None for x in coords ) : <TAB> <TAB> <TAB> logger . warning ( "" Failed to load coordinates for  ' {} ' "" . format ( dsid ) ) <TAB> <TAB> <TAB> return None <TAB> <TAB> area = self . _make_area_from_coords ( coords ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( "" No coordinates found for  %s "" , str ( dsid ) ) <TAB> <TAB> return area ","if area is None : 
","if area is None :
",100.0,100.0,True
"def __getattr__ ( self , name ) : <TAB> if Popen . verbose : <TAB> <TAB> sys . stdout . write ( "" Getattr:  %s ... "" % name ) <TAB> if name in Popen . __slots__ : <TAB> <TAB> return object . __getattribute__ ( self , name ) <TAB> else : <TAB> <TAB> if self . popen is not None : <TAB> <TAB> <TAB> if Popen . verbose : <TAB> <TAB> <TAB> <TAB> print ( "" from Popen "" ) <TAB> <TAB> <TAB> return getattr ( self . popen , name ) <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return self . emu_wait <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> raise Exception ( "" subprocess emulation: not implemented:  %s "" % name ) ","if name == "" wait "" : 
","if self . emu_wait is not None :
",26.98,5.52,False
"def update ( self , time_delta ) : <TAB> super ( ) . update ( time_delta ) <TAB> n = self . menu . selected_option <TAB> if n == self . last : <TAB> <TAB> return <TAB> self . last = n <TAB> s = "" "" <TAB> for i in range ( len ( self . files ) ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> for l in open ( self . files [ i ] [ 1 ] ) : <TAB> <TAB> <TAB> <TAB> x = l . strip ( ) <TAB> <TAB> <TAB> <TAB> if len ( x ) > 1 and x [ 0 ] == "" # "" : <TAB> <TAB> <TAB> <TAB> <TAB> x = "" <b><u> "" + x [ 1 : ] + ""  </u></b> "" <TAB> <TAB> <TAB> <TAB> s + = x + "" <br> "" <TAB> self . set_text ( s ) ","if self . files [ i ] [ 0 ] == n : 
","if self . files [ i ] [ 0 ] == "" # "" :
",76.58,73.68,False
"def wrapper ( * args , * * kwargs ) : <TAB> list_args , empty = _apply_defaults ( func , args , kwargs ) <TAB> if len ( dimensions ) > len ( list_args ) : <TAB> <TAB> raise TypeError ( <TAB> <TAB> <TAB> "" %s  takes  %i  parameters, but  %i  dimensions were passed "" <TAB> <TAB> <TAB> % ( func . __name__ , len ( list_args ) , len ( dimensions ) ) <TAB> <TAB> ) <TAB> for dim , value in zip ( dimensions , list_args ) : <TAB> <TAB> if dim is None : <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val_dim = ureg . get_dimensionality ( value ) <TAB> <TAB> <TAB> raise DimensionalityError ( value , "" a quantity of "" , val_dim , dim ) <TAB> return func ( * args , * * kwargs ) ","if not ureg . Quantity ( value ) . check ( dim ) : 
","if value . quantity < = 0 :
",28.78,3.69,False
"def _check ( self , name , size = None , * extra ) : <TAB> func = getattr ( imageop , name ) <TAB> for height in VALUES : <TAB> <TAB> for width in VALUES : <TAB> <TAB> <TAB> strlen = abs ( width * height ) <TAB> <TAB> <TAB> if size : <TAB> <TAB> <TAB> <TAB> strlen * = size <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> data = "" A "" * strlen <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> data = AAAAA <TAB> <TAB> <TAB> if size : <TAB> <TAB> <TAB> <TAB> arguments = ( data , size , width , height ) + extra <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> arguments = ( data , width , height ) + extra <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> func ( * arguments ) <TAB> <TAB> <TAB> except ( ValueError , imageop . error ) : <TAB> <TAB> <TAB> <TAB> pass ","if strlen < MAX_LEN : 
","if strlen > 0 :
",31.5,15.85,False
"def wait_send_all_might_not_block ( self ) - > None : <TAB> with self . _send_conflict_detector : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise trio . ClosedResourceError ( "" file was already closed "" ) <TAB> <TAB> try : <TAB> <TAB> <TAB> await trio . lowlevel . wait_writable ( self . _fd_holder . fd ) <TAB> <TAB> except BrokenPipeError as e : <TAB> <TAB> <TAB> # kqueue: raises EPIPE on wait_writable instead <TAB> <TAB> <TAB> # of sending, which is annoying <TAB> <TAB> <TAB> raise trio . BrokenResourceError from e ","if self . _fd_holder . closed : 
","if self . _fd_holder . fd is not None :
",64.1,57.61,False
"def parse_win_proxy ( val ) : <TAB> proxies = [ ] <TAB> for p in val . split ( "" ; "" ) : <TAB> <TAB> if "" = "" in p : <TAB> <TAB> <TAB> tab = p . split ( "" = "" , 1 ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tab [ 0 ] = "" SOCKS4 "" <TAB> <TAB> <TAB> proxies . append ( <TAB> <TAB> <TAB> <TAB> ( tab [ 0 ] . upper ( ) , tab [ 1 ] , None , None ) <TAB> <TAB> <TAB> )<TAB> # type, addr:port, username, password <TAB> <TAB> else : <TAB> <TAB> <TAB> proxies . append ( ( "" HTTP "" , p , None , None ) ) <TAB> return proxies ","if tab [ 0 ] == "" socks "" : 
","if len ( tab ) == 2 :
",26.58,9.6,False
"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB> <TAB> return passed_class <TAB> else : <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> if isinstance ( pyclass , pyobjects . AbstractClass ) : <TAB> <TAB> <TAB> supers = pyclass . get_superclasses ( ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return pyobjects . PyObject ( supers [ 0 ] ) <TAB> <TAB> return passed_self ","if supers : 
","if len ( supers ) == 1 :
",29.65,6.27,False
"def update_output_mintime ( job ) : <TAB> try : <TAB> <TAB> return output_mintime [ job ] <TAB> except KeyError : <TAB> <TAB> for job_ in chain ( [ job ] , self . depending [ job ] ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> t = output_mintime [ job_ ] <TAB> <TAB> <TAB> except KeyError : <TAB> <TAB> <TAB> <TAB> t = job_ . output_mintime <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> output_mintime [ job ] = t <TAB> <TAB> <TAB> <TAB> return <TAB> <TAB> output_mintime [ job ] = None ","if t is not None : 
","if t > = 0 :
",29.52,17.97,False
"def get_list_of_strings_to_mongo_objects ( self , notifications_list = None ) : <TAB> result = [ ] <TAB> if len ( notifications_list ) > 0 : <TAB> <TAB> for x in notifications_list : <TAB> <TAB> <TAB> split_provider_id = x . split ( "" : "" )<TAB> # email:id <TAB> <TAB> <TAB> if len ( split_provider_id ) == 2 : <TAB> <TAB> <TAB> <TAB> _id = split_provider_id [ 1 ] <TAB> <TAB> <TAB> <TAB> cursor = self . get_by_id ( _id ) <TAB> <TAB> <TAB> <TAB> if cursor :<TAB> # Append if exists <TAB> <TAB> <TAB> <TAB> <TAB> result . append ( cursor ) <TAB> return result ","if cursor : 
","if cursor :
",78.12,0.0,False
"def stop ( self ) : <TAB> with self . lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return <TAB> <TAB> self . task_queue . put ( None ) <TAB> <TAB> self . result_queue . put ( None ) <TAB> <TAB> process = self . process <TAB> <TAB> self . process = None <TAB> <TAB> self . task_queue = None <TAB> <TAB> self . result_queue = None <TAB> process . join ( timeout = 0.1 ) <TAB> if process . exitcode is None : <TAB> <TAB> os . kill ( process . pid , signal . SIGKILL ) <TAB> <TAB> process . join ( ) ","if not self . process : 
","if self . process is None :
",41.27,27.78,False
"def on_api_command ( self , command , data ) : <TAB> if command == "" select "" : <TAB> <TAB> if not Permissions . PLUGIN_ACTION_COMMAND_PROMPT_INTERACT . can ( ) : <TAB> <TAB> <TAB> return flask . abort ( 403 , "" Insufficient permissions "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return flask . abort ( 409 , "" No active prompt "" ) <TAB> <TAB> choice = data [ "" choice "" ] <TAB> <TAB> if not isinstance ( choice , int ) or not self . _prompt . validate_choice ( choice ) : <TAB> <TAB> <TAB> return flask . abort ( <TAB> <TAB> <TAB> <TAB> 400 , "" {!r}  is not a valid value for choice "" . format ( choice ) <TAB> <TAB> <TAB> ) <TAB> <TAB> self . _answer_prompt ( choice ) ","if self . _prompt is None : 
","elif "" choice "" not in data :
",26.34,5.52,False
"def application_openFiles_ ( self , nsapp , filenames ) : <TAB> # logging.info('[osx] file open') <TAB> # logging.info('[osx] file : %s' % (filenames)) <TAB> for filename in filenames : <TAB> <TAB> logging . info ( "" [osx] receiving from macOS :  %s "" , filename ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if sabnzbd . filesystem . get_ext ( filename ) in VALID_ARCHIVES + VALID_NZB_FILES : <TAB> <TAB> <TAB> <TAB> sabnzbd . add_nzbfile ( filename , keep = True ) ","if os . path . exists ( filename ) : 
","if nsapp == "" mac "" :
",26.4,5.11,False
"def test_error_through_destructor ( self ) : <TAB> # Test that the exception state is not modified by a destructor, <TAB> # even if close() fails. <TAB> rawio = self . CloseFailureIO ( ) <TAB> with support . catch_unraisable_exception ( ) as cm : <TAB> <TAB> with self . assertRaises ( AttributeError ) : <TAB> <TAB> <TAB> self . tp ( rawio ) . xyzzy <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertIsNone ( cm . unraisable ) <TAB> <TAB> elif cm . unraisable is not None : <TAB> <TAB> <TAB> self . assertEqual ( cm . unraisable . exc_type , OSError ) ","if not IOBASE_EMITS_UNRAISABLE : 
","if isinstance ( cm , UnraisableException ) :
",28.21,6.57,False
"def http_wrapper ( self , url , postdata = { } ) : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> f = urllib . urlopen ( url , postdata ) <TAB> <TAB> else : <TAB> <TAB> <TAB> f = urllib . urlopen ( url ) <TAB> <TAB> response = f . read ( ) <TAB> except : <TAB> <TAB> import traceback <TAB> <TAB> import logging , sys <TAB> <TAB> cla , exc , tb = sys . exc_info ( ) <TAB> <TAB> logging . error ( url ) <TAB> <TAB> if postdata : <TAB> <TAB> <TAB> logging . error ( "" with post data "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> logging . error ( "" without post data "" ) <TAB> <TAB> logging . error ( exc . args ) <TAB> <TAB> logging . error ( traceback . format_tb ( tb ) ) <TAB> <TAB> response = "" "" <TAB> return response ","if postdata != { } : 
","if postdata :
",30.04,0.0,False
"def check_single_file ( fn , fetchuri ) : <TAB> """"""Determine if a single downloaded file is something we can't handle"""""" <TAB> with open ( fn , "" r "" , errors = "" surrogateescape "" ) as f : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . error ( <TAB> <TAB> <TAB> <TAB> ' Fetching  "" %s ""  returned a single HTML page - check the URL is correct and functional ' <TAB> <TAB> <TAB> <TAB> % fetchuri <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> sys . exit ( 1 ) ","if "" <html "" in f . read ( 100 ) . lower ( ) : 
","if "" html "" in f . read ( ) :
",53.05,42.89,False
"def update_properties ( self , update_dict ) : <TAB> signed_attribute_changed = False <TAB> for k , value in update_dict . items ( ) : <TAB> <TAB> if getattr ( self , k ) != value : <TAB> <TAB> <TAB> setattr ( self , k , value ) <TAB> <TAB> <TAB> signed_attribute_changed = signed_attribute_changed or ( <TAB> <TAB> <TAB> <TAB> k in self . payload_arguments <TAB> <TAB> <TAB> ) <TAB> if signed_attribute_changed : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . status = UPDATED <TAB> <TAB> self . timestamp = clock . tick ( ) <TAB> <TAB> self . sign ( ) <TAB> return self ","if self . status != NEW : 
","if self . status in ( REAL , REAL_UPDATED ) :
",48.7,20.45,False
"def clean_items ( event , items , variations ) : <TAB> for item in items : <TAB> <TAB> if event != item . event : <TAB> <TAB> <TAB> raise ValidationError ( _ ( "" One or more items do not belong to this event. "" ) ) <TAB> <TAB> if item . has_variations : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> raise ValidationError ( <TAB> <TAB> <TAB> <TAB> <TAB> _ ( <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> "" One or more items has variations but none of these are in the variations list. "" <TAB> <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> ) ","if not any ( var . item == item for var in variations ) : 
","if variations and len ( variations ) > 0 :
",6.7,5.79,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_status ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> if tt == 18 : <TAB> <TAB> <TAB> self . add_doc_id ( d . getPrefixedString ( ) ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def connections ( self ) : <TAB> # Connections look something like this: <TAB> # socket:[102422] <TAB> fds = self . open_files <TAB> socket = "" socket:[ "" <TAB> result = [ ] <TAB> functions = [ pwndbg . net . tcp , pwndbg . net . unix , pwndbg . net . netlink ] <TAB> for fd , path in fds . items ( ) : <TAB> <TAB> if socket not in path : <TAB> <TAB> <TAB> continue <TAB> <TAB> inode = path [ len ( socket ) : - 1 ] <TAB> <TAB> inode = int ( inode ) <TAB> <TAB> for func in functions : <TAB> <TAB> <TAB> for x in func ( ) : <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> x . fd = fd <TAB> <TAB> <TAB> <TAB> <TAB> result . append ( x ) <TAB> return tuple ( result ) ","if x . inode == inode : 
","if x . inode == inode :
",100.0,100.0,True
"def _movement_finished ( self ) : <TAB> if self . in_ship_map : <TAB> <TAB> # if the movement somehow stops, the position sticks, and the unit isn't at next_target any more <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ship = self . session . world . ship_map . get ( self . _next_target . to_tuple ( ) ) <TAB> <TAB> <TAB> if ship is not None and ship ( ) is self : <TAB> <TAB> <TAB> <TAB> del self . session . world . ship_map [ self . _next_target . to_tuple ( ) ] <TAB> super ( ) . _movement_finished ( ) ","if self . _next_target is not None : 
","if self . _next_target . to_tuple ( ) in self . session . world . ship_map :
",41.83,24.77,False
"def print_addresses ( self ) : <TAB> p = 3 <TAB> tmp_str = "" [ "" <TAB> if self . get_len ( ) > = 7 :<TAB> # at least one complete IP address <TAB> <TAB> while 1 : <TAB> <TAB> <TAB> if p + 1 == self . get_ptr ( ) : <TAB> <TAB> <TAB> <TAB> tmp_str + = "" # "" <TAB> <TAB> <TAB> tmp_str + = self . get_ip_address ( p ) <TAB> <TAB> <TAB> p + = 4 <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> tmp_str + = "" ,  "" <TAB> tmp_str + = "" ]  "" <TAB> if self . get_ptr ( ) % 4 :<TAB> # ptr field should be a multiple of 4 <TAB> <TAB> tmp_str + = "" nonsense ptr field:  %d "" % self . get_ptr ( ) <TAB> return tmp_str ","if p > = self . get_len ( ) : 
","if self . get_len ( ) == 0 :
",57.57,56.38,False
"def source_shapes ( self ) : <TAB> """"""Prints debug information about the sources in this provider."""""" <TAB> if logger . isEnabledFor ( logging . DEBUG ) : <TAB> <TAB> for i , source in enumerate ( self . sources ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> name = "" anonymous "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> name = self . keys [ i ] <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> shape = source . shape ( ) <TAB> <TAB> <TAB> except NotImplementedError : <TAB> <TAB> <TAB> <TAB> shape = "" N/A "" <TAB> <TAB> <TAB> logger . debug ( <TAB> <TAB> <TAB> <TAB> ' Data source  "" %s "" : entries= %s , shape= %s ' , name , len ( source ) , shape <TAB> <TAB> <TAB> ) ","if self . keys is None : 
","if i == 0 :
",27.08,8.17,False
def swap_actions ( actions ) : <TAB> for mutexgroup in mutex_groups : <TAB> <TAB> mutex_actions = mutexgroup . _group_actions <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # make a best guess as to where we should store the group <TAB> <TAB> <TAB> targetindex = actions . index ( mutexgroup . _group_actions [ 0 ] ) <TAB> <TAB> <TAB> # insert the _ArgumentGroup container <TAB> <TAB> <TAB> actions [ targetindex ] = mutexgroup <TAB> <TAB> <TAB> # remove the duplicated individual actions <TAB> <TAB> <TAB> actions = [ action for action in actions if action not in mutex_actions ] <TAB> return actions ,"if contains_actions ( mutex_actions , actions ) : 
","if mutexgroup . _group_actions :
",26.86,8.42,False
"def rec_deps ( services , container_by_name , cnt , init_service ) : <TAB> deps = cnt [ "" _deps "" ] <TAB> for dep in deps . copy ( ) : <TAB> <TAB> dep_cnts = services . get ( dep ) <TAB> <TAB> if not dep_cnts : <TAB> <TAB> <TAB> continue <TAB> <TAB> dep_cnt = container_by_name . get ( dep_cnts [ 0 ] ) <TAB> <TAB> if dep_cnt : <TAB> <TAB> <TAB> # TODO: avoid creating loops, A->B->A <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> new_deps = rec_deps ( services , container_by_name , dep_cnt , init_service ) <TAB> <TAB> <TAB> deps . update ( new_deps ) <TAB> return deps ","if init_service and init_service in dep_cnt [ "" _deps "" ] : 
","if dep_cnt == 0 :
",26.02,5.91,False
"def make_dump_list_by_name_list ( name_list ) : <TAB> info_list = [ ] <TAB> for info_name in name_list : <TAB> <TAB> info = next ( ( x for x in DUMP_LIST if x . info_name == info_name ) , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RuntimeError ( ' Unknown info name:  "" {} "" ' . format ( info_name ) ) <TAB> <TAB> info_list . append ( info ) <TAB> return info_list ","if not info : 
","if not info :
",100.0,100.0,True
"def create ( self , private = False ) : <TAB> try : <TAB> <TAB> if private : <TAB> <TAB> <TAB> log . info ( "" Creating private channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( <TAB> <TAB> <TAB> <TAB> "" conversations.create "" , data = { "" name "" : self . name , "" is_private "" : True } <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> log . info ( "" Creating channel  %s . "" , self ) <TAB> <TAB> <TAB> self . _bot . api_call ( "" conversations.create "" , data = { "" name "" : self . name } ) <TAB> except SlackAPIResponseError as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise RoomError ( f "" Unable to create channel.  { USER_IS_BOT_HELPTEXT } "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> raise RoomError ( e ) ","if e . error == "" user_is_bot "" : 
","if e . error == "" user_is_bot "" :
",100.0,100.0,True
"def talk ( self , words ) : <TAB> if self . writeSentence ( words ) == 0 : <TAB> <TAB> return <TAB> r = [ ] <TAB> while 1 : <TAB> <TAB> i = self . readSentence ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> reply = i [ 0 ] <TAB> <TAB> attrs = { } <TAB> <TAB> for w in i [ 1 : ] : <TAB> <TAB> <TAB> j = w . find ( "" = "" , 1 ) <TAB> <TAB> <TAB> if j == - 1 : <TAB> <TAB> <TAB> <TAB> attrs [ w ] = "" "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> attrs [ w [ : j ] ] = w [ j + 1 : ] <TAB> <TAB> r . append ( ( reply , attrs ) ) <TAB> <TAB> if reply == "" !done "" : <TAB> <TAB> <TAB> return r ","if len ( i ) == 0 : 
","if len ( i ) < 2 :
",77.42,47.75,False
"def _load_logfile ( self , lfn ) : <TAB> enc_key = self . decryption_key_func ( ) <TAB> with open ( os . path . join ( self . logdir , lfn ) ) as fd : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> with DecryptingStreamer ( <TAB> <TAB> <TAB> <TAB> fd , mep_key = enc_key , name = "" EventLog/DS( %s ) "" % lfn <TAB> <TAB> <TAB> ) as streamer : <TAB> <TAB> <TAB> <TAB> lines = streamer . read ( ) <TAB> <TAB> <TAB> <TAB> streamer . verify ( _raise = IOError ) <TAB> <TAB> else : <TAB> <TAB> <TAB> lines = fd . read ( ) <TAB> <TAB> if lines : <TAB> <TAB> <TAB> for line in lines . splitlines ( ) : <TAB> <TAB> <TAB> <TAB> event = Event . Parse ( line . strip ( ) ) <TAB> <TAB> <TAB> <TAB> self . _events [ event . event_id ] = event ","if enc_key : 
","if enc_key :
",78.12,100.0,True
"def set_ok_port ( self , cookie , request ) : <TAB> if cookie . port_specified : <TAB> <TAB> req_port = request_port ( request ) <TAB> <TAB> if req_port is None : <TAB> <TAB> <TAB> req_port = "" 80 "" <TAB> <TAB> else : <TAB> <TAB> <TAB> req_port = str ( req_port ) <TAB> <TAB> for p in cookie . port . split ( "" , "" ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> int ( p ) <TAB> <TAB> <TAB> except ValueError : <TAB> <TAB> <TAB> <TAB> debug ( ""<TAB> bad port  %s  (not numeric) "" , p ) <TAB> <TAB> <TAB> <TAB> return False <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> else : <TAB> <TAB> <TAB> debug ( ""<TAB> request port ( %s ) not found in  %s "" , req_port , cookie . port ) <TAB> <TAB> <TAB> return False <TAB> return True ","if p == req_port : 
","if p == req_port :
",100.0,100.0,True
"def get_attribute_value ( self , nodeid , attr ) : <TAB> with self . _lock : <TAB> <TAB> self . logger . debug ( "" get attr val:  %s %s "" , nodeid , attr ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadNodeIdUnknown ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> node = self . _nodes [ nodeid ] <TAB> <TAB> if attr not in node . attributes : <TAB> <TAB> <TAB> dv = ua . DataValue ( ) <TAB> <TAB> <TAB> dv . StatusCode = ua . StatusCode ( ua . StatusCodes . BadAttributeIdInvalid ) <TAB> <TAB> <TAB> return dv <TAB> <TAB> attval = node . attributes [ attr ] <TAB> <TAB> if attval . value_callback : <TAB> <TAB> <TAB> return attval . value_callback ( ) <TAB> <TAB> return attval . value ","if nodeid not in self . _nodes : 
","if nodeid not in self . _nodes :
",100.0,100.0,True
"def data_logging_status ( self , trail_name , trail_details , api_client ) : <TAB> for es in api_client . get_event_selectors ( TrailName = trail_name ) [ "" EventSelectors "" ] : <TAB> <TAB> has_wildcard = { <TAB> <TAB> <TAB> u "" Values "" : [ u "" arn:aws:s3::: "" ] , <TAB> <TAB> <TAB> u "" Type "" : u "" AWS::S3::Object "" , <TAB> <TAB> } in es [ "" DataResources "" ] <TAB> <TAB> is_logging = trail_details [ "" IsLogging "" ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if has_wildcard and is_logging and self . is_fresh ( trail_details ) : 
","if has_wildcard and is_logging :
",38.91,26.19,False
"def pytest_deselected ( items ) : <TAB> if sb_config . dashboard : <TAB> <TAB> sb_config . item_count - = len ( items ) <TAB> <TAB> for item in items : <TAB> <TAB> <TAB> test_id , display_id = _get_test_ids_ ( item ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> sb_config . _results . pop ( test_id ) ","if test_id in sb_config . _results . keys ( ) : 
","if test_id in sb_config . _results :
",53.1,66.17,False
"def _visit ( self , func ) : <TAB> fname = func [ 0 ] <TAB> if fname in self . _flags : <TAB> <TAB> if self . _flags [ fname ] == 1 : <TAB> <TAB> <TAB> logger . critical ( "" Fatal error! network ins not Dag. "" ) <TAB> <TAB> <TAB> import sys <TAB> <TAB> <TAB> sys . exit ( - 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return <TAB> else : <TAB> <TAB> if fname not in self . _flags : <TAB> <TAB> <TAB> self . _flags [ fname ] = 1 <TAB> <TAB> for output in func [ 3 ] : <TAB> <TAB> <TAB> for f in self . _orig : <TAB> <TAB> <TAB> <TAB> for input in f [ 2 ] : <TAB> <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> <TAB> self . _visit ( f ) <TAB> self . _flags [ fname ] = 2 <TAB> self . _sorted . insert ( 0 , func ) ","if output == input : 
","if input == output :
",54.02,21.36,False
"def printWiki ( ) : <TAB> firstHeading = False <TAB> for m in protocol : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if firstHeading : <TAB> <TAB> <TAB> <TAB> output ( "" |} "" ) <TAB> <TAB> <TAB> __printWikiHeader ( m [ 1 ] , m [ 2 ] ) <TAB> <TAB> <TAB> firstHeading = True <TAB> <TAB> else : <TAB> <TAB> <TAB> output ( "" |- "" ) <TAB> <TAB> <TAB> output ( <TAB> <TAB> <TAB> <TAB> ' | <span style= "" white-space:nowrap; "" ><tt> ' <TAB> <TAB> <TAB> <TAB> + m [ 0 ] <TAB> <TAB> <TAB> <TAB> + "" </tt></span> || ||  "" <TAB> <TAB> <TAB> <TAB> + m [ 1 ] <TAB> <TAB> <TAB> ) <TAB> output ( "" |} "" ) ","if m [ 0 ] == "" "" : 
","if m [ 0 ] == "" || "" :
",87.76,67.04,False
"def test_getitem ( self ) : <TAB> n = 200 <TAB> d = deque ( range ( n ) ) <TAB> l = list ( range ( n ) ) <TAB> for i in range ( n ) : <TAB> <TAB> d . popleft ( ) <TAB> <TAB> l . pop ( 0 ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d . append ( i ) <TAB> <TAB> <TAB> l . append ( i ) <TAB> <TAB> for j in range ( 1 - len ( l ) , len ( l ) ) : <TAB> <TAB> <TAB> assert d [ j ] == l [ j ] <TAB> d = deque ( "" superman "" ) <TAB> self . assertEqual ( d [ 0 ] , "" s "" ) <TAB> self . assertEqual ( d [ - 1 ] , "" n "" ) <TAB> d = deque ( ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , 0 ) <TAB> self . assertRaises ( IndexError , d . __getitem__ , - 1 ) ","if random . random ( ) < 0.5 : 
","if len ( l ) < n :
",28.31,12.26,False
"def get_num ( line , char_ptr , num_chars ) : <TAB> char_ptr = char_ptr + 1 <TAB> numstr = "" "" <TAB> good = "" -.0123456789 "" <TAB> while char_ptr < num_chars : <TAB> <TAB> digit = line [ char_ptr ] <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> numstr = numstr + digit <TAB> <TAB> <TAB> char_ptr = char_ptr + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> break <TAB> return numstr ","if good . find ( digit ) != - 1 : 
","if digit in good :
",26.31,3.73,False
"def read_digits ( source , start , first_code ) : <TAB> body = source . body <TAB> position = start <TAB> code = first_code <TAB> if code is not None and 48 < = code < = 57 :<TAB> # 0 - 9 <TAB> <TAB> while True : <TAB> <TAB> <TAB> position + = 1 <TAB> <TAB> <TAB> code = char_code_at ( body , position ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> return position <TAB> raise GraphQLSyntaxError ( <TAB> <TAB> source , <TAB> <TAB> position , <TAB> <TAB> u "" Invalid number, expected digit but got:  {} . "" . format ( print_char_code ( code ) ) , <TAB> ) ","if not ( code is not None and 48 < = code < = 57 ) : 
","if code is not None and 48 < = code < = 57 :
",75.16,70.34,False
"def get_aws_metadata ( headers , provider = None ) : <TAB> if not provider : <TAB> <TAB> provider = boto . provider . get_default ( ) <TAB> metadata_prefix = provider . metadata_prefix <TAB> metadata = { } <TAB> for hkey in headers . keys ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> val = urllib . unquote_plus ( headers [ hkey ] ) <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = unicode ( val , "" utf-8 "" ) <TAB> <TAB> <TAB> except UnicodeDecodeError : <TAB> <TAB> <TAB> <TAB> metadata [ hkey [ len ( metadata_prefix ) : ] ] = val <TAB> <TAB> <TAB> del headers [ hkey ] <TAB> return metadata ","if hkey . lower ( ) . startswith ( metadata_prefix ) : 
","if hkey . startswith ( metadata_prefix ) :
",57.28,59.6,False
"def _process_rtdest ( self ) : <TAB> LOG . debug ( "" Processing RT NLRI destination... "" ) <TAB> if self . _rtdest_queue . is_empty ( ) : <TAB> <TAB> return <TAB> else : <TAB> <TAB> processed_any = False <TAB> <TAB> while not self . _rtdest_queue . is_empty ( ) : <TAB> <TAB> <TAB> # We process the first destination in the queue. <TAB> <TAB> <TAB> next_dest = self . _rtdest_queue . pop_first ( ) <TAB> <TAB> <TAB> if next_dest : <TAB> <TAB> <TAB> <TAB> next_dest . process ( ) <TAB> <TAB> <TAB> <TAB> processed_any = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Since RT destination were updated we update RT filters <TAB> <TAB> <TAB> self . _core_service . update_rtfilters ( ) ","if processed_any : 
","if processed_any :
",78.12,100.0,True
"def _get_header ( self , requester , header_name ) : <TAB> hits = sum ( [ header_name in headers for _ , headers in requester . requests ] ) <TAB> self . assertEquals ( hits , 2 if self . revs_enabled else 1 ) <TAB> for url , headers in requester . requests : <TAB> <TAB> if header_name in headers : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /latest "" ) , msg = url ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . assertTrue ( url . endswith ( "" /download_urls "" ) , msg = url ) <TAB> <TAB> <TAB> return headers . get ( header_name ) ","if self . revs_enabled : 
","if self . revs_enabled :
",100.0,100.0,True
"def add_external_deps ( self , deps ) : <TAB> for dep in deps : <TAB> <TAB> if hasattr ( dep , "" el "" ) : <TAB> <TAB> <TAB> dep = dep . el <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidArguments ( "" Argument is not an external dependency "" ) <TAB> <TAB> self . external_deps . append ( dep ) <TAB> <TAB> if isinstance ( dep , dependencies . Dependency ) : <TAB> <TAB> <TAB> self . process_sourcelist ( dep . get_sources ( ) ) ","if not isinstance ( dep , dependencies . Dependency ) : 
","if not isinstance ( dep , dependencies . ExternalDependency ) :
",87.29,74.19,False
"def _consume_msg ( self ) : <TAB> ws = self . _ws <TAB> try : <TAB> <TAB> while True : <TAB> <TAB> <TAB> r = await ws . recv ( ) <TAB> <TAB> <TAB> if isinstance ( r , bytes ) : <TAB> <TAB> <TAB> <TAB> r = r . decode ( "" utf-8 "" ) <TAB> <TAB> <TAB> msg = json . loads ( r ) <TAB> <TAB> <TAB> stream = msg . get ( "" stream "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> await self . _dispatch ( stream , msg ) <TAB> except websockets . WebSocketException as wse : <TAB> <TAB> logging . warn ( wse ) <TAB> <TAB> await self . close ( ) <TAB> <TAB> asyncio . ensure_future ( self . _ensure_ws ( ) ) ","if stream is not None : 
","if stream :
",29.58,0.0,False
"def generate_and_check_random ( ) : <TAB> random_size = 256 <TAB> while True : <TAB> <TAB> random = os . urandom ( random_size ) <TAB> <TAB> a = int . from_bytes ( random , "" big "" ) <TAB> <TAB> A = pow ( g , a , p ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> a_for_hash = big_num_for_hash ( A ) <TAB> <TAB> <TAB> u = int . from_bytes ( sha256 ( a_for_hash , b_for_hash ) , "" big "" ) <TAB> <TAB> <TAB> if u > 0 : <TAB> <TAB> <TAB> <TAB> return ( a , a_for_hash , u ) ","if is_good_mod_exp_first ( A , p ) : 
","if A > 0 :
",26.99,1.56,False
"def write ( self , datagram , address ) : <TAB> """"""Write a datagram."""""" <TAB> try : <TAB> <TAB> return self . socket . sendto ( datagram , address ) <TAB> except OSError as se : <TAB> <TAB> no = se . args [ 0 ] <TAB> <TAB> if no == EINTR : <TAB> <TAB> <TAB> return self . write ( datagram , address ) <TAB> <TAB> elif no == EMSGSIZE : <TAB> <TAB> <TAB> raise error . MessageLengthError ( "" message too long "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # oh, well, drop the data. The only difference from UDP <TAB> <TAB> <TAB> # is that UDP won't ever notice. <TAB> <TAB> <TAB> # TODO: add TCP-like buffering <TAB> <TAB> <TAB> pass <TAB> <TAB> else : <TAB> <TAB> <TAB> raise ","elif no == EAGAIN : 
","elif no == ECONNABORTED :
",64.48,53.73,False
"def doDir ( elem ) : <TAB> for child in elem . childNodes : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if child . tagName == "" Directory "" : <TAB> <TAB> <TAB> doDir ( child ) <TAB> <TAB> elif child . tagName == "" Component "" : <TAB> <TAB> <TAB> for grandchild in child . childNodes : <TAB> <TAB> <TAB> <TAB> if not isinstance ( grandchild , minidom . Element ) : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> if grandchild . tagName != "" File "" : <TAB> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> <TAB> files . add ( grandchild . getAttribute ( "" Source "" ) . replace ( os . sep , "" / "" ) ) ","if not isinstance ( child , minidom . Element ) : 
","if not isinstance ( child , minidom . Element ) :
",100.0,100.0,True
"def add_reversed_tensor ( i , X , reversed_X ) : <TAB> # Do not keep tensors that should stop the mapping. <TAB> if X in stop_mapping_at_tensors : <TAB> <TAB> return <TAB> if X not in reversed_tensors : <TAB> <TAB> reversed_tensors [ X ] = { "" id "" : ( nid , i ) , "" tensor "" : reversed_X } <TAB> else : <TAB> <TAB> tmp = reversed_tensors [ X ] <TAB> <TAB> if "" tensor "" in tmp and "" tensors "" in tmp : <TAB> <TAB> <TAB> raise Exception ( "" Wrong order, tensors already aggregated! "" ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> tmp [ "" tensors "" ] = [ tmp [ "" tensor "" ] , reversed_X ] <TAB> <TAB> <TAB> del tmp [ "" tensor "" ] <TAB> <TAB> else : <TAB> <TAB> <TAB> tmp [ "" tensors "" ] . append ( reversed_X ) ","if "" tensor "" in tmp : 
","if "" type "" in tmp and "" type "" in tmp [ "" tensors "" ] :
",44.75,10.52,False
"def walk ( source , path , default , delimiter = "" . "" ) : <TAB> """"""Walk the sourch hash given the path and return the value or default if not found"""""" <TAB> if not isinstance ( source , dict ) : <TAB> <TAB> raise RuntimeError ( <TAB> <TAB> <TAB> "" The source is not a walkable dict:  {}  path:  {} "" . format ( source , path ) <TAB> <TAB> ) <TAB> keys = path . split ( delimiter ) <TAB> max_depth = len ( keys ) <TAB> cur_depth = 0 <TAB> while cur_depth < max_depth : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> source = source [ keys [ cur_depth ] ] <TAB> <TAB> <TAB> cur_depth = cur_depth + 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return default <TAB> return source ","if keys [ cur_depth ] in source : 
","if keys [ cur_depth ] in source :
",100.0,100.0,True
"def _from_txt_get_vulns ( self ) : <TAB> file_vulns = [ ] <TAB> vuln_regex = ( <TAB> <TAB> ' SQL injection in a .*? was found at:  "" (.*?) "" ' <TAB> <TAB> ' , using HTTP method (.*?). The sent .*?data was:  "" (.*?) "" ' <TAB> ) <TAB> vuln_re = re . compile ( vuln_regex ) <TAB> for line in file ( self . OUTPUT_FILE ) : <TAB> <TAB> mo = vuln_re . search ( line ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> v = MockVuln ( "" TestCase "" , None , "" High "" , 1 , "" plugin "" ) <TAB> <TAB> <TAB> v . set_url ( URL ( mo . group ( 1 ) ) ) <TAB> <TAB> <TAB> v . set_method ( mo . group ( 2 ) ) <TAB> <TAB> <TAB> file_vulns . append ( v ) <TAB> return file_vulns ","if mo : 
","if mo :
",78.12,0.0,False
"def __get__ ( self , instance , instance_type = None ) : <TAB> if instance : <TAB> <TAB> if self . att_name not in instance . _obj_cache : <TAB> <TAB> <TAB> rel_obj = self . get_obj ( instance ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> instance . _obj_cache [ self . att_name ] = rel_obj <TAB> <TAB> return instance . _obj_cache . get ( self . att_name ) <TAB> return self ","if rel_obj : 
","if rel_obj :
",78.12,100.0,True
"def get_ranges_from_func_set ( support_set ) : <TAB> pos_start = 0 <TAB> pos_end = 0 <TAB> ranges = [ ] <TAB> for pos , func in enumerate ( network . function ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> pos_end = pos <TAB> <TAB> else : <TAB> <TAB> <TAB> if pos_end > = pos_start : <TAB> <TAB> <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> <TAB> <TAB> pos_start = pos + 1 <TAB> if pos_end > = pos_start : <TAB> <TAB> ranges . append ( ( pos_start , pos_end ) ) <TAB> return ranges ","if func . type in support_set : 
","if func . set_ranges ( support_set ) :
",39.35,22.03,False
"def get_all_active_plugins ( self ) - > List [ BotPlugin ] : <TAB> """"""This returns the list of plugins in the callback ordered defined from the config."""""" <TAB> all_plugins = [ ] <TAB> for name in self . plugins_callback_order : <TAB> <TAB> # None is a placeholder for any plugin not having a defined order <TAB> <TAB> if name is None : <TAB> <TAB> <TAB> all_plugins + = [ <TAB> <TAB> <TAB> <TAB> plugin <TAB> <TAB> <TAB> <TAB> for name , plugin in self . plugins . items ( ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ] <TAB> <TAB> else : <TAB> <TAB> <TAB> plugin = self . plugins [ name ] <TAB> <TAB> <TAB> if plugin . is_activated : <TAB> <TAB> <TAB> <TAB> all_plugins . append ( plugin ) <TAB> return all_plugins ","if name not in self . plugins_callback_order and plugin . is_activated 
","if plugin . is_activated
",36.38,12.71,False
"def render_token_list ( self , tokens ) : <TAB> result = [ ] <TAB> vars = [ ] <TAB> for token in tokens : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result . append ( token . contents . replace ( "" % "" , "" %% "" ) ) <TAB> <TAB> elif token . token_type == TOKEN_VAR : <TAB> <TAB> <TAB> result . append ( "" %% ( %s )s "" % token . contents ) <TAB> <TAB> <TAB> vars . append ( token . contents ) <TAB> msg = "" "" . join ( result ) <TAB> if self . trimmed : <TAB> <TAB> msg = translation . trim_whitespace ( msg ) <TAB> return msg , vars ","if token . token_type == TOKEN_TEXT : 
","if token . token_type == TOKEN_TEXT :
",100.0,100.0,True
"def test_build_root_config_overwrite ( self ) : <TAB> cfg = build_root_config ( "" tests.files.settings_overwrite "" ) <TAB> for key , val in DEFAULT_SPIDER_GLOBAL_CONFIG . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , [ "" zzz "" ] ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . assertEqual ( cfg [ "" global "" ] [ key ] , val ) ","if key == "" spider_modules "" : 
","if key == "" paths "" :
",74.63,46.31,False
"def get_limit ( self , request ) : <TAB> if self . limit_query_param : <TAB> <TAB> try : <TAB> <TAB> <TAB> limit = int ( request . query_params [ self . limit_query_param ] ) <TAB> <TAB> <TAB> if limit < 0 : <TAB> <TAB> <TAB> <TAB> raise ValueError ( ) <TAB> <TAB> <TAB> # Enforce maximum page size, if defined <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> if limit == 0 : <TAB> <TAB> <TAB> <TAB> <TAB> return settings . MAX_PAGE_SIZE <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> return min ( limit , settings . MAX_PAGE_SIZE ) <TAB> <TAB> <TAB> return limit <TAB> <TAB> except ( KeyError , ValueError ) : <TAB> <TAB> <TAB> pass <TAB> return self . default_limit ","if settings . MAX_PAGE_SIZE : 
","if settings . MAX_PAGE_SIZE > settings . MAX_PAGE_SIZE :
",69.49,47.97,False
"def track_handler ( handler ) : <TAB> tid = handler . request . tid <TAB> for event in events_monitored : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> e = Event ( event , handler . request . execution_time ) <TAB> <TAB> <TAB> State . tenant_state [ tid ] . RecentEventQ . append ( e ) <TAB> <TAB> <TAB> State . tenant_state [ tid ] . EventQ . append ( e ) <TAB> <TAB> <TAB> break ","if event [ "" handler_check "" ] ( handler ) : 
","if event . execution_time > handler . request . execution_time :
",27.49,6.61,False
"def TryMerge ( self , d ) : <TAB> while d . avail ( ) > 0 : <TAB> <TAB> tt = d . getVarInt32 ( ) <TAB> <TAB> if tt == 10 : <TAB> <TAB> <TAB> length = d . getVarInt32 ( ) <TAB> <TAB> <TAB> tmp = ProtocolBuffer . Decoder ( d . buffer ( ) , d . pos ( ) , d . pos ( ) + length ) <TAB> <TAB> <TAB> d . skip ( length ) <TAB> <TAB> <TAB> self . add_subscription ( ) . TryMerge ( tmp ) <TAB> <TAB> <TAB> continue <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ProtocolBuffer . ProtocolBufferDecodeError <TAB> <TAB> d . skipData ( tt ) ","if tt == 0 : 
","if tt == 0 :
",100.0,100.0,True
"def GetCreateInstanceBinder ( self , info ) : <TAB> with self . _lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return self . _createInstanceBinders [ info ] <TAB> <TAB> b = runtime . SymplCreateInstanceBinder ( info ) <TAB> <TAB> self . _createInstanceBinders [ info ] = b <TAB> return b ","if self . _createInstanceBinders . ContainsKey ( info ) : 
","if self . _createInstanceBinders . ContainsKey ( info ) :
",100.0,100.0,True
"def process_task ( self , body , message ) : <TAB> if "" control "" in body : <TAB> <TAB> try : <TAB> <TAB> <TAB> return self . control ( body , message ) <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> logger . exception ( "" Exception handling control message: "" ) <TAB> <TAB> <TAB> return <TAB> if len ( self . pool ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> queue = UUID ( body [ "" uuid "" ] ) . int % len ( self . pool ) <TAB> <TAB> <TAB> except Exception : <TAB> <TAB> <TAB> <TAB> queue = self . total_messages % len ( self . pool ) <TAB> <TAB> else : <TAB> <TAB> <TAB> queue = self . total_messages % len ( self . pool ) <TAB> else : <TAB> <TAB> queue = 0 <TAB> self . pool . write ( queue , body ) <TAB> self . total_messages + = 1 <TAB> message . ack ( ) ","if "" uuid "" in body and body [ "" uuid "" ] : 
","if "" uuid "" in body :
",52.87,30.93,False
"def is_defined_in_base_class ( self , var : Var ) - > bool : <TAB> if var . info : <TAB> <TAB> for base in var . info . mro [ 1 : ] : <TAB> <TAB> <TAB> if base . get ( var . name ) is not None : <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return True <TAB> return False ","if var . info . fallback_to_any : 
","if var . name in self . defined_vars :
",39.43,16.59,False
"def ant_map ( m ) : <TAB> tmp = "" rows  %s \n cols  %s \n "" % ( len ( m ) , len ( m [ 0 ] ) ) <TAB> players = { } <TAB> for row in m : <TAB> <TAB> tmp + = "" m  "" <TAB> <TAB> for col in row : <TAB> <TAB> <TAB> if col == LAND : <TAB> <TAB> <TAB> <TAB> tmp + = "" . "" <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> tmp + = "" % "" <TAB> <TAB> <TAB> elif col == FOOD : <TAB> <TAB> <TAB> <TAB> tmp + = "" * "" <TAB> <TAB> <TAB> elif col == UNSEEN : <TAB> <TAB> <TAB> <TAB> tmp + = "" ? "" <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> players [ col ] = True <TAB> <TAB> <TAB> <TAB> tmp + = chr ( col + 97 ) <TAB> <TAB> tmp + = "" \n "" <TAB> tmp = ( "" players  %s \n "" % len ( players ) ) + tmp <TAB> return tmp ","elif col == BARRIER : 
","elif col == JUST :
",64.48,53.73,False
"def prompt_for_resume ( config ) : <TAB> logger = logging . getLogger ( "" changeme "" ) <TAB> logger . error ( <TAB> <TAB> "" A previous scan was interrupted. Type R to resume or F to start a fresh scan "" <TAB> ) <TAB> answer = "" "" <TAB> while not ( answer == "" R "" or answer == "" F "" ) : <TAB> <TAB> prompt = "" (R/F)>  "" <TAB> <TAB> answer = "" "" <TAB> <TAB> try : <TAB> <TAB> <TAB> answer = raw_input ( prompt ) <TAB> <TAB> except NameError : <TAB> <TAB> <TAB> answer = input ( prompt ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logger . debug ( "" Forcing a fresh scan "" ) <TAB> <TAB> elif answer . upper ( ) == "" R "" : <TAB> <TAB> <TAB> logger . debug ( "" Resuming previous scan "" ) <TAB> <TAB> <TAB> config . resume = True <TAB> return config . resume ","if answer . upper ( ) == "" F "" : 
","if answer == "" F "" :
",49.01,46.41,False
"def f ( view , s ) : <TAB> if mode == modes . INTERNAL_NORMAL : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if view . line ( s . b ) . size ( ) > 0 : <TAB> <TAB> <TAB> <TAB> eol = view . line ( s . b ) . b <TAB> <TAB> <TAB> <TAB> return R ( s . b , eol ) <TAB> <TAB> <TAB> return s <TAB> return s ","if count == 1 : 
","if s . b . size ( ) > 0 :
",27.38,4.46,False
"def flush ( self ) : <TAB> if not self . cuts : <TAB> <TAB> return <TAB> for move , ( x , y , z ) , cent in douglas ( self . cuts , self . tolerance , self . plane ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . write ( "" %s  X %.4f  Y %.4f  Z %.4f %s "" % ( move , x , y , z , cent ) ) <TAB> <TAB> <TAB> self . lastgcode = None <TAB> <TAB> <TAB> self . lastx = x <TAB> <TAB> <TAB> self . lasty = y <TAB> <TAB> <TAB> self . lastz = z <TAB> <TAB> else : <TAB> <TAB> <TAB> self . move_common ( x , y , z , gcode = "" G1 "" ) <TAB> self . cuts = [ ] ","if cent : 
","if self . verbosity > = 2 :
",29.42,6.57,False
"def copy_shell ( self ) : <TAB> cls = self . __class__ <TAB> old_id = cls . id <TAB> new_i = cls ( )<TAB> # create a new group <TAB> new_i . id = self . id<TAB> # with the same id <TAB> cls . id = old_id<TAB> # Reset the Class counter <TAB> # Copy all properties <TAB> for prop in cls . properties : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> if self . has ( prop ) : <TAB> <TAB> <TAB> <TAB> val = getattr ( self , prop ) <TAB> <TAB> <TAB> <TAB> setattr ( new_i , prop , val ) <TAB> # but no members <TAB> new_i . members = [ ] <TAB> return new_i ","if prop is not "" members "" : 
","if hasattr ( self , prop ) :
",26.81,7.27,False
"def find_region_by_value ( key , value ) : <TAB> for region in cognitoidp_backends : <TAB> <TAB> backend = cognitoidp_backends [ region ] <TAB> <TAB> for user_pool in backend . user_pools . values ( ) : <TAB> <TAB> <TAB> if key == "" client_id "" and value in user_pool . clients : <TAB> <TAB> <TAB> <TAB> return region <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return region <TAB> # If we can't find the `client_id` or `access_token`, we just pass <TAB> # back a default backend region, which will raise the appropriate <TAB> # error message (e.g. NotAuthorized or NotFound). <TAB> return list ( cognitoidp_backends ) [ 0 ] ","if key == "" access_token "" and value in user_pool . access_tokens : 
","if key == "" access_token "" and value in user_pool . clients :
",92.33,79.78,False
"def __init__ ( <TAB> self , fixed : MQTTFixedHeader = None , variable_header : PacketIdVariableHeader = None ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PUBREL , 0x02 )<TAB> # [MQTT-3.6.1-1] <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise HBMQTTException ( <TAB> <TAB> <TAB> <TAB> "" Invalid fixed packet type  %s  for PubrelPacket init "" % fixed . packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = variable_header <TAB> self . payload = None ","if fixed . packet_type is not PUBREL : 
","if fixed . packet_type is not PUBREL :
",100.0,100.0,True
"def _on_event_MetadataStatisticsUpdated ( self , event , data ) : <TAB> with self . _selectedFileMutex : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . _setJobData ( <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" filename "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" filesize "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" sd "" ] , <TAB> <TAB> <TAB> <TAB> self . _selectedFile [ "" user "" ] , <TAB> <TAB> <TAB> ) ","if self . _selectedFile : 
","if self . _selectedFile and self . _selectedFile [ "" filename "" ] :
",55.71,23.96,False
"def _validate_parameter_range ( self , value_hp , parameter_range ) : <TAB> """"""Placeholder docstring"""""" <TAB> for ( <TAB> <TAB> parameter_range_key , <TAB> <TAB> parameter_range_value , <TAB> ) in parameter_range . __dict__ . items ( ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> # Categorical ranges <TAB> <TAB> if isinstance ( parameter_range_value , list ) : <TAB> <TAB> <TAB> for categorical_value in parameter_range_value : <TAB> <TAB> <TAB> <TAB> value_hp . validate ( categorical_value ) <TAB> <TAB> # Continuous, Integer ranges <TAB> <TAB> else : <TAB> <TAB> <TAB> value_hp . validate ( parameter_range_value ) ","if parameter_range_key == "" scaling_type "" : 
","if parameter_range_key not in self . parameter_range_keys :
",28.76,32.38,False
"def visit_filter_projection ( self , node , value ) : <TAB> base = self . visit ( node [ "" children "" ] [ 0 ] , value ) <TAB> if not isinstance ( base , list ) : <TAB> <TAB> return None <TAB> comparator_node = node [ "" children "" ] [ 2 ] <TAB> collected = [ ] <TAB> for element in base : <TAB> <TAB> if self . _is_true ( self . visit ( comparator_node , element ) ) : <TAB> <TAB> <TAB> current = self . visit ( node [ "" children "" ] [ 1 ] , element ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> collected . append ( current ) <TAB> return collected ","if current is not None : 
","if current is not None :
",100.0,100.0,True
"def _getSubstrings ( self , va , size , ltyp ) : <TAB> # rip through the desired memory range to populate any substrings <TAB> subs = set ( ) <TAB> end = va + size <TAB> for offs in range ( va , end , 1 ) : <TAB> <TAB> loc = self . getLocation ( offs , range = True ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> subs . add ( ( loc [ L_VA ] , loc [ L_SIZE ] ) ) <TAB> <TAB> <TAB> if loc [ L_TINFO ] : <TAB> <TAB> <TAB> <TAB> subs = subs . union ( set ( loc [ L_TINFO ] ) ) <TAB> return list ( subs ) ","if loc and loc [ L_LTYPE ] == LOC_STRING and loc [ L_VA ] > va : 
","if ltyp == L_STRING :
",25.57,2.69,False
"def run ( self ) : <TAB> while not self . _stopped : <TAB> <TAB> try : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> test_name = next ( self . pending ) <TAB> <TAB> <TAB> except StopIteration : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> mp_result = self . _runtest ( test_name ) <TAB> <TAB> <TAB> self . output . put ( ( False , mp_result ) ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> except ExitThread : <TAB> <TAB> <TAB> break <TAB> <TAB> except BaseException : <TAB> <TAB> <TAB> self . output . put ( ( True , traceback . format_exc ( ) ) ) <TAB> <TAB> <TAB> break ","if must_stop ( mp_result . result , self . ns ) : 
","if mp_result is False :
",26.08,7.68,False
"def get_in_inputs ( key , data ) : <TAB> if isinstance ( data , dict ) : <TAB> <TAB> for k , v in data . items ( ) : <TAB> <TAB> <TAB> if k == key : <TAB> <TAB> <TAB> <TAB> return v <TAB> <TAB> <TAB> elif isinstance ( v , ( list , tuple , dict ) ) : <TAB> <TAB> <TAB> <TAB> out = get_in_inputs ( key , v ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> return out <TAB> elif isinstance ( data , ( list , tuple ) ) : <TAB> <TAB> out = [ get_in_inputs ( key , x ) for x in data ] <TAB> <TAB> out = [ x for x in out if x ] <TAB> <TAB> if out : <TAB> <TAB> <TAB> return out [ 0 ] ","if out : 
","if out :
",78.12,0.0,False
"def act_mapping ( self , items , actions , mapping ) : <TAB> """"""Executes all the actions on the list of pods."""""" <TAB> success = True <TAB> for action in actions : <TAB> <TAB> for key , method in mapping . items ( ) : <TAB> <TAB> <TAB> if key in action : <TAB> <TAB> <TAB> <TAB> params = action . get ( key ) <TAB> <TAB> <TAB> <TAB> ret = method ( items , params ) <TAB> <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> <TAB> success = False <TAB> return success ","if not ret : 
","if ret is None :
",29.25,14.06,False
"def _apply ( self , plan ) : <TAB> desired = plan . desired <TAB> changes = plan . changes <TAB> self . log . debug ( "" _apply: zone= %s , len(changes)= %d "" , desired . name , len ( changes ) ) <TAB> domain_name = desired . name [ : - 1 ] <TAB> try : <TAB> <TAB> nsone_zone = self . _client . loadZone ( domain_name ) <TAB> except ResourceException as e : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise <TAB> <TAB> self . log . debug ( "" _apply:   no matching zone, creating "" ) <TAB> <TAB> nsone_zone = self . _client . createZone ( domain_name ) <TAB> for change in changes : <TAB> <TAB> class_name = change . __class__ . __name__ <TAB> <TAB> getattr ( self , "" _apply_ {} "" . format ( class_name ) ) ( nsone_zone , change ) ","if e . message != self . ZONE_NOT_FOUND_MESSAGE : 
","if e . args [ 0 ] != ENoError :
",41.53,11.65,False
"def split_artists ( self , json ) : <TAB> if len ( json ) == 0 : <TAB> <TAB> ( [ ] , [ ] ) <TAB> elif len ( json ) == 1 : <TAB> <TAB> artist = Artist . query . filter_by ( name = json [ 0 ] [ "" name "" ] ) . first ( ) <TAB> <TAB> return ( [ artist ] , [ ] ) <TAB> my_artists = [ ] <TAB> other_artists = [ ] <TAB> for artist_dict in json : <TAB> <TAB> artist = Artist . query . filter_by ( name = artist_dict [ "" name "" ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> my_artists . append ( artist . first ( ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> del artist_dict [ "" thumb_url "" ] <TAB> <TAB> <TAB> other_artists . append ( artist_dict ) <TAB> return ( my_artists , other_artists ) ","if artist . count ( ) : 
","if artist :
",28.89,0.0,False
"def update_metadata ( self ) : <TAB> for attrname in dir ( self ) : <TAB> <TAB> if attrname . startswith ( "" __ "" ) : <TAB> <TAB> <TAB> continue <TAB> <TAB> attrvalue = getattr ( self , attrname , None ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> if attrname == "" salt_version "" : <TAB> <TAB> <TAB> attrname = "" version "" <TAB> <TAB> if hasattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) : <TAB> <TAB> <TAB> getattr ( self . metadata , "" set_ {0} "" . format ( attrname ) ) ( attrvalue ) <TAB> <TAB> elif hasattr ( self . metadata , attrname ) : <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> setattr ( self . metadata , attrname , attrvalue ) <TAB> <TAB> <TAB> except AttributeError : <TAB> <TAB> <TAB> <TAB> pass ","if attrvalue == 0 : 
","if attrvalue is None :
",31.5,19.36,False
"def close ( self , code = errno . ECONNRESET ) : <TAB> with self . shutdown_lock : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> super ( RemoteIPRoute , self ) . close ( code = code ) <TAB> <TAB> <TAB> self . closed = True <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> self . _mitogen_call . get ( ) <TAB> <TAB> <TAB> except mitogen . core . ChannelError : <TAB> <TAB> <TAB> <TAB> pass <TAB> <TAB> <TAB> if self . _mitogen_broker is not None : <TAB> <TAB> <TAB> <TAB> self . _mitogen_broker . shutdown ( ) <TAB> <TAB> <TAB> <TAB> self . _mitogen_broker . join ( ) ","if not self . closed : 
","if not self . closed :
",100.0,100.0,True
"def untokenize ( self , iterable ) : <TAB> for t in iterable : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . compat ( t , iterable ) <TAB> <TAB> <TAB> break <TAB> <TAB> tok_type , token , start , end , line = t <TAB> <TAB> self . add_whitespace ( start ) <TAB> <TAB> self . tokens . append ( token ) <TAB> <TAB> self . prev_row , self . prev_col = end <TAB> <TAB> if tok_type in ( NEWLINE , NL ) : <TAB> <TAB> <TAB> self . prev_row + = 1 <TAB> <TAB> <TAB> self . prev_col = 0 <TAB> return "" "" . join ( self . tokens ) ","if len ( t ) == 2 : 
","if isinstance ( t , ( list , tuple ) ) :
",28.06,8.52,False
"def __call__ ( self , x , uttid = None ) : <TAB> if self . utt2spk is not None : <TAB> <TAB> spk = self . utt2spk [ uttid ] <TAB> else : <TAB> <TAB> spk = uttid <TAB> if not self . reverse : <TAB> <TAB> if self . norm_means : <TAB> <TAB> <TAB> x = np . add ( x , self . bias [ spk ] ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> x = np . multiply ( x , self . scale [ spk ] ) <TAB> else : <TAB> <TAB> if self . norm_vars : <TAB> <TAB> <TAB> x = np . divide ( x , self . scale [ spk ] ) <TAB> <TAB> if self . norm_means : <TAB> <TAB> <TAB> x = np . subtract ( x , self . bias [ spk ] ) <TAB> return x ","if self . norm_vars : 
","if self . norm_vars :
",100.0,100.0,True
"def get_party_total ( self , args ) : <TAB> self . party_total = frappe . _dict ( ) <TAB> for d in self . receivables : <TAB> <TAB> self . init_party_total ( d ) <TAB> <TAB> # Add all amount columns <TAB> <TAB> for k in list ( self . party_total [ d . party ] ) : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . party_total [ d . party ] [ k ] + = d . get ( k , 0.0 ) <TAB> <TAB> # set territory, customer_group, sales person etc <TAB> <TAB> self . set_party_details ( d ) ","if k not in [ "" currency "" , "" sales_person "" ] : 
","if d . get ( k ) :
",25.93,2.67,False
"def get_databases ( request ) : <TAB> dbs = { } <TAB> global_env = globals ( ) <TAB> for ( key , value ) in global_env . items ( ) : <TAB> <TAB> try : <TAB> <TAB> <TAB> cond = isinstance ( value , GQLDB ) <TAB> <TAB> except : <TAB> <TAB> <TAB> cond = isinstance ( value , SQLDB ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> dbs [ key ] = value <TAB> return dbs ","if cond : 
","if cond :
",78.12,0.0,False
"def check_twobit_file ( dbkey , GALAXY_DATA_INDEX_DIR ) : <TAB> twobit_file = "" %s /twobit.loc "" % GALAXY_DATA_INDEX_DIR <TAB> twobit_path = "" "" <TAB> twobits = { } <TAB> for i , line in enumerate ( open ( twobit_file ) ) : <TAB> <TAB> line = line . rstrip ( "" \r \n "" ) <TAB> <TAB> if line and not line . startswith ( "" # "" ) : <TAB> <TAB> <TAB> fields = line . split ( "" \t "" ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> <TAB> twobits [ ( fields [ 0 ] ) ] = fields [ 1 ] <TAB> if dbkey in twobits : <TAB> <TAB> twobit_path = twobits [ ( dbkey ) ] <TAB> return twobit_path ","if len ( fields ) < 2 : 
","if len ( fields ) != 2 :
",79.9,51.33,False
"def action ( scheduler , _ ) : <TAB> nonlocal state <TAB> nonlocal has_result <TAB> nonlocal result <TAB> nonlocal first <TAB> nonlocal time <TAB> <MASK> <TAB> <TAB> observer . on_next ( result ) <TAB> try : <TAB> <TAB> if first : <TAB> <TAB> <TAB> first = False <TAB> <TAB> else : <TAB> <TAB> <TAB> state = iterate ( state ) <TAB> <TAB> has_result = condition ( state ) <TAB> <TAB> if has_result : <TAB> <TAB> <TAB> result = state <TAB> <TAB> <TAB> time = time_mapper ( state ) <TAB> except Exception as e :<TAB> # pylint: disable=broad-except <TAB> <TAB> observer . on_error ( e ) <TAB> <TAB> return <TAB> if has_result : <TAB> <TAB> mad . disposable = scheduler . schedule_relative ( time , action ) <TAB> else : <TAB> <TAB> observer . on_completed ( ) ","if has_result : 
","if result :
",56.98,0.0,False
def orthogonalEnd ( self ) : <TAB> if self . type == Segment . LINE : <TAB> <TAB> O = self . AB . orthogonal ( ) <TAB> <TAB> O . norm ( ) <TAB> <TAB> return O <TAB> else : <TAB> <TAB> O = self . B - self . C <TAB> <TAB> O . norm ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return - O <TAB> <TAB> else : <TAB> <TAB> <TAB> return O ,"if self . type == Segment . CCW : 
","if self . type == Segment . CCW :
",100.0,100.0,True
"def remove ( self , values ) : <TAB> if not isinstance ( values , ( list , tuple , set ) ) : <TAB> <TAB> values = [ values ] <TAB> for v in values : <TAB> <TAB> v = str ( v ) <TAB> <TAB> if isinstance ( self . _definition , dict ) : <TAB> <TAB> <TAB> self . _definition . pop ( v , None ) <TAB> <TAB> elif self . _definition == "" ANY "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . _definition = [ ] <TAB> <TAB> elif v in self . _definition : <TAB> <TAB> <TAB> self . _definition . remove ( v ) <TAB> if ( <TAB> <TAB> self . _value is not None <TAB> <TAB> and self . _value not in self . _definition <TAB> <TAB> and self . _not_any ( ) <TAB> ) : <TAB> <TAB> raise ConanException ( bad_value_msg ( self . _name , self . _value , self . values_range ) ) ","if v == "" ANY "" : 
","if not self . _definition :
",27.18,6.77,False
"def __enter__ ( self ) - > None : <TAB> try : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> signal . signal ( signal . SIGALRM , self . handle_timeout ) <TAB> <TAB> <TAB> signal . alarm ( self . seconds ) <TAB> except ValueError as ex : <TAB> <TAB> logger . warning ( "" timeout can ' t be used in the current context "" ) <TAB> <TAB> logger . exception ( ex ) ","if threading . current_thread ( ) == threading . main_thread ( ) : 
","if self . seconds is not None :
",31.64,2.08,False
"def __init__ ( self , fixed : MQTTFixedHeader = None ) : <TAB> if fixed is None : <TAB> <TAB> header = MQTTFixedHeader ( PINGRESP , 0x00 ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise HBMQTTException ( <TAB> <TAB> <TAB> <TAB> "" Invalid fixed packet type  %s  for PingRespPacket init "" <TAB> <TAB> <TAB> <TAB> % fixed . packet_type <TAB> <TAB> <TAB> ) <TAB> <TAB> header = fixed <TAB> super ( ) . __init__ ( header ) <TAB> self . variable_header = None <TAB> self . payload = None ","if fixed . packet_type is not PINGRESP : 
","if fixed . packet_type is not PINGRESP :
",100.0,100.0,True
"def _put_nowait ( self , data , * , sender ) : <TAB> if not self . _running : <TAB> <TAB> logger . warning ( "" Pub/Sub listener message after stop:  %r ,  %r "" , sender , data ) <TAB> <TAB> return <TAB> self . _queue . put_nowait ( ( sender , data ) ) <TAB> if self . _waiter is not None : <TAB> <TAB> fut , self . _waiter = self . _waiter , None <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> assert fut . cancelled ( ) , ( "" Waiting future is in wrong state "" , self , fut ) <TAB> <TAB> <TAB> return <TAB> <TAB> fut . set_result ( None ) ","if fut . done ( ) : 
","if fut . done ( ) :
",100.0,100.0,True
"def OnAssignBuiltin ( self , cmd_val ) : <TAB> # type: (cmd_value__Assign) -> None <TAB> buf = self . _ShTraceBegin ( ) <TAB> if not buf : <TAB> <TAB> return <TAB> for i , arg in enumerate ( cmd_val . argv ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> buf . write ( "" "" ) <TAB> <TAB> buf . write ( arg ) <TAB> for pair in cmd_val . pairs : <TAB> <TAB> buf . write ( "" "" ) <TAB> <TAB> buf . write ( pair . var_name ) <TAB> <TAB> buf . write ( "" = "" ) <TAB> <TAB> if pair . rval : <TAB> <TAB> <TAB> _PrintShValue ( pair . rval , buf ) <TAB> buf . write ( "" \n "" ) <TAB> self . f . write ( buf . getvalue ( ) ) ","if i != 0 : 
","if i :
",31.77,0.0,False
"def convertDict ( obj ) : <TAB> obj = dict ( obj ) <TAB> for k , v in obj . items ( ) : <TAB> <TAB> del obj [ k ] <TAB> <TAB> if not ( isinstance ( k , str ) or isinstance ( k , unicode ) ) : <TAB> <TAB> <TAB> k = dumps ( k ) <TAB> <TAB> <TAB> # Keep track of which keys need to be decoded when loading. <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> obj [ Types . KEYS ] = [ ] <TAB> <TAB> <TAB> obj [ Types . KEYS ] . append ( k ) <TAB> <TAB> obj [ k ] = convertObjects ( v ) <TAB> return obj ","if Types . KEYS not in obj : 
","if Types . KEYS not in obj :
",100.0,100.0,True
"def _ArgumentListHasDictionaryEntry ( self , token ) : <TAB> """"""Check if the function argument list has a dictionary as an arg."""""" <TAB> if _IsArgumentToFunction ( token ) : <TAB> <TAB> while token : <TAB> <TAB> <TAB> if token . value == "" { "" : <TAB> <TAB> <TAB> <TAB> length = token . matching_bracket . total_length - token . total_length <TAB> <TAB> <TAB> <TAB> return length + self . stack [ - 2 ] . indent > self . column_limit <TAB> <TAB> <TAB> if token . ClosesScope ( ) : <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> token = token . matching_bracket <TAB> <TAB> <TAB> token = token . next_token <TAB> return False ","if token . OpensScope ( ) : 
","if token . value == "" } "" :
",37.85,16.78,False
"def get_editable_dict ( self ) : <TAB> ret = { } <TAB> for ref , ws_package in self . _workspace_packages . items ( ) : <TAB> <TAB> path = ws_package . root_folder <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> path = os . path . join ( path , CONANFILE ) <TAB> <TAB> ret [ ref ] = { "" path "" : path , "" layout "" : ws_package . layout } <TAB> return ret ","if os . path . isdir ( path ) : 
","if not os . path . isabs ( path ) :
",67.38,48.33,False
"def serialize ( self , name = None ) : <TAB> data = super ( WebLink , self ) . serialize ( name ) <TAB> data [ "" contentType "" ] = self . contentType <TAB> if self . width : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise InvalidWidthException ( self . width ) <TAB> <TAB> data [ "" inputOptions "" ] = { } <TAB> <TAB> data [ "" width "" ] = self . width <TAB> data . update ( { "" content "" : { "" url "" : self . linkUrl , "" text "" : self . linkText } } ) <TAB> return data ","if self . width not in [ 100 , 50 , 33 , 25 ] : 
","if self . width not in [ 100 , 100 , 200 , 202 ] :
",79.3,57.91,False
"def callback ( lexer , match , context ) : <TAB> text = match . group ( ) <TAB> extra = "" "" <TAB> if start : <TAB> <TAB> context . next_indent = len ( text ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> while context . next_indent < context . indent : <TAB> <TAB> <TAB> <TAB> context . indent = context . indent_stack . pop ( ) <TAB> <TAB> <TAB> if context . next_indent > context . indent : <TAB> <TAB> <TAB> <TAB> extra = text [ context . indent : ] <TAB> <TAB> <TAB> <TAB> text = text [ : context . indent ] <TAB> else : <TAB> <TAB> context . next_indent + = len ( text ) <TAB> if text : <TAB> <TAB> yield match . start ( ) , TokenClass , text <TAB> if extra : <TAB> <TAB> yield match . start ( ) + len ( text ) , TokenClass . Error , extra <TAB> context . pos = match . end ( ) ","if context . next_indent < context . indent : 
","if context . next_indent < context . indent :
",100.0,100.0,True
"def _handle_unsubscribe ( self , web_sock ) : <TAB> index = None <TAB> with await self . _subscriber_lock : <TAB> <TAB> for i , ( subscriber_web_sock , _ ) in enumerate ( self . _subscribers ) : <TAB> <TAB> <TAB> if subscriber_web_sock == web_sock : <TAB> <TAB> <TAB> <TAB> index = i <TAB> <TAB> <TAB> <TAB> break <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del self . _subscribers [ index ] <TAB> <TAB> if not self . _subscribers : <TAB> <TAB> <TAB> asyncio . ensure_future ( self . _unregister_subscriptions ( ) ) ","if index is not None : 
","if index :
",29.58,0.0,False
"def test_missing_dict_param ( ) : <TAB> expected_err = "" params dictionary did not contain value for placeholder "" <TAB> try : <TAB> <TAB> substitute_params ( <TAB> <TAB> <TAB> "" SELECT * FROM cust WHERE salesrep =  %(name)s "" , { "" foobar "" : "" John Doe "" } <TAB> <TAB> ) <TAB> <TAB> assert False , "" expected exception b/c dict did not contain replacement value "" <TAB> except ValueError as exc : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> raise ","if expected_err not in str ( exc ) : 
","if expected_err != "" params not found "" :
",28.11,23.46,False
"def one_gpr_reg_one_mem_scalable ( ii ) : <TAB> n , r = 0 , 0 <TAB> for op in _gen_opnds ( ii ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> n + = 1 <TAB> <TAB> elif op_gprv ( op ) : <TAB> <TAB> <TAB> r + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> return False <TAB> return n == 1 and r == 1 ","if op_agen ( op ) or ( op_mem ( op ) and op . oc2 in [ "" v "" ] ) : 
","if op_mem ( op ) :
",36.63,7.82,False
"def on_enter ( self ) : <TAB> """"""Fired when mouse enter the bbox of the widget."""""" <TAB> if hasattr ( self , "" md_bg_color "" ) and self . focus_behavior : <TAB> <TAB> if hasattr ( self , "" theme_cls "" ) and not self . focus_color : <TAB> <TAB> <TAB> self . md_bg_color = self . theme_cls . bg_normal <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> self . md_bg_color = App . get_running_app ( ) . theme_cls . bg_normal <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> self . md_bg_color = self . focus_color ","if not self . focus_color : 
","if hasattr ( App , "" get_running_app ( ) "" theme_cls "" ) :
",26.72,2.52,False
"def __init__ ( self , * args , * * kwargs ) : <TAB> BaseCellExporter . __init__ ( self , * args , * * kwargs ) <TAB> self . comment = "" # "" <TAB> for key in [ "" cell_marker "" ] : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . metadata [ key ] = self . unfiltered_metadata [ key ] <TAB> if self . fmt . get ( "" rst2md "" ) : <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> "" The  ' rst2md '  option is a read only option. The reverse conversion is not  "" <TAB> <TAB> <TAB> "" implemented. Please either deactivate the option, or save to another format. "" <TAB> <TAB> )<TAB> # pragma: no cover ","if key in self . unfiltered_metadata : 
","if key in self . unfiltered_metadata :
",100.0,100.0,True
"def sendQueryQueueByAfterNate ( self ) : <TAB> for i in range ( 10 ) : <TAB> <TAB> queryQueueByAfterNateRsp = self . session . httpClint . send ( urls . get ( "" queryQueue "" ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> print ( <TAB> <TAB> <TAB> <TAB> "" "" . join ( queryQueueByAfterNateRsp . get ( "" messages "" ) ) <TAB> <TAB> <TAB> <TAB> or queryQueueByAfterNateRsp . get ( "" validateMessages "" ) <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> time . sleep ( 1 ) <TAB> <TAB> else : <TAB> <TAB> <TAB> sendEmail ( ticket . WAIT_ORDER_SUCCESS ) <TAB> <TAB> <TAB> sendServerChan ( ticket . WAIT_ORDER_SUCCESS ) <TAB> <TAB> <TAB> raise ticketIsExitsException ( ticket . WAIT_AFTER_NATE_SUCCESS ) ","if not queryQueueByAfterNateRsp . get ( "" status "" ) : 
","if queryQueueByAfterNateRsp . get ( "" messages "" ) :
",63.08,48.96,False
"def filter_errors ( self , errors : List [ str ] ) - > List [ str ] : <TAB> real_errors : List [ str ] = list ( ) <TAB> current_file = __file__ <TAB> current_path = os . path . split ( current_file ) <TAB> for line in errors : <TAB> <TAB> line = line . strip ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> continue <TAB> <TAB> fn , lno , lvl , msg = self . parse_trace_line ( line ) <TAB> <TAB> if fn is not None : <TAB> <TAB> <TAB> _path = os . path . split ( fn ) <TAB> <TAB> <TAB> if _path [ - 1 ] != current_path [ - 1 ] : <TAB> <TAB> <TAB> <TAB> continue <TAB> <TAB> real_errors . append ( line ) <TAB> return real_errors ","if not line : 
","if not line :
",100.0,100.0,True
"def pretty ( self , n , comment = True ) : <TAB> if isinstance ( n , ( str , bytes , list , tuple , dict ) ) : <TAB> <TAB> r = repr ( n ) <TAB> <TAB> if not comment :<TAB> # then it can be inside a comment! <TAB> <TAB> <TAB> r = r . replace ( "" */ "" , r "" \ x2a/ "" ) <TAB> <TAB> return r <TAB> if not isinstance ( n , six . integer_types ) : <TAB> <TAB> return n <TAB> if isinstance ( n , constants . Constant ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return "" %s  /*  %s  */ "" % ( n , self . pretty ( int ( n ) ) ) <TAB> <TAB> else : <TAB> <TAB> <TAB> return "" %s  ( %s ) "" % ( n , self . pretty ( int ( n ) ) ) <TAB> elif abs ( n ) < 10 : <TAB> <TAB> return str ( n ) <TAB> else : <TAB> <TAB> return hex ( n ) ","if comment : 
","if comment :
",78.12,0.0,False
"def get_pricings ( self , subscription_id : str ) : <TAB> try : <TAB> <TAB> client = self . get_client ( subscription_id ) <TAB> <TAB> pricings_list = await run_concurrently ( lambda : client . pricings . list ( ) ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> return pricings_list . value <TAB> <TAB> else : <TAB> <TAB> <TAB> return [ ] <TAB> except Exception as e : <TAB> <TAB> print_exception ( f "" Failed to retrieve pricings:  { e } "" ) <TAB> <TAB> return [ ] ","if hasattr ( pricings_list , "" value "" ) : 
","if pricings_list . value :
",26.51,14.23,False
"def add_doc ( target , variables , body_lines ) : <TAB> if isinstance ( target , ast . Name ) : <TAB> <TAB> # if it is a variable name add it to the doc <TAB> <TAB> name = target . id <TAB> <TAB> if name not in variables : <TAB> <TAB> <TAB> doc = find_doc_for ( target , body_lines ) <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> variables [ name ] = doc <TAB> elif isinstance ( target , ast . Tuple ) : <TAB> <TAB> # if it is a tuple then iterate the elements <TAB> <TAB> # this can happen like this: <TAB> <TAB> # a, b = 1, 2 <TAB> <TAB> for e in target . elts : <TAB> <TAB> <TAB> add_doc ( e , variables , body_lines ) ","if doc is not None : 
","if doc is not None :
",100.0,100.0,True
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ right ] ) : <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right ","if right == len ( text ) : 
","if right not in allowed_chars :
",28.53,10.79,False
"def pxrun_nodes ( self , * args , * * kwargs ) : <TAB> cell = self . _px_cell <TAB> if re . search ( r "" ^ \ s* %a utopx \ b "" , cell ) : <TAB> <TAB> self . _disable_autopx ( ) <TAB> <TAB> return False <TAB> else : <TAB> <TAB> try : <TAB> <TAB> <TAB> result = self . view . execute ( cell , silent = False , block = False ) <TAB> <TAB> except : <TAB> <TAB> <TAB> self . shell . showtraceback ( ) <TAB> <TAB> <TAB> return True <TAB> <TAB> else : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> try : <TAB> <TAB> <TAB> <TAB> <TAB> result . get ( ) <TAB> <TAB> <TAB> <TAB> except : <TAB> <TAB> <TAB> <TAB> <TAB> self . shell . showtraceback ( ) <TAB> <TAB> <TAB> <TAB> <TAB> return True <TAB> <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> <TAB> result . display_outputs ( ) <TAB> <TAB> <TAB> return False ","if self . view . block : 
","if isinstance ( result , Deferred ) :
",26.98,6.57,False
"def candidates ( ) - > Generator [ "" Symbol "" , None , None ] : <TAB> s = self <TAB> if Symbol . debug_lookup : <TAB> <TAB> Symbol . debug_print ( "" searching in self: "" ) <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) <TAB> while True : <TAB> <TAB> if matchSelf : <TAB> <TAB> <TAB> yield s <TAB> <TAB> if recurseInAnon : <TAB> <TAB> <TAB> yield from s . children_recurse_anon <TAB> <TAB> else : <TAB> <TAB> <TAB> yield from s . _children <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> break <TAB> <TAB> s = s . siblingAbove <TAB> <TAB> if Symbol . debug_lookup : <TAB> <TAB> <TAB> Symbol . debug_print ( "" searching in sibling: "" ) <TAB> <TAB> <TAB> print ( s . to_string ( Symbol . debug_indent + 1 ) , end = "" "" ) ","if s . siblingAbove is None : 
","if s . siblingAbove is None :
",100.0,100.0,True
"def decTaskGen ( ) : <TAB> cnt = intbv ( 0 , min = - n , max = n ) <TAB> while 1 : <TAB> <TAB> yield clock . posedge , reset . negedge <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> cnt [ : ] = 0 <TAB> <TAB> <TAB> count . next = 0 <TAB> <TAB> else : <TAB> <TAB> <TAB> # print count <TAB> <TAB> <TAB> decTaskFunc ( cnt , enable , reset , n ) <TAB> <TAB> <TAB> count . next = cnt ","if reset == ACTIVE_LOW : 
","if enable :
",28.55,0.0,False
"def __call__ ( self , * args , * * kwargs ) : <TAB> if not NET_INITTED : <TAB> <TAB> return self . raw ( * args , * * kwargs ) <TAB> for stack in traceback . walk_stack ( None ) : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> layer = stack [ 0 ] . f_locals [ "" self "" ] <TAB> <TAB> <TAB> if layer in layer_names : <TAB> <TAB> <TAB> <TAB> log . pytorch_layer_name = layer_names [ layer ] <TAB> <TAB> <TAB> <TAB> print ( layer_names [ layer ] ) <TAB> <TAB> <TAB> <TAB> break <TAB> out = self . obj ( self . raw , * args , * * kwargs ) <TAB> # if isinstance(out,Variable): <TAB> #<TAB>  out=[out]<TAB> return out ","if "" self "" in stack [ 0 ] . f_locals : 
","if stack :
",25.8,0.0,False
"def to_json_dict ( self ) : <TAB> d = super ( ) . to_json_dict ( ) <TAB> d [ "" bullet_list "" ] = RenderedContent . rendered_content_list_to_json ( self . bullet_list ) <TAB> if self . header is not None : <TAB> <TAB> if isinstance ( self . header , RenderedContent ) : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" header "" ] = self . header <TAB> if self . subheader is not None : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader . to_json_dict ( ) <TAB> <TAB> else : <TAB> <TAB> <TAB> d [ "" subheader "" ] = self . subheader <TAB> return d ","if isinstance ( self . subheader , RenderedContent ) : 
","if isinstance ( self . subheader , RenderedContent ) :
",100.0,100.0,True
"def add ( request ) : <TAB> form_type = "" servers "" <TAB> if request . method == "" POST "" : <TAB> <TAB> form = BookMarkForm ( request . POST ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> form_type = form . save ( ) <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , "" Bookmark created "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> messages . add_message ( request , messages . INFO , form . errors ) <TAB> <TAB> if form_type == "" server "" : <TAB> <TAB> <TAB> url = reverse ( "" servers "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> url = reverse ( "" metrics "" ) <TAB> <TAB> return redirect ( url ) <TAB> else : <TAB> <TAB> return redirect ( reverse ( "" servers "" ) ) ","if form . is_valid ( ) : 
","if form . is_valid ( ) :
",100.0,100.0,True
"def fee_amount_in_quote ( self , trading_pair : str , price : Decimal , order_amount : Decimal ) : <TAB> fee_amount = Decimal ( "" 0 "" ) <TAB> if self . percent > 0 : <TAB> <TAB> fee_amount = ( price * order_amount ) * self . percent <TAB> base , quote = trading_pair . split ( "" - "" ) <TAB> for flat_fee in self . flat_fees : <TAB> <TAB> if interchangeable ( flat_fee [ 0 ] , base ) : <TAB> <TAB> <TAB> fee_amount + = flat_fee [ 1 ] * price <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fee_amount + = flat_fee [ 1 ] <TAB> return fee_amount ","elif interchangeable ( flat_fee [ 0 ] , quote ) : 
","elif interchangeable ( flat_fee [ 0 ] , quote ) :
",100.0,100.0,True
"def load_batch ( fpath ) : <TAB> with open ( fpath , "" rb "" ) as f : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Python3 <TAB> <TAB> <TAB> d = pickle . load ( f , encoding = "" latin1 "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> # Python2 <TAB> <TAB> <TAB> d = pickle . load ( f ) <TAB> data = d [ "" data "" ] <TAB> labels = d [ "" labels "" ] <TAB> return data , labels ","if sys . version_info > ( 3 , 0 ) : 
","if sys . version_info > ( 3 , 0 ) :
",100.0,100.0,True
"def clear_entries ( options ) : <TAB> """"""Clear pending entries"""""" <TAB> with Session ( ) as session : <TAB> <TAB> query = session . query ( db . PendingEntry ) . filter ( db . PendingEntry . approved == False ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> query = query . filter ( db . PendingEntry . task_name == options . task_name ) <TAB> <TAB> deleted = query . delete ( ) <TAB> <TAB> console ( "" Successfully deleted  %i  pending entries "" % deleted ) ","if options . task_name : 
","if options . task_name :
",100.0,100.0,True
"def attribute_table ( self , attribute ) : <TAB> """"""Return a tuple (schema, table) for attribute."""""" <TAB> dimension = attribute . dimension <TAB> if dimension : <TAB> <TAB> schema = self . naming . dimension_schema or self . naming . schema <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> table = self . fact_name <TAB> <TAB> else : <TAB> <TAB> <TAB> table = self . naming . dimension_table_name ( dimension ) <TAB> else : <TAB> <TAB> table = self . fact_name <TAB> <TAB> schema = self . naming . schema <TAB> return ( schema , table ) ","if dimension . is_flat and not dimension . has_details : 
","if not dimension :
",27.56,3.12,False
"def remove_rating ( self , songs , librarian ) : <TAB> count = len ( songs ) <TAB> if count > 1 and config . getboolean ( "" browsers "" , "" rating_confirm_multiple "" ) : <TAB> <TAB> parent = qltk . get_menu_item_top_parent ( self ) <TAB> <TAB> dialog = ConfirmRateMultipleDialog ( parent , _ ( "" _Remove Rating "" ) , count , None ) <TAB> <TAB> if dialog . run ( ) != Gtk . ResponseType . YES : <TAB> <TAB> <TAB> return <TAB> reset = [ ] <TAB> for song in songs : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> del song [ "" ~#rating "" ] <TAB> <TAB> <TAB> reset . append ( song ) <TAB> librarian . changed ( reset ) ","if "" ~#rating "" in song : 
","if "" ~#rating "" in song :
",100.0,100.0,True
"def find_word_bounds ( self , text , index , allowed_chars ) : <TAB> right = left = index <TAB> done = False <TAB> while not done : <TAB> <TAB> if left == 0 : <TAB> <TAB> <TAB> done = True <TAB> <TAB> elif not self . word_boundary_char ( text [ left - 1 ] ) : <TAB> <TAB> <TAB> left - = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> done = False <TAB> while not done : <TAB> <TAB> if right == len ( text ) : <TAB> <TAB> <TAB> done = True <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> right + = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> done = True <TAB> return left , right ","elif not self . word_boundary_char ( text [ right ] ) : 
","elif self . word_boundary_char ( text [ right ] ) :
",78.03,88.08,False
"def handle_read ( self ) : <TAB> """"""Called when there is data waiting to be read."""""" <TAB> try : <TAB> <TAB> chunk = self . recv ( self . ac_in_buffer_size ) <TAB> except RetryError : <TAB> <TAB> pass <TAB> except socket . error : <TAB> <TAB> self . handle_error ( ) <TAB> else : <TAB> <TAB> self . tot_bytes_received + = len ( chunk ) <TAB> <TAB> if not chunk : <TAB> <TAB> <TAB> self . transfer_finished = True <TAB> <TAB> <TAB> # self.close()  # <-- asyncore.recv() already do that... <TAB> <TAB> <TAB> return <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> chunk = self . _data_wrapper ( chunk ) <TAB> <TAB> try : <TAB> <TAB> <TAB> self . file_obj . write ( chunk ) <TAB> <TAB> except OSError as err : <TAB> <TAB> <TAB> raise _FileReadWriteError ( err ) ","if self . _data_wrapper is not None : 
","if self . _data_wrapper :
",47.74,59.76,False
"def toggle ( self , event = None ) : <TAB> if self . absolute : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 100 <TAB> <TAB> if self . split > 20 : <TAB> <TAB> <TAB> self . save = self . split <TAB> <TAB> <TAB> self . split = 1 <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . save <TAB> else : <TAB> <TAB> if self . save == self . split : <TAB> <TAB> <TAB> self . save = 0.3 <TAB> <TAB> if self . split < = self . min or self . split > = self . max : <TAB> <TAB> <TAB> self . split = self . save <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> self . split = self . min <TAB> <TAB> else : <TAB> <TAB> <TAB> self . split = self . max <TAB> self . placeChilds ( ) ","elif self . split < 0.5 : 
","elif self . split < = self . min :
",57.85,41.11,False
"def readAtOffset ( self , offset , size , shortok = False ) : <TAB> ret = b "" "" <TAB> self . fd . seek ( offset ) <TAB> while len ( ret ) != size : <TAB> <TAB> rlen = size - len ( ret ) <TAB> <TAB> x = self . fd . read ( rlen ) <TAB> <TAB> if x == b "" "" : <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> return None <TAB> <TAB> <TAB> return ret <TAB> <TAB> ret + = x <TAB> return ret ","if not shortok : 
","if shortok :
",34.18,0.0,False
"def webfinger ( environ , start_response , _ ) : <TAB> query = parse_qs ( environ [ "" QUERY_STRING "" ] ) <TAB> try : <TAB> <TAB> rel = query [ "" rel "" ] <TAB> <TAB> resource = query [ "" resource "" ] [ 0 ] <TAB> except KeyError : <TAB> <TAB> resp = BadRequest ( "" Missing parameter in request "" ) <TAB> else : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> resp = BadRequest ( "" Bad issuer in request "" ) <TAB> <TAB> else : <TAB> <TAB> <TAB> wf = WebFinger ( ) <TAB> <TAB> <TAB> resp = Response ( wf . response ( subject = resource , base = OAS . baseurl ) ) <TAB> return resp ( environ , start_response ) ","if rel != [ OIC_ISSUER ] : 
","if rel != [ OAS . OAS_ISSUER ] :
",46.28,53.11,False
"def _tokenize ( self , text ) : <TAB> if format_text ( text ) == EMPTY_TEXT : <TAB> <TAB> return [ self . additional_special_tokens [ 0 ] ] <TAB> split_tokens = [ ] <TAB> if self . do_basic_tokenize : <TAB> <TAB> for token in self . basic_tokenizer . tokenize ( <TAB> <TAB> <TAB> text , never_split = self . all_special_tokens <TAB> <TAB> ) : <TAB> <TAB> <TAB> # If the token is part of the never_split set <TAB> <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> <TAB> split_tokens . append ( token ) <TAB> <TAB> <TAB> else : <TAB> <TAB> <TAB> <TAB> split_tokens + = self . wordpiece_tokenizer . tokenize ( token ) <TAB> else : <TAB> <TAB> split_tokens = self . wordpiece_tokenizer . tokenize ( text ) <TAB> return split_tokens ","if token in self . basic_tokenizer . never_split : 
","if token in self . basic_tokenizer . never_split :
",100.0,100.0,True
"def send_packed_command ( self , command , check_health = True ) : <TAB> if not self . _sock : <TAB> <TAB> self . connect ( ) <TAB> try : <TAB> <TAB> if isinstance ( command , str ) : <TAB> <TAB> <TAB> command = [ command ] <TAB> <TAB> for item in command : <TAB> <TAB> <TAB> self . _sock . sendall ( item ) <TAB> except socket . error as e : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> _errno , errmsg = "" UNKNOWN "" , e . args [ 0 ] <TAB> <TAB> else : <TAB> <TAB> <TAB> _errno , errmsg = e . args <TAB> <TAB> raise ConnectionError ( <TAB> <TAB> <TAB> "" Error  %s  while writing to socket.  %s . "" % ( _errno , errmsg ) <TAB> <TAB> ) <TAB> except Exception : <TAB> <TAB> self . disconnect ( ) <TAB> <TAB> raise ","if len ( e . args ) == 1 : 
","if e . args [ 0 ] == ENOTCONN :
",35.52,19.08,False
"def to_value ( self , value ) : <TAB> # Tip: 'value' is the object returned by <TAB> #<TAB>   taiga.projects.history.models.HistoryEntry.values_diff()<TAB> ret = { } <TAB> for key , val in value . items ( ) : <TAB> <TAB> if key in [ "" attachments "" , "" custom_attributes "" , "" description_diff "" ] : <TAB> <TAB> <TAB> ret [ key ] = val <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> ret [ key ] = { k : { "" from "" : v [ 0 ] , "" to "" : v [ 1 ] } for k , v in val . items ( ) } <TAB> <TAB> else : <TAB> <TAB> <TAB> ret [ key ] = { "" from "" : val [ 0 ] , "" to "" : val [ 1 ] } <TAB> return ret ","elif key == "" points "" : 
","elif isinstance ( val , dict ) :
",26.98,6.57,False
"def to_child ( cls , key = None , process = None ) : <TAB> if process is not None : <TAB> <TAB> if type ( process ) is not dict : <TAB> <TAB> <TAB> raise ValueError ( <TAB> <TAB> <TAB> <TAB> ' Invalid value provided for  "" process ""  parameter, expected a dictionary ' <TAB> <TAB> <TAB> ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> # Merge class `__process__` parameters with provided parameters <TAB> <TAB> <TAB> result = { } <TAB> <TAB> <TAB> result . update ( deepcopy ( cls . __process__ ) ) <TAB> <TAB> <TAB> result . update ( process ) <TAB> <TAB> <TAB> process = result <TAB> class Child ( cls ) : <TAB> <TAB> __key__ = key <TAB> <TAB> __process__ = process <TAB> <TAB> __root__ = False <TAB> Child . __name__ = cls . __name__ <TAB> return Child ","if cls . __process__ : 
","if key is not None and cls . __process__ :
",57.96,52.96,False
"def _super_function ( args ) : <TAB> passed_class , passed_self = args . get_arguments ( [ "" type "" , "" self "" ] ) <TAB> if passed_self is None : <TAB> <TAB> return passed_class <TAB> else : <TAB> <TAB> # pyclass = passed_self.get_type() <TAB> <TAB> pyclass = passed_class <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> supers = pyclass . get_superclasses ( ) <TAB> <TAB> <TAB> if supers : <TAB> <TAB> <TAB> <TAB> return pyobjects . PyObject ( supers [ 0 ] ) <TAB> <TAB> return passed_self ","if isinstance ( pyclass , pyobjects . AbstractClass ) : 
","if pyclass :
",26.15,0.0,False
"def get_data ( row ) : <TAB> data = [ ] <TAB> for field_name , field_xpath in fields : <TAB> <TAB> result = row . xpath ( field_xpath ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> result = "" "" . join ( <TAB> <TAB> <TAB> <TAB> text <TAB> <TAB> <TAB> <TAB> for text in map ( <TAB> <TAB> <TAB> <TAB> <TAB> six . text_type . strip , map ( six . text_type , map ( unescape , result ) ) <TAB> <TAB> <TAB> <TAB> ) <TAB> <TAB> <TAB> <TAB> if text <TAB> <TAB> <TAB> ) <TAB> <TAB> else : <TAB> <TAB> <TAB> result = None <TAB> <TAB> data . append ( result ) <TAB> return data ","if result : 
","if result :
",78.12,0.0,False
"def say ( jarvis , s ) : <TAB> """"""Reads what is typed."""""" <TAB> if not s : <TAB> <TAB> jarvis . say ( "" What should I say? "" ) <TAB> else : <TAB> <TAB> voice_state = jarvis . is_voice_enabled ( ) <TAB> <TAB> jarvis . enable_voice ( ) <TAB> <TAB> jarvis . say ( s ) <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> jarvis . disable_voice ( ) ","if not voice_state : 
","if voice_state :
",34.18,57.89,False
"def __import__ ( name , globals = None , locals = None , fromlist = ( ) , level = 0 ) : <TAB> module = orig___import__ ( name , globals , locals , fromlist , level ) <TAB> if fromlist and module . __name__ in modules : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> fromlist = list ( fromlist ) <TAB> <TAB> <TAB> fromlist . remove ( "" * "" ) <TAB> <TAB> <TAB> fromlist . extend ( getattr ( module , "" __all__ "" , [ ] ) ) <TAB> <TAB> for x in fromlist : <TAB> <TAB> <TAB> if isinstance ( getattr ( module , x , None ) , types . ModuleType ) : <TAB> <TAB> <TAB> <TAB> from_name = "" {} . {} "" . format ( module . __name__ , x ) <TAB> <TAB> <TAB> <TAB> if from_name in modules : <TAB> <TAB> <TAB> <TAB> <TAB> importlib . import_module ( from_name ) <TAB> return module ","if "" * "" in fromlist : 
","if "" * "" in fromlist :
",100.0,100.0,True
"def _read_pricing_file ( self , region = None , pricing_file = None ) : <TAB> if not self . __pricing_file_cache : <TAB> <TAB> <MASK> <TAB> <TAB> <TAB> logging . info ( "" Reading pricing file... "" ) <TAB> <TAB> <TAB> with open ( pricing_file ) as data_file : <TAB> <TAB> <TAB> <TAB> self . __pricing_file_cache = json . load ( data_file ) <TAB> <TAB> else : <TAB> <TAB> <TAB> self . __pricing_file_cache = self . _download_pricing_file ( region ) <TAB> return self . __pricing_file_cache ","if pricing_file : 
","if pricing_file :
",78.12,100.0,True
